Fri Mar  1 10:48:23 2024       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 545.23.08              Driver Version: 545.23.08    CUDA Version: 12.3     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA TITAN Xp                Off | 00000000:83:00.0 Off |                  N/A |
| 23%   25C    P8               9W / 250W |      0MiB / 12288MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|  No running processes found                                                           |
+---------------------------------------------------------------------------------------+


* * * Run SGD for cluster size = 7. * * *


Budget: 71


* * * Run SGD for ID = 7_1. * * *


2024-03-01 10:48:25.831771: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-01 10:48:44.492799: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-01 10:48:44.494903: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-01 10:48:44.540016: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-01 10:48:44.540048: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-01 10:48:44.610467: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-01 10:48:44.610515: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-01 10:48:44.666110: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-01 10:48:44.816680: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-01 10:48:44.860900: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-01 10:48:44.910786: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-01 10:48:45.018234: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-01 10:48:45.019116: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-01 10:48:45.019217: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
<__array_function__ internals>:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray
/home/gkb738/.conda/envs/TF_KERAS_GPU/lib/python3.9/site-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray
  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])
/home/gkb738/.conda/envs/TF_KERAS_GPU/lib/python3.9/site-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray
  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])
2024-03-01 10:48:50.627197: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-01 10:48:50.627718: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-01 10:48:50.628286: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-01 10:48:50.628315: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-01 10:48:50.628360: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-01 10:48:50.628380: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-01 10:48:50.628398: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-01 10:48:50.628416: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-01 10:48:50.628436: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-01 10:48:50.628455: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-01 10:48:50.628474: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-01 10:48:50.629233: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-01 10:48:50.629267: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-01 10:48:52.787984: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-01 10:48:52.788040: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-01 10:48:52.788050: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-01 10:48:52.789007: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': '07_01', 'seed': 1, 'out_folder': 'results/epoch_budget', 'batch_size': 32, 'epochs': 71, 'validation_split': 0.2, 'checkpointing': True, 'initial_lr': 0.1, 'momentum': 0.98, 'nesterov': True, 'bootstrapping': False, 'map_optimizer': True, 'model': 'CNN-LSTM', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Loading data...
Pad sequences (samples x time)
20000 train sequences
5000 validation sequences
25000 test sequences
x_train shape: (20000, 100)
x_val shape: (5000, 100)
x_test shape: (25000, 100)
Using MAP optimizer with reg_weight:  5e-05
CNN-LSTM
0epoch [00:00, ?epoch/s]  0%|          | 0/71 [00:00<?, ?epoch/s]2024-03-01 10:48:53.210231: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-01 10:48:53.221951: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199945000 Hz
2024-03-01 10:48:54.749020: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-01 10:48:54.925794: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-01 10:48:56.698329: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-01 10:48:56.737871: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|▏         | 1/71 [00:14<16:52, 14.47s/epoch, loss=0.694, accuracy=0.597, val_loss=0.513, val_accuracy=0.789]  3%|▎         | 2/71 [00:22<12:23, 10.78s/epoch, loss=0.472, accuracy=0.818, val_loss=0.455, val_accuracy=0.837]  4%|▍         | 3/71 [00:30<10:47,  9.52s/epoch, loss=0.437, accuracy=0.858, val_loss=0.47, val_accuracy=0.847]   6%|▌         | 4/71 [00:37<09:39,  8.64s/epoch, loss=0.435, accuracy=0.869, val_loss=0.522, val_accuracy=0.846]  7%|▋         | 5/71 [00:45<08:59,  8.17s/epoch, loss=0.472, accuracy=0.877, val_loss=0.59, val_accuracy=0.834]   8%|▊         | 6/71 [00:52<08:33,  7.89s/epoch, loss=0.55, accuracy=0.865, val_loss=0.732, val_accuracy=0.798] 10%|▉         | 7/71 [00:59<08:12,  7.70s/epoch, loss=0.877, accuracy=0.756, val_loss=1.13, val_accuracy=0.646] 11%|█▏        | 8/71 [01:07<07:56,  7.57s/epoch, loss=1.18, accuracy=0.604, val_loss=1.19, val_accuracy=0.599]  13%|█▎        | 9/71 [01:14<07:43,  7.48s/epoch, loss=1.14, accuracy=0.603, val_loss=1.14, val_accuracy=0.613] 14%|█▍        | 10/71 [01:21<07:33,  7.44s/epoch, loss=1.14, accuracy=0.561, val_loss=1.11, val_accuracy=0.623] 15%|█▌        | 11/71 [01:29<07:22,  7.37s/epoch, loss=1.09, accuracy=0.55, val_loss=1.04, val_accuracy=0.603]  17%|█▋        | 12/71 [01:36<07:13,  7.36s/epoch, loss=1.02, accuracy=0.584, val_loss=0.988, val_accuracy=0.619] 18%|█▊        | 13/71 [01:43<07:04,  7.31s/epoch, loss=0.999, accuracy=0.58, val_loss=1.07, val_accuracy=0.556]  20%|█▉        | 14/71 [01:50<06:55,  7.29s/epoch, loss=1.01, accuracy=0.583, val_loss=1.07, val_accuracy=0.568] 21%|██        | 15/71 [01:58<06:49,  7.31s/epoch, loss=1.02, accuracy=0.544, val_loss=0.991, val_accuracy=0.509] 23%|██▎       | 16/71 [02:05<06:43,  7.33s/epoch, loss=0.982, accuracy=0.522, val_loss=0.992, val_accuracy=0.516] 24%|██▍       | 17/71 [02:12<06:35,  7.32s/epoch, loss=0.92, accuracy=0.537, val_loss=0.892, val_accuracy=0.557]  25%|██▌       | 18/71 [02:20<06:25,  7.28s/epoch, loss=0.878, accuracy=0.559, val_loss=0.826, val_accuracy=0.61] 27%|██▋       | 19/71 [02:27<06:19,  7.29s/epoch, loss=0.824, accuracy=0.608, val_loss=0.809, val_accuracy=0.658] 28%|██▊       | 20/71 [02:34<06:12,  7.31s/epoch, loss=0.864, accuracy=0.621, val_loss=0.857, val_accuracy=0.648] 30%|██▉       | 21/71 [02:41<06:03,  7.27s/epoch, loss=0.885, accuracy=0.606, val_loss=0.856, val_accuracy=0.652] 31%|███       | 22/71 [02:49<05:56,  7.28s/epoch, loss=0.869, accuracy=0.626, val_loss=0.935, val_accuracy=0.62]  32%|███▏      | 23/71 [02:56<05:49,  7.29s/epoch, loss=0.895, accuracy=0.607, val_loss=0.877, val_accuracy=0.584] 34%|███▍      | 24/71 [03:03<05:43,  7.30s/epoch, loss=0.878, accuracy=0.626, val_loss=0.89, val_accuracy=0.6]    35%|███▌      | 25/71 [03:11<05:36,  7.31s/epoch, loss=0.9, accuracy=0.624, val_loss=0.912, val_accuracy=0.623] 37%|███▋      | 26/71 [03:18<05:29,  7.31s/epoch, loss=0.923, accuracy=0.608, val_loss=0.928, val_accuracy=0.513] 38%|███▊      | 27/71 [03:25<05:21,  7.31s/epoch, loss=0.893, accuracy=0.605, val_loss=0.892, val_accuracy=0.596] 39%|███▉      | 28/71 [03:33<05:13,  7.29s/epoch, loss=0.858, accuracy=0.61, val_loss=0.842, val_accuracy=0.615]  41%|████      | 29/71 [03:40<05:07,  7.32s/epoch, loss=0.862, accuracy=0.607, val_loss=0.841, val_accuracy=0.604] 42%|████▏     | 30/71 [03:47<04:58,  7.28s/epoch, loss=0.905, accuracy=0.606, val_loss=0.93, val_accuracy=0.568]  44%|████▎     | 31/71 [03:54<04:50,  7.27s/epoch, loss=1.14, accuracy=0.608, val_loss=1.18, val_accuracy=0.624]  45%|████▌     | 32/71 [04:02<04:43,  7.28s/epoch, loss=1.1, accuracy=0.644, val_loss=1.04, val_accuracy=0.635]  46%|████▋     | 33/71 [04:09<04:36,  7.27s/epoch, loss=1.01, accuracy=0.642, val_loss=1.01, val_accuracy=0.615] 48%|████▊     | 34/71 [04:16<04:28,  7.27s/epoch, loss=1.01, accuracy=0.649, val_loss=1, val_accuracy=0.661]    49%|████▉     | 35/71 [04:24<04:22,  7.29s/epoch, loss=0.959, accuracy=0.667, val_loss=0.928, val_accuracy=0.688] 51%|█████     | 36/71 [04:31<04:15,  7.29s/epoch, loss=0.944, accuracy=0.661, val_loss=0.987, val_accuracy=0.618] 52%|█████▏    | 37/71 [04:38<04:08,  7.31s/epoch, loss=0.981, accuracy=0.612, val_loss=0.943, val_accuracy=0.624] 54%|█████▎    | 38/71 [04:46<04:00,  7.30s/epoch, loss=0.919, accuracy=0.635, val_loss=0.892, val_accuracy=0.641] 55%|█████▍    | 39/71 [04:53<03:54,  7.32s/epoch, loss=0.886, accuracy=0.666, val_loss=0.872, val_accuracy=0.67]  56%|█████▋    | 40/71 [05:00<03:46,  7.31s/epoch, loss=0.912, accuracy=0.655, val_loss=1.05, val_accuracy=0.603] 58%|█████▊    | 41/71 [05:07<03:39,  7.32s/epoch, loss=1.01, accuracy=0.648, val_loss=1.08, val_accuracy=0.601]  59%|█████▉    | 42/71 [05:15<03:31,  7.30s/epoch, loss=1.01, accuracy=0.612, val_loss=0.984, val_accuracy=0.619] 61%|██████    | 43/71 [05:22<03:24,  7.30s/epoch, loss=0.941, accuracy=0.636, val_loss=0.962, val_accuracy=0.615] 62%|██████▏   | 44/71 [05:29<03:16,  7.28s/epoch, loss=0.895, accuracy=0.658, val_loss=0.858, val_accuracy=0.666] 63%|██████▎   | 45/71 [05:37<03:09,  7.28s/epoch, loss=0.992, accuracy=0.607, val_loss=1.02, val_accuracy=0.612]  65%|██████▍   | 46/71 [05:44<03:02,  7.32s/epoch, loss=1.01, accuracy=0.584, val_loss=0.963, val_accuracy=0.589] 66%|██████▌   | 47/71 [05:51<02:55,  7.31s/epoch, loss=0.956, accuracy=0.581, val_loss=0.918, val_accuracy=0.615] 68%|██████▊   | 48/71 [05:59<02:47,  7.29s/epoch, loss=0.894, accuracy=0.613, val_loss=0.865, val_accuracy=0.613] 69%|██████▉   | 49/71 [06:06<02:40,  7.30s/epoch, loss=0.839, accuracy=0.648, val_loss=0.894, val_accuracy=0.624] 70%|███████   | 50/71 [06:13<02:32,  7.29s/epoch, loss=0.862, accuracy=0.615, val_loss=0.854, val_accuracy=0.641] 72%|███████▏  | 51/71 [06:20<02:25,  7.29s/epoch, loss=0.896, accuracy=0.603, val_loss=0.915, val_accuracy=0.515] 73%|███████▎  | 52/71 [06:28<02:18,  7.31s/epoch, loss=0.879, accuracy=0.6, val_loss=0.876, val_accuracy=0.632]   75%|███████▍  | 53/71 [06:35<02:11,  7.33s/epoch, loss=0.875, accuracy=0.605, val_loss=0.86, val_accuracy=0.624] 76%|███████▌  | 54/71 [06:42<02:03,  7.29s/epoch, loss=0.871, accuracy=0.614, val_loss=0.888, val_accuracy=0.588] 77%|███████▋  | 55/71 [06:50<01:56,  7.27s/epoch, loss=0.87, accuracy=0.593, val_loss=0.842, val_accuracy=0.613]  79%|███████▉  | 56/71 [06:57<01:49,  7.29s/epoch, loss=0.844, accuracy=0.617, val_loss=0.823, val_accuracy=0.642] 80%|████████  | 57/71 [07:04<01:41,  7.28s/epoch, loss=0.832, accuracy=0.646, val_loss=0.869, val_accuracy=0.653] 82%|████████▏ | 58/71 [07:11<01:34,  7.30s/epoch, loss=0.865, accuracy=0.619, val_loss=0.881, val_accuracy=0.62]  83%|████████▎ | 59/71 [07:19<01:27,  7.29s/epoch, loss=0.858, accuracy=0.64, val_loss=0.915, val_accuracy=0.598] 85%|████████▍ | 60/71 [07:26<01:20,  7.28s/epoch, loss=0.862, accuracy=0.639, val_loss=0.94, val_accuracy=0.515] 86%|████████▌ | 61/71 [07:33<01:12,  7.27s/epoch, loss=0.911, accuracy=0.612, val_loss=0.874, val_accuracy=0.641] 87%|████████▋ | 62/71 [07:41<01:05,  7.30s/epoch, loss=0.916, accuracy=0.608, val_loss=0.91, val_accuracy=0.606]  89%|████████▊ | 63/71 [07:48<00:58,  7.30s/epoch, loss=0.916, accuracy=0.583, val_loss=0.881, val_accuracy=0.606] 90%|█████████ | 64/71 [07:55<00:50,  7.27s/epoch, loss=0.865, accuracy=0.639, val_loss=0.864, val_accuracy=0.618] 92%|█████████▏| 65/71 [08:02<00:43,  7.28s/epoch, loss=0.918, accuracy=0.635, val_loss=1.08, val_accuracy=0.623]  93%|█████████▎| 66/71 [08:10<00:36,  7.27s/epoch, loss=1.03, accuracy=0.645, val_loss=1, val_accuracy=0.642]     94%|█████████▍| 67/71 [08:17<00:29,  7.27s/epoch, loss=1.02, accuracy=0.609, val_loss=1, val_accuracy=0.546] 96%|█████████▌| 68/71 [08:24<00:21,  7.28s/epoch, loss=1.1, accuracy=0.581, val_loss=1.16, val_accuracy=0.625] 97%|█████████▋| 69/71 [08:31<00:14,  7.27s/epoch, loss=1.13, accuracy=0.616, val_loss=1.13, val_accuracy=0.649] 99%|█████████▊| 70/71 [08:39<00:07,  7.28s/epoch, loss=1.03, accuracy=0.644, val_loss=0.987, val_accuracy=0.634]100%|██████████| 71/71 [08:46<00:00,  7.28s/epoch, loss=1.25, accuracy=0.657, val_loss=1.28, val_accuracy=0.651] 100%|██████████| 71/71 [08:46<00:00,  7.42s/epoch, loss=1.25, accuracy=0.657, val_loss=1.28, val_accuracy=0.651]
Test score: 0.47547483444213867
Test accuracy: 0.8409600257873535


* * * Run SGD for ID = 7_2. * * *


2024-03-01 10:57:46.468080: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-01 10:57:50.396534: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-01 10:57:50.397697: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-01 10:57:50.439845: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-01 10:57:50.439891: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-01 10:57:50.442974: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-01 10:57:50.443049: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-01 10:57:50.445310: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-01 10:57:50.446482: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-01 10:57:50.448896: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-01 10:57:50.450496: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-01 10:57:50.455571: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-01 10:57:50.456270: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-01 10:57:50.456399: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
<__array_function__ internals>:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray
/home/gkb738/.conda/envs/TF_KERAS_GPU/lib/python3.9/site-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray
  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])
/home/gkb738/.conda/envs/TF_KERAS_GPU/lib/python3.9/site-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray
  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])
2024-03-01 10:57:57.028058: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-01 10:57:57.028648: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-01 10:57:57.029177: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-01 10:57:57.029218: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-01 10:57:57.029268: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-01 10:57:57.029290: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-01 10:57:57.029312: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-01 10:57:57.029332: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-01 10:57:57.029353: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-01 10:57:57.029374: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-01 10:57:57.029396: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-01 10:57:57.029911: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-01 10:57:57.029955: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-01 10:57:57.821124: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-01 10:57:57.821187: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-01 10:57:57.821197: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-01 10:57:57.822589: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': '07_02', 'seed': 2, 'out_folder': 'results/epoch_budget', 'batch_size': 32, 'epochs': 71, 'validation_split': 0.2, 'checkpointing': True, 'initial_lr': 0.1, 'momentum': 0.98, 'nesterov': True, 'bootstrapping': False, 'map_optimizer': True, 'model': 'CNN-LSTM', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Loading data...
Pad sequences (samples x time)
20000 train sequences
5000 validation sequences
25000 test sequences
x_train shape: (20000, 100)
x_val shape: (5000, 100)
x_test shape: (25000, 100)
Using MAP optimizer with reg_weight:  5e-05
CNN-LSTM
0epoch [00:00, ?epoch/s]  0%|          | 0/71 [00:00<?, ?epoch/s]2024-03-01 10:57:58.308541: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-01 10:57:58.321000: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199945000 Hz
2024-03-01 10:58:00.142931: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-01 10:58:00.357777: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-01 10:58:01.176950: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-01 10:58:01.227171: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|▏         | 1/71 [00:14<16:24, 14.06s/epoch, loss=0.663, accuracy=0.634, val_loss=0.531, val_accuracy=0.798]  3%|▎         | 2/71 [00:21<12:00, 10.45s/epoch, loss=0.474, accuracy=0.823, val_loss=0.453, val_accuracy=0.843]  4%|▍         | 3/71 [00:29<10:14,  9.03s/epoch, loss=0.425, accuracy=0.858, val_loss=0.503, val_accuracy=0.839]  6%|▌         | 4/71 [00:36<09:24,  8.42s/epoch, loss=0.432, accuracy=0.874, val_loss=0.51, val_accuracy=0.848]   7%|▋         | 5/71 [00:44<08:49,  8.03s/epoch, loss=0.446, accuracy=0.879, val_loss=0.628, val_accuracy=0.819]  8%|▊         | 6/71 [00:51<08:25,  7.77s/epoch, loss=0.478, accuracy=0.885, val_loss=0.668, val_accuracy=0.826] 10%|▉         | 7/71 [00:58<08:06,  7.60s/epoch, loss=0.499, accuracy=0.892, val_loss=0.697, val_accuracy=0.809] 11%|█▏        | 8/71 [01:05<07:42,  7.34s/epoch, loss=0.705, accuracy=0.818, val_loss=0.942, val_accuracy=0.734] 13%|█▎        | 9/71 [01:11<07:15,  7.02s/epoch, loss=1.1, accuracy=0.652, val_loss=1.17, val_accuracy=0.616]    14%|█▍        | 10/71 [01:18<06:56,  6.82s/epoch, loss=1.12, accuracy=0.619, val_loss=1.09, val_accuracy=0.644] 15%|█▌        | 11/71 [01:24<06:41,  6.70s/epoch, loss=1.09, accuracy=0.63, val_loss=1.21, val_accuracy=0.607]  17%|█▋        | 12/71 [01:31<06:44,  6.86s/epoch, loss=1.24, accuracy=0.549, val_loss=1.23, val_accuracy=0.563] 18%|█▊        | 13/71 [01:39<06:45,  7.00s/epoch, loss=1.15, accuracy=0.538, val_loss=1.11, val_accuracy=0.509] 20%|█▉        | 14/71 [01:46<06:45,  7.12s/epoch, loss=1.05, accuracy=0.523, val_loss=1.03, val_accuracy=0.583] 21%|██        | 15/71 [01:54<06:45,  7.23s/epoch, loss=0.967, accuracy=0.562, val_loss=0.91, val_accuracy=0.621] 23%|██▎       | 16/71 [02:01<06:40,  7.28s/epoch, loss=0.932, accuracy=0.565, val_loss=0.899, val_accuracy=0.613] 24%|██▍       | 17/71 [02:08<06:36,  7.34s/epoch, loss=0.897, accuracy=0.607, val_loss=0.868, val_accuracy=0.641] 25%|██▌       | 18/71 [02:16<06:31,  7.39s/epoch, loss=0.862, accuracy=0.64, val_loss=0.822, val_accuracy=0.673]  27%|██▋       | 19/71 [02:23<06:22,  7.36s/epoch, loss=0.872, accuracy=0.645, val_loss=0.889, val_accuracy=0.579] 28%|██▊       | 20/71 [02:31<06:16,  7.37s/epoch, loss=0.915, accuracy=0.599, val_loss=0.927, val_accuracy=0.53]  30%|██▉       | 21/71 [02:38<06:09,  7.38s/epoch, loss=0.936, accuracy=0.572, val_loss=0.895, val_accuracy=0.604] 31%|███       | 22/71 [02:45<06:01,  7.39s/epoch, loss=0.941, accuracy=0.599, val_loss=0.913, val_accuracy=0.637] 32%|███▏      | 23/71 [02:53<05:54,  7.38s/epoch, loss=0.914, accuracy=0.626, val_loss=0.904, val_accuracy=0.626] 34%|███▍      | 24/71 [03:00<05:47,  7.40s/epoch, loss=1.15, accuracy=0.62, val_loss=2.36, val_accuracy=0.6]      35%|███▌      | 25/71 [03:08<05:42,  7.45s/epoch, loss=2.21, accuracy=0.608, val_loss=2.08, val_accuracy=0.51] 37%|███▋      | 26/71 [03:15<05:35,  7.45s/epoch, loss=1.84, accuracy=0.611, val_loss=1.67, val_accuracy=0.635] 38%|███▊      | 27/71 [03:23<05:29,  7.49s/epoch, loss=1.56, accuracy=0.65, val_loss=1.55, val_accuracy=0.582]  39%|███▉      | 28/71 [03:30<05:22,  7.50s/epoch, loss=1.38, accuracy=0.626, val_loss=1.29, val_accuracy=0.62] 41%|████      | 29/71 [03:38<05:13,  7.47s/epoch, loss=1.23, accuracy=0.632, val_loss=1.15, val_accuracy=0.625] 42%|████▏     | 30/71 [03:45<05:06,  7.48s/epoch, loss=1.15, accuracy=0.606, val_loss=1.09, val_accuracy=0.642] 44%|████▎     | 31/71 [03:53<04:59,  7.49s/epoch, loss=1.08, accuracy=0.622, val_loss=1.02, val_accuracy=0.646] 45%|████▌     | 32/71 [04:00<04:52,  7.49s/epoch, loss=1.04, accuracy=0.627, val_loss=1.22, val_accuracy=0.511] 46%|████▋     | 33/71 [04:08<04:44,  7.49s/epoch, loss=1.08, accuracy=0.525, val_loss=1.04, val_accuracy=0.607] 48%|████▊     | 34/71 [04:15<04:36,  7.48s/epoch, loss=0.979, accuracy=0.575, val_loss=0.927, val_accuracy=0.629] 49%|████▉     | 35/71 [04:23<04:28,  7.46s/epoch, loss=0.953, accuracy=0.595, val_loss=0.947, val_accuracy=0.556] 51%|█████     | 36/71 [04:30<04:20,  7.46s/epoch, loss=0.936, accuracy=0.611, val_loss=0.942, val_accuracy=0.623] 52%|█████▏    | 37/71 [04:37<04:12,  7.41s/epoch, loss=0.977, accuracy=0.586, val_loss=0.948, val_accuracy=0.598] 54%|█████▎    | 38/71 [04:45<04:05,  7.44s/epoch, loss=0.953, accuracy=0.585, val_loss=0.916, val_accuracy=0.577] 55%|█████▍    | 39/71 [04:52<03:57,  7.42s/epoch, loss=0.905, accuracy=0.606, val_loss=0.934, val_accuracy=0.594] 56%|█████▋    | 40/71 [05:00<03:50,  7.43s/epoch, loss=0.887, accuracy=0.643, val_loss=0.915, val_accuracy=0.615] 58%|█████▊    | 41/71 [05:07<03:41,  7.37s/epoch, loss=0.946, accuracy=0.597, val_loss=0.915, val_accuracy=0.613] 59%|█████▉    | 42/71 [05:14<03:33,  7.38s/epoch, loss=0.906, accuracy=0.612, val_loss=0.888, val_accuracy=0.621] 61%|██████    | 43/71 [05:22<03:26,  7.37s/epoch, loss=0.872, accuracy=0.629, val_loss=0.851, val_accuracy=0.641] 62%|██████▏   | 44/71 [05:29<03:19,  7.39s/epoch, loss=0.861, accuracy=0.655, val_loss=0.88, val_accuracy=0.658]  63%|██████▎   | 45/71 [05:36<03:11,  7.36s/epoch, loss=0.883, accuracy=0.658, val_loss=0.906, val_accuracy=0.64] 65%|██████▍   | 46/71 [05:44<03:03,  7.34s/epoch, loss=0.919, accuracy=0.622, val_loss=0.907, val_accuracy=0.636] 66%|██████▌   | 47/71 [05:51<02:55,  7.32s/epoch, loss=0.902, accuracy=0.622, val_loss=0.879, val_accuracy=0.639] 68%|██████▊   | 48/71 [05:58<02:47,  7.28s/epoch, loss=0.873, accuracy=0.64, val_loss=0.859, val_accuracy=0.628]  69%|██████▉   | 49/71 [06:05<02:40,  7.29s/epoch, loss=0.862, accuracy=0.626, val_loss=0.877, val_accuracy=0.607] 70%|███████   | 50/71 [06:13<02:33,  7.29s/epoch, loss=0.876, accuracy=0.611, val_loss=0.879, val_accuracy=0.603] 72%|███████▏  | 51/71 [06:20<02:26,  7.32s/epoch, loss=0.889, accuracy=0.608, val_loss=0.908, val_accuracy=0.635] 73%|███████▎  | 52/71 [06:27<02:18,  7.30s/epoch, loss=0.901, accuracy=0.627, val_loss=0.892, val_accuracy=0.622] 75%|███████▍  | 53/71 [06:35<02:10,  7.26s/epoch, loss=0.895, accuracy=0.601, val_loss=0.902, val_accuracy=0.629] 76%|███████▌  | 54/71 [06:42<02:03,  7.27s/epoch, loss=0.902, accuracy=0.595, val_loss=0.922, val_accuracy=0.584] 77%|███████▋  | 55/71 [06:49<01:56,  7.26s/epoch, loss=0.862, accuracy=0.631, val_loss=0.86, val_accuracy=0.622]  79%|███████▉  | 56/71 [06:56<01:49,  7.29s/epoch, loss=0.864, accuracy=0.605, val_loss=0.865, val_accuracy=0.509] 80%|████████  | 57/71 [07:04<01:42,  7.29s/epoch, loss=0.838, accuracy=0.623, val_loss=0.826, val_accuracy=0.632] 82%|████████▏ | 58/71 [07:11<01:35,  7.32s/epoch, loss=0.816, accuracy=0.651, val_loss=0.824, val_accuracy=0.641] 83%|████████▎ | 59/71 [07:18<01:27,  7.28s/epoch, loss=0.813, accuracy=0.641, val_loss=0.909, val_accuracy=0.613] 85%|████████▍ | 60/71 [07:26<01:19,  7.27s/epoch, loss=0.85, accuracy=0.619, val_loss=0.89, val_accuracy=0.528]   86%|████████▌ | 61/71 [07:33<01:12,  7.29s/epoch, loss=0.883, accuracy=0.614, val_loss=0.931, val_accuracy=0.603] 87%|████████▋ | 62/71 [07:40<01:05,  7.27s/epoch, loss=0.928, accuracy=0.605, val_loss=0.909, val_accuracy=0.64]  89%|████████▊ | 63/71 [07:47<00:58,  7.27s/epoch, loss=0.929, accuracy=0.605, val_loss=1.24, val_accuracy=0.644] 90%|█████████ | 64/71 [07:55<00:50,  7.23s/epoch, loss=1.35, accuracy=0.62, val_loss=1.28, val_accuracy=0.623]   92%|█████████▏| 65/71 [08:02<00:43,  7.23s/epoch, loss=1.25, accuracy=0.604, val_loss=1.22, val_accuracy=0.609] 93%|█████████▎| 66/71 [08:09<00:35,  7.17s/epoch, loss=1.17, accuracy=0.577, val_loss=1.1, val_accuracy=0.572]  94%|█████████▍| 67/71 [08:16<00:28,  7.16s/epoch, loss=1.08, accuracy=0.574, val_loss=1.03, val_accuracy=0.553] 96%|█████████▌| 68/71 [08:23<00:21,  7.23s/epoch, loss=1.02, accuracy=0.567, val_loss=1.01, val_accuracy=0.566] 97%|█████████▋| 69/71 [08:31<00:14,  7.22s/epoch, loss=0.973, accuracy=0.571, val_loss=1.02, val_accuracy=0.491] 99%|█████████▊| 70/71 [08:38<00:07,  7.25s/epoch, loss=0.93, accuracy=0.57, val_loss=0.898, val_accuracy=0.598] 100%|██████████| 71/71 [08:45<00:00,  7.25s/epoch, loss=0.898, accuracy=0.572, val_loss=0.889, val_accuracy=0.57]100%|██████████| 71/71 [08:45<00:00,  7.40s/epoch, loss=0.898, accuracy=0.572, val_loss=0.889, val_accuracy=0.57]
Test score: 0.505364179611206
Test accuracy: 0.8450000286102295


* * * Run SGD for ID = 7_3. * * *


2024-03-01 11:06:50.365072: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-01 11:06:54.215700: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-01 11:06:54.216939: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-01 11:06:54.259847: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-01 11:06:54.259894: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-01 11:06:54.262961: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-01 11:06:54.263007: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-01 11:06:54.265266: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-01 11:06:54.266474: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-01 11:06:54.269235: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-01 11:06:54.270927: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-01 11:06:54.275918: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-01 11:06:54.278138: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-01 11:06:54.278244: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
<__array_function__ internals>:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray
/home/gkb738/.conda/envs/TF_KERAS_GPU/lib/python3.9/site-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray
  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])
/home/gkb738/.conda/envs/TF_KERAS_GPU/lib/python3.9/site-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray
  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])
2024-03-01 11:07:00.718219: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-01 11:07:00.718732: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-01 11:07:00.719235: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-01 11:07:00.719271: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-01 11:07:00.719321: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-01 11:07:00.719342: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-01 11:07:00.719361: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-01 11:07:00.719381: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-01 11:07:00.719400: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-01 11:07:00.719419: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-01 11:07:00.719438: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-01 11:07:00.719872: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-01 11:07:00.719909: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-01 11:07:01.492488: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-01 11:07:01.492563: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-01 11:07:01.492573: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-01 11:07:01.493960: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': '07_03', 'seed': 3, 'out_folder': 'results/epoch_budget', 'batch_size': 32, 'epochs': 71, 'validation_split': 0.2, 'checkpointing': True, 'initial_lr': 0.1, 'momentum': 0.98, 'nesterov': True, 'bootstrapping': False, 'map_optimizer': True, 'model': 'CNN-LSTM', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Loading data...
Pad sequences (samples x time)
20000 train sequences
5000 validation sequences
25000 test sequences
x_train shape: (20000, 100)
x_val shape: (5000, 100)
x_test shape: (25000, 100)
Using MAP optimizer with reg_weight:  5e-05
CNN-LSTM
0epoch [00:00, ?epoch/s]  0%|          | 0/71 [00:00<?, ?epoch/s]2024-03-01 11:07:01.974136: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-01 11:07:01.986035: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199945000 Hz
2024-03-01 11:07:03.756086: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-01 11:07:03.971389: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-01 11:07:04.768552: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-01 11:07:04.818145: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|▏         | 1/71 [00:13<15:37, 13.39s/epoch, loss=0.642, accuracy=0.663, val_loss=0.509, val_accuracy=0.799]  3%|▎         | 2/71 [00:21<12:02, 10.47s/epoch, loss=0.459, accuracy=0.832, val_loss=0.472, val_accuracy=0.829]  4%|▍         | 3/71 [00:30<10:42,  9.45s/epoch, loss=0.425, accuracy=0.863, val_loss=0.493, val_accuracy=0.831]  6%|▌         | 4/71 [00:37<09:36,  8.61s/epoch, loss=0.445, accuracy=0.871, val_loss=0.563, val_accuracy=0.826]  7%|▋         | 5/71 [00:44<08:57,  8.14s/epoch, loss=0.541, accuracy=0.852, val_loss=0.665, val_accuracy=0.801]  8%|▊         | 6/71 [00:52<08:30,  7.86s/epoch, loss=0.762, accuracy=0.779, val_loss=0.939, val_accuracy=0.726] 10%|▉         | 7/71 [00:59<08:10,  7.67s/epoch, loss=1.01, accuracy=0.687, val_loss=1.07, val_accuracy=0.671]   11%|█▏        | 8/71 [01:06<07:55,  7.55s/epoch, loss=1.04, accuracy=0.662, val_loss=1.07, val_accuracy=0.661] 13%|█▎        | 9/71 [01:13<07:42,  7.46s/epoch, loss=1.07, accuracy=0.585, val_loss=1.06, val_accuracy=0.572] 14%|█▍        | 10/71 [01:21<07:31,  7.40s/epoch, loss=1.07, accuracy=0.556, val_loss=1.05, val_accuracy=0.56] 15%|█▌        | 11/71 [01:28<07:22,  7.38s/epoch, loss=1.04, accuracy=0.602, val_loss=1.02, val_accuracy=0.606] 17%|█▋        | 12/71 [01:35<07:14,  7.36s/epoch, loss=1.04, accuracy=0.517, val_loss=1.07, val_accuracy=0.502] 18%|█▊        | 13/71 [01:43<07:06,  7.35s/epoch, loss=0.962, accuracy=0.545, val_loss=0.946, val_accuracy=0.509] 20%|█▉        | 14/71 [01:50<06:57,  7.32s/epoch, loss=0.924, accuracy=0.527, val_loss=0.937, val_accuracy=0.525] 21%|██        | 15/71 [01:57<06:49,  7.31s/epoch, loss=0.868, accuracy=0.573, val_loss=0.841, val_accuracy=0.602] 23%|██▎       | 16/71 [02:04<06:41,  7.30s/epoch, loss=0.864, accuracy=0.617, val_loss=0.915, val_accuracy=0.649] 24%|██▍       | 17/71 [02:12<06:34,  7.31s/epoch, loss=1.54, accuracy=0.651, val_loss=1.53, val_accuracy=0.683]   25%|██▌       | 18/71 [02:19<06:28,  7.32s/epoch, loss=1.48, accuracy=0.646, val_loss=1.44, val_accuracy=0.61]  27%|██▋       | 19/71 [02:26<06:18,  7.28s/epoch, loss=1.35, accuracy=0.643, val_loss=1.28, val_accuracy=0.623] 28%|██▊       | 20/71 [02:33<05:57,  7.01s/epoch, loss=1.24, accuracy=0.599, val_loss=1.18, val_accuracy=0.585] 30%|██▉       | 21/71 [02:39<05:40,  6.81s/epoch, loss=1.14, accuracy=0.608, val_loss=1.1, val_accuracy=0.596]  31%|███       | 22/71 [02:45<05:26,  6.66s/epoch, loss=1.09, accuracy=0.59, val_loss=1.04, val_accuracy=0.631] 32%|███▏      | 23/71 [02:52<05:26,  6.80s/epoch, loss=1.02, accuracy=0.631, val_loss=1.08, val_accuracy=0.663] 34%|███▍      | 24/71 [02:59<05:22,  6.86s/epoch, loss=1.06, accuracy=0.645, val_loss=1.07, val_accuracy=0.595] 35%|███▌      | 25/71 [03:07<05:21,  6.98s/epoch, loss=1.07, accuracy=0.601, val_loss=1.03, val_accuracy=0.6]   37%|███▋      | 26/71 [03:14<05:18,  7.07s/epoch, loss=1.03, accuracy=0.592, val_loss=1.02, val_accuracy=0.569] 38%|███▊      | 27/71 [03:21<05:13,  7.12s/epoch, loss=0.999, accuracy=0.586, val_loss=0.968, val_accuracy=0.571] 39%|███▉      | 28/71 [03:29<05:09,  7.19s/epoch, loss=0.959, accuracy=0.593, val_loss=0.92, val_accuracy=0.578]  41%|████      | 29/71 [03:36<05:02,  7.21s/epoch, loss=0.91, accuracy=0.614, val_loss=0.888, val_accuracy=0.623] 42%|████▏     | 30/71 [03:43<04:56,  7.23s/epoch, loss=0.89, accuracy=0.617, val_loss=0.895, val_accuracy=0.628] 44%|████▎     | 31/71 [03:50<04:50,  7.26s/epoch, loss=0.893, accuracy=0.603, val_loss=0.884, val_accuracy=0.597] 45%|████▌     | 32/71 [03:58<04:44,  7.28s/epoch, loss=0.994, accuracy=0.59, val_loss=1.11, val_accuracy=0.507]   46%|████▋     | 33/71 [04:05<04:36,  7.28s/epoch, loss=1.05, accuracy=0.598, val_loss=0.987, val_accuracy=0.635] 48%|████▊     | 34/71 [04:12<04:29,  7.28s/epoch, loss=0.968, accuracy=0.635, val_loss=0.95, val_accuracy=0.637] 49%|████▉     | 35/71 [04:20<04:22,  7.28s/epoch, loss=0.916, accuracy=0.657, val_loss=0.934, val_accuracy=0.624] 51%|█████     | 36/71 [04:27<04:14,  7.27s/epoch, loss=0.889, accuracy=0.655, val_loss=0.912, val_accuracy=0.621] 52%|█████▏    | 37/71 [04:34<04:07,  7.29s/epoch, loss=0.869, accuracy=0.655, val_loss=0.891, val_accuracy=0.634] 54%|█████▎    | 38/71 [04:41<04:00,  7.28s/epoch, loss=0.851, accuracy=0.649, val_loss=0.859, val_accuracy=0.654] 55%|█████▍    | 39/71 [04:49<03:53,  7.28s/epoch, loss=0.897, accuracy=0.639, val_loss=0.936, val_accuracy=0.584] 56%|█████▋    | 40/71 [04:56<03:45,  7.27s/epoch, loss=0.948, accuracy=0.621, val_loss=0.939, val_accuracy=0.624] 58%|█████▊    | 41/71 [05:03<03:37,  7.26s/epoch, loss=0.921, accuracy=0.619, val_loss=0.891, val_accuracy=0.593] 59%|█████▉    | 42/71 [05:10<03:30,  7.27s/epoch, loss=0.904, accuracy=0.609, val_loss=0.942, val_accuracy=0.599] 61%|██████    | 43/71 [05:18<03:23,  7.25s/epoch, loss=0.879, accuracy=0.623, val_loss=0.865, val_accuracy=0.632] 62%|██████▏   | 44/71 [05:25<03:15,  7.25s/epoch, loss=0.842, accuracy=0.649, val_loss=0.888, val_accuracy=0.595] 63%|██████▎   | 45/71 [05:32<03:08,  7.25s/epoch, loss=0.864, accuracy=0.633, val_loss=0.902, val_accuracy=0.624] 65%|██████▍   | 46/71 [05:39<03:01,  7.25s/epoch, loss=0.873, accuracy=0.632, val_loss=0.887, val_accuracy=0.633] 66%|██████▌   | 47/71 [05:47<02:53,  7.25s/epoch, loss=0.863, accuracy=0.653, val_loss=0.874, val_accuracy=0.603] 68%|██████▊   | 48/71 [05:54<02:47,  7.26s/epoch, loss=0.873, accuracy=0.653, val_loss=0.895, val_accuracy=0.635] 69%|██████▉   | 49/71 [06:01<02:40,  7.28s/epoch, loss=0.86, accuracy=0.662, val_loss=0.88, val_accuracy=0.633]   70%|███████   | 50/71 [06:09<02:32,  7.28s/epoch, loss=0.834, accuracy=0.67, val_loss=0.89, val_accuracy=0.669] 72%|███████▏  | 51/71 [06:16<02:25,  7.28s/epoch, loss=0.828, accuracy=0.676, val_loss=0.864, val_accuracy=0.615] 73%|███████▎  | 52/71 [06:23<02:17,  7.26s/epoch, loss=0.869, accuracy=0.644, val_loss=0.893, val_accuracy=0.633] 75%|███████▍  | 53/71 [06:30<02:10,  7.27s/epoch, loss=0.907, accuracy=0.63, val_loss=0.918, val_accuracy=0.628]  76%|███████▌  | 54/71 [06:38<02:03,  7.24s/epoch, loss=0.929, accuracy=0.62, val_loss=0.903, val_accuracy=0.632] 77%|███████▋  | 55/71 [06:45<01:56,  7.26s/epoch, loss=0.901, accuracy=0.628, val_loss=1.01, val_accuracy=0.573] 79%|███████▉  | 56/71 [06:52<01:48,  7.24s/epoch, loss=0.915, accuracy=0.618, val_loss=0.908, val_accuracy=0.621] 80%|████████  | 57/71 [06:59<01:41,  7.26s/epoch, loss=0.896, accuracy=0.64, val_loss=0.921, val_accuracy=0.619]  82%|████████▏ | 58/71 [07:07<01:34,  7.25s/epoch, loss=0.906, accuracy=0.642, val_loss=0.895, val_accuracy=0.647] 83%|████████▎ | 59/71 [07:14<01:27,  7.28s/epoch, loss=0.928, accuracy=0.636, val_loss=1.02, val_accuracy=0.558]  85%|████████▍ | 60/71 [07:21<01:19,  7.27s/epoch, loss=0.996, accuracy=0.631, val_loss=0.977, val_accuracy=0.635] 86%|████████▌ | 61/71 [07:28<01:12,  7.28s/epoch, loss=0.984, accuracy=0.621, val_loss=0.969, val_accuracy=0.612] 87%|████████▋ | 62/71 [07:36<01:05,  7.28s/epoch, loss=0.958, accuracy=0.62, val_loss=0.95, val_accuracy=0.605]   89%|████████▊ | 63/71 [07:43<00:57,  7.23s/epoch, loss=0.923, accuracy=0.619, val_loss=0.909, val_accuracy=0.617] 90%|█████████ | 64/71 [07:50<00:50,  7.24s/epoch, loss=0.9, accuracy=0.611, val_loss=0.906, val_accuracy=0.609]   92%|█████████▏| 65/71 [07:57<00:43,  7.21s/epoch, loss=1.1, accuracy=0.625, val_loss=1.65, val_accuracy=0.583]  93%|█████████▎| 66/71 [08:04<00:36,  7.21s/epoch, loss=1.56, accuracy=0.61, val_loss=1.47, val_accuracy=0.5]   94%|█████████▍| 67/71 [08:12<00:28,  7.22s/epoch, loss=1.39, accuracy=0.606, val_loss=1.37, val_accuracy=0.509] 96%|█████████▌| 68/71 [08:19<00:21,  7.23s/epoch, loss=1.29, accuracy=0.582, val_loss=1.26, val_accuracy=0.554] 97%|█████████▋| 69/71 [08:26<00:14,  7.24s/epoch, loss=1.19, accuracy=0.557, val_loss=1.12, val_accuracy=0.574] 99%|█████████▊| 70/71 [08:33<00:07,  7.24s/epoch, loss=1.09, accuracy=0.57, val_loss=1.09, val_accuracy=0.508] 100%|██████████| 71/71 [08:41<00:00,  7.26s/epoch, loss=1.03, accuracy=0.563, val_loss=1, val_accuracy=0.552]  100%|██████████| 71/71 [08:41<00:00,  7.34s/epoch, loss=1.03, accuracy=0.563, val_loss=1, val_accuracy=0.552]
Test score: 0.4783755838871002
Test accuracy: 0.8409600257873535


* * * Run SGD for ID = 7_4. * * *


2024-03-01 11:15:49.746802: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-01 11:15:53.494197: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-01 11:15:53.495394: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-01 11:15:53.536914: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-01 11:15:53.536964: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-01 11:15:53.540196: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-01 11:15:53.540317: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-01 11:15:53.542640: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-01 11:15:53.543413: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-01 11:15:53.545922: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-01 11:15:53.547453: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-01 11:15:53.552508: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-01 11:15:53.553173: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-01 11:15:53.553262: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
<__array_function__ internals>:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray
/home/gkb738/.conda/envs/TF_KERAS_GPU/lib/python3.9/site-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray
  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])
/home/gkb738/.conda/envs/TF_KERAS_GPU/lib/python3.9/site-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray
  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])
2024-03-01 11:15:59.915285: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-01 11:15:59.915865: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-01 11:15:59.916471: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-01 11:15:59.916508: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-01 11:15:59.916562: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-01 11:15:59.916583: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-01 11:15:59.916603: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-01 11:15:59.916622: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-01 11:15:59.916643: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-01 11:15:59.916663: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-01 11:15:59.916694: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-01 11:15:59.917158: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-01 11:15:59.917199: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-01 11:16:00.699741: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-01 11:16:00.699801: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-01 11:16:00.699813: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-01 11:16:00.700770: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': '07_04', 'seed': 4, 'out_folder': 'results/epoch_budget', 'batch_size': 32, 'epochs': 71, 'validation_split': 0.2, 'checkpointing': True, 'initial_lr': 0.1, 'momentum': 0.98, 'nesterov': True, 'bootstrapping': False, 'map_optimizer': True, 'model': 'CNN-LSTM', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Loading data...
Pad sequences (samples x time)
20000 train sequences
5000 validation sequences
25000 test sequences
x_train shape: (20000, 100)
x_val shape: (5000, 100)
x_test shape: (25000, 100)
Using MAP optimizer with reg_weight:  5e-05
CNN-LSTM
0epoch [00:00, ?epoch/s]  0%|          | 0/71 [00:00<?, ?epoch/s]2024-03-01 11:16:01.188549: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-01 11:16:01.201002: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199945000 Hz
2024-03-01 11:16:03.010861: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-01 11:16:03.225797: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-01 11:16:04.025169: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-01 11:16:04.071627: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|▏         | 1/71 [00:13<15:37, 13.39s/epoch, loss=0.667, accuracy=0.625, val_loss=0.521, val_accuracy=0.805]  3%|▎         | 2/71 [00:21<11:41, 10.17s/epoch, loss=0.483, accuracy=0.819, val_loss=0.459, val_accuracy=0.835]  4%|▍         | 3/71 [00:28<09:59,  8.82s/epoch, loss=0.454, accuracy=0.85, val_loss=0.512, val_accuracy=0.822]   6%|▌         | 4/71 [00:35<09:09,  8.20s/epoch, loss=0.633, accuracy=0.791, val_loss=0.795, val_accuracy=0.74]  7%|▋         | 5/71 [00:43<08:38,  7.86s/epoch, loss=0.923, accuracy=0.641, val_loss=0.875, val_accuracy=0.697]  8%|▊         | 6/71 [00:50<08:18,  7.67s/epoch, loss=1.01, accuracy=0.607, val_loss=1.04, val_accuracy=0.557]   10%|▉         | 7/71 [00:57<08:03,  7.56s/epoch, loss=1.04, accuracy=0.553, val_loss=1.02, val_accuracy=0.563] 11%|█▏        | 8/71 [01:04<07:50,  7.46s/epoch, loss=0.982, accuracy=0.563, val_loss=0.951, val_accuracy=0.593] 13%|█▎        | 9/71 [01:12<07:39,  7.41s/epoch, loss=1, accuracy=0.58, val_loss=1.13, val_accuracy=0.57]        14%|█▍        | 10/71 [01:19<07:30,  7.38s/epoch, loss=1.02, accuracy=0.56, val_loss=0.999, val_accuracy=0.495] 15%|█▌        | 11/71 [01:26<07:21,  7.35s/epoch, loss=0.964, accuracy=0.597, val_loss=0.946, val_accuracy=0.574] 17%|█▋        | 12/71 [01:34<07:13,  7.34s/epoch, loss=0.96, accuracy=0.557, val_loss=0.947, val_accuracy=0.572]  18%|█▊        | 13/71 [01:41<07:05,  7.33s/epoch, loss=0.938, accuracy=0.566, val_loss=0.873, val_accuracy=0.65] 20%|█▉        | 14/71 [01:48<06:57,  7.32s/epoch, loss=0.931, accuracy=0.573, val_loss=0.905, val_accuracy=0.586] 21%|██        | 15/71 [01:56<06:49,  7.31s/epoch, loss=0.911, accuracy=0.562, val_loss=0.87, val_accuracy=0.587]  23%|██▎       | 16/71 [02:03<06:41,  7.29s/epoch, loss=0.873, accuracy=0.585, val_loss=0.967, val_accuracy=0.511] 24%|██▍       | 17/71 [02:10<06:32,  7.27s/epoch, loss=0.855, accuracy=0.604, val_loss=0.864, val_accuracy=0.561] 25%|██▌       | 18/71 [02:17<06:26,  7.29s/epoch, loss=0.861, accuracy=0.609, val_loss=0.905, val_accuracy=0.491] 27%|██▋       | 19/71 [02:25<06:19,  7.29s/epoch, loss=0.908, accuracy=0.583, val_loss=0.841, val_accuracy=0.628] 28%|██▊       | 20/71 [02:32<06:11,  7.28s/epoch, loss=0.88, accuracy=0.624, val_loss=0.847, val_accuracy=0.661]  30%|██▉       | 21/71 [02:39<06:04,  7.30s/epoch, loss=0.899, accuracy=0.595, val_loss=0.855, val_accuracy=0.617] 31%|███       | 22/71 [02:46<05:57,  7.30s/epoch, loss=0.86, accuracy=0.598, val_loss=0.808, val_accuracy=0.647]  32%|███▏      | 23/71 [02:54<05:50,  7.29s/epoch, loss=0.84, accuracy=0.631, val_loss=0.975, val_accuracy=0.621] 34%|███▍      | 24/71 [03:01<05:42,  7.28s/epoch, loss=0.858, accuracy=0.642, val_loss=0.827, val_accuracy=0.657] 35%|███▌      | 25/71 [03:08<05:35,  7.28s/epoch, loss=0.88, accuracy=0.623, val_loss=0.883, val_accuracy=0.599]  37%|███▋      | 26/71 [03:16<05:28,  7.29s/epoch, loss=0.906, accuracy=0.609, val_loss=1.04, val_accuracy=0.541] 38%|███▊      | 27/71 [03:23<05:20,  7.28s/epoch, loss=0.94, accuracy=0.589, val_loss=0.942, val_accuracy=0.569] 39%|███▉      | 28/71 [03:30<05:13,  7.28s/epoch, loss=0.893, accuracy=0.628, val_loss=0.872, val_accuracy=0.649] 41%|████      | 29/71 [03:37<05:05,  7.28s/epoch, loss=0.868, accuracy=0.656, val_loss=0.898, val_accuracy=0.645] 42%|████▏     | 30/71 [03:45<04:58,  7.28s/epoch, loss=0.875, accuracy=0.657, val_loss=0.9, val_accuracy=0.637]   44%|████▎     | 31/71 [03:51<04:44,  7.12s/epoch, loss=0.892, accuracy=0.637, val_loss=0.908, val_accuracy=0.612] 45%|████▌     | 32/71 [03:58<04:27,  6.87s/epoch, loss=0.912, accuracy=0.636, val_loss=0.913, val_accuracy=0.619] 46%|████▋     | 33/71 [04:04<04:14,  6.70s/epoch, loss=0.979, accuracy=0.573, val_loss=0.969, val_accuracy=0.598] 48%|████▊     | 34/71 [04:11<04:05,  6.63s/epoch, loss=0.961, accuracy=0.58, val_loss=0.976, val_accuracy=0.501]  49%|████▉     | 35/71 [04:18<04:04,  6.80s/epoch, loss=0.94, accuracy=0.568, val_loss=0.942, val_accuracy=0.516] 51%|█████     | 36/71 [04:25<04:03,  6.96s/epoch, loss=0.925, accuracy=0.579, val_loss=0.927, val_accuracy=0.602] 52%|█████▏    | 37/71 [04:32<03:59,  7.04s/epoch, loss=0.92, accuracy=0.564, val_loss=0.874, val_accuracy=0.553]  54%|█████▎    | 38/71 [04:40<03:54,  7.10s/epoch, loss=0.878, accuracy=0.592, val_loss=0.845, val_accuracy=0.611] 55%|█████▍    | 39/71 [04:47<03:49,  7.17s/epoch, loss=1.09, accuracy=0.577, val_loss=1.1, val_accuracy=0.606]    56%|█████▋    | 40/71 [04:54<03:42,  7.18s/epoch, loss=1.07, accuracy=0.578, val_loss=1.21, val_accuracy=0.572] 58%|█████▊    | 41/71 [05:01<03:36,  7.22s/epoch, loss=1.02, accuracy=0.559, val_loss=0.984, val_accuracy=0.525] 59%|█████▉    | 42/71 [05:09<03:30,  7.26s/epoch, loss=0.957, accuracy=0.586, val_loss=0.947, val_accuracy=0.613] 61%|██████    | 43/71 [05:16<03:23,  7.28s/epoch, loss=0.981, accuracy=0.614, val_loss=1.03, val_accuracy=0.603]  62%|██████▏   | 44/71 [05:23<03:16,  7.29s/epoch, loss=1.02, accuracy=0.598, val_loss=1, val_accuracy=0.599]     63%|██████▎   | 45/71 [05:31<03:09,  7.29s/epoch, loss=0.978, accuracy=0.612, val_loss=1.05, val_accuracy=0.5] 65%|██████▍   | 46/71 [05:38<03:01,  7.28s/epoch, loss=0.954, accuracy=0.617, val_loss=1, val_accuracy=0.578]  66%|██████▌   | 47/71 [05:45<02:54,  7.26s/epoch, loss=0.977, accuracy=0.585, val_loss=1.03, val_accuracy=0.501] 68%|██████▊   | 48/71 [05:52<02:46,  7.25s/epoch, loss=0.971, accuracy=0.554, val_loss=1.02, val_accuracy=0.501] 69%|██████▉   | 49/71 [06:00<02:39,  7.27s/epoch, loss=0.909, accuracy=0.567, val_loss=0.875, val_accuracy=0.557] 70%|███████   | 50/71 [06:07<02:33,  7.30s/epoch, loss=0.875, accuracy=0.577, val_loss=0.839, val_accuracy=0.598] 72%|███████▏  | 51/71 [06:14<02:25,  7.30s/epoch, loss=0.854, accuracy=0.586, val_loss=0.853, val_accuracy=0.603] 73%|███████▎  | 52/71 [06:22<02:18,  7.31s/epoch, loss=0.841, accuracy=0.581, val_loss=0.822, val_accuracy=0.598] 75%|███████▍  | 53/71 [06:29<02:11,  7.30s/epoch, loss=0.866, accuracy=0.553, val_loss=0.898, val_accuracy=0.573] 76%|███████▌  | 54/71 [06:36<02:03,  7.26s/epoch, loss=0.856, accuracy=0.6, val_loss=0.858, val_accuracy=0.56]    77%|███████▋  | 55/71 [06:43<01:56,  7.27s/epoch, loss=0.893, accuracy=0.607, val_loss=0.897, val_accuracy=0.628] 79%|███████▉  | 56/71 [06:51<01:48,  7.24s/epoch, loss=0.905, accuracy=0.625, val_loss=0.882, val_accuracy=0.636] 80%|████████  | 57/71 [06:58<01:41,  7.23s/epoch, loss=0.913, accuracy=0.627, val_loss=0.905, val_accuracy=0.629] 82%|████████▏ | 58/71 [07:05<01:33,  7.22s/epoch, loss=0.93, accuracy=0.593, val_loss=0.914, val_accuracy=0.594]  83%|████████▎ | 59/71 [07:12<01:26,  7.24s/epoch, loss=0.903, accuracy=0.604, val_loss=0.915, val_accuracy=0.59] 85%|████████▍ | 60/71 [07:20<01:19,  7.24s/epoch, loss=0.901, accuracy=0.604, val_loss=0.893, val_accuracy=0.586] 86%|████████▌ | 61/71 [07:27<01:12,  7.23s/epoch, loss=0.912, accuracy=0.584, val_loss=0.917, val_accuracy=0.554] 87%|████████▋ | 62/71 [07:34<01:05,  7.24s/epoch, loss=0.888, accuracy=0.601, val_loss=0.871, val_accuracy=0.621] 89%|████████▊ | 63/71 [07:41<00:57,  7.24s/epoch, loss=0.866, accuracy=0.618, val_loss=0.87, val_accuracy=0.605]  90%|█████████ | 64/71 [07:49<00:50,  7.25s/epoch, loss=0.876, accuracy=0.621, val_loss=0.954, val_accuracy=0.502] 92%|█████████▏| 65/71 [07:56<00:43,  7.25s/epoch, loss=0.886, accuracy=0.602, val_loss=0.843, val_accuracy=0.623] 93%|█████████▎| 66/71 [08:03<00:36,  7.21s/epoch, loss=0.859, accuracy=0.623, val_loss=0.912, val_accuracy=0.595] 94%|█████████▍| 67/71 [08:10<00:28,  7.23s/epoch, loss=0.873, accuracy=0.596, val_loss=0.866, val_accuracy=0.545] 96%|█████████▌| 68/71 [08:17<00:21,  7.20s/epoch, loss=0.893, accuracy=0.576, val_loss=0.896, val_accuracy=0.604] 97%|█████████▋| 69/71 [08:24<00:14,  7.19s/epoch, loss=0.898, accuracy=0.574, val_loss=0.847, val_accuracy=0.62]  99%|█████████▊| 70/71 [08:32<00:07,  7.19s/epoch, loss=0.84, accuracy=0.624, val_loss=0.843, val_accuracy=0.593]100%|██████████| 71/71 [08:39<00:00,  7.19s/epoch, loss=0.826, accuracy=0.621, val_loss=0.819, val_accuracy=0.616]100%|██████████| 71/71 [08:39<00:00,  7.31s/epoch, loss=0.826, accuracy=0.621, val_loss=0.819, val_accuracy=0.616]
Test score: 0.45445019006729126
Test accuracy: 0.8361999988555908


* * * Run SGD for ID = 7_5. * * *


2024-03-01 11:24:46.968085: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-01 11:24:50.749963: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-01 11:24:50.751161: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-01 11:24:50.793799: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-01 11:24:50.793876: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-01 11:24:50.797143: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-01 11:24:50.797226: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-01 11:24:50.799484: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-01 11:24:50.800168: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-01 11:24:50.802800: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-01 11:24:50.804576: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-01 11:24:50.809889: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-01 11:24:50.811880: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-01 11:24:50.812005: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
<__array_function__ internals>:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray
/home/gkb738/.conda/envs/TF_KERAS_GPU/lib/python3.9/site-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray
  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])
/home/gkb738/.conda/envs/TF_KERAS_GPU/lib/python3.9/site-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray
  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])
2024-03-01 11:24:57.262776: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-01 11:24:57.263366: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-01 11:24:57.263906: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-01 11:24:57.263945: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-01 11:24:57.263996: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-01 11:24:57.264019: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-01 11:24:57.264040: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-01 11:24:57.264070: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-01 11:24:57.264093: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-01 11:24:57.264115: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-01 11:24:57.264137: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-01 11:24:57.264586: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-01 11:24:57.264636: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-01 11:24:58.039878: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-01 11:24:58.039938: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-01 11:24:58.039948: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-01 11:24:58.041346: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': '07_05', 'seed': 5, 'out_folder': 'results/epoch_budget', 'batch_size': 32, 'epochs': 71, 'validation_split': 0.2, 'checkpointing': True, 'initial_lr': 0.1, 'momentum': 0.98, 'nesterov': True, 'bootstrapping': False, 'map_optimizer': True, 'model': 'CNN-LSTM', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Loading data...
Pad sequences (samples x time)
20000 train sequences
5000 validation sequences
25000 test sequences
x_train shape: (20000, 100)
x_val shape: (5000, 100)
x_test shape: (25000, 100)
Using MAP optimizer with reg_weight:  5e-05
CNN-LSTM
0epoch [00:00, ?epoch/s]  0%|          | 0/71 [00:00<?, ?epoch/s]2024-03-01 11:24:58.523619: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-01 11:24:58.536011: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199945000 Hz
2024-03-01 11:25:00.344057: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-01 11:25:00.543567: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-01 11:25:01.303715: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-01 11:25:01.357252: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|▏         | 1/71 [00:13<15:53, 13.62s/epoch, loss=0.731, accuracy=0.54, val_loss=0.624, val_accuracy=0.717]  3%|▎         | 2/71 [00:21<11:48, 10.26s/epoch, loss=0.531, accuracy=0.781, val_loss=0.539, val_accuracy=0.794]  4%|▍         | 3/71 [00:29<10:37,  9.37s/epoch, loss=0.446, accuracy=0.844, val_loss=0.471, val_accuracy=0.83]   6%|▌         | 4/71 [00:38<10:02,  9.00s/epoch, loss=0.427, accuracy=0.87, val_loss=0.505, val_accuracy=0.835]  7%|▋         | 5/71 [00:45<09:16,  8.43s/epoch, loss=0.47, accuracy=0.866, val_loss=0.651, val_accuracy=0.799]  8%|▊         | 6/71 [00:53<08:45,  8.09s/epoch, loss=0.802, accuracy=0.719, val_loss=0.991, val_accuracy=0.598] 10%|▉         | 7/71 [01:00<08:24,  7.88s/epoch, loss=0.991, accuracy=0.574, val_loss=1.04, val_accuracy=0.492]  11%|█▏        | 8/71 [01:07<08:05,  7.71s/epoch, loss=0.949, accuracy=0.568, val_loss=0.93, val_accuracy=0.592] 13%|█▎        | 9/71 [01:15<07:52,  7.63s/epoch, loss=0.919, accuracy=0.622, val_loss=0.875, val_accuracy=0.668] 14%|█▍        | 10/71 [01:22<07:39,  7.53s/epoch, loss=0.919, accuracy=0.654, val_loss=1.07, val_accuracy=0.512] 15%|█▌        | 11/71 [01:30<07:28,  7.48s/epoch, loss=1.02, accuracy=0.564, val_loss=0.997, val_accuracy=0.59]  17%|█▋        | 12/71 [01:37<07:19,  7.45s/epoch, loss=0.969, accuracy=0.606, val_loss=0.901, val_accuracy=0.668] 18%|█▊        | 13/71 [01:44<07:11,  7.43s/epoch, loss=0.976, accuracy=0.595, val_loss=0.994, val_accuracy=0.557] 20%|█▉        | 14/71 [01:52<07:02,  7.41s/epoch, loss=0.955, accuracy=0.603, val_loss=0.933, val_accuracy=0.624] 21%|██        | 15/71 [01:59<06:54,  7.40s/epoch, loss=0.93, accuracy=0.595, val_loss=0.885, val_accuracy=0.616]  23%|██▎       | 16/71 [02:06<06:46,  7.39s/epoch, loss=0.884, accuracy=0.61, val_loss=0.883, val_accuracy=0.609] 24%|██▍       | 17/71 [02:14<06:39,  7.39s/epoch, loss=0.886, accuracy=0.609, val_loss=0.95, val_accuracy=0.548] 25%|██▌       | 18/71 [02:21<06:31,  7.38s/epoch, loss=0.886, accuracy=0.587, val_loss=0.883, val_accuracy=0.562] 27%|██▋       | 19/71 [02:29<06:23,  7.38s/epoch, loss=0.892, accuracy=0.598, val_loss=0.939, val_accuracy=0.555] 28%|██▊       | 20/71 [02:36<06:17,  7.40s/epoch, loss=0.902, accuracy=0.598, val_loss=0.916, val_accuracy=0.543] 30%|██▉       | 21/71 [02:43<06:08,  7.38s/epoch, loss=0.908, accuracy=0.567, val_loss=0.888, val_accuracy=0.59]  31%|███       | 22/71 [02:51<06:01,  7.38s/epoch, loss=0.874, accuracy=0.604, val_loss=0.941, val_accuracy=0.608] 32%|███▏      | 23/71 [02:58<05:54,  7.38s/epoch, loss=0.868, accuracy=0.622, val_loss=0.92, val_accuracy=0.594]  34%|███▍      | 24/71 [03:05<05:46,  7.38s/epoch, loss=0.885, accuracy=0.605, val_loss=0.913, val_accuracy=0.492] 35%|███▌      | 25/71 [03:13<05:38,  7.35s/epoch, loss=0.887, accuracy=0.569, val_loss=0.865, val_accuracy=0.594] 37%|███▋      | 26/71 [03:20<05:31,  7.37s/epoch, loss=0.842, accuracy=0.59, val_loss=0.828, val_accuracy=0.57]   38%|███▊      | 27/71 [03:28<05:24,  7.37s/epoch, loss=0.82, accuracy=0.612, val_loss=0.886, val_accuracy=0.586] 39%|███▉      | 28/71 [03:35<05:17,  7.38s/epoch, loss=0.819, accuracy=0.645, val_loss=0.831, val_accuracy=0.632] 41%|████      | 29/71 [03:42<05:10,  7.39s/epoch, loss=0.824, accuracy=0.648, val_loss=0.804, val_accuracy=0.677] 42%|████▏     | 30/71 [03:50<05:02,  7.37s/epoch, loss=0.85, accuracy=0.637, val_loss=0.901, val_accuracy=0.492]  44%|████▎     | 31/71 [03:57<04:54,  7.37s/epoch, loss=0.869, accuracy=0.626, val_loss=0.88, val_accuracy=0.623] 45%|████▌     | 32/71 [04:04<04:47,  7.37s/epoch, loss=0.885, accuracy=0.624, val_loss=0.881, val_accuracy=0.635] 46%|████▋     | 33/71 [04:12<04:40,  7.37s/epoch, loss=0.875, accuracy=0.639, val_loss=0.872, val_accuracy=0.652] 48%|████▊     | 34/71 [04:19<04:33,  7.39s/epoch, loss=0.897, accuracy=0.62, val_loss=1.03, val_accuracy=0.492]   49%|████▉     | 35/71 [04:27<04:26,  7.40s/epoch, loss=0.907, accuracy=0.59, val_loss=0.896, val_accuracy=0.611] 51%|█████     | 36/71 [04:34<04:19,  7.40s/epoch, loss=0.883, accuracy=0.638, val_loss=1, val_accuracy=0.656]    52%|█████▏    | 37/71 [04:41<04:11,  7.39s/epoch, loss=1.04, accuracy=0.631, val_loss=1.03, val_accuracy=0.629] 54%|█████▎    | 38/71 [04:49<04:04,  7.40s/epoch, loss=1.01, accuracy=0.628, val_loss=0.972, val_accuracy=0.634] 55%|█████▍    | 39/71 [04:56<03:56,  7.39s/epoch, loss=0.966, accuracy=0.63, val_loss=0.971, val_accuracy=0.612] 56%|█████▋    | 40/71 [05:04<03:49,  7.40s/epoch, loss=0.925, accuracy=0.649, val_loss=0.919, val_accuracy=0.638] 58%|█████▊    | 41/71 [05:11<03:42,  7.40s/epoch, loss=0.952, accuracy=0.602, val_loss=0.926, val_accuracy=0.587] 59%|█████▉    | 42/71 [05:18<03:32,  7.32s/epoch, loss=0.928, accuracy=0.589, val_loss=0.954, val_accuracy=0.492] 61%|██████    | 43/71 [05:25<03:17,  7.05s/epoch, loss=0.939, accuracy=0.576, val_loss=0.912, val_accuracy=0.6]   62%|██████▏   | 44/71 [05:31<03:04,  6.83s/epoch, loss=0.908, accuracy=0.577, val_loss=1, val_accuracy=0.571]   63%|██████▎   | 45/71 [05:37<02:53,  6.69s/epoch, loss=0.893, accuracy=0.611, val_loss=0.912, val_accuracy=0.555] 65%|██████▍   | 46/71 [05:44<02:51,  6.85s/epoch, loss=0.913, accuracy=0.597, val_loss=0.906, val_accuracy=0.583] 66%|██████▌   | 47/71 [05:52<02:45,  6.91s/epoch, loss=0.897, accuracy=0.592, val_loss=0.868, val_accuracy=0.595] 68%|██████▊   | 48/71 [05:59<02:41,  7.02s/epoch, loss=0.857, accuracy=0.616, val_loss=0.884, val_accuracy=0.58]  69%|██████▉   | 49/71 [06:06<02:36,  7.10s/epoch, loss=0.896, accuracy=0.594, val_loss=0.923, val_accuracy=0.598] 70%|███████   | 50/71 [06:13<02:30,  7.16s/epoch, loss=0.877, accuracy=0.598, val_loss=0.816, val_accuracy=0.66]  72%|███████▏  | 51/71 [06:21<02:23,  7.20s/epoch, loss=0.865, accuracy=0.623, val_loss=0.879, val_accuracy=0.622] 73%|███████▎  | 52/71 [06:28<02:17,  7.23s/epoch, loss=0.839, accuracy=0.638, val_loss=0.818, val_accuracy=0.662] 75%|███████▍  | 53/71 [06:35<02:10,  7.25s/epoch, loss=0.866, accuracy=0.603, val_loss=0.894, val_accuracy=0.608] 76%|███████▌  | 54/71 [06:43<02:03,  7.27s/epoch, loss=0.91, accuracy=0.621, val_loss=1.03, val_accuracy=0.493]   77%|███████▋  | 55/71 [06:50<01:56,  7.27s/epoch, loss=0.952, accuracy=0.607, val_loss=0.962, val_accuracy=0.614] 79%|███████▉  | 56/71 [06:57<01:49,  7.29s/epoch, loss=0.928, accuracy=0.607, val_loss=0.957, val_accuracy=0.499] 80%|████████  | 57/71 [07:04<01:41,  7.28s/epoch, loss=0.891, accuracy=0.636, val_loss=0.866, val_accuracy=0.645] 82%|████████▏ | 58/71 [07:12<01:34,  7.30s/epoch, loss=0.843, accuracy=0.662, val_loss=0.839, val_accuracy=0.647] 83%|████████▎ | 59/71 [07:19<01:27,  7.31s/epoch, loss=0.842, accuracy=0.659, val_loss=0.861, val_accuracy=0.678] 85%|████████▍ | 60/71 [07:26<01:20,  7.32s/epoch, loss=0.869, accuracy=0.637, val_loss=0.884, val_accuracy=0.633] 86%|████████▌ | 61/71 [07:34<01:13,  7.33s/epoch, loss=0.907, accuracy=0.615, val_loss=1.17, val_accuracy=0.507]  87%|████████▋ | 62/71 [07:41<01:06,  7.33s/epoch, loss=0.911, accuracy=0.609, val_loss=0.874, val_accuracy=0.628] 89%|████████▊ | 63/71 [07:48<00:58,  7.33s/epoch, loss=0.896, accuracy=0.621, val_loss=0.929, val_accuracy=0.629] 90%|█████████ | 64/71 [07:56<00:51,  7.33s/epoch, loss=0.908, accuracy=0.622, val_loss=0.908, val_accuracy=0.615] 92%|█████████▏| 65/71 [08:03<00:44,  7.34s/epoch, loss=0.929, accuracy=0.581, val_loss=0.914, val_accuracy=0.619] 93%|█████████▎| 66/71 [08:10<00:36,  7.31s/epoch, loss=0.886, accuracy=0.616, val_loss=0.905, val_accuracy=0.559] 94%|█████████▍| 67/71 [08:18<00:29,  7.33s/epoch, loss=0.875, accuracy=0.615, val_loss=0.857, val_accuracy=0.642] 96%|█████████▌| 68/71 [08:25<00:21,  7.31s/epoch, loss=0.843, accuracy=0.651, val_loss=0.867, val_accuracy=0.626] 97%|█████████▋| 69/71 [08:32<00:14,  7.29s/epoch, loss=0.92, accuracy=0.598, val_loss=1.03, val_accuracy=0.492]   99%|█████████▊| 70/71 [08:40<00:07,  7.29s/epoch, loss=0.928, accuracy=0.562, val_loss=0.901, val_accuracy=0.587]100%|██████████| 71/71 [08:47<00:00,  7.29s/epoch, loss=0.9, accuracy=0.557, val_loss=0.895, val_accuracy=0.558]  100%|██████████| 71/71 [08:47<00:00,  7.43s/epoch, loss=0.9, accuracy=0.557, val_loss=0.895, val_accuracy=0.558]
Test score: 0.4909239113330841
Test accuracy: 0.8393200039863586


* * * Run SGD for ID = 7_6. * * *


2024-03-01 11:33:52.482669: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-01 11:33:56.220923: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-01 11:33:56.222173: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-01 11:33:56.265080: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-01 11:33:56.265148: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-01 11:33:56.268329: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-01 11:33:56.268394: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-01 11:33:56.270676: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-01 11:33:56.271367: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-01 11:33:56.274033: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-01 11:33:56.275793: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-01 11:33:56.281156: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-01 11:33:56.281788: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-01 11:33:56.281926: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
<__array_function__ internals>:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray
/home/gkb738/.conda/envs/TF_KERAS_GPU/lib/python3.9/site-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray
  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])
/home/gkb738/.conda/envs/TF_KERAS_GPU/lib/python3.9/site-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray
  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])
2024-03-01 11:34:02.686267: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-01 11:34:02.686812: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-01 11:34:02.689518: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-01 11:34:02.689604: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-01 11:34:02.689675: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-01 11:34:02.689698: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-01 11:34:02.689719: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-01 11:34:02.689755: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-01 11:34:02.689789: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-01 11:34:02.689808: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-01 11:34:02.689833: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-01 11:34:02.692036: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-01 11:34:02.692106: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-01 11:34:03.500094: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-01 11:34:03.500185: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-01 11:34:03.500196: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-01 11:34:03.501552: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': '07_06', 'seed': 6, 'out_folder': 'results/epoch_budget', 'batch_size': 32, 'epochs': 71, 'validation_split': 0.2, 'checkpointing': True, 'initial_lr': 0.1, 'momentum': 0.98, 'nesterov': True, 'bootstrapping': False, 'map_optimizer': True, 'model': 'CNN-LSTM', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Loading data...
Pad sequences (samples x time)
20000 train sequences
5000 validation sequences
25000 test sequences
x_train shape: (20000, 100)
x_val shape: (5000, 100)
x_test shape: (25000, 100)
Using MAP optimizer with reg_weight:  5e-05
CNN-LSTM
0epoch [00:00, ?epoch/s]  0%|          | 0/71 [00:00<?, ?epoch/s]2024-03-01 11:34:03.985814: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-01 11:34:03.998004: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199945000 Hz
2024-03-01 11:34:05.813876: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-01 11:34:06.017691: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-01 11:34:06.811737: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-01 11:34:06.863603: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|▏         | 1/71 [00:13<15:48, 13.55s/epoch, loss=0.633, accuracy=0.661, val_loss=0.505, val_accuracy=0.808]  3%|▎         | 2/71 [00:21<11:47, 10.25s/epoch, loss=0.463, accuracy=0.834, val_loss=0.464, val_accuracy=0.834]  4%|▍         | 3/71 [00:28<10:06,  8.91s/epoch, loss=0.434, accuracy=0.863, val_loss=0.544, val_accuracy=0.82]   6%|▌         | 4/71 [00:36<09:14,  8.28s/epoch, loss=0.456, accuracy=0.869, val_loss=0.559, val_accuracy=0.832]  7%|▋         | 5/71 [00:43<08:43,  7.93s/epoch, loss=0.544, accuracy=0.854, val_loss=0.669, val_accuracy=0.813]  8%|▊         | 6/71 [00:50<08:20,  7.70s/epoch, loss=0.902, accuracy=0.7, val_loss=1.04, val_accuracy=0.614]    10%|▉         | 7/71 [00:57<08:04,  7.57s/epoch, loss=1.03, accuracy=0.637, val_loss=1.09, val_accuracy=0.564] 11%|█▏        | 8/71 [01:05<07:50,  7.47s/epoch, loss=1.06, accuracy=0.624, val_loss=1.12, val_accuracy=0.553] 13%|█▎        | 9/71 [01:12<07:38,  7.39s/epoch, loss=1.1, accuracy=0.551, val_loss=1.05, val_accuracy=0.595]  14%|█▍        | 10/71 [01:19<07:27,  7.34s/epoch, loss=1.05, accuracy=0.563, val_loss=1.1, val_accuracy=0.491] 15%|█▌        | 11/71 [01:26<07:19,  7.33s/epoch, loss=1.04, accuracy=0.507, val_loss=0.994, val_accuracy=0.488] 17%|█▋        | 12/71 [01:34<07:12,  7.32s/epoch, loss=0.962, accuracy=0.552, val_loss=1.03, val_accuracy=0.549] 18%|█▊        | 13/71 [01:41<07:04,  7.32s/epoch, loss=0.999, accuracy=0.538, val_loss=0.962, val_accuracy=0.564] 20%|█▉        | 14/71 [01:48<06:57,  7.32s/epoch, loss=0.972, accuracy=0.559, val_loss=0.973, val_accuracy=0.526] 21%|██        | 15/71 [01:56<06:49,  7.32s/epoch, loss=0.948, accuracy=0.582, val_loss=0.922, val_accuracy=0.603] 23%|██▎       | 16/71 [02:03<06:42,  7.32s/epoch, loss=0.878, accuracy=0.633, val_loss=0.848, val_accuracy=0.671] 24%|██▍       | 17/71 [02:10<06:35,  7.33s/epoch, loss=0.888, accuracy=0.619, val_loss=0.953, val_accuracy=0.488] 25%|██▌       | 18/71 [02:18<06:27,  7.30s/epoch, loss=0.881, accuracy=0.619, val_loss=0.862, val_accuracy=0.603] 27%|██▋       | 19/71 [02:25<06:19,  7.31s/epoch, loss=0.853, accuracy=0.637, val_loss=0.824, val_accuracy=0.673] 28%|██▊       | 20/71 [02:32<06:13,  7.32s/epoch, loss=0.896, accuracy=0.633, val_loss=0.932, val_accuracy=0.603] 30%|██▉       | 21/71 [02:40<06:05,  7.31s/epoch, loss=0.916, accuracy=0.627, val_loss=0.923, val_accuracy=0.636] 31%|███       | 22/71 [02:47<05:58,  7.31s/epoch, loss=0.893, accuracy=0.625, val_loss=0.887, val_accuracy=0.65]  32%|███▏      | 23/71 [02:54<05:50,  7.30s/epoch, loss=0.903, accuracy=0.627, val_loss=0.879, val_accuracy=0.631] 34%|███▍      | 24/71 [03:01<05:42,  7.28s/epoch, loss=0.891, accuracy=0.63, val_loss=0.908, val_accuracy=0.605]  35%|███▌      | 25/71 [03:09<05:35,  7.30s/epoch, loss=0.87, accuracy=0.627, val_loss=0.815, val_accuracy=0.672] 37%|███▋      | 26/71 [03:16<05:28,  7.29s/epoch, loss=0.83, accuracy=0.656, val_loss=0.865, val_accuracy=0.658] 38%|███▊      | 27/71 [03:23<05:20,  7.28s/epoch, loss=0.886, accuracy=0.587, val_loss=0.873, val_accuracy=0.583] 39%|███▉      | 28/71 [03:31<05:12,  7.27s/epoch, loss=0.893, accuracy=0.607, val_loss=0.905, val_accuracy=0.612] 41%|████      | 29/71 [03:38<05:05,  7.27s/epoch, loss=0.858, accuracy=0.624, val_loss=0.848, val_accuracy=0.626] 42%|████▏     | 30/71 [03:45<04:58,  7.29s/epoch, loss=0.836, accuracy=0.65, val_loss=1.12, val_accuracy=0.548]   44%|████▎     | 31/71 [03:52<04:51,  7.30s/epoch, loss=1.23, accuracy=0.641, val_loss=1.23, val_accuracy=0.632] 45%|████▌     | 32/71 [04:00<04:45,  7.33s/epoch, loss=1.16, accuracy=0.643, val_loss=1.1, val_accuracy=0.636]  46%|████▋     | 33/71 [04:07<04:37,  7.30s/epoch, loss=1.07, accuracy=0.639, val_loss=1.06, val_accuracy=0.626] 48%|████▊     | 34/71 [04:14<04:30,  7.30s/epoch, loss=1.02, accuracy=0.638, val_loss=0.978, val_accuracy=0.639] 49%|████▉     | 35/71 [04:22<04:22,  7.29s/epoch, loss=0.974, accuracy=0.654, val_loss=0.974, val_accuracy=0.633] 51%|█████     | 36/71 [04:29<04:14,  7.28s/epoch, loss=1.01, accuracy=0.635, val_loss=0.984, val_accuracy=0.629]  52%|█████▏    | 37/71 [04:36<04:08,  7.29s/epoch, loss=0.988, accuracy=0.619, val_loss=0.959, val_accuracy=0.622] 54%|█████▎    | 38/71 [04:44<04:00,  7.30s/epoch, loss=0.956, accuracy=0.599, val_loss=0.924, val_accuracy=0.601] 55%|█████▍    | 39/71 [04:51<03:53,  7.30s/epoch, loss=0.921, accuracy=0.574, val_loss=0.887, val_accuracy=0.624] 56%|█████▋    | 40/71 [04:58<03:46,  7.30s/epoch, loss=0.891, accuracy=0.607, val_loss=0.871, val_accuracy=0.622] 58%|█████▊    | 41/71 [05:05<03:38,  7.29s/epoch, loss=0.849, accuracy=0.628, val_loss=0.855, val_accuracy=0.652] 59%|█████▉    | 42/71 [05:13<03:31,  7.29s/epoch, loss=0.813, accuracy=0.651, val_loss=0.8, val_accuracy=0.632]   61%|██████    | 43/71 [05:20<03:23,  7.28s/epoch, loss=0.815, accuracy=0.652, val_loss=0.867, val_accuracy=0.575] 62%|██████▏   | 44/71 [05:27<03:16,  7.26s/epoch, loss=0.867, accuracy=0.632, val_loss=0.835, val_accuracy=0.658] 63%|██████▎   | 45/71 [05:35<03:09,  7.27s/epoch, loss=0.928, accuracy=0.664, val_loss=0.952, val_accuracy=0.641] 65%|██████▍   | 46/71 [05:42<03:01,  7.27s/epoch, loss=0.931, accuracy=0.66, val_loss=0.971, val_accuracy=0.612]  66%|██████▌   | 47/71 [05:49<02:54,  7.29s/epoch, loss=0.938, accuracy=0.645, val_loss=0.967, val_accuracy=0.626] 68%|██████▊   | 48/71 [05:56<02:47,  7.30s/epoch, loss=0.965, accuracy=0.611, val_loss=1.01, val_accuracy=0.488]  69%|██████▉   | 49/71 [06:04<02:40,  7.29s/epoch, loss=0.935, accuracy=0.614, val_loss=0.982, val_accuracy=0.512] 70%|███████   | 50/71 [06:11<02:32,  7.28s/epoch, loss=0.896, accuracy=0.623, val_loss=0.98, val_accuracy=0.576]  72%|███████▏  | 51/71 [06:18<02:25,  7.28s/epoch, loss=0.881, accuracy=0.631, val_loss=0.905, val_accuracy=0.63] 73%|███████▎  | 52/71 [06:26<02:18,  7.30s/epoch, loss=0.927, accuracy=0.616, val_loss=0.896, val_accuracy=0.641] 75%|███████▍  | 53/71 [06:33<02:11,  7.28s/epoch, loss=0.904, accuracy=0.634, val_loss=0.904, val_accuracy=0.636] 76%|███████▌  | 54/71 [06:39<01:59,  7.04s/epoch, loss=0.905, accuracy=0.628, val_loss=0.891, val_accuracy=0.606] 77%|███████▋  | 55/71 [06:46<01:49,  6.84s/epoch, loss=0.907, accuracy=0.619, val_loss=1.01, val_accuracy=0.617]  79%|███████▉  | 56/71 [06:52<01:40,  6.68s/epoch, loss=0.89, accuracy=0.607, val_loss=0.868, val_accuracy=0.642] 80%|████████  | 57/71 [06:59<01:34,  6.74s/epoch, loss=0.887, accuracy=0.6, val_loss=0.897, val_accuracy=0.618]  82%|████████▏ | 58/71 [07:06<01:28,  6.81s/epoch, loss=0.859, accuracy=0.629, val_loss=0.834, val_accuracy=0.633] 83%|████████▎ | 59/71 [07:13<01:23,  6.93s/epoch, loss=0.937, accuracy=0.655, val_loss=1.06, val_accuracy=0.639]  85%|████████▍ | 60/71 [07:20<01:17,  7.03s/epoch, loss=1.05, accuracy=0.674, val_loss=1.04, val_accuracy=0.683]  86%|████████▌ | 61/71 [07:28<01:11,  7.11s/epoch, loss=1.04, accuracy=0.668, val_loss=1.04, val_accuracy=0.623] 87%|████████▋ | 62/71 [07:35<01:04,  7.15s/epoch, loss=0.982, accuracy=0.668, val_loss=0.952, val_accuracy=0.676] 89%|████████▊ | 63/71 [07:42<00:57,  7.19s/epoch, loss=0.967, accuracy=0.678, val_loss=0.951, val_accuracy=0.676] 90%|█████████ | 64/71 [07:49<00:50,  7.22s/epoch, loss=0.973, accuracy=0.673, val_loss=0.993, val_accuracy=0.66]  92%|█████████▏| 65/71 [07:57<00:43,  7.23s/epoch, loss=1.01, accuracy=0.626, val_loss=0.984, val_accuracy=0.615] 93%|█████████▎| 66/71 [08:04<00:36,  7.26s/epoch, loss=0.985, accuracy=0.632, val_loss=0.952, val_accuracy=0.671] 94%|█████████▍| 67/71 [08:11<00:29,  7.28s/epoch, loss=1.6, accuracy=0.634, val_loss=2.06, val_accuracy=0.623]    96%|█████████▌| 68/71 [08:19<00:21,  7.30s/epoch, loss=1.9, accuracy=0.642, val_loss=1.85, val_accuracy=0.562] 97%|█████████▋| 69/71 [08:26<00:14,  7.31s/epoch, loss=1.67, accuracy=0.62, val_loss=1.61, val_accuracy=0.607] 99%|█████████▊| 70/71 [08:33<00:07,  7.29s/epoch, loss=1.47, accuracy=0.627, val_loss=1.38, val_accuracy=0.617]100%|██████████| 71/71 [08:41<00:00,  7.30s/epoch, loss=1.32, accuracy=0.607, val_loss=1.21, val_accuracy=0.669]100%|██████████| 71/71 [08:41<00:00,  7.34s/epoch, loss=1.32, accuracy=0.607, val_loss=1.21, val_accuracy=0.669]
Test score: 0.4682976305484772
Test accuracy: 0.830560028553009


* * * Run SGD for ID = 7_7. * * *


2024-03-01 11:42:51.510517: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-01 11:42:55.350048: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-01 11:42:55.351265: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-01 11:42:55.392523: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-01 11:42:55.392599: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-01 11:42:55.396512: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-01 11:42:55.396603: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-01 11:42:55.399098: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-01 11:42:55.400225: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-01 11:42:55.402732: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-01 11:42:55.404349: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-01 11:42:55.409493: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-01 11:42:55.410229: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-01 11:42:55.410318: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
<__array_function__ internals>:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray
/home/gkb738/.conda/envs/TF_KERAS_GPU/lib/python3.9/site-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray
  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])
/home/gkb738/.conda/envs/TF_KERAS_GPU/lib/python3.9/site-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray
  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])
2024-03-01 11:43:01.861485: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-01 11:43:01.861988: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-01 11:43:01.862478: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-01 11:43:01.862513: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-01 11:43:01.862562: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-01 11:43:01.862584: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-01 11:43:01.862606: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-01 11:43:01.862627: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-01 11:43:01.862650: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-01 11:43:01.862672: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-01 11:43:01.862694: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-01 11:43:01.863147: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-01 11:43:01.863188: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-01 11:43:02.637159: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-01 11:43:02.637220: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-01 11:43:02.637230: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-01 11:43:02.638608: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': '07_07', 'seed': 7, 'out_folder': 'results/epoch_budget', 'batch_size': 32, 'epochs': 71, 'validation_split': 0.2, 'checkpointing': True, 'initial_lr': 0.1, 'momentum': 0.98, 'nesterov': True, 'bootstrapping': False, 'map_optimizer': True, 'model': 'CNN-LSTM', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Loading data...
Pad sequences (samples x time)
20000 train sequences
5000 validation sequences
25000 test sequences
x_train shape: (20000, 100)
x_val shape: (5000, 100)
x_test shape: (25000, 100)
Using MAP optimizer with reg_weight:  5e-05
CNN-LSTM
0epoch [00:00, ?epoch/s]  0%|          | 0/71 [00:00<?, ?epoch/s]2024-03-01 11:43:03.128427: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-01 11:43:03.140992: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199945000 Hz
2024-03-01 11:43:04.944177: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-01 11:43:05.159997: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-01 11:43:05.959656: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-01 11:43:06.018322: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|▏         | 1/71 [00:13<15:40, 13.43s/epoch, loss=0.697, accuracy=0.595, val_loss=0.512, val_accuracy=0.788]  3%|▎         | 2/71 [00:21<11:36, 10.10s/epoch, loss=0.485, accuracy=0.819, val_loss=0.455, val_accuracy=0.837]  4%|▍         | 3/71 [00:28<10:00,  8.83s/epoch, loss=0.424, accuracy=0.86, val_loss=0.508, val_accuracy=0.816]   6%|▌         | 4/71 [00:35<09:11,  8.23s/epoch, loss=0.437, accuracy=0.871, val_loss=0.656, val_accuracy=0.782]  7%|▋         | 5/71 [00:43<08:41,  7.90s/epoch, loss=0.483, accuracy=0.867, val_loss=0.644, val_accuracy=0.802]  8%|▊         | 6/71 [00:50<08:21,  7.71s/epoch, loss=0.856, accuracy=0.702, val_loss=0.978, val_accuracy=0.609] 10%|▉         | 7/71 [00:57<08:07,  7.61s/epoch, loss=1.09, accuracy=0.562, val_loss=1.09, val_accuracy=0.516]   11%|█▏        | 8/71 [01:05<07:53,  7.52s/epoch, loss=1.06, accuracy=0.526, val_loss=1.02, val_accuracy=0.506] 13%|█▎        | 9/71 [01:12<07:41,  7.45s/epoch, loss=0.995, accuracy=0.52, val_loss=1.1, val_accuracy=0.502]  14%|█▍        | 10/71 [01:19<07:32,  7.41s/epoch, loss=0.921, accuracy=0.565, val_loss=0.909, val_accuracy=0.603] 15%|█▌        | 11/71 [01:27<07:22,  7.38s/epoch, loss=0.874, accuracy=0.623, val_loss=0.892, val_accuracy=0.636] 17%|█▋        | 12/71 [01:34<07:14,  7.36s/epoch, loss=0.862, accuracy=0.641, val_loss=0.958, val_accuracy=0.639] 18%|█▊        | 13/71 [01:41<07:05,  7.34s/epoch, loss=0.972, accuracy=0.63, val_loss=1.09, val_accuracy=0.588]   20%|█▉        | 14/71 [01:49<06:58,  7.35s/epoch, loss=1.07, accuracy=0.584, val_loss=1.02, val_accuracy=0.615] 21%|██        | 15/71 [01:56<06:50,  7.33s/epoch, loss=1.03, accuracy=0.589, val_loss=1.04, val_accuracy=0.591] 23%|██▎       | 16/71 [02:03<06:43,  7.33s/epoch, loss=0.966, accuracy=0.606, val_loss=0.95, val_accuracy=0.561] 24%|██▍       | 17/71 [02:11<06:36,  7.33s/epoch, loss=0.941, accuracy=0.608, val_loss=0.973, val_accuracy=0.575] 25%|██▌       | 18/71 [02:18<06:28,  7.34s/epoch, loss=0.888, accuracy=0.65, val_loss=0.863, val_accuracy=0.651]  27%|██▋       | 19/71 [02:25<06:21,  7.34s/epoch, loss=0.894, accuracy=0.645, val_loss=0.899, val_accuracy=0.648] 28%|██▊       | 20/71 [02:33<06:14,  7.34s/epoch, loss=0.921, accuracy=0.635, val_loss=0.938, val_accuracy=0.623] 30%|██▉       | 21/71 [02:40<06:06,  7.34s/epoch, loss=0.92, accuracy=0.628, val_loss=0.936, val_accuracy=0.609]  31%|███       | 22/71 [02:47<05:59,  7.33s/epoch, loss=0.974, accuracy=0.621, val_loss=1.05, val_accuracy=0.639] 32%|███▏      | 23/71 [02:55<05:52,  7.34s/epoch, loss=1.04, accuracy=0.633, val_loss=1.02, val_accuracy=0.63]   34%|███▍      | 24/71 [03:02<05:45,  7.35s/epoch, loss=0.994, accuracy=0.639, val_loss=0.959, val_accuracy=0.653] 35%|███▌      | 25/71 [03:09<05:37,  7.34s/epoch, loss=1.2, accuracy=0.596, val_loss=2.53, val_accuracy=0.502]    37%|███▋      | 26/71 [03:17<05:30,  7.34s/epoch, loss=2.45, accuracy=0.608, val_loss=2.33, val_accuracy=0.561] 38%|███▊      | 27/71 [03:24<05:23,  7.35s/epoch, loss=2.06, accuracy=0.576, val_loss=1.87, val_accuracy=0.555] 39%|███▉      | 28/71 [03:31<05:15,  7.34s/epoch, loss=1.72, accuracy=0.598, val_loss=1.57, val_accuracy=0.601] 41%|████      | 29/71 [03:39<05:08,  7.34s/epoch, loss=1.46, accuracy=0.619, val_loss=1.46, val_accuracy=0.572] 42%|████▏     | 30/71 [03:46<05:00,  7.34s/epoch, loss=1.31, accuracy=0.612, val_loss=1.24, val_accuracy=0.633] 44%|████▎     | 31/71 [03:53<04:52,  7.32s/epoch, loss=1.2, accuracy=0.593, val_loss=1.17, val_accuracy=0.612]  45%|████▌     | 32/71 [04:01<04:45,  7.31s/epoch, loss=1.15, accuracy=0.597, val_loss=1.15, val_accuracy=0.504] 46%|████▋     | 33/71 [04:08<04:37,  7.31s/epoch, loss=1.08, accuracy=0.589, val_loss=1.1, val_accuracy=0.536]  48%|████▊     | 34/71 [04:15<04:30,  7.30s/epoch, loss=1.01, accuracy=0.611, val_loss=0.967, val_accuracy=0.602] 49%|████▉     | 35/71 [04:22<04:22,  7.30s/epoch, loss=0.922, accuracy=0.645, val_loss=0.88, val_accuracy=0.664] 51%|█████     | 36/71 [04:30<04:15,  7.29s/epoch, loss=0.911, accuracy=0.64, val_loss=0.929, val_accuracy=0.636] 52%|█████▏    | 37/71 [04:37<04:07,  7.29s/epoch, loss=0.897, accuracy=0.65, val_loss=0.91, val_accuracy=0.652]  54%|█████▎    | 38/71 [04:44<04:00,  7.29s/epoch, loss=0.946, accuracy=0.6, val_loss=0.919, val_accuracy=0.62]  55%|█████▍    | 39/71 [04:52<03:53,  7.28s/epoch, loss=0.951, accuracy=0.588, val_loss=0.937, val_accuracy=0.607] 56%|█████▋    | 40/71 [04:59<03:45,  7.29s/epoch, loss=0.954, accuracy=0.579, val_loss=1.04, val_accuracy=0.503]  58%|█████▊    | 41/71 [05:06<03:38,  7.29s/epoch, loss=0.94, accuracy=0.567, val_loss=0.94, val_accuracy=0.562]  59%|█████▉    | 42/71 [05:13<03:31,  7.29s/epoch, loss=0.906, accuracy=0.582, val_loss=0.924, val_accuracy=0.595] 61%|██████    | 43/71 [05:21<03:24,  7.29s/epoch, loss=0.893, accuracy=0.604, val_loss=0.93, val_accuracy=0.572]  62%|██████▏   | 44/71 [05:28<03:16,  7.29s/epoch, loss=0.862, accuracy=0.616, val_loss=0.87, val_accuracy=0.615] 63%|██████▎   | 45/71 [05:35<03:09,  7.30s/epoch, loss=0.837, accuracy=0.629, val_loss=0.83, val_accuracy=0.595] 65%|██████▍   | 46/71 [05:43<03:02,  7.30s/epoch, loss=0.807, accuracy=0.65, val_loss=0.837, val_accuracy=0.63]  66%|██████▌   | 47/71 [05:50<02:55,  7.30s/epoch, loss=0.825, accuracy=0.635, val_loss=0.854, val_accuracy=0.601] 68%|██████▊   | 48/71 [05:57<02:47,  7.29s/epoch, loss=0.882, accuracy=0.566, val_loss=0.892, val_accuracy=0.502] 69%|██████▉   | 49/71 [06:05<02:40,  7.29s/epoch, loss=0.87, accuracy=0.593, val_loss=0.865, val_accuracy=0.623]  70%|███████   | 50/71 [06:12<02:33,  7.29s/epoch, loss=0.858, accuracy=0.618, val_loss=0.858, val_accuracy=0.612] 72%|███████▏  | 51/71 [06:19<02:26,  7.30s/epoch, loss=0.885, accuracy=0.615, val_loss=0.851, val_accuracy=0.642] 73%|███████▎  | 52/71 [06:26<02:18,  7.30s/epoch, loss=0.863, accuracy=0.628, val_loss=0.897, val_accuracy=0.592] 75%|███████▍  | 53/71 [06:34<02:11,  7.30s/epoch, loss=0.855, accuracy=0.652, val_loss=0.904, val_accuracy=0.653] 76%|███████▌  | 54/71 [06:41<02:04,  7.30s/epoch, loss=0.909, accuracy=0.602, val_loss=0.893, val_accuracy=0.628] 77%|███████▋  | 55/71 [06:48<01:56,  7.29s/epoch, loss=0.932, accuracy=0.602, val_loss=0.945, val_accuracy=0.568] 79%|███████▉  | 56/71 [06:56<01:49,  7.28s/epoch, loss=0.935, accuracy=0.587, val_loss=0.898, val_accuracy=0.634] 80%|████████  | 57/71 [07:03<01:41,  7.27s/epoch, loss=0.944, accuracy=0.615, val_loss=0.994, val_accuracy=0.594] 82%|████████▏ | 58/71 [07:10<01:34,  7.28s/epoch, loss=0.979, accuracy=0.582, val_loss=0.966, val_accuracy=0.581] 83%|████████▎ | 59/71 [07:17<01:27,  7.27s/epoch, loss=0.925, accuracy=0.611, val_loss=0.926, val_accuracy=0.547] 85%|████████▍ | 60/71 [07:25<01:19,  7.27s/epoch, loss=0.906, accuracy=0.627, val_loss=1.01, val_accuracy=0.592]  86%|████████▌ | 61/71 [07:32<01:12,  7.27s/epoch, loss=0.945, accuracy=0.58, val_loss=1.09, val_accuracy=0.576]  87%|████████▋ | 62/71 [07:39<01:05,  7.29s/epoch, loss=0.934, accuracy=0.584, val_loss=0.92, val_accuracy=0.616] 89%|████████▊ | 63/71 [07:47<00:58,  7.28s/epoch, loss=0.954, accuracy=0.589, val_loss=1.08, val_accuracy=0.503] 90%|█████████ | 64/71 [07:54<00:50,  7.27s/epoch, loss=1.01, accuracy=0.569, val_loss=0.955, val_accuracy=0.579] 92%|█████████▏| 65/71 [08:01<00:42,  7.12s/epoch, loss=0.938, accuracy=0.585, val_loss=1.08, val_accuracy=0.549] 93%|█████████▎| 66/71 [08:07<00:34,  6.90s/epoch, loss=0.907, accuracy=0.596, val_loss=0.893, val_accuracy=0.546] 94%|█████████▍| 67/71 [08:13<00:26,  6.75s/epoch, loss=0.893, accuracy=0.604, val_loss=0.908, val_accuracy=0.619] 96%|█████████▌| 68/71 [08:20<00:19,  6.63s/epoch, loss=0.879, accuracy=0.616, val_loss=0.869, val_accuracy=0.6]   97%|█████████▋| 69/71 [08:26<00:13,  6.55s/epoch, loss=0.839, accuracy=0.64, val_loss=0.82, val_accuracy=0.663] 99%|█████████▊| 70/71 [08:32<00:06,  6.51s/epoch, loss=0.804, accuracy=0.686, val_loss=0.836, val_accuracy=0.664]100%|██████████| 71/71 [08:39<00:00,  6.47s/epoch, loss=0.855, accuracy=0.653, val_loss=0.913, val_accuracy=0.634]100%|██████████| 71/71 [08:39<00:00,  7.31s/epoch, loss=0.855, accuracy=0.653, val_loss=0.913, val_accuracy=0.634]
Test score: 0.46826067566871643
Test accuracy: 0.8321999907493591
