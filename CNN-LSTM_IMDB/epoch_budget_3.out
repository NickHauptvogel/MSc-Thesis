Fri Mar  1 10:48:23 2024       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 545.23.08              Driver Version: 545.23.08    CUDA Version: 12.3     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA TITAN Xp                Off | 00000000:18:00.0 Off |                  N/A |
| 23%   29C    P8               9W / 250W |      0MiB / 12288MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|  No running processes found                                                           |
+---------------------------------------------------------------------------------------+


* * * Run SGD for cluster size = 3. * * *


Budget: 166


* * * Run SGD for ID = 3_1. * * *


2024-03-01 10:48:32.860386: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-01 10:48:52.764048: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-01 10:48:52.766374: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-01 10:48:52.809028: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:18:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-01 10:48:52.809073: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-01 10:48:52.868568: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-01 10:48:52.868668: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-01 10:48:53.001002: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-01 10:48:53.135734: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-01 10:48:53.214624: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-01 10:48:53.427855: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-01 10:48:53.564927: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-01 10:48:53.568760: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-01 10:48:53.568896: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
<__array_function__ internals>:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray
/home/gkb738/.conda/envs/TF_KERAS_GPU/lib/python3.9/site-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray
  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])
/home/gkb738/.conda/envs/TF_KERAS_GPU/lib/python3.9/site-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray
  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])
2024-03-01 10:48:59.602076: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-01 10:48:59.602640: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-01 10:48:59.603267: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:18:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-01 10:48:59.603305: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-01 10:48:59.603365: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-01 10:48:59.603384: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-01 10:48:59.603404: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-01 10:48:59.603420: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-01 10:48:59.603439: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-01 10:48:59.603459: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-01 10:48:59.603478: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-01 10:48:59.604072: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-01 10:48:59.604115: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-01 10:49:00.687550: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-01 10:49:00.687604: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-01 10:49:00.687615: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-01 10:49:00.688738: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:18:00.0, compute capability: 6.1)
{'id': '03_01', 'seed': 1, 'out_folder': 'results/epoch_budget', 'batch_size': 32, 'epochs': 166, 'validation_split': 0.2, 'checkpointing': True, 'initial_lr': 0.1, 'momentum': 0.98, 'nesterov': True, 'bootstrapping': False, 'map_optimizer': True, 'model': 'CNN-LSTM', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Loading data...
Pad sequences (samples x time)
20000 train sequences
5000 validation sequences
25000 test sequences
x_train shape: (20000, 100)
x_val shape: (5000, 100)
x_test shape: (25000, 100)
Using MAP optimizer with reg_weight:  5e-05
CNN-LSTM
0epoch [00:00, ?epoch/s]  0%|          | 0/166 [00:00<?, ?epoch/s]2024-03-01 10:49:01.099138: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-01 10:49:01.111000: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2100000000 Hz
2024-03-01 10:49:02.556607: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-01 10:49:02.774272: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-01 10:49:04.089601: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-01 10:49:04.132367: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/166 [00:14<40:22, 14.68s/epoch, loss=0.695, accuracy=0.599, val_loss=0.51, val_accuracy=0.789]  1%|          | 2/166 [00:22<29:49, 10.91s/epoch, loss=0.476, accuracy=0.82, val_loss=0.475, val_accuracy=0.811]  2%|▏         | 3/166 [00:31<26:18,  9.68s/epoch, loss=0.425, accuracy=0.855, val_loss=0.48, val_accuracy=0.836]  2%|▏         | 4/166 [00:38<24:07,  8.94s/epoch, loss=0.432, accuracy=0.872, val_loss=0.569, val_accuracy=0.828]  3%|▎         | 5/166 [00:46<22:54,  8.53s/epoch, loss=0.447, accuracy=0.885, val_loss=0.583, val_accuracy=0.834]  4%|▎         | 6/166 [00:54<22:04,  8.28s/epoch, loss=0.575, accuracy=0.848, val_loss=0.779, val_accuracy=0.766]  4%|▍         | 7/166 [01:02<21:29,  8.11s/epoch, loss=0.885, accuracy=0.74, val_loss=1.12, val_accuracy=0.632]    5%|▍         | 8/166 [01:10<21:06,  8.01s/epoch, loss=1.18, accuracy=0.606, val_loss=1.18, val_accuracy=0.545]  5%|▌         | 9/166 [01:17<20:50,  7.97s/epoch, loss=1.2, accuracy=0.568, val_loss=1.19, val_accuracy=0.513]   6%|▌         | 10/166 [01:25<20:36,  7.93s/epoch, loss=1.14, accuracy=0.545, val_loss=1.08, val_accuracy=0.59]  7%|▋         | 11/166 [01:33<20:23,  7.90s/epoch, loss=1.07, accuracy=0.555, val_loss=1.05, val_accuracy=0.576]  7%|▋         | 12/166 [01:41<20:10,  7.86s/epoch, loss=1.04, accuracy=0.564, val_loss=0.975, val_accuracy=0.582]  8%|▊         | 13/166 [01:49<20:01,  7.85s/epoch, loss=0.976, accuracy=0.588, val_loss=0.994, val_accuracy=0.498]  8%|▊         | 14/166 [01:57<19:49,  7.83s/epoch, loss=0.966, accuracy=0.598, val_loss=1.03, val_accuracy=0.547]   9%|▉         | 15/166 [02:04<19:39,  7.81s/epoch, loss=0.97, accuracy=0.554, val_loss=0.954, val_accuracy=0.511] 10%|▉         | 16/166 [02:12<19:29,  7.79s/epoch, loss=0.919, accuracy=0.577, val_loss=0.985, val_accuracy=0.513] 10%|█         | 17/166 [02:20<19:20,  7.79s/epoch, loss=0.898, accuracy=0.575, val_loss=0.875, val_accuracy=0.612] 11%|█         | 18/166 [02:28<19:10,  7.78s/epoch, loss=0.875, accuracy=0.592, val_loss=0.851, val_accuracy=0.623] 11%|█▏        | 19/166 [02:35<19:01,  7.77s/epoch, loss=0.842, accuracy=0.628, val_loss=0.813, val_accuracy=0.684] 12%|█▏        | 20/166 [02:43<18:52,  7.76s/epoch, loss=0.878, accuracy=0.619, val_loss=0.896, val_accuracy=0.617] 13%|█▎        | 21/166 [02:51<18:44,  7.75s/epoch, loss=0.857, accuracy=0.638, val_loss=0.836, val_accuracy=0.654] 13%|█▎        | 22/166 [02:59<18:39,  7.78s/epoch, loss=0.861, accuracy=0.637, val_loss=0.84, val_accuracy=0.644]  14%|█▍        | 23/166 [03:06<18:33,  7.79s/epoch, loss=0.843, accuracy=0.644, val_loss=0.87, val_accuracy=0.606] 14%|█▍        | 24/166 [03:14<18:28,  7.80s/epoch, loss=0.903, accuracy=0.62, val_loss=0.942, val_accuracy=0.607] 15%|█▌        | 25/166 [03:22<18:21,  7.81s/epoch, loss=0.904, accuracy=0.648, val_loss=0.941, val_accuracy=0.621] 16%|█▌        | 26/166 [03:30<18:13,  7.81s/epoch, loss=0.912, accuracy=0.63, val_loss=0.937, val_accuracy=0.609]  16%|█▋        | 27/166 [03:38<18:03,  7.80s/epoch, loss=0.932, accuracy=0.62, val_loss=0.929, val_accuracy=0.6]   17%|█▋        | 28/166 [03:46<17:58,  7.81s/epoch, loss=0.941, accuracy=0.624, val_loss=0.967, val_accuracy=0.598] 17%|█▋        | 29/166 [03:53<17:48,  7.80s/epoch, loss=0.979, accuracy=0.578, val_loss=0.923, val_accuracy=0.622] 18%|█▊        | 30/166 [04:01<17:42,  7.81s/epoch, loss=0.918, accuracy=0.614, val_loss=0.889, val_accuracy=0.624] 19%|█▊        | 31/166 [04:09<17:36,  7.82s/epoch, loss=0.886, accuracy=0.624, val_loss=0.85, val_accuracy=0.608]  19%|█▉        | 32/166 [04:17<17:28,  7.82s/epoch, loss=0.877, accuracy=0.615, val_loss=0.867, val_accuracy=0.64] 20%|█▉        | 33/166 [04:25<17:21,  7.83s/epoch, loss=0.883, accuracy=0.629, val_loss=0.944, val_accuracy=0.572] 20%|██        | 34/166 [04:32<17:11,  7.82s/epoch, loss=0.935, accuracy=0.583, val_loss=0.956, val_accuracy=0.522] 21%|██        | 35/166 [04:40<17:02,  7.80s/epoch, loss=0.929, accuracy=0.553, val_loss=0.918, val_accuracy=0.564] 22%|██▏       | 36/166 [04:48<16:54,  7.80s/epoch, loss=0.909, accuracy=0.55, val_loss=0.869, val_accuracy=0.567]  22%|██▏       | 37/166 [04:56<16:47,  7.81s/epoch, loss=0.859, accuracy=0.604, val_loss=0.833, val_accuracy=0.644] 23%|██▎       | 38/166 [05:04<16:39,  7.81s/epoch, loss=0.861, accuracy=0.591, val_loss=0.856, val_accuracy=0.573] 23%|██▎       | 39/166 [05:11<16:30,  7.80s/epoch, loss=0.863, accuracy=0.595, val_loss=0.856, val_accuracy=0.569] 24%|██▍       | 40/166 [05:19<16:23,  7.80s/epoch, loss=0.836, accuracy=0.605, val_loss=0.871, val_accuracy=0.558] 25%|██▍       | 41/166 [05:27<16:15,  7.80s/epoch, loss=0.827, accuracy=0.63, val_loss=0.866, val_accuracy=0.622]  25%|██▌       | 42/166 [05:35<16:09,  7.82s/epoch, loss=0.854, accuracy=0.634, val_loss=0.861, val_accuracy=0.62] 26%|██▌       | 43/166 [05:43<16:03,  7.83s/epoch, loss=0.844, accuracy=0.634, val_loss=0.855, val_accuracy=0.608] 27%|██▋       | 44/166 [05:51<15:56,  7.84s/epoch, loss=0.809, accuracy=0.666, val_loss=0.818, val_accuracy=0.658] 27%|██▋       | 45/166 [05:58<15:48,  7.84s/epoch, loss=0.81, accuracy=0.657, val_loss=0.796, val_accuracy=0.674]  28%|██▊       | 46/166 [06:06<15:41,  7.84s/epoch, loss=0.815, accuracy=0.664, val_loss=0.876, val_accuracy=0.542] 28%|██▊       | 47/166 [06:14<15:31,  7.82s/epoch, loss=0.856, accuracy=0.65, val_loss=0.927, val_accuracy=0.676]  29%|██▉       | 48/166 [06:22<15:21,  7.81s/epoch, loss=1.1, accuracy=0.656, val_loss=1.1, val_accuracy=0.679]    30%|██▉       | 49/166 [06:30<15:16,  7.83s/epoch, loss=1.12, accuracy=0.59, val_loss=1.08, val_accuracy=0.608] 30%|███       | 50/166 [06:38<15:07,  7.82s/epoch, loss=1.01, accuracy=0.61, val_loss=0.972, val_accuracy=0.622] 31%|███       | 51/166 [06:45<15:00,  7.83s/epoch, loss=0.962, accuracy=0.607, val_loss=1.04, val_accuracy=0.581] 31%|███▏      | 52/166 [06:53<14:50,  7.82s/epoch, loss=0.965, accuracy=0.647, val_loss=0.985, val_accuracy=0.616] 32%|███▏      | 53/166 [07:01<14:40,  7.79s/epoch, loss=0.954, accuracy=0.647, val_loss=0.971, val_accuracy=0.616] 33%|███▎      | 54/166 [07:09<14:33,  7.80s/epoch, loss=0.988, accuracy=0.593, val_loss=0.958, val_accuracy=0.613] 33%|███▎      | 55/166 [07:17<14:27,  7.82s/epoch, loss=0.927, accuracy=0.623, val_loss=0.995, val_accuracy=0.615] 34%|███▎      | 56/166 [07:24<14:19,  7.81s/epoch, loss=0.958, accuracy=0.642, val_loss=0.962, val_accuracy=0.643] 34%|███▍      | 57/166 [07:32<14:11,  7.81s/epoch, loss=0.952, accuracy=0.641, val_loss=0.978, val_accuracy=0.605] 35%|███▍      | 58/166 [07:40<14:02,  7.80s/epoch, loss=0.963, accuracy=0.589, val_loss=0.93, val_accuracy=0.602]  36%|███▌      | 59/166 [07:48<13:54,  7.80s/epoch, loss=0.905, accuracy=0.639, val_loss=0.899, val_accuracy=0.641] 36%|███▌      | 60/166 [07:56<13:47,  7.81s/epoch, loss=0.927, accuracy=0.61, val_loss=0.991, val_accuracy=0.514]  37%|███▋      | 61/166 [08:03<13:40,  7.82s/epoch, loss=0.957, accuracy=0.529, val_loss=0.909, val_accuracy=0.567] 37%|███▋      | 62/166 [08:11<13:31,  7.81s/epoch, loss=0.908, accuracy=0.56, val_loss=0.874, val_accuracy=0.586]  38%|███▊      | 63/166 [08:19<13:23,  7.80s/epoch, loss=0.855, accuracy=0.615, val_loss=0.855, val_accuracy=0.63] 39%|███▊      | 64/166 [08:27<13:15,  7.79s/epoch, loss=0.889, accuracy=0.597, val_loss=0.893, val_accuracy=0.597] 39%|███▉      | 65/166 [08:35<13:08,  7.81s/epoch, loss=0.9, accuracy=0.577, val_loss=0.856, val_accuracy=0.611]   40%|███▉      | 66/166 [08:42<13:00,  7.81s/epoch, loss=0.936, accuracy=0.607, val_loss=1.13, val_accuracy=0.628] 40%|████      | 67/166 [08:50<12:53,  7.81s/epoch, loss=1.12, accuracy=0.618, val_loss=1.07, val_accuracy=0.634]  41%|████      | 68/166 [08:58<12:47,  7.83s/epoch, loss=1.03, accuracy=0.637, val_loss=0.999, val_accuracy=0.656] 42%|████▏     | 69/166 [09:06<12:40,  7.84s/epoch, loss=1.01, accuracy=0.631, val_loss=1.05, val_accuracy=0.565]  42%|████▏     | 70/166 [09:14<12:31,  7.83s/epoch, loss=1.01, accuracy=0.59, val_loss=0.966, val_accuracy=0.609] 43%|████▎     | 71/166 [09:22<12:24,  7.84s/epoch, loss=0.988, accuracy=0.602, val_loss=0.963, val_accuracy=0.61] 43%|████▎     | 72/166 [09:30<12:17,  7.84s/epoch, loss=0.977, accuracy=0.59, val_loss=0.947, val_accuracy=0.611] 44%|████▍     | 73/166 [09:37<12:07,  7.82s/epoch, loss=0.928, accuracy=0.617, val_loss=0.898, val_accuracy=0.602] 45%|████▍     | 74/166 [09:45<11:57,  7.80s/epoch, loss=0.911, accuracy=0.602, val_loss=0.904, val_accuracy=0.578] 45%|████▌     | 75/166 [09:53<11:49,  7.79s/epoch, loss=0.901, accuracy=0.607, val_loss=0.909, val_accuracy=0.577] 46%|████▌     | 76/166 [10:01<11:41,  7.80s/epoch, loss=0.874, accuracy=0.616, val_loss=0.864, val_accuracy=0.635] 46%|████▋     | 77/166 [10:09<11:35,  7.82s/epoch, loss=0.873, accuracy=0.619, val_loss=0.884, val_accuracy=0.652] 47%|████▋     | 78/166 [10:16<11:30,  7.85s/epoch, loss=0.827, accuracy=0.655, val_loss=0.825, val_accuracy=0.66]  48%|████▊     | 79/166 [10:24<11:22,  7.84s/epoch, loss=0.835, accuracy=0.656, val_loss=0.877, val_accuracy=0.617] 48%|████▊     | 80/166 [10:32<11:12,  7.82s/epoch, loss=0.902, accuracy=0.61, val_loss=1.02, val_accuracy=0.625]   49%|████▉     | 81/166 [10:40<11:04,  7.82s/epoch, loss=0.882, accuracy=0.619, val_loss=0.928, val_accuracy=0.609] 49%|████▉     | 82/166 [10:48<10:55,  7.80s/epoch, loss=0.873, accuracy=0.637, val_loss=0.854, val_accuracy=0.649] 50%|█████     | 83/166 [10:55<10:48,  7.82s/epoch, loss=0.876, accuracy=0.627, val_loss=0.863, val_accuracy=0.637] 51%|█████     | 84/166 [11:03<10:42,  7.83s/epoch, loss=0.889, accuracy=0.62, val_loss=0.91, val_accuracy=0.62]    51%|█████     | 85/166 [11:11<10:34,  7.84s/epoch, loss=0.865, accuracy=0.658, val_loss=0.903, val_accuracy=0.64] 52%|█████▏    | 86/166 [11:19<10:28,  7.86s/epoch, loss=0.875, accuracy=0.648, val_loss=0.861, val_accuracy=0.64] 52%|█████▏    | 87/166 [11:27<10:23,  7.89s/epoch, loss=0.879, accuracy=0.633, val_loss=0.891, val_accuracy=0.563] 53%|█████▎    | 88/166 [11:35<10:16,  7.90s/epoch, loss=0.894, accuracy=0.607, val_loss=0.901, val_accuracy=0.616] 54%|█████▎    | 89/166 [11:43<10:08,  7.90s/epoch, loss=0.875, accuracy=0.626, val_loss=0.855, val_accuracy=0.649] 54%|█████▍    | 90/166 [11:51<09:57,  7.87s/epoch, loss=0.868, accuracy=0.62, val_loss=0.843, val_accuracy=0.645]  55%|█████▍    | 91/166 [11:58<09:48,  7.85s/epoch, loss=0.848, accuracy=0.64, val_loss=0.873, val_accuracy=0.62]  55%|█████▌    | 92/166 [12:06<09:41,  7.85s/epoch, loss=0.845, accuracy=0.641, val_loss=0.856, val_accuracy=0.628] 56%|█████▌    | 93/166 [12:14<09:32,  7.84s/epoch, loss=0.881, accuracy=0.596, val_loss=0.929, val_accuracy=0.606] 57%|█████▋    | 94/166 [12:22<09:23,  7.83s/epoch, loss=0.93, accuracy=0.62, val_loss=0.917, val_accuracy=0.608]   57%|█████▋    | 95/166 [12:30<09:15,  7.83s/epoch, loss=0.903, accuracy=0.632, val_loss=0.886, val_accuracy=0.647] 58%|█████▊    | 96/166 [12:38<09:08,  7.84s/epoch, loss=0.855, accuracy=0.666, val_loss=0.881, val_accuracy=0.623] 58%|█████▊    | 97/166 [12:45<08:59,  7.82s/epoch, loss=1.08, accuracy=0.679, val_loss=1.26, val_accuracy=0.624]   59%|█████▉    | 98/166 [12:53<08:50,  7.81s/epoch, loss=1.21, accuracy=0.626, val_loss=1.17, val_accuracy=0.613] 60%|█████▉    | 99/166 [13:01<08:43,  7.81s/epoch, loss=1.14, accuracy=0.621, val_loss=1.13, val_accuracy=0.571] 60%|██████    | 100/166 [13:09<08:35,  7.82s/epoch, loss=1.11, accuracy=0.545, val_loss=1.06, val_accuracy=0.565] 61%|██████    | 101/166 [13:17<08:27,  7.81s/epoch, loss=1.01, accuracy=0.593, val_loss=0.966, val_accuracy=0.625] 61%|██████▏   | 102/166 [13:24<08:19,  7.80s/epoch, loss=0.926, accuracy=0.642, val_loss=0.95, val_accuracy=0.602] 62%|██████▏   | 103/166 [13:32<08:11,  7.81s/epoch, loss=0.945, accuracy=0.635, val_loss=0.991, val_accuracy=0.641] 63%|██████▎   | 104/166 [13:40<08:04,  7.81s/epoch, loss=0.971, accuracy=0.619, val_loss=0.981, val_accuracy=0.638] 63%|██████▎   | 105/166 [13:48<07:56,  7.82s/epoch, loss=0.983, accuracy=0.608, val_loss=0.986, val_accuracy=0.496] 64%|██████▍   | 106/166 [13:56<07:49,  7.83s/epoch, loss=0.947, accuracy=0.601, val_loss=0.92, val_accuracy=0.624]  64%|██████▍   | 107/166 [14:04<07:41,  7.82s/epoch, loss=0.88, accuracy=0.651, val_loss=0.872, val_accuracy=0.641] 65%|██████▌   | 108/166 [14:11<07:33,  7.82s/epoch, loss=0.852, accuracy=0.653, val_loss=0.868, val_accuracy=0.619] 66%|██████▌   | 109/166 [14:19<07:25,  7.82s/epoch, loss=0.839, accuracy=0.662, val_loss=0.827, val_accuracy=0.658] 66%|██████▋   | 110/166 [14:27<07:17,  7.81s/epoch, loss=0.852, accuracy=0.641, val_loss=0.875, val_accuracy=0.644] 67%|██████▋   | 111/166 [14:35<07:10,  7.83s/epoch, loss=0.871, accuracy=0.646, val_loss=0.882, val_accuracy=0.631] 67%|██████▋   | 112/166 [14:43<07:03,  7.84s/epoch, loss=0.867, accuracy=0.625, val_loss=0.849, val_accuracy=0.648] 68%|██████▊   | 113/166 [14:51<06:55,  7.85s/epoch, loss=0.863, accuracy=0.606, val_loss=0.894, val_accuracy=0.553] 69%|██████▊   | 114/166 [14:58<06:48,  7.85s/epoch, loss=0.848, accuracy=0.623, val_loss=0.876, val_accuracy=0.631] 69%|██████▉   | 115/166 [15:06<06:39,  7.83s/epoch, loss=0.858, accuracy=0.619, val_loss=0.89, val_accuracy=0.509]  70%|██████▉   | 116/166 [15:14<06:31,  7.82s/epoch, loss=0.847, accuracy=0.637, val_loss=0.915, val_accuracy=0.609] 70%|███████   | 117/166 [15:22<06:24,  7.84s/epoch, loss=0.846, accuracy=0.638, val_loss=0.934, val_accuracy=0.614] 71%|███████   | 118/166 [15:30<06:16,  7.85s/epoch, loss=0.858, accuracy=0.621, val_loss=0.868, val_accuracy=0.61]  72%|███████▏  | 119/166 [15:38<06:08,  7.83s/epoch, loss=0.837, accuracy=0.621, val_loss=0.826, val_accuracy=0.61] 72%|███████▏  | 120/166 [15:45<06:00,  7.84s/epoch, loss=0.811, accuracy=0.647, val_loss=0.829, val_accuracy=0.679] 73%|███████▎  | 121/166 [15:53<05:52,  7.84s/epoch, loss=0.793, accuracy=0.667, val_loss=0.82, val_accuracy=0.647]  73%|███████▎  | 122/166 [16:01<05:45,  7.85s/epoch, loss=0.838, accuracy=0.602, val_loss=0.81, val_accuracy=0.665] 74%|███████▍  | 123/166 [16:09<05:36,  7.83s/epoch, loss=0.85, accuracy=0.633, val_loss=0.901, val_accuracy=0.6]   75%|███████▍  | 124/166 [16:17<05:27,  7.80s/epoch, loss=0.914, accuracy=0.611, val_loss=0.894, val_accuracy=0.628] 75%|███████▌  | 125/166 [16:24<05:20,  7.82s/epoch, loss=0.892, accuracy=0.625, val_loss=0.898, val_accuracy=0.622] 76%|███████▌  | 126/166 [16:32<05:13,  7.84s/epoch, loss=0.879, accuracy=0.607, val_loss=0.877, val_accuracy=0.621] 77%|███████▋  | 127/166 [16:40<05:06,  7.85s/epoch, loss=0.863, accuracy=0.622, val_loss=0.851, val_accuracy=0.635] 77%|███████▋  | 128/166 [16:48<04:58,  7.85s/epoch, loss=0.895, accuracy=0.594, val_loss=0.848, val_accuracy=0.637] 78%|███████▊  | 129/166 [16:56<04:50,  7.85s/epoch, loss=0.9, accuracy=0.606, val_loss=0.944, val_accuracy=0.532]   78%|███████▊  | 130/166 [17:04<04:42,  7.86s/epoch, loss=0.948, accuracy=0.593, val_loss=0.915, val_accuracy=0.6] 79%|███████▉  | 131/166 [17:12<04:35,  7.86s/epoch, loss=0.909, accuracy=0.599, val_loss=0.878, val_accuracy=0.62] 80%|███████▉  | 132/166 [17:19<04:26,  7.84s/epoch, loss=0.872, accuracy=0.624, val_loss=0.846, val_accuracy=0.636] 80%|████████  | 133/166 [17:27<04:18,  7.84s/epoch, loss=0.865, accuracy=0.598, val_loss=0.867, val_accuracy=0.597] 81%|████████  | 134/166 [17:35<04:10,  7.82s/epoch, loss=0.884, accuracy=0.585, val_loss=0.864, val_accuracy=0.62]  81%|████████▏ | 135/166 [17:43<04:02,  7.83s/epoch, loss=0.857, accuracy=0.615, val_loss=0.885, val_accuracy=0.622] 82%|████████▏ | 136/166 [17:51<03:55,  7.86s/epoch, loss=0.95, accuracy=0.601, val_loss=0.95, val_accuracy=0.599]   83%|████████▎ | 137/166 [17:59<03:47,  7.86s/epoch, loss=0.932, accuracy=0.621, val_loss=0.947, val_accuracy=0.582] 83%|████████▎ | 138/166 [18:07<03:40,  7.87s/epoch, loss=0.949, accuracy=0.567, val_loss=0.889, val_accuracy=0.634] 84%|████████▎ | 139/166 [18:14<03:31,  7.84s/epoch, loss=0.892, accuracy=0.608, val_loss=0.899, val_accuracy=0.566] 84%|████████▍ | 140/166 [18:22<03:21,  7.76s/epoch, loss=0.864, accuracy=0.608, val_loss=0.867, val_accuracy=0.513] 85%|████████▍ | 141/166 [18:30<03:12,  7.72s/epoch, loss=0.831, accuracy=0.618, val_loss=0.789, val_accuracy=0.656] 86%|████████▌ | 142/166 [18:37<03:06,  7.76s/epoch, loss=0.82, accuracy=0.647, val_loss=0.874, val_accuracy=0.525]  86%|████████▌ | 143/166 [18:46<03:02,  7.92s/epoch, loss=0.872, accuracy=0.607, val_loss=0.935, val_accuracy=0.581] 87%|████████▋ | 144/166 [18:54<02:54,  7.95s/epoch, loss=0.879, accuracy=0.616, val_loss=0.955, val_accuracy=0.664] 87%|████████▋ | 145/166 [19:02<02:49,  8.06s/epoch, loss=3.65, accuracy=0.578, val_loss=3.62, val_accuracy=0.575]   88%|████████▊ | 146/166 [19:11<02:43,  8.18s/epoch, loss=3.23, accuracy=0.582, val_loss=2.86, val_accuracy=0.581] 89%|████████▊ | 147/166 [19:19<02:36,  8.21s/epoch, loss=2.58, accuracy=0.59, val_loss=2.3, val_accuracy=0.61]    89%|████████▉ | 148/166 [19:27<02:27,  8.17s/epoch, loss=2.1, accuracy=0.587, val_loss=1.9, val_accuracy=0.617] 90%|████████▉ | 149/166 [19:35<02:20,  8.26s/epoch, loss=1.74, accuracy=0.612, val_loss=1.57, val_accuracy=0.631] 90%|█████████ | 150/166 [19:44<02:13,  8.35s/epoch, loss=1.48, accuracy=0.626, val_loss=1.39, val_accuracy=0.626] 91%|█████████ | 151/166 [19:52<02:05,  8.39s/epoch, loss=1.3, accuracy=0.631, val_loss=1.25, val_accuracy=0.652]  92%|█████████▏| 152/166 [20:01<01:57,  8.40s/epoch, loss=1.15, accuracy=0.658, val_loss=1.12, val_accuracy=0.646] 92%|█████████▏| 153/166 [20:09<01:49,  8.40s/epoch, loss=1.12, accuracy=0.639, val_loss=1.1, val_accuracy=0.619]  93%|█████████▎| 154/166 [20:18<01:40,  8.41s/epoch, loss=1.08, accuracy=0.589, val_loss=1.05, val_accuracy=0.592] 93%|█████████▎| 155/166 [20:26<01:32,  8.41s/epoch, loss=1.04, accuracy=0.579, val_loss=0.997, val_accuracy=0.598] 94%|█████████▍| 156/166 [20:35<01:24,  8.43s/epoch, loss=0.99, accuracy=0.573, val_loss=1.19, val_accuracy=0.528]  95%|█████████▍| 157/166 [20:43<01:16,  8.45s/epoch, loss=0.971, accuracy=0.599, val_loss=0.94, val_accuracy=0.612] 95%|█████████▌| 158/166 [20:51<01:07,  8.43s/epoch, loss=0.93, accuracy=0.62, val_loss=0.892, val_accuracy=0.636]  96%|█████████▌| 159/166 [21:00<00:59,  8.44s/epoch, loss=0.908, accuracy=0.606, val_loss=1.06, val_accuracy=0.487] 96%|█████████▋| 160/166 [21:08<00:50,  8.43s/epoch, loss=0.913, accuracy=0.565, val_loss=0.888, val_accuracy=0.514] 97%|█████████▋| 161/166 [21:17<00:42,  8.45s/epoch, loss=0.92, accuracy=0.563, val_loss=1.12, val_accuracy=0.583]   98%|█████████▊| 162/166 [21:25<00:33,  8.48s/epoch, loss=1.09, accuracy=0.604, val_loss=1.04, val_accuracy=0.621] 98%|█████████▊| 163/166 [21:34<00:25,  8.46s/epoch, loss=1.03, accuracy=0.599, val_loss=1.17, val_accuracy=0.487] 99%|█████████▉| 164/166 [21:42<00:16,  8.46s/epoch, loss=0.968, accuracy=0.606, val_loss=0.974, val_accuracy=0.62] 99%|█████████▉| 165/166 [21:51<00:08,  8.47s/epoch, loss=0.913, accuracy=0.632, val_loss=0.915, val_accuracy=0.569]100%|██████████| 166/166 [21:59<00:00,  8.47s/epoch, loss=0.901, accuracy=0.633, val_loss=0.922, val_accuracy=0.567]100%|██████████| 166/166 [21:59<00:00,  7.95s/epoch, loss=0.901, accuracy=0.633, val_loss=0.922, val_accuracy=0.567]
Test score: 0.4863409101963043
Test accuracy: 0.8365600109100342


* * * Run SGD for ID = 3_2. * * *


2024-03-01 11:11:09.388995: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-01 11:11:12.997413: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-01 11:11:12.998738: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-01 11:11:13.042379: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:18:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-01 11:11:13.042425: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-01 11:11:13.046050: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-01 11:11:13.046139: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-01 11:11:13.048786: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-01 11:11:13.049549: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-01 11:11:13.052433: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-01 11:11:13.054272: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-01 11:11:13.060406: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-01 11:11:13.061194: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-01 11:11:13.061311: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
<__array_function__ internals>:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray
/home/gkb738/.conda/envs/TF_KERAS_GPU/lib/python3.9/site-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray
  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])
/home/gkb738/.conda/envs/TF_KERAS_GPU/lib/python3.9/site-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray
  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])
2024-03-01 11:11:20.226356: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-01 11:11:20.227083: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-01 11:11:20.228301: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:18:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-01 11:11:20.228342: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-01 11:11:20.228414: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-01 11:11:20.228435: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-01 11:11:20.228453: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-01 11:11:20.228470: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-01 11:11:20.228490: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-01 11:11:20.228509: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-01 11:11:20.228529: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-01 11:11:20.229122: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-01 11:11:20.229167: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-01 11:11:20.951972: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-01 11:11:20.952050: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-01 11:11:20.952063: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-01 11:11:20.953372: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:18:00.0, compute capability: 6.1)
{'id': '03_02', 'seed': 2, 'out_folder': 'results/epoch_budget', 'batch_size': 32, 'epochs': 166, 'validation_split': 0.2, 'checkpointing': True, 'initial_lr': 0.1, 'momentum': 0.98, 'nesterov': True, 'bootstrapping': False, 'map_optimizer': True, 'model': 'CNN-LSTM', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Loading data...
Pad sequences (samples x time)
20000 train sequences
5000 validation sequences
25000 test sequences
x_train shape: (20000, 100)
x_val shape: (5000, 100)
x_test shape: (25000, 100)
Using MAP optimizer with reg_weight:  5e-05
CNN-LSTM
0epoch [00:00, ?epoch/s]  0%|          | 0/166 [00:00<?, ?epoch/s]2024-03-01 11:11:21.401428: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-01 11:11:21.414956: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2100000000 Hz
2024-03-01 11:11:23.068144: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-01 11:11:23.290264: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-01 11:11:24.162807: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-01 11:11:24.215114: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/166 [00:14<40:43, 14.81s/epoch, loss=0.664, accuracy=0.633, val_loss=0.536, val_accuracy=0.789]  1%|          | 2/166 [00:23<30:47, 11.27s/epoch, loss=0.475, accuracy=0.823, val_loss=0.456, val_accuracy=0.838]  2%|▏         | 3/166 [00:32<27:17, 10.04s/epoch, loss=0.418, accuracy=0.864, val_loss=0.489, val_accuracy=0.836]  2%|▏         | 4/166 [00:40<25:33,  9.47s/epoch, loss=0.408, accuracy=0.88, val_loss=0.534, val_accuracy=0.834]   3%|▎         | 5/166 [00:49<24:27,  9.12s/epoch, loss=0.421, accuracy=0.888, val_loss=0.571, val_accuracy=0.837]  4%|▎         | 6/166 [00:57<23:42,  8.89s/epoch, loss=0.493, accuracy=0.879, val_loss=0.631, val_accuracy=0.83]   4%|▍         | 7/166 [01:06<23:11,  8.75s/epoch, loss=0.691, accuracy=0.82, val_loss=0.999, val_accuracy=0.667]  5%|▍         | 8/166 [01:14<22:48,  8.66s/epoch, loss=1.11, accuracy=0.617, val_loss=1.15, val_accuracy=0.553]   5%|▌         | 9/166 [01:23<22:32,  8.61s/epoch, loss=1.16, accuracy=0.543, val_loss=1.13, val_accuracy=0.558]  6%|▌         | 10/166 [01:31<22:15,  8.56s/epoch, loss=1.08, accuracy=0.554, val_loss=1.03, val_accuracy=0.585]  7%|▋         | 11/166 [01:40<22:03,  8.54s/epoch, loss=1.01, accuracy=0.557, val_loss=0.988, val_accuracy=0.513]  7%|▋         | 12/166 [01:48<21:52,  8.52s/epoch, loss=0.949, accuracy=0.6, val_loss=1.01, val_accuracy=0.494]    8%|▊         | 13/166 [01:57<21:40,  8.50s/epoch, loss=0.918, accuracy=0.616, val_loss=0.985, val_accuracy=0.536]  8%|▊         | 14/166 [02:05<21:30,  8.49s/epoch, loss=0.95, accuracy=0.568, val_loss=1.01, val_accuracy=0.529]    9%|▉         | 15/166 [02:13<21:21,  8.49s/epoch, loss=0.933, accuracy=0.587, val_loss=0.887, val_accuracy=0.634] 10%|▉         | 16/166 [02:22<21:12,  8.48s/epoch, loss=0.898, accuracy=0.613, val_loss=0.884, val_accuracy=0.643] 10%|█         | 17/166 [02:30<21:07,  8.51s/epoch, loss=0.958, accuracy=0.583, val_loss=0.998, val_accuracy=0.571] 11%|█         | 18/166 [02:39<21:04,  8.54s/epoch, loss=0.975, accuracy=0.58, val_loss=0.932, val_accuracy=0.624]  11%|█▏        | 19/166 [02:48<20:53,  8.52s/epoch, loss=0.974, accuracy=0.587, val_loss=0.961, val_accuracy=0.626] 12%|█▏        | 20/166 [02:56<20:44,  8.53s/epoch, loss=0.975, accuracy=0.579, val_loss=0.929, val_accuracy=0.618] 13%|█▎        | 21/166 [03:05<20:31,  8.50s/epoch, loss=0.976, accuracy=0.582, val_loss=0.973, val_accuracy=0.573] 13%|█▎        | 22/166 [03:13<20:22,  8.49s/epoch, loss=1, accuracy=0.534, val_loss=0.984, val_accuracy=0.547]     14%|█▍        | 23/166 [03:21<20:09,  8.46s/epoch, loss=1.07, accuracy=0.541, val_loss=1.08, val_accuracy=0.553] 14%|█▍        | 24/166 [03:30<19:59,  8.45s/epoch, loss=1.07, accuracy=0.54, val_loss=1.01, val_accuracy=0.568]  15%|█▌        | 25/166 [03:38<19:49,  8.43s/epoch, loss=1, accuracy=0.54, val_loss=1.05, val_accuracy=0.537]    16%|█▌        | 26/166 [03:47<19:41,  8.44s/epoch, loss=0.949, accuracy=0.562, val_loss=0.928, val_accuracy=0.563] 16%|█▋        | 27/166 [03:55<19:34,  8.45s/epoch, loss=0.94, accuracy=0.562, val_loss=1.06, val_accuracy=0.492]   17%|█▋        | 28/166 [04:04<19:25,  8.45s/epoch, loss=0.924, accuracy=0.552, val_loss=0.927, val_accuracy=0.523] 17%|█▋        | 29/166 [04:12<19:18,  8.46s/epoch, loss=0.879, accuracy=0.576, val_loss=0.865, val_accuracy=0.606] 18%|█▊        | 30/166 [04:20<19:07,  8.44s/epoch, loss=0.888, accuracy=0.568, val_loss=0.863, val_accuracy=0.545] 19%|█▊        | 31/166 [04:29<18:58,  8.44s/epoch, loss=0.861, accuracy=0.575, val_loss=0.792, val_accuracy=0.647] 19%|█▉        | 32/166 [04:37<18:51,  8.44s/epoch, loss=0.842, accuracy=0.619, val_loss=0.948, val_accuracy=0.539] 20%|█▉        | 33/166 [04:46<18:50,  8.50s/epoch, loss=0.863, accuracy=0.612, val_loss=0.885, val_accuracy=0.541] 20%|██        | 34/166 [04:55<18:49,  8.56s/epoch, loss=0.858, accuracy=0.618, val_loss=0.837, val_accuracy=0.616] 21%|██        | 35/166 [05:03<18:43,  8.58s/epoch, loss=0.865, accuracy=0.605, val_loss=0.846, val_accuracy=0.642] 22%|██▏       | 36/166 [05:12<18:36,  8.59s/epoch, loss=0.889, accuracy=0.582, val_loss=0.851, val_accuracy=0.598] 22%|██▏       | 37/166 [05:21<18:26,  8.58s/epoch, loss=0.869, accuracy=0.607, val_loss=0.905, val_accuracy=0.512] 23%|██▎       | 38/166 [05:29<18:16,  8.57s/epoch, loss=0.949, accuracy=0.576, val_loss=0.928, val_accuracy=0.59]  23%|██▎       | 39/166 [05:38<18:04,  8.54s/epoch, loss=0.917, accuracy=0.626, val_loss=0.952, val_accuracy=0.618] 24%|██▍       | 40/166 [05:46<17:57,  8.55s/epoch, loss=0.931, accuracy=0.621, val_loss=0.941, val_accuracy=0.643] 25%|██▍       | 41/166 [05:55<17:44,  8.52s/epoch, loss=1.11, accuracy=0.58, val_loss=1.23, val_accuracy=0.567]    25%|██▌       | 42/166 [06:03<17:39,  8.54s/epoch, loss=1.16, accuracy=0.59, val_loss=1.12, val_accuracy=0.594] 26%|██▌       | 43/166 [06:12<17:33,  8.57s/epoch, loss=1.09, accuracy=0.599, val_loss=1.07, val_accuracy=0.606] 27%|██▋       | 44/166 [06:20<17:23,  8.55s/epoch, loss=1.05, accuracy=0.593, val_loss=1.01, val_accuracy=0.599] 27%|██▋       | 45/166 [06:29<17:15,  8.55s/epoch, loss=1.01, accuracy=0.576, val_loss=0.932, val_accuracy=0.643] 28%|██▊       | 46/166 [06:37<17:03,  8.53s/epoch, loss=0.948, accuracy=0.618, val_loss=0.922, val_accuracy=0.639] 28%|██▊       | 47/166 [06:46<16:54,  8.52s/epoch, loss=0.941, accuracy=0.599, val_loss=0.92, val_accuracy=0.588]  29%|██▉       | 48/166 [06:54<16:44,  8.51s/epoch, loss=0.936, accuracy=0.577, val_loss=0.92, val_accuracy=0.606] 30%|██▉       | 49/166 [07:03<16:35,  8.51s/epoch, loss=0.934, accuracy=0.567, val_loss=0.928, val_accuracy=0.514] 30%|███       | 50/166 [07:11<16:28,  8.52s/epoch, loss=0.907, accuracy=0.569, val_loss=0.87, val_accuracy=0.594]  31%|███       | 51/166 [07:20<16:19,  8.52s/epoch, loss=0.862, accuracy=0.588, val_loss=0.835, val_accuracy=0.596] 31%|███▏      | 52/166 [07:28<16:10,  8.51s/epoch, loss=0.837, accuracy=0.595, val_loss=0.804, val_accuracy=0.617] 32%|███▏      | 53/166 [07:37<16:01,  8.51s/epoch, loss=0.808, accuracy=0.618, val_loss=0.819, val_accuracy=0.616] 33%|███▎      | 54/166 [07:45<15:55,  8.53s/epoch, loss=0.796, accuracy=0.656, val_loss=0.908, val_accuracy=0.647] 33%|███▎      | 55/166 [07:54<15:44,  8.51s/epoch, loss=0.818, accuracy=0.681, val_loss=0.847, val_accuracy=0.652] 34%|███▎      | 56/166 [08:02<15:33,  8.49s/epoch, loss=0.875, accuracy=0.661, val_loss=1.01, val_accuracy=0.61]   34%|███▍      | 57/166 [08:11<15:23,  8.48s/epoch, loss=0.942, accuracy=0.643, val_loss=1, val_accuracy=0.563]   35%|███▍      | 58/166 [08:19<15:16,  8.49s/epoch, loss=0.965, accuracy=0.605, val_loss=0.984, val_accuracy=0.633] 36%|███▌      | 59/166 [08:28<15:04,  8.46s/epoch, loss=0.972, accuracy=0.588, val_loss=0.949, val_accuracy=0.598] 36%|███▌      | 60/166 [08:36<14:54,  8.44s/epoch, loss=0.93, accuracy=0.594, val_loss=0.908, val_accuracy=0.612]  37%|███▋      | 61/166 [08:45<14:45,  8.43s/epoch, loss=0.91, accuracy=0.618, val_loss=1.02, val_accuracy=0.56]   37%|███▋      | 62/166 [08:53<14:38,  8.45s/epoch, loss=0.917, accuracy=0.614, val_loss=0.899, val_accuracy=0.626] 38%|███▊      | 63/166 [09:01<14:30,  8.45s/epoch, loss=0.892, accuracy=0.618, val_loss=0.874, val_accuracy=0.63]  39%|███▊      | 64/166 [09:10<14:25,  8.48s/epoch, loss=0.854, accuracy=0.629, val_loss=0.819, val_accuracy=0.637] 39%|███▉      | 65/166 [09:18<14:16,  8.48s/epoch, loss=0.825, accuracy=0.649, val_loss=0.898, val_accuracy=0.566] 40%|███▉      | 66/166 [09:27<14:08,  8.48s/epoch, loss=0.856, accuracy=0.62, val_loss=0.841, val_accuracy=0.649]  40%|████      | 67/166 [09:35<13:58,  8.47s/epoch, loss=0.865, accuracy=0.631, val_loss=0.829, val_accuracy=0.66] 41%|████      | 68/166 [09:44<13:47,  8.45s/epoch, loss=0.851, accuracy=0.63, val_loss=0.857, val_accuracy=0.643] 42%|████▏     | 69/166 [09:52<13:36,  8.41s/epoch, loss=0.863, accuracy=0.615, val_loss=0.846, val_accuracy=0.603] 42%|████▏     | 70/166 [10:01<13:27,  8.41s/epoch, loss=0.865, accuracy=0.62, val_loss=0.883, val_accuracy=0.659]  43%|████▎     | 71/166 [10:09<13:21,  8.44s/epoch, loss=0.895, accuracy=0.619, val_loss=0.881, val_accuracy=0.642] 43%|████▎     | 72/166 [10:18<13:15,  8.47s/epoch, loss=0.892, accuracy=0.627, val_loss=0.96, val_accuracy=0.529]  44%|████▍     | 73/166 [10:26<13:07,  8.47s/epoch, loss=0.927, accuracy=0.582, val_loss=0.915, val_accuracy=0.579] 45%|████▍     | 74/166 [10:34<12:55,  8.43s/epoch, loss=0.913, accuracy=0.607, val_loss=0.881, val_accuracy=0.633] 45%|████▌     | 75/166 [10:43<12:43,  8.39s/epoch, loss=0.906, accuracy=0.59, val_loss=0.884, val_accuracy=0.614]  46%|████▌     | 76/166 [10:51<12:33,  8.38s/epoch, loss=0.891, accuracy=0.594, val_loss=0.861, val_accuracy=0.604] 46%|████▋     | 77/166 [10:59<12:26,  8.39s/epoch, loss=0.876, accuracy=0.587, val_loss=0.885, val_accuracy=0.509] 47%|████▋     | 78/166 [11:08<12:21,  8.42s/epoch, loss=0.882, accuracy=0.566, val_loss=0.875, val_accuracy=0.509] 48%|████▊     | 79/166 [11:16<12:15,  8.46s/epoch, loss=0.861, accuracy=0.584, val_loss=0.811, val_accuracy=0.621] 48%|████▊     | 80/166 [11:25<12:09,  8.48s/epoch, loss=0.83, accuracy=0.632, val_loss=0.847, val_accuracy=0.565]  49%|████▉     | 81/166 [11:34<12:02,  8.50s/epoch, loss=0.836, accuracy=0.626, val_loss=0.941, val_accuracy=0.584] 49%|████▉     | 82/166 [11:42<11:53,  8.49s/epoch, loss=0.86, accuracy=0.608, val_loss=0.901, val_accuracy=0.492]  50%|█████     | 83/166 [11:51<11:44,  8.49s/epoch, loss=0.91, accuracy=0.618, val_loss=0.888, val_accuracy=0.627] 51%|█████     | 84/166 [11:59<11:36,  8.50s/epoch, loss=0.871, accuracy=0.639, val_loss=0.855, val_accuracy=0.627] 51%|█████     | 85/166 [12:07<11:26,  8.48s/epoch, loss=0.873, accuracy=0.636, val_loss=0.88, val_accuracy=0.633]  52%|█████▏    | 86/166 [12:16<11:18,  8.49s/epoch, loss=0.861, accuracy=0.655, val_loss=0.877, val_accuracy=0.641] 52%|█████▏    | 87/166 [12:25<11:12,  8.52s/epoch, loss=1.04, accuracy=0.624, val_loss=1.13, val_accuracy=0.624]   53%|█████▎    | 88/166 [12:33<11:03,  8.50s/epoch, loss=1.07, accuracy=0.618, val_loss=1.04, val_accuracy=0.645] 54%|█████▎    | 89/166 [12:41<10:51,  8.47s/epoch, loss=0.99, accuracy=0.655, val_loss=0.986, val_accuracy=0.635] 54%|█████▍    | 90/166 [12:50<10:42,  8.45s/epoch, loss=0.973, accuracy=0.65, val_loss=0.988, val_accuracy=0.658] 55%|█████▍    | 91/166 [12:58<10:35,  8.47s/epoch, loss=1.01, accuracy=0.639, val_loss=1.02, val_accuracy=0.617]  55%|█████▌    | 92/166 [13:07<10:27,  8.47s/epoch, loss=1, accuracy=0.621, val_loss=0.963, val_accuracy=0.673]   56%|█████▌    | 93/166 [13:15<10:19,  8.49s/epoch, loss=0.995, accuracy=0.62, val_loss=0.982, val_accuracy=0.631] 57%|█████▋    | 94/166 [13:24<10:11,  8.49s/epoch, loss=0.962, accuracy=0.624, val_loss=0.978, val_accuracy=0.605] 57%|█████▋    | 95/166 [13:32<10:03,  8.50s/epoch, loss=0.922, accuracy=0.633, val_loss=0.895, val_accuracy=0.626] 58%|█████▊    | 96/166 [13:41<09:54,  8.49s/epoch, loss=0.877, accuracy=0.644, val_loss=0.886, val_accuracy=0.654] 58%|█████▊    | 97/166 [13:49<09:47,  8.51s/epoch, loss=0.864, accuracy=0.638, val_loss=0.865, val_accuracy=0.648] 59%|█████▉    | 98/166 [13:58<09:39,  8.53s/epoch, loss=0.872, accuracy=0.634, val_loss=0.93, val_accuracy=0.554]  60%|█████▉    | 99/166 [14:06<09:30,  8.52s/epoch, loss=0.888, accuracy=0.644, val_loss=0.908, val_accuracy=0.573] 60%|██████    | 100/166 [14:15<09:23,  8.53s/epoch, loss=0.897, accuracy=0.639, val_loss=0.896, val_accuracy=0.631] 61%|██████    | 101/166 [14:23<09:12,  8.50s/epoch, loss=0.945, accuracy=0.646, val_loss=1.01, val_accuracy=0.627]  61%|██████▏   | 102/166 [14:32<09:03,  8.50s/epoch, loss=0.999, accuracy=0.617, val_loss=1.04, val_accuracy=0.496] 62%|██████▏   | 103/166 [14:40<08:55,  8.51s/epoch, loss=0.947, accuracy=0.619, val_loss=1.02, val_accuracy=0.561] 63%|██████▎   | 104/166 [14:49<08:50,  8.56s/epoch, loss=0.949, accuracy=0.617, val_loss=0.943, val_accuracy=0.626] 63%|██████▎   | 105/166 [14:58<08:44,  8.60s/epoch, loss=0.941, accuracy=0.616, val_loss=0.908, val_accuracy=0.633] 64%|██████▍   | 106/166 [15:06<08:35,  8.60s/epoch, loss=1.07, accuracy=0.603, val_loss=1.42, val_accuracy=0.628]   64%|██████▍   | 107/166 [15:15<08:27,  8.60s/epoch, loss=1.35, accuracy=0.614, val_loss=1.28, val_accuracy=0.625] 65%|██████▌   | 108/166 [15:24<08:19,  8.61s/epoch, loss=1.2, accuracy=0.639, val_loss=1.21, val_accuracy=0.519]  66%|██████▌   | 109/166 [15:32<08:03,  8.49s/epoch, loss=1.09, accuracy=0.646, val_loss=1.05, val_accuracy=0.62] 66%|██████▋   | 110/166 [15:40<07:41,  8.24s/epoch, loss=1.05, accuracy=0.624, val_loss=1.03, val_accuracy=0.623] 67%|██████▋   | 111/166 [15:47<07:22,  8.05s/epoch, loss=0.997, accuracy=0.63, val_loss=1.01, val_accuracy=0.593] 67%|██████▋   | 112/166 [15:55<07:07,  7.92s/epoch, loss=0.945, accuracy=0.629, val_loss=0.952, val_accuracy=0.543] 68%|██████▊   | 113/166 [16:03<06:58,  7.90s/epoch, loss=0.965, accuracy=0.558, val_loss=0.947, val_accuracy=0.598] 69%|██████▊   | 114/166 [16:10<06:48,  7.86s/epoch, loss=0.918, accuracy=0.599, val_loss=0.91, val_accuracy=0.597]  69%|██████▉   | 115/166 [16:18<06:40,  7.86s/epoch, loss=0.921, accuracy=0.558, val_loss=0.967, val_accuracy=0.509] 70%|██████▉   | 116/166 [16:26<06:32,  7.85s/epoch, loss=0.897, accuracy=0.564, val_loss=0.857, val_accuracy=0.607] 70%|███████   | 117/166 [16:34<06:24,  7.84s/epoch, loss=0.853, accuracy=0.609, val_loss=0.839, val_accuracy=0.616] 71%|███████   | 118/166 [16:42<06:15,  7.83s/epoch, loss=0.826, accuracy=0.608, val_loss=0.808, val_accuracy=0.63]  72%|███████▏  | 119/166 [16:50<06:08,  7.83s/epoch, loss=0.85, accuracy=0.603, val_loss=0.83, val_accuracy=0.613]  72%|███████▏  | 120/166 [16:57<05:59,  7.82s/epoch, loss=0.854, accuracy=0.612, val_loss=0.932, val_accuracy=0.607] 73%|███████▎  | 121/166 [17:05<05:51,  7.81s/epoch, loss=0.999, accuracy=0.577, val_loss=1.08, val_accuracy=0.5]    73%|███████▎  | 122/166 [17:13<05:43,  7.82s/epoch, loss=1.07, accuracy=0.544, val_loss=1.03, val_accuracy=0.519] 74%|███████▍  | 123/166 [17:21<05:36,  7.83s/epoch, loss=1, accuracy=0.536, val_loss=0.98, val_accuracy=0.499]    75%|███████▍  | 124/166 [17:29<05:28,  7.82s/epoch, loss=0.984, accuracy=0.531, val_loss=1, val_accuracy=0.501] 75%|███████▌  | 125/166 [17:37<05:21,  7.84s/epoch, loss=0.954, accuracy=0.531, val_loss=0.925, val_accuracy=0.559] 76%|███████▌  | 126/166 [17:44<05:12,  7.82s/epoch, loss=0.942, accuracy=0.535, val_loss=0.921, val_accuracy=0.536] 77%|███████▋  | 127/166 [17:52<05:04,  7.81s/epoch, loss=0.928, accuracy=0.549, val_loss=0.917, val_accuracy=0.528] 77%|███████▋  | 128/166 [18:00<04:56,  7.80s/epoch, loss=0.895, accuracy=0.542, val_loss=0.868, val_accuracy=0.529] 78%|███████▊  | 129/166 [18:08<04:48,  7.80s/epoch, loss=0.857, accuracy=0.557, val_loss=0.822, val_accuracy=0.578] 78%|███████▊  | 130/166 [18:15<04:40,  7.80s/epoch, loss=0.806, accuracy=0.601, val_loss=0.777, val_accuracy=0.64]  79%|███████▉  | 131/166 [18:23<04:33,  7.81s/epoch, loss=0.764, accuracy=0.649, val_loss=0.723, val_accuracy=0.701] 80%|███████▉  | 132/166 [18:31<04:24,  7.79s/epoch, loss=0.771, accuracy=0.673, val_loss=0.796, val_accuracy=0.651] 80%|████████  | 133/166 [18:39<04:16,  7.78s/epoch, loss=0.806, accuracy=0.665, val_loss=0.844, val_accuracy=0.639] 81%|████████  | 134/166 [18:47<04:09,  7.78s/epoch, loss=0.831, accuracy=0.674, val_loss=0.849, val_accuracy=0.705] 81%|████████▏ | 135/166 [18:54<04:01,  7.80s/epoch, loss=0.889, accuracy=0.644, val_loss=0.872, val_accuracy=0.678] 82%|████████▏ | 136/166 [19:02<03:55,  7.84s/epoch, loss=0.919, accuracy=0.635, val_loss=0.971, val_accuracy=0.518] 83%|████████▎ | 137/166 [19:10<03:47,  7.84s/epoch, loss=0.925, accuracy=0.605, val_loss=0.892, val_accuracy=0.631] 83%|████████▎ | 138/166 [19:18<03:39,  7.84s/epoch, loss=0.878, accuracy=0.632, val_loss=0.913, val_accuracy=0.576] 84%|████████▎ | 139/166 [19:26<03:31,  7.84s/epoch, loss=0.857, accuracy=0.632, val_loss=0.878, val_accuracy=0.629] 84%|████████▍ | 140/166 [19:34<03:23,  7.83s/epoch, loss=0.865, accuracy=0.647, val_loss=0.857, val_accuracy=0.649] 85%|████████▍ | 141/166 [19:41<03:15,  7.82s/epoch, loss=0.849, accuracy=0.646, val_loss=0.857, val_accuracy=0.647] 86%|████████▌ | 142/166 [19:49<03:06,  7.79s/epoch, loss=0.855, accuracy=0.63, val_loss=0.848, val_accuracy=0.61]   86%|████████▌ | 143/166 [19:57<02:58,  7.78s/epoch, loss=0.83, accuracy=0.653, val_loss=0.869, val_accuracy=0.62] 87%|████████▋ | 144/166 [20:05<02:50,  7.76s/epoch, loss=0.824, accuracy=0.65, val_loss=0.866, val_accuracy=0.631] 87%|████████▋ | 145/166 [20:12<02:42,  7.74s/epoch, loss=0.806, accuracy=0.662, val_loss=0.817, val_accuracy=0.664] 88%|████████▊ | 146/166 [20:20<02:35,  7.77s/epoch, loss=0.856, accuracy=0.644, val_loss=0.941, val_accuracy=0.601] 89%|████████▊ | 147/166 [20:28<02:27,  7.78s/epoch, loss=0.888, accuracy=0.624, val_loss=0.898, val_accuracy=0.626] 89%|████████▉ | 148/166 [20:36<02:19,  7.76s/epoch, loss=0.857, accuracy=0.65, val_loss=0.964, val_accuracy=0.492]  90%|████████▉ | 149/166 [20:43<02:11,  7.75s/epoch, loss=0.934, accuracy=0.603, val_loss=0.927, val_accuracy=0.615] 90%|█████████ | 150/166 [20:51<02:04,  7.76s/epoch, loss=0.964, accuracy=0.588, val_loss=0.995, val_accuracy=0.583] 91%|█████████ | 151/166 [20:59<01:56,  7.76s/epoch, loss=1.02, accuracy=0.539, val_loss=0.982, val_accuracy=0.525]  92%|█████████▏| 152/166 [21:07<01:48,  7.77s/epoch, loss=0.972, accuracy=0.538, val_loss=1, val_accuracy=0.491]    92%|█████████▏| 153/166 [21:15<01:41,  7.77s/epoch, loss=0.944, accuracy=0.53, val_loss=1.01, val_accuracy=0.492] 93%|█████████▎| 154/166 [21:22<01:33,  7.77s/epoch, loss=0.91, accuracy=0.547, val_loss=0.983, val_accuracy=0.534] 93%|█████████▎| 155/166 [21:30<01:25,  7.79s/epoch, loss=0.844, accuracy=0.591, val_loss=0.816, val_accuracy=0.637] 94%|█████████▍| 156/166 [21:38<01:17,  7.79s/epoch, loss=0.874, accuracy=0.569, val_loss=0.874, val_accuracy=0.579] 95%|█████████▍| 157/166 [21:46<01:10,  7.79s/epoch, loss=0.872, accuracy=0.581, val_loss=0.859, val_accuracy=0.583] 95%|█████████▌| 158/166 [21:53<01:02,  7.76s/epoch, loss=0.841, accuracy=0.587, val_loss=0.808, val_accuracy=0.577] 96%|█████████▌| 159/166 [22:01<00:54,  7.77s/epoch, loss=0.804, accuracy=0.617, val_loss=0.791, val_accuracy=0.642] 96%|█████████▋| 160/166 [22:09<00:46,  7.77s/epoch, loss=0.824, accuracy=0.613, val_loss=0.848, val_accuracy=0.644] 97%|█████████▋| 161/166 [22:17<00:38,  7.77s/epoch, loss=0.853, accuracy=0.609, val_loss=0.943, val_accuracy=0.52]  98%|█████████▊| 162/166 [22:24<00:31,  7.76s/epoch, loss=0.84, accuracy=0.629, val_loss=0.879, val_accuracy=0.619] 98%|█████████▊| 163/166 [22:32<00:23,  7.76s/epoch, loss=0.828, accuracy=0.646, val_loss=0.841, val_accuracy=0.648] 99%|█████████▉| 164/166 [22:40<00:15,  7.76s/epoch, loss=0.894, accuracy=0.632, val_loss=0.924, val_accuracy=0.604] 99%|█████████▉| 165/166 [22:48<00:07,  7.76s/epoch, loss=0.938, accuracy=0.613, val_loss=0.935, val_accuracy=0.6]  100%|██████████| 166/166 [22:56<00:00,  7.76s/epoch, loss=0.954, accuracy=0.576, val_loss=0.916, val_accuracy=0.574]100%|██████████| 166/166 [22:56<00:00,  8.29s/epoch, loss=0.954, accuracy=0.576, val_loss=0.916, val_accuracy=0.574]
Test score: 0.4544243812561035
Test accuracy: 0.8367599844932556


* * * Run SGD for ID = 3_3. * * *


2024-03-01 11:34:26.256852: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-01 11:34:35.602366: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-01 11:34:35.603890: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-01 11:34:35.649006: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:18:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-01 11:34:35.649057: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-01 11:34:35.653589: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-01 11:34:35.653671: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-01 11:34:35.656975: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-01 11:34:35.658160: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-01 11:34:35.661929: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-01 11:34:35.664540: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-01 11:34:35.672033: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-01 11:34:35.672821: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-01 11:34:35.672949: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
<__array_function__ internals>:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray
/home/gkb738/.conda/envs/TF_KERAS_GPU/lib/python3.9/site-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray
  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])
/home/gkb738/.conda/envs/TF_KERAS_GPU/lib/python3.9/site-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray
  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])
2024-03-01 11:34:42.837201: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-01 11:34:42.837797: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-01 11:34:42.838428: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:18:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-01 11:34:42.838465: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-01 11:34:42.838523: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-01 11:34:42.838541: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-01 11:34:42.838560: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-01 11:34:42.838577: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-01 11:34:42.838596: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-01 11:34:42.838614: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-01 11:34:42.838633: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-01 11:34:42.839228: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-01 11:34:42.839277: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-01 11:34:43.483060: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-01 11:34:43.483159: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-01 11:34:43.483191: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-01 11:34:43.485369: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:18:00.0, compute capability: 6.1)
{'id': '03_03', 'seed': 3, 'out_folder': 'results/epoch_budget', 'batch_size': 32, 'epochs': 166, 'validation_split': 0.2, 'checkpointing': True, 'initial_lr': 0.1, 'momentum': 0.98, 'nesterov': True, 'bootstrapping': False, 'map_optimizer': True, 'model': 'CNN-LSTM', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Loading data...
Pad sequences (samples x time)
20000 train sequences
5000 validation sequences
25000 test sequences
x_train shape: (20000, 100)
x_val shape: (5000, 100)
x_test shape: (25000, 100)
Using MAP optimizer with reg_weight:  5e-05
CNN-LSTM
0epoch [00:00, ?epoch/s]  0%|          | 0/166 [00:00<?, ?epoch/s]2024-03-01 11:34:44.069721: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-01 11:34:44.082956: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2100000000 Hz
2024-03-01 11:34:45.727247: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-01 11:34:45.940465: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-01 11:34:46.813946: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-01 11:34:46.877451: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/166 [00:14<40:43, 14.81s/epoch, loss=0.64, accuracy=0.665, val_loss=0.473, val_accuracy=0.819]  1%|          | 2/166 [00:23<30:06, 11.02s/epoch, loss=0.453, accuracy=0.836, val_loss=0.472, val_accuracy=0.833]  2%|▏         | 3/166 [00:31<26:16,  9.67s/epoch, loss=0.408, accuracy=0.87, val_loss=0.486, val_accuracy=0.841]   2%|▏         | 4/166 [00:39<24:14,  8.98s/epoch, loss=0.393, accuracy=0.889, val_loss=0.531, val_accuracy=0.841]  3%|▎         | 5/166 [00:47<23:10,  8.64s/epoch, loss=0.406, accuracy=0.9, val_loss=0.608, val_accuracy=0.844]    4%|▎         | 6/166 [00:55<22:19,  8.37s/epoch, loss=0.545, accuracy=0.857, val_loss=0.86, val_accuracy=0.699]  4%|▍         | 7/166 [01:02<21:45,  8.21s/epoch, loss=0.977, accuracy=0.673, val_loss=1.13, val_accuracy=0.583]  5%|▍         | 8/166 [01:10<21:16,  8.08s/epoch, loss=1.08, accuracy=0.6, val_loss=1.1, val_accuracy=0.542]      5%|▌         | 9/166 [01:18<20:58,  8.02s/epoch, loss=1.03, accuracy=0.615, val_loss=1.03, val_accuracy=0.623]  6%|▌         | 10/166 [01:26<20:41,  7.96s/epoch, loss=1.04, accuracy=0.578, val_loss=0.983, val_accuracy=0.619]  7%|▋         | 11/166 [01:34<20:30,  7.94s/epoch, loss=0.994, accuracy=0.606, val_loss=0.999, val_accuracy=0.51]  7%|▋         | 12/166 [01:42<20:20,  7.92s/epoch, loss=0.982, accuracy=0.584, val_loss=1.03, val_accuracy=0.493]  8%|▊         | 13/166 [01:50<20:11,  7.92s/epoch, loss=0.93, accuracy=0.627, val_loss=0.961, val_accuracy=0.621]  8%|▊         | 14/166 [01:57<20:02,  7.91s/epoch, loss=0.965, accuracy=0.587, val_loss=0.973, val_accuracy=0.546]  9%|▉         | 15/166 [02:05<19:53,  7.90s/epoch, loss=0.973, accuracy=0.544, val_loss=0.954, val_accuracy=0.572] 10%|▉         | 16/166 [02:13<19:47,  7.92s/epoch, loss=0.944, accuracy=0.552, val_loss=0.973, val_accuracy=0.586] 10%|█         | 17/166 [02:21<19:39,  7.92s/epoch, loss=0.907, accuracy=0.567, val_loss=0.894, val_accuracy=0.559] 11%|█         | 18/166 [02:29<19:27,  7.89s/epoch, loss=0.889, accuracy=0.593, val_loss=0.883, val_accuracy=0.596] 11%|█▏        | 19/166 [02:37<19:17,  7.88s/epoch, loss=0.88, accuracy=0.584, val_loss=0.863, val_accuracy=0.601]  12%|█▏        | 20/166 [02:45<19:09,  7.87s/epoch, loss=0.871, accuracy=0.6, val_loss=0.83, val_accuracy=0.626]   13%|█▎        | 21/166 [02:53<19:02,  7.88s/epoch, loss=0.842, accuracy=0.614, val_loss=0.873, val_accuracy=0.623] 13%|█▎        | 22/166 [03:01<18:56,  7.89s/epoch, loss=0.851, accuracy=0.601, val_loss=0.812, val_accuracy=0.647] 14%|█▍        | 23/166 [03:09<18:50,  7.90s/epoch, loss=0.844, accuracy=0.642, val_loss=0.907, val_accuracy=0.594] 14%|█▍        | 24/166 [03:16<18:39,  7.88s/epoch, loss=0.857, accuracy=0.614, val_loss=0.865, val_accuracy=0.629] 15%|█▌        | 25/166 [03:24<18:32,  7.89s/epoch, loss=0.854, accuracy=0.626, val_loss=0.827, val_accuracy=0.638] 16%|█▌        | 26/166 [03:32<18:26,  7.90s/epoch, loss=0.828, accuracy=0.641, val_loss=0.848, val_accuracy=0.603] 16%|█▋        | 27/166 [03:40<18:20,  7.92s/epoch, loss=0.842, accuracy=0.619, val_loss=0.872, val_accuracy=0.604] 17%|█▋        | 28/166 [03:48<18:12,  7.92s/epoch, loss=0.835, accuracy=0.663, val_loss=0.841, val_accuracy=0.684] 17%|█▋        | 29/166 [03:56<18:01,  7.89s/epoch, loss=0.856, accuracy=0.653, val_loss=0.879, val_accuracy=0.632] 18%|█▊        | 30/166 [04:04<17:56,  7.92s/epoch, loss=0.844, accuracy=0.67, val_loss=0.872, val_accuracy=0.62]   19%|█▊        | 31/166 [04:12<17:48,  7.92s/epoch, loss=0.9, accuracy=0.637, val_loss=0.909, val_accuracy=0.636] 19%|█▉        | 32/166 [04:20<17:38,  7.90s/epoch, loss=0.894, accuracy=0.651, val_loss=0.922, val_accuracy=0.593] 20%|█▉        | 33/166 [04:28<17:29,  7.89s/epoch, loss=0.861, accuracy=0.66, val_loss=0.895, val_accuracy=0.61]   20%|██        | 34/166 [04:35<17:17,  7.86s/epoch, loss=0.866, accuracy=0.653, val_loss=0.881, val_accuracy=0.642] 21%|██        | 35/166 [04:43<17:10,  7.86s/epoch, loss=0.891, accuracy=0.647, val_loss=0.987, val_accuracy=0.578] 22%|██▏       | 36/166 [04:51<17:03,  7.87s/epoch, loss=0.961, accuracy=0.617, val_loss=0.94, val_accuracy=0.614]  22%|██▏       | 37/166 [04:59<16:56,  7.88s/epoch, loss=0.919, accuracy=0.631, val_loss=0.91, val_accuracy=0.631] 23%|██▎       | 38/166 [05:07<16:50,  7.89s/epoch, loss=0.884, accuracy=0.637, val_loss=0.888, val_accuracy=0.612] 23%|██▎       | 39/166 [05:15<16:38,  7.86s/epoch, loss=0.905, accuracy=0.625, val_loss=0.948, val_accuracy=0.603] 24%|██▍       | 40/166 [05:23<16:29,  7.86s/epoch, loss=0.895, accuracy=0.621, val_loss=0.868, val_accuracy=0.639] 25%|██▍       | 41/166 [05:30<16:23,  7.86s/epoch, loss=0.856, accuracy=0.649, val_loss=0.857, val_accuracy=0.636] 25%|██▌       | 42/166 [05:38<16:15,  7.87s/epoch, loss=0.86, accuracy=0.658, val_loss=0.887, val_accuracy=0.633]  26%|██▌       | 43/166 [05:46<16:05,  7.85s/epoch, loss=0.866, accuracy=0.672, val_loss=0.907, val_accuracy=0.634] 27%|██▋       | 44/166 [05:54<15:57,  7.85s/epoch, loss=0.894, accuracy=0.643, val_loss=0.943, val_accuracy=0.625] 27%|██▋       | 45/166 [06:02<15:53,  7.88s/epoch, loss=0.926, accuracy=0.605, val_loss=0.927, val_accuracy=0.614] 28%|██▊       | 46/166 [06:10<15:46,  7.89s/epoch, loss=0.914, accuracy=0.623, val_loss=0.928, val_accuracy=0.517] 28%|██▊       | 47/166 [06:18<15:39,  7.90s/epoch, loss=0.927, accuracy=0.618, val_loss=0.926, val_accuracy=0.632] 29%|██▉       | 48/166 [06:26<15:33,  7.92s/epoch, loss=1.1, accuracy=0.628, val_loss=1.7, val_accuracy=0.634]     30%|██▉       | 49/166 [06:34<15:25,  7.91s/epoch, loss=1.63, accuracy=0.615, val_loss=1.55, val_accuracy=0.507] 30%|███       | 50/166 [06:42<15:19,  7.93s/epoch, loss=1.39, accuracy=0.638, val_loss=1.34, val_accuracy=0.656] 31%|███       | 51/166 [06:50<15:12,  7.94s/epoch, loss=1.28, accuracy=0.645, val_loss=1.23, val_accuracy=0.638] 31%|███▏      | 52/166 [06:57<15:01,  7.91s/epoch, loss=1.21, accuracy=0.618, val_loss=1.2, val_accuracy=0.593]  32%|███▏      | 53/166 [07:05<14:55,  7.92s/epoch, loss=1.15, accuracy=0.6, val_loss=1.1, val_accuracy=0.551]   33%|███▎      | 54/166 [07:13<14:46,  7.92s/epoch, loss=1.04, accuracy=0.608, val_loss=1.03, val_accuracy=0.608] 33%|███▎      | 55/166 [07:21<14:36,  7.90s/epoch, loss=1.01, accuracy=0.614, val_loss=1.05, val_accuracy=0.585] 34%|███▎      | 56/166 [07:29<14:31,  7.92s/epoch, loss=0.973, accuracy=0.602, val_loss=0.919, val_accuracy=0.638] 34%|███▍      | 57/166 [07:37<14:22,  7.91s/epoch, loss=0.915, accuracy=0.629, val_loss=0.939, val_accuracy=0.508] 35%|███▍      | 58/166 [07:45<14:15,  7.92s/epoch, loss=0.912, accuracy=0.61, val_loss=0.891, val_accuracy=0.618]  36%|███▌      | 59/166 [07:53<14:06,  7.91s/epoch, loss=0.873, accuracy=0.644, val_loss=0.883, val_accuracy=0.625] 36%|███▌      | 60/166 [08:01<13:59,  7.92s/epoch, loss=0.905, accuracy=0.64, val_loss=0.901, val_accuracy=0.623]  37%|███▋      | 61/166 [08:09<13:52,  7.93s/epoch, loss=0.895, accuracy=0.627, val_loss=0.914, val_accuracy=0.623] 37%|███▋      | 62/166 [08:16<13:41,  7.90s/epoch, loss=0.976, accuracy=0.575, val_loss=1, val_accuracy=0.515]     38%|███▊      | 63/166 [08:24<13:35,  7.91s/epoch, loss=0.993, accuracy=0.547, val_loss=0.941, val_accuracy=0.606] 39%|███▊      | 64/166 [08:32<13:27,  7.92s/epoch, loss=0.95, accuracy=0.567, val_loss=0.922, val_accuracy=0.594]  39%|███▉      | 65/166 [08:40<13:18,  7.91s/epoch, loss=0.922, accuracy=0.584, val_loss=0.924, val_accuracy=0.561] 40%|███▉      | 66/166 [08:48<13:09,  7.90s/epoch, loss=0.925, accuracy=0.546, val_loss=0.88, val_accuracy=0.524]  40%|████      | 67/166 [08:56<13:00,  7.89s/epoch, loss=0.905, accuracy=0.558, val_loss=1.01, val_accuracy=0.511] 41%|████      | 68/166 [09:04<12:51,  7.87s/epoch, loss=0.928, accuracy=0.527, val_loss=0.876, val_accuracy=0.566] 42%|████▏     | 69/166 [09:12<12:43,  7.87s/epoch, loss=0.875, accuracy=0.575, val_loss=0.842, val_accuracy=0.57]  42%|████▏     | 70/166 [09:20<12:35,  7.87s/epoch, loss=0.86, accuracy=0.59, val_loss=0.89, val_accuracy=0.585]   43%|████▎     | 71/166 [09:28<12:29,  7.89s/epoch, loss=0.848, accuracy=0.613, val_loss=0.902, val_accuracy=0.626] 43%|████▎     | 72/166 [09:35<12:24,  7.92s/epoch, loss=0.899, accuracy=0.63, val_loss=0.921, val_accuracy=0.594]  44%|████▍     | 73/166 [09:43<12:18,  7.94s/epoch, loss=0.912, accuracy=0.611, val_loss=0.914, val_accuracy=0.554] 45%|████▍     | 74/166 [09:51<12:10,  7.94s/epoch, loss=0.907, accuracy=0.598, val_loss=0.89, val_accuracy=0.62]   45%|████▌     | 75/166 [09:59<12:01,  7.93s/epoch, loss=0.893, accuracy=0.607, val_loss=0.923, val_accuracy=0.598] 46%|████▌     | 76/166 [10:07<11:53,  7.93s/epoch, loss=0.876, accuracy=0.63, val_loss=0.884, val_accuracy=0.632]  46%|████▋     | 77/166 [10:15<11:43,  7.90s/epoch, loss=0.918, accuracy=0.595, val_loss=0.93, val_accuracy=0.611] 47%|████▋     | 78/166 [10:23<11:35,  7.91s/epoch, loss=0.917, accuracy=0.581, val_loss=0.961, val_accuracy=0.507] 48%|████▊     | 79/166 [10:31<11:28,  7.92s/epoch, loss=0.912, accuracy=0.569, val_loss=0.862, val_accuracy=0.605] 48%|████▊     | 80/166 [10:39<11:20,  7.91s/epoch, loss=0.859, accuracy=0.606, val_loss=0.836, val_accuracy=0.609] 49%|████▉     | 81/166 [10:47<11:11,  7.90s/epoch, loss=0.845, accuracy=0.609, val_loss=0.86, val_accuracy=0.496]  49%|████▉     | 82/166 [10:55<11:03,  7.90s/epoch, loss=0.845, accuracy=0.615, val_loss=0.856, val_accuracy=0.637] 50%|█████     | 83/166 [11:02<10:53,  7.88s/epoch, loss=0.852, accuracy=0.62, val_loss=0.959, val_accuracy=0.524]  51%|█████     | 84/166 [11:10<10:46,  7.88s/epoch, loss=0.86, accuracy=0.641, val_loss=0.883, val_accuracy=0.627] 51%|█████     | 85/166 [11:18<10:37,  7.86s/epoch, loss=0.901, accuracy=0.622, val_loss=0.912, val_accuracy=0.618] 52%|█████▏    | 86/166 [11:26<10:28,  7.85s/epoch, loss=0.907, accuracy=0.613, val_loss=0.924, val_accuracy=0.543] 52%|█████▏    | 87/166 [11:34<10:22,  7.88s/epoch, loss=0.908, accuracy=0.621, val_loss=0.915, val_accuracy=0.624] 53%|█████▎    | 88/166 [11:42<10:14,  7.88s/epoch, loss=0.937, accuracy=0.589, val_loss=0.985, val_accuracy=0.579] 54%|█████▎    | 89/166 [11:50<10:06,  7.88s/epoch, loss=0.935, accuracy=0.573, val_loss=0.997, val_accuracy=0.507] 54%|█████▍    | 90/166 [11:57<09:54,  7.83s/epoch, loss=0.92, accuracy=0.557, val_loss=1.18, val_accuracy=0.498]   55%|█████▍    | 91/166 [12:05<09:43,  7.79s/epoch, loss=0.92, accuracy=0.549, val_loss=0.979, val_accuracy=0.551] 55%|█████▌    | 92/166 [12:13<09:37,  7.80s/epoch, loss=0.985, accuracy=0.57, val_loss=0.948, val_accuracy=0.588] 56%|█████▌    | 93/166 [12:21<09:44,  8.01s/epoch, loss=0.945, accuracy=0.584, val_loss=0.917, val_accuracy=0.6]  57%|█████▋    | 94/166 [12:30<09:45,  8.13s/epoch, loss=0.895, accuracy=0.599, val_loss=0.858, val_accuracy=0.634] 57%|█████▋    | 95/166 [12:38<09:42,  8.20s/epoch, loss=0.861, accuracy=0.624, val_loss=0.877, val_accuracy=0.587] 58%|█████▊    | 96/166 [12:47<09:41,  8.31s/epoch, loss=0.828, accuracy=0.648, val_loss=0.926, val_accuracy=0.566] 58%|█████▊    | 97/166 [12:55<09:39,  8.40s/epoch, loss=0.818, accuracy=0.666, val_loss=0.83, val_accuracy=0.676]  59%|█████▉    | 98/166 [13:04<09:34,  8.46s/epoch, loss=0.858, accuracy=0.645, val_loss=0.873, val_accuracy=0.617] 60%|█████▉    | 99/166 [13:13<09:29,  8.51s/epoch, loss=0.854, accuracy=0.638, val_loss=0.865, val_accuracy=0.629] 60%|██████    | 100/166 [13:21<09:22,  8.53s/epoch, loss=0.883, accuracy=0.636, val_loss=0.926, val_accuracy=0.613] 61%|██████    | 101/166 [13:30<09:12,  8.51s/epoch, loss=0.893, accuracy=0.63, val_loss=0.919, val_accuracy=0.625]  61%|██████▏   | 102/166 [13:38<09:03,  8.49s/epoch, loss=0.938, accuracy=0.598, val_loss=0.929, val_accuracy=0.602] 62%|██████▏   | 103/166 [13:46<08:53,  8.47s/epoch, loss=0.916, accuracy=0.593, val_loss=0.902, val_accuracy=0.61]  63%|██████▎   | 104/166 [13:55<08:45,  8.47s/epoch, loss=0.898, accuracy=0.611, val_loss=0.886, val_accuracy=0.619] 63%|██████▎   | 105/166 [14:04<08:38,  8.51s/epoch, loss=0.879, accuracy=0.601, val_loss=0.853, val_accuracy=0.608] 64%|██████▍   | 106/166 [14:12<08:32,  8.54s/epoch, loss=0.855, accuracy=0.621, val_loss=0.837, val_accuracy=0.658] 64%|██████▍   | 107/166 [14:21<08:26,  8.59s/epoch, loss=0.845, accuracy=0.634, val_loss=0.879, val_accuracy=0.558] 65%|██████▌   | 108/166 [14:30<08:19,  8.62s/epoch, loss=0.892, accuracy=0.62, val_loss=0.938, val_accuracy=0.494]  66%|██████▌   | 109/166 [14:38<08:11,  8.62s/epoch, loss=0.938, accuracy=0.571, val_loss=0.929, val_accuracy=0.564] 66%|██████▋   | 110/166 [14:47<08:00,  8.59s/epoch, loss=0.929, accuracy=0.561, val_loss=0.929, val_accuracy=0.507] 67%|██████▋   | 111/166 [14:55<07:49,  8.53s/epoch, loss=0.898, accuracy=0.54, val_loss=0.862, val_accuracy=0.6]    67%|██████▋   | 112/166 [15:04<07:39,  8.51s/epoch, loss=0.874, accuracy=0.578, val_loss=0.968, val_accuracy=0.616] 68%|██████▊   | 113/166 [15:12<07:30,  8.50s/epoch, loss=0.969, accuracy=0.613, val_loss=0.929, val_accuracy=0.612] 69%|██████▊   | 114/166 [15:21<07:23,  8.52s/epoch, loss=0.913, accuracy=0.641, val_loss=0.892, val_accuracy=0.645] 69%|██████▉   | 115/166 [15:29<07:14,  8.52s/epoch, loss=0.915, accuracy=0.623, val_loss=0.991, val_accuracy=0.545] 70%|██████▉   | 116/166 [15:38<07:06,  8.54s/epoch, loss=0.916, accuracy=0.608, val_loss=0.898, val_accuracy=0.617] 70%|███████   | 117/166 [15:46<07:00,  8.59s/epoch, loss=0.879, accuracy=0.624, val_loss=0.946, val_accuracy=0.538] 71%|███████   | 118/166 [15:55<06:53,  8.61s/epoch, loss=0.884, accuracy=0.616, val_loss=0.921, val_accuracy=0.574] 72%|███████▏  | 119/166 [16:04<06:42,  8.56s/epoch, loss=0.901, accuracy=0.585, val_loss=0.932, val_accuracy=0.598] 72%|███████▏  | 120/166 [16:12<06:33,  8.54s/epoch, loss=0.902, accuracy=0.576, val_loss=0.913, val_accuracy=0.588] 73%|███████▎  | 121/166 [16:21<06:23,  8.52s/epoch, loss=1.04, accuracy=0.594, val_loss=1.17, val_accuracy=0.509]   73%|███████▎  | 122/166 [16:29<06:12,  8.47s/epoch, loss=1.09, accuracy=0.598, val_loss=1.05, val_accuracy=0.6]   74%|███████▍  | 123/166 [16:37<06:03,  8.45s/epoch, loss=1.05, accuracy=0.573, val_loss=1.03, val_accuracy=0.583] 75%|███████▍  | 124/166 [16:46<05:54,  8.44s/epoch, loss=0.973, accuracy=0.599, val_loss=0.94, val_accuracy=0.611] 75%|███████▌  | 125/166 [16:54<05:45,  8.43s/epoch, loss=0.928, accuracy=0.61, val_loss=0.916, val_accuracy=0.612] 76%|███████▌  | 126/166 [17:03<05:37,  8.45s/epoch, loss=0.871, accuracy=0.636, val_loss=0.896, val_accuracy=0.588] 77%|███████▋  | 127/166 [17:11<05:29,  8.45s/epoch, loss=0.863, accuracy=0.623, val_loss=0.869, val_accuracy=0.604] 77%|███████▋  | 128/166 [17:20<05:22,  8.48s/epoch, loss=0.844, accuracy=0.636, val_loss=0.834, val_accuracy=0.66]  78%|███████▊  | 129/166 [17:28<05:13,  8.48s/epoch, loss=0.888, accuracy=0.618, val_loss=0.901, val_accuracy=0.592] 78%|███████▊  | 130/166 [17:36<05:04,  8.46s/epoch, loss=0.875, accuracy=0.625, val_loss=0.874, val_accuracy=0.639] 79%|███████▉  | 131/166 [17:45<04:55,  8.44s/epoch, loss=0.886, accuracy=0.626, val_loss=0.92, val_accuracy=0.612]  80%|███████▉  | 132/166 [17:53<04:47,  8.46s/epoch, loss=0.907, accuracy=0.63, val_loss=0.922, val_accuracy=0.62]  80%|████████  | 133/166 [18:02<04:39,  8.46s/epoch, loss=0.931, accuracy=0.613, val_loss=0.994, val_accuracy=0.553] 81%|████████  | 134/166 [18:10<04:30,  8.46s/epoch, loss=0.914, accuracy=0.606, val_loss=0.894, val_accuracy=0.638] 81%|████████▏ | 135/166 [18:19<04:22,  8.47s/epoch, loss=0.897, accuracy=0.601, val_loss=0.877, val_accuracy=0.607] 82%|████████▏ | 136/166 [18:27<04:14,  8.49s/epoch, loss=0.857, accuracy=0.62, val_loss=0.833, val_accuracy=0.636]  83%|████████▎ | 137/166 [18:36<04:07,  8.53s/epoch, loss=0.888, accuracy=0.623, val_loss=0.861, val_accuracy=0.676] 83%|████████▎ | 138/166 [18:44<03:58,  8.52s/epoch, loss=0.917, accuracy=0.623, val_loss=0.889, val_accuracy=0.64]  84%|████████▎ | 139/166 [18:53<03:50,  8.52s/epoch, loss=0.896, accuracy=0.639, val_loss=0.928, val_accuracy=0.563] 84%|████████▍ | 140/166 [19:01<03:41,  8.52s/epoch, loss=0.91, accuracy=0.601, val_loss=1.01, val_accuracy=0.507]   85%|████████▍ | 141/166 [19:10<03:32,  8.49s/epoch, loss=1.01, accuracy=0.57, val_loss=1.04, val_accuracy=0.626]  86%|████████▌ | 142/166 [19:18<03:23,  8.47s/epoch, loss=1.01, accuracy=0.614, val_loss=0.96, val_accuracy=0.584] 86%|████████▌ | 143/166 [19:27<03:14,  8.46s/epoch, loss=0.933, accuracy=0.642, val_loss=0.902, val_accuracy=0.662] 87%|████████▋ | 144/166 [19:35<03:05,  8.45s/epoch, loss=0.909, accuracy=0.644, val_loss=0.901, val_accuracy=0.668] 87%|████████▋ | 145/166 [19:44<02:58,  8.52s/epoch, loss=0.924, accuracy=0.627, val_loss=0.909, val_accuracy=0.649] 88%|████████▊ | 146/166 [19:52<02:50,  8.52s/epoch, loss=0.937, accuracy=0.605, val_loss=0.957, val_accuracy=0.591] 89%|████████▊ | 147/166 [20:01<02:41,  8.52s/epoch, loss=0.937, accuracy=0.588, val_loss=0.906, val_accuracy=0.616] 89%|████████▉ | 148/166 [20:09<02:33,  8.52s/epoch, loss=0.904, accuracy=0.607, val_loss=0.882, val_accuracy=0.61]  90%|████████▉ | 149/166 [20:18<02:24,  8.50s/epoch, loss=0.882, accuracy=0.615, val_loss=0.91, val_accuracy=0.625] 90%|█████████ | 150/166 [20:26<02:16,  8.50s/epoch, loss=0.845, accuracy=0.647, val_loss=0.848, val_accuracy=0.659] 91%|█████████ | 151/166 [20:35<02:06,  8.46s/epoch, loss=0.898, accuracy=0.611, val_loss=0.915, val_accuracy=0.612] 92%|█████████▏| 152/166 [20:43<01:58,  8.47s/epoch, loss=0.934, accuracy=0.596, val_loss=0.954, val_accuracy=0.54]  92%|█████████▏| 153/166 [20:52<01:50,  8.51s/epoch, loss=1.18, accuracy=0.593, val_loss=1.31, val_accuracy=0.619]  93%|█████████▎| 154/166 [21:00<01:42,  8.54s/epoch, loss=1.26, accuracy=0.577, val_loss=1.21, val_accuracy=0.557] 93%|█████████▎| 155/166 [21:09<01:34,  8.57s/epoch, loss=1.16, accuracy=0.575, val_loss=1.1, val_accuracy=0.594]  94%|█████████▍| 156/166 [21:18<01:25,  8.54s/epoch, loss=1.07, accuracy=0.581, val_loss=0.992, val_accuracy=0.628] 95%|█████████▍| 157/166 [21:26<01:16,  8.50s/epoch, loss=0.973, accuracy=0.617, val_loss=0.98, val_accuracy=0.527] 95%|█████████▌| 158/166 [21:34<01:07,  8.46s/epoch, loss=0.945, accuracy=0.611, val_loss=0.952, val_accuracy=0.623] 96%|█████████▌| 159/166 [21:43<00:59,  8.46s/epoch, loss=1.11, accuracy=0.622, val_loss=1.44, val_accuracy=0.614]   96%|█████████▋| 160/166 [21:51<00:50,  8.48s/epoch, loss=1.34, accuracy=0.632, val_loss=1.27, val_accuracy=0.644] 97%|█████████▋| 161/166 [22:00<00:42,  8.47s/epoch, loss=1.25, accuracy=0.598, val_loss=1.18, val_accuracy=0.628] 98%|█████████▊| 162/166 [22:08<00:33,  8.47s/epoch, loss=1.15, accuracy=0.599, val_loss=1.11, val_accuracy=0.59]  98%|█████████▊| 163/166 [22:17<00:25,  8.52s/epoch, loss=1.07, accuracy=0.59, val_loss=1.17, val_accuracy=0.519] 99%|█████████▉| 164/166 [22:25<00:17,  8.53s/epoch, loss=0.999, accuracy=0.623, val_loss=0.986, val_accuracy=0.603] 99%|█████████▉| 165/166 [22:34<00:08,  8.51s/epoch, loss=0.999, accuracy=0.589, val_loss=0.979, val_accuracy=0.566]100%|██████████| 166/166 [22:42<00:00,  8.52s/epoch, loss=0.943, accuracy=0.616, val_loss=0.935, val_accuracy=0.623]100%|██████████| 166/166 [22:42<00:00,  8.21s/epoch, loss=0.943, accuracy=0.616, val_loss=0.935, val_accuracy=0.623]
Test score: 0.5978286862373352
Test accuracy: 0.8412799835205078
