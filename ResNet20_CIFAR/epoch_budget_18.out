Mon Feb 19 23:02:17 2024       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 545.23.08              Driver Version: 545.23.08    CUDA Version: 12.3     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA TITAN X (Pascal)        Off | 00000000:03:00.0 Off |                  N/A |
| 50%   79C    P0              93W / 250W |      0MiB / 12288MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|  No running processes found                                                           |
+---------------------------------------------------------------------------------------+


* * * Run SGD for cluster size = 18. * * *


Budget: 83


* * * Run SGD for ID = 18_1. * * *


2024-02-19 23:02:17.671617: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-19 23:02:20.745076: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-19 23:02:20.745965: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-19 23:02:20.782442: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-19 23:02:20.782475: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-19 23:02:20.785440: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-19 23:02:20.785478: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-19 23:02:20.787584: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-19 23:02:20.788879: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-19 23:02:20.791088: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-19 23:02:20.792513: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-19 23:02:20.796923: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-19 23:02:20.797422: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-19 23:02:20.797496: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-19 23:02:22.224753: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-19 23:02:22.226335: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-19 23:02:22.227093: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-19 23:02:22.227129: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-19 23:02:22.227163: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-19 23:02:22.227178: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-19 23:02:22.227194: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-19 23:02:22.227209: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-19 23:02:22.227224: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-19 23:02:22.227237: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-19 23:02:22.227251: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-19 23:02:22.227669: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-19 23:02:22.227699: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-19 23:02:22.833266: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-19 23:02:22.833316: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-19 23:02:22.833324: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-19 23:02:22.834157: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:03:00.0, compute capability: 6.1)
{'id': '18_01', 'batch_size': 128, 'epochs': 83, 'validation_split': 0.1, 'checkpointing': True, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
x_train shape: (45000, 32, 32, 3)
45000 train samples
5000 validation samples
10000 test samples
y_train shape: (45000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/83 [00:00<?, ?epoch/s]2024-02-19 23:02:23.610725: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-19 23:02:23.623085: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600020000 Hz
2024-02-19 23:02:25.456582: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-19 23:02:25.644086: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-19 23:02:26.332259: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-19 23:02:26.361399: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/83 [00:44<1:00:18, 44.13s/epoch, loss=3.29, accuracy=0.303, val_loss=2.25, val_accuracy=0.289, lr=0.1]  2%|▏         | 2/83 [01:01<37:58, 28.12s/epoch, loss=1.65, accuracy=0.494, val_loss=2.18, val_accuracy=0.385, lr=0.1]    4%|▎         | 3/83 [01:18<30:45, 23.07s/epoch, loss=1.4, accuracy=0.611, val_loss=1.77, val_accuracy=0.514, lr=0.1]   5%|▍         | 4/83 [01:35<27:16, 20.71s/epoch, loss=1.31, accuracy=0.665, val_loss=1.64, val_accuracy=0.572, lr=0.1]  6%|▌         | 5/83 [01:52<25:16, 19.44s/epoch, loss=1.26, accuracy=0.695, val_loss=1.58, val_accuracy=0.601, lr=0.1]  7%|▋         | 6/83 [02:09<23:46, 18.53s/epoch, loss=1.24, accuracy=0.706, val_loss=1.89, val_accuracy=0.478, lr=0.1]  8%|▊         | 7/83 [02:25<22:40, 17.91s/epoch, loss=1.22, accuracy=0.717, val_loss=2.41, val_accuracy=0.411, lr=0.1] 10%|▉         | 8/83 [02:42<21:59, 17.59s/epoch, loss=1.22, accuracy=0.718, val_loss=1.96, val_accuracy=0.515, lr=0.1] 11%|█         | 9/83 [02:59<21:27, 17.40s/epoch, loss=1.21, accuracy=0.725, val_loss=1.86, val_accuracy=0.479, lr=0.1] 12%|█▏        | 10/83 [03:16<20:53, 17.17s/epoch, loss=1.2, accuracy=0.731, val_loss=1.81, val_accuracy=0.564, lr=0.0316] 13%|█▎        | 11/83 [03:33<20:29, 17.07s/epoch, loss=1.19, accuracy=0.728, val_loss=1.95, val_accuracy=0.486, lr=0.1]   14%|█▍        | 12/83 [03:49<20:01, 16.92s/epoch, loss=1.2, accuracy=0.732, val_loss=2.01, val_accuracy=0.496, lr=0.1]  16%|█▌        | 13/83 [04:06<19:44, 16.92s/epoch, loss=1.18, accuracy=0.741, val_loss=2.33, val_accuracy=0.421, lr=0.1] 17%|█▋        | 14/83 [04:23<19:27, 16.92s/epoch, loss=1.18, accuracy=0.74, val_loss=2.46, val_accuracy=0.424, lr=0.1]  18%|█▊        | 15/83 [04:40<19:11, 16.94s/epoch, loss=1.17, accuracy=0.739, val_loss=1.91, val_accuracy=0.518, lr=0.0316] 19%|█▉        | 16/83 [04:57<18:53, 16.91s/epoch, loss=1.18, accuracy=0.738, val_loss=1.45, val_accuracy=0.666, lr=0.1]    20%|██        | 17/83 [05:15<18:50, 17.13s/epoch, loss=1.16, accuracy=0.745, val_loss=2.67, val_accuracy=0.449, lr=0.1] 22%|██▏       | 18/83 [05:31<18:25, 17.00s/epoch, loss=1.17, accuracy=0.742, val_loss=1.65, val_accuracy=0.579, lr=0.1] 23%|██▎       | 19/83 [05:48<18:06, 16.97s/epoch, loss=1.17, accuracy=0.742, val_loss=2.87, val_accuracy=0.4, lr=0.1]   24%|██▍       | 20/83 [06:05<17:53, 17.04s/epoch, loss=1.16, accuracy=0.744, val_loss=2.92, val_accuracy=0.378, lr=0.1] 25%|██▌       | 21/83 [06:22<17:31, 16.96s/epoch, loss=1.16, accuracy=0.746, val_loss=2.11, val_accuracy=0.477, lr=0.0316] 27%|██▋       | 22/83 [06:39<17:17, 17.01s/epoch, loss=1.15, accuracy=0.748, val_loss=3.46, val_accuracy=0.401, lr=0.1]    28%|██▊       | 23/83 [06:56<16:58, 16.98s/epoch, loss=1.16, accuracy=0.744, val_loss=1.65, val_accuracy=0.6, lr=0.1]   29%|██▉       | 24/83 [07:13<16:44, 17.03s/epoch, loss=1.16, accuracy=0.747, val_loss=1.87, val_accuracy=0.514, lr=0.1] 30%|███       | 25/83 [07:32<16:47, 17.38s/epoch, loss=1.16, accuracy=0.748, val_loss=3.52, val_accuracy=0.317, lr=0.1] 31%|███▏      | 26/83 [07:48<16:21, 17.22s/epoch, loss=1.15, accuracy=0.751, val_loss=1.88, val_accuracy=0.539, lr=0.0316] 33%|███▎      | 27/83 [08:05<15:58, 17.12s/epoch, loss=1.16, accuracy=0.744, val_loss=2.22, val_accuracy=0.455, lr=0.1]    34%|███▎      | 28/83 [08:23<15:45, 17.19s/epoch, loss=1.16, accuracy=0.747, val_loss=1.7, val_accuracy=0.595, lr=0.1]  35%|███▍      | 29/83 [08:39<15:21, 17.07s/epoch, loss=1.15, accuracy=0.75, val_loss=3.95, val_accuracy=0.341, lr=0.1] 36%|███▌      | 30/83 [08:56<15:01, 17.01s/epoch, loss=1.15, accuracy=0.749, val_loss=2.45, val_accuracy=0.447, lr=0.1] 37%|███▋      | 31/83 [09:13<14:44, 17.01s/epoch, loss=1.15, accuracy=0.751, val_loss=1.55, val_accuracy=0.614, lr=0.0316] 39%|███▊      | 32/83 [09:31<14:31, 17.09s/epoch, loss=1.15, accuracy=0.75, val_loss=4.77, val_accuracy=0.215, lr=0.1]     40%|███▉      | 33/83 [09:48<14:16, 17.13s/epoch, loss=1.15, accuracy=0.751, val_loss=1.74, val_accuracy=0.55, lr=0.1] 41%|████      | 34/83 [10:05<13:55, 17.05s/epoch, loss=1.14, accuracy=0.753, val_loss=2.95, val_accuracy=0.433, lr=0.1] 42%|████▏     | 35/83 [10:21<13:33, 16.95s/epoch, loss=1.14, accuracy=0.752, val_loss=1.92, val_accuracy=0.516, lr=0.1] 43%|████▎     | 36/83 [10:38<13:12, 16.86s/epoch, loss=1.14, accuracy=0.755, val_loss=1.87, val_accuracy=0.502, lr=0.0316] 45%|████▍     | 37/83 [10:55<12:58, 16.92s/epoch, loss=1.14, accuracy=0.751, val_loss=2.45, val_accuracy=0.464, lr=0.1]    46%|████▌     | 38/83 [11:13<12:50, 17.12s/epoch, loss=1.14, accuracy=0.757, val_loss=1.83, val_accuracy=0.55, lr=0.1]  47%|████▋     | 39/83 [11:29<12:29, 17.04s/epoch, loss=1.15, accuracy=0.753, val_loss=1.72, val_accuracy=0.564, lr=0.1] 48%|████▊     | 40/83 [11:46<12:11, 17.02s/epoch, loss=1.13, accuracy=0.757, val_loss=2.52, val_accuracy=0.416, lr=0.1] 49%|████▉     | 41/83 [12:04<11:55, 17.05s/epoch, loss=1.14, accuracy=0.753, val_loss=1.67, val_accuracy=0.601, lr=0.0316] 51%|█████     | 42/83 [12:21<11:40, 17.08s/epoch, loss=1.14, accuracy=0.754, val_loss=1.86, val_accuracy=0.564, lr=0.1]    52%|█████▏    | 43/83 [12:38<11:26, 17.17s/epoch, loss=1.14, accuracy=0.754, val_loss=1.95, val_accuracy=0.529, lr=0.1] 53%|█████▎    | 44/83 [12:55<11:10, 17.19s/epoch, loss=1.14, accuracy=0.754, val_loss=2.42, val_accuracy=0.505, lr=0.1] 54%|█████▍    | 45/83 [13:12<10:51, 17.14s/epoch, loss=1.14, accuracy=0.754, val_loss=2.04, val_accuracy=0.517, lr=0.1] 55%|█████▌    | 46/83 [13:29<10:29, 17.01s/epoch, loss=1.13, accuracy=0.756, val_loss=2.03, val_accuracy=0.475, lr=0.0316] 57%|█████▋    | 47/83 [13:46<10:11, 17.00s/epoch, loss=1.13, accuracy=0.757, val_loss=2.53, val_accuracy=0.448, lr=0.1]    58%|█████▊    | 48/83 [14:03<09:51, 16.91s/epoch, loss=1.13, accuracy=0.756, val_loss=2.52, val_accuracy=0.382, lr=0.1] 59%|█████▉    | 49/83 [14:19<09:31, 16.82s/epoch, loss=1.14, accuracy=0.756, val_loss=2.18, val_accuracy=0.446, lr=0.1] 60%|██████    | 50/83 [14:36<09:16, 16.85s/epoch, loss=1.13, accuracy=0.754, val_loss=2.11, val_accuracy=0.445, lr=0.1] 61%|██████▏   | 51/83 [14:53<08:57, 16.79s/epoch, loss=1.13, accuracy=0.756, val_loss=2.04, val_accuracy=0.446, lr=0.0316] 63%|██████▎   | 52/83 [15:10<08:39, 16.76s/epoch, loss=1.14, accuracy=0.754, val_loss=2.17, val_accuracy=0.523, lr=0.1]    64%|██████▍   | 53/83 [15:26<08:23, 16.79s/epoch, loss=1.14, accuracy=0.755, val_loss=1.73, val_accuracy=0.574, lr=0.1] 65%|██████▌   | 54/83 [15:43<08:08, 16.84s/epoch, loss=1.13, accuracy=0.758, val_loss=2.99, val_accuracy=0.312, lr=0.1] 66%|██████▋   | 55/83 [16:01<07:57, 17.04s/epoch, loss=1.13, accuracy=0.755, val_loss=1.68, val_accuracy=0.566, lr=0.1] 67%|██████▋   | 56/83 [16:18<07:38, 16.99s/epoch, loss=1.12, accuracy=0.759, val_loss=3.28, val_accuracy=0.288, lr=0.0316] 69%|██████▊   | 57/83 [16:35<07:21, 16.98s/epoch, loss=1.13, accuracy=0.758, val_loss=1.6, val_accuracy=0.628, lr=0.1]     70%|██████▉   | 58/83 [16:52<07:06, 17.05s/epoch, loss=1.13, accuracy=0.754, val_loss=2, val_accuracy=0.511, lr=0.1]   71%|███████   | 59/83 [17:09<06:52, 17.18s/epoch, loss=1.12, accuracy=0.756, val_loss=2.38, val_accuracy=0.442, lr=0.1] 72%|███████▏  | 60/83 [17:27<06:38, 17.33s/epoch, loss=1.13, accuracy=0.754, val_loss=4.08, val_accuracy=0.358, lr=0.1] 73%|███████▎  | 61/83 [17:45<06:24, 17.46s/epoch, loss=1.13, accuracy=0.757, val_loss=1.76, val_accuracy=0.527, lr=0.0316] 75%|███████▍  | 62/83 [18:02<06:06, 17.48s/epoch, loss=1.13, accuracy=0.757, val_loss=3.2, val_accuracy=0.359, lr=0.1]     76%|███████▌  | 63/83 [18:20<05:49, 17.46s/epoch, loss=1.13, accuracy=0.756, val_loss=1.64, val_accuracy=0.618, lr=0.1] 77%|███████▋  | 64/83 [18:37<05:31, 17.43s/epoch, loss=1.13, accuracy=0.755, val_loss=2.1, val_accuracy=0.506, lr=0.1]  78%|███████▊  | 65/83 [18:55<05:14, 17.49s/epoch, loss=1.13, accuracy=0.758, val_loss=1.92, val_accuracy=0.488, lr=0.1] 80%|███████▉  | 66/83 [19:12<04:55, 17.41s/epoch, loss=1.13, accuracy=0.757, val_loss=2.13, val_accuracy=0.468, lr=0.0316] 81%|████████  | 67/83 [19:29<04:38, 17.40s/epoch, loss=1.12, accuracy=0.759, val_loss=2.58, val_accuracy=0.417, lr=0.1]    82%|████████▏ | 68/83 [19:47<04:22, 17.49s/epoch, loss=1.12, accuracy=0.759, val_loss=1.76, val_accuracy=0.531, lr=0.1] 83%|████████▎ | 69/83 [20:05<04:05, 17.54s/epoch, loss=1.13, accuracy=0.757, val_loss=1.93, val_accuracy=0.54, lr=0.1]  84%|████████▍ | 70/83 [20:22<03:47, 17.51s/epoch, loss=1.13, accuracy=0.758, val_loss=2.2, val_accuracy=0.504, lr=0.1] 86%|████████▌ | 71/83 [20:40<03:30, 17.50s/epoch, loss=1.12, accuracy=0.757, val_loss=2.81, val_accuracy=0.388, lr=0.0316] 87%|████████▋ | 72/83 [20:57<03:13, 17.56s/epoch, loss=1.12, accuracy=0.756, val_loss=2.95, val_accuracy=0.393, lr=0.1]    88%|████████▊ | 73/83 [21:15<02:55, 17.55s/epoch, loss=1.12, accuracy=0.758, val_loss=2.06, val_accuracy=0.47, lr=0.1]  89%|████████▉ | 74/83 [21:33<02:38, 17.62s/epoch, loss=1.12, accuracy=0.759, val_loss=2.8, val_accuracy=0.341, lr=0.1] 90%|█████████ | 75/83 [21:50<02:20, 17.58s/epoch, loss=1.12, accuracy=0.758, val_loss=1.73, val_accuracy=0.568, lr=0.1] 92%|█████████▏| 76/83 [22:08<02:03, 17.58s/epoch, loss=1.11, accuracy=0.76, val_loss=1.56, val_accuracy=0.627, lr=0.0316] 93%|█████████▎| 77/83 [22:25<01:45, 17.51s/epoch, loss=1.13, accuracy=0.755, val_loss=2.38, val_accuracy=0.47, lr=0.1]    94%|█████████▍| 78/83 [22:42<01:27, 17.42s/epoch, loss=1.12, accuracy=0.761, val_loss=1.73, val_accuracy=0.534, lr=0.1] 95%|█████████▌| 79/83 [23:00<01:09, 17.43s/epoch, loss=1.12, accuracy=0.757, val_loss=1.61, val_accuracy=0.567, lr=0.1] 96%|█████████▋| 80/83 [23:17<00:52, 17.47s/epoch, loss=1.12, accuracy=0.757, val_loss=2.01, val_accuracy=0.482, lr=0.1] 98%|█████████▊| 81/83 [23:35<00:34, 17.43s/epoch, loss=1.11, accuracy=0.758, val_loss=3.08, val_accuracy=0.342, lr=0.0316] 99%|█████████▉| 82/83 [23:52<00:17, 17.43s/epoch, loss=0.936, accuracy=0.813, val_loss=0.973, val_accuracy=0.783, lr=0.01]100%|██████████| 83/83 [24:10<00:00, 17.50s/epoch, loss=0.749, accuracy=0.848, val_loss=0.813, val_accuracy=0.81, lr=0.01] 100%|██████████| 83/83 [24:10<00:00, 17.47s/epoch, loss=0.749, accuracy=0.848, val_loss=0.813, val_accuracy=0.81, lr=0.01]
Using real-time data augmentation.
Test score: 0.8162328600883484
Test accuracy: 0.8159999847412109


* * * Run SGD for ID = 18_2. * * *


2024-02-19 23:26:40.409116: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-19 23:26:42.929793: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-19 23:26:42.930761: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-19 23:26:42.966783: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-19 23:26:42.966810: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-19 23:26:42.969741: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-19 23:26:42.969786: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-19 23:26:42.972065: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-19 23:26:42.972777: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-19 23:26:42.975187: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-19 23:26:42.976609: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-19 23:26:42.981285: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-19 23:26:42.981769: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-19 23:26:42.981848: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-19 23:26:44.363071: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-19 23:26:44.364134: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-19 23:26:44.364824: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-19 23:26:44.364852: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-19 23:26:44.364886: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-19 23:26:44.364903: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-19 23:26:44.364920: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-19 23:26:44.364935: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-19 23:26:44.364950: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-19 23:26:44.364995: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-19 23:26:44.365011: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-19 23:26:44.365424: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-19 23:26:44.365455: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-19 23:26:44.958300: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-19 23:26:44.958354: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-19 23:26:44.958363: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-19 23:26:44.959278: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:03:00.0, compute capability: 6.1)
{'id': '18_02', 'batch_size': 128, 'epochs': 83, 'validation_split': 0.1, 'checkpointing': True, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
x_train shape: (45000, 32, 32, 3)
45000 train samples
5000 validation samples
10000 test samples
y_train shape: (45000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/83 [00:00<?, ?epoch/s]2024-02-19 23:26:45.741017: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-19 23:26:45.753087: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600020000 Hz
2024-02-19 23:26:47.623798: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-19 23:26:47.843373: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-19 23:26:48.451388: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-19 23:26:48.496027: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/83 [00:51<1:09:44, 51.03s/epoch, loss=3.48, accuracy=0.298, val_loss=2.51, val_accuracy=0.245, lr=0.1]  2%|▏         | 2/83 [01:09<42:42, 31.63s/epoch, loss=1.69, accuracy=0.478, val_loss=2.18, val_accuracy=0.355, lr=0.1]    4%|▎         | 3/83 [01:26<33:40, 25.25s/epoch, loss=1.46, accuracy=0.579, val_loss=1.91, val_accuracy=0.435, lr=0.1]  5%|▍         | 4/83 [01:44<29:10, 22.16s/epoch, loss=1.35, accuracy=0.648, val_loss=2.88, val_accuracy=0.344, lr=0.1]  6%|▌         | 5/83 [02:01<26:42, 20.54s/epoch, loss=1.28, accuracy=0.683, val_loss=2.08, val_accuracy=0.455, lr=0.1]  7%|▋         | 6/83 [02:19<25:01, 19.49s/epoch, loss=1.26, accuracy=0.699, val_loss=1.73, val_accuracy=0.528, lr=0.1]  8%|▊         | 7/83 [02:36<23:49, 18.81s/epoch, loss=1.25, accuracy=0.708, val_loss=2.19, val_accuracy=0.421, lr=0.1] 10%|▉         | 8/83 [02:54<23:02, 18.43s/epoch, loss=1.24, accuracy=0.718, val_loss=2.48, val_accuracy=0.434, lr=0.1] 11%|█         | 9/83 [03:12<22:28, 18.22s/epoch, loss=1.22, accuracy=0.726, val_loss=1.45, val_accuracy=0.642, lr=0.1] 12%|█▏        | 10/83 [03:29<21:55, 18.03s/epoch, loss=1.23, accuracy=0.727, val_loss=1.65, val_accuracy=0.564, lr=0.1] 13%|█▎        | 11/83 [03:47<21:34, 17.98s/epoch, loss=1.21, accuracy=0.73, val_loss=2.13, val_accuracy=0.439, lr=0.1]  14%|█▍        | 12/83 [04:04<21:05, 17.82s/epoch, loss=1.22, accuracy=0.733, val_loss=1.55, val_accuracy=0.615, lr=0.1] 16%|█▌        | 13/83 [04:22<20:45, 17.80s/epoch, loss=1.21, accuracy=0.73, val_loss=1.53, val_accuracy=0.634, lr=0.1]  17%|█▋        | 14/83 [04:40<20:22, 17.72s/epoch, loss=1.21, accuracy=0.733, val_loss=1.9, val_accuracy=0.494, lr=0.0316] 18%|█▊        | 15/83 [04:57<20:01, 17.67s/epoch, loss=1.2, accuracy=0.738, val_loss=3.01, val_accuracy=0.413, lr=0.1]    19%|█▉        | 16/83 [05:15<19:43, 17.66s/epoch, loss=1.2, accuracy=0.74, val_loss=2.15, val_accuracy=0.461, lr=0.1]  20%|██        | 17/83 [05:33<19:25, 17.66s/epoch, loss=1.2, accuracy=0.74, val_loss=2.01, val_accuracy=0.498, lr=0.1] 22%|██▏       | 18/83 [05:50<19:02, 17.58s/epoch, loss=1.2, accuracy=0.742, val_loss=2.04, val_accuracy=0.512, lr=0.1] 23%|██▎       | 19/83 [06:08<18:45, 17.58s/epoch, loss=1.2, accuracy=0.743, val_loss=2.06, val_accuracy=0.463, lr=0.0316] 24%|██▍       | 20/83 [06:25<18:31, 17.64s/epoch, loss=1.19, accuracy=0.741, val_loss=2.34, val_accuracy=0.437, lr=0.1]   25%|██▌       | 21/83 [06:43<18:11, 17.60s/epoch, loss=1.19, accuracy=0.742, val_loss=1.85, val_accuracy=0.52, lr=0.1]  27%|██▋       | 22/83 [07:00<17:47, 17.49s/epoch, loss=1.19, accuracy=0.743, val_loss=1.68, val_accuracy=0.581, lr=0.1] 28%|██▊       | 23/83 [07:18<17:33, 17.56s/epoch, loss=1.18, accuracy=0.744, val_loss=1.97, val_accuracy=0.54, lr=0.1]  29%|██▉       | 24/83 [07:36<17:18, 17.61s/epoch, loss=1.18, accuracy=0.744, val_loss=2.11, val_accuracy=0.445, lr=0.0316] 30%|███       | 25/83 [07:53<17:00, 17.60s/epoch, loss=1.18, accuracy=0.748, val_loss=1.54, val_accuracy=0.629, lr=0.1]    31%|███▏      | 26/83 [08:11<16:40, 17.56s/epoch, loss=1.17, accuracy=0.745, val_loss=3.02, val_accuracy=0.313, lr=0.1] 33%|███▎      | 27/83 [08:28<16:23, 17.57s/epoch, loss=1.17, accuracy=0.747, val_loss=3, val_accuracy=0.349, lr=0.1]    34%|███▎      | 28/83 [08:46<16:05, 17.56s/epoch, loss=1.17, accuracy=0.75, val_loss=1.64, val_accuracy=0.601, lr=0.1] 35%|███▍      | 29/83 [09:04<15:51, 17.63s/epoch, loss=1.17, accuracy=0.751, val_loss=2.15, val_accuracy=0.529, lr=0.0316] 36%|███▌      | 30/83 [09:21<15:34, 17.63s/epoch, loss=1.17, accuracy=0.748, val_loss=2.43, val_accuracy=0.461, lr=0.1]    37%|███▋      | 31/83 [09:39<15:15, 17.60s/epoch, loss=1.17, accuracy=0.749, val_loss=1.83, val_accuracy=0.532, lr=0.1] 39%|███▊      | 32/83 [09:57<15:03, 17.71s/epoch, loss=1.16, accuracy=0.75, val_loss=1.56, val_accuracy=0.602, lr=0.1]  40%|███▉      | 33/83 [10:14<14:45, 17.70s/epoch, loss=1.15, accuracy=0.75, val_loss=1.55, val_accuracy=0.627, lr=0.1] 41%|████      | 34/83 [10:32<14:29, 17.75s/epoch, loss=1.16, accuracy=0.75, val_loss=1.91, val_accuracy=0.54, lr=0.0316] 42%|████▏     | 35/83 [10:50<14:08, 17.67s/epoch, loss=1.16, accuracy=0.752, val_loss=2.61, val_accuracy=0.405, lr=0.1]  43%|████▎     | 36/83 [11:07<13:51, 17.70s/epoch, loss=1.16, accuracy=0.75, val_loss=1.58, val_accuracy=0.602, lr=0.1]  45%|████▍     | 37/83 [11:25<13:32, 17.67s/epoch, loss=1.16, accuracy=0.75, val_loss=2.88, val_accuracy=0.416, lr=0.1] 46%|████▌     | 38/83 [11:43<13:12, 17.62s/epoch, loss=1.16, accuracy=0.751, val_loss=1.6, val_accuracy=0.614, lr=0.1] 47%|████▋     | 39/83 [12:00<12:54, 17.61s/epoch, loss=1.16, accuracy=0.75, val_loss=2.28, val_accuracy=0.425, lr=0.0316] 48%|████▊     | 40/83 [12:18<12:37, 17.62s/epoch, loss=1.15, accuracy=0.752, val_loss=1.63, val_accuracy=0.598, lr=0.1]   49%|████▉     | 41/83 [12:35<12:20, 17.62s/epoch, loss=1.15, accuracy=0.754, val_loss=2.24, val_accuracy=0.442, lr=0.1] 51%|█████     | 42/83 [12:53<12:06, 17.73s/epoch, loss=1.15, accuracy=0.752, val_loss=1.76, val_accuracy=0.548, lr=0.1] 52%|█████▏    | 43/83 [13:11<11:49, 17.75s/epoch, loss=1.15, accuracy=0.754, val_loss=1.95, val_accuracy=0.537, lr=0.1] 53%|█████▎    | 44/83 [13:29<11:29, 17.69s/epoch, loss=1.15, accuracy=0.754, val_loss=1.79, val_accuracy=0.553, lr=0.0316] 54%|█████▍    | 45/83 [13:46<11:10, 17.65s/epoch, loss=1.15, accuracy=0.752, val_loss=3.77, val_accuracy=0.302, lr=0.1]    55%|█████▌    | 46/83 [14:04<10:49, 17.57s/epoch, loss=1.15, accuracy=0.756, val_loss=1.54, val_accuracy=0.627, lr=0.1] 57%|█████▋    | 47/83 [14:21<10:31, 17.55s/epoch, loss=1.15, accuracy=0.753, val_loss=3.61, val_accuracy=0.213, lr=0.1] 58%|█████▊    | 48/83 [14:39<10:13, 17.52s/epoch, loss=1.15, accuracy=0.753, val_loss=3.41, val_accuracy=0.335, lr=0.1] 59%|█████▉    | 49/83 [14:56<09:57, 17.58s/epoch, loss=1.15, accuracy=0.753, val_loss=2.05, val_accuracy=0.499, lr=0.0316] 60%|██████    | 50/83 [15:14<09:42, 17.65s/epoch, loss=1.15, accuracy=0.752, val_loss=1.72, val_accuracy=0.556, lr=0.1]    61%|██████▏   | 51/83 [15:32<09:27, 17.75s/epoch, loss=1.15, accuracy=0.755, val_loss=1.37, val_accuracy=0.67, lr=0.1]  63%|██████▎   | 52/83 [15:50<09:08, 17.68s/epoch, loss=1.15, accuracy=0.754, val_loss=2.01, val_accuracy=0.459, lr=0.1] 64%|██████▍   | 53/83 [16:07<08:49, 17.66s/epoch, loss=1.14, accuracy=0.755, val_loss=2.85, val_accuracy=0.434, lr=0.1] 65%|██████▌   | 54/83 [16:25<08:29, 17.58s/epoch, loss=1.14, accuracy=0.758, val_loss=3.93, val_accuracy=0.345, lr=0.1] 66%|██████▋   | 55/83 [16:42<08:11, 17.55s/epoch, loss=1.14, accuracy=0.753, val_loss=1.97, val_accuracy=0.523, lr=0.1] 67%|██████▋   | 56/83 [17:00<07:54, 17.56s/epoch, loss=1.14, accuracy=0.754, val_loss=1.76, val_accuracy=0.58, lr=0.0316] 69%|██████▊   | 57/83 [17:17<07:36, 17.57s/epoch, loss=1.14, accuracy=0.754, val_loss=2.17, val_accuracy=0.506, lr=0.1]   70%|██████▉   | 58/83 [17:35<07:18, 17.55s/epoch, loss=1.14, accuracy=0.756, val_loss=1.78, val_accuracy=0.541, lr=0.1] 71%|███████   | 59/83 [17:52<07:01, 17.55s/epoch, loss=1.14, accuracy=0.756, val_loss=2.79, val_accuracy=0.33, lr=0.1]  72%|███████▏  | 60/83 [18:10<06:44, 17.59s/epoch, loss=1.14, accuracy=0.758, val_loss=1.82, val_accuracy=0.551, lr=0.1] 73%|███████▎  | 61/83 [18:28<06:27, 17.59s/epoch, loss=1.14, accuracy=0.753, val_loss=1.65, val_accuracy=0.591, lr=0.0316] 75%|███████▍  | 62/83 [18:45<06:10, 17.65s/epoch, loss=1.14, accuracy=0.755, val_loss=1.8, val_accuracy=0.559, lr=0.1]     76%|███████▌  | 63/83 [19:03<05:52, 17.64s/epoch, loss=1.14, accuracy=0.755, val_loss=2.26, val_accuracy=0.418, lr=0.1] 77%|███████▋  | 64/83 [19:21<05:35, 17.65s/epoch, loss=1.14, accuracy=0.755, val_loss=2.87, val_accuracy=0.371, lr=0.1] 78%|███████▊  | 65/83 [19:39<05:19, 17.73s/epoch, loss=1.13, accuracy=0.758, val_loss=2.44, val_accuracy=0.399, lr=0.1] 80%|███████▉  | 66/83 [19:56<04:59, 17.64s/epoch, loss=1.14, accuracy=0.756, val_loss=4, val_accuracy=0.292, lr=0.0316] 81%|████████  | 67/83 [20:14<04:41, 17.59s/epoch, loss=1.14, accuracy=0.755, val_loss=1.61, val_accuracy=0.615, lr=0.1] 82%|████████▏ | 68/83 [20:31<04:22, 17.53s/epoch, loss=1.14, accuracy=0.753, val_loss=2.02, val_accuracy=0.521, lr=0.1] 83%|████████▎ | 69/83 [20:48<04:03, 17.38s/epoch, loss=1.14, accuracy=0.756, val_loss=2, val_accuracy=0.477, lr=0.1]    84%|████████▍ | 70/83 [21:05<03:45, 17.36s/epoch, loss=1.14, accuracy=0.755, val_loss=1.82, val_accuracy=0.565, lr=0.1] 86%|████████▌ | 71/83 [21:23<03:28, 17.39s/epoch, loss=1.14, accuracy=0.757, val_loss=2.2, val_accuracy=0.55, lr=0.0316] 87%|████████▋ | 72/83 [21:40<03:10, 17.32s/epoch, loss=1.14, accuracy=0.758, val_loss=2.08, val_accuracy=0.496, lr=0.1]  88%|████████▊ | 73/83 [21:57<02:52, 17.26s/epoch, loss=1.14, accuracy=0.755, val_loss=3.9, val_accuracy=0.33, lr=0.1]   89%|████████▉ | 74/83 [22:14<02:35, 17.23s/epoch, loss=1.14, accuracy=0.755, val_loss=1.8, val_accuracy=0.534, lr=0.1] 90%|█████████ | 75/83 [22:32<02:18, 17.33s/epoch, loss=1.13, accuracy=0.755, val_loss=1.76, val_accuracy=0.513, lr=0.1] 92%|█████████▏| 76/83 [22:49<02:00, 17.28s/epoch, loss=1.13, accuracy=0.759, val_loss=1.53, val_accuracy=0.632, lr=0.0316] 93%|█████████▎| 77/83 [23:06<01:43, 17.31s/epoch, loss=1.13, accuracy=0.757, val_loss=1.68, val_accuracy=0.558, lr=0.1]    94%|█████████▍| 78/83 [23:24<01:26, 17.38s/epoch, loss=1.14, accuracy=0.757, val_loss=2.08, val_accuracy=0.435, lr=0.1] 95%|█████████▌| 79/83 [23:41<01:09, 17.29s/epoch, loss=1.13, accuracy=0.757, val_loss=2.26, val_accuracy=0.424, lr=0.1] 96%|█████████▋| 80/83 [23:58<00:52, 17.36s/epoch, loss=1.13, accuracy=0.759, val_loss=2.33, val_accuracy=0.5, lr=0.1]   98%|█████████▊| 81/83 [24:15<00:34, 17.24s/epoch, loss=1.14, accuracy=0.756, val_loss=1.98, val_accuracy=0.506, lr=0.0316] 99%|█████████▉| 82/83 [24:33<00:17, 17.41s/epoch, loss=0.928, accuracy=0.816, val_loss=0.992, val_accuracy=0.777, lr=0.01]100%|██████████| 83/83 [24:51<00:00, 17.38s/epoch, loss=0.752, accuracy=0.848, val_loss=0.836, val_accuracy=0.802, lr=0.01]100%|██████████| 83/83 [24:51<00:00, 17.96s/epoch, loss=0.752, accuracy=0.848, val_loss=0.836, val_accuracy=0.802, lr=0.01]
Using real-time data augmentation.
Test score: 0.848407506942749
Test accuracy: 0.8054999709129333


* * * Run SGD for ID = 18_3. * * *


2024-02-19 23:51:44.265915: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-19 23:51:46.729122: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-19 23:51:46.730044: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-19 23:51:46.766062: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-19 23:51:46.766094: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-19 23:51:46.768868: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-19 23:51:46.768905: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-19 23:51:46.771127: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-19 23:51:46.771727: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-19 23:51:46.774055: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-19 23:51:46.775430: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-19 23:51:46.779966: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-19 23:51:46.780447: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-19 23:51:46.780525: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-19 23:51:48.199321: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-19 23:51:48.200368: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-19 23:51:48.201116: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-19 23:51:48.201148: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-19 23:51:48.201190: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-19 23:51:48.201208: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-19 23:51:48.201224: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-19 23:51:48.201241: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-19 23:51:48.201257: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-19 23:51:48.201280: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-19 23:51:48.201297: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-19 23:51:48.201723: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-19 23:51:48.201759: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-19 23:51:48.810327: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-19 23:51:48.810381: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-19 23:51:48.810390: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-19 23:51:48.811275: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:03:00.0, compute capability: 6.1)
{'id': '18_03', 'batch_size': 128, 'epochs': 83, 'validation_split': 0.1, 'checkpointing': True, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
x_train shape: (45000, 32, 32, 3)
45000 train samples
5000 validation samples
10000 test samples
y_train shape: (45000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/83 [00:00<?, ?epoch/s]2024-02-19 23:51:49.586022: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-19 23:51:49.598078: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600020000 Hz
2024-02-19 23:51:51.464580: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-19 23:51:51.691799: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-19 23:51:52.358278: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-19 23:51:52.407745: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/83 [00:51<1:09:47, 51.06s/epoch, loss=3.23, accuracy=0.293, val_loss=2.55, val_accuracy=0.245, lr=0.1]  2%|▏         | 2/83 [01:08<42:07, 31.21s/epoch, loss=1.62, accuracy=0.504, val_loss=2.02, val_accuracy=0.42, lr=0.1]     4%|▎         | 3/83 [01:25<32:57, 24.72s/epoch, loss=1.37, accuracy=0.63, val_loss=2.21, val_accuracy=0.373, lr=0.1]  5%|▍         | 4/83 [01:42<28:31, 21.67s/epoch, loss=1.29, accuracy=0.677, val_loss=4.55, val_accuracy=0.255, lr=0.1]  6%|▌         | 5/83 [02:00<26:17, 20.23s/epoch, loss=1.26, accuracy=0.696, val_loss=1.64, val_accuracy=0.575, lr=0.1]  7%|▋         | 6/83 [02:17<24:35, 19.16s/epoch, loss=1.24, accuracy=0.707, val_loss=4.02, val_accuracy=0.283, lr=0.1]  8%|▊         | 7/83 [02:34<23:27, 18.52s/epoch, loss=1.23, accuracy=0.714, val_loss=3.23, val_accuracy=0.372, lr=0.1] 10%|▉         | 8/83 [02:51<22:34, 18.06s/epoch, loss=1.21, accuracy=0.723, val_loss=2.35, val_accuracy=0.341, lr=0.1] 11%|█         | 9/83 [03:09<22:06, 17.92s/epoch, loss=1.21, accuracy=0.725, val_loss=1.67, val_accuracy=0.57, lr=0.1]  12%|█▏        | 10/83 [03:26<21:37, 17.77s/epoch, loss=1.2, accuracy=0.725, val_loss=1.75, val_accuracy=0.58, lr=0.0316] 13%|█▎        | 11/83 [03:43<21:01, 17.52s/epoch, loss=1.19, accuracy=0.729, val_loss=2.21, val_accuracy=0.487, lr=0.1]  14%|█▍        | 12/83 [04:00<20:35, 17.41s/epoch, loss=1.19, accuracy=0.731, val_loss=1.72, val_accuracy=0.559, lr=0.1] 16%|█▌        | 13/83 [04:17<20:17, 17.40s/epoch, loss=1.18, accuracy=0.738, val_loss=2.7, val_accuracy=0.325, lr=0.1]  17%|█▋        | 14/83 [04:35<19:56, 17.34s/epoch, loss=1.18, accuracy=0.735, val_loss=1.63, val_accuracy=0.567, lr=0.1] 18%|█▊        | 15/83 [04:52<19:33, 17.26s/epoch, loss=1.17, accuracy=0.742, val_loss=1.97, val_accuracy=0.489, lr=0.1] 19%|█▉        | 16/83 [05:09<19:17, 17.27s/epoch, loss=1.18, accuracy=0.738, val_loss=2.74, val_accuracy=0.378, lr=0.1] 20%|██        | 17/83 [05:26<19:00, 17.28s/epoch, loss=1.17, accuracy=0.74, val_loss=2.25, val_accuracy=0.404, lr=0.1]  22%|██▏       | 18/83 [05:44<18:42, 17.27s/epoch, loss=1.16, accuracy=0.742, val_loss=2.53, val_accuracy=0.478, lr=0.1] 23%|██▎       | 19/83 [06:01<18:28, 17.32s/epoch, loss=1.16, accuracy=0.74, val_loss=2.1, val_accuracy=0.536, lr=0.0316] 24%|██▍       | 20/83 [06:18<18:05, 17.22s/epoch, loss=1.16, accuracy=0.744, val_loss=2.14, val_accuracy=0.544, lr=0.1]  25%|██▌       | 21/83 [06:35<17:47, 17.21s/epoch, loss=1.16, accuracy=0.745, val_loss=6.96, val_accuracy=0.275, lr=0.1] 27%|██▋       | 22/83 [06:53<17:38, 17.35s/epoch, loss=1.16, accuracy=0.742, val_loss=2.84, val_accuracy=0.431, lr=0.1] 28%|██▊       | 23/83 [07:10<17:18, 17.32s/epoch, loss=1.15, accuracy=0.744, val_loss=2.4, val_accuracy=0.467, lr=0.1]  29%|██▉       | 24/83 [07:27<16:56, 17.22s/epoch, loss=1.15, accuracy=0.749, val_loss=1.77, val_accuracy=0.572, lr=0.0316] 30%|███       | 25/83 [07:44<16:38, 17.21s/epoch, loss=1.15, accuracy=0.745, val_loss=4.36, val_accuracy=0.22, lr=0.1]     31%|███▏      | 26/83 [08:02<16:21, 17.23s/epoch, loss=1.14, accuracy=0.749, val_loss=2.19, val_accuracy=0.471, lr=0.1] 33%|███▎      | 27/83 [08:19<16:02, 17.19s/epoch, loss=1.15, accuracy=0.749, val_loss=2.15, val_accuracy=0.467, lr=0.1] 34%|███▎      | 28/83 [08:37<15:58, 17.42s/epoch, loss=1.15, accuracy=0.752, val_loss=1.5, val_accuracy=0.622, lr=0.1]  35%|███▍      | 29/83 [08:55<15:51, 17.61s/epoch, loss=1.14, accuracy=0.75, val_loss=2.22, val_accuracy=0.482, lr=0.1] 36%|███▌      | 30/83 [09:12<15:26, 17.48s/epoch, loss=1.14, accuracy=0.75, val_loss=1.49, val_accuracy=0.615, lr=0.1] 37%|███▋      | 31/83 [09:29<15:08, 17.47s/epoch, loss=1.15, accuracy=0.747, val_loss=3.08, val_accuracy=0.377, lr=0.1] 39%|███▊      | 32/83 [09:46<14:44, 17.34s/epoch, loss=1.14, accuracy=0.75, val_loss=1.98, val_accuracy=0.5, lr=0.1]    40%|███▉      | 33/83 [10:04<14:36, 17.53s/epoch, loss=1.13, accuracy=0.754, val_loss=1.81, val_accuracy=0.532, lr=0.1] 41%|████      | 34/83 [10:22<14:18, 17.52s/epoch, loss=1.13, accuracy=0.753, val_loss=2.16, val_accuracy=0.476, lr=0.1] 42%|████▏     | 35/83 [10:39<13:52, 17.35s/epoch, loss=1.14, accuracy=0.751, val_loss=2.36, val_accuracy=0.435, lr=0.0316] 43%|████▎     | 36/83 [10:56<13:27, 17.18s/epoch, loss=1.13, accuracy=0.755, val_loss=1.56, val_accuracy=0.608, lr=0.1]    45%|████▍     | 37/83 [11:13<13:13, 17.25s/epoch, loss=1.13, accuracy=0.756, val_loss=1.36, val_accuracy=0.678, lr=0.1] 46%|████▌     | 38/83 [11:30<12:55, 17.24s/epoch, loss=1.13, accuracy=0.751, val_loss=1.4, val_accuracy=0.655, lr=0.1]  47%|████▋     | 39/83 [11:47<12:33, 17.12s/epoch, loss=1.12, accuracy=0.756, val_loss=2.34, val_accuracy=0.429, lr=0.1] 48%|████▊     | 40/83 [12:04<12:16, 17.12s/epoch, loss=1.13, accuracy=0.752, val_loss=2.11, val_accuracy=0.48, lr=0.1]  49%|████▉     | 41/83 [12:21<11:59, 17.13s/epoch, loss=1.12, accuracy=0.752, val_loss=2.22, val_accuracy=0.425, lr=0.1] 51%|█████     | 42/83 [12:39<11:45, 17.21s/epoch, loss=1.13, accuracy=0.754, val_loss=2.49, val_accuracy=0.453, lr=0.0316] 52%|█████▏    | 43/83 [12:55<11:23, 17.09s/epoch, loss=1.12, accuracy=0.755, val_loss=1.84, val_accuracy=0.56, lr=0.1]     53%|█████▎    | 44/83 [13:13<11:06, 17.08s/epoch, loss=1.12, accuracy=0.756, val_loss=1.96, val_accuracy=0.48, lr=0.1] 54%|█████▍    | 45/83 [13:30<10:48, 17.06s/epoch, loss=1.12, accuracy=0.754, val_loss=1.41, val_accuracy=0.651, lr=0.1] 55%|█████▌    | 46/83 [13:46<10:29, 17.02s/epoch, loss=1.13, accuracy=0.754, val_loss=1.78, val_accuracy=0.56, lr=0.1]  57%|█████▋    | 47/83 [14:03<10:08, 16.91s/epoch, loss=1.12, accuracy=0.753, val_loss=1.87, val_accuracy=0.522, lr=0.0316] 58%|█████▊    | 48/83 [14:20<09:51, 16.89s/epoch, loss=1.12, accuracy=0.753, val_loss=1.79, val_accuracy=0.567, lr=0.1]    59%|█████▉    | 49/83 [14:37<09:35, 16.92s/epoch, loss=1.12, accuracy=0.756, val_loss=1.49, val_accuracy=0.604, lr=0.1] 60%|██████    | 50/83 [14:54<09:21, 17.00s/epoch, loss=1.12, accuracy=0.756, val_loss=1.74, val_accuracy=0.588, lr=0.1] 61%|██████▏   | 51/83 [15:11<08:58, 16.83s/epoch, loss=1.12, accuracy=0.755, val_loss=1.94, val_accuracy=0.508, lr=0.1] 63%|██████▎   | 52/83 [15:27<08:40, 16.78s/epoch, loss=1.11, accuracy=0.757, val_loss=1.6, val_accuracy=0.598, lr=0.0316] 64%|██████▍   | 53/83 [15:44<08:24, 16.80s/epoch, loss=1.11, accuracy=0.757, val_loss=2.31, val_accuracy=0.497, lr=0.1]   65%|██████▌   | 54/83 [16:01<08:04, 16.71s/epoch, loss=1.11, accuracy=0.755, val_loss=1.97, val_accuracy=0.468, lr=0.1] 66%|██████▋   | 55/83 [16:17<07:49, 16.76s/epoch, loss=1.12, accuracy=0.757, val_loss=1.57, val_accuracy=0.606, lr=0.1] 67%|██████▋   | 56/83 [16:34<07:34, 16.83s/epoch, loss=1.11, accuracy=0.759, val_loss=1.85, val_accuracy=0.513, lr=0.1] 69%|██████▊   | 57/83 [16:52<07:19, 16.90s/epoch, loss=1.11, accuracy=0.755, val_loss=3.79, val_accuracy=0.335, lr=0.0316] 70%|██████▉   | 58/83 [17:08<07:02, 16.89s/epoch, loss=1.12, accuracy=0.756, val_loss=1.43, val_accuracy=0.65, lr=0.1]     71%|███████   | 59/83 [17:25<06:43, 16.80s/epoch, loss=1.11, accuracy=0.758, val_loss=1.7, val_accuracy=0.562, lr=0.1] 72%|███████▏  | 60/83 [17:42<06:27, 16.83s/epoch, loss=1.1, accuracy=0.76, val_loss=8, val_accuracy=0.231, lr=0.1]     73%|███████▎  | 61/83 [17:59<06:10, 16.83s/epoch, loss=1.11, accuracy=0.756, val_loss=1.66, val_accuracy=0.611, lr=0.1] 75%|███████▍  | 62/83 [18:16<05:54, 16.90s/epoch, loss=1.11, accuracy=0.757, val_loss=2.42, val_accuracy=0.471, lr=0.0316] 76%|███████▌  | 63/83 [18:33<05:37, 16.90s/epoch, loss=1.11, accuracy=0.758, val_loss=1.5, val_accuracy=0.642, lr=0.1]     77%|███████▋  | 64/83 [18:49<05:20, 16.86s/epoch, loss=1.11, accuracy=0.758, val_loss=1.71, val_accuracy=0.543, lr=0.1] 78%|███████▊  | 65/83 [19:06<05:04, 16.89s/epoch, loss=1.11, accuracy=0.758, val_loss=1.85, val_accuracy=0.561, lr=0.1] 80%|███████▉  | 66/83 [19:23<04:47, 16.94s/epoch, loss=1.1, accuracy=0.76, val_loss=2.31, val_accuracy=0.42, lr=0.1]    81%|████████  | 67/83 [19:40<04:29, 16.85s/epoch, loss=1.11, accuracy=0.756, val_loss=2.81, val_accuracy=0.359, lr=0.0316] 82%|████████▏ | 68/83 [19:57<04:13, 16.89s/epoch, loss=1.11, accuracy=0.759, val_loss=1.79, val_accuracy=0.568, lr=0.1]    83%|████████▎ | 69/83 [20:14<03:55, 16.79s/epoch, loss=1.11, accuracy=0.755, val_loss=2.75, val_accuracy=0.397, lr=0.1] 84%|████████▍ | 70/83 [20:31<03:39, 16.85s/epoch, loss=1.11, accuracy=0.758, val_loss=2.18, val_accuracy=0.42, lr=0.1]  86%|████████▌ | 71/83 [20:47<03:21, 16.81s/epoch, loss=1.11, accuracy=0.758, val_loss=2, val_accuracy=0.547, lr=0.1]   87%|████████▋ | 72/83 [21:04<03:04, 16.78s/epoch, loss=1.11, accuracy=0.757, val_loss=3.7, val_accuracy=0.406, lr=0.0316] 88%|████████▊ | 73/83 [21:21<02:47, 16.74s/epoch, loss=1.1, accuracy=0.759, val_loss=2.46, val_accuracy=0.412, lr=0.1]    89%|████████▉ | 74/83 [21:38<02:31, 16.81s/epoch, loss=1.11, accuracy=0.758, val_loss=1.97, val_accuracy=0.56, lr=0.1] 90%|█████████ | 75/83 [21:54<02:13, 16.68s/epoch, loss=1.11, accuracy=0.758, val_loss=4.32, val_accuracy=0.282, lr=0.1] 92%|█████████▏| 76/83 [22:10<01:56, 16.59s/epoch, loss=1.11, accuracy=0.759, val_loss=1.57, val_accuracy=0.599, lr=0.1] 93%|█████████▎| 77/83 [22:27<01:40, 16.70s/epoch, loss=1.11, accuracy=0.758, val_loss=1.57, val_accuracy=0.604, lr=0.0316] 94%|█████████▍| 78/83 [22:44<01:23, 16.62s/epoch, loss=1.11, accuracy=0.759, val_loss=4.7, val_accuracy=0.211, lr=0.1]     95%|█████████▌| 79/83 [23:01<01:06, 16.65s/epoch, loss=1.11, accuracy=0.758, val_loss=1.39, val_accuracy=0.654, lr=0.1] 96%|█████████▋| 80/83 [23:18<00:50, 16.77s/epoch, loss=1.1, accuracy=0.757, val_loss=1.97, val_accuracy=0.486, lr=0.1]  98%|█████████▊| 81/83 [23:34<00:33, 16.70s/epoch, loss=1.1, accuracy=0.758, val_loss=1.89, val_accuracy=0.49, lr=0.1]  99%|█████████▉| 82/83 [23:51<00:16, 16.86s/epoch, loss=0.907, accuracy=0.816, val_loss=0.873, val_accuracy=0.811, lr=0.01]100%|██████████| 83/83 [24:08<00:00, 16.84s/epoch, loss=0.738, accuracy=0.848, val_loss=0.797, val_accuracy=0.816, lr=0.01]100%|██████████| 83/83 [24:08<00:00, 17.45s/epoch, loss=0.738, accuracy=0.848, val_loss=0.797, val_accuracy=0.816, lr=0.01]
Using real-time data augmentation.
Test score: 0.8140324950218201
Test accuracy: 0.8101999759674072


* * * Run SGD for ID = 18_4. * * *


2024-02-20 00:16:03.722486: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 00:16:06.142420: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 00:16:06.143374: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-20 00:16:06.179451: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-20 00:16:06.179477: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 00:16:06.182006: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 00:16:06.182044: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-20 00:16:06.184198: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-20 00:16:06.184782: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-20 00:16:06.186925: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-20 00:16:06.188288: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-20 00:16:06.192675: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 00:16:06.193152: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-20 00:16:06.193227: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 00:16:07.593821: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-20 00:16:07.595311: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 00:16:07.596043: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-20 00:16:07.596072: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 00:16:07.596107: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 00:16:07.596123: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-20 00:16:07.596138: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-20 00:16:07.596153: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-20 00:16:07.596167: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-20 00:16:07.596181: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-20 00:16:07.596195: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 00:16:07.596618: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-20 00:16:07.596653: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 00:16:08.188798: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-20 00:16:08.188844: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-20 00:16:08.188853: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-20 00:16:08.189741: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:03:00.0, compute capability: 6.1)
{'id': '18_04', 'batch_size': 128, 'epochs': 83, 'validation_split': 0.1, 'checkpointing': True, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
x_train shape: (45000, 32, 32, 3)
45000 train samples
5000 validation samples
10000 test samples
y_train shape: (45000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/83 [00:00<?, ?epoch/s]2024-02-20 00:16:08.972834: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-20 00:16:08.985081: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600020000 Hz
2024-02-20 00:16:10.894882: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 00:16:11.116667: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 00:16:11.777798: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-20 00:16:11.806474: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/83 [00:51<1:10:39, 51.70s/epoch, loss=3.35, accuracy=0.281, val_loss=3.27, val_accuracy=0.131, lr=0.1]  2%|▏         | 2/83 [01:09<43:06, 31.94s/epoch, loss=1.68, accuracy=0.478, val_loss=2.83, val_accuracy=0.303, lr=0.1]    4%|▎         | 3/83 [01:27<33:42, 25.28s/epoch, loss=1.37, accuracy=0.619, val_loss=2.18, val_accuracy=0.406, lr=0.1]  5%|▍         | 4/83 [01:44<29:14, 22.21s/epoch, loss=1.29, accuracy=0.673, val_loss=2.31, val_accuracy=0.478, lr=0.1]  6%|▌         | 5/83 [02:02<26:36, 20.46s/epoch, loss=1.25, accuracy=0.692, val_loss=1.67, val_accuracy=0.543, lr=0.1]  7%|▋         | 6/83 [02:19<24:48, 19.33s/epoch, loss=1.23, accuracy=0.707, val_loss=1.86, val_accuracy=0.548, lr=0.1]  8%|▊         | 7/83 [02:36<23:27, 18.52s/epoch, loss=1.22, accuracy=0.714, val_loss=1.97, val_accuracy=0.513, lr=0.1] 10%|▉         | 8/83 [02:53<22:35, 18.07s/epoch, loss=1.22, accuracy=0.718, val_loss=1.56, val_accuracy=0.568, lr=0.1] 11%|█         | 9/83 [03:10<21:49, 17.70s/epoch, loss=1.21, accuracy=0.721, val_loss=1.74, val_accuracy=0.541, lr=0.1] 12%|█▏        | 10/83 [03:27<21:16, 17.49s/epoch, loss=1.21, accuracy=0.725, val_loss=4.37, val_accuracy=0.26, lr=0.1] 13%|█▎        | 11/83 [03:44<21:04, 17.57s/epoch, loss=1.2, accuracy=0.729, val_loss=2.05, val_accuracy=0.452, lr=0.1] 14%|█▍        | 12/83 [04:01<20:39, 17.46s/epoch, loss=1.19, accuracy=0.73, val_loss=3.65, val_accuracy=0.3, lr=0.1]   16%|█▌        | 13/83 [04:19<20:18, 17.41s/epoch, loss=1.2, accuracy=0.732, val_loss=3.73, val_accuracy=0.302, lr=0.0316] 17%|█▋        | 14/83 [04:36<19:57, 17.35s/epoch, loss=1.19, accuracy=0.736, val_loss=1.56, val_accuracy=0.624, lr=0.1]   18%|█▊        | 15/83 [04:53<19:34, 17.28s/epoch, loss=1.18, accuracy=0.738, val_loss=1.32, val_accuracy=0.7, lr=0.1]   19%|█▉        | 16/83 [05:10<19:16, 17.27s/epoch, loss=1.18, accuracy=0.735, val_loss=1.77, val_accuracy=0.567, lr=0.1] 20%|██        | 17/83 [05:27<18:56, 17.22s/epoch, loss=1.18, accuracy=0.739, val_loss=1.51, val_accuracy=0.628, lr=0.1] 22%|██▏       | 18/83 [05:45<18:41, 17.25s/epoch, loss=1.17, accuracy=0.741, val_loss=1.86, val_accuracy=0.538, lr=0.1] 23%|██▎       | 19/83 [06:02<18:25, 17.27s/epoch, loss=1.18, accuracy=0.739, val_loss=1.95, val_accuracy=0.528, lr=0.1] 24%|██▍       | 20/83 [06:19<18:08, 17.27s/epoch, loss=1.17, accuracy=0.743, val_loss=1.69, val_accuracy=0.588, lr=0.0316] 25%|██▌       | 21/83 [06:36<17:45, 17.19s/epoch, loss=1.17, accuracy=0.742, val_loss=1.97, val_accuracy=0.521, lr=0.1]    27%|██▋       | 22/83 [06:54<17:28, 17.19s/epoch, loss=1.17, accuracy=0.743, val_loss=2.08, val_accuracy=0.53, lr=0.1]  28%|██▊       | 23/83 [07:11<17:09, 17.16s/epoch, loss=1.17, accuracy=0.745, val_loss=2.78, val_accuracy=0.406, lr=0.1] 29%|██▉       | 24/83 [07:28<17:02, 17.34s/epoch, loss=1.17, accuracy=0.748, val_loss=1.49, val_accuracy=0.637, lr=0.1] 30%|███       | 25/83 [07:46<16:46, 17.36s/epoch, loss=1.16, accuracy=0.746, val_loss=2.48, val_accuracy=0.456, lr=0.0316] 31%|███▏      | 26/83 [08:03<16:29, 17.37s/epoch, loss=1.17, accuracy=0.746, val_loss=1.88, val_accuracy=0.511, lr=0.1]    33%|███▎      | 27/83 [08:20<16:08, 17.29s/epoch, loss=1.16, accuracy=0.746, val_loss=1.9, val_accuracy=0.542, lr=0.1]  34%|███▎      | 28/83 [08:38<15:50, 17.29s/epoch, loss=1.16, accuracy=0.746, val_loss=1.64, val_accuracy=0.596, lr=0.1] 35%|███▍      | 29/83 [08:55<15:31, 17.25s/epoch, loss=1.15, accuracy=0.75, val_loss=2.38, val_accuracy=0.413, lr=0.1]  36%|███▌      | 30/83 [09:12<15:17, 17.30s/epoch, loss=1.15, accuracy=0.751, val_loss=2.28, val_accuracy=0.476, lr=0.0316] 37%|███▋      | 31/83 [09:29<14:59, 17.30s/epoch, loss=1.16, accuracy=0.747, val_loss=3.3, val_accuracy=0.34, lr=0.1]      39%|███▊      | 32/83 [09:47<14:41, 17.29s/epoch, loss=1.16, accuracy=0.747, val_loss=1.59, val_accuracy=0.609, lr=0.1] 40%|███▉      | 33/83 [10:04<14:28, 17.36s/epoch, loss=1.16, accuracy=0.747, val_loss=1.65, val_accuracy=0.591, lr=0.1] 41%|████      | 34/83 [10:22<14:08, 17.33s/epoch, loss=1.16, accuracy=0.748, val_loss=2.12, val_accuracy=0.484, lr=0.1] 42%|████▏     | 35/83 [10:39<13:48, 17.27s/epoch, loss=1.16, accuracy=0.75, val_loss=2.08, val_accuracy=0.527, lr=0.0316] 43%|████▎     | 36/83 [10:56<13:34, 17.33s/epoch, loss=1.16, accuracy=0.746, val_loss=2.87, val_accuracy=0.328, lr=0.1]   45%|████▍     | 37/83 [11:14<13:19, 17.37s/epoch, loss=1.16, accuracy=0.752, val_loss=1.81, val_accuracy=0.524, lr=0.1] 46%|████▌     | 38/83 [11:31<13:01, 17.38s/epoch, loss=1.15, accuracy=0.75, val_loss=1.4, val_accuracy=0.656, lr=0.1]   47%|████▋     | 39/83 [11:49<12:50, 17.52s/epoch, loss=1.16, accuracy=0.747, val_loss=1.67, val_accuracy=0.556, lr=0.1] 48%|████▊     | 40/83 [12:07<12:41, 17.71s/epoch, loss=1.15, accuracy=0.751, val_loss=1.87, val_accuracy=0.571, lr=0.0316] 49%|████▉     | 41/83 [12:25<12:23, 17.71s/epoch, loss=1.15, accuracy=0.75, val_loss=1.86, val_accuracy=0.532, lr=0.1]     51%|█████     | 42/83 [12:43<12:10, 17.81s/epoch, loss=1.14, accuracy=0.752, val_loss=2.03, val_accuracy=0.553, lr=0.1] 52%|█████▏    | 43/83 [13:01<11:52, 17.82s/epoch, loss=1.15, accuracy=0.751, val_loss=2.27, val_accuracy=0.419, lr=0.1] 53%|█████▎    | 44/83 [13:18<11:36, 17.85s/epoch, loss=1.15, accuracy=0.752, val_loss=1.96, val_accuracy=0.511, lr=0.1] 54%|█████▍    | 45/83 [13:36<11:15, 17.78s/epoch, loss=1.15, accuracy=0.752, val_loss=1.56, val_accuracy=0.597, lr=0.0316] 55%|█████▌    | 46/83 [13:54<11:00, 17.85s/epoch, loss=1.15, accuracy=0.753, val_loss=2.54, val_accuracy=0.385, lr=0.1]    57%|█████▋    | 47/83 [14:12<10:37, 17.72s/epoch, loss=1.15, accuracy=0.752, val_loss=2.4, val_accuracy=0.48, lr=0.1]   58%|█████▊    | 48/83 [14:29<10:18, 17.66s/epoch, loss=1.15, accuracy=0.751, val_loss=2.09, val_accuracy=0.515, lr=0.1] 59%|█████▉    | 49/83 [14:47<10:00, 17.67s/epoch, loss=1.15, accuracy=0.747, val_loss=1.94, val_accuracy=0.512, lr=0.1] 60%|██████    | 50/83 [15:05<09:44, 17.70s/epoch, loss=1.15, accuracy=0.751, val_loss=2.49, val_accuracy=0.479, lr=0.0316] 61%|██████▏   | 51/83 [15:22<09:24, 17.65s/epoch, loss=1.14, accuracy=0.753, val_loss=3.38, val_accuracy=0.364, lr=0.1]    63%|██████▎   | 52/83 [15:40<09:06, 17.64s/epoch, loss=1.14, accuracy=0.754, val_loss=1.63, val_accuracy=0.579, lr=0.1] 64%|██████▍   | 53/83 [15:57<08:46, 17.54s/epoch, loss=1.14, accuracy=0.755, val_loss=2.19, val_accuracy=0.489, lr=0.1] 65%|██████▌   | 54/83 [16:15<08:34, 17.72s/epoch, loss=1.14, accuracy=0.753, val_loss=2.88, val_accuracy=0.431, lr=0.1] 66%|██████▋   | 55/83 [16:33<08:15, 17.69s/epoch, loss=1.15, accuracy=0.752, val_loss=2.73, val_accuracy=0.281, lr=0.0316] 67%|██████▋   | 56/83 [16:50<07:55, 17.61s/epoch, loss=1.14, accuracy=0.754, val_loss=3.87, val_accuracy=0.285, lr=0.1]    69%|██████▊   | 57/83 [17:08<07:37, 17.59s/epoch, loss=1.14, accuracy=0.754, val_loss=1.87, val_accuracy=0.54, lr=0.1]  70%|██████▉   | 58/83 [17:25<07:19, 17.58s/epoch, loss=1.14, accuracy=0.756, val_loss=1.73, val_accuracy=0.55, lr=0.1] 71%|███████   | 59/83 [17:43<07:01, 17.55s/epoch, loss=1.14, accuracy=0.753, val_loss=1.55, val_accuracy=0.629, lr=0.1] 72%|███████▏  | 60/83 [18:00<06:43, 17.54s/epoch, loss=1.13, accuracy=0.754, val_loss=1.96, val_accuracy=0.513, lr=0.0316] 73%|███████▎  | 61/83 [18:18<06:26, 17.57s/epoch, loss=1.14, accuracy=0.753, val_loss=1.54, val_accuracy=0.625, lr=0.1]    75%|███████▍  | 62/83 [18:35<06:08, 17.57s/epoch, loss=1.14, accuracy=0.753, val_loss=4.29, val_accuracy=0.24, lr=0.1]  76%|███████▌  | 63/83 [18:53<05:51, 17.59s/epoch, loss=1.13, accuracy=0.755, val_loss=1.83, val_accuracy=0.512, lr=0.1] 77%|███████▋  | 64/83 [19:11<05:33, 17.58s/epoch, loss=1.13, accuracy=0.752, val_loss=2.31, val_accuracy=0.439, lr=0.1] 78%|███████▊  | 65/83 [19:28<05:15, 17.56s/epoch, loss=1.13, accuracy=0.753, val_loss=2.21, val_accuracy=0.442, lr=0.0316] 80%|███████▉  | 66/83 [19:46<05:00, 17.69s/epoch, loss=1.13, accuracy=0.757, val_loss=2.1, val_accuracy=0.444, lr=0.1]     81%|████████  | 67/83 [20:04<04:44, 17.80s/epoch, loss=1.13, accuracy=0.753, val_loss=2.17, val_accuracy=0.497, lr=0.1] 82%|████████▏ | 68/83 [20:22<04:26, 17.75s/epoch, loss=1.13, accuracy=0.753, val_loss=1.66, val_accuracy=0.578, lr=0.1] 83%|████████▎ | 69/83 [20:40<04:09, 17.79s/epoch, loss=1.13, accuracy=0.756, val_loss=2.36, val_accuracy=0.495, lr=0.1] 84%|████████▍ | 70/83 [20:57<03:49, 17.69s/epoch, loss=1.13, accuracy=0.754, val_loss=2.2, val_accuracy=0.441, lr=0.0316] 86%|████████▌ | 71/83 [21:15<03:31, 17.59s/epoch, loss=1.13, accuracy=0.756, val_loss=2.07, val_accuracy=0.398, lr=0.1]   87%|████████▋ | 72/83 [21:32<03:12, 17.54s/epoch, loss=1.13, accuracy=0.755, val_loss=2.03, val_accuracy=0.542, lr=0.1] 88%|████████▊ | 73/83 [21:50<02:56, 17.63s/epoch, loss=1.13, accuracy=0.755, val_loss=1.94, val_accuracy=0.536, lr=0.1] 89%|████████▉ | 74/83 [22:07<02:38, 17.59s/epoch, loss=1.12, accuracy=0.756, val_loss=3.24, val_accuracy=0.368, lr=0.1] 90%|█████████ | 75/83 [22:25<02:20, 17.61s/epoch, loss=1.13, accuracy=0.753, val_loss=1.62, val_accuracy=0.585, lr=0.0316] 92%|█████████▏| 76/83 [22:43<02:03, 17.64s/epoch, loss=1.13, accuracy=0.756, val_loss=1.82, val_accuracy=0.563, lr=0.1]    93%|█████████▎| 77/83 [23:00<01:45, 17.61s/epoch, loss=1.12, accuracy=0.755, val_loss=2.53, val_accuracy=0.411, lr=0.1] 94%|█████████▍| 78/83 [23:18<01:28, 17.65s/epoch, loss=1.13, accuracy=0.753, val_loss=2.86, val_accuracy=0.356, lr=0.1] 95%|█████████▌| 79/83 [23:36<01:10, 17.68s/epoch, loss=1.12, accuracy=0.756, val_loss=2.01, val_accuracy=0.464, lr=0.1] 96%|█████████▋| 80/83 [23:53<00:52, 17.61s/epoch, loss=1.12, accuracy=0.757, val_loss=2.47, val_accuracy=0.403, lr=0.0316] 98%|█████████▊| 81/83 [24:11<00:35, 17.63s/epoch, loss=1.12, accuracy=0.754, val_loss=2.27, val_accuracy=0.431, lr=0.1]    99%|█████████▉| 82/83 [24:28<00:17, 17.62s/epoch, loss=0.933, accuracy=0.812, val_loss=0.905, val_accuracy=0.802, lr=0.01]100%|██████████| 83/83 [24:46<00:00, 17.64s/epoch, loss=0.76, accuracy=0.842, val_loss=0.802, val_accuracy=0.818, lr=0.01] 100%|██████████| 83/83 [24:46<00:00, 17.91s/epoch, loss=0.76, accuracy=0.842, val_loss=0.802, val_accuracy=0.818, lr=0.01]
Using real-time data augmentation.
Test score: 0.8206949234008789
Test accuracy: 0.8062000274658203


* * * Run SGD for ID = 18_5. * * *


2024-02-20 00:41:03.308143: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 00:41:05.749464: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 00:41:05.750387: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-20 00:41:05.785934: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-20 00:41:05.786002: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 00:41:05.788578: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 00:41:05.788623: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-20 00:41:05.790615: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-20 00:41:05.791677: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-20 00:41:05.793786: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-20 00:41:05.795183: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-20 00:41:05.799358: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 00:41:05.800589: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-20 00:41:05.800666: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 00:41:07.210030: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-20 00:41:07.211409: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 00:41:07.212141: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-20 00:41:07.212173: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 00:41:07.212208: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 00:41:07.212226: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-20 00:41:07.212242: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-20 00:41:07.212257: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-20 00:41:07.212274: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-20 00:41:07.212294: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-20 00:41:07.212309: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 00:41:07.212725: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-20 00:41:07.212758: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 00:41:07.818289: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-20 00:41:07.818340: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-20 00:41:07.818355: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-20 00:41:07.819229: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:03:00.0, compute capability: 6.1)
{'id': '18_05', 'batch_size': 128, 'epochs': 83, 'validation_split': 0.1, 'checkpointing': True, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
x_train shape: (45000, 32, 32, 3)
45000 train samples
5000 validation samples
10000 test samples
y_train shape: (45000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/83 [00:00<?, ?epoch/s]2024-02-20 00:41:08.606657: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-20 00:41:08.619107: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600020000 Hz
2024-02-20 00:41:10.443622: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 00:41:10.661950: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 00:41:11.359985: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-20 00:41:11.398148: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/83 [00:44<1:01:18, 44.85s/epoch, loss=3.48, accuracy=0.229, val_loss=2.46, val_accuracy=0.239, lr=0.1]  2%|▏         | 2/83 [01:02<39:13, 29.05s/epoch, loss=1.76, accuracy=0.426, val_loss=1.77, val_accuracy=0.421, lr=0.1]    4%|▎         | 3/83 [01:20<31:33, 23.67s/epoch, loss=1.59, accuracy=0.501, val_loss=1.84, val_accuracy=0.437, lr=0.1]  5%|▍         | 4/83 [01:37<27:41, 21.03s/epoch, loss=1.4, accuracy=0.61, val_loss=2.74, val_accuracy=0.351, lr=0.1]    6%|▌         | 5/83 [01:54<25:29, 19.62s/epoch, loss=1.3, accuracy=0.665, val_loss=2.07, val_accuracy=0.418, lr=0.1]  7%|▋         | 6/83 [02:11<24:09, 18.83s/epoch, loss=1.27, accuracy=0.688, val_loss=1.9, val_accuracy=0.54, lr=0.1]   8%|▊         | 7/83 [02:28<23:13, 18.34s/epoch, loss=1.25, accuracy=0.703, val_loss=1.93, val_accuracy=0.553, lr=0.0316] 10%|▉         | 8/83 [02:45<22:17, 17.83s/epoch, loss=1.24, accuracy=0.709, val_loss=2.22, val_accuracy=0.429, lr=0.1]    11%|█         | 9/83 [03:02<21:41, 17.59s/epoch, loss=1.23, accuracy=0.719, val_loss=2.51, val_accuracy=0.363, lr=0.1] 12%|█▏        | 10/83 [03:20<21:24, 17.60s/epoch, loss=1.21, accuracy=0.727, val_loss=2.09, val_accuracy=0.511, lr=0.1] 13%|█▎        | 11/83 [03:37<20:54, 17.42s/epoch, loss=1.21, accuracy=0.728, val_loss=1.89, val_accuracy=0.54, lr=0.1]  14%|█▍        | 12/83 [03:54<20:27, 17.29s/epoch, loss=1.21, accuracy=0.728, val_loss=1.74, val_accuracy=0.53, lr=0.1] 16%|█▌        | 13/83 [04:11<20:09, 17.28s/epoch, loss=1.21, accuracy=0.732, val_loss=1.83, val_accuracy=0.49, lr=0.1] 17%|█▋        | 14/83 [04:28<19:53, 17.30s/epoch, loss=1.19, accuracy=0.733, val_loss=1.71, val_accuracy=0.602, lr=0.1] 18%|█▊        | 15/83 [04:45<19:29, 17.20s/epoch, loss=1.19, accuracy=0.735, val_loss=1.66, val_accuracy=0.591, lr=0.1] 19%|█▉        | 16/83 [05:03<19:15, 17.25s/epoch, loss=1.19, accuracy=0.735, val_loss=1.62, val_accuracy=0.58, lr=0.1]  20%|██        | 17/83 [05:20<18:52, 17.16s/epoch, loss=1.19, accuracy=0.739, val_loss=2.39, val_accuracy=0.424, lr=0.1] 22%|██▏       | 18/83 [05:37<18:32, 17.12s/epoch, loss=1.2, accuracy=0.734, val_loss=2.91, val_accuracy=0.4, lr=0.1]    23%|██▎       | 19/83 [05:54<18:12, 17.07s/epoch, loss=1.19, accuracy=0.737, val_loss=1.64, val_accuracy=0.56, lr=0.1] 24%|██▍       | 20/83 [06:10<17:51, 17.00s/epoch, loss=1.18, accuracy=0.737, val_loss=1.67, val_accuracy=0.585, lr=0.1] 25%|██▌       | 21/83 [06:27<17:32, 16.98s/epoch, loss=1.18, accuracy=0.741, val_loss=2.29, val_accuracy=0.483, lr=0.0316] 27%|██▋       | 22/83 [06:45<17:21, 17.07s/epoch, loss=1.18, accuracy=0.741, val_loss=2, val_accuracy=0.524, lr=0.1]       28%|██▊       | 23/83 [07:02<17:01, 17.03s/epoch, loss=1.18, accuracy=0.74, val_loss=2.96, val_accuracy=0.36, lr=0.1] 29%|██▉       | 24/83 [07:19<16:51, 17.15s/epoch, loss=1.17, accuracy=0.742, val_loss=1.57, val_accuracy=0.619, lr=0.1] 30%|███       | 25/83 [07:36<16:36, 17.18s/epoch, loss=1.18, accuracy=0.74, val_loss=2.62, val_accuracy=0.454, lr=0.1]  31%|███▏      | 26/83 [07:54<16:31, 17.39s/epoch, loss=1.18, accuracy=0.742, val_loss=1.51, val_accuracy=0.621, lr=0.1] 33%|███▎      | 27/83 [08:11<16:08, 17.30s/epoch, loss=1.18, accuracy=0.741, val_loss=2.94, val_accuracy=0.427, lr=0.1] 34%|███▎      | 28/83 [08:28<15:45, 17.20s/epoch, loss=1.17, accuracy=0.745, val_loss=1.83, val_accuracy=0.519, lr=0.1] 35%|███▍      | 29/83 [08:45<15:24, 17.11s/epoch, loss=1.18, accuracy=0.744, val_loss=4.45, val_accuracy=0.175, lr=0.1] 36%|███▌      | 30/83 [09:02<15:03, 17.04s/epoch, loss=1.17, accuracy=0.743, val_loss=2.06, val_accuracy=0.473, lr=0.1] 37%|███▋      | 31/83 [09:19<14:44, 17.00s/epoch, loss=1.17, accuracy=0.746, val_loss=3.03, val_accuracy=0.361, lr=0.0316] 39%|███▊      | 32/83 [09:37<14:38, 17.22s/epoch, loss=1.16, accuracy=0.748, val_loss=2.98, val_accuracy=0.362, lr=0.1]    40%|███▉      | 33/83 [09:54<14:18, 17.18s/epoch, loss=1.17, accuracy=0.746, val_loss=1.98, val_accuracy=0.494, lr=0.1] 41%|████      | 34/83 [10:11<14:03, 17.20s/epoch, loss=1.16, accuracy=0.746, val_loss=2.34, val_accuracy=0.455, lr=0.1] 42%|████▏     | 35/83 [10:28<13:49, 17.28s/epoch, loss=1.16, accuracy=0.747, val_loss=1.94, val_accuracy=0.548, lr=0.1] 43%|████▎     | 36/83 [10:46<13:41, 17.48s/epoch, loss=1.16, accuracy=0.746, val_loss=3.12, val_accuracy=0.35, lr=0.0316] 45%|████▍     | 37/83 [11:03<13:18, 17.37s/epoch, loss=1.15, accuracy=0.752, val_loss=3.81, val_accuracy=0.288, lr=0.1]   46%|████▌     | 38/83 [11:21<12:58, 17.30s/epoch, loss=1.16, accuracy=0.75, val_loss=1.89, val_accuracy=0.571, lr=0.1]  47%|████▋     | 39/83 [11:38<12:44, 17.39s/epoch, loss=1.16, accuracy=0.751, val_loss=4.07, val_accuracy=0.283, lr=0.1] 48%|████▊     | 40/83 [11:56<12:33, 17.52s/epoch, loss=1.16, accuracy=0.748, val_loss=2.07, val_accuracy=0.529, lr=0.1] 49%|████▉     | 41/83 [12:14<12:21, 17.66s/epoch, loss=1.16, accuracy=0.75, val_loss=1.45, val_accuracy=0.65, lr=0.1]   51%|█████     | 42/83 [12:32<12:02, 17.63s/epoch, loss=1.16, accuracy=0.751, val_loss=1.82, val_accuracy=0.515, lr=0.1] 52%|█████▏    | 43/83 [12:49<11:44, 17.61s/epoch, loss=1.16, accuracy=0.749, val_loss=4.21, val_accuracy=0.355, lr=0.1] 53%|█████▎    | 44/83 [13:07<11:25, 17.58s/epoch, loss=1.15, accuracy=0.749, val_loss=1.78, val_accuracy=0.562, lr=0.1] 54%|█████▍    | 45/83 [13:24<11:08, 17.60s/epoch, loss=1.15, accuracy=0.752, val_loss=1.4, val_accuracy=0.66, lr=0.1]   55%|█████▌    | 46/83 [13:42<10:50, 17.58s/epoch, loss=1.14, accuracy=0.754, val_loss=1.49, val_accuracy=0.63, lr=0.1] 57%|█████▋    | 47/83 [14:00<10:34, 17.62s/epoch, loss=1.15, accuracy=0.753, val_loss=3.71, val_accuracy=0.347, lr=0.1] 58%|█████▊    | 48/83 [14:17<10:17, 17.65s/epoch, loss=1.15, accuracy=0.749, val_loss=3.41, val_accuracy=0.348, lr=0.1] 59%|█████▉    | 49/83 [14:35<10:03, 17.74s/epoch, loss=1.15, accuracy=0.752, val_loss=1.59, val_accuracy=0.61, lr=0.1]  60%|██████    | 50/83 [14:53<09:44, 17.70s/epoch, loss=1.14, accuracy=0.752, val_loss=2.62, val_accuracy=0.46, lr=0.0316] 61%|██████▏   | 51/83 [15:10<09:24, 17.66s/epoch, loss=1.14, accuracy=0.755, val_loss=1.75, val_accuracy=0.545, lr=0.1]   63%|██████▎   | 52/83 [15:28<09:09, 17.73s/epoch, loss=1.14, accuracy=0.751, val_loss=6.31, val_accuracy=0.299, lr=0.1] 64%|██████▍   | 53/83 [15:46<08:51, 17.72s/epoch, loss=1.15, accuracy=0.753, val_loss=1.81, val_accuracy=0.536, lr=0.1] 65%|██████▌   | 54/83 [16:04<08:35, 17.77s/epoch, loss=1.14, accuracy=0.751, val_loss=2.04, val_accuracy=0.534, lr=0.1] 66%|██████▋   | 55/83 [16:21<08:12, 17.57s/epoch, loss=1.14, accuracy=0.752, val_loss=2.23, val_accuracy=0.413, lr=0.0316] 67%|██████▋   | 56/83 [16:38<07:50, 17.41s/epoch, loss=1.14, accuracy=0.752, val_loss=1.72, val_accuracy=0.556, lr=0.1]    69%|██████▊   | 57/83 [16:55<07:30, 17.31s/epoch, loss=1.14, accuracy=0.752, val_loss=2.55, val_accuracy=0.309, lr=0.1] 70%|██████▉   | 58/83 [17:12<07:09, 17.17s/epoch, loss=1.14, accuracy=0.752, val_loss=2.28, val_accuracy=0.418, lr=0.1] 71%|███████   | 59/83 [17:29<06:52, 17.18s/epoch, loss=1.13, accuracy=0.755, val_loss=1.97, val_accuracy=0.516, lr=0.1] 72%|███████▏  | 60/83 [17:46<06:33, 17.11s/epoch, loss=1.13, accuracy=0.753, val_loss=2.03, val_accuracy=0.479, lr=0.0316] 73%|███████▎  | 61/83 [18:03<06:16, 17.13s/epoch, loss=1.13, accuracy=0.758, val_loss=1.57, val_accuracy=0.611, lr=0.1]    75%|███████▍  | 62/83 [18:20<05:58, 17.08s/epoch, loss=1.14, accuracy=0.753, val_loss=2.77, val_accuracy=0.418, lr=0.1] 76%|███████▌  | 63/83 [18:37<05:41, 17.08s/epoch, loss=1.14, accuracy=0.755, val_loss=1.67, val_accuracy=0.597, lr=0.1] 77%|███████▋  | 64/83 [18:54<05:23, 17.00s/epoch, loss=1.13, accuracy=0.756, val_loss=2.67, val_accuracy=0.51, lr=0.1]  78%|███████▊  | 65/83 [19:11<05:06, 17.04s/epoch, loss=1.13, accuracy=0.754, val_loss=2.34, val_accuracy=0.425, lr=0.0316] 80%|███████▉  | 66/83 [19:28<04:49, 17.01s/epoch, loss=1.13, accuracy=0.754, val_loss=1.69, val_accuracy=0.599, lr=0.1]    81%|████████  | 67/83 [19:45<04:32, 17.03s/epoch, loss=1.13, accuracy=0.752, val_loss=10.3, val_accuracy=0.145, lr=0.1] 82%|████████▏ | 68/83 [20:03<04:16, 17.10s/epoch, loss=1.13, accuracy=0.752, val_loss=1.95, val_accuracy=0.465, lr=0.1] 83%|████████▎ | 69/83 [20:19<03:57, 16.98s/epoch, loss=1.14, accuracy=0.753, val_loss=1.75, val_accuracy=0.541, lr=0.1] 84%|████████▍ | 70/83 [20:36<03:40, 16.94s/epoch, loss=1.13, accuracy=0.755, val_loss=4.03, val_accuracy=0.355, lr=0.0316] 86%|████████▌ | 71/83 [20:53<03:22, 16.84s/epoch, loss=1.13, accuracy=0.752, val_loss=1.67, val_accuracy=0.575, lr=0.1]    87%|████████▋ | 72/83 [21:10<03:05, 16.88s/epoch, loss=1.13, accuracy=0.755, val_loss=1.37, val_accuracy=0.672, lr=0.1] 88%|████████▊ | 73/83 [21:27<02:49, 16.98s/epoch, loss=1.13, accuracy=0.753, val_loss=1.92, val_accuracy=0.511, lr=0.1] 89%|████████▉ | 74/83 [21:44<02:32, 16.96s/epoch, loss=1.14, accuracy=0.752, val_loss=1.58, val_accuracy=0.626, lr=0.1] 90%|█████████ | 75/83 [22:01<02:15, 16.93s/epoch, loss=1.13, accuracy=0.755, val_loss=2.93, val_accuracy=0.362, lr=0.1] 92%|█████████▏| 76/83 [22:17<01:58, 16.88s/epoch, loss=1.13, accuracy=0.755, val_loss=1.63, val_accuracy=0.582, lr=0.1] 93%|█████████▎| 77/83 [22:34<01:41, 16.86s/epoch, loss=1.14, accuracy=0.752, val_loss=1.68, val_accuracy=0.581, lr=0.0316] 94%|█████████▍| 78/83 [22:52<01:25, 17.00s/epoch, loss=1.13, accuracy=0.755, val_loss=1.98, val_accuracy=0.46, lr=0.1]     95%|█████████▌| 79/83 [23:08<01:07, 16.89s/epoch, loss=1.13, accuracy=0.755, val_loss=1.88, val_accuracy=0.521, lr=0.1] 96%|█████████▋| 80/83 [23:25<00:50, 16.96s/epoch, loss=1.13, accuracy=0.755, val_loss=2.01, val_accuracy=0.504, lr=0.1] 98%|█████████▊| 81/83 [23:43<00:34, 17.09s/epoch, loss=1.13, accuracy=0.755, val_loss=2.27, val_accuracy=0.435, lr=0.1] 99%|█████████▉| 82/83 [24:00<00:17, 17.09s/epoch, loss=0.927, accuracy=0.813, val_loss=0.873, val_accuracy=0.816, lr=0.01]100%|██████████| 83/83 [24:17<00:00, 17.04s/epoch, loss=0.755, accuracy=0.845, val_loss=0.839, val_accuracy=0.801, lr=0.01]100%|██████████| 83/83 [24:17<00:00, 17.56s/epoch, loss=0.755, accuracy=0.845, val_loss=0.839, val_accuracy=0.801, lr=0.01]
Using real-time data augmentation.
Test score: 0.9013365507125854
Test accuracy: 0.8069000244140625


* * * Run SGD for ID = 18_6. * * *


2024-02-20 01:05:32.696275: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 01:05:38.545699: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 01:05:38.546684: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-20 01:05:38.582417: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-20 01:05:38.582446: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 01:05:38.587989: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 01:05:38.588029: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-20 01:05:38.591849: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-20 01:05:38.594374: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-20 01:05:38.597949: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-20 01:05:38.600668: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-20 01:05:38.606885: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 01:05:38.607485: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-20 01:05:38.607563: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 01:05:40.018148: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-20 01:05:40.019173: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 01:05:40.019898: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-20 01:05:40.019928: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 01:05:40.020007: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 01:05:40.020026: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-20 01:05:40.020043: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-20 01:05:40.020059: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-20 01:05:40.020074: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-20 01:05:40.020097: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-20 01:05:40.020112: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 01:05:40.020556: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-20 01:05:40.020592: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 01:05:40.605715: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-20 01:05:40.605765: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-20 01:05:40.605772: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-20 01:05:40.606587: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:03:00.0, compute capability: 6.1)
{'id': '18_06', 'batch_size': 128, 'epochs': 83, 'validation_split': 0.1, 'checkpointing': True, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
x_train shape: (45000, 32, 32, 3)
45000 train samples
5000 validation samples
10000 test samples
y_train shape: (45000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/83 [00:00<?, ?epoch/s]2024-02-20 01:05:41.383690: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-20 01:05:41.396083: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600020000 Hz
2024-02-20 01:05:43.225684: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 01:05:43.449128: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 01:05:44.073470: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-20 01:05:44.124099: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/83 [00:52<1:11:31, 52.34s/epoch, loss=3.44, accuracy=0.191, val_loss=2.35, val_accuracy=0.185, lr=0.1]  2%|▏         | 2/83 [01:10<43:13, 32.02s/epoch, loss=1.65, accuracy=0.479, val_loss=1.94, val_accuracy=0.433, lr=0.1]    4%|▎         | 3/83 [01:26<33:25, 25.07s/epoch, loss=1.39, accuracy=0.611, val_loss=1.99, val_accuracy=0.443, lr=0.1]  5%|▍         | 4/83 [01:44<28:53, 21.94s/epoch, loss=1.3, accuracy=0.67, val_loss=1.86, val_accuracy=0.518, lr=0.1]    6%|▌         | 5/83 [02:01<26:14, 20.18s/epoch, loss=1.25, accuracy=0.693, val_loss=1.59, val_accuracy=0.58, lr=0.1]  7%|▋         | 6/83 [02:17<24:23, 19.01s/epoch, loss=1.24, accuracy=0.705, val_loss=1.8, val_accuracy=0.543, lr=0.1]  8%|▊         | 7/83 [02:34<23:13, 18.33s/epoch, loss=1.23, accuracy=0.711, val_loss=2.8, val_accuracy=0.398, lr=0.1] 10%|▉         | 8/83 [02:51<22:22, 17.90s/epoch, loss=1.21, accuracy=0.72, val_loss=1.42, val_accuracy=0.655, lr=0.1] 11%|█         | 9/83 [03:08<21:42, 17.60s/epoch, loss=1.2, accuracy=0.724, val_loss=1.93, val_accuracy=0.484, lr=0.1] 12%|█▏        | 10/83 [03:25<21:08, 17.37s/epoch, loss=1.2, accuracy=0.73, val_loss=1.46, val_accuracy=0.64, lr=0.1]  13%|█▎        | 11/83 [03:42<20:45, 17.29s/epoch, loss=1.19, accuracy=0.73, val_loss=3.66, val_accuracy=0.3, lr=0.1] 14%|█▍        | 12/83 [03:59<20:21, 17.20s/epoch, loss=1.18, accuracy=0.735, val_loss=1.79, val_accuracy=0.579, lr=0.1] 16%|█▌        | 13/83 [04:16<20:03, 17.20s/epoch, loss=1.18, accuracy=0.735, val_loss=2.31, val_accuracy=0.462, lr=0.0316] 17%|█▋        | 14/83 [04:33<19:41, 17.12s/epoch, loss=1.18, accuracy=0.735, val_loss=1.89, val_accuracy=0.514, lr=0.1]    18%|█▊        | 15/83 [04:50<19:24, 17.13s/epoch, loss=1.18, accuracy=0.739, val_loss=1.78, val_accuracy=0.561, lr=0.1] 19%|█▉        | 16/83 [05:08<19:08, 17.14s/epoch, loss=1.17, accuracy=0.738, val_loss=2, val_accuracy=0.452, lr=0.1]    20%|██        | 17/83 [05:25<18:47, 17.09s/epoch, loss=1.17, accuracy=0.742, val_loss=2.46, val_accuracy=0.514, lr=0.1] 22%|██▏       | 18/83 [05:41<18:26, 17.03s/epoch, loss=1.16, accuracy=0.745, val_loss=2.13, val_accuracy=0.509, lr=0.0316] 23%|██▎       | 19/83 [05:58<18:06, 16.98s/epoch, loss=1.16, accuracy=0.745, val_loss=1.69, val_accuracy=0.564, lr=0.1]    24%|██▍       | 20/83 [06:16<17:57, 17.10s/epoch, loss=1.16, accuracy=0.746, val_loss=2.02, val_accuracy=0.486, lr=0.1] 25%|██▌       | 21/83 [06:33<17:35, 17.03s/epoch, loss=1.16, accuracy=0.744, val_loss=1.88, val_accuracy=0.484, lr=0.1] 27%|██▋       | 22/83 [06:49<17:14, 16.96s/epoch, loss=1.15, accuracy=0.747, val_loss=2.81, val_accuracy=0.369, lr=0.1] 28%|██▊       | 23/83 [07:06<16:55, 16.92s/epoch, loss=1.16, accuracy=0.746, val_loss=1.81, val_accuracy=0.556, lr=0.0316] 29%|██▉       | 24/83 [07:23<16:42, 16.99s/epoch, loss=1.14, accuracy=0.749, val_loss=3.87, val_accuracy=0.327, lr=0.1]    30%|███       | 25/83 [07:40<16:23, 16.96s/epoch, loss=1.16, accuracy=0.745, val_loss=1.8, val_accuracy=0.522, lr=0.1]  31%|███▏      | 26/83 [07:57<16:05, 16.94s/epoch, loss=1.15, accuracy=0.748, val_loss=2.23, val_accuracy=0.459, lr=0.1] 33%|███▎      | 27/83 [08:14<15:54, 17.04s/epoch, loss=1.14, accuracy=0.753, val_loss=1.74, val_accuracy=0.582, lr=0.1] 34%|███▎      | 28/83 [08:32<15:44, 17.18s/epoch, loss=1.14, accuracy=0.751, val_loss=1.4, val_accuracy=0.677, lr=0.1]  35%|███▍      | 29/83 [08:49<15:22, 17.08s/epoch, loss=1.15, accuracy=0.75, val_loss=1.79, val_accuracy=0.498, lr=0.1] 36%|███▌      | 30/83 [09:06<15:12, 17.23s/epoch, loss=1.14, accuracy=0.748, val_loss=1.99, val_accuracy=0.52, lr=0.1] 37%|███▋      | 31/83 [09:24<14:56, 17.25s/epoch, loss=1.15, accuracy=0.748, val_loss=2.4, val_accuracy=0.366, lr=0.1] 39%|███▊      | 32/83 [09:41<14:37, 17.20s/epoch, loss=1.14, accuracy=0.75, val_loss=1.57, val_accuracy=0.622, lr=0.1] 40%|███▉      | 33/83 [09:58<14:14, 17.09s/epoch, loss=1.14, accuracy=0.75, val_loss=1.63, val_accuracy=0.59, lr=0.0316] 41%|████      | 34/83 [10:14<13:53, 17.02s/epoch, loss=1.14, accuracy=0.751, val_loss=2.21, val_accuracy=0.455, lr=0.1]  42%|████▏     | 35/83 [10:31<13:37, 17.02s/epoch, loss=1.14, accuracy=0.751, val_loss=1.51, val_accuracy=0.633, lr=0.1] 43%|████▎     | 36/83 [10:49<13:22, 17.07s/epoch, loss=1.14, accuracy=0.748, val_loss=1.73, val_accuracy=0.548, lr=0.1] 45%|████▍     | 37/83 [11:06<13:04, 17.06s/epoch, loss=1.13, accuracy=0.752, val_loss=2.05, val_accuracy=0.502, lr=0.1] 46%|████▌     | 38/83 [11:24<12:59, 17.32s/epoch, loss=1.13, accuracy=0.753, val_loss=2.19, val_accuracy=0.475, lr=0.0316] 47%|████▋     | 39/83 [11:41<12:37, 17.22s/epoch, loss=1.14, accuracy=0.753, val_loss=2.92, val_accuracy=0.426, lr=0.1]    48%|████▊     | 40/83 [11:58<12:26, 17.36s/epoch, loss=1.13, accuracy=0.753, val_loss=3.1, val_accuracy=0.417, lr=0.1]  49%|████▉     | 41/83 [12:16<12:08, 17.35s/epoch, loss=1.13, accuracy=0.753, val_loss=1.48, val_accuracy=0.631, lr=0.1] 51%|█████     | 42/83 [12:33<11:47, 17.26s/epoch, loss=1.13, accuracy=0.753, val_loss=2.15, val_accuracy=0.475, lr=0.1] 52%|█████▏    | 43/83 [12:50<11:28, 17.22s/epoch, loss=1.13, accuracy=0.752, val_loss=1.54, val_accuracy=0.622, lr=0.0316] 53%|█████▎    | 44/83 [13:07<11:13, 17.26s/epoch, loss=1.13, accuracy=0.753, val_loss=3.05, val_accuracy=0.403, lr=0.1]    54%|█████▍    | 45/83 [13:25<11:00, 17.37s/epoch, loss=1.13, accuracy=0.752, val_loss=3.24, val_accuracy=0.417, lr=0.1] 55%|█████▌    | 46/83 [13:42<10:42, 17.36s/epoch, loss=1.12, accuracy=0.754, val_loss=1.48, val_accuracy=0.635, lr=0.1] 57%|█████▋    | 47/83 [14:00<10:25, 17.38s/epoch, loss=1.13, accuracy=0.754, val_loss=2.18, val_accuracy=0.459, lr=0.1] 58%|█████▊    | 48/83 [14:17<10:09, 17.40s/epoch, loss=1.13, accuracy=0.752, val_loss=1.82, val_accuracy=0.543, lr=0.0316] 59%|█████▉    | 49/83 [14:35<09:53, 17.46s/epoch, loss=1.12, accuracy=0.753, val_loss=1.89, val_accuracy=0.482, lr=0.1]    60%|██████    | 50/83 [14:52<09:34, 17.41s/epoch, loss=1.13, accuracy=0.754, val_loss=2.36, val_accuracy=0.425, lr=0.1] 61%|██████▏   | 51/83 [15:09<09:14, 17.34s/epoch, loss=1.13, accuracy=0.754, val_loss=1.94, val_accuracy=0.515, lr=0.1] 63%|██████▎   | 52/83 [15:27<08:59, 17.42s/epoch, loss=1.13, accuracy=0.754, val_loss=2.78, val_accuracy=0.412, lr=0.1] 64%|██████▍   | 53/83 [15:44<08:40, 17.36s/epoch, loss=1.13, accuracy=0.755, val_loss=1.52, val_accuracy=0.614, lr=0.0316] 65%|██████▌   | 54/83 [16:01<08:21, 17.28s/epoch, loss=1.12, accuracy=0.757, val_loss=2.51, val_accuracy=0.313, lr=0.1]    66%|██████▋   | 55/83 [16:18<08:03, 17.25s/epoch, loss=1.12, accuracy=0.757, val_loss=1.69, val_accuracy=0.555, lr=0.1] 67%|██████▋   | 56/83 [16:35<07:43, 17.16s/epoch, loss=1.12, accuracy=0.758, val_loss=3.02, val_accuracy=0.393, lr=0.1] 69%|██████▊   | 57/83 [16:52<07:25, 17.12s/epoch, loss=1.12, accuracy=0.756, val_loss=2.07, val_accuracy=0.493, lr=0.1] 70%|██████▉   | 58/83 [17:10<07:10, 17.23s/epoch, loss=1.12, accuracy=0.754, val_loss=1.69, val_accuracy=0.582, lr=0.0316] 71%|███████   | 59/83 [17:27<06:53, 17.23s/epoch, loss=1.12, accuracy=0.756, val_loss=1.87, val_accuracy=0.493, lr=0.1]    72%|███████▏  | 60/83 [17:45<06:39, 17.39s/epoch, loss=1.12, accuracy=0.755, val_loss=2.26, val_accuracy=0.459, lr=0.1] 73%|███████▎  | 61/83 [18:02<06:20, 17.31s/epoch, loss=1.12, accuracy=0.759, val_loss=2.18, val_accuracy=0.451, lr=0.1] 75%|███████▍  | 62/83 [18:19<06:04, 17.37s/epoch, loss=1.12, accuracy=0.754, val_loss=1.93, val_accuracy=0.548, lr=0.1] 76%|███████▌  | 63/83 [18:36<05:45, 17.26s/epoch, loss=1.12, accuracy=0.759, val_loss=1.71, val_accuracy=0.535, lr=0.0316] 77%|███████▋  | 64/83 [18:54<05:30, 17.37s/epoch, loss=1.13, accuracy=0.755, val_loss=1.8, val_accuracy=0.517, lr=0.1]     78%|███████▊  | 65/83 [19:11<05:13, 17.42s/epoch, loss=1.12, accuracy=0.758, val_loss=2.42, val_accuracy=0.374, lr=0.1] 80%|███████▉  | 66/83 [19:29<04:57, 17.50s/epoch, loss=1.12, accuracy=0.757, val_loss=1.33, val_accuracy=0.696, lr=0.1] 81%|████████  | 67/83 [19:46<04:39, 17.47s/epoch, loss=1.12, accuracy=0.757, val_loss=2.79, val_accuracy=0.403, lr=0.1] 82%|████████▏ | 68/83 [20:04<04:22, 17.47s/epoch, loss=1.11, accuracy=0.758, val_loss=2.26, val_accuracy=0.527, lr=0.1] 83%|████████▎ | 69/83 [20:22<04:05, 17.52s/epoch, loss=1.11, accuracy=0.756, val_loss=3.76, val_accuracy=0.351, lr=0.1] 84%|████████▍ | 70/83 [20:39<03:48, 17.56s/epoch, loss=1.12, accuracy=0.755, val_loss=2.08, val_accuracy=0.479, lr=0.1] 86%|████████▌ | 71/83 [20:57<03:30, 17.56s/epoch, loss=1.12, accuracy=0.757, val_loss=2.2, val_accuracy=0.528, lr=0.0316] 87%|████████▋ | 72/83 [21:14<03:12, 17.54s/epoch, loss=1.12, accuracy=0.758, val_loss=1.98, val_accuracy=0.509, lr=0.1]   88%|████████▊ | 73/83 [21:32<02:54, 17.47s/epoch, loss=1.12, accuracy=0.756, val_loss=1.62, val_accuracy=0.594, lr=0.1] 89%|████████▉ | 74/83 [21:49<02:36, 17.37s/epoch, loss=1.12, accuracy=0.756, val_loss=2.65, val_accuracy=0.433, lr=0.1] 90%|█████████ | 75/83 [22:06<02:19, 17.45s/epoch, loss=1.12, accuracy=0.754, val_loss=4.08, val_accuracy=0.318, lr=0.1] 92%|█████████▏| 76/83 [22:24<02:02, 17.47s/epoch, loss=1.12, accuracy=0.757, val_loss=1.81, val_accuracy=0.55, lr=0.0316] 93%|█████████▎| 77/83 [22:41<01:44, 17.47s/epoch, loss=1.12, accuracy=0.757, val_loss=2.59, val_accuracy=0.428, lr=0.1]   94%|█████████▍| 78/83 [22:59<01:27, 17.50s/epoch, loss=1.11, accuracy=0.759, val_loss=2.53, val_accuracy=0.393, lr=0.1] 95%|█████████▌| 79/83 [23:17<01:10, 17.55s/epoch, loss=1.12, accuracy=0.756, val_loss=2.94, val_accuracy=0.334, lr=0.1] 96%|█████████▋| 80/83 [23:34<00:52, 17.47s/epoch, loss=1.12, accuracy=0.755, val_loss=1.68, val_accuracy=0.582, lr=0.1] 98%|█████████▊| 81/83 [23:51<00:34, 17.48s/epoch, loss=1.13, accuracy=0.753, val_loss=2.51, val_accuracy=0.47, lr=0.0316] 99%|█████████▉| 82/83 [24:09<00:17, 17.48s/epoch, loss=0.934, accuracy=0.81, val_loss=0.965, val_accuracy=0.779, lr=0.01]100%|██████████| 83/83 [24:26<00:00, 17.45s/epoch, loss=0.751, accuracy=0.846, val_loss=0.819, val_accuracy=0.814, lr=0.01]100%|██████████| 83/83 [24:26<00:00, 17.67s/epoch, loss=0.751, accuracy=0.846, val_loss=0.819, val_accuracy=0.814, lr=0.01]
Using real-time data augmentation.
Test score: 0.8353596925735474
Test accuracy: 0.8086000084877014


* * * Run SGD for ID = 18_7. * * *


2024-02-20 01:30:13.695304: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 01:30:16.651075: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 01:30:16.652083: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-20 01:30:16.688491: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-20 01:30:16.688517: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 01:30:16.691620: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 01:30:16.691658: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-20 01:30:16.693853: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-20 01:30:16.694495: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-20 01:30:16.696705: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-20 01:30:16.698432: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-20 01:30:16.703065: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 01:30:16.703558: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-20 01:30:16.703631: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 01:30:18.114442: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-20 01:30:18.115431: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 01:30:18.116187: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-20 01:30:18.116218: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 01:30:18.116252: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 01:30:18.116268: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-20 01:30:18.116284: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-20 01:30:18.116299: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-20 01:30:18.116314: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-20 01:30:18.116336: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-20 01:30:18.116351: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 01:30:18.116775: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-20 01:30:18.116808: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 01:30:18.713770: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-20 01:30:18.713823: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-20 01:30:18.713839: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-20 01:30:18.714707: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:03:00.0, compute capability: 6.1)
{'id': '18_07', 'batch_size': 128, 'epochs': 83, 'validation_split': 0.1, 'checkpointing': True, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
x_train shape: (45000, 32, 32, 3)
45000 train samples
5000 validation samples
10000 test samples
y_train shape: (45000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/83 [00:00<?, ?epoch/s]2024-02-20 01:30:19.503780: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-20 01:30:19.516090: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600020000 Hz
2024-02-20 01:30:21.371979: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 01:30:21.583008: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 01:30:22.253240: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-20 01:30:22.293389: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/83 [00:47<1:05:00, 47.57s/epoch, loss=3.51, accuracy=0.284, val_loss=2.45, val_accuracy=0.196, lr=0.1]  2%|▏         | 2/83 [01:06<41:12, 30.52s/epoch, loss=1.71, accuracy=0.469, val_loss=2.44, val_accuracy=0.298, lr=0.1]    4%|▎         | 3/83 [01:24<33:28, 25.10s/epoch, loss=1.51, accuracy=0.549, val_loss=2.52, val_accuracy=0.356, lr=0.1]  5%|▍         | 4/83 [01:43<29:38, 22.52s/epoch, loss=1.4, accuracy=0.612, val_loss=2.05, val_accuracy=0.42, lr=0.1]    6%|▌         | 5/83 [02:02<27:38, 21.27s/epoch, loss=1.31, accuracy=0.665, val_loss=1.75, val_accuracy=0.547, lr=0.1]  7%|▋         | 6/83 [02:20<26:02, 20.30s/epoch, loss=1.27, accuracy=0.692, val_loss=2.16, val_accuracy=0.439, lr=0.1]  8%|▊         | 7/83 [02:39<24:59, 19.73s/epoch, loss=1.25, accuracy=0.706, val_loss=3.31, val_accuracy=0.27, lr=0.1]  10%|▉         | 8/83 [02:58<24:20, 19.47s/epoch, loss=1.24, accuracy=0.714, val_loss=2.33, val_accuracy=0.469, lr=0.1] 11%|█         | 9/83 [03:16<23:26, 19.01s/epoch, loss=1.23, accuracy=0.717, val_loss=1.78, val_accuracy=0.519, lr=0.1] 12%|█▏        | 10/83 [03:34<22:39, 18.62s/epoch, loss=1.22, accuracy=0.725, val_loss=2.02, val_accuracy=0.536, lr=0.0316] 13%|█▎        | 11/83 [03:51<22:03, 18.39s/epoch, loss=1.22, accuracy=0.726, val_loss=1.66, val_accuracy=0.564, lr=0.1]    14%|█▍        | 12/83 [04:09<21:33, 18.22s/epoch, loss=1.21, accuracy=0.731, val_loss=2.23, val_accuracy=0.456, lr=0.1] 16%|█▌        | 13/83 [04:27<21:15, 18.23s/epoch, loss=1.2, accuracy=0.733, val_loss=1.48, val_accuracy=0.626, lr=0.1]  17%|█▋        | 14/83 [04:45<20:43, 18.02s/epoch, loss=1.21, accuracy=0.731, val_loss=2.52, val_accuracy=0.469, lr=0.1] 18%|█▊        | 15/83 [05:03<20:23, 17.99s/epoch, loss=1.2, accuracy=0.732, val_loss=1.88, val_accuracy=0.503, lr=0.1]  19%|█▉        | 16/83 [05:21<20:01, 17.94s/epoch, loss=1.19, accuracy=0.74, val_loss=1.78, val_accuracy=0.567, lr=0.1] 20%|██        | 17/83 [05:39<19:46, 17.98s/epoch, loss=1.2, accuracy=0.739, val_loss=1.75, val_accuracy=0.55, lr=0.1]  22%|██▏       | 18/83 [05:57<19:33, 18.05s/epoch, loss=1.19, accuracy=0.741, val_loss=1.91, val_accuracy=0.505, lr=0.0316] 23%|██▎       | 19/83 [06:15<19:19, 18.11s/epoch, loss=1.19, accuracy=0.743, val_loss=1.97, val_accuracy=0.558, lr=0.1]    24%|██▍       | 20/83 [06:33<18:58, 18.07s/epoch, loss=1.19, accuracy=0.743, val_loss=2.16, val_accuracy=0.465, lr=0.1] 25%|██▌       | 21/83 [06:51<18:33, 17.96s/epoch, loss=1.19, accuracy=0.744, val_loss=1.75, val_accuracy=0.569, lr=0.1] 27%|██▋       | 22/83 [07:09<18:09, 17.86s/epoch, loss=1.19, accuracy=0.744, val_loss=2.77, val_accuracy=0.281, lr=0.1] 28%|██▊       | 23/83 [07:26<17:47, 17.79s/epoch, loss=1.18, accuracy=0.745, val_loss=1.45, val_accuracy=0.632, lr=0.1] 29%|██▉       | 24/83 [07:44<17:24, 17.71s/epoch, loss=1.18, accuracy=0.743, val_loss=1.97, val_accuracy=0.501, lr=0.1] 30%|███       | 25/83 [08:01<17:03, 17.65s/epoch, loss=1.18, accuracy=0.745, val_loss=2.32, val_accuracy=0.433, lr=0.1] 31%|███▏      | 26/83 [08:19<16:44, 17.62s/epoch, loss=1.17, accuracy=0.747, val_loss=2.2, val_accuracy=0.463, lr=0.1]  33%|███▎      | 27/83 [08:37<16:35, 17.78s/epoch, loss=1.18, accuracy=0.747, val_loss=2.35, val_accuracy=0.402, lr=0.1] 34%|███▎      | 28/83 [08:55<16:17, 17.78s/epoch, loss=1.17, accuracy=0.751, val_loss=1.5, val_accuracy=0.632, lr=0.0316] 35%|███▍      | 29/83 [09:12<15:59, 17.76s/epoch, loss=1.18, accuracy=0.747, val_loss=2.62, val_accuracy=0.307, lr=0.1]   36%|███▌      | 30/83 [09:30<15:41, 17.76s/epoch, loss=1.17, accuracy=0.748, val_loss=2.27, val_accuracy=0.493, lr=0.1] 37%|███▋      | 31/83 [09:48<15:24, 17.78s/epoch, loss=1.17, accuracy=0.747, val_loss=1.89, val_accuracy=0.51, lr=0.1]  39%|███▊      | 32/83 [10:06<15:03, 17.72s/epoch, loss=1.17, accuracy=0.747, val_loss=3.08, val_accuracy=0.372, lr=0.1] 40%|███▉      | 33/83 [10:24<14:48, 17.76s/epoch, loss=1.17, accuracy=0.75, val_loss=3.18, val_accuracy=0.286, lr=0.0316] 41%|████      | 34/83 [10:41<14:30, 17.77s/epoch, loss=1.16, accuracy=0.751, val_loss=2.14, val_accuracy=0.525, lr=0.1]   42%|████▏     | 35/83 [10:59<14:12, 17.77s/epoch, loss=1.16, accuracy=0.749, val_loss=1.64, val_accuracy=0.572, lr=0.1] 43%|████▎     | 36/83 [11:17<13:57, 17.82s/epoch, loss=1.16, accuracy=0.749, val_loss=5.86, val_accuracy=0.189, lr=0.1] 45%|████▍     | 37/83 [11:35<13:38, 17.79s/epoch, loss=1.16, accuracy=0.749, val_loss=1.97, val_accuracy=0.558, lr=0.1] 46%|████▌     | 38/83 [11:52<13:17, 17.72s/epoch, loss=1.16, accuracy=0.749, val_loss=1.86, val_accuracy=0.561, lr=0.0316] 47%|████▋     | 39/83 [12:10<12:59, 17.71s/epoch, loss=1.15, accuracy=0.753, val_loss=2.77, val_accuracy=0.273, lr=0.1]    48%|████▊     | 40/83 [12:28<12:42, 17.74s/epoch, loss=1.16, accuracy=0.75, val_loss=1.9, val_accuracy=0.551, lr=0.1]   49%|████▉     | 41/83 [12:45<12:23, 17.71s/epoch, loss=1.15, accuracy=0.754, val_loss=2.29, val_accuracy=0.422, lr=0.1] 51%|█████     | 42/83 [13:04<12:10, 17.83s/epoch, loss=1.15, accuracy=0.754, val_loss=1.65, val_accuracy=0.58, lr=0.1]  52%|█████▏    | 43/83 [13:21<11:53, 17.84s/epoch, loss=1.15, accuracy=0.753, val_loss=3.14, val_accuracy=0.251, lr=0.0316] 53%|█████▎    | 44/83 [13:40<11:42, 18.02s/epoch, loss=1.14, accuracy=0.754, val_loss=1.74, val_accuracy=0.585, lr=0.1]    54%|█████▍    | 45/83 [13:58<11:22, 17.95s/epoch, loss=1.14, accuracy=0.753, val_loss=1.71, val_accuracy=0.583, lr=0.1] 55%|█████▌    | 46/83 [14:15<11:03, 17.92s/epoch, loss=1.15, accuracy=0.754, val_loss=2.07, val_accuracy=0.5, lr=0.1]   57%|█████▋    | 47/83 [14:33<10:45, 17.92s/epoch, loss=1.14, accuracy=0.755, val_loss=1.49, val_accuracy=0.619, lr=0.1] 58%|█████▊    | 48/83 [14:51<10:26, 17.89s/epoch, loss=1.14, accuracy=0.753, val_loss=1.49, val_accuracy=0.621, lr=0.0316] 59%|█████▉    | 49/83 [15:09<10:10, 17.95s/epoch, loss=1.15, accuracy=0.754, val_loss=9.89, val_accuracy=0.135, lr=0.1]    60%|██████    | 50/83 [15:28<09:56, 18.08s/epoch, loss=1.14, accuracy=0.754, val_loss=1.61, val_accuracy=0.628, lr=0.1] 61%|██████▏   | 51/83 [15:47<09:47, 18.35s/epoch, loss=1.14, accuracy=0.754, val_loss=1.61, val_accuracy=0.593, lr=0.1] 63%|██████▎   | 52/83 [16:04<09:23, 18.17s/epoch, loss=1.14, accuracy=0.753, val_loss=1.72, val_accuracy=0.566, lr=0.1] 64%|██████▍   | 53/83 [16:22<09:00, 18.02s/epoch, loss=1.14, accuracy=0.754, val_loss=1.96, val_accuracy=0.517, lr=0.0316] 65%|██████▌   | 54/83 [16:40<08:40, 17.95s/epoch, loss=1.13, accuracy=0.756, val_loss=2.7, val_accuracy=0.416, lr=0.1]     66%|██████▋   | 55/83 [16:58<08:21, 17.90s/epoch, loss=1.14, accuracy=0.753, val_loss=2.06, val_accuracy=0.51, lr=0.1] 67%|██████▋   | 56/83 [17:15<08:01, 17.85s/epoch, loss=1.14, accuracy=0.755, val_loss=1.88, val_accuracy=0.564, lr=0.1] 69%|██████▊   | 57/83 [17:33<07:45, 17.90s/epoch, loss=1.14, accuracy=0.753, val_loss=1.63, val_accuracy=0.589, lr=0.1] 70%|██████▉   | 58/83 [17:51<07:26, 17.87s/epoch, loss=1.13, accuracy=0.757, val_loss=1.65, val_accuracy=0.57, lr=0.0316] 71%|███████   | 59/83 [18:09<07:07, 17.80s/epoch, loss=1.14, accuracy=0.752, val_loss=1.81, val_accuracy=0.534, lr=0.1]   72%|███████▏  | 60/83 [18:27<06:48, 17.77s/epoch, loss=1.13, accuracy=0.756, val_loss=2.01, val_accuracy=0.5, lr=0.1]   73%|███████▎  | 61/83 [18:44<06:30, 17.73s/epoch, loss=1.13, accuracy=0.757, val_loss=5.01, val_accuracy=0.206, lr=0.1] 75%|███████▍  | 62/83 [19:02<06:11, 17.69s/epoch, loss=1.13, accuracy=0.755, val_loss=1.57, val_accuracy=0.605, lr=0.1] 76%|███████▌  | 63/83 [19:20<05:54, 17.70s/epoch, loss=1.13, accuracy=0.756, val_loss=2.11, val_accuracy=0.504, lr=0.0316] 77%|███████▋  | 64/83 [19:37<05:37, 17.74s/epoch, loss=1.13, accuracy=0.754, val_loss=2.31, val_accuracy=0.336, lr=0.1]    78%|███████▊  | 65/83 [19:55<05:20, 17.80s/epoch, loss=1.12, accuracy=0.758, val_loss=2.17, val_accuracy=0.484, lr=0.1] 80%|███████▉  | 66/83 [20:13<05:03, 17.88s/epoch, loss=1.14, accuracy=0.753, val_loss=1.75, val_accuracy=0.548, lr=0.1] 81%|████████  | 67/83 [20:32<04:47, 17.96s/epoch, loss=1.13, accuracy=0.756, val_loss=1.7, val_accuracy=0.55, lr=0.1]   82%|████████▏ | 68/83 [20:50<04:29, 17.98s/epoch, loss=1.13, accuracy=0.757, val_loss=2.88, val_accuracy=0.41, lr=0.0316] 83%|████████▎ | 69/83 [21:08<04:13, 18.10s/epoch, loss=1.13, accuracy=0.756, val_loss=2.22, val_accuracy=0.492, lr=0.1]   84%|████████▍ | 70/83 [21:26<03:55, 18.10s/epoch, loss=1.13, accuracy=0.756, val_loss=1.99, val_accuracy=0.479, lr=0.1] 86%|████████▌ | 71/83 [21:44<03:36, 18.05s/epoch, loss=1.14, accuracy=0.753, val_loss=1.97, val_accuracy=0.508, lr=0.1] 87%|████████▋ | 72/83 [22:02<03:18, 18.02s/epoch, loss=1.12, accuracy=0.758, val_loss=1.67, val_accuracy=0.559, lr=0.1] 88%|████████▊ | 73/83 [22:20<02:59, 17.95s/epoch, loss=1.13, accuracy=0.758, val_loss=3.88, val_accuracy=0.3, lr=0.0316] 89%|████████▉ | 74/83 [22:38<02:41, 17.93s/epoch, loss=1.13, accuracy=0.756, val_loss=2.51, val_accuracy=0.379, lr=0.1]  90%|█████████ | 75/83 [22:55<02:23, 17.91s/epoch, loss=1.12, accuracy=0.758, val_loss=1.65, val_accuracy=0.562, lr=0.1] 92%|█████████▏| 76/83 [23:13<02:05, 17.86s/epoch, loss=1.13, accuracy=0.757, val_loss=2.19, val_accuracy=0.359, lr=0.1] 93%|█████████▎| 77/83 [23:31<01:47, 17.91s/epoch, loss=1.12, accuracy=0.754, val_loss=1.67, val_accuracy=0.561, lr=0.1] 94%|█████████▍| 78/83 [23:49<01:29, 17.98s/epoch, loss=1.12, accuracy=0.756, val_loss=1.89, val_accuracy=0.528, lr=0.0316] 95%|█████████▌| 79/83 [24:07<01:11, 18.00s/epoch, loss=1.11, accuracy=0.757, val_loss=1.91, val_accuracy=0.498, lr=0.1]    96%|█████████▋| 80/83 [24:25<00:53, 17.96s/epoch, loss=1.12, accuracy=0.756, val_loss=2.1, val_accuracy=0.472, lr=0.1]  98%|█████████▊| 81/83 [24:43<00:35, 17.89s/epoch, loss=1.12, accuracy=0.757, val_loss=1.86, val_accuracy=0.534, lr=0.1] 99%|█████████▉| 82/83 [25:01<00:17, 17.84s/epoch, loss=0.921, accuracy=0.814, val_loss=0.908, val_accuracy=0.804, lr=0.01]100%|██████████| 83/83 [25:19<00:00, 17.92s/epoch, loss=0.747, accuracy=0.846, val_loss=0.823, val_accuracy=0.809, lr=0.01]100%|██████████| 83/83 [25:19<00:00, 18.31s/epoch, loss=0.747, accuracy=0.846, val_loss=0.823, val_accuracy=0.809, lr=0.01]
Using real-time data augmentation.
Test score: 0.8532767295837402
Test accuracy: 0.7922000288963318


* * * Run SGD for ID = 18_8. * * *


2024-02-20 01:55:46.622173: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 01:55:49.012388: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 01:55:49.013239: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-20 01:55:49.049135: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-20 01:55:49.049168: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 01:55:49.051858: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 01:55:49.051897: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-20 01:55:49.054040: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-20 01:55:49.054700: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-20 01:55:49.056972: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-20 01:55:49.058434: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-20 01:55:49.062760: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 01:55:49.063283: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-20 01:55:49.063362: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 01:55:50.471394: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-20 01:55:50.472373: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 01:55:50.473103: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-20 01:55:50.473147: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 01:55:50.473190: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 01:55:50.473208: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-20 01:55:50.473225: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-20 01:55:50.473241: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-20 01:55:50.473264: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-20 01:55:50.473279: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-20 01:55:50.473295: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 01:55:50.473732: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-20 01:55:50.473763: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 01:55:51.078072: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-20 01:55:51.078126: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-20 01:55:51.078135: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-20 01:55:51.079014: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:03:00.0, compute capability: 6.1)
{'id': '18_08', 'batch_size': 128, 'epochs': 83, 'validation_split': 0.1, 'checkpointing': True, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
x_train shape: (45000, 32, 32, 3)
45000 train samples
5000 validation samples
10000 test samples
y_train shape: (45000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/83 [00:00<?, ?epoch/s]2024-02-20 01:55:51.859764: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-20 01:55:51.872081: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600020000 Hz
2024-02-20 01:55:53.696671: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 01:55:53.888326: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 01:55:54.589700: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-20 01:55:54.634823: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/83 [00:51<1:10:25, 51.53s/epoch, loss=3.36, accuracy=0.282, val_loss=3.96, val_accuracy=0.11, lr=0.1]  2%|▏         | 2/83 [01:09<42:33, 31.53s/epoch, loss=1.62, accuracy=0.509, val_loss=2.07, val_accuracy=0.417, lr=0.1]   4%|▎         | 3/83 [01:25<32:57, 24.72s/epoch, loss=1.35, accuracy=0.63, val_loss=2.43, val_accuracy=0.407, lr=0.1]   5%|▍         | 4/83 [01:42<28:37, 21.74s/epoch, loss=1.27, accuracy=0.682, val_loss=1.62, val_accuracy=0.554, lr=0.1]  6%|▌         | 5/83 [01:59<26:02, 20.03s/epoch, loss=1.24, accuracy=0.703, val_loss=2.09, val_accuracy=0.421, lr=0.1]  7%|▋         | 6/83 [02:16<24:21, 18.98s/epoch, loss=1.22, accuracy=0.71, val_loss=1.8, val_accuracy=0.495, lr=0.1]    8%|▊         | 7/83 [02:33<23:12, 18.32s/epoch, loss=1.21, accuracy=0.718, val_loss=2.51, val_accuracy=0.307, lr=0.1] 10%|▉         | 8/83 [02:50<22:21, 17.89s/epoch, loss=1.2, accuracy=0.721, val_loss=1.85, val_accuracy=0.516, lr=0.1]  11%|█         | 9/83 [03:07<21:42, 17.60s/epoch, loss=1.2, accuracy=0.728, val_loss=3.78, val_accuracy=0.341, lr=0.0316] 12%|█▏        | 10/83 [03:24<21:09, 17.39s/epoch, loss=1.18, accuracy=0.736, val_loss=4.17, val_accuracy=0.353, lr=0.1]  13%|█▎        | 11/83 [03:41<20:48, 17.34s/epoch, loss=1.18, accuracy=0.734, val_loss=1.88, val_accuracy=0.516, lr=0.1] 14%|█▍        | 12/83 [03:59<20:30, 17.33s/epoch, loss=1.17, accuracy=0.737, val_loss=2.2, val_accuracy=0.453, lr=0.1]  16%|█▌        | 13/83 [04:16<20:13, 17.33s/epoch, loss=1.17, accuracy=0.739, val_loss=1.47, val_accuracy=0.643, lr=0.1] 17%|█▋        | 14/83 [04:33<19:49, 17.23s/epoch, loss=1.17, accuracy=0.742, val_loss=1.77, val_accuracy=0.542, lr=0.1] 18%|█▊        | 15/83 [04:50<19:30, 17.22s/epoch, loss=1.16, accuracy=0.743, val_loss=1.39, val_accuracy=0.67, lr=0.1]  19%|█▉        | 16/83 [05:07<19:03, 17.06s/epoch, loss=1.15, accuracy=0.748, val_loss=2.03, val_accuracy=0.568, lr=0.1] 20%|██        | 17/83 [05:24<18:41, 16.99s/epoch, loss=1.15, accuracy=0.745, val_loss=2.05, val_accuracy=0.523, lr=0.1] 22%|██▏       | 18/83 [05:40<18:19, 16.91s/epoch, loss=1.15, accuracy=0.747, val_loss=1.85, val_accuracy=0.541, lr=0.1] 23%|██▎       | 19/83 [05:57<18:00, 16.88s/epoch, loss=1.15, accuracy=0.746, val_loss=1.85, val_accuracy=0.524, lr=0.1] 24%|██▍       | 20/83 [06:14<17:39, 16.82s/epoch, loss=1.15, accuracy=0.747, val_loss=1.84, val_accuracy=0.55, lr=0.0316] 25%|██▌       | 21/83 [06:31<17:24, 16.84s/epoch, loss=1.14, accuracy=0.749, val_loss=3.64, val_accuracy=0.388, lr=0.1]   27%|██▋       | 22/83 [06:48<17:07, 16.84s/epoch, loss=1.14, accuracy=0.749, val_loss=1.43, val_accuracy=0.646, lr=0.1] 28%|██▊       | 23/83 [07:04<16:46, 16.78s/epoch, loss=1.14, accuracy=0.75, val_loss=2.74, val_accuracy=0.436, lr=0.1]  29%|██▉       | 24/83 [07:21<16:29, 16.77s/epoch, loss=1.15, accuracy=0.749, val_loss=2.09, val_accuracy=0.477, lr=0.1] 30%|███       | 25/83 [07:38<16:11, 16.76s/epoch, loss=1.14, accuracy=0.754, val_loss=1.79, val_accuracy=0.54, lr=0.0316] 31%|███▏      | 26/83 [07:55<15:57, 16.80s/epoch, loss=1.14, accuracy=0.751, val_loss=1.99, val_accuracy=0.439, lr=0.1]   33%|███▎      | 27/83 [08:12<15:46, 16.91s/epoch, loss=1.13, accuracy=0.753, val_loss=1.61, val_accuracy=0.562, lr=0.1] 34%|███▎      | 28/83 [08:29<15:30, 16.91s/epoch, loss=1.14, accuracy=0.751, val_loss=2.44, val_accuracy=0.396, lr=0.1] 35%|███▍      | 29/83 [08:46<15:12, 16.89s/epoch, loss=1.13, accuracy=0.754, val_loss=1.62, val_accuracy=0.594, lr=0.1] 36%|███▌      | 30/83 [09:03<14:58, 16.95s/epoch, loss=1.13, accuracy=0.754, val_loss=1.46, val_accuracy=0.647, lr=0.0316] 37%|███▋      | 31/83 [09:20<14:42, 16.97s/epoch, loss=1.14, accuracy=0.75, val_loss=5.66, val_accuracy=0.234, lr=0.1]     39%|███▊      | 32/83 [09:37<14:24, 16.95s/epoch, loss=1.13, accuracy=0.754, val_loss=2.46, val_accuracy=0.404, lr=0.1] 40%|███▉      | 33/83 [09:54<14:12, 17.05s/epoch, loss=1.13, accuracy=0.755, val_loss=2.04, val_accuracy=0.501, lr=0.1] 41%|████      | 34/83 [10:11<13:55, 17.05s/epoch, loss=1.13, accuracy=0.757, val_loss=2.14, val_accuracy=0.425, lr=0.1] 42%|████▏     | 35/83 [10:28<13:38, 17.05s/epoch, loss=1.12, accuracy=0.758, val_loss=2.84, val_accuracy=0.403, lr=0.0316] 43%|████▎     | 36/83 [10:45<13:20, 17.04s/epoch, loss=1.13, accuracy=0.756, val_loss=1.98, val_accuracy=0.555, lr=0.1]    45%|████▍     | 37/83 [11:02<13:04, 17.04s/epoch, loss=1.12, accuracy=0.759, val_loss=5.42, val_accuracy=0.277, lr=0.1] 46%|████▌     | 38/83 [11:19<12:52, 17.17s/epoch, loss=1.13, accuracy=0.756, val_loss=1.32, val_accuracy=0.697, lr=0.1] 47%|████▋     | 39/83 [11:36<12:33, 17.12s/epoch, loss=1.12, accuracy=0.758, val_loss=1.8, val_accuracy=0.499, lr=0.1]  48%|████▊     | 40/83 [11:54<12:15, 17.11s/epoch, loss=1.12, accuracy=0.759, val_loss=1.72, val_accuracy=0.584, lr=0.1] 49%|████▉     | 41/83 [12:11<11:57, 17.08s/epoch, loss=1.13, accuracy=0.754, val_loss=2.23, val_accuracy=0.43, lr=0.1]  51%|█████     | 42/83 [12:28<11:39, 17.06s/epoch, loss=1.13, accuracy=0.756, val_loss=1.58, val_accuracy=0.604, lr=0.1] 52%|█████▏    | 43/83 [12:45<11:22, 17.07s/epoch, loss=1.13, accuracy=0.758, val_loss=2.67, val_accuracy=0.382, lr=0.0316] 53%|█████▎    | 44/83 [13:02<11:03, 17.02s/epoch, loss=1.12, accuracy=0.76, val_loss=3.57, val_accuracy=0.313, lr=0.1]     54%|█████▍    | 45/83 [13:19<10:50, 17.13s/epoch, loss=1.12, accuracy=0.758, val_loss=1.89, val_accuracy=0.52, lr=0.1] 55%|█████▌    | 46/83 [13:36<10:31, 17.07s/epoch, loss=1.12, accuracy=0.759, val_loss=1.58, val_accuracy=0.597, lr=0.1] 57%|█████▋    | 47/83 [13:53<10:18, 17.17s/epoch, loss=1.12, accuracy=0.757, val_loss=1.9, val_accuracy=0.568, lr=0.1]  58%|█████▊    | 48/83 [14:10<10:00, 17.17s/epoch, loss=1.12, accuracy=0.758, val_loss=1.95, val_accuracy=0.52, lr=0.0316] 59%|█████▉    | 49/83 [14:28<09:43, 17.15s/epoch, loss=1.13, accuracy=0.756, val_loss=1.63, val_accuracy=0.573, lr=0.1]   60%|██████    | 50/83 [14:44<09:21, 17.03s/epoch, loss=1.12, accuracy=0.758, val_loss=1.91, val_accuracy=0.548, lr=0.1] 61%|██████▏   | 51/83 [15:01<09:03, 16.97s/epoch, loss=1.12, accuracy=0.758, val_loss=1.83, val_accuracy=0.578, lr=0.1] 63%|██████▎   | 52/83 [15:18<08:48, 17.05s/epoch, loss=1.12, accuracy=0.755, val_loss=3.65, val_accuracy=0.361, lr=0.1] 64%|██████▍   | 53/83 [15:35<08:27, 16.92s/epoch, loss=1.12, accuracy=0.756, val_loss=2.08, val_accuracy=0.512, lr=0.0316] 65%|██████▌   | 54/83 [15:52<08:12, 16.98s/epoch, loss=1.12, accuracy=0.753, val_loss=3.26, val_accuracy=0.37, lr=0.1]     66%|██████▋   | 55/83 [16:09<07:55, 16.99s/epoch, loss=1.13, accuracy=0.757, val_loss=2.13, val_accuracy=0.462, lr=0.1] 67%|██████▋   | 56/83 [16:26<07:35, 16.86s/epoch, loss=1.12, accuracy=0.757, val_loss=2.3, val_accuracy=0.526, lr=0.1]  69%|██████▊   | 57/83 [16:43<07:18, 16.87s/epoch, loss=1.13, accuracy=0.756, val_loss=2.52, val_accuracy=0.441, lr=0.1] 70%|██████▉   | 58/83 [17:00<07:02, 16.90s/epoch, loss=1.12, accuracy=0.756, val_loss=2.47, val_accuracy=0.461, lr=0.0316] 71%|███████   | 59/83 [17:17<06:47, 16.97s/epoch, loss=1.11, accuracy=0.759, val_loss=1.92, val_accuracy=0.504, lr=0.1]    72%|███████▏  | 60/83 [17:34<06:31, 17.03s/epoch, loss=1.12, accuracy=0.756, val_loss=1.99, val_accuracy=0.448, lr=0.1] 73%|███████▎  | 61/83 [17:51<06:16, 17.12s/epoch, loss=1.12, accuracy=0.755, val_loss=1.62, val_accuracy=0.599, lr=0.1] 75%|███████▍  | 62/83 [18:09<06:01, 17.22s/epoch, loss=1.11, accuracy=0.758, val_loss=1.34, val_accuracy=0.675, lr=0.1] 76%|███████▌  | 63/83 [18:26<05:44, 17.21s/epoch, loss=1.11, accuracy=0.76, val_loss=1.7, val_accuracy=0.59, lr=0.0316] 77%|███████▋  | 64/83 [18:43<05:24, 17.07s/epoch, loss=1.11, accuracy=0.756, val_loss=3.06, val_accuracy=0.345, lr=0.1] 78%|███████▊  | 65/83 [19:00<05:08, 17.13s/epoch, loss=1.12, accuracy=0.757, val_loss=1.76, val_accuracy=0.548, lr=0.1] 80%|███████▉  | 66/83 [19:17<04:51, 17.12s/epoch, loss=1.11, accuracy=0.758, val_loss=2.4, val_accuracy=0.474, lr=0.1]  81%|████████  | 67/83 [19:34<04:34, 17.16s/epoch, loss=1.11, accuracy=0.757, val_loss=1.7, val_accuracy=0.603, lr=0.1] 82%|████████▏ | 68/83 [19:51<04:15, 17.04s/epoch, loss=1.12, accuracy=0.755, val_loss=2.07, val_accuracy=0.434, lr=0.0316] 83%|████████▎ | 69/83 [20:08<03:57, 16.99s/epoch, loss=1.11, accuracy=0.76, val_loss=1.79, val_accuracy=0.567, lr=0.1]     84%|████████▍ | 70/83 [20:25<03:39, 16.90s/epoch, loss=1.11, accuracy=0.759, val_loss=2.18, val_accuracy=0.43, lr=0.1] 86%|████████▌ | 71/83 [20:42<03:22, 16.91s/epoch, loss=1.1, accuracy=0.762, val_loss=1.46, val_accuracy=0.654, lr=0.1] 87%|████████▋ | 72/83 [20:59<03:06, 16.94s/epoch, loss=1.11, accuracy=0.76, val_loss=1.99, val_accuracy=0.533, lr=0.1] 88%|████████▊ | 73/83 [21:15<02:48, 16.88s/epoch, loss=1.12, accuracy=0.755, val_loss=2.21, val_accuracy=0.448, lr=0.0316] 89%|████████▉ | 74/83 [21:32<02:32, 16.92s/epoch, loss=1.11, accuracy=0.759, val_loss=1.53, val_accuracy=0.637, lr=0.1]    90%|█████████ | 75/83 [21:49<02:15, 16.92s/epoch, loss=1.1, accuracy=0.762, val_loss=2.14, val_accuracy=0.459, lr=0.1]  92%|█████████▏| 76/83 [22:06<01:58, 16.91s/epoch, loss=1.1, accuracy=0.762, val_loss=1.69, val_accuracy=0.6, lr=0.1]   93%|█████████▎| 77/83 [22:23<01:41, 17.00s/epoch, loss=1.11, accuracy=0.76, val_loss=2.82, val_accuracy=0.436, lr=0.1] 94%|█████████▍| 78/83 [22:40<01:24, 16.97s/epoch, loss=1.11, accuracy=0.759, val_loss=2.86, val_accuracy=0.441, lr=0.0316] 95%|█████████▌| 79/83 [22:57<01:07, 16.86s/epoch, loss=1.11, accuracy=0.758, val_loss=1.69, val_accuracy=0.54, lr=0.1]     96%|█████████▋| 80/83 [23:14<00:50, 16.91s/epoch, loss=1.11, accuracy=0.762, val_loss=2.47, val_accuracy=0.445, lr=0.1] 98%|█████████▊| 81/83 [23:31<00:33, 16.88s/epoch, loss=1.11, accuracy=0.762, val_loss=2, val_accuracy=0.478, lr=0.1]    99%|█████████▉| 82/83 [23:48<00:17, 17.02s/epoch, loss=0.908, accuracy=0.818, val_loss=0.886, val_accuracy=0.81, lr=0.01]100%|██████████| 83/83 [24:05<00:00, 17.02s/epoch, loss=0.732, accuracy=0.848, val_loss=0.879, val_accuracy=0.788, lr=0.01]100%|██████████| 83/83 [24:05<00:00, 17.42s/epoch, loss=0.732, accuracy=0.848, val_loss=0.879, val_accuracy=0.788, lr=0.01]
Using real-time data augmentation.
Test score: 0.8807386755943298
Test accuracy: 0.8127999901771545


* * * Run SGD for ID = 18_9. * * *


2024-02-20 02:20:08.387908: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 02:20:20.964780: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 02:20:20.965791: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-20 02:20:21.002493: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-20 02:20:21.002530: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 02:20:21.007741: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 02:20:21.007781: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-20 02:20:21.011240: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-20 02:20:21.015269: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-20 02:20:21.018631: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-20 02:20:21.021329: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-20 02:20:21.027132: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 02:20:21.027641: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-20 02:20:21.027722: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 02:20:22.435294: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-20 02:20:22.435833: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 02:20:22.436567: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-20 02:20:22.436600: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 02:20:22.436636: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 02:20:22.436653: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-20 02:20:22.436670: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-20 02:20:22.436687: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-20 02:20:22.436703: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-20 02:20:22.436718: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-20 02:20:22.436742: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 02:20:22.437188: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-20 02:20:22.437226: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 02:20:23.056403: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-20 02:20:23.056457: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-20 02:20:23.056465: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-20 02:20:23.057338: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:03:00.0, compute capability: 6.1)
{'id': '18_09', 'batch_size': 128, 'epochs': 83, 'validation_split': 0.1, 'checkpointing': True, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
x_train shape: (45000, 32, 32, 3)
45000 train samples
5000 validation samples
10000 test samples
y_train shape: (45000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/83 [00:00<?, ?epoch/s]2024-02-20 02:20:23.848933: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-20 02:20:23.861078: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600020000 Hz
2024-02-20 02:20:25.679983: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 02:20:25.876455: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 02:20:26.457458: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-20 02:20:26.512846: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/83 [00:52<1:12:24, 52.98s/epoch, loss=3.26, accuracy=0.281, val_loss=2.68, val_accuracy=0.223, lr=0.1]  2%|▏         | 2/83 [01:10<43:08, 31.96s/epoch, loss=1.65, accuracy=0.493, val_loss=2.37, val_accuracy=0.331, lr=0.1]    4%|▎         | 3/83 [01:27<33:57, 25.47s/epoch, loss=1.42, accuracy=0.596, val_loss=1.69, val_accuracy=0.494, lr=0.1]  5%|▍         | 4/83 [01:44<29:07, 22.12s/epoch, loss=1.3, accuracy=0.657, val_loss=2.53, val_accuracy=0.378, lr=0.1]   6%|▌         | 5/83 [02:02<26:22, 20.29s/epoch, loss=1.26, accuracy=0.681, val_loss=4.05, val_accuracy=0.29, lr=0.1]  7%|▋         | 6/83 [02:18<24:34, 19.14s/epoch, loss=1.24, accuracy=0.698, val_loss=3.6, val_accuracy=0.367, lr=0.1]  8%|▊         | 7/83 [02:36<23:29, 18.55s/epoch, loss=1.22, accuracy=0.709, val_loss=1.43, val_accuracy=0.638, lr=0.1] 10%|▉         | 8/83 [02:53<22:40, 18.14s/epoch, loss=1.21, accuracy=0.714, val_loss=1.61, val_accuracy=0.59, lr=0.1]  11%|█         | 9/83 [03:11<22:08, 17.96s/epoch, loss=1.2, accuracy=0.722, val_loss=1.45, val_accuracy=0.639, lr=0.1] 12%|█▏        | 10/83 [03:27<21:19, 17.53s/epoch, loss=1.21, accuracy=0.721, val_loss=1.62, val_accuracy=0.559, lr=0.1] 13%|█▎        | 11/83 [03:44<20:42, 17.26s/epoch, loss=1.2, accuracy=0.725, val_loss=2.07, val_accuracy=0.442, lr=0.1]  14%|█▍        | 12/83 [04:01<20:16, 17.14s/epoch, loss=1.19, accuracy=0.729, val_loss=2.15, val_accuracy=0.476, lr=0.0316] 16%|█▌        | 13/83 [04:18<19:58, 17.13s/epoch, loss=1.19, accuracy=0.73, val_loss=2.21, val_accuracy=0.504, lr=0.1]     17%|█▋        | 14/83 [04:34<19:31, 16.98s/epoch, loss=1.19, accuracy=0.734, val_loss=1.74, val_accuracy=0.564, lr=0.1] 18%|█▊        | 15/83 [04:51<19:10, 16.92s/epoch, loss=1.18, accuracy=0.735, val_loss=3.09, val_accuracy=0.414, lr=0.1] 19%|█▉        | 16/83 [05:08<18:59, 17.01s/epoch, loss=1.17, accuracy=0.737, val_loss=2.65, val_accuracy=0.436, lr=0.1] 20%|██        | 17/83 [05:25<18:35, 16.90s/epoch, loss=1.17, accuracy=0.738, val_loss=2.31, val_accuracy=0.391, lr=0.0316] 22%|██▏       | 18/83 [05:42<18:20, 16.92s/epoch, loss=1.16, accuracy=0.742, val_loss=1.61, val_accuracy=0.59, lr=0.1]     23%|██▎       | 19/83 [05:59<18:01, 16.91s/epoch, loss=1.18, accuracy=0.74, val_loss=2.18, val_accuracy=0.464, lr=0.1] 24%|██▍       | 20/83 [06:16<17:41, 16.85s/epoch, loss=1.18, accuracy=0.74, val_loss=1.58, val_accuracy=0.592, lr=0.1] 25%|██▌       | 21/83 [06:32<17:22, 16.82s/epoch, loss=1.18, accuracy=0.739, val_loss=1.43, val_accuracy=0.658, lr=0.1] 27%|██▋       | 22/83 [06:49<17:08, 16.86s/epoch, loss=1.17, accuracy=0.743, val_loss=1.48, val_accuracy=0.638, lr=0.1] 28%|██▊       | 23/83 [07:06<16:47, 16.79s/epoch, loss=1.17, accuracy=0.744, val_loss=2.02, val_accuracy=0.486, lr=0.1] 29%|██▉       | 24/83 [07:23<16:40, 16.96s/epoch, loss=1.17, accuracy=0.742, val_loss=2.6, val_accuracy=0.423, lr=0.1]  30%|███       | 25/83 [07:40<16:17, 16.86s/epoch, loss=1.16, accuracy=0.744, val_loss=1.85, val_accuracy=0.542, lr=0.1] 31%|███▏      | 26/83 [07:56<15:55, 16.76s/epoch, loss=1.16, accuracy=0.744, val_loss=1.89, val_accuracy=0.466, lr=0.0316] 33%|███▎      | 27/83 [08:13<15:39, 16.78s/epoch, loss=1.17, accuracy=0.745, val_loss=3.56, val_accuracy=0.267, lr=0.1]    34%|███▎      | 28/83 [08:30<15:17, 16.69s/epoch, loss=1.16, accuracy=0.745, val_loss=2.44, val_accuracy=0.45, lr=0.1]  35%|███▍      | 29/83 [08:46<15:00, 16.68s/epoch, loss=1.16, accuracy=0.746, val_loss=2.26, val_accuracy=0.481, lr=0.1] 36%|███▌      | 30/83 [09:03<14:46, 16.72s/epoch, loss=1.15, accuracy=0.746, val_loss=3.8, val_accuracy=0.258, lr=0.1]  37%|███▋      | 31/83 [09:20<14:34, 16.82s/epoch, loss=1.15, accuracy=0.749, val_loss=2.97, val_accuracy=0.343, lr=0.0316] 39%|███▊      | 32/83 [09:37<14:20, 16.87s/epoch, loss=1.15, accuracy=0.749, val_loss=1.78, val_accuracy=0.544, lr=0.1]    40%|███▉      | 33/83 [09:54<14:06, 16.92s/epoch, loss=1.14, accuracy=0.751, val_loss=2.96, val_accuracy=0.392, lr=0.1] 41%|████      | 34/83 [10:11<13:47, 16.89s/epoch, loss=1.15, accuracy=0.75, val_loss=2.02, val_accuracy=0.446, lr=0.1]  42%|████▏     | 35/83 [10:28<13:28, 16.84s/epoch, loss=1.15, accuracy=0.748, val_loss=1.98, val_accuracy=0.556, lr=0.1] 43%|████▎     | 36/83 [10:44<13:08, 16.78s/epoch, loss=1.15, accuracy=0.749, val_loss=2.11, val_accuracy=0.549, lr=0.0316] 45%|████▍     | 37/83 [11:01<12:49, 16.72s/epoch, loss=1.14, accuracy=0.752, val_loss=2.46, val_accuracy=0.38, lr=0.1]     46%|████▌     | 38/83 [11:18<12:32, 16.72s/epoch, loss=1.15, accuracy=0.75, val_loss=3.74, val_accuracy=0.331, lr=0.1] 47%|████▋     | 39/83 [11:34<12:14, 16.69s/epoch, loss=1.15, accuracy=0.752, val_loss=2.16, val_accuracy=0.486, lr=0.1] 48%|████▊     | 40/83 [11:51<11:54, 16.62s/epoch, loss=1.15, accuracy=0.752, val_loss=3.4, val_accuracy=0.385, lr=0.1]  49%|████▉     | 41/83 [12:08<11:42, 16.73s/epoch, loss=1.14, accuracy=0.752, val_loss=2.8, val_accuracy=0.419, lr=0.0316] 51%|█████     | 42/83 [12:24<11:23, 16.67s/epoch, loss=1.14, accuracy=0.754, val_loss=4.48, val_accuracy=0.258, lr=0.1]   52%|█████▏    | 43/83 [12:41<11:04, 16.61s/epoch, loss=1.13, accuracy=0.754, val_loss=2.65, val_accuracy=0.359, lr=0.1] 53%|█████▎    | 44/83 [12:57<10:44, 16.51s/epoch, loss=1.14, accuracy=0.754, val_loss=2.27, val_accuracy=0.495, lr=0.1] 54%|█████▍    | 45/83 [13:14<10:33, 16.68s/epoch, loss=1.14, accuracy=0.755, val_loss=1.81, val_accuracy=0.583, lr=0.1] 55%|█████▌    | 46/83 [13:31<10:14, 16.61s/epoch, loss=1.14, accuracy=0.752, val_loss=1.54, val_accuracy=0.594, lr=0.0316] 57%|█████▋    | 47/83 [13:48<10:02, 16.73s/epoch, loss=1.14, accuracy=0.75, val_loss=2.35, val_accuracy=0.521, lr=0.1]     58%|█████▊    | 48/83 [14:04<09:46, 16.77s/epoch, loss=1.13, accuracy=0.754, val_loss=1.68, val_accuracy=0.542, lr=0.1] 59%|█████▉    | 49/83 [14:21<09:28, 16.72s/epoch, loss=1.13, accuracy=0.754, val_loss=3.03, val_accuracy=0.324, lr=0.1] 60%|██████    | 50/83 [14:38<09:14, 16.80s/epoch, loss=1.14, accuracy=0.753, val_loss=1.85, val_accuracy=0.514, lr=0.1] 61%|██████▏   | 51/83 [14:54<08:52, 16.65s/epoch, loss=1.14, accuracy=0.752, val_loss=1.73, val_accuracy=0.552, lr=0.0316] 63%|██████▎   | 52/83 [15:11<08:35, 16.62s/epoch, loss=1.13, accuracy=0.753, val_loss=2.6, val_accuracy=0.425, lr=0.1]     64%|██████▍   | 53/83 [15:27<08:17, 16.58s/epoch, loss=1.13, accuracy=0.752, val_loss=3, val_accuracy=0.362, lr=0.1]   65%|██████▌   | 54/83 [15:44<07:58, 16.50s/epoch, loss=1.13, accuracy=0.756, val_loss=3.12, val_accuracy=0.387, lr=0.1] 66%|██████▋   | 55/83 [16:00<07:40, 16.44s/epoch, loss=1.13, accuracy=0.757, val_loss=3.5, val_accuracy=0.319, lr=0.1]  67%|██████▋   | 56/83 [16:16<07:22, 16.40s/epoch, loss=1.13, accuracy=0.754, val_loss=3.66, val_accuracy=0.397, lr=0.0316] 69%|██████▊   | 57/83 [16:33<07:07, 16.44s/epoch, loss=1.13, accuracy=0.753, val_loss=1.67, val_accuracy=0.604, lr=0.1]    70%|██████▉   | 58/83 [16:49<06:50, 16.43s/epoch, loss=1.13, accuracy=0.757, val_loss=3.19, val_accuracy=0.237, lr=0.1] 71%|███████   | 59/83 [17:06<06:35, 16.47s/epoch, loss=1.13, accuracy=0.757, val_loss=2.32, val_accuracy=0.454, lr=0.1] 72%|███████▏  | 60/83 [17:22<06:17, 16.42s/epoch, loss=1.13, accuracy=0.756, val_loss=1.97, val_accuracy=0.492, lr=0.1] 73%|███████▎  | 61/83 [17:39<06:04, 16.57s/epoch, loss=1.13, accuracy=0.757, val_loss=1.84, val_accuracy=0.584, lr=0.0316] 75%|███████▍  | 62/83 [17:56<05:47, 16.54s/epoch, loss=1.13, accuracy=0.755, val_loss=2.68, val_accuracy=0.338, lr=0.1]    76%|███████▌  | 63/83 [18:12<05:31, 16.58s/epoch, loss=1.12, accuracy=0.758, val_loss=1.41, val_accuracy=0.665, lr=0.1] 77%|███████▋  | 64/83 [18:29<05:14, 16.56s/epoch, loss=1.12, accuracy=0.757, val_loss=1.83, val_accuracy=0.518, lr=0.1] 78%|███████▊  | 65/83 [18:45<04:56, 16.47s/epoch, loss=1.13, accuracy=0.755, val_loss=1.9, val_accuracy=0.552, lr=0.1]  80%|███████▉  | 66/83 [19:01<04:39, 16.45s/epoch, loss=1.12, accuracy=0.758, val_loss=2.9, val_accuracy=0.37, lr=0.1]  81%|████████  | 67/83 [19:18<04:22, 16.41s/epoch, loss=1.13, accuracy=0.758, val_loss=2.28, val_accuracy=0.395, lr=0.1] 82%|████████▏ | 68/83 [19:34<04:06, 16.41s/epoch, loss=1.12, accuracy=0.758, val_loss=2.87, val_accuracy=0.317, lr=0.0316] 83%|████████▎ | 69/83 [19:51<03:50, 16.44s/epoch, loss=1.13, accuracy=0.757, val_loss=3.29, val_accuracy=0.247, lr=0.1]    84%|████████▍ | 70/83 [20:07<03:34, 16.53s/epoch, loss=1.12, accuracy=0.759, val_loss=2.05, val_accuracy=0.437, lr=0.1] 86%|████████▌ | 71/83 [20:24<03:18, 16.58s/epoch, loss=1.12, accuracy=0.76, val_loss=4.36, val_accuracy=0.247, lr=0.1]  87%|████████▋ | 72/83 [20:40<03:01, 16.52s/epoch, loss=1.12, accuracy=0.755, val_loss=1.67, val_accuracy=0.593, lr=0.1] 88%|████████▊ | 73/83 [20:57<02:44, 16.47s/epoch, loss=1.12, accuracy=0.76, val_loss=2.12, val_accuracy=0.489, lr=0.0316] 89%|████████▉ | 74/83 [21:13<02:27, 16.42s/epoch, loss=1.13, accuracy=0.758, val_loss=2.76, val_accuracy=0.398, lr=0.1]   90%|█████████ | 75/83 [21:30<02:11, 16.43s/epoch, loss=1.12, accuracy=0.758, val_loss=2.5, val_accuracy=0.411, lr=0.1]  92%|█████████▏| 76/83 [21:46<01:55, 16.48s/epoch, loss=1.12, accuracy=0.76, val_loss=1.87, val_accuracy=0.573, lr=0.1] 93%|█████████▎| 77/83 [22:02<01:38, 16.37s/epoch, loss=1.12, accuracy=0.758, val_loss=2.63, val_accuracy=0.404, lr=0.1] 94%|█████████▍| 78/83 [22:18<01:21, 16.30s/epoch, loss=1.11, accuracy=0.759, val_loss=5.64, val_accuracy=0.177, lr=0.0316] 95%|█████████▌| 79/83 [22:35<01:05, 16.33s/epoch, loss=1.12, accuracy=0.756, val_loss=3.06, val_accuracy=0.347, lr=0.1]    96%|█████████▋| 80/83 [22:51<00:49, 16.42s/epoch, loss=1.12, accuracy=0.756, val_loss=1.71, val_accuracy=0.552, lr=0.1] 98%|█████████▊| 81/83 [23:08<00:32, 16.38s/epoch, loss=1.11, accuracy=0.759, val_loss=2.5, val_accuracy=0.4, lr=0.1]    99%|█████████▉| 82/83 [23:24<00:16, 16.48s/epoch, loss=0.909, accuracy=0.819, val_loss=1, val_accuracy=0.766, lr=0.01]100%|██████████| 83/83 [23:41<00:00, 16.51s/epoch, loss=0.731, accuracy=0.851, val_loss=0.814, val_accuracy=0.817, lr=0.01]100%|██████████| 83/83 [23:41<00:00, 17.13s/epoch, loss=0.731, accuracy=0.851, val_loss=0.814, val_accuracy=0.817, lr=0.01]
Using real-time data augmentation.
Test score: 0.8294590711593628
Test accuracy: 0.8073999881744385


* * * Run SGD for ID = 18_10. * * *


2024-02-20 02:44:13.345778: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 02:44:27.613651: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 02:44:27.615664: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-20 02:44:27.651342: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-20 02:44:27.651368: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 02:44:27.677410: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 02:44:27.677448: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-20 02:44:27.691852: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-20 02:44:27.710469: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-20 02:44:27.726388: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-20 02:44:27.740021: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-20 02:44:27.755090: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 02:44:27.755644: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-20 02:44:27.755715: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 02:44:29.254411: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-20 02:44:29.254867: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 02:44:29.255596: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-20 02:44:29.255624: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 02:44:29.255656: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 02:44:29.255670: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-20 02:44:29.255684: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-20 02:44:29.255699: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-20 02:44:29.255712: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-20 02:44:29.255725: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-20 02:44:29.255738: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 02:44:29.256167: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-20 02:44:29.256200: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 02:44:30.134137: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-20 02:44:30.134188: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-20 02:44:30.134196: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-20 02:44:30.135071: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:03:00.0, compute capability: 6.1)
{'id': '18_10', 'batch_size': 128, 'epochs': 83, 'validation_split': 0.1, 'checkpointing': True, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
x_train shape: (45000, 32, 32, 3)
45000 train samples
5000 validation samples
10000 test samples
y_train shape: (45000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/83 [00:00<?, ?epoch/s]2024-02-20 02:44:30.872715: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-20 02:44:30.885184: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600020000 Hz
2024-02-20 02:44:32.715748: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 02:44:32.951829: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 02:44:33.889096: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-20 02:44:33.921648: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/83 [00:48<1:06:27, 48.62s/epoch, loss=3.37, accuracy=0.309, val_loss=3.15, val_accuracy=0.137, lr=0.1]  2%|▏         | 2/83 [01:06<41:14, 30.55s/epoch, loss=1.58, accuracy=0.541, val_loss=2.03, val_accuracy=0.382, lr=0.1]    4%|▎         | 3/83 [01:23<32:21, 24.27s/epoch, loss=1.43, accuracy=0.598, val_loss=1.63, val_accuracy=0.537, lr=0.1]  5%|▍         | 4/83 [01:39<27:53, 21.18s/epoch, loss=1.36, accuracy=0.64, val_loss=2.29, val_accuracy=0.444, lr=0.1]   6%|▌         | 5/83 [01:56<25:25, 19.56s/epoch, loss=1.31, accuracy=0.676, val_loss=2.54, val_accuracy=0.409, lr=0.1]  7%|▋         | 6/83 [02:12<23:39, 18.44s/epoch, loss=1.28, accuracy=0.692, val_loss=2.37, val_accuracy=0.367, lr=0.1]  8%|▊         | 7/83 [02:29<22:38, 17.88s/epoch, loss=1.25, accuracy=0.702, val_loss=1.57, val_accuracy=0.604, lr=0.1] 10%|▉         | 8/83 [02:46<21:57, 17.57s/epoch, loss=1.25, accuracy=0.707, val_loss=2.05, val_accuracy=0.514, lr=0.1] 11%|█         | 9/83 [03:03<21:22, 17.33s/epoch, loss=1.23, accuracy=0.716, val_loss=2.45, val_accuracy=0.41, lr=0.1]  12%|█▏        | 10/83 [03:19<20:51, 17.14s/epoch, loss=1.23, accuracy=0.716, val_loss=1.48, val_accuracy=0.627, lr=0.1] 13%|█▎        | 11/83 [03:36<20:16, 16.89s/epoch, loss=1.22, accuracy=0.725, val_loss=2.22, val_accuracy=0.447, lr=0.1] 14%|█▍        | 12/83 [03:52<19:46, 16.71s/epoch, loss=1.21, accuracy=0.724, val_loss=1.95, val_accuracy=0.498, lr=0.1] 16%|█▌        | 13/83 [04:09<19:28, 16.70s/epoch, loss=1.2, accuracy=0.724, val_loss=1.75, val_accuracy=0.58, lr=0.1]   17%|█▋        | 14/83 [04:25<19:08, 16.65s/epoch, loss=1.2, accuracy=0.73, val_loss=1.77, val_accuracy=0.564, lr=0.1] 18%|█▊        | 15/83 [04:42<18:46, 16.56s/epoch, loss=1.19, accuracy=0.728, val_loss=1.66, val_accuracy=0.564, lr=0.0316] 19%|█▉        | 16/83 [04:58<18:27, 16.53s/epoch, loss=1.18, accuracy=0.735, val_loss=1.78, val_accuracy=0.545, lr=0.1]    20%|██        | 17/83 [05:14<18:05, 16.45s/epoch, loss=1.18, accuracy=0.733, val_loss=3.04, val_accuracy=0.355, lr=0.1] 22%|██▏       | 18/83 [05:30<17:43, 16.37s/epoch, loss=1.18, accuracy=0.736, val_loss=1.51, val_accuracy=0.613, lr=0.1] 23%|██▎       | 19/83 [05:47<17:30, 16.42s/epoch, loss=1.17, accuracy=0.74, val_loss=1.89, val_accuracy=0.451, lr=0.1]  24%|██▍       | 20/83 [06:04<17:23, 16.56s/epoch, loss=1.18, accuracy=0.737, val_loss=1.93, val_accuracy=0.513, lr=0.0316] 25%|██▌       | 21/83 [06:21<17:16, 16.72s/epoch, loss=1.16, accuracy=0.742, val_loss=1.73, val_accuracy=0.552, lr=0.1]    27%|██▋       | 22/83 [06:38<16:59, 16.72s/epoch, loss=1.17, accuracy=0.74, val_loss=1.85, val_accuracy=0.549, lr=0.1]  28%|██▊       | 23/83 [06:55<16:50, 16.84s/epoch, loss=1.17, accuracy=0.741, val_loss=1.66, val_accuracy=0.552, lr=0.1] 29%|██▉       | 24/83 [07:12<16:32, 16.83s/epoch, loss=1.16, accuracy=0.742, val_loss=2.32, val_accuracy=0.444, lr=0.1] 30%|███       | 25/83 [07:28<16:12, 16.77s/epoch, loss=1.16, accuracy=0.74, val_loss=1.5, val_accuracy=0.627, lr=0.0316] 31%|███▏      | 26/83 [07:45<15:48, 16.65s/epoch, loss=1.16, accuracy=0.745, val_loss=2.07, val_accuracy=0.5, lr=0.1]    33%|███▎      | 27/83 [08:01<15:32, 16.65s/epoch, loss=1.15, accuracy=0.744, val_loss=2.14, val_accuracy=0.504, lr=0.1] 34%|███▎      | 28/83 [08:18<15:16, 16.67s/epoch, loss=1.16, accuracy=0.743, val_loss=3.57, val_accuracy=0.345, lr=0.1] 35%|███▍      | 29/83 [08:35<15:03, 16.72s/epoch, loss=1.16, accuracy=0.744, val_loss=1.65, val_accuracy=0.573, lr=0.1] 36%|███▌      | 30/83 [08:52<14:51, 16.82s/epoch, loss=1.16, accuracy=0.743, val_loss=1.73, val_accuracy=0.588, lr=0.0316] 37%|███▋      | 31/83 [09:08<14:27, 16.69s/epoch, loss=1.16, accuracy=0.745, val_loss=2.01, val_accuracy=0.519, lr=0.1]    39%|███▊      | 32/83 [09:25<14:08, 16.64s/epoch, loss=1.15, accuracy=0.747, val_loss=4.66, val_accuracy=0.282, lr=0.1] 40%|███▉      | 33/83 [09:41<13:47, 16.55s/epoch, loss=1.15, accuracy=0.746, val_loss=6.74, val_accuracy=0.235, lr=0.1] 41%|████      | 34/83 [09:59<13:43, 16.81s/epoch, loss=1.15, accuracy=0.744, val_loss=2.66, val_accuracy=0.448, lr=0.1] 42%|████▏     | 35/83 [10:15<13:22, 16.72s/epoch, loss=1.15, accuracy=0.747, val_loss=2.59, val_accuracy=0.391, lr=0.0316] 43%|████▎     | 36/83 [10:32<13:05, 16.72s/epoch, loss=1.16, accuracy=0.745, val_loss=2.18, val_accuracy=0.454, lr=0.1]    45%|████▍     | 37/83 [10:48<12:44, 16.62s/epoch, loss=1.15, accuracy=0.751, val_loss=2.9, val_accuracy=0.414, lr=0.1]  46%|████▌     | 38/83 [11:04<12:24, 16.53s/epoch, loss=1.15, accuracy=0.747, val_loss=1.68, val_accuracy=0.572, lr=0.1] 47%|████▋     | 39/83 [11:21<12:06, 16.51s/epoch, loss=1.14, accuracy=0.752, val_loss=2.03, val_accuracy=0.494, lr=0.1] 48%|████▊     | 40/83 [11:37<11:47, 16.46s/epoch, loss=1.15, accuracy=0.749, val_loss=2.04, val_accuracy=0.464, lr=0.0316] 49%|████▉     | 41/83 [11:54<11:29, 16.42s/epoch, loss=1.15, accuracy=0.749, val_loss=2.98, val_accuracy=0.404, lr=0.1]    51%|█████     | 42/83 [12:10<11:11, 16.37s/epoch, loss=1.14, accuracy=0.749, val_loss=2.63, val_accuracy=0.435, lr=0.1] 52%|█████▏    | 43/83 [12:26<10:57, 16.43s/epoch, loss=1.14, accuracy=0.75, val_loss=3.6, val_accuracy=0.329, lr=0.1]   53%|█████▎    | 44/83 [12:43<10:41, 16.44s/epoch, loss=1.14, accuracy=0.747, val_loss=2.66, val_accuracy=0.385, lr=0.1] 54%|█████▍    | 45/83 [12:59<10:23, 16.40s/epoch, loss=1.14, accuracy=0.752, val_loss=2.46, val_accuracy=0.348, lr=0.0316] 55%|█████▌    | 46/83 [13:16<10:05, 16.37s/epoch, loss=1.14, accuracy=0.751, val_loss=1.72, val_accuracy=0.558, lr=0.1]    57%|█████▋    | 47/83 [13:32<09:51, 16.43s/epoch, loss=1.13, accuracy=0.749, val_loss=1.74, val_accuracy=0.588, lr=0.1] 58%|█████▊    | 48/83 [13:49<09:35, 16.44s/epoch, loss=1.13, accuracy=0.749, val_loss=2.42, val_accuracy=0.432, lr=0.1] 59%|█████▉    | 49/83 [14:05<09:22, 16.55s/epoch, loss=1.13, accuracy=0.749, val_loss=2.47, val_accuracy=0.429, lr=0.1] 60%|██████    | 50/83 [14:22<09:07, 16.58s/epoch, loss=1.14, accuracy=0.749, val_loss=4.44, val_accuracy=0.249, lr=0.0316] 61%|██████▏   | 51/83 [14:38<08:49, 16.56s/epoch, loss=1.14, accuracy=0.751, val_loss=2.51, val_accuracy=0.469, lr=0.1]    63%|██████▎   | 52/83 [14:55<08:33, 16.56s/epoch, loss=1.14, accuracy=0.75, val_loss=2.23, val_accuracy=0.37, lr=0.1]   64%|██████▍   | 53/83 [15:12<08:15, 16.52s/epoch, loss=1.13, accuracy=0.753, val_loss=2.7, val_accuracy=0.414, lr=0.1] 65%|██████▌   | 54/83 [15:28<08:01, 16.62s/epoch, loss=1.14, accuracy=0.75, val_loss=2.12, val_accuracy=0.499, lr=0.1] 66%|██████▋   | 55/83 [15:45<07:44, 16.57s/epoch, loss=1.14, accuracy=0.75, val_loss=1.72, val_accuracy=0.568, lr=0.0316] 67%|██████▋   | 56/83 [16:01<07:26, 16.55s/epoch, loss=1.14, accuracy=0.751, val_loss=2.64, val_accuracy=0.376, lr=0.1]   69%|██████▊   | 57/83 [16:18<07:10, 16.56s/epoch, loss=1.13, accuracy=0.754, val_loss=3.04, val_accuracy=0.394, lr=0.1] 70%|██████▉   | 58/83 [16:35<06:55, 16.60s/epoch, loss=1.14, accuracy=0.751, val_loss=1.78, val_accuracy=0.536, lr=0.1] 71%|███████   | 59/83 [16:51<06:36, 16.51s/epoch, loss=1.14, accuracy=0.752, val_loss=3.45, val_accuracy=0.354, lr=0.1] 72%|███████▏  | 60/83 [17:07<06:19, 16.50s/epoch, loss=1.14, accuracy=0.752, val_loss=2.98, val_accuracy=0.4, lr=0.0316] 73%|███████▎  | 61/83 [17:24<06:01, 16.42s/epoch, loss=1.14, accuracy=0.752, val_loss=2.25, val_accuracy=0.523, lr=0.1]  75%|███████▍  | 62/83 [17:40<05:46, 16.50s/epoch, loss=1.13, accuracy=0.751, val_loss=1.55, val_accuracy=0.619, lr=0.1] 76%|███████▌  | 63/83 [17:57<05:30, 16.52s/epoch, loss=1.14, accuracy=0.751, val_loss=1.92, val_accuracy=0.516, lr=0.1] 77%|███████▋  | 64/83 [18:13<05:14, 16.55s/epoch, loss=1.13, accuracy=0.753, val_loss=2.42, val_accuracy=0.443, lr=0.1] 78%|███████▊  | 65/83 [18:30<04:57, 16.54s/epoch, loss=1.13, accuracy=0.757, val_loss=3.38, val_accuracy=0.262, lr=0.0316] 80%|███████▉  | 66/83 [18:46<04:40, 16.52s/epoch, loss=1.14, accuracy=0.752, val_loss=1.92, val_accuracy=0.506, lr=0.1]    81%|████████  | 67/83 [19:03<04:23, 16.44s/epoch, loss=1.13, accuracy=0.753, val_loss=1.74, val_accuracy=0.553, lr=0.1] 82%|████████▏ | 68/83 [19:19<04:05, 16.35s/epoch, loss=1.13, accuracy=0.755, val_loss=1.79, val_accuracy=0.569, lr=0.1] 83%|████████▎ | 69/83 [19:36<03:51, 16.51s/epoch, loss=1.14, accuracy=0.751, val_loss=1.58, val_accuracy=0.609, lr=0.1] 84%|████████▍ | 70/83 [19:52<03:35, 16.58s/epoch, loss=1.13, accuracy=0.753, val_loss=4.33, val_accuracy=0.321, lr=0.0316] 86%|████████▌ | 71/83 [20:09<03:17, 16.46s/epoch, loss=1.13, accuracy=0.753, val_loss=1.69, val_accuracy=0.596, lr=0.1]    87%|████████▋ | 72/83 [20:25<03:01, 16.52s/epoch, loss=1.13, accuracy=0.752, val_loss=1.82, val_accuracy=0.579, lr=0.1] 88%|████████▊ | 73/83 [20:42<02:44, 16.44s/epoch, loss=1.13, accuracy=0.755, val_loss=1.98, val_accuracy=0.438, lr=0.1] 89%|████████▉ | 74/83 [20:58<02:28, 16.45s/epoch, loss=1.13, accuracy=0.754, val_loss=1.79, val_accuracy=0.541, lr=0.1] 90%|█████████ | 75/83 [21:15<02:11, 16.47s/epoch, loss=1.13, accuracy=0.754, val_loss=1.6, val_accuracy=0.606, lr=0.0316] 92%|█████████▏| 76/83 [21:32<01:56, 16.70s/epoch, loss=1.13, accuracy=0.754, val_loss=1.49, val_accuracy=0.617, lr=0.1]   93%|█████████▎| 77/83 [21:49<01:40, 16.73s/epoch, loss=1.13, accuracy=0.756, val_loss=1.98, val_accuracy=0.533, lr=0.1] 94%|█████████▍| 78/83 [22:05<01:22, 16.54s/epoch, loss=1.13, accuracy=0.753, val_loss=2.07, val_accuracy=0.489, lr=0.1] 95%|█████████▌| 79/83 [22:21<01:05, 16.46s/epoch, loss=1.13, accuracy=0.755, val_loss=2.23, val_accuracy=0.486, lr=0.1] 96%|█████████▋| 80/83 [22:37<00:49, 16.43s/epoch, loss=1.13, accuracy=0.757, val_loss=1.59, val_accuracy=0.584, lr=0.0316] 98%|█████████▊| 81/83 [22:55<00:33, 16.69s/epoch, loss=1.13, accuracy=0.754, val_loss=2.54, val_accuracy=0.453, lr=0.1]    99%|█████████▉| 82/83 [23:12<00:16, 16.76s/epoch, loss=0.932, accuracy=0.813, val_loss=0.924, val_accuracy=0.8, lr=0.01]100%|██████████| 83/83 [23:29<00:00, 16.93s/epoch, loss=0.753, accuracy=0.846, val_loss=0.941, val_accuracy=0.769, lr=0.01]100%|██████████| 83/83 [23:29<00:00, 16.98s/epoch, loss=0.753, accuracy=0.846, val_loss=0.941, val_accuracy=0.769, lr=0.01]
Using real-time data augmentation.
Test score: 0.9364840984344482
Test accuracy: 0.8011000156402588


* * * Run SGD for ID = 18_11. * * *


2024-02-20 03:08:05.305435: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 03:08:07.580857: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 03:08:07.581694: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-20 03:08:07.616736: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-20 03:08:07.616770: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 03:08:07.619610: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 03:08:07.619646: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-20 03:08:07.621688: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-20 03:08:07.622521: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-20 03:08:07.624864: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-20 03:08:07.626513: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-20 03:08:07.631452: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 03:08:07.631951: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-20 03:08:07.632065: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 03:08:08.997545: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-20 03:08:08.998142: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 03:08:08.998881: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-20 03:08:08.998912: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 03:08:08.998946: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 03:08:08.998989: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-20 03:08:08.999009: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-20 03:08:08.999027: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-20 03:08:08.999043: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-20 03:08:08.999058: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-20 03:08:08.999074: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 03:08:08.999517: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-20 03:08:08.999549: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 03:08:09.582247: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-20 03:08:09.582298: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-20 03:08:09.582306: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-20 03:08:09.583228: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:03:00.0, compute capability: 6.1)
{'id': '18_11', 'batch_size': 128, 'epochs': 83, 'validation_split': 0.1, 'checkpointing': True, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
x_train shape: (45000, 32, 32, 3)
45000 train samples
5000 validation samples
10000 test samples
y_train shape: (45000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/83 [00:00<?, ?epoch/s]2024-02-20 03:08:10.350671: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-20 03:08:10.351161: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600020000 Hz
2024-02-20 03:08:12.076944: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 03:08:12.272834: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 03:08:12.890360: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-20 03:08:12.925108: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/83 [00:41<57:07, 41.80s/epoch, loss=3.44, accuracy=0.252, val_loss=2.67, val_accuracy=0.156, lr=0.1]  2%|▏         | 2/83 [00:59<37:12, 27.57s/epoch, loss=1.75, accuracy=0.438, val_loss=2.86, val_accuracy=0.221, lr=0.1]  4%|▎         | 3/83 [01:16<30:19, 22.75s/epoch, loss=1.55, accuracy=0.525, val_loss=2, val_accuracy=0.45, lr=0.1]      5%|▍         | 4/83 [01:33<27:04, 20.57s/epoch, loss=1.4, accuracy=0.62, val_loss=1.74, val_accuracy=0.536, lr=0.1]  6%|▌         | 5/83 [01:50<24:57, 19.20s/epoch, loss=1.3, accuracy=0.674, val_loss=2.1, val_accuracy=0.505, lr=0.1]  7%|▋         | 6/83 [02:06<23:27, 18.28s/epoch, loss=1.27, accuracy=0.697, val_loss=2.16, val_accuracy=0.449, lr=0.1]  8%|▊         | 7/83 [02:23<22:37, 17.86s/epoch, loss=1.25, accuracy=0.709, val_loss=2.83, val_accuracy=0.336, lr=0.1] 10%|▉         | 8/83 [02:40<21:56, 17.55s/epoch, loss=1.23, accuracy=0.718, val_loss=1.89, val_accuracy=0.474, lr=0.1] 11%|█         | 9/83 [02:57<21:29, 17.42s/epoch, loss=1.24, accuracy=0.72, val_loss=1.51, val_accuracy=0.635, lr=0.1]  12%|█▏        | 10/83 [03:14<20:53, 17.17s/epoch, loss=1.22, accuracy=0.727, val_loss=2.82, val_accuracy=0.334, lr=0.1] 13%|█▎        | 11/83 [03:31<20:21, 16.96s/epoch, loss=1.21, accuracy=0.731, val_loss=1.62, val_accuracy=0.59, lr=0.1]  14%|█▍        | 12/83 [03:47<19:56, 16.85s/epoch, loss=1.21, accuracy=0.732, val_loss=2.02, val_accuracy=0.501, lr=0.1] 16%|█▌        | 13/83 [04:04<19:43, 16.90s/epoch, loss=1.21, accuracy=0.734, val_loss=2.26, val_accuracy=0.422, lr=0.1] 17%|█▋        | 14/83 [04:21<19:20, 16.82s/epoch, loss=1.21, accuracy=0.734, val_loss=1.88, val_accuracy=0.513, lr=0.0316] 18%|█▊        | 15/83 [04:38<19:04, 16.83s/epoch, loss=1.21, accuracy=0.735, val_loss=2.25, val_accuracy=0.471, lr=0.1]    19%|█▉        | 16/83 [04:55<18:48, 16.85s/epoch, loss=1.2, accuracy=0.738, val_loss=2.86, val_accuracy=0.346, lr=0.1]  20%|██        | 17/83 [05:11<18:31, 16.84s/epoch, loss=1.2, accuracy=0.738, val_loss=1.99, val_accuracy=0.464, lr=0.1] 22%|██▏       | 18/83 [05:28<18:12, 16.81s/epoch, loss=1.19, accuracy=0.739, val_loss=1.94, val_accuracy=0.542, lr=0.1] 23%|██▎       | 19/83 [05:45<17:55, 16.81s/epoch, loss=1.2, accuracy=0.735, val_loss=3.76, val_accuracy=0.405, lr=0.0316] 24%|██▍       | 20/83 [06:02<17:40, 16.83s/epoch, loss=1.19, accuracy=0.743, val_loss=2.18, val_accuracy=0.502, lr=0.1]   25%|██▌       | 21/83 [06:19<17:23, 16.82s/epoch, loss=1.19, accuracy=0.743, val_loss=1.61, val_accuracy=0.593, lr=0.1] 27%|██▋       | 22/83 [06:36<17:08, 16.86s/epoch, loss=1.2, accuracy=0.74, val_loss=1.83, val_accuracy=0.56, lr=0.1]    28%|██▊       | 23/83 [06:53<17:01, 17.02s/epoch, loss=1.18, accuracy=0.743, val_loss=1.92, val_accuracy=0.56, lr=0.1] 29%|██▉       | 24/83 [07:10<16:50, 17.12s/epoch, loss=1.18, accuracy=0.745, val_loss=1.8, val_accuracy=0.55, lr=0.0316] 30%|███       | 25/83 [07:27<16:33, 17.13s/epoch, loss=1.18, accuracy=0.746, val_loss=2.28, val_accuracy=0.411, lr=0.1]  31%|███▏      | 26/83 [07:45<16:22, 17.24s/epoch, loss=1.18, accuracy=0.745, val_loss=1.89, val_accuracy=0.565, lr=0.1] 33%|███▎      | 27/83 [08:02<16:07, 17.28s/epoch, loss=1.18, accuracy=0.745, val_loss=1.76, val_accuracy=0.573, lr=0.1] 34%|███▎      | 28/83 [08:20<15:49, 17.27s/epoch, loss=1.18, accuracy=0.747, val_loss=1.4, val_accuracy=0.663, lr=0.1]  35%|███▍      | 29/83 [08:36<15:20, 17.05s/epoch, loss=1.17, accuracy=0.748, val_loss=2.22, val_accuracy=0.499, lr=0.1] 36%|███▌      | 30/83 [08:54<15:18, 17.33s/epoch, loss=1.18, accuracy=0.749, val_loss=1.53, val_accuracy=0.637, lr=0.1] 37%|███▋      | 31/83 [09:11<14:51, 17.15s/epoch, loss=1.17, accuracy=0.751, val_loss=3.37, val_accuracy=0.323, lr=0.1] 39%|███▊      | 32/83 [09:28<14:30, 17.07s/epoch, loss=1.17, accuracy=0.749, val_loss=2.29, val_accuracy=0.399, lr=0.1] 40%|███▉      | 33/83 [09:45<14:14, 17.08s/epoch, loss=1.17, accuracy=0.751, val_loss=4.64, val_accuracy=0.199, lr=0.0316] 41%|████      | 34/83 [10:02<13:56, 17.06s/epoch, loss=1.17, accuracy=0.749, val_loss=2.07, val_accuracy=0.499, lr=0.1]    42%|████▏     | 35/83 [10:19<13:42, 17.13s/epoch, loss=1.17, accuracy=0.749, val_loss=2.5, val_accuracy=0.478, lr=0.1]  43%|████▎     | 36/83 [10:36<13:22, 17.07s/epoch, loss=1.16, accuracy=0.749, val_loss=1.64, val_accuracy=0.6, lr=0.1]  45%|████▍     | 37/83 [10:53<13:09, 17.16s/epoch, loss=1.16, accuracy=0.751, val_loss=3.11, val_accuracy=0.408, lr=0.1] 46%|████▌     | 38/83 [11:11<12:58, 17.29s/epoch, loss=1.16, accuracy=0.752, val_loss=1.87, val_accuracy=0.502, lr=0.0316] 47%|████▋     | 39/83 [11:28<12:38, 17.23s/epoch, loss=1.16, accuracy=0.749, val_loss=1.85, val_accuracy=0.522, lr=0.1]    48%|████▊     | 40/83 [11:45<12:15, 17.11s/epoch, loss=1.16, accuracy=0.751, val_loss=2.08, val_accuracy=0.441, lr=0.1] 49%|████▉     | 41/83 [12:02<11:58, 17.10s/epoch, loss=1.17, accuracy=0.75, val_loss=1.86, val_accuracy=0.555, lr=0.1]  51%|█████     | 42/83 [12:19<11:37, 17.01s/epoch, loss=1.18, accuracy=0.748, val_loss=2.22, val_accuracy=0.437, lr=0.1] 52%|█████▏    | 43/83 [12:36<11:21, 17.03s/epoch, loss=1.17, accuracy=0.751, val_loss=2.87, val_accuracy=0.393, lr=0.0316] 53%|█████▎    | 44/83 [12:52<10:59, 16.91s/epoch, loss=1.16, accuracy=0.751, val_loss=1.87, val_accuracy=0.566, lr=0.1]    54%|█████▍    | 45/83 [13:09<10:39, 16.83s/epoch, loss=1.16, accuracy=0.753, val_loss=1.85, val_accuracy=0.511, lr=0.1] 55%|█████▌    | 46/83 [13:26<10:21, 16.79s/epoch, loss=1.16, accuracy=0.751, val_loss=1.72, val_accuracy=0.576, lr=0.1] 57%|█████▋    | 47/83 [13:43<10:09, 16.93s/epoch, loss=1.16, accuracy=0.752, val_loss=1.76, val_accuracy=0.54, lr=0.1]  58%|█████▊    | 48/83 [14:00<09:49, 16.84s/epoch, loss=1.15, accuracy=0.754, val_loss=2.08, val_accuracy=0.443, lr=0.0316] 59%|█████▉    | 49/83 [14:17<09:32, 16.83s/epoch, loss=1.16, accuracy=0.752, val_loss=2.16, val_accuracy=0.534, lr=0.1]    60%|██████    | 50/83 [14:33<09:15, 16.83s/epoch, loss=1.16, accuracy=0.752, val_loss=2.52, val_accuracy=0.356, lr=0.1] 61%|██████▏   | 51/83 [14:50<09:00, 16.89s/epoch, loss=1.15, accuracy=0.752, val_loss=1.7, val_accuracy=0.57, lr=0.1]   63%|██████▎   | 52/83 [15:07<08:43, 16.88s/epoch, loss=1.15, accuracy=0.753, val_loss=1.96, val_accuracy=0.495, lr=0.1] 64%|██████▍   | 53/83 [15:24<08:23, 16.80s/epoch, loss=1.15, accuracy=0.753, val_loss=1.7, val_accuracy=0.57, lr=0.0316] 65%|██████▌   | 54/83 [15:40<08:05, 16.74s/epoch, loss=1.16, accuracy=0.752, val_loss=2.77, val_accuracy=0.401, lr=0.1]  66%|██████▋   | 55/83 [15:57<07:50, 16.80s/epoch, loss=1.15, accuracy=0.753, val_loss=2.55, val_accuracy=0.468, lr=0.1] 67%|██████▋   | 56/83 [16:14<07:34, 16.85s/epoch, loss=1.15, accuracy=0.754, val_loss=1.83, val_accuracy=0.534, lr=0.1] 69%|██████▊   | 57/83 [16:31<07:17, 16.84s/epoch, loss=1.14, accuracy=0.753, val_loss=2.88, val_accuracy=0.35, lr=0.1]  70%|██████▉   | 58/83 [16:48<07:03, 16.95s/epoch, loss=1.14, accuracy=0.753, val_loss=5.2, val_accuracy=0.269, lr=0.0316] 71%|███████   | 59/83 [17:05<06:46, 16.92s/epoch, loss=1.14, accuracy=0.756, val_loss=3.68, val_accuracy=0.35, lr=0.1]    72%|███████▏  | 60/83 [17:23<06:34, 17.14s/epoch, loss=1.15, accuracy=0.755, val_loss=2.29, val_accuracy=0.494, lr=0.1] 73%|███████▎  | 61/83 [17:40<06:16, 17.09s/epoch, loss=1.14, accuracy=0.757, val_loss=2.15, val_accuracy=0.44, lr=0.1]  75%|███████▍  | 62/83 [17:57<06:01, 17.20s/epoch, loss=1.14, accuracy=0.756, val_loss=3.33, val_accuracy=0.302, lr=0.1] 76%|███████▌  | 63/83 [18:14<05:41, 17.07s/epoch, loss=1.14, accuracy=0.755, val_loss=1.59, val_accuracy=0.601, lr=0.0316] 77%|███████▋  | 64/83 [18:31<05:20, 16.88s/epoch, loss=1.14, accuracy=0.755, val_loss=1.79, val_accuracy=0.563, lr=0.1]    78%|███████▊  | 65/83 [18:47<05:02, 16.83s/epoch, loss=1.14, accuracy=0.758, val_loss=2.32, val_accuracy=0.43, lr=0.1]  80%|███████▉  | 66/83 [19:04<04:45, 16.80s/epoch, loss=1.14, accuracy=0.757, val_loss=3.01, val_accuracy=0.293, lr=0.1] 81%|████████  | 67/83 [19:20<04:26, 16.64s/epoch, loss=1.15, accuracy=0.754, val_loss=2.86, val_accuracy=0.383, lr=0.1] 82%|████████▏ | 68/83 [19:37<04:09, 16.64s/epoch, loss=1.13, accuracy=0.756, val_loss=2.26, val_accuracy=0.506, lr=0.0316] 83%|████████▎ | 69/83 [19:54<03:53, 16.68s/epoch, loss=1.14, accuracy=0.755, val_loss=1.73, val_accuracy=0.552, lr=0.1]    84%|████████▍ | 70/83 [20:10<03:36, 16.63s/epoch, loss=1.14, accuracy=0.756, val_loss=1.92, val_accuracy=0.531, lr=0.1] 86%|████████▌ | 71/83 [20:27<03:19, 16.62s/epoch, loss=1.14, accuracy=0.756, val_loss=1.68, val_accuracy=0.63, lr=0.1]  87%|████████▋ | 72/83 [20:44<03:03, 16.72s/epoch, loss=1.13, accuracy=0.757, val_loss=1.76, val_accuracy=0.518, lr=0.1] 88%|████████▊ | 73/83 [21:01<02:47, 16.76s/epoch, loss=1.13, accuracy=0.756, val_loss=1.45, val_accuracy=0.639, lr=0.0316] 89%|████████▉ | 74/83 [21:18<02:32, 16.94s/epoch, loss=1.14, accuracy=0.756, val_loss=3.73, val_accuracy=0.258, lr=0.1]    90%|█████████ | 75/83 [21:35<02:15, 16.92s/epoch, loss=1.14, accuracy=0.756, val_loss=1.71, val_accuracy=0.581, lr=0.1] 92%|█████████▏| 76/83 [21:51<01:57, 16.76s/epoch, loss=1.13, accuracy=0.757, val_loss=3.2, val_accuracy=0.359, lr=0.1]  93%|█████████▎| 77/83 [22:07<01:39, 16.60s/epoch, loss=1.14, accuracy=0.754, val_loss=2.59, val_accuracy=0.285, lr=0.1] 94%|█████████▍| 78/83 [22:24<01:22, 16.55s/epoch, loss=1.14, accuracy=0.754, val_loss=2.17, val_accuracy=0.492, lr=0.0316] 95%|█████████▌| 79/83 [22:40<01:05, 16.49s/epoch, loss=1.13, accuracy=0.759, val_loss=1.66, val_accuracy=0.594, lr=0.1]    96%|█████████▋| 80/83 [22:57<00:49, 16.57s/epoch, loss=1.13, accuracy=0.76, val_loss=2.46, val_accuracy=0.406, lr=0.1]  98%|█████████▊| 81/83 [23:14<00:33, 16.66s/epoch, loss=1.13, accuracy=0.757, val_loss=3.66, val_accuracy=0.347, lr=0.1] 99%|█████████▉| 82/83 [23:30<00:16, 16.66s/epoch, loss=0.931, accuracy=0.815, val_loss=0.885, val_accuracy=0.816, lr=0.01]100%|██████████| 83/83 [23:47<00:00, 16.70s/epoch, loss=0.75, accuracy=0.847, val_loss=0.78, val_accuracy=0.826, lr=0.01]  100%|██████████| 83/83 [23:47<00:00, 17.20s/epoch, loss=0.75, accuracy=0.847, val_loss=0.78, val_accuracy=0.826, lr=0.01]
Using real-time data augmentation.
Test score: 0.7990621328353882
Test accuracy: 0.817799985408783


* * * Run SGD for ID = 18_12. * * *


2024-02-20 03:32:03.870054: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 03:32:06.332881: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 03:32:06.333725: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-20 03:32:06.368087: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-20 03:32:06.368114: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 03:32:06.370751: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 03:32:06.370788: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-20 03:32:06.372812: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-20 03:32:06.373672: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-20 03:32:06.375844: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-20 03:32:06.377274: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-20 03:32:06.381747: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 03:32:06.382239: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-20 03:32:06.382322: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 03:32:07.708128: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-20 03:32:07.708701: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 03:32:07.709369: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-20 03:32:07.709400: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 03:32:07.709433: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 03:32:07.709450: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-20 03:32:07.709466: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-20 03:32:07.709483: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-20 03:32:07.709499: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-20 03:32:07.709514: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-20 03:32:07.709538: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 03:32:07.709948: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-20 03:32:07.710003: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 03:32:08.274229: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-20 03:32:08.274280: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-20 03:32:08.274289: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-20 03:32:08.275195: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:03:00.0, compute capability: 6.1)
{'id': '18_12', 'batch_size': 128, 'epochs': 83, 'validation_split': 0.1, 'checkpointing': True, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
x_train shape: (45000, 32, 32, 3)
45000 train samples
5000 validation samples
10000 test samples
y_train shape: (45000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/83 [00:00<?, ?epoch/s]2024-02-20 03:32:09.030043: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-20 03:32:09.030612: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600020000 Hz
2024-02-20 03:32:10.764777: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 03:32:10.954834: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 03:32:11.624673: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-20 03:32:11.654708: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/83 [00:43<59:39, 43.66s/epoch, loss=3.36, accuracy=0.27, val_loss=2.35, val_accuracy=0.2, lr=0.1]  2%|▏         | 2/83 [01:01<38:09, 28.27s/epoch, loss=1.72, accuracy=0.451, val_loss=1.68, val_accuracy=0.476, lr=0.1]  4%|▎         | 3/83 [01:18<30:47, 23.10s/epoch, loss=1.5, accuracy=0.552, val_loss=2.3, val_accuracy=0.377, lr=0.1]    5%|▍         | 4/83 [01:35<27:18, 20.74s/epoch, loss=1.37, accuracy=0.629, val_loss=1.72, val_accuracy=0.521, lr=0.1]  6%|▌         | 5/83 [01:52<25:17, 19.45s/epoch, loss=1.29, accuracy=0.677, val_loss=1.39, val_accuracy=0.636, lr=0.1]  7%|▋         | 6/83 [02:09<23:49, 18.56s/epoch, loss=1.26, accuracy=0.695, val_loss=4.68, val_accuracy=0.217, lr=0.1]  8%|▊         | 7/83 [02:26<22:46, 17.98s/epoch, loss=1.24, accuracy=0.71, val_loss=2.11, val_accuracy=0.477, lr=0.1]  10%|▉         | 8/83 [02:42<22:01, 17.63s/epoch, loss=1.23, accuracy=0.715, val_loss=1.93, val_accuracy=0.493, lr=0.1] 11%|█         | 9/83 [02:59<21:22, 17.33s/epoch, loss=1.22, accuracy=0.722, val_loss=1.87, val_accuracy=0.531, lr=0.1] 12%|█▏        | 10/83 [03:16<20:56, 17.22s/epoch, loss=1.21, accuracy=0.725, val_loss=2.41, val_accuracy=0.391, lr=0.0316] 13%|█▎        | 11/83 [03:33<20:35, 17.16s/epoch, loss=1.21, accuracy=0.729, val_loss=2.82, val_accuracy=0.367, lr=0.1]    14%|█▍        | 12/83 [03:50<20:20, 17.20s/epoch, loss=1.21, accuracy=0.733, val_loss=1.89, val_accuracy=0.502, lr=0.1] 16%|█▌        | 13/83 [04:07<19:50, 17.01s/epoch, loss=1.21, accuracy=0.735, val_loss=1.59, val_accuracy=0.606, lr=0.1] 17%|█▋        | 14/83 [04:24<19:32, 17.00s/epoch, loss=1.2, accuracy=0.738, val_loss=1.97, val_accuracy=0.511, lr=0.1]  18%|█▊        | 15/83 [04:41<19:17, 17.02s/epoch, loss=1.2, accuracy=0.739, val_loss=1.96, val_accuracy=0.51, lr=0.0316] 19%|█▉        | 16/83 [04:58<18:57, 16.97s/epoch, loss=1.19, accuracy=0.738, val_loss=2.25, val_accuracy=0.431, lr=0.1]  20%|██        | 17/83 [05:14<18:34, 16.89s/epoch, loss=1.2, accuracy=0.742, val_loss=2.61, val_accuracy=0.227, lr=0.1]  22%|██▏       | 18/83 [05:31<18:15, 16.85s/epoch, loss=1.18, accuracy=0.743, val_loss=2.2, val_accuracy=0.484, lr=0.1] 23%|██▎       | 19/83 [05:48<17:58, 16.85s/epoch, loss=1.19, accuracy=0.739, val_loss=2.16, val_accuracy=0.528, lr=0.1] 24%|██▍       | 20/83 [06:05<17:48, 16.97s/epoch, loss=1.18, accuracy=0.745, val_loss=1.95, val_accuracy=0.502, lr=0.0316] 25%|██▌       | 21/83 [06:22<17:35, 17.02s/epoch, loss=1.18, accuracy=0.746, val_loss=2.03, val_accuracy=0.476, lr=0.1]    27%|██▋       | 22/83 [06:39<17:15, 16.97s/epoch, loss=1.17, accuracy=0.745, val_loss=2.18, val_accuracy=0.447, lr=0.1] 28%|██▊       | 23/83 [06:56<16:56, 16.94s/epoch, loss=1.16, accuracy=0.748, val_loss=1.74, val_accuracy=0.582, lr=0.1] 29%|██▉       | 24/83 [07:13<16:37, 16.90s/epoch, loss=1.17, accuracy=0.748, val_loss=3.1, val_accuracy=0.34, lr=0.1]   30%|███       | 25/83 [07:30<16:18, 16.88s/epoch, loss=1.17, accuracy=0.746, val_loss=2.56, val_accuracy=0.468, lr=0.0316] 31%|███▏      | 26/83 [07:47<16:03, 16.90s/epoch, loss=1.17, accuracy=0.745, val_loss=2.3, val_accuracy=0.383, lr=0.1]     33%|███▎      | 27/83 [08:04<15:43, 16.85s/epoch, loss=1.16, accuracy=0.748, val_loss=3.29, val_accuracy=0.382, lr=0.1] 34%|███▎      | 28/83 [08:20<15:26, 16.84s/epoch, loss=1.16, accuracy=0.751, val_loss=1.56, val_accuracy=0.624, lr=0.1] 35%|███▍      | 29/83 [08:37<15:12, 16.90s/epoch, loss=1.15, accuracy=0.752, val_loss=1.91, val_accuracy=0.469, lr=0.1] 36%|███▌      | 30/83 [08:55<15:03, 17.05s/epoch, loss=1.16, accuracy=0.751, val_loss=2.12, val_accuracy=0.467, lr=0.0316] 37%|███▋      | 31/83 [09:12<14:45, 17.03s/epoch, loss=1.16, accuracy=0.749, val_loss=1.98, val_accuracy=0.512, lr=0.1]    39%|███▊      | 32/83 [09:29<14:30, 17.07s/epoch, loss=1.15, accuracy=0.753, val_loss=4.44, val_accuracy=0.131, lr=0.1] 40%|███▉      | 33/83 [09:46<14:11, 17.02s/epoch, loss=1.15, accuracy=0.75, val_loss=1.99, val_accuracy=0.535, lr=0.1]  41%|████      | 34/83 [10:03<13:56, 17.07s/epoch, loss=1.15, accuracy=0.749, val_loss=2.3, val_accuracy=0.493, lr=0.1] 42%|████▏     | 35/83 [10:20<13:33, 16.95s/epoch, loss=1.15, accuracy=0.749, val_loss=1.66, val_accuracy=0.595, lr=0.0316] 43%|████▎     | 36/83 [10:37<13:20, 17.03s/epoch, loss=1.15, accuracy=0.753, val_loss=1.67, val_accuracy=0.589, lr=0.1]    45%|████▍     | 37/83 [10:54<13:04, 17.05s/epoch, loss=1.16, accuracy=0.749, val_loss=2.89, val_accuracy=0.322, lr=0.1] 46%|████▌     | 38/83 [11:12<12:55, 17.22s/epoch, loss=1.15, accuracy=0.751, val_loss=2.73, val_accuracy=0.425, lr=0.1] 47%|████▋     | 39/83 [11:30<12:48, 17.46s/epoch, loss=1.15, accuracy=0.752, val_loss=2.64, val_accuracy=0.44, lr=0.1]  48%|████▊     | 40/83 [11:47<12:23, 17.28s/epoch, loss=1.14, accuracy=0.752, val_loss=1.84, val_accuracy=0.509, lr=0.0316] 49%|████▉     | 41/83 [12:04<12:12, 17.44s/epoch, loss=1.15, accuracy=0.751, val_loss=1.75, val_accuracy=0.54, lr=0.1]     51%|█████     | 42/83 [12:22<11:52, 17.37s/epoch, loss=1.14, accuracy=0.752, val_loss=2.23, val_accuracy=0.43, lr=0.1] 52%|█████▏    | 43/83 [12:38<11:28, 17.21s/epoch, loss=1.14, accuracy=0.752, val_loss=4.07, val_accuracy=0.311, lr=0.1] 53%|█████▎    | 44/83 [12:55<11:06, 17.10s/epoch, loss=1.14, accuracy=0.752, val_loss=2.01, val_accuracy=0.512, lr=0.1] 54%|█████▍    | 45/83 [13:12<10:47, 17.04s/epoch, loss=1.15, accuracy=0.752, val_loss=1.64, val_accuracy=0.596, lr=0.0316] 55%|█████▌    | 46/83 [13:29<10:28, 16.99s/epoch, loss=1.14, accuracy=0.755, val_loss=1.6, val_accuracy=0.595, lr=0.1]     57%|█████▋    | 47/83 [13:46<10:14, 17.07s/epoch, loss=1.15, accuracy=0.752, val_loss=2.17, val_accuracy=0.431, lr=0.1] 58%|█████▊    | 48/83 [14:04<10:00, 17.16s/epoch, loss=1.14, accuracy=0.753, val_loss=2.41, val_accuracy=0.372, lr=0.1] 59%|█████▉    | 49/83 [14:21<09:40, 17.08s/epoch, loss=1.14, accuracy=0.755, val_loss=2.71, val_accuracy=0.387, lr=0.1] 60%|██████    | 50/83 [14:37<09:21, 17.03s/epoch, loss=1.14, accuracy=0.755, val_loss=2.09, val_accuracy=0.482, lr=0.0316] 61%|██████▏   | 51/83 [14:54<09:05, 17.04s/epoch, loss=1.14, accuracy=0.756, val_loss=3.34, val_accuracy=0.375, lr=0.1]    63%|██████▎   | 52/83 [15:12<08:50, 17.12s/epoch, loss=1.14, accuracy=0.757, val_loss=2.19, val_accuracy=0.425, lr=0.1] 64%|██████▍   | 53/83 [15:29<08:34, 17.14s/epoch, loss=1.14, accuracy=0.756, val_loss=1.97, val_accuracy=0.448, lr=0.1] 65%|██████▌   | 54/83 [15:46<08:16, 17.13s/epoch, loss=1.14, accuracy=0.755, val_loss=2.26, val_accuracy=0.506, lr=0.1] 66%|██████▋   | 55/83 [16:03<08:00, 17.16s/epoch, loss=1.12, accuracy=0.758, val_loss=2.36, val_accuracy=0.428, lr=0.0316] 67%|██████▋   | 56/83 [16:21<07:45, 17.23s/epoch, loss=1.14, accuracy=0.756, val_loss=3.37, val_accuracy=0.306, lr=0.1]    69%|██████▊   | 57/83 [16:38<07:24, 17.09s/epoch, loss=1.13, accuracy=0.758, val_loss=2.61, val_accuracy=0.348, lr=0.1] 70%|██████▉   | 58/83 [16:55<07:07, 17.08s/epoch, loss=1.13, accuracy=0.758, val_loss=1.45, val_accuracy=0.64, lr=0.1]  71%|███████   | 59/83 [17:12<06:54, 17.28s/epoch, loss=1.12, accuracy=0.757, val_loss=1.48, val_accuracy=0.631, lr=0.1] 72%|███████▏  | 60/83 [17:29<06:35, 17.18s/epoch, loss=1.13, accuracy=0.755, val_loss=3.36, val_accuracy=0.374, lr=0.0316] 73%|███████▎  | 61/83 [17:46<06:16, 17.10s/epoch, loss=1.13, accuracy=0.759, val_loss=1.68, val_accuracy=0.591, lr=0.1]    75%|███████▍  | 62/83 [18:03<06:00, 17.15s/epoch, loss=1.13, accuracy=0.756, val_loss=4.82, val_accuracy=0.253, lr=0.1] 76%|███████▌  | 63/83 [18:20<05:39, 16.97s/epoch, loss=1.12, accuracy=0.76, val_loss=2.91, val_accuracy=0.371, lr=0.1]  77%|███████▋  | 64/83 [18:37<05:22, 16.95s/epoch, loss=1.13, accuracy=0.756, val_loss=1.78, val_accuracy=0.534, lr=0.1] 78%|███████▊  | 65/83 [18:54<05:04, 16.94s/epoch, loss=1.13, accuracy=0.755, val_loss=2.04, val_accuracy=0.493, lr=0.0316] 80%|███████▉  | 66/83 [19:11<04:48, 16.95s/epoch, loss=1.13, accuracy=0.758, val_loss=2.34, val_accuracy=0.365, lr=0.1]    81%|████████  | 67/83 [19:28<04:34, 17.18s/epoch, loss=1.14, accuracy=0.757, val_loss=1.58, val_accuracy=0.598, lr=0.1] 82%|████████▏ | 68/83 [19:46<04:20, 17.35s/epoch, loss=1.13, accuracy=0.759, val_loss=2.11, val_accuracy=0.544, lr=0.1] 83%|████████▎ | 69/83 [20:04<04:04, 17.48s/epoch, loss=1.12, accuracy=0.759, val_loss=1.37, val_accuracy=0.667, lr=0.1] 84%|████████▍ | 70/83 [20:21<03:46, 17.39s/epoch, loss=1.13, accuracy=0.759, val_loss=3.02, val_accuracy=0.288, lr=0.1] 86%|████████▌ | 71/83 [20:38<03:27, 17.32s/epoch, loss=1.13, accuracy=0.758, val_loss=2.03, val_accuracy=0.437, lr=0.1] 87%|████████▋ | 72/83 [20:55<03:09, 17.19s/epoch, loss=1.12, accuracy=0.759, val_loss=1.93, val_accuracy=0.494, lr=0.1] 88%|████████▊ | 73/83 [21:12<02:50, 17.10s/epoch, loss=1.13, accuracy=0.756, val_loss=1.81, val_accuracy=0.534, lr=0.1] 89%|████████▉ | 74/83 [21:29<02:34, 17.16s/epoch, loss=1.13, accuracy=0.758, val_loss=1.43, val_accuracy=0.657, lr=0.0316] 90%|█████████ | 75/83 [21:46<02:16, 17.00s/epoch, loss=1.13, accuracy=0.758, val_loss=3, val_accuracy=0.42, lr=0.1]        92%|█████████▏| 76/83 [22:03<01:58, 16.87s/epoch, loss=1.13, accuracy=0.756, val_loss=1.86, val_accuracy=0.495, lr=0.1] 93%|█████████▎| 77/83 [22:19<01:40, 16.74s/epoch, loss=1.12, accuracy=0.758, val_loss=1.98, val_accuracy=0.475, lr=0.1] 94%|█████████▍| 78/83 [22:36<01:23, 16.73s/epoch, loss=1.12, accuracy=0.756, val_loss=1.63, val_accuracy=0.581, lr=0.1] 95%|█████████▌| 79/83 [22:52<01:06, 16.66s/epoch, loss=1.12, accuracy=0.758, val_loss=2.15, val_accuracy=0.452, lr=0.0316] 96%|█████████▋| 80/83 [23:09<00:50, 16.73s/epoch, loss=1.11, accuracy=0.757, val_loss=1.96, val_accuracy=0.585, lr=0.1]    98%|█████████▊| 81/83 [23:26<00:33, 16.81s/epoch, loss=1.12, accuracy=0.758, val_loss=2.3, val_accuracy=0.425, lr=0.1]  99%|█████████▉| 82/83 [23:43<00:16, 16.88s/epoch, loss=0.914, accuracy=0.817, val_loss=0.858, val_accuracy=0.824, lr=0.01]100%|██████████| 83/83 [24:00<00:00, 16.76s/epoch, loss=0.739, accuracy=0.847, val_loss=0.784, val_accuracy=0.817, lr=0.01]100%|██████████| 83/83 [24:00<00:00, 17.35s/epoch, loss=0.739, accuracy=0.847, val_loss=0.784, val_accuracy=0.817, lr=0.01]
Using real-time data augmentation.
Test score: 0.8913900256156921
Test accuracy: 0.8055999875068665


* * * Run SGD for ID = 18_13. * * *


2024-02-20 03:56:15.078981: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 03:56:17.564400: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 03:56:17.565220: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-20 03:56:17.600437: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-20 03:56:17.600472: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 03:56:17.603103: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 03:56:17.603141: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-20 03:56:17.605374: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-20 03:56:17.606497: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-20 03:56:17.608848: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-20 03:56:17.610196: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-20 03:56:17.614541: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 03:56:17.615083: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-20 03:56:17.615160: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 03:56:18.965719: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-20 03:56:18.966704: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 03:56:18.967431: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-20 03:56:18.967459: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 03:56:18.967494: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 03:56:18.967511: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-20 03:56:18.967527: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-20 03:56:18.967543: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-20 03:56:18.967558: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-20 03:56:18.967573: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-20 03:56:18.967588: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 03:56:18.968036: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-20 03:56:18.968071: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 03:56:19.544899: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-20 03:56:19.545982: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-20 03:56:19.546001: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-20 03:56:19.546862: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:03:00.0, compute capability: 6.1)
{'id': '18_13', 'batch_size': 128, 'epochs': 83, 'validation_split': 0.1, 'checkpointing': True, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
x_train shape: (45000, 32, 32, 3)
45000 train samples
5000 validation samples
10000 test samples
y_train shape: (45000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/83 [00:00<?, ?epoch/s]2024-02-20 03:56:20.306159: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-20 03:56:20.306726: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600020000 Hz
2024-02-20 03:56:22.153080: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 03:56:22.360793: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 03:56:22.943909: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-20 03:56:22.983677: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/83 [00:40<55:50, 40.86s/epoch, loss=3.32, accuracy=0.282, val_loss=2.71, val_accuracy=0.188, lr=0.1]  2%|▏         | 2/83 [00:57<36:06, 26.74s/epoch, loss=1.64, accuracy=0.496, val_loss=1.7, val_accuracy=0.487, lr=0.1]   4%|▎         | 3/83 [01:14<29:39, 22.25s/epoch, loss=1.43, accuracy=0.586, val_loss=2.01, val_accuracy=0.451, lr=0.1]  5%|▍         | 4/83 [01:32<26:59, 20.51s/epoch, loss=1.32, accuracy=0.649, val_loss=6.18, val_accuracy=0.203, lr=0.1]  6%|▌         | 5/83 [01:49<25:08, 19.34s/epoch, loss=1.27, accuracy=0.685, val_loss=2.83, val_accuracy=0.293, lr=0.1]  7%|▋         | 6/83 [02:07<24:16, 18.92s/epoch, loss=1.25, accuracy=0.704, val_loss=3.58, val_accuracy=0.258, lr=0.1]  8%|▊         | 7/83 [02:24<23:00, 18.17s/epoch, loss=1.24, accuracy=0.714, val_loss=2.5, val_accuracy=0.438, lr=0.0316] 10%|▉         | 8/83 [02:42<22:31, 18.02s/epoch, loss=1.22, accuracy=0.721, val_loss=1.73, val_accuracy=0.551, lr=0.1]   11%|█         | 9/83 [02:58<21:34, 17.49s/epoch, loss=1.21, accuracy=0.725, val_loss=1.91, val_accuracy=0.529, lr=0.1] 12%|█▏        | 10/83 [03:15<21:06, 17.34s/epoch, loss=1.21, accuracy=0.729, val_loss=1.56, val_accuracy=0.608, lr=0.1] 13%|█▎        | 11/83 [03:32<20:44, 17.29s/epoch, loss=1.2, accuracy=0.733, val_loss=2.95, val_accuracy=0.346, lr=0.1]  14%|█▍        | 12/83 [03:49<20:12, 17.08s/epoch, loss=1.2, accuracy=0.734, val_loss=2.34, val_accuracy=0.42, lr=0.1]  16%|█▌        | 13/83 [04:05<19:41, 16.89s/epoch, loss=1.19, accuracy=0.737, val_loss=2.13, val_accuracy=0.43, lr=0.1] 17%|█▋        | 14/83 [04:22<19:27, 16.92s/epoch, loss=1.19, accuracy=0.741, val_loss=1.52, val_accuracy=0.636, lr=0.1] 18%|█▊        | 15/83 [04:39<18:57, 16.73s/epoch, loss=1.18, accuracy=0.741, val_loss=1.74, val_accuracy=0.542, lr=0.1] 19%|█▉        | 16/83 [04:55<18:41, 16.74s/epoch, loss=1.18, accuracy=0.744, val_loss=1.83, val_accuracy=0.566, lr=0.1] 20%|██        | 17/83 [05:12<18:28, 16.80s/epoch, loss=1.18, accuracy=0.742, val_loss=2.78, val_accuracy=0.341, lr=0.1] 22%|██▏       | 18/83 [05:29<18:08, 16.74s/epoch, loss=1.18, accuracy=0.746, val_loss=1.68, val_accuracy=0.561, lr=0.1] 23%|██▎       | 19/83 [05:45<17:47, 16.69s/epoch, loss=1.17, accuracy=0.745, val_loss=2.5, val_accuracy=0.359, lr=0.0316] 24%|██▍       | 20/83 [06:02<17:23, 16.56s/epoch, loss=1.17, accuracy=0.745, val_loss=3.77, val_accuracy=0.269, lr=0.1]   25%|██▌       | 21/83 [06:18<17:03, 16.50s/epoch, loss=1.16, accuracy=0.747, val_loss=1.98, val_accuracy=0.545, lr=0.1] 27%|██▋       | 22/83 [06:35<16:50, 16.57s/epoch, loss=1.16, accuracy=0.749, val_loss=2.02, val_accuracy=0.52, lr=0.1]  28%|██▊       | 23/83 [06:51<16:33, 16.56s/epoch, loss=1.17, accuracy=0.745, val_loss=1.89, val_accuracy=0.535, lr=0.1] 29%|██▉       | 24/83 [07:08<16:23, 16.67s/epoch, loss=1.16, accuracy=0.746, val_loss=1.69, val_accuracy=0.595, lr=0.0316] 30%|███       | 25/83 [07:25<16:07, 16.67s/epoch, loss=1.16, accuracy=0.748, val_loss=2.22, val_accuracy=0.38, lr=0.1]     31%|███▏      | 26/83 [07:42<15:51, 16.69s/epoch, loss=1.15, accuracy=0.75, val_loss=2.55, val_accuracy=0.45, lr=0.1]  33%|███▎      | 27/83 [07:58<15:33, 16.67s/epoch, loss=1.16, accuracy=0.75, val_loss=1.76, val_accuracy=0.554, lr=0.1] 34%|███▎      | 28/83 [08:15<15:17, 16.68s/epoch, loss=1.15, accuracy=0.751, val_loss=1.66, val_accuracy=0.574, lr=0.1] 35%|███▍      | 29/83 [08:32<15:00, 16.67s/epoch, loss=1.15, accuracy=0.751, val_loss=1.73, val_accuracy=0.572, lr=0.0316] 36%|███▌      | 30/83 [08:48<14:42, 16.65s/epoch, loss=1.15, accuracy=0.752, val_loss=2.39, val_accuracy=0.456, lr=0.1]    37%|███▋      | 31/83 [09:05<14:28, 16.71s/epoch, loss=1.15, accuracy=0.753, val_loss=5.02, val_accuracy=0.206, lr=0.1] 39%|███▊      | 32/83 [09:21<14:08, 16.64s/epoch, loss=1.15, accuracy=0.752, val_loss=1.76, val_accuracy=0.581, lr=0.1] 40%|███▉      | 33/83 [09:38<13:50, 16.61s/epoch, loss=1.15, accuracy=0.752, val_loss=2.09, val_accuracy=0.473, lr=0.1] 41%|████      | 34/83 [09:55<13:33, 16.59s/epoch, loss=1.15, accuracy=0.754, val_loss=2.14, val_accuracy=0.42, lr=0.0316] 42%|████▏     | 35/83 [10:11<13:12, 16.51s/epoch, loss=1.14, accuracy=0.754, val_loss=1.67, val_accuracy=0.559, lr=0.1]   43%|████▎     | 36/83 [10:27<12:55, 16.50s/epoch, loss=1.15, accuracy=0.753, val_loss=2.64, val_accuracy=0.34, lr=0.1]  45%|████▍     | 37/83 [10:44<12:35, 16.42s/epoch, loss=1.15, accuracy=0.752, val_loss=2.3, val_accuracy=0.43, lr=0.1]  46%|████▌     | 38/83 [11:00<12:18, 16.41s/epoch, loss=1.15, accuracy=0.755, val_loss=2.77, val_accuracy=0.428, lr=0.1] 47%|████▋     | 39/83 [11:17<12:07, 16.53s/epoch, loss=1.15, accuracy=0.755, val_loss=2.36, val_accuracy=0.445, lr=0.0316] 48%|████▊     | 40/83 [11:33<11:51, 16.55s/epoch, loss=1.14, accuracy=0.755, val_loss=1.51, val_accuracy=0.632, lr=0.1]    49%|████▉     | 41/83 [11:50<11:34, 16.55s/epoch, loss=1.14, accuracy=0.752, val_loss=1.74, val_accuracy=0.575, lr=0.1] 51%|█████     | 42/83 [12:07<11:21, 16.62s/epoch, loss=1.14, accuracy=0.756, val_loss=2.16, val_accuracy=0.389, lr=0.1] 52%|█████▏    | 43/83 [12:24<11:13, 16.84s/epoch, loss=1.14, accuracy=0.754, val_loss=1.79, val_accuracy=0.498, lr=0.1] 53%|█████▎    | 44/83 [12:41<10:54, 16.77s/epoch, loss=1.13, accuracy=0.757, val_loss=2.08, val_accuracy=0.444, lr=0.1] 54%|█████▍    | 45/83 [12:58<10:39, 16.82s/epoch, loss=1.14, accuracy=0.756, val_loss=2.04, val_accuracy=0.44, lr=0.0316] 55%|█████▌    | 46/83 [13:14<10:19, 16.75s/epoch, loss=1.14, accuracy=0.757, val_loss=2.24, val_accuracy=0.404, lr=0.1]   57%|█████▋    | 47/83 [13:31<10:05, 16.82s/epoch, loss=1.14, accuracy=0.755, val_loss=2.35, val_accuracy=0.399, lr=0.1] 58%|█████▊    | 48/83 [13:48<09:51, 16.89s/epoch, loss=1.14, accuracy=0.756, val_loss=2.15, val_accuracy=0.482, lr=0.1] 59%|█████▉    | 49/83 [14:05<09:33, 16.86s/epoch, loss=1.13, accuracy=0.756, val_loss=2.39, val_accuracy=0.439, lr=0.1] 60%|██████    | 50/83 [14:22<09:19, 16.95s/epoch, loss=1.13, accuracy=0.757, val_loss=1.62, val_accuracy=0.615, lr=0.0316] 61%|██████▏   | 51/83 [14:39<08:59, 16.87s/epoch, loss=1.14, accuracy=0.754, val_loss=1.65, val_accuracy=0.569, lr=0.1]    63%|██████▎   | 52/83 [14:56<08:42, 16.84s/epoch, loss=1.14, accuracy=0.755, val_loss=5.71, val_accuracy=0.155, lr=0.1] 64%|██████▍   | 53/83 [15:12<08:22, 16.76s/epoch, loss=1.13, accuracy=0.756, val_loss=2.06, val_accuracy=0.473, lr=0.1] 65%|██████▌   | 54/83 [15:29<08:03, 16.66s/epoch, loss=1.13, accuracy=0.758, val_loss=5.92, val_accuracy=0.284, lr=0.1] 66%|██████▋   | 55/83 [15:45<07:45, 16.62s/epoch, loss=1.14, accuracy=0.759, val_loss=5.44, val_accuracy=0.147, lr=0.0316] 67%|██████▋   | 56/83 [16:02<07:30, 16.68s/epoch, loss=1.13, accuracy=0.755, val_loss=2.83, val_accuracy=0.43, lr=0.1]     69%|██████▊   | 57/83 [16:18<07:11, 16.58s/epoch, loss=1.13, accuracy=0.76, val_loss=3.07, val_accuracy=0.362, lr=0.1] 70%|██████▉   | 58/83 [16:35<06:58, 16.73s/epoch, loss=1.12, accuracy=0.759, val_loss=2.54, val_accuracy=0.356, lr=0.1] 71%|███████   | 59/83 [16:52<06:41, 16.72s/epoch, loss=1.13, accuracy=0.757, val_loss=2.62, val_accuracy=0.393, lr=0.1] 72%|███████▏  | 60/83 [17:09<06:25, 16.76s/epoch, loss=1.12, accuracy=0.757, val_loss=2.46, val_accuracy=0.444, lr=0.0316] 73%|███████▎  | 61/83 [17:26<06:08, 16.76s/epoch, loss=1.13, accuracy=0.759, val_loss=3.51, val_accuracy=0.286, lr=0.1]    75%|███████▍  | 62/83 [17:42<05:51, 16.72s/epoch, loss=1.12, accuracy=0.759, val_loss=2.88, val_accuracy=0.411, lr=0.1] 76%|███████▌  | 63/83 [17:59<05:35, 16.78s/epoch, loss=1.13, accuracy=0.758, val_loss=4.36, val_accuracy=0.299, lr=0.1] 77%|███████▋  | 64/83 [18:16<05:20, 16.88s/epoch, loss=1.12, accuracy=0.759, val_loss=3.78, val_accuracy=0.254, lr=0.1] 78%|███████▊  | 65/83 [18:34<05:05, 16.99s/epoch, loss=1.13, accuracy=0.76, val_loss=1.57, val_accuracy=0.605, lr=0.0316] 80%|███████▉  | 66/83 [18:51<04:49, 17.01s/epoch, loss=1.12, accuracy=0.758, val_loss=1.93, val_accuracy=0.548, lr=0.1]   81%|████████  | 67/83 [19:07<04:30, 16.93s/epoch, loss=1.12, accuracy=0.759, val_loss=3.52, val_accuracy=0.263, lr=0.1] 82%|████████▏ | 68/83 [19:24<04:12, 16.82s/epoch, loss=1.12, accuracy=0.759, val_loss=1.99, val_accuracy=0.484, lr=0.1] 83%|████████▎ | 69/83 [19:41<03:54, 16.75s/epoch, loss=1.13, accuracy=0.757, val_loss=4.06, val_accuracy=0.369, lr=0.1] 84%|████████▍ | 70/83 [19:57<03:37, 16.70s/epoch, loss=1.12, accuracy=0.76, val_loss=2.69, val_accuracy=0.471, lr=0.0316] 86%|████████▌ | 71/83 [20:14<03:19, 16.62s/epoch, loss=1.13, accuracy=0.759, val_loss=2.28, val_accuracy=0.375, lr=0.1]   87%|████████▋ | 72/83 [20:30<03:01, 16.50s/epoch, loss=1.12, accuracy=0.76, val_loss=1.58, val_accuracy=0.58, lr=0.1]   88%|████████▊ | 73/83 [20:46<02:44, 16.45s/epoch, loss=1.13, accuracy=0.758, val_loss=1.59, val_accuracy=0.595, lr=0.1] 89%|████████▉ | 74/83 [21:03<02:28, 16.53s/epoch, loss=1.12, accuracy=0.759, val_loss=1.58, val_accuracy=0.629, lr=0.1] 90%|█████████ | 75/83 [21:19<02:12, 16.50s/epoch, loss=1.12, accuracy=0.761, val_loss=1.94, val_accuracy=0.507, lr=0.0316] 92%|█████████▏| 76/83 [21:36<01:56, 16.59s/epoch, loss=1.12, accuracy=0.759, val_loss=2.65, val_accuracy=0.371, lr=0.1]    93%|█████████▎| 77/83 [21:52<01:38, 16.48s/epoch, loss=1.12, accuracy=0.76, val_loss=2.48, val_accuracy=0.369, lr=0.1]  94%|█████████▍| 78/83 [22:09<01:22, 16.46s/epoch, loss=1.13, accuracy=0.757, val_loss=2.26, val_accuracy=0.448, lr=0.1] 95%|█████████▌| 79/83 [22:25<01:05, 16.49s/epoch, loss=1.12, accuracy=0.762, val_loss=3.38, val_accuracy=0.356, lr=0.1] 96%|█████████▋| 80/83 [22:42<00:49, 16.54s/epoch, loss=1.12, accuracy=0.761, val_loss=1.94, val_accuracy=0.462, lr=0.0316] 98%|█████████▊| 81/83 [23:00<00:33, 16.88s/epoch, loss=1.12, accuracy=0.758, val_loss=1.96, val_accuracy=0.556, lr=0.1]    99%|█████████▉| 82/83 [23:16<00:16, 16.85s/epoch, loss=0.914, accuracy=0.82, val_loss=0.912, val_accuracy=0.804, lr=0.01]100%|██████████| 83/83 [23:33<00:00, 16.87s/epoch, loss=0.737, accuracy=0.852, val_loss=0.819, val_accuracy=0.81, lr=0.01]100%|██████████| 83/83 [23:33<00:00, 17.03s/epoch, loss=0.737, accuracy=0.852, val_loss=0.819, val_accuracy=0.81, lr=0.01]
Using real-time data augmentation.
Test score: 0.8199740052223206
Test accuracy: 0.8112000226974487


* * * Run SGD for ID = 18_14. * * *


2024-02-20 04:19:59.937439: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 04:20:02.436131: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 04:20:02.437059: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-20 04:20:02.472434: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-20 04:20:02.472465: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 04:20:02.475217: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 04:20:02.475270: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-20 04:20:02.477498: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-20 04:20:02.478224: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-20 04:20:02.480503: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-20 04:20:02.482068: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-20 04:20:02.486373: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 04:20:02.486840: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-20 04:20:02.486939: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 04:20:03.891393: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-20 04:20:03.892324: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 04:20:03.893109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-20 04:20:03.893139: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 04:20:03.893174: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 04:20:03.893190: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-20 04:20:03.893205: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-20 04:20:03.893221: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-20 04:20:03.893235: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-20 04:20:03.893249: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-20 04:20:03.893264: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 04:20:03.893712: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-20 04:20:03.893747: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 04:20:04.470210: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-20 04:20:04.470268: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-20 04:20:04.470276: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-20 04:20:04.471145: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:03:00.0, compute capability: 6.1)
{'id': '18_14', 'batch_size': 128, 'epochs': 83, 'validation_split': 0.1, 'checkpointing': True, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
x_train shape: (45000, 32, 32, 3)
45000 train samples
5000 validation samples
10000 test samples
y_train shape: (45000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/83 [00:00<?, ?epoch/s]2024-02-20 04:20:05.262472: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-20 04:20:05.274096: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600020000 Hz
2024-02-20 04:20:07.077205: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 04:20:07.330283: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 04:20:08.038239: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-20 04:20:08.082234: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/83 [00:45<1:02:27, 45.70s/epoch, loss=3.43, accuracy=0.27, val_loss=2.42, val_accuracy=0.244, lr=0.1]  2%|▏         | 2/83 [01:04<40:15, 29.83s/epoch, loss=1.71, accuracy=0.459, val_loss=2.68, val_accuracy=0.316, lr=0.1]   4%|▎         | 3/83 [01:22<32:24, 24.31s/epoch, loss=1.45, accuracy=0.581, val_loss=2.85, val_accuracy=0.376, lr=0.1]  5%|▍         | 4/83 [01:39<28:34, 21.71s/epoch, loss=1.34, accuracy=0.652, val_loss=1.82, val_accuracy=0.478, lr=0.1]  6%|▌         | 5/83 [01:57<26:20, 20.26s/epoch, loss=1.3, accuracy=0.68, val_loss=1.8, val_accuracy=0.55, lr=0.1]      7%|▋         | 6/83 [02:14<24:43, 19.27s/epoch, loss=1.27, accuracy=0.696, val_loss=1.95, val_accuracy=0.506, lr=0.1]  8%|▊         | 7/83 [02:32<23:45, 18.76s/epoch, loss=1.25, accuracy=0.709, val_loss=1.7, val_accuracy=0.539, lr=0.1]  10%|▉         | 8/83 [02:50<22:55, 18.35s/epoch, loss=1.23, accuracy=0.717, val_loss=4.48, val_accuracy=0.177, lr=0.1] 11%|█         | 9/83 [03:07<22:19, 18.10s/epoch, loss=1.22, accuracy=0.722, val_loss=1.93, val_accuracy=0.537, lr=0.1] 12%|█▏        | 10/83 [03:24<21:39, 17.80s/epoch, loss=1.22, accuracy=0.726, val_loss=1.62, val_accuracy=0.609, lr=0.1] 13%|█▎        | 11/83 [03:42<21:15, 17.71s/epoch, loss=1.22, accuracy=0.727, val_loss=2.12, val_accuracy=0.431, lr=0.1] 14%|█▍        | 12/83 [03:59<20:45, 17.55s/epoch, loss=1.21, accuracy=0.729, val_loss=1.94, val_accuracy=0.537, lr=0.1] 16%|█▌        | 13/83 [04:16<20:26, 17.52s/epoch, loss=1.21, accuracy=0.73, val_loss=3.64, val_accuracy=0.255, lr=0.1]  17%|█▋        | 14/83 [04:34<20:02, 17.43s/epoch, loss=1.19, accuracy=0.736, val_loss=1.97, val_accuracy=0.543, lr=0.1] 18%|█▊        | 15/83 [04:51<19:34, 17.27s/epoch, loss=1.2, accuracy=0.737, val_loss=3.83, val_accuracy=0.385, lr=0.0316] 19%|█▉        | 16/83 [05:08<19:29, 17.46s/epoch, loss=1.19, accuracy=0.738, val_loss=2.16, val_accuracy=0.452, lr=0.1]   20%|██        | 17/83 [05:26<19:15, 17.51s/epoch, loss=1.19, accuracy=0.736, val_loss=1.86, val_accuracy=0.533, lr=0.1] 22%|██▏       | 18/83 [05:44<18:58, 17.51s/epoch, loss=1.18, accuracy=0.743, val_loss=1.9, val_accuracy=0.516, lr=0.1]  23%|██▎       | 19/83 [06:00<18:27, 17.31s/epoch, loss=1.18, accuracy=0.742, val_loss=1.62, val_accuracy=0.572, lr=0.1] 24%|██▍       | 20/83 [06:18<18:12, 17.34s/epoch, loss=1.18, accuracy=0.743, val_loss=1.51, val_accuracy=0.623, lr=0.1] 25%|██▌       | 21/83 [06:35<17:59, 17.41s/epoch, loss=1.18, accuracy=0.743, val_loss=1.92, val_accuracy=0.523, lr=0.1] 27%|██▋       | 22/83 [06:53<17:40, 17.38s/epoch, loss=1.18, accuracy=0.746, val_loss=1.89, val_accuracy=0.539, lr=0.1] 28%|██▊       | 23/83 [07:10<17:30, 17.50s/epoch, loss=1.18, accuracy=0.744, val_loss=1.38, val_accuracy=0.676, lr=0.1] 29%|██▉       | 24/83 [07:27<17:03, 17.34s/epoch, loss=1.17, accuracy=0.742, val_loss=1.71, val_accuracy=0.579, lr=0.1] 30%|███       | 25/83 [07:45<16:56, 17.53s/epoch, loss=1.17, accuracy=0.745, val_loss=1.72, val_accuracy=0.579, lr=0.1] 31%|███▏      | 26/83 [08:03<16:40, 17.56s/epoch, loss=1.16, accuracy=0.746, val_loss=2.37, val_accuracy=0.422, lr=0.1] 33%|███▎      | 27/83 [08:20<16:13, 17.39s/epoch, loss=1.17, accuracy=0.746, val_loss=1.91, val_accuracy=0.525, lr=0.1] 34%|███▎      | 28/83 [08:38<15:57, 17.41s/epoch, loss=1.15, accuracy=0.746, val_loss=1.77, val_accuracy=0.556, lr=0.0316] 35%|███▍      | 29/83 [08:55<15:36, 17.35s/epoch, loss=1.17, accuracy=0.748, val_loss=2.44, val_accuracy=0.487, lr=0.1]    36%|███▌      | 30/83 [09:12<15:17, 17.31s/epoch, loss=1.16, accuracy=0.746, val_loss=1.63, val_accuracy=0.578, lr=0.1] 37%|███▋      | 31/83 [09:29<15:03, 17.38s/epoch, loss=1.15, accuracy=0.75, val_loss=1.72, val_accuracy=0.558, lr=0.1]  39%|███▊      | 32/83 [09:47<14:55, 17.57s/epoch, loss=1.15, accuracy=0.749, val_loss=1.37, val_accuracy=0.684, lr=0.1] 40%|███▉      | 33/83 [10:05<14:37, 17.54s/epoch, loss=1.15, accuracy=0.75, val_loss=1.62, val_accuracy=0.578, lr=0.1]  41%|████      | 34/83 [10:22<14:18, 17.52s/epoch, loss=1.15, accuracy=0.749, val_loss=1.81, val_accuracy=0.517, lr=0.1] 42%|████▏     | 35/83 [10:40<14:01, 17.53s/epoch, loss=1.14, accuracy=0.751, val_loss=2.16, val_accuracy=0.427, lr=0.1] 43%|████▎     | 36/83 [10:57<13:39, 17.44s/epoch, loss=1.15, accuracy=0.75, val_loss=1.72, val_accuracy=0.584, lr=0.1]  45%|████▍     | 37/83 [11:15<13:25, 17.51s/epoch, loss=1.14, accuracy=0.753, val_loss=2.22, val_accuracy=0.451, lr=0.0316] 46%|████▌     | 38/83 [11:33<13:19, 17.76s/epoch, loss=1.14, accuracy=0.75, val_loss=3.14, val_accuracy=0.327, lr=0.1]     47%|████▋     | 39/83 [11:51<12:55, 17.63s/epoch, loss=1.14, accuracy=0.752, val_loss=2.05, val_accuracy=0.466, lr=0.1] 48%|████▊     | 40/83 [12:08<12:39, 17.66s/epoch, loss=1.14, accuracy=0.753, val_loss=2.24, val_accuracy=0.47, lr=0.1]  49%|████▉     | 41/83 [12:26<12:16, 17.54s/epoch, loss=1.14, accuracy=0.75, val_loss=1.53, val_accuracy=0.642, lr=0.1] 51%|█████     | 42/83 [12:43<11:57, 17.49s/epoch, loss=1.14, accuracy=0.754, val_loss=2.64, val_accuracy=0.461, lr=0.0316] 52%|█████▏    | 43/83 [13:00<11:35, 17.38s/epoch, loss=1.14, accuracy=0.751, val_loss=1.51, val_accuracy=0.654, lr=0.1]    53%|█████▎    | 44/83 [13:18<11:18, 17.41s/epoch, loss=1.14, accuracy=0.753, val_loss=3.58, val_accuracy=0.318, lr=0.1] 54%|█████▍    | 45/83 [13:35<11:03, 17.45s/epoch, loss=1.14, accuracy=0.752, val_loss=2.03, val_accuracy=0.538, lr=0.1] 55%|█████▌    | 46/83 [13:52<10:42, 17.37s/epoch, loss=1.14, accuracy=0.755, val_loss=1.6, val_accuracy=0.611, lr=0.1]  57%|█████▋    | 47/83 [14:10<10:26, 17.39s/epoch, loss=1.15, accuracy=0.752, val_loss=2.25, val_accuracy=0.489, lr=0.0316] 58%|█████▊    | 48/83 [14:27<10:10, 17.43s/epoch, loss=1.13, accuracy=0.755, val_loss=2.23, val_accuracy=0.418, lr=0.1]    59%|█████▉    | 49/83 [14:45<09:52, 17.44s/epoch, loss=1.13, accuracy=0.754, val_loss=1.88, val_accuracy=0.514, lr=0.1] 60%|██████    | 50/83 [15:02<09:32, 17.35s/epoch, loss=1.13, accuracy=0.754, val_loss=2.17, val_accuracy=0.467, lr=0.1] 61%|██████▏   | 51/83 [15:19<09:15, 17.36s/epoch, loss=1.13, accuracy=0.754, val_loss=1.98, val_accuracy=0.532, lr=0.1] 63%|██████▎   | 52/83 [15:36<08:56, 17.31s/epoch, loss=1.13, accuracy=0.755, val_loss=1.69, val_accuracy=0.576, lr=0.0316] 64%|██████▍   | 53/83 [15:54<08:42, 17.43s/epoch, loss=1.13, accuracy=0.756, val_loss=3.61, val_accuracy=0.264, lr=0.1]    65%|██████▌   | 54/83 [16:11<08:22, 17.32s/epoch, loss=1.12, accuracy=0.757, val_loss=2.68, val_accuracy=0.373, lr=0.1] 66%|██████▋   | 55/83 [16:29<08:05, 17.34s/epoch, loss=1.13, accuracy=0.757, val_loss=1.73, val_accuracy=0.577, lr=0.1] 67%|██████▋   | 56/83 [16:47<07:54, 17.56s/epoch, loss=1.12, accuracy=0.758, val_loss=2.09, val_accuracy=0.534, lr=0.1] 69%|██████▊   | 57/83 [17:05<07:41, 17.75s/epoch, loss=1.13, accuracy=0.757, val_loss=2.71, val_accuracy=0.367, lr=0.0316] 70%|██████▉   | 58/83 [17:23<07:25, 17.80s/epoch, loss=1.12, accuracy=0.758, val_loss=1.5, val_accuracy=0.625, lr=0.1]     71%|███████   | 59/83 [17:40<07:04, 17.68s/epoch, loss=1.12, accuracy=0.756, val_loss=3.39, val_accuracy=0.198, lr=0.1] 72%|███████▏  | 60/83 [17:57<06:41, 17.44s/epoch, loss=1.13, accuracy=0.755, val_loss=1.63, val_accuracy=0.603, lr=0.1] 73%|███████▎  | 61/83 [18:14<06:20, 17.30s/epoch, loss=1.12, accuracy=0.755, val_loss=2.44, val_accuracy=0.438, lr=0.1] 75%|███████▍  | 62/83 [18:31<06:03, 17.31s/epoch, loss=1.12, accuracy=0.756, val_loss=7.75, val_accuracy=0.191, lr=0.0316] 76%|███████▌  | 63/83 [18:49<05:46, 17.32s/epoch, loss=1.12, accuracy=0.754, val_loss=1.99, val_accuracy=0.458, lr=0.1]    77%|███████▋  | 64/83 [19:06<05:26, 17.18s/epoch, loss=1.12, accuracy=0.757, val_loss=1.85, val_accuracy=0.512, lr=0.1] 78%|███████▊  | 65/83 [19:22<05:07, 17.11s/epoch, loss=1.12, accuracy=0.754, val_loss=2.98, val_accuracy=0.342, lr=0.1] 80%|███████▉  | 66/83 [19:39<04:50, 17.06s/epoch, loss=1.12, accuracy=0.756, val_loss=5.47, val_accuracy=0.155, lr=0.1] 81%|████████  | 67/83 [19:56<04:31, 16.97s/epoch, loss=1.12, accuracy=0.758, val_loss=1.52, val_accuracy=0.648, lr=0.0316] 82%|████████▏ | 68/83 [20:13<04:15, 17.03s/epoch, loss=1.12, accuracy=0.755, val_loss=2.69, val_accuracy=0.416, lr=0.1]    83%|████████▎ | 69/83 [20:30<03:58, 17.06s/epoch, loss=1.11, accuracy=0.759, val_loss=2.34, val_accuracy=0.37, lr=0.1]  84%|████████▍ | 70/83 [20:48<03:44, 17.29s/epoch, loss=1.12, accuracy=0.756, val_loss=2.2, val_accuracy=0.485, lr=0.1] 86%|████████▌ | 71/83 [21:06<03:27, 17.28s/epoch, loss=1.11, accuracy=0.759, val_loss=2.33, val_accuracy=0.47, lr=0.1] 87%|████████▋ | 72/83 [21:23<03:11, 17.42s/epoch, loss=1.12, accuracy=0.755, val_loss=1.64, val_accuracy=0.608, lr=0.0316] 88%|████████▊ | 73/83 [21:41<02:53, 17.36s/epoch, loss=1.12, accuracy=0.757, val_loss=1.59, val_accuracy=0.612, lr=0.1]    89%|████████▉ | 74/83 [21:58<02:36, 17.35s/epoch, loss=1.11, accuracy=0.756, val_loss=2.12, val_accuracy=0.485, lr=0.1] 90%|█████████ | 75/83 [22:15<02:18, 17.25s/epoch, loss=1.11, accuracy=0.756, val_loss=1.81, val_accuracy=0.508, lr=0.1] 92%|█████████▏| 76/83 [22:32<02:00, 17.23s/epoch, loss=1.12, accuracy=0.759, val_loss=2.31, val_accuracy=0.453, lr=0.1] 93%|█████████▎| 77/83 [22:49<01:42, 17.14s/epoch, loss=1.11, accuracy=0.758, val_loss=2.75, val_accuracy=0.377, lr=0.0316] 94%|█████████▍| 78/83 [23:06<01:25, 17.06s/epoch, loss=1.11, accuracy=0.756, val_loss=3.62, val_accuracy=0.281, lr=0.1]    95%|█████████▌| 79/83 [23:23<01:08, 17.17s/epoch, loss=1.12, accuracy=0.757, val_loss=2.98, val_accuracy=0.379, lr=0.1] 96%|█████████▋| 80/83 [23:40<00:51, 17.10s/epoch, loss=1.11, accuracy=0.759, val_loss=1.86, val_accuracy=0.557, lr=0.1] 98%|█████████▊| 81/83 [23:58<00:34, 17.23s/epoch, loss=1.11, accuracy=0.757, val_loss=2.55, val_accuracy=0.465, lr=0.1] 99%|█████████▉| 82/83 [24:15<00:17, 17.32s/epoch, loss=0.914, accuracy=0.813, val_loss=0.915, val_accuracy=0.794, lr=0.01]100%|██████████| 83/83 [24:33<00:00, 17.35s/epoch, loss=0.744, accuracy=0.845, val_loss=0.757, val_accuracy=0.828, lr=0.01]100%|██████████| 83/83 [24:33<00:00, 17.75s/epoch, loss=0.744, accuracy=0.845, val_loss=0.757, val_accuracy=0.828, lr=0.01]
Using real-time data augmentation.
Test score: 0.7868973016738892
Test accuracy: 0.8180000185966492


* * * Run SGD for ID = 18_15. * * *


2024-02-20 04:44:44.210528: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 04:44:47.332552: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 04:44:47.333547: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-20 04:44:47.369386: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-20 04:44:47.369417: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 04:44:47.372281: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 04:44:47.372317: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-20 04:44:47.374600: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-20 04:44:47.375707: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-20 04:44:47.378055: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-20 04:44:47.379695: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-20 04:44:47.383857: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 04:44:47.384357: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-20 04:44:47.384429: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 04:44:48.755736: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-20 04:44:48.757114: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 04:44:48.757855: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-20 04:44:48.757885: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 04:44:48.757920: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 04:44:48.757937: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-20 04:44:48.757953: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-20 04:44:48.757999: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-20 04:44:48.758014: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-20 04:44:48.758029: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-20 04:44:48.758052: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 04:44:48.758506: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-20 04:44:48.758536: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 04:44:49.332145: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-20 04:44:49.332195: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-20 04:44:49.332202: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-20 04:44:49.333052: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:03:00.0, compute capability: 6.1)
{'id': '18_15', 'batch_size': 128, 'epochs': 83, 'validation_split': 0.1, 'checkpointing': True, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
x_train shape: (45000, 32, 32, 3)
45000 train samples
5000 validation samples
10000 test samples
y_train shape: (45000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/83 [00:00<?, ?epoch/s]2024-02-20 04:44:50.088047: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-20 04:44:50.088623: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600020000 Hz
2024-02-20 04:44:51.923356: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 04:44:52.169276: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 04:44:52.756024: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-20 04:44:52.788207: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/83 [00:44<1:00:42, 44.42s/epoch, loss=3.58, accuracy=0.183, val_loss=2.43, val_accuracy=0.184, lr=0.1]  2%|▏         | 2/83 [01:02<38:42, 28.67s/epoch, loss=1.68, accuracy=0.463, val_loss=1.92, val_accuracy=0.434, lr=0.1]    4%|▎         | 3/83 [01:19<31:16, 23.45s/epoch, loss=1.38, accuracy=0.602, val_loss=1.8, val_accuracy=0.498, lr=0.1]   5%|▍         | 4/83 [01:36<27:31, 20.91s/epoch, loss=1.29, accuracy=0.657, val_loss=1.65, val_accuracy=0.545, lr=0.1]  6%|▌         | 5/83 [01:52<25:09, 19.36s/epoch, loss=1.24, accuracy=0.685, val_loss=1.88, val_accuracy=0.497, lr=0.1]  7%|▋         | 6/83 [02:09<23:41, 18.46s/epoch, loss=1.22, accuracy=0.7, val_loss=2.01, val_accuracy=0.468, lr=0.1]    8%|▊         | 7/83 [02:26<22:44, 17.95s/epoch, loss=1.21, accuracy=0.714, val_loss=1.98, val_accuracy=0.455, lr=0.1] 10%|▉         | 8/83 [02:43<21:56, 17.55s/epoch, loss=1.2, accuracy=0.719, val_loss=1.94, val_accuracy=0.527, lr=0.1]  11%|█         | 9/83 [03:00<21:23, 17.35s/epoch, loss=1.2, accuracy=0.723, val_loss=1.98, val_accuracy=0.487, lr=0.0316] 12%|█▏        | 10/83 [03:17<20:57, 17.23s/epoch, loss=1.19, accuracy=0.728, val_loss=2.34, val_accuracy=0.454, lr=0.1]  13%|█▎        | 11/83 [03:34<20:40, 17.23s/epoch, loss=1.19, accuracy=0.729, val_loss=1.82, val_accuracy=0.495, lr=0.1] 14%|█▍        | 12/83 [03:51<20:18, 17.16s/epoch, loss=1.18, accuracy=0.735, val_loss=7.23, val_accuracy=0.121, lr=0.1] 16%|█▌        | 13/83 [04:08<19:57, 17.11s/epoch, loss=1.18, accuracy=0.735, val_loss=1.5, val_accuracy=0.63, lr=0.1]   17%|█▋        | 14/83 [04:25<19:33, 17.00s/epoch, loss=1.17, accuracy=0.737, val_loss=1.59, val_accuracy=0.607, lr=0.1] 18%|█▊        | 15/83 [04:42<19:16, 17.00s/epoch, loss=1.17, accuracy=0.736, val_loss=3.42, val_accuracy=0.299, lr=0.1] 19%|█▉        | 16/83 [04:58<18:52, 16.91s/epoch, loss=1.17, accuracy=0.738, val_loss=1.6, val_accuracy=0.614, lr=0.1]  20%|██        | 17/83 [05:15<18:30, 16.83s/epoch, loss=1.17, accuracy=0.74, val_loss=2.27, val_accuracy=0.485, lr=0.1] 22%|██▏       | 18/83 [05:32<18:13, 16.82s/epoch, loss=1.16, accuracy=0.74, val_loss=2.02, val_accuracy=0.442, lr=0.0316] 23%|██▎       | 19/83 [05:49<17:56, 16.82s/epoch, loss=1.17, accuracy=0.742, val_loss=2.93, val_accuracy=0.37, lr=0.1]    24%|██▍       | 20/83 [06:06<17:46, 16.92s/epoch, loss=1.16, accuracy=0.743, val_loss=3.05, val_accuracy=0.428, lr=0.1] 25%|██▌       | 21/83 [06:22<17:22, 16.82s/epoch, loss=1.16, accuracy=0.743, val_loss=1.87, val_accuracy=0.52, lr=0.1]  27%|██▋       | 22/83 [06:39<17:05, 16.81s/epoch, loss=1.16, accuracy=0.746, val_loss=1.91, val_accuracy=0.543, lr=0.1] 28%|██▊       | 23/83 [06:56<16:46, 16.77s/epoch, loss=1.15, accuracy=0.745, val_loss=1.63, val_accuracy=0.617, lr=0.0316] 29%|██▉       | 24/83 [07:12<16:26, 16.72s/epoch, loss=1.15, accuracy=0.747, val_loss=2.19, val_accuracy=0.483, lr=0.1]    30%|███       | 25/83 [07:29<16:09, 16.71s/epoch, loss=1.14, accuracy=0.749, val_loss=2.18, val_accuracy=0.43, lr=0.1]  31%|███▏      | 26/83 [07:46<15:50, 16.68s/epoch, loss=1.14, accuracy=0.749, val_loss=2.24, val_accuracy=0.415, lr=0.1] 33%|███▎      | 27/83 [08:03<15:41, 16.81s/epoch, loss=1.14, accuracy=0.75, val_loss=2.65, val_accuracy=0.468, lr=0.1]  34%|███▎      | 28/83 [08:20<15:32, 16.95s/epoch, loss=1.14, accuracy=0.751, val_loss=1.84, val_accuracy=0.528, lr=0.0316] 35%|███▍      | 29/83 [08:37<15:17, 16.99s/epoch, loss=1.14, accuracy=0.748, val_loss=1.69, val_accuracy=0.588, lr=0.1]    36%|███▌      | 30/83 [08:55<15:11, 17.20s/epoch, loss=1.15, accuracy=0.748, val_loss=1.95, val_accuracy=0.481, lr=0.1] 37%|███▋      | 31/83 [09:11<14:45, 17.03s/epoch, loss=1.14, accuracy=0.747, val_loss=1.66, val_accuracy=0.578, lr=0.1] 39%|███▊      | 32/83 [09:29<14:35, 17.16s/epoch, loss=1.14, accuracy=0.752, val_loss=2.85, val_accuracy=0.385, lr=0.1] 40%|███▉      | 33/83 [09:46<14:13, 17.08s/epoch, loss=1.14, accuracy=0.749, val_loss=1.85, val_accuracy=0.57, lr=0.0316] 41%|████      | 34/83 [10:03<13:53, 17.01s/epoch, loss=1.13, accuracy=0.754, val_loss=3.19, val_accuracy=0.344, lr=0.1]   42%|████▏     | 35/83 [10:20<13:40, 17.09s/epoch, loss=1.13, accuracy=0.753, val_loss=2.48, val_accuracy=0.451, lr=0.1] 43%|████▎     | 36/83 [10:37<13:20, 17.02s/epoch, loss=1.14, accuracy=0.752, val_loss=2.12, val_accuracy=0.524, lr=0.1] 45%|████▍     | 37/83 [10:54<13:01, 16.98s/epoch, loss=1.13, accuracy=0.752, val_loss=2.24, val_accuracy=0.462, lr=0.1] 46%|████▌     | 38/83 [11:11<12:42, 16.95s/epoch, loss=1.13, accuracy=0.751, val_loss=1.66, val_accuracy=0.581, lr=0.0316] 47%|████▋     | 39/83 [11:27<12:20, 16.83s/epoch, loss=1.13, accuracy=0.753, val_loss=1.68, val_accuracy=0.604, lr=0.1]    48%|████▊     | 40/83 [11:44<12:03, 16.82s/epoch, loss=1.13, accuracy=0.752, val_loss=1.84, val_accuracy=0.577, lr=0.1] 49%|████▉     | 41/83 [12:01<11:43, 16.76s/epoch, loss=1.13, accuracy=0.756, val_loss=3.24, val_accuracy=0.339, lr=0.1] 51%|█████     | 42/83 [12:18<11:35, 16.96s/epoch, loss=1.13, accuracy=0.754, val_loss=2.37, val_accuracy=0.44, lr=0.1]  52%|█████▏    | 43/83 [12:35<11:24, 17.11s/epoch, loss=1.12, accuracy=0.755, val_loss=2.25, val_accuracy=0.396, lr=0.0316] 53%|█████▎    | 44/83 [12:52<11:02, 16.98s/epoch, loss=1.12, accuracy=0.756, val_loss=3.35, val_accuracy=0.375, lr=0.1]    54%|█████▍    | 45/83 [13:09<10:43, 16.95s/epoch, loss=1.13, accuracy=0.754, val_loss=2.84, val_accuracy=0.329, lr=0.1] 55%|█████▌    | 46/83 [13:26<10:33, 17.11s/epoch, loss=1.13, accuracy=0.753, val_loss=1.52, val_accuracy=0.636, lr=0.1] 57%|█████▋    | 47/83 [13:43<10:11, 17.00s/epoch, loss=1.13, accuracy=0.753, val_loss=1.92, val_accuracy=0.52, lr=0.1]  58%|█████▊    | 48/83 [14:01<09:58, 17.09s/epoch, loss=1.12, accuracy=0.753, val_loss=2.17, val_accuracy=0.437, lr=0.0316] 59%|█████▉    | 49/83 [14:18<09:43, 17.17s/epoch, loss=1.12, accuracy=0.754, val_loss=2, val_accuracy=0.472, lr=0.1]       60%|██████    | 50/83 [14:35<09:29, 17.24s/epoch, loss=1.12, accuracy=0.755, val_loss=2.14, val_accuracy=0.478, lr=0.1] 61%|██████▏   | 51/83 [14:52<09:08, 17.14s/epoch, loss=1.11, accuracy=0.757, val_loss=3.32, val_accuracy=0.218, lr=0.1] 63%|██████▎   | 52/83 [15:10<08:53, 17.21s/epoch, loss=1.12, accuracy=0.756, val_loss=2.41, val_accuracy=0.457, lr=0.1] 64%|██████▍   | 53/83 [15:26<08:31, 17.06s/epoch, loss=1.11, accuracy=0.757, val_loss=1.92, val_accuracy=0.508, lr=0.0316] 65%|██████▌   | 54/83 [15:43<08:12, 16.97s/epoch, loss=1.11, accuracy=0.754, val_loss=2.24, val_accuracy=0.494, lr=0.1]    66%|██████▋   | 55/83 [16:00<07:53, 16.92s/epoch, loss=1.12, accuracy=0.755, val_loss=4.04, val_accuracy=0.295, lr=0.1] 67%|██████▋   | 56/83 [16:17<07:39, 17.02s/epoch, loss=1.11, accuracy=0.756, val_loss=1.65, val_accuracy=0.589, lr=0.1] 69%|██████▊   | 57/83 [16:34<07:20, 16.96s/epoch, loss=1.11, accuracy=0.759, val_loss=1.95, val_accuracy=0.471, lr=0.1] 70%|██████▉   | 58/83 [16:51<07:01, 16.88s/epoch, loss=1.12, accuracy=0.756, val_loss=1.9, val_accuracy=0.531, lr=0.0316] 71%|███████   | 59/83 [17:07<06:42, 16.76s/epoch, loss=1.12, accuracy=0.756, val_loss=1.77, val_accuracy=0.552, lr=0.1]   72%|███████▏  | 60/83 [17:24<06:25, 16.77s/epoch, loss=1.12, accuracy=0.758, val_loss=3.03, val_accuracy=0.389, lr=0.1] 73%|███████▎  | 61/83 [17:41<06:09, 16.79s/epoch, loss=1.12, accuracy=0.754, val_loss=2.72, val_accuracy=0.426, lr=0.1] 75%|███████▍  | 62/83 [17:57<05:51, 16.73s/epoch, loss=1.12, accuracy=0.756, val_loss=1.49, val_accuracy=0.606, lr=0.1] 76%|███████▌  | 63/83 [18:15<05:39, 16.95s/epoch, loss=1.1, accuracy=0.76, val_loss=1.63, val_accuracy=0.573, lr=0.1]   77%|███████▋  | 64/83 [18:31<05:20, 16.88s/epoch, loss=1.11, accuracy=0.758, val_loss=3.37, val_accuracy=0.378, lr=0.1] 78%|███████▊  | 65/83 [18:48<05:02, 16.81s/epoch, loss=1.11, accuracy=0.757, val_loss=4, val_accuracy=0.351, lr=0.1]    80%|███████▉  | 66/83 [19:05<04:46, 16.85s/epoch, loss=1.11, accuracy=0.76, val_loss=1.58, val_accuracy=0.593, lr=0.1] 81%|████████  | 67/83 [19:22<04:28, 16.81s/epoch, loss=1.11, accuracy=0.76, val_loss=2.11, val_accuracy=0.475, lr=0.0316] 82%|████████▏ | 68/83 [19:38<04:10, 16.73s/epoch, loss=1.11, accuracy=0.757, val_loss=2.05, val_accuracy=0.581, lr=0.1]   83%|████████▎ | 69/83 [19:55<03:54, 16.73s/epoch, loss=1.11, accuracy=0.759, val_loss=1.71, val_accuracy=0.576, lr=0.1] 84%|████████▍ | 70/83 [20:12<03:38, 16.81s/epoch, loss=1.11, accuracy=0.76, val_loss=3.11, val_accuracy=0.203, lr=0.1]  86%|████████▌ | 71/83 [20:29<03:20, 16.73s/epoch, loss=1.11, accuracy=0.763, val_loss=1.68, val_accuracy=0.57, lr=0.1] 87%|████████▋ | 72/83 [20:46<03:04, 16.81s/epoch, loss=1.11, accuracy=0.757, val_loss=1.54, val_accuracy=0.645, lr=0.0316] 88%|████████▊ | 73/83 [21:02<02:47, 16.79s/epoch, loss=1.1, accuracy=0.76, val_loss=2.66, val_accuracy=0.383, lr=0.1]      89%|████████▉ | 74/83 [21:19<02:31, 16.79s/epoch, loss=1.11, accuracy=0.759, val_loss=2.79, val_accuracy=0.337, lr=0.1] 90%|█████████ | 75/83 [21:36<02:14, 16.80s/epoch, loss=1.1, accuracy=0.76, val_loss=2.31, val_accuracy=0.401, lr=0.1]   92%|█████████▏| 76/83 [21:53<01:57, 16.85s/epoch, loss=1.11, accuracy=0.758, val_loss=2.08, val_accuracy=0.504, lr=0.1] 93%|█████████▎| 77/83 [22:10<01:41, 16.94s/epoch, loss=1.11, accuracy=0.756, val_loss=1.35, val_accuracy=0.672, lr=0.1] 94%|█████████▍| 78/83 [22:27<01:24, 16.88s/epoch, loss=1.11, accuracy=0.759, val_loss=2.72, val_accuracy=0.379, lr=0.1] 95%|█████████▌| 79/83 [22:43<01:07, 16.80s/epoch, loss=1.11, accuracy=0.758, val_loss=2.65, val_accuracy=0.453, lr=0.1] 96%|█████████▋| 80/83 [23:00<00:50, 16.73s/epoch, loss=1.11, accuracy=0.76, val_loss=1.79, val_accuracy=0.561, lr=0.1]  98%|█████████▊| 81/83 [23:17<00:33, 16.94s/epoch, loss=1.1, accuracy=0.76, val_loss=1.57, val_accuracy=0.599, lr=0.1]  99%|█████████▉| 82/83 [23:34<00:16, 16.97s/epoch, loss=0.906, accuracy=0.819, val_loss=0.91, val_accuracy=0.794, lr=0.01]100%|██████████| 83/83 [23:51<00:00, 16.87s/epoch, loss=0.732, accuracy=0.85, val_loss=0.778, val_accuracy=0.819, lr=0.01]100%|██████████| 83/83 [23:51<00:00, 17.25s/epoch, loss=0.732, accuracy=0.85, val_loss=0.778, val_accuracy=0.819, lr=0.01]
Using real-time data augmentation.
Test score: 0.7864024043083191
Test accuracy: 0.8197000026702881


* * * Run SGD for ID = 18_16. * * *


2024-02-20 05:08:46.852147: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 05:08:49.419123: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 05:08:49.419997: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-20 05:08:49.456088: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-20 05:08:49.456116: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 05:08:49.458725: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 05:08:49.458759: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-20 05:08:49.460776: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-20 05:08:49.461500: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-20 05:08:49.463559: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-20 05:08:49.464840: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-20 05:08:49.469124: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 05:08:49.469585: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-20 05:08:49.469660: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 05:08:50.788204: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-20 05:08:50.789183: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 05:08:50.789882: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-20 05:08:50.789911: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 05:08:50.789943: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 05:08:50.789968: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-20 05:08:50.790007: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-20 05:08:50.790023: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-20 05:08:50.790037: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-20 05:08:50.790050: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-20 05:08:50.790064: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 05:08:50.790490: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-20 05:08:50.790523: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 05:08:51.344654: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-20 05:08:51.344706: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-20 05:08:51.344714: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-20 05:08:51.345600: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:03:00.0, compute capability: 6.1)
{'id': '18_16', 'batch_size': 128, 'epochs': 83, 'validation_split': 0.1, 'checkpointing': True, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
x_train shape: (45000, 32, 32, 3)
45000 train samples
5000 validation samples
10000 test samples
y_train shape: (45000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/83 [00:00<?, ?epoch/s]2024-02-20 05:08:52.079914: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-20 05:08:52.092059: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600020000 Hz
2024-02-20 05:08:53.810324: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 05:08:54.004855: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 05:08:54.576421: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-20 05:08:54.606230: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/83 [00:40<55:09, 40.36s/epoch, loss=3.51, accuracy=0.244, val_loss=3.52, val_accuracy=0.116, lr=0.1]  2%|▏         | 2/83 [00:57<36:13, 26.83s/epoch, loss=1.65, accuracy=0.488, val_loss=2.86, val_accuracy=0.259, lr=0.1]  4%|▎         | 3/83 [01:14<29:35, 22.20s/epoch, loss=1.4, accuracy=0.607, val_loss=2.63, val_accuracy=0.265, lr=0.1]   5%|▍         | 4/83 [01:31<26:39, 20.24s/epoch, loss=1.3, accuracy=0.664, val_loss=1.47, val_accuracy=0.606, lr=0.1]  6%|▌         | 5/83 [01:48<24:36, 18.93s/epoch, loss=1.26, accuracy=0.692, val_loss=3.45, val_accuracy=0.277, lr=0.1]  7%|▋         | 6/83 [02:05<23:23, 18.23s/epoch, loss=1.24, accuracy=0.702, val_loss=1.6, val_accuracy=0.598, lr=0.1]   8%|▊         | 7/83 [02:21<22:26, 17.72s/epoch, loss=1.23, accuracy=0.709, val_loss=3.84, val_accuracy=0.336, lr=0.1] 10%|▉         | 8/83 [02:38<21:43, 17.39s/epoch, loss=1.22, accuracy=0.716, val_loss=3.04, val_accuracy=0.434, lr=0.1] 11%|█         | 9/83 [02:55<21:12, 17.20s/epoch, loss=1.21, accuracy=0.724, val_loss=1.74, val_accuracy=0.558, lr=0.0316] 12%|█▏        | 10/83 [03:12<20:48, 17.10s/epoch, loss=1.21, accuracy=0.724, val_loss=2.25, val_accuracy=0.435, lr=0.1]   13%|█▎        | 11/83 [03:28<20:17, 16.90s/epoch, loss=1.21, accuracy=0.727, val_loss=1.89, val_accuracy=0.493, lr=0.1] 14%|█▍        | 12/83 [03:45<19:53, 16.81s/epoch, loss=1.19, accuracy=0.731, val_loss=1.56, val_accuracy=0.619, lr=0.1] 16%|█▌        | 13/83 [04:01<19:34, 16.78s/epoch, loss=1.19, accuracy=0.733, val_loss=1.79, val_accuracy=0.564, lr=0.1] 17%|█▋        | 14/83 [04:18<19:20, 16.82s/epoch, loss=1.19, accuracy=0.73, val_loss=1.43, val_accuracy=0.657, lr=0.1]  18%|█▊        | 15/83 [04:35<18:57, 16.73s/epoch, loss=1.19, accuracy=0.735, val_loss=2.1, val_accuracy=0.502, lr=0.1] 19%|█▉        | 16/83 [04:52<18:41, 16.73s/epoch, loss=1.18, accuracy=0.736, val_loss=1.55, val_accuracy=0.629, lr=0.1] 20%|██        | 17/83 [05:08<18:18, 16.65s/epoch, loss=1.18, accuracy=0.734, val_loss=4.75, val_accuracy=0.311, lr=0.1] 22%|██▏       | 18/83 [05:25<18:01, 16.64s/epoch, loss=1.18, accuracy=0.739, val_loss=2.41, val_accuracy=0.401, lr=0.1] 23%|██▎       | 19/83 [05:41<17:43, 16.62s/epoch, loss=1.17, accuracy=0.74, val_loss=2.39, val_accuracy=0.498, lr=0.0316] 24%|██▍       | 20/83 [05:58<17:27, 16.63s/epoch, loss=1.17, accuracy=0.738, val_loss=3.04, val_accuracy=0.334, lr=0.1]   25%|██▌       | 21/83 [06:15<17:13, 16.66s/epoch, loss=1.17, accuracy=0.74, val_loss=2.24, val_accuracy=0.408, lr=0.1]  27%|██▋       | 22/83 [06:31<16:55, 16.65s/epoch, loss=1.17, accuracy=0.74, val_loss=2.08, val_accuracy=0.51, lr=0.1]  28%|██▊       | 23/83 [06:48<16:35, 16.58s/epoch, loss=1.16, accuracy=0.742, val_loss=1.55, val_accuracy=0.619, lr=0.1] 29%|██▉       | 24/83 [07:04<16:17, 16.56s/epoch, loss=1.17, accuracy=0.743, val_loss=1.98, val_accuracy=0.48, lr=0.0316] 30%|███       | 25/83 [07:21<16:04, 16.62s/epoch, loss=1.16, accuracy=0.743, val_loss=3.14, val_accuracy=0.4, lr=0.1]     31%|███▏      | 26/83 [07:38<15:57, 16.80s/epoch, loss=1.16, accuracy=0.743, val_loss=2.44, val_accuracy=0.372, lr=0.1] 33%|███▎      | 27/83 [07:55<15:37, 16.73s/epoch, loss=1.16, accuracy=0.743, val_loss=2.49, val_accuracy=0.431, lr=0.1] 34%|███▎      | 28/83 [08:12<15:23, 16.80s/epoch, loss=1.16, accuracy=0.745, val_loss=2, val_accuracy=0.534, lr=0.1]    35%|███▍      | 29/83 [08:29<15:11, 16.88s/epoch, loss=1.15, accuracy=0.75, val_loss=2.73, val_accuracy=0.456, lr=0.0316] 36%|███▌      | 30/83 [08:45<14:51, 16.82s/epoch, loss=1.15, accuracy=0.749, val_loss=2.14, val_accuracy=0.433, lr=0.1]   37%|███▋      | 31/83 [09:02<14:36, 16.86s/epoch, loss=1.16, accuracy=0.745, val_loss=3.55, val_accuracy=0.23, lr=0.1]  39%|███▊      | 32/83 [09:19<14:19, 16.86s/epoch, loss=1.15, accuracy=0.748, val_loss=1.75, val_accuracy=0.545, lr=0.1] 40%|███▉      | 33/83 [09:36<14:06, 16.93s/epoch, loss=1.15, accuracy=0.747, val_loss=2.82, val_accuracy=0.349, lr=0.1] 41%|████      | 34/83 [09:53<13:50, 16.96s/epoch, loss=1.15, accuracy=0.748, val_loss=3.63, val_accuracy=0.171, lr=0.0316] 42%|████▏     | 35/83 [10:10<13:32, 16.93s/epoch, loss=1.15, accuracy=0.746, val_loss=3.53, val_accuracy=0.28, lr=0.1]     43%|████▎     | 36/83 [10:27<13:16, 16.96s/epoch, loss=1.14, accuracy=0.749, val_loss=2.21, val_accuracy=0.391, lr=0.1] 45%|████▍     | 37/83 [10:44<12:58, 16.93s/epoch, loss=1.14, accuracy=0.752, val_loss=2.22, val_accuracy=0.468, lr=0.1] 46%|████▌     | 38/83 [11:01<12:39, 16.88s/epoch, loss=1.14, accuracy=0.747, val_loss=1.7, val_accuracy=0.601, lr=0.1]  47%|████▋     | 39/83 [11:18<12:27, 16.98s/epoch, loss=1.14, accuracy=0.749, val_loss=2.55, val_accuracy=0.418, lr=0.0316] 48%|████▊     | 40/83 [11:35<12:13, 17.06s/epoch, loss=1.14, accuracy=0.749, val_loss=1.47, val_accuracy=0.631, lr=0.1]    49%|████▉     | 41/83 [11:52<11:55, 17.05s/epoch, loss=1.14, accuracy=0.753, val_loss=2.31, val_accuracy=0.492, lr=0.1] 51%|█████     | 42/83 [12:09<11:32, 16.88s/epoch, loss=1.14, accuracy=0.753, val_loss=2.57, val_accuracy=0.382, lr=0.1] 52%|█████▏    | 43/83 [12:26<11:16, 16.92s/epoch, loss=1.14, accuracy=0.751, val_loss=2.72, val_accuracy=0.318, lr=0.1] 53%|█████▎    | 44/83 [12:43<11:06, 17.08s/epoch, loss=1.13, accuracy=0.75, val_loss=1.73, val_accuracy=0.564, lr=0.0316] 54%|█████▍    | 45/83 [13:00<10:42, 16.91s/epoch, loss=1.13, accuracy=0.751, val_loss=1.98, val_accuracy=0.483, lr=0.1]   55%|█████▌    | 46/83 [13:16<10:22, 16.84s/epoch, loss=1.13, accuracy=0.751, val_loss=1.62, val_accuracy=0.582, lr=0.1] 57%|█████▋    | 47/83 [13:33<10:03, 16.76s/epoch, loss=1.13, accuracy=0.754, val_loss=1.75, val_accuracy=0.546, lr=0.1] 58%|█████▊    | 48/83 [13:50<09:46, 16.76s/epoch, loss=1.14, accuracy=0.75, val_loss=3.63, val_accuracy=0.288, lr=0.1]  59%|█████▉    | 49/83 [14:06<09:26, 16.67s/epoch, loss=1.13, accuracy=0.753, val_loss=2.82, val_accuracy=0.374, lr=0.0316] 60%|██████    | 50/83 [14:23<09:11, 16.71s/epoch, loss=1.13, accuracy=0.752, val_loss=1.91, val_accuracy=0.495, lr=0.1]    61%|██████▏   | 51/83 [14:39<08:50, 16.58s/epoch, loss=1.12, accuracy=0.753, val_loss=2.15, val_accuracy=0.507, lr=0.1] 63%|██████▎   | 52/83 [14:56<08:35, 16.62s/epoch, loss=1.13, accuracy=0.753, val_loss=2.59, val_accuracy=0.401, lr=0.1] 64%|██████▍   | 53/83 [15:12<08:15, 16.52s/epoch, loss=1.13, accuracy=0.753, val_loss=2.25, val_accuracy=0.526, lr=0.1] 65%|██████▌   | 54/83 [15:29<07:59, 16.54s/epoch, loss=1.12, accuracy=0.755, val_loss=1.73, val_accuracy=0.583, lr=0.0316] 66%|██████▋   | 55/83 [15:45<07:41, 16.49s/epoch, loss=1.13, accuracy=0.755, val_loss=1.97, val_accuracy=0.521, lr=0.1]    67%|██████▋   | 56/83 [16:02<07:22, 16.40s/epoch, loss=1.12, accuracy=0.757, val_loss=2.5, val_accuracy=0.415, lr=0.1]  69%|██████▊   | 57/83 [16:18<07:06, 16.40s/epoch, loss=1.12, accuracy=0.755, val_loss=2.59, val_accuracy=0.385, lr=0.1] 70%|██████▉   | 58/83 [16:35<06:52, 16.50s/epoch, loss=1.13, accuracy=0.752, val_loss=2.18, val_accuracy=0.454, lr=0.1] 71%|███████   | 59/83 [16:51<06:35, 16.48s/epoch, loss=1.12, accuracy=0.755, val_loss=2.11, val_accuracy=0.515, lr=0.0316] 72%|███████▏  | 60/83 [17:08<06:20, 16.55s/epoch, loss=1.12, accuracy=0.756, val_loss=2.23, val_accuracy=0.483, lr=0.1]    73%|███████▎  | 61/83 [17:24<06:02, 16.46s/epoch, loss=1.13, accuracy=0.755, val_loss=1.91, val_accuracy=0.498, lr=0.1] 75%|███████▍  | 62/83 [17:40<05:43, 16.37s/epoch, loss=1.12, accuracy=0.755, val_loss=1.9, val_accuracy=0.525, lr=0.1]  76%|███████▌  | 63/83 [17:57<05:30, 16.54s/epoch, loss=1.13, accuracy=0.754, val_loss=2.23, val_accuracy=0.485, lr=0.1] 77%|███████▋  | 64/83 [18:14<05:16, 16.63s/epoch, loss=1.12, accuracy=0.757, val_loss=1.99, val_accuracy=0.509, lr=0.0316] 78%|███████▊  | 65/83 [18:31<04:59, 16.64s/epoch, loss=1.12, accuracy=0.756, val_loss=2.99, val_accuracy=0.336, lr=0.1]    80%|███████▉  | 66/83 [18:47<04:41, 16.54s/epoch, loss=1.11, accuracy=0.761, val_loss=2.47, val_accuracy=0.336, lr=0.1] 81%|████████  | 67/83 [19:04<04:25, 16.58s/epoch, loss=1.13, accuracy=0.754, val_loss=2.66, val_accuracy=0.325, lr=0.1] 82%|████████▏ | 68/83 [19:20<04:07, 16.49s/epoch, loss=1.12, accuracy=0.756, val_loss=3.21, val_accuracy=0.383, lr=0.1] 83%|████████▎ | 69/83 [19:36<03:50, 16.47s/epoch, loss=1.12, accuracy=0.757, val_loss=1.67, val_accuracy=0.56, lr=0.0316] 84%|████████▍ | 70/83 [19:53<03:34, 16.49s/epoch, loss=1.12, accuracy=0.758, val_loss=3.22, val_accuracy=0.361, lr=0.1]   86%|████████▌ | 71/83 [20:09<03:16, 16.41s/epoch, loss=1.12, accuracy=0.758, val_loss=2.46, val_accuracy=0.403, lr=0.1] 87%|████████▋ | 72/83 [20:26<03:01, 16.50s/epoch, loss=1.11, accuracy=0.757, val_loss=1.65, val_accuracy=0.56, lr=0.1]  88%|████████▊ | 73/83 [20:42<02:43, 16.40s/epoch, loss=1.12, accuracy=0.759, val_loss=1.65, val_accuracy=0.58, lr=0.1] 89%|████████▉ | 74/83 [20:58<02:27, 16.38s/epoch, loss=1.11, accuracy=0.758, val_loss=2.2, val_accuracy=0.467, lr=0.0316] 90%|█████████ | 75/83 [21:15<02:11, 16.38s/epoch, loss=1.12, accuracy=0.758, val_loss=1.64, val_accuracy=0.586, lr=0.1]   92%|█████████▏| 76/83 [21:31<01:54, 16.32s/epoch, loss=1.12, accuracy=0.757, val_loss=5.53, val_accuracy=0.193, lr=0.1] 93%|█████████▎| 77/83 [21:47<01:37, 16.30s/epoch, loss=1.12, accuracy=0.756, val_loss=2.85, val_accuracy=0.391, lr=0.1] 94%|█████████▍| 78/83 [22:04<01:21, 16.37s/epoch, loss=1.12, accuracy=0.755, val_loss=2.57, val_accuracy=0.393, lr=0.1] 95%|█████████▌| 79/83 [22:20<01:05, 16.47s/epoch, loss=1.11, accuracy=0.756, val_loss=2.25, val_accuracy=0.428, lr=0.0316] 96%|█████████▋| 80/83 [22:37<00:49, 16.49s/epoch, loss=1.11, accuracy=0.756, val_loss=1.47, val_accuracy=0.617, lr=0.1]    98%|█████████▊| 81/83 [22:53<00:33, 16.51s/epoch, loss=1.11, accuracy=0.759, val_loss=2.01, val_accuracy=0.523, lr=0.1] 99%|█████████▉| 82/83 [23:10<00:16, 16.59s/epoch, loss=0.917, accuracy=0.815, val_loss=0.894, val_accuracy=0.802, lr=0.01]100%|██████████| 83/83 [23:27<00:00, 16.62s/epoch, loss=0.739, accuracy=0.845, val_loss=0.794, val_accuracy=0.815, lr=0.01]100%|██████████| 83/83 [23:27<00:00, 16.96s/epoch, loss=0.739, accuracy=0.845, val_loss=0.794, val_accuracy=0.815, lr=0.01]
Using real-time data augmentation.
Test score: 0.807099461555481
Test accuracy: 0.8119999766349792


* * * Run SGD for ID = 18_17. * * *


2024-02-20 05:32:25.152519: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 05:32:28.078764: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 05:32:28.079697: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-20 05:32:28.116403: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-20 05:32:28.116496: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 05:32:28.119337: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 05:32:28.119373: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-20 05:32:28.121377: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-20 05:32:28.122158: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-20 05:32:28.124376: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-20 05:32:28.125792: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-20 05:32:28.130498: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 05:32:28.131014: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-20 05:32:28.131088: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 05:32:29.622333: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-20 05:32:29.622827: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 05:32:29.623570: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-20 05:32:29.623601: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 05:32:29.623634: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 05:32:29.623651: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-20 05:32:29.623668: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-20 05:32:29.623686: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-20 05:32:29.623702: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-20 05:32:29.623717: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-20 05:32:29.623733: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 05:32:29.624157: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-20 05:32:29.624192: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 05:32:30.188120: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-20 05:32:30.188175: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-20 05:32:30.188183: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-20 05:32:30.189043: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:03:00.0, compute capability: 6.1)
{'id': '18_17', 'batch_size': 128, 'epochs': 83, 'validation_split': 0.1, 'checkpointing': True, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
x_train shape: (45000, 32, 32, 3)
45000 train samples
5000 validation samples
10000 test samples
y_train shape: (45000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/83 [00:00<?, ?epoch/s]2024-02-20 05:32:30.937416: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-20 05:32:30.949205: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600020000 Hz
2024-02-20 05:32:32.650578: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 05:32:32.844438: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 05:32:33.399047: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-20 05:32:33.430926: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/83 [00:41<56:06, 41.05s/epoch, loss=3.38, accuracy=0.228, val_loss=3.13, val_accuracy=0.143, lr=0.1]  2%|▏         | 2/83 [00:58<36:22, 26.94s/epoch, loss=1.67, accuracy=0.478, val_loss=1.92, val_accuracy=0.41, lr=0.1]   4%|▎         | 3/83 [01:15<30:02, 22.53s/epoch, loss=1.44, accuracy=0.582, val_loss=2.12, val_accuracy=0.476, lr=0.1]  5%|▍         | 4/83 [01:32<26:36, 20.21s/epoch, loss=1.36, accuracy=0.642, val_loss=2.04, val_accuracy=0.442, lr=0.1]  6%|▌         | 5/83 [01:48<24:33, 18.89s/epoch, loss=1.31, accuracy=0.673, val_loss=2.4, val_accuracy=0.377, lr=0.1]   7%|▋         | 6/83 [02:05<23:27, 18.28s/epoch, loss=1.27, accuracy=0.69, val_loss=1.81, val_accuracy=0.546, lr=0.1]  8%|▊         | 7/83 [02:22<22:25, 17.70s/epoch, loss=1.26, accuracy=0.703, val_loss=1.83, val_accuracy=0.554, lr=0.1] 10%|▉         | 8/83 [02:38<21:41, 17.35s/epoch, loss=1.23, accuracy=0.714, val_loss=2.06, val_accuracy=0.443, lr=0.1] 11%|█         | 9/83 [02:55<21:08, 17.15s/epoch, loss=1.22, accuracy=0.72, val_loss=1.97, val_accuracy=0.431, lr=0.1]  12%|█▏        | 10/83 [03:12<20:45, 17.06s/epoch, loss=1.22, accuracy=0.72, val_loss=1.62, val_accuracy=0.596, lr=0.1] 13%|█▎        | 11/83 [03:28<20:15, 16.89s/epoch, loss=1.21, accuracy=0.726, val_loss=1.8, val_accuracy=0.536, lr=0.1] 14%|█▍        | 12/83 [03:45<19:50, 16.77s/epoch, loss=1.21, accuracy=0.731, val_loss=1.61, val_accuracy=0.572, lr=0.1] 16%|█▌        | 13/83 [04:02<19:33, 16.76s/epoch, loss=1.21, accuracy=0.732, val_loss=2.66, val_accuracy=0.43, lr=0.1]  17%|█▋        | 14/83 [04:18<19:11, 16.68s/epoch, loss=1.19, accuracy=0.735, val_loss=5.46, val_accuracy=0.191, lr=0.1] 18%|█▊        | 15/83 [04:35<18:56, 16.71s/epoch, loss=1.2, accuracy=0.735, val_loss=1.52, val_accuracy=0.596, lr=0.1]  19%|█▉        | 16/83 [04:52<18:41, 16.74s/epoch, loss=1.19, accuracy=0.734, val_loss=2.43, val_accuracy=0.456, lr=0.1] 20%|██        | 17/83 [05:08<18:20, 16.68s/epoch, loss=1.18, accuracy=0.738, val_loss=1.78, val_accuracy=0.558, lr=0.1] 22%|██▏       | 18/83 [05:25<18:04, 16.69s/epoch, loss=1.18, accuracy=0.741, val_loss=2.08, val_accuracy=0.489, lr=0.1] 23%|██▎       | 19/83 [05:41<17:43, 16.62s/epoch, loss=1.17, accuracy=0.744, val_loss=2.31, val_accuracy=0.372, lr=0.1] 24%|██▍       | 20/83 [05:58<17:28, 16.64s/epoch, loss=1.18, accuracy=0.742, val_loss=2.91, val_accuracy=0.432, lr=0.0316] 25%|██▌       | 21/83 [06:15<17:10, 16.62s/epoch, loss=1.18, accuracy=0.743, val_loss=1.94, val_accuracy=0.574, lr=0.1]    27%|██▋       | 22/83 [06:31<16:56, 16.66s/epoch, loss=1.17, accuracy=0.743, val_loss=3.84, val_accuracy=0.286, lr=0.1] 28%|██▊       | 23/83 [06:48<16:36, 16.61s/epoch, loss=1.17, accuracy=0.742, val_loss=1.61, val_accuracy=0.597, lr=0.1] 29%|██▉       | 24/83 [07:05<16:23, 16.66s/epoch, loss=1.17, accuracy=0.744, val_loss=1.41, val_accuracy=0.66, lr=0.1]  30%|███       | 25/83 [07:22<16:13, 16.79s/epoch, loss=1.16, accuracy=0.748, val_loss=2.2, val_accuracy=0.493, lr=0.1] 31%|███▏      | 26/83 [07:38<15:51, 16.68s/epoch, loss=1.16, accuracy=0.745, val_loss=2.74, val_accuracy=0.459, lr=0.1] 33%|███▎      | 27/83 [07:55<15:38, 16.75s/epoch, loss=1.16, accuracy=0.744, val_loss=2.59, val_accuracy=0.429, lr=0.1] 34%|███▎      | 28/83 [08:12<15:22, 16.77s/epoch, loss=1.16, accuracy=0.749, val_loss=2.28, val_accuracy=0.461, lr=0.1] 35%|███▍      | 29/83 [08:29<15:11, 16.87s/epoch, loss=1.16, accuracy=0.746, val_loss=2.99, val_accuracy=0.353, lr=0.0316] 36%|███▌      | 30/83 [08:46<14:53, 16.85s/epoch, loss=1.16, accuracy=0.747, val_loss=2.23, val_accuracy=0.441, lr=0.1]    37%|███▋      | 31/83 [09:02<14:28, 16.71s/epoch, loss=1.15, accuracy=0.747, val_loss=1.85, val_accuracy=0.56, lr=0.1]  39%|███▊      | 32/83 [09:19<14:12, 16.72s/epoch, loss=1.16, accuracy=0.746, val_loss=2.48, val_accuracy=0.424, lr=0.1] 40%|███▉      | 33/83 [09:36<13:54, 16.68s/epoch, loss=1.16, accuracy=0.749, val_loss=1.63, val_accuracy=0.583, lr=0.1] 41%|████      | 34/83 [09:52<13:39, 16.71s/epoch, loss=1.14, accuracy=0.751, val_loss=1.81, val_accuracy=0.523, lr=0.0316] 42%|████▏     | 35/83 [10:09<13:22, 16.71s/epoch, loss=1.15, accuracy=0.748, val_loss=1.54, val_accuracy=0.617, lr=0.1]    43%|████▎     | 36/83 [10:26<13:07, 16.75s/epoch, loss=1.15, accuracy=0.75, val_loss=2.39, val_accuracy=0.474, lr=0.1]  45%|████▍     | 37/83 [10:43<12:52, 16.79s/epoch, loss=1.15, accuracy=0.748, val_loss=1.7, val_accuracy=0.573, lr=0.1] 46%|████▌     | 38/83 [10:59<12:32, 16.71s/epoch, loss=1.14, accuracy=0.753, val_loss=2.3, val_accuracy=0.461, lr=0.1] 47%|████▋     | 39/83 [11:16<12:10, 16.61s/epoch, loss=1.15, accuracy=0.751, val_loss=2.17, val_accuracy=0.513, lr=0.0316] 48%|████▊     | 40/83 [11:32<11:52, 16.56s/epoch, loss=1.14, accuracy=0.752, val_loss=2.07, val_accuracy=0.455, lr=0.1]    49%|████▉     | 41/83 [11:49<11:34, 16.54s/epoch, loss=1.14, accuracy=0.753, val_loss=2.82, val_accuracy=0.372, lr=0.1] 51%|█████     | 42/83 [12:05<11:19, 16.57s/epoch, loss=1.14, accuracy=0.754, val_loss=2.03, val_accuracy=0.51, lr=0.1]  52%|█████▏    | 43/83 [12:22<11:03, 16.58s/epoch, loss=1.14, accuracy=0.754, val_loss=5.37, val_accuracy=0.161, lr=0.1] 53%|█████▎    | 44/83 [12:38<10:42, 16.47s/epoch, loss=1.14, accuracy=0.752, val_loss=2.02, val_accuracy=0.507, lr=0.0316] 54%|█████▍    | 45/83 [12:54<10:22, 16.39s/epoch, loss=1.14, accuracy=0.754, val_loss=1.71, val_accuracy=0.551, lr=0.1]    55%|█████▌    | 46/83 [13:11<10:06, 16.39s/epoch, loss=1.14, accuracy=0.752, val_loss=1.97, val_accuracy=0.527, lr=0.1] 57%|█████▋    | 47/83 [13:27<09:53, 16.49s/epoch, loss=1.13, accuracy=0.756, val_loss=1.86, val_accuracy=0.515, lr=0.1] 58%|█████▊    | 48/83 [13:44<09:37, 16.49s/epoch, loss=1.14, accuracy=0.753, val_loss=2.55, val_accuracy=0.429, lr=0.1] 59%|█████▉    | 49/83 [14:00<09:20, 16.50s/epoch, loss=1.14, accuracy=0.752, val_loss=2.54, val_accuracy=0.415, lr=0.0316] 60%|██████    | 50/83 [14:17<09:04, 16.49s/epoch, loss=1.13, accuracy=0.754, val_loss=1.83, val_accuracy=0.531, lr=0.1]    61%|██████▏   | 51/83 [14:34<08:49, 16.55s/epoch, loss=1.13, accuracy=0.753, val_loss=2.04, val_accuracy=0.518, lr=0.1] 63%|██████▎   | 52/83 [14:50<08:31, 16.49s/epoch, loss=1.14, accuracy=0.753, val_loss=1.86, val_accuracy=0.542, lr=0.1] 64%|██████▍   | 53/83 [15:06<08:11, 16.39s/epoch, loss=1.14, accuracy=0.753, val_loss=1.9, val_accuracy=0.476, lr=0.1]  65%|██████▌   | 54/83 [15:22<07:55, 16.38s/epoch, loss=1.13, accuracy=0.753, val_loss=2.23, val_accuracy=0.456, lr=0.0316] 66%|██████▋   | 55/83 [15:39<07:41, 16.49s/epoch, loss=1.13, accuracy=0.754, val_loss=1.38, val_accuracy=0.668, lr=0.1]    67%|██████▋   | 56/83 [15:56<07:27, 16.57s/epoch, loss=1.13, accuracy=0.756, val_loss=1.88, val_accuracy=0.492, lr=0.1] 69%|██████▊   | 57/83 [16:12<07:08, 16.49s/epoch, loss=1.14, accuracy=0.754, val_loss=2.54, val_accuracy=0.385, lr=0.1] 70%|██████▉   | 58/83 [16:29<06:55, 16.62s/epoch, loss=1.12, accuracy=0.76, val_loss=2.52, val_accuracy=0.407, lr=0.1]  71%|███████   | 59/83 [16:46<06:38, 16.59s/epoch, loss=1.14, accuracy=0.753, val_loss=2.23, val_accuracy=0.4, lr=0.1]  72%|███████▏  | 60/83 [17:02<06:19, 16.49s/epoch, loss=1.13, accuracy=0.756, val_loss=2.23, val_accuracy=0.444, lr=0.0316] 73%|███████▎  | 61/83 [17:18<06:01, 16.43s/epoch, loss=1.13, accuracy=0.755, val_loss=2.06, val_accuracy=0.494, lr=0.1]    75%|███████▍  | 62/83 [17:35<05:46, 16.49s/epoch, loss=1.13, accuracy=0.755, val_loss=1.6, val_accuracy=0.58, lr=0.1]   76%|███████▌  | 63/83 [17:52<05:30, 16.54s/epoch, loss=1.13, accuracy=0.755, val_loss=2.11, val_accuracy=0.51, lr=0.1] 77%|███████▋  | 64/83 [18:08<05:14, 16.56s/epoch, loss=1.12, accuracy=0.757, val_loss=3.08, val_accuracy=0.271, lr=0.1] 78%|███████▊  | 65/83 [18:25<04:57, 16.53s/epoch, loss=1.13, accuracy=0.755, val_loss=4.08, val_accuracy=0.324, lr=0.0316] 80%|███████▉  | 66/83 [18:41<04:39, 16.46s/epoch, loss=1.12, accuracy=0.756, val_loss=2.99, val_accuracy=0.371, lr=0.1]    81%|████████  | 67/83 [18:58<04:24, 16.54s/epoch, loss=1.12, accuracy=0.757, val_loss=1.77, val_accuracy=0.539, lr=0.1] 82%|████████▏ | 68/83 [19:14<04:07, 16.53s/epoch, loss=1.12, accuracy=0.757, val_loss=2.19, val_accuracy=0.486, lr=0.1] 83%|████████▎ | 69/83 [19:31<03:51, 16.51s/epoch, loss=1.12, accuracy=0.757, val_loss=2.26, val_accuracy=0.402, lr=0.1] 84%|████████▍ | 70/83 [19:47<03:33, 16.46s/epoch, loss=1.12, accuracy=0.754, val_loss=1.71, val_accuracy=0.549, lr=0.0316] 86%|████████▌ | 71/83 [20:04<03:18, 16.50s/epoch, loss=1.12, accuracy=0.755, val_loss=3.1, val_accuracy=0.314, lr=0.1]     87%|████████▋ | 72/83 [20:20<03:02, 16.55s/epoch, loss=1.11, accuracy=0.76, val_loss=2.9, val_accuracy=0.309, lr=0.1]  88%|████████▊ | 73/83 [20:37<02:46, 16.62s/epoch, loss=1.13, accuracy=0.753, val_loss=2.06, val_accuracy=0.466, lr=0.1] 89%|████████▉ | 74/83 [20:53<02:29, 16.57s/epoch, loss=1.12, accuracy=0.757, val_loss=2.5, val_accuracy=0.448, lr=0.1]  90%|█████████ | 75/83 [21:10<02:12, 16.58s/epoch, loss=1.11, accuracy=0.761, val_loss=1.73, val_accuracy=0.586, lr=0.0316] 92%|█████████▏| 76/83 [21:27<01:56, 16.58s/epoch, loss=1.12, accuracy=0.757, val_loss=1.66, val_accuracy=0.562, lr=0.1]    93%|█████████▎| 77/83 [21:43<01:39, 16.52s/epoch, loss=1.11, accuracy=0.758, val_loss=1.84, val_accuracy=0.571, lr=0.1] 94%|█████████▍| 78/83 [21:59<01:22, 16.50s/epoch, loss=1.12, accuracy=0.757, val_loss=1.74, val_accuracy=0.591, lr=0.1] 95%|█████████▌| 79/83 [22:16<01:05, 16.46s/epoch, loss=1.12, accuracy=0.755, val_loss=1.82, val_accuracy=0.518, lr=0.1] 96%|█████████▋| 80/83 [22:32<00:49, 16.49s/epoch, loss=1.12, accuracy=0.756, val_loss=3.38, val_accuracy=0.372, lr=0.0316] 98%|█████████▊| 81/83 [22:49<00:32, 16.46s/epoch, loss=1.11, accuracy=0.758, val_loss=1.85, val_accuracy=0.519, lr=0.1]    99%|█████████▉| 82/83 [23:05<00:16, 16.48s/epoch, loss=0.908, accuracy=0.815, val_loss=0.856, val_accuracy=0.821, lr=0.01]100%|██████████| 83/83 [23:22<00:00, 16.48s/epoch, loss=0.74, accuracy=0.845, val_loss=0.786, val_accuracy=0.823, lr=0.01] 100%|██████████| 83/83 [23:22<00:00, 16.89s/epoch, loss=0.74, accuracy=0.845, val_loss=0.786, val_accuracy=0.823, lr=0.01]
Using real-time data augmentation.
Test score: 0.8156256079673767
Test accuracy: 0.8119000196456909


* * * Run SGD for ID = 18_18. * * *


2024-02-20 05:55:57.959798: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 05:56:00.419191: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 05:56:00.420075: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-20 05:56:00.454751: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-20 05:56:00.454779: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 05:56:00.457576: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 05:56:00.457613: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-20 05:56:00.459638: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-20 05:56:00.460636: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-20 05:56:00.462767: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-20 05:56:00.464312: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-20 05:56:00.468833: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 05:56:00.469364: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-20 05:56:00.469450: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 05:56:01.844557: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-20 05:56:01.845938: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 05:56:01.846371: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-20 05:56:01.846402: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 05:56:01.846434: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 05:56:01.846450: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-20 05:56:01.846465: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-20 05:56:01.846480: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-20 05:56:01.846495: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-20 05:56:01.846511: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-20 05:56:01.846527: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 05:56:01.846946: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-20 05:56:01.846984: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 05:56:02.409981: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-20 05:56:02.410038: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-20 05:56:02.410047: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-20 05:56:02.411190: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:03:00.0, compute capability: 6.1)
{'id': '18_18', 'batch_size': 128, 'epochs': 83, 'validation_split': 0.1, 'checkpointing': True, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
x_train shape: (45000, 32, 32, 3)
45000 train samples
5000 validation samples
10000 test samples
y_train shape: (45000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/83 [00:00<?, ?epoch/s]2024-02-20 05:56:03.163688: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-20 05:56:03.176081: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600020000 Hz
2024-02-20 05:56:04.894180: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 05:56:05.111924: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 05:56:05.709878: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-20 05:56:05.744663: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/83 [00:44<1:00:13, 44.07s/epoch, loss=3.35, accuracy=0.266, val_loss=2.7, val_accuracy=0.2, lr=0.1]  2%|▏         | 2/83 [01:01<37:58, 28.14s/epoch, loss=1.63, accuracy=0.505, val_loss=2.41, val_accuracy=0.38, lr=0.1]  4%|▎         | 3/83 [01:18<30:48, 23.11s/epoch, loss=1.4, accuracy=0.614, val_loss=2.75, val_accuracy=0.39, lr=0.1]   5%|▍         | 4/83 [01:35<27:22, 20.79s/epoch, loss=1.31, accuracy=0.668, val_loss=2.24, val_accuracy=0.442, lr=0.1]  6%|▌         | 5/83 [01:52<25:07, 19.33s/epoch, loss=1.27, accuracy=0.691, val_loss=2.47, val_accuracy=0.424, lr=0.1]  7%|▋         | 6/83 [02:08<23:40, 18.45s/epoch, loss=1.24, accuracy=0.703, val_loss=2.75, val_accuracy=0.393, lr=0.1]  8%|▊         | 7/83 [02:25<22:44, 17.95s/epoch, loss=1.23, accuracy=0.715, val_loss=1.81, val_accuracy=0.544, lr=0.1] 10%|▉         | 8/83 [02:42<22:00, 17.60s/epoch, loss=1.22, accuracy=0.719, val_loss=2.33, val_accuracy=0.451, lr=0.1] 11%|█         | 9/83 [02:59<21:24, 17.35s/epoch, loss=1.21, accuracy=0.722, val_loss=1.75, val_accuracy=0.575, lr=0.1] 12%|█▏        | 10/83 [03:16<21:02, 17.30s/epoch, loss=1.2, accuracy=0.729, val_loss=1.47, val_accuracy=0.644, lr=0.1] 13%|█▎        | 11/83 [03:33<20:38, 17.21s/epoch, loss=1.19, accuracy=0.733, val_loss=1.82, val_accuracy=0.588, lr=0.1] 14%|█▍        | 12/83 [03:50<20:08, 17.02s/epoch, loss=1.2, accuracy=0.73, val_loss=1.78, val_accuracy=0.544, lr=0.1]   16%|█▌        | 13/83 [04:07<19:53, 17.05s/epoch, loss=1.19, accuracy=0.736, val_loss=1.61, val_accuracy=0.57, lr=0.1] 17%|█▋        | 14/83 [04:24<19:31, 16.98s/epoch, loss=1.18, accuracy=0.737, val_loss=1.82, val_accuracy=0.551, lr=0.1] 18%|█▊        | 15/83 [04:40<19:09, 16.90s/epoch, loss=1.18, accuracy=0.74, val_loss=1.68, val_accuracy=0.585, lr=0.0316] 19%|█▉        | 16/83 [04:57<18:51, 16.89s/epoch, loss=1.18, accuracy=0.741, val_loss=1.72, val_accuracy=0.581, lr=0.1]   20%|██        | 17/83 [05:14<18:28, 16.79s/epoch, loss=1.17, accuracy=0.741, val_loss=2.33, val_accuracy=0.403, lr=0.1] 22%|██▏       | 18/83 [05:30<18:07, 16.73s/epoch, loss=1.17, accuracy=0.743, val_loss=2.44, val_accuracy=0.406, lr=0.1] 23%|██▎       | 19/83 [05:47<17:52, 16.75s/epoch, loss=1.16, accuracy=0.744, val_loss=2.31, val_accuracy=0.507, lr=0.1] 24%|██▍       | 20/83 [06:04<17:38, 16.80s/epoch, loss=1.17, accuracy=0.745, val_loss=1.71, val_accuracy=0.558, lr=0.0316] 25%|██▌       | 21/83 [06:21<17:28, 16.92s/epoch, loss=1.17, accuracy=0.744, val_loss=2.38, val_accuracy=0.479, lr=0.1]    27%|██▋       | 22/83 [06:38<17:05, 16.82s/epoch, loss=1.16, accuracy=0.745, val_loss=1.68, val_accuracy=0.56, lr=0.1]  28%|██▊       | 23/83 [06:55<16:53, 16.90s/epoch, loss=1.15, accuracy=0.748, val_loss=3.64, val_accuracy=0.291, lr=0.1] 29%|██▉       | 24/83 [07:12<16:33, 16.83s/epoch, loss=1.15, accuracy=0.745, val_loss=1.95, val_accuracy=0.528, lr=0.1] 30%|███       | 25/83 [07:29<16:18, 16.87s/epoch, loss=1.16, accuracy=0.747, val_loss=2.21, val_accuracy=0.465, lr=0.0316] 31%|███▏      | 26/83 [07:46<16:02, 16.88s/epoch, loss=1.15, accuracy=0.746, val_loss=1.6, val_accuracy=0.616, lr=0.1]     33%|███▎      | 27/83 [08:03<15:48, 16.93s/epoch, loss=1.16, accuracy=0.747, val_loss=2, val_accuracy=0.447, lr=0.1]   34%|███▎      | 28/83 [08:19<15:30, 16.92s/epoch, loss=1.16, accuracy=0.747, val_loss=2.79, val_accuracy=0.425, lr=0.1] 35%|███▍      | 29/83 [08:36<15:10, 16.86s/epoch, loss=1.15, accuracy=0.747, val_loss=2.11, val_accuracy=0.484, lr=0.1] 36%|███▌      | 30/83 [08:53<14:51, 16.82s/epoch, loss=1.15, accuracy=0.748, val_loss=3.35, val_accuracy=0.361, lr=0.0316] 37%|███▋      | 31/83 [09:10<14:46, 17.05s/epoch, loss=1.14, accuracy=0.75, val_loss=1.8, val_accuracy=0.578, lr=0.1]      39%|███▊      | 32/83 [09:28<14:33, 17.13s/epoch, loss=1.14, accuracy=0.749, val_loss=2.33, val_accuracy=0.456, lr=0.1] 40%|███▉      | 33/83 [09:44<14:09, 16.98s/epoch, loss=1.14, accuracy=0.754, val_loss=2.67, val_accuracy=0.377, lr=0.1] 41%|████      | 34/83 [10:02<13:54, 17.03s/epoch, loss=1.14, accuracy=0.755, val_loss=2.64, val_accuracy=0.468, lr=0.1] 42%|████▏     | 35/83 [10:18<13:32, 16.93s/epoch, loss=1.14, accuracy=0.753, val_loss=2.85, val_accuracy=0.367, lr=0.0316] 43%|████▎     | 36/83 [10:35<13:15, 16.93s/epoch, loss=1.14, accuracy=0.753, val_loss=4.17, val_accuracy=0.358, lr=0.1]    45%|████▍     | 37/83 [10:52<12:58, 16.92s/epoch, loss=1.14, accuracy=0.753, val_loss=1.57, val_accuracy=0.628, lr=0.1] 46%|████▌     | 38/83 [11:09<12:39, 16.87s/epoch, loss=1.14, accuracy=0.751, val_loss=2.07, val_accuracy=0.52, lr=0.1]  47%|████▋     | 39/83 [11:25<12:18, 16.79s/epoch, loss=1.14, accuracy=0.748, val_loss=4.15, val_accuracy=0.218, lr=0.1] 48%|████▊     | 40/83 [11:43<12:05, 16.87s/epoch, loss=1.13, accuracy=0.752, val_loss=1.66, val_accuracy=0.607, lr=0.0316] 49%|████▉     | 41/83 [11:59<11:44, 16.78s/epoch, loss=1.13, accuracy=0.751, val_loss=2.37, val_accuracy=0.404, lr=0.1]    51%|█████     | 42/83 [12:16<11:24, 16.70s/epoch, loss=1.14, accuracy=0.753, val_loss=1.77, val_accuracy=0.525, lr=0.1] 52%|█████▏    | 43/83 [12:32<11:05, 16.63s/epoch, loss=1.14, accuracy=0.75, val_loss=1.95, val_accuracy=0.518, lr=0.1]  53%|█████▎    | 44/83 [12:49<10:49, 16.65s/epoch, loss=1.13, accuracy=0.752, val_loss=1.69, val_accuracy=0.584, lr=0.1] 54%|█████▍    | 45/83 [13:05<10:31, 16.62s/epoch, loss=1.14, accuracy=0.752, val_loss=2.5, val_accuracy=0.389, lr=0.0316] 55%|█████▌    | 46/83 [13:22<10:15, 16.62s/epoch, loss=1.13, accuracy=0.754, val_loss=2.23, val_accuracy=0.485, lr=0.1]   57%|█████▋    | 47/83 [13:39<10:01, 16.71s/epoch, loss=1.13, accuracy=0.755, val_loss=2.04, val_accuracy=0.545, lr=0.1] 58%|█████▊    | 48/83 [13:56<09:45, 16.73s/epoch, loss=1.14, accuracy=0.755, val_loss=2.54, val_accuracy=0.47, lr=0.1]  59%|█████▉    | 49/83 [14:12<09:28, 16.73s/epoch, loss=1.13, accuracy=0.755, val_loss=1.73, val_accuracy=0.574, lr=0.1] 60%|██████    | 50/83 [14:29<09:13, 16.77s/epoch, loss=1.13, accuracy=0.755, val_loss=1.97, val_accuracy=0.509, lr=0.0316] 61%|██████▏   | 51/83 [14:46<08:57, 16.79s/epoch, loss=1.13, accuracy=0.755, val_loss=1.34, val_accuracy=0.68, lr=0.1]     63%|██████▎   | 52/83 [15:03<08:38, 16.71s/epoch, loss=1.13, accuracy=0.754, val_loss=2.65, val_accuracy=0.424, lr=0.1] 64%|██████▍   | 53/83 [15:19<08:22, 16.74s/epoch, loss=1.13, accuracy=0.755, val_loss=9.48, val_accuracy=0.248, lr=0.1] 65%|██████▌   | 54/83 [15:36<08:05, 16.75s/epoch, loss=1.13, accuracy=0.757, val_loss=1.91, val_accuracy=0.568, lr=0.1] 66%|██████▋   | 55/83 [15:53<07:48, 16.73s/epoch, loss=1.14, accuracy=0.754, val_loss=3.45, val_accuracy=0.318, lr=0.1] 67%|██████▋   | 56/83 [16:10<07:31, 16.72s/epoch, loss=1.13, accuracy=0.756, val_loss=1.62, val_accuracy=0.58, lr=0.0316] 69%|██████▊   | 57/83 [16:26<07:14, 16.71s/epoch, loss=1.13, accuracy=0.755, val_loss=6.3, val_accuracy=0.223, lr=0.1]    70%|██████▉   | 58/83 [16:43<06:56, 16.66s/epoch, loss=1.13, accuracy=0.756, val_loss=2.83, val_accuracy=0.395, lr=0.1] 71%|███████   | 59/83 [16:59<06:40, 16.67s/epoch, loss=1.13, accuracy=0.758, val_loss=1.95, val_accuracy=0.51, lr=0.1]  72%|███████▏  | 60/83 [17:16<06:22, 16.64s/epoch, loss=1.13, accuracy=0.758, val_loss=2.45, val_accuracy=0.462, lr=0.1] 73%|███████▎  | 61/83 [17:33<06:05, 16.62s/epoch, loss=1.13, accuracy=0.756, val_loss=1.82, val_accuracy=0.551, lr=0.0316] 75%|███████▍  | 62/83 [17:49<05:49, 16.64s/epoch, loss=1.13, accuracy=0.758, val_loss=2.04, val_accuracy=0.538, lr=0.1]    76%|███████▌  | 63/83 [18:06<05:33, 16.70s/epoch, loss=1.13, accuracy=0.754, val_loss=7.38, val_accuracy=0.226, lr=0.1] 77%|███████▋  | 64/83 [18:23<05:18, 16.78s/epoch, loss=1.13, accuracy=0.755, val_loss=2.14, val_accuracy=0.442, lr=0.1] 78%|███████▊  | 65/83 [18:40<05:02, 16.81s/epoch, loss=1.12, accuracy=0.755, val_loss=3, val_accuracy=0.381, lr=0.1]    80%|███████▉  | 66/83 [18:57<04:45, 16.77s/epoch, loss=1.12, accuracy=0.755, val_loss=1.9, val_accuracy=0.567, lr=0.0316] 81%|████████  | 67/83 [19:13<04:28, 16.78s/epoch, loss=1.13, accuracy=0.755, val_loss=2.11, val_accuracy=0.554, lr=0.1]   82%|████████▏ | 68/83 [19:30<04:11, 16.79s/epoch, loss=1.13, accuracy=0.754, val_loss=1.79, val_accuracy=0.536, lr=0.1] 83%|████████▎ | 69/83 [19:47<03:55, 16.81s/epoch, loss=1.12, accuracy=0.758, val_loss=1.67, val_accuracy=0.575, lr=0.1] 84%|████████▍ | 70/83 [20:04<03:39, 16.86s/epoch, loss=1.13, accuracy=0.753, val_loss=2.47, val_accuracy=0.279, lr=0.1] 86%|████████▌ | 71/83 [20:21<03:21, 16.80s/epoch, loss=1.12, accuracy=0.757, val_loss=2.34, val_accuracy=0.375, lr=0.0316] 87%|████████▋ | 72/83 [20:37<03:04, 16.75s/epoch, loss=1.12, accuracy=0.757, val_loss=3.38, val_accuracy=0.343, lr=0.1]    88%|████████▊ | 73/83 [20:54<02:47, 16.75s/epoch, loss=1.13, accuracy=0.757, val_loss=1.95, val_accuracy=0.475, lr=0.1] 89%|████████▉ | 74/83 [21:11<02:30, 16.78s/epoch, loss=1.13, accuracy=0.757, val_loss=1.7, val_accuracy=0.578, lr=0.1]  90%|█████████ | 75/83 [21:28<02:14, 16.81s/epoch, loss=1.13, accuracy=0.756, val_loss=11.6, val_accuracy=0.11, lr=0.1] 92%|█████████▏| 76/83 [21:44<01:56, 16.67s/epoch, loss=1.13, accuracy=0.757, val_loss=6.38, val_accuracy=0.248, lr=0.0316] 93%|█████████▎| 77/83 [22:01<01:39, 16.62s/epoch, loss=1.13, accuracy=0.757, val_loss=3.44, val_accuracy=0.375, lr=0.1]    94%|█████████▍| 78/83 [22:17<01:23, 16.61s/epoch, loss=1.13, accuracy=0.757, val_loss=1.81, val_accuracy=0.549, lr=0.1] 95%|█████████▌| 79/83 [22:34<01:06, 16.55s/epoch, loss=1.13, accuracy=0.754, val_loss=2.64, val_accuracy=0.449, lr=0.1] 96%|█████████▋| 80/83 [22:50<00:49, 16.54s/epoch, loss=1.12, accuracy=0.757, val_loss=1.68, val_accuracy=0.569, lr=0.1] 98%|█████████▊| 81/83 [23:07<00:33, 16.56s/epoch, loss=1.12, accuracy=0.755, val_loss=2.15, val_accuracy=0.493, lr=0.0316] 99%|█████████▉| 82/83 [23:24<00:16, 16.74s/epoch, loss=0.92, accuracy=0.816, val_loss=0.93, val_accuracy=0.797, lr=0.01]  100%|██████████| 83/83 [23:41<00:00, 16.69s/epoch, loss=0.75, accuracy=0.845, val_loss=0.821, val_accuracy=0.815, lr=0.01]100%|██████████| 83/83 [23:41<00:00, 17.12s/epoch, loss=0.75, accuracy=0.845, val_loss=0.821, val_accuracy=0.815, lr=0.01]
Using real-time data augmentation.
Test score: 0.8476641774177551
Test accuracy: 0.7993000149726868
