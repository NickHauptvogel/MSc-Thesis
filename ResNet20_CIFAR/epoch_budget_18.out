Thu Feb 15 14:00:36 2024       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA TITAN Xp                Off | 00000000:03:00.0 Off |                  N/A |
| 48%   74C    P0              93W / 250W |      0MiB / 12288MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|  No running processes found                                                           |
+---------------------------------------------------------------------------------------+


* * * Run SGD for cluster size = 18. * * *


Budget: 83


* * * Run SGD for ID = 18_1. * * *


2024-02-15 14:00:36.695510: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 14:00:42.708827: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 14:00:42.710727: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-15 14:00:42.750513: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 14:00:42.750549: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 14:00:42.780713: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 14:00:42.780765: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 14:00:42.841209: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 14:00:42.898660: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 14:00:42.949185: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 14:00:42.972045: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 14:00:42.991799: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 14:00:42.992435: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 14:00:42.992521: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 14:00:44.376295: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-15 14:00:44.377415: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 14:00:44.377867: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 14:00:44.377897: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 14:00:44.377931: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 14:00:44.377950: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 14:00:44.377968: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 14:00:44.377986: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 14:00:44.378004: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 14:00:44.378022: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 14:00:44.378040: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 14:00:44.378482: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 14:00:44.378516: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 14:00:45.652354: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-15 14:00:45.652412: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-15 14:00:45.652422: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-15 14:00:45.653687: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:03:00.0, compute capability: 6.1)
{'id': 181, 'batch_size': 128, 'epochs': 83, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/83 [00:00<?, ?epoch/s]2024-02-15 14:00:46.501170: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-15 14:00:46.513720: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2200060000 Hz
2024-02-15 14:00:48.654937: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 14:00:48.962890: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 14:00:49.899927: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-15 14:00:49.931804: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/83 [00:51<1:10:16, 51.42s/epoch, loss=3.24, accuracy=0.259, val_loss=2.5, val_accuracy=0.2, lr=0.1]  2%|▏         | 2/83 [01:16<48:53, 36.22s/epoch, loss=1.53, accuracy=0.538, val_loss=2.03, val_accuracy=0.421, lr=0.1]  4%|▎         | 3/83 [01:40<40:28, 30.35s/epoch, loss=1.31, accuracy=0.642, val_loss=2.42, val_accuracy=0.391, lr=0.1]  5%|▍         | 4/83 [02:05<37:00, 28.10s/epoch, loss=1.25, accuracy=0.687, val_loss=2.66, val_accuracy=0.406, lr=0.1]  6%|▌         | 5/83 [02:28<34:25, 26.48s/epoch, loss=1.22, accuracy=0.704, val_loss=1.58, val_accuracy=0.578, lr=0.1]  7%|▋         | 6/83 [02:53<33:23, 26.02s/epoch, loss=1.21, accuracy=0.714, val_loss=2.97, val_accuracy=0.322, lr=0.1]  8%|▊         | 7/83 [03:18<32:34, 25.71s/epoch, loss=1.2, accuracy=0.722, val_loss=3.12, val_accuracy=0.352, lr=0.1]  10%|▉         | 8/83 [03:44<32:04, 25.66s/epoch, loss=1.19, accuracy=0.725, val_loss=1.92, val_accuracy=0.523, lr=0.1] 11%|█         | 9/83 [04:09<31:31, 25.56s/epoch, loss=1.19, accuracy=0.728, val_loss=2.31, val_accuracy=0.487, lr=0.1] 12%|█▏        | 10/83 [04:34<30:57, 25.44s/epoch, loss=1.19, accuracy=0.731, val_loss=2.55, val_accuracy=0.353, lr=0.0316] 13%|█▎        | 11/83 [05:00<30:29, 25.42s/epoch, loss=1.18, accuracy=0.735, val_loss=2.67, val_accuracy=0.446, lr=0.1]    14%|█▍        | 12/83 [05:26<30:13, 25.54s/epoch, loss=1.19, accuracy=0.737, val_loss=1.82, val_accuracy=0.548, lr=0.1] 16%|█▌        | 13/83 [05:50<29:28, 25.27s/epoch, loss=1.18, accuracy=0.736, val_loss=2.7, val_accuracy=0.443, lr=0.1]  17%|█▋        | 14/83 [06:13<28:18, 24.62s/epoch, loss=1.18, accuracy=0.738, val_loss=3.03, val_accuracy=0.379, lr=0.1] 18%|█▊        | 15/83 [06:36<27:21, 24.13s/epoch, loss=1.18, accuracy=0.738, val_loss=2.55, val_accuracy=0.331, lr=0.0316] 19%|█▉        | 16/83 [07:02<27:18, 24.45s/epoch, loss=1.17, accuracy=0.74, val_loss=2.34, val_accuracy=0.452, lr=0.1]     20%|██        | 17/83 [07:26<27:03, 24.60s/epoch, loss=1.16, accuracy=0.741, val_loss=2.12, val_accuracy=0.472, lr=0.1] 22%|██▏       | 18/83 [07:52<26:52, 24.81s/epoch, loss=1.16, accuracy=0.746, val_loss=2, val_accuracy=0.47, lr=0.1]     23%|██▎       | 19/83 [08:17<26:32, 24.88s/epoch, loss=1.15, accuracy=0.748, val_loss=1.69, val_accuracy=0.532, lr=0.1] 24%|██▍       | 20/83 [08:42<26:12, 24.95s/epoch, loss=1.15, accuracy=0.746, val_loss=1.67, val_accuracy=0.537, lr=0.0316] 25%|██▌       | 21/83 [09:07<25:56, 25.10s/epoch, loss=1.15, accuracy=0.746, val_loss=1.83, val_accuracy=0.523, lr=0.1]    27%|██▋       | 22/83 [09:33<25:37, 25.20s/epoch, loss=1.15, accuracy=0.744, val_loss=3.32, val_accuracy=0.324, lr=0.1] 28%|██▊       | 23/83 [09:58<25:20, 25.33s/epoch, loss=1.15, accuracy=0.748, val_loss=2.31, val_accuracy=0.408, lr=0.1] 29%|██▉       | 24/83 [10:24<24:55, 25.34s/epoch, loss=1.14, accuracy=0.751, val_loss=2.45, val_accuracy=0.518, lr=0.1] 30%|███       | 25/83 [10:49<24:23, 25.23s/epoch, loss=1.14, accuracy=0.75, val_loss=1.64, val_accuracy=0.569, lr=0.0316] 31%|███▏      | 26/83 [11:14<24:01, 25.28s/epoch, loss=1.14, accuracy=0.75, val_loss=3.47, val_accuracy=0.358, lr=0.1]    33%|███▎      | 27/83 [11:40<23:39, 25.35s/epoch, loss=1.14, accuracy=0.748, val_loss=3.02, val_accuracy=0.381, lr=0.1] 34%|███▎      | 28/83 [12:05<23:18, 25.42s/epoch, loss=1.14, accuracy=0.748, val_loss=4.4, val_accuracy=0.254, lr=0.1]  35%|███▍      | 29/83 [12:30<22:47, 25.33s/epoch, loss=1.13, accuracy=0.755, val_loss=2.67, val_accuracy=0.298, lr=0.1] 36%|███▌      | 30/83 [12:56<22:30, 25.47s/epoch, loss=1.13, accuracy=0.752, val_loss=2.62, val_accuracy=0.35, lr=0.0316] 37%|███▋      | 31/83 [13:22<22:07, 25.53s/epoch, loss=1.13, accuracy=0.752, val_loss=1.8, val_accuracy=0.521, lr=0.1]    39%|███▊      | 32/83 [13:48<21:45, 25.59s/epoch, loss=1.13, accuracy=0.753, val_loss=2.01, val_accuracy=0.503, lr=0.1] 40%|███▉      | 33/83 [14:13<21:22, 25.65s/epoch, loss=1.12, accuracy=0.756, val_loss=2.21, val_accuracy=0.415, lr=0.1] 41%|████      | 34/83 [14:39<21:01, 25.74s/epoch, loss=1.12, accuracy=0.756, val_loss=3.5, val_accuracy=0.217, lr=0.1]  42%|████▏     | 35/83 [15:05<20:32, 25.68s/epoch, loss=1.12, accuracy=0.756, val_loss=3.73, val_accuracy=0.279, lr=0.0316] 43%|████▎     | 36/83 [15:30<20:03, 25.60s/epoch, loss=1.13, accuracy=0.756, val_loss=2.11, val_accuracy=0.44, lr=0.1]     45%|████▍     | 37/83 [15:56<19:40, 25.66s/epoch, loss=1.13, accuracy=0.754, val_loss=1.74, val_accuracy=0.538, lr=0.1] 46%|████▌     | 38/83 [16:22<19:14, 25.67s/epoch, loss=1.13, accuracy=0.753, val_loss=2.23, val_accuracy=0.478, lr=0.1] 47%|████▋     | 39/83 [16:47<18:44, 25.56s/epoch, loss=1.12, accuracy=0.752, val_loss=3.19, val_accuracy=0.296, lr=0.1] 48%|████▊     | 40/83 [17:12<18:14, 25.46s/epoch, loss=1.12, accuracy=0.757, val_loss=2.19, val_accuracy=0.466, lr=0.0316] 49%|████▉     | 41/83 [17:37<17:39, 25.22s/epoch, loss=1.12, accuracy=0.755, val_loss=1.88, val_accuracy=0.516, lr=0.1]    51%|█████     | 42/83 [18:02<17:14, 25.24s/epoch, loss=1.12, accuracy=0.756, val_loss=3.06, val_accuracy=0.359, lr=0.1] 52%|█████▏    | 43/83 [18:27<16:41, 25.03s/epoch, loss=1.12, accuracy=0.757, val_loss=2.28, val_accuracy=0.375, lr=0.1] 53%|█████▎    | 44/83 [18:52<16:17, 25.05s/epoch, loss=1.13, accuracy=0.754, val_loss=3.2, val_accuracy=0.414, lr=0.1]  54%|█████▍    | 45/83 [19:17<15:51, 25.04s/epoch, loss=1.12, accuracy=0.755, val_loss=1.7, val_accuracy=0.586, lr=0.0316] 55%|█████▌    | 46/83 [19:42<15:22, 24.94s/epoch, loss=1.12, accuracy=0.756, val_loss=2.22, val_accuracy=0.471, lr=0.1]   57%|█████▋    | 47/83 [20:07<14:59, 24.99s/epoch, loss=1.12, accuracy=0.755, val_loss=5.32, val_accuracy=0.159, lr=0.1] 58%|█████▊    | 48/83 [20:32<14:40, 25.14s/epoch, loss=1.12, accuracy=0.757, val_loss=2.09, val_accuracy=0.461, lr=0.1] 59%|█████▉    | 49/83 [20:58<14:19, 25.27s/epoch, loss=1.12, accuracy=0.757, val_loss=2.03, val_accuracy=0.477, lr=0.1] 60%|██████    | 50/83 [21:23<13:52, 25.23s/epoch, loss=1.11, accuracy=0.757, val_loss=1.75, val_accuracy=0.58, lr=0.0316] 61%|██████▏   | 51/83 [21:49<13:30, 25.32s/epoch, loss=1.11, accuracy=0.759, val_loss=1.7, val_accuracy=0.582, lr=0.1]    63%|██████▎   | 52/83 [22:14<13:08, 25.44s/epoch, loss=1.11, accuracy=0.758, val_loss=2.61, val_accuracy=0.403, lr=0.1] 64%|██████▍   | 53/83 [22:40<12:42, 25.43s/epoch, loss=1.11, accuracy=0.757, val_loss=1.73, val_accuracy=0.57, lr=0.1]  65%|██████▌   | 54/83 [23:05<12:17, 25.42s/epoch, loss=1.11, accuracy=0.758, val_loss=3.04, val_accuracy=0.285, lr=0.1] 66%|██████▋   | 55/83 [23:30<11:51, 25.40s/epoch, loss=1.11, accuracy=0.757, val_loss=4.55, val_accuracy=0.208, lr=0.0316] 67%|██████▋   | 56/83 [23:55<11:15, 25.03s/epoch, loss=1.11, accuracy=0.757, val_loss=1.91, val_accuracy=0.511, lr=0.1]    69%|██████▊   | 57/83 [24:19<10:49, 24.97s/epoch, loss=1.11, accuracy=0.755, val_loss=2.71, val_accuracy=0.331, lr=0.1] 70%|██████▉   | 58/83 [24:45<10:26, 25.06s/epoch, loss=1.11, accuracy=0.758, val_loss=3.63, val_accuracy=0.274, lr=0.1] 71%|███████   | 59/83 [25:08<09:52, 24.68s/epoch, loss=1.11, accuracy=0.756, val_loss=2.38, val_accuracy=0.499, lr=0.1] 72%|███████▏  | 60/83 [25:33<09:27, 24.68s/epoch, loss=1.11, accuracy=0.758, val_loss=2.58, val_accuracy=0.382, lr=0.0316] 73%|███████▎  | 61/83 [25:58<09:04, 24.76s/epoch, loss=1.11, accuracy=0.758, val_loss=3.2, val_accuracy=0.322, lr=0.1]     75%|███████▍  | 62/83 [26:22<08:37, 24.65s/epoch, loss=1.12, accuracy=0.757, val_loss=2.72, val_accuracy=0.401, lr=0.1] 76%|███████▌  | 63/83 [26:48<08:16, 24.80s/epoch, loss=1.11, accuracy=0.757, val_loss=2.1, val_accuracy=0.511, lr=0.1]  77%|███████▋  | 64/83 [27:13<07:55, 25.00s/epoch, loss=1.11, accuracy=0.759, val_loss=1.75, val_accuracy=0.536, lr=0.1] 78%|███████▊  | 65/83 [27:38<07:28, 24.94s/epoch, loss=1.12, accuracy=0.755, val_loss=2.14, val_accuracy=0.482, lr=0.0316] 80%|███████▉  | 66/83 [28:03<07:05, 25.03s/epoch, loss=1.11, accuracy=0.757, val_loss=2.21, val_accuracy=0.491, lr=0.1]    81%|████████  | 67/83 [28:27<06:35, 24.75s/epoch, loss=1.11, accuracy=0.759, val_loss=1.72, val_accuracy=0.577, lr=0.1] 82%|████████▏ | 68/83 [28:52<06:13, 24.87s/epoch, loss=1.11, accuracy=0.757, val_loss=2.63, val_accuracy=0.389, lr=0.1] 83%|████████▎ | 69/83 [29:17<05:49, 24.94s/epoch, loss=1.11, accuracy=0.757, val_loss=1.91, val_accuracy=0.478, lr=0.1] 84%|████████▍ | 70/83 [29:43<05:26, 25.09s/epoch, loss=1.11, accuracy=0.758, val_loss=4.01, val_accuracy=0.293, lr=0.0316] 86%|████████▌ | 71/83 [30:09<05:02, 25.24s/epoch, loss=1.11, accuracy=0.756, val_loss=1.89, val_accuracy=0.515, lr=0.1]    87%|████████▋ | 72/83 [30:33<04:36, 25.16s/epoch, loss=1.11, accuracy=0.759, val_loss=1.63, val_accuracy=0.591, lr=0.1] 88%|████████▊ | 73/83 [30:58<04:08, 24.83s/epoch, loss=1.11, accuracy=0.757, val_loss=2.86, val_accuracy=0.362, lr=0.1] 89%|████████▉ | 74/83 [31:22<03:41, 24.58s/epoch, loss=1.11, accuracy=0.757, val_loss=1.94, val_accuracy=0.516, lr=0.1] 90%|█████████ | 75/83 [31:46<03:16, 24.59s/epoch, loss=1.11, accuracy=0.756, val_loss=2.19, val_accuracy=0.416, lr=0.0316] 92%|█████████▏| 76/83 [32:10<02:50, 24.38s/epoch, loss=1.11, accuracy=0.757, val_loss=2.11, val_accuracy=0.455, lr=0.1]    93%|█████████▎| 77/83 [32:34<02:25, 24.30s/epoch, loss=1.11, accuracy=0.756, val_loss=2.22, val_accuracy=0.511, lr=0.1] 94%|█████████▍| 78/83 [32:59<02:02, 24.48s/epoch, loss=1.12, accuracy=0.756, val_loss=2.22, val_accuracy=0.443, lr=0.1] 95%|█████████▌| 79/83 [33:24<01:38, 24.63s/epoch, loss=1.12, accuracy=0.757, val_loss=1.94, val_accuracy=0.466, lr=0.1] 96%|█████████▋| 80/83 [33:48<01:13, 24.45s/epoch, loss=1.11, accuracy=0.758, val_loss=3, val_accuracy=0.328, lr=0.0316] 98%|█████████▊| 81/83 [34:13<00:49, 24.57s/epoch, loss=1.11, accuracy=0.761, val_loss=1.97, val_accuracy=0.56, lr=0.1]  99%|█████████▉| 82/83 [34:37<00:24, 24.55s/epoch, loss=0.884, accuracy=0.821, val_loss=0.949, val_accuracy=0.78, lr=0.01]100%|██████████| 83/83 [35:02<00:00, 24.58s/epoch, loss=0.72, accuracy=0.847, val_loss=0.794, val_accuracy=0.811, lr=0.01]100%|██████████| 83/83 [35:02<00:00, 25.33s/epoch, loss=0.72, accuracy=0.847, val_loss=0.794, val_accuracy=0.811, lr=0.01]
Using real-time data augmentation.
Test loss: 0.7943068742752075
Test accuracy: 0.8108000159263611


* * * Run SGD for ID = 18_2. * * *


2024-02-15 14:35:51.696548: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 14:35:54.527180: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 14:35:54.528347: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-15 14:35:54.566201: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 14:35:54.566233: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 14:35:54.568953: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 14:35:54.569001: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 14:35:54.571150: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 14:35:54.571862: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 14:35:54.574250: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 14:35:54.575798: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 14:35:54.580247: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 14:35:54.580785: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 14:35:54.580869: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 14:35:55.865996: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-15 14:35:55.867048: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 14:35:55.867488: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 14:35:55.867517: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 14:35:55.867549: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 14:35:55.867566: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 14:35:55.867606: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 14:35:55.867625: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 14:35:55.867641: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 14:35:55.867657: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 14:35:55.867673: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 14:35:55.868125: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 14:35:55.868163: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 14:35:56.552279: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-15 14:35:56.552334: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-15 14:35:56.552345: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-15 14:35:56.553256: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:03:00.0, compute capability: 6.1)
{'id': 182, 'batch_size': 128, 'epochs': 83, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/83 [00:00<?, ?epoch/s]2024-02-15 14:35:57.365950: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-15 14:35:57.377720: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2200060000 Hz
2024-02-15 14:35:59.420340: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 14:35:59.649155: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 14:36:00.381261: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-15 14:36:00.444995: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/83 [00:55<1:15:14, 55.05s/epoch, loss=3.23, accuracy=0.294, val_loss=3.23, val_accuracy=0.197, lr=0.1]  2%|▏         | 2/83 [01:20<50:28, 37.39s/epoch, loss=1.59, accuracy=0.525, val_loss=2.04, val_accuracy=0.417, lr=0.1]    4%|▎         | 3/83 [01:45<42:31, 31.89s/epoch, loss=1.41, accuracy=0.613, val_loss=1.73, val_accuracy=0.506, lr=0.1]  5%|▍         | 4/83 [02:10<38:34, 29.30s/epoch, loss=1.33, accuracy=0.661, val_loss=1.91, val_accuracy=0.485, lr=0.1]  6%|▌         | 5/83 [02:36<36:12, 27.85s/epoch, loss=1.29, accuracy=0.686, val_loss=1.55, val_accuracy=0.581, lr=0.1]  7%|▋         | 6/83 [03:01<34:41, 27.04s/epoch, loss=1.26, accuracy=0.701, val_loss=1.51, val_accuracy=0.629, lr=0.1]  8%|▊         | 7/83 [03:25<33:10, 26.19s/epoch, loss=1.25, accuracy=0.709, val_loss=1.96, val_accuracy=0.47, lr=0.1]  10%|▉         | 8/83 [03:48<31:18, 25.04s/epoch, loss=1.22, accuracy=0.718, val_loss=2.14, val_accuracy=0.453, lr=0.1] 11%|█         | 9/83 [04:13<30:49, 25.00s/epoch, loss=1.22, accuracy=0.722, val_loss=2.25, val_accuracy=0.446, lr=0.1] 12%|█▏        | 10/83 [04:38<30:22, 24.97s/epoch, loss=1.21, accuracy=0.726, val_loss=1.86, val_accuracy=0.546, lr=0.1] 13%|█▎        | 11/83 [05:02<29:50, 24.87s/epoch, loss=1.2, accuracy=0.728, val_loss=2.02, val_accuracy=0.568, lr=0.0316] 14%|█▍        | 12/83 [05:27<29:28, 24.91s/epoch, loss=1.2, accuracy=0.732, val_loss=2.74, val_accuracy=0.431, lr=0.1]    16%|█▌        | 13/83 [05:52<28:57, 24.83s/epoch, loss=1.19, accuracy=0.736, val_loss=1.53, val_accuracy=0.638, lr=0.1] 17%|█▋        | 14/83 [06:17<28:33, 24.83s/epoch, loss=1.19, accuracy=0.735, val_loss=1.78, val_accuracy=0.491, lr=0.1] 18%|█▊        | 15/83 [06:42<28:12, 24.89s/epoch, loss=1.18, accuracy=0.737, val_loss=3.4, val_accuracy=0.315, lr=0.1]  19%|█▉        | 16/83 [07:07<27:50, 24.93s/epoch, loss=1.18, accuracy=0.74, val_loss=1.87, val_accuracy=0.486, lr=0.0316] 20%|██        | 17/83 [07:32<27:26, 24.94s/epoch, loss=1.17, accuracy=0.742, val_loss=2.08, val_accuracy=0.49, lr=0.1]    22%|██▏       | 18/83 [07:57<26:56, 24.88s/epoch, loss=1.17, accuracy=0.74, val_loss=1.85, val_accuracy=0.553, lr=0.1] 23%|██▎       | 19/83 [08:21<26:28, 24.82s/epoch, loss=1.17, accuracy=0.742, val_loss=3.13, val_accuracy=0.372, lr=0.1] 24%|██▍       | 20/83 [08:46<26:00, 24.76s/epoch, loss=1.17, accuracy=0.745, val_loss=1.87, val_accuracy=0.574, lr=0.1] 25%|██▌       | 21/83 [09:11<25:34, 24.75s/epoch, loss=1.16, accuracy=0.745, val_loss=1.9, val_accuracy=0.521, lr=0.0316] 27%|██▋       | 22/83 [09:36<25:12, 24.79s/epoch, loss=1.15, accuracy=0.749, val_loss=1.71, val_accuracy=0.565, lr=0.1]   28%|██▊       | 23/83 [10:00<24:48, 24.81s/epoch, loss=1.16, accuracy=0.743, val_loss=1.64, val_accuracy=0.592, lr=0.1] 29%|██▉       | 24/83 [10:25<24:18, 24.71s/epoch, loss=1.15, accuracy=0.748, val_loss=1.56, val_accuracy=0.615, lr=0.1] 30%|███       | 25/83 [10:48<23:31, 24.33s/epoch, loss=1.15, accuracy=0.748, val_loss=2.42, val_accuracy=0.479, lr=0.1] 31%|███▏      | 26/83 [11:12<22:53, 24.09s/epoch, loss=1.15, accuracy=0.75, val_loss=1.62, val_accuracy=0.61, lr=0.0316] 33%|███▎      | 27/83 [11:37<22:37, 24.24s/epoch, loss=1.15, accuracy=0.75, val_loss=1.94, val_accuracy=0.511, lr=0.1]   34%|███▎      | 28/83 [12:02<22:25, 24.46s/epoch, loss=1.15, accuracy=0.75, val_loss=2.04, val_accuracy=0.502, lr=0.1] 35%|███▍      | 29/83 [12:27<22:10, 24.65s/epoch, loss=1.15, accuracy=0.749, val_loss=1.65, val_accuracy=0.594, lr=0.1] 36%|███▌      | 30/83 [12:51<21:43, 24.60s/epoch, loss=1.14, accuracy=0.751, val_loss=1.51, val_accuracy=0.619, lr=0.1] 37%|███▋      | 31/83 [13:16<21:17, 24.57s/epoch, loss=1.15, accuracy=0.75, val_loss=1.99, val_accuracy=0.445, lr=0.0316] 39%|███▊      | 32/83 [13:40<20:57, 24.66s/epoch, loss=1.14, accuracy=0.753, val_loss=3.49, val_accuracy=0.322, lr=0.1]   40%|███▉      | 33/83 [14:05<20:32, 24.66s/epoch, loss=1.14, accuracy=0.751, val_loss=2.42, val_accuracy=0.442, lr=0.1] 41%|████      | 34/83 [14:30<20:06, 24.63s/epoch, loss=1.14, accuracy=0.753, val_loss=2.34, val_accuracy=0.488, lr=0.1] 42%|████▏     | 35/83 [14:54<19:43, 24.66s/epoch, loss=1.14, accuracy=0.751, val_loss=1.58, val_accuracy=0.59, lr=0.1]  43%|████▎     | 36/83 [15:19<19:15, 24.59s/epoch, loss=1.14, accuracy=0.752, val_loss=1.64, val_accuracy=0.619, lr=0.0316] 45%|████▍     | 37/83 [15:44<18:56, 24.71s/epoch, loss=1.13, accuracy=0.753, val_loss=1.5, val_accuracy=0.609, lr=0.1]     46%|████▌     | 38/83 [16:09<18:33, 24.75s/epoch, loss=1.14, accuracy=0.756, val_loss=3.88, val_accuracy=0.326, lr=0.1] 47%|████▋     | 39/83 [16:32<17:51, 24.36s/epoch, loss=1.14, accuracy=0.755, val_loss=1.44, val_accuracy=0.659, lr=0.1] 48%|████▊     | 40/83 [16:57<17:33, 24.51s/epoch, loss=1.14, accuracy=0.754, val_loss=2.2, val_accuracy=0.502, lr=0.1]  49%|████▉     | 41/83 [17:21<17:03, 24.36s/epoch, loss=1.14, accuracy=0.752, val_loss=2.08, val_accuracy=0.519, lr=0.1] 51%|█████     | 42/83 [17:45<16:37, 24.33s/epoch, loss=1.14, accuracy=0.754, val_loss=2.5, val_accuracy=0.386, lr=0.1]  52%|█████▏    | 43/83 [18:10<16:18, 24.46s/epoch, loss=1.13, accuracy=0.755, val_loss=3.35, val_accuracy=0.41, lr=0.1] 53%|█████▎    | 44/83 [18:35<16:00, 24.62s/epoch, loss=1.14, accuracy=0.754, val_loss=1.79, val_accuracy=0.513, lr=0.0316] 54%|█████▍    | 45/83 [18:59<15:33, 24.57s/epoch, loss=1.13, accuracy=0.754, val_loss=1.9, val_accuracy=0.548, lr=0.1]     55%|█████▌    | 46/83 [19:23<14:57, 24.26s/epoch, loss=1.13, accuracy=0.755, val_loss=2.86, val_accuracy=0.315, lr=0.1] 57%|█████▋    | 47/83 [19:47<14:30, 24.17s/epoch, loss=1.13, accuracy=0.756, val_loss=1.8, val_accuracy=0.522, lr=0.1]  58%|█████▊    | 48/83 [20:12<14:10, 24.31s/epoch, loss=1.12, accuracy=0.755, val_loss=3.16, val_accuracy=0.442, lr=0.1] 59%|█████▉    | 49/83 [20:36<13:48, 24.36s/epoch, loss=1.13, accuracy=0.756, val_loss=2.08, val_accuracy=0.52, lr=0.0316] 60%|██████    | 50/83 [21:01<13:26, 24.43s/epoch, loss=1.12, accuracy=0.757, val_loss=2.24, val_accuracy=0.397, lr=0.1]   61%|██████▏   | 51/83 [21:25<13:02, 24.47s/epoch, loss=1.12, accuracy=0.755, val_loss=2.24, val_accuracy=0.455, lr=0.1] 63%|██████▎   | 52/83 [21:50<12:39, 24.50s/epoch, loss=1.12, accuracy=0.76, val_loss=2.27, val_accuracy=0.45, lr=0.1]   64%|██████▍   | 53/83 [22:13<12:04, 24.16s/epoch, loss=1.13, accuracy=0.755, val_loss=1.82, val_accuracy=0.526, lr=0.1] 65%|██████▌   | 54/83 [22:37<11:41, 24.19s/epoch, loss=1.12, accuracy=0.757, val_loss=1.92, val_accuracy=0.5, lr=0.0316] 66%|██████▋   | 55/83 [23:02<11:19, 24.27s/epoch, loss=1.12, accuracy=0.756, val_loss=1.75, val_accuracy=0.546, lr=0.1]  67%|██████▋   | 56/83 [23:26<10:58, 24.38s/epoch, loss=1.12, accuracy=0.757, val_loss=1.76, val_accuracy=0.568, lr=0.1] 69%|██████▊   | 57/83 [23:51<10:36, 24.48s/epoch, loss=1.11, accuracy=0.759, val_loss=1.89, val_accuracy=0.512, lr=0.1] 70%|██████▉   | 58/83 [24:15<10:07, 24.30s/epoch, loss=1.11, accuracy=0.758, val_loss=2, val_accuracy=0.489, lr=0.1]    71%|███████   | 59/83 [24:39<09:43, 24.33s/epoch, loss=1.12, accuracy=0.755, val_loss=1.67, val_accuracy=0.624, lr=0.0316] 72%|███████▏  | 60/83 [25:05<09:25, 24.58s/epoch, loss=1.11, accuracy=0.758, val_loss=2.62, val_accuracy=0.383, lr=0.1]    73%|███████▎  | 61/83 [25:30<09:04, 24.73s/epoch, loss=1.12, accuracy=0.756, val_loss=2.04, val_accuracy=0.563, lr=0.1] 75%|███████▍  | 62/83 [25:55<08:41, 24.82s/epoch, loss=1.11, accuracy=0.756, val_loss=1.43, val_accuracy=0.639, lr=0.1] 76%|███████▌  | 63/83 [26:20<08:18, 24.93s/epoch, loss=1.12, accuracy=0.757, val_loss=1.98, val_accuracy=0.447, lr=0.1] 77%|███████▋  | 64/83 [26:45<07:55, 25.05s/epoch, loss=1.12, accuracy=0.759, val_loss=2.21, val_accuracy=0.489, lr=0.1] 78%|███████▊  | 65/83 [27:10<07:29, 24.99s/epoch, loss=1.12, accuracy=0.757, val_loss=1.72, val_accuracy=0.559, lr=0.1] 80%|███████▉  | 66/83 [27:35<07:05, 25.01s/epoch, loss=1.11, accuracy=0.76, val_loss=1.97, val_accuracy=0.447, lr=0.1]  81%|████████  | 67/83 [28:00<06:39, 24.98s/epoch, loss=1.11, accuracy=0.76, val_loss=2.02, val_accuracy=0.509, lr=0.0316] 82%|████████▏ | 68/83 [28:24<06:10, 24.72s/epoch, loss=1.11, accuracy=0.76, val_loss=2.68, val_accuracy=0.432, lr=0.1]    83%|████████▎ | 69/83 [28:49<05:47, 24.84s/epoch, loss=1.11, accuracy=0.759, val_loss=1.91, val_accuracy=0.519, lr=0.1] 84%|████████▍ | 70/83 [29:13<05:18, 24.52s/epoch, loss=1.11, accuracy=0.759, val_loss=2.38, val_accuracy=0.416, lr=0.1] 86%|████████▌ | 71/83 [29:38<04:54, 24.57s/epoch, loss=1.11, accuracy=0.757, val_loss=2.71, val_accuracy=0.336, lr=0.1] 87%|████████▋ | 72/83 [30:02<04:30, 24.56s/epoch, loss=1.11, accuracy=0.757, val_loss=2.37, val_accuracy=0.465, lr=0.0316] 88%|████████▊ | 73/83 [30:27<04:05, 24.58s/epoch, loss=1.11, accuracy=0.757, val_loss=2.22, val_accuracy=0.432, lr=0.1]    89%|████████▉ | 74/83 [30:51<03:40, 24.54s/epoch, loss=1.12, accuracy=0.757, val_loss=1.99, val_accuracy=0.485, lr=0.1] 90%|█████████ | 75/83 [31:16<03:15, 24.44s/epoch, loss=1.12, accuracy=0.759, val_loss=1.49, val_accuracy=0.628, lr=0.1] 92%|█████████▏| 76/83 [31:40<02:50, 24.40s/epoch, loss=1.1, accuracy=0.759, val_loss=1.94, val_accuracy=0.504, lr=0.1]  93%|█████████▎| 77/83 [32:04<02:25, 24.27s/epoch, loss=1.11, accuracy=0.757, val_loss=1.55, val_accuracy=0.598, lr=0.0316] 94%|█████████▍| 78/83 [32:28<02:01, 24.33s/epoch, loss=1.11, accuracy=0.758, val_loss=1.81, val_accuracy=0.538, lr=0.1]    95%|█████████▌| 79/83 [32:52<01:37, 24.27s/epoch, loss=1.11, accuracy=0.757, val_loss=1.42, val_accuracy=0.646, lr=0.1] 96%|█████████▋| 80/83 [33:18<01:13, 24.55s/epoch, loss=1.11, accuracy=0.756, val_loss=1.98, val_accuracy=0.567, lr=0.1] 98%|█████████▊| 81/83 [33:42<00:49, 24.59s/epoch, loss=1.12, accuracy=0.756, val_loss=3.89, val_accuracy=0.29, lr=0.1]  99%|█████████▉| 82/83 [34:07<00:24, 24.53s/epoch, loss=0.901, accuracy=0.818, val_loss=0.965, val_accuracy=0.773, lr=0.01]100%|██████████| 83/83 [34:30<00:00, 24.28s/epoch, loss=0.725, accuracy=0.849, val_loss=0.774, val_accuracy=0.819, lr=0.01]100%|██████████| 83/83 [34:30<00:00, 24.95s/epoch, loss=0.725, accuracy=0.849, val_loss=0.774, val_accuracy=0.819, lr=0.01]
Using real-time data augmentation.
Test loss: 0.7744196057319641
Test accuracy: 0.8187999725341797


* * * Run SGD for ID = 18_3. * * *


2024-02-15 15:10:32.201385: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 15:10:40.417853: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 15:10:40.418911: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-15 15:10:40.458109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 15:10:40.458150: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 15:10:40.460935: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 15:10:40.460979: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 15:10:40.463070: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 15:10:40.463734: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 15:10:40.466103: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 15:10:40.467627: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 15:10:40.472505: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 15:10:40.473062: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 15:10:40.473141: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 15:10:41.802061: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-15 15:10:41.803068: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 15:10:41.803500: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 15:10:41.803531: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 15:10:41.803566: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 15:10:41.803595: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 15:10:41.803615: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 15:10:41.803633: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 15:10:41.803651: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 15:10:41.803678: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 15:10:41.803697: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 15:10:41.804158: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 15:10:41.804197: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 15:10:42.516885: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-15 15:10:42.516948: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-15 15:10:42.516959: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-15 15:10:42.518264: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:03:00.0, compute capability: 6.1)
{'id': 183, 'batch_size': 128, 'epochs': 83, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/83 [00:00<?, ?epoch/s]2024-02-15 15:10:43.335716: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-15 15:10:43.347760: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2200060000 Hz
2024-02-15 15:10:45.503725: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 15:10:45.777095: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 15:10:46.515024: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-15 15:10:46.564231: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/83 [00:55<1:16:00, 55.61s/epoch, loss=3.26, accuracy=0.264, val_loss=2.1, val_accuracy=0.327, lr=0.1]  2%|▏         | 2/83 [01:19<49:45, 36.86s/epoch, loss=1.63, accuracy=0.499, val_loss=1.97, val_accuracy=0.401, lr=0.1]   4%|▎         | 3/83 [01:43<41:14, 30.93s/epoch, loss=1.44, accuracy=0.597, val_loss=1.91, val_accuracy=0.497, lr=0.1]  5%|▍         | 4/83 [02:08<37:43, 28.65s/epoch, loss=1.33, accuracy=0.658, val_loss=1.71, val_accuracy=0.509, lr=0.1]  6%|▌         | 5/83 [02:33<35:28, 27.29s/epoch, loss=1.29, accuracy=0.686, val_loss=1.69, val_accuracy=0.553, lr=0.1]  7%|▋         | 6/83 [02:58<33:57, 26.46s/epoch, loss=1.26, accuracy=0.701, val_loss=2.02, val_accuracy=0.46, lr=0.1]   8%|▊         | 7/83 [03:23<32:56, 26.00s/epoch, loss=1.24, accuracy=0.712, val_loss=1.47, val_accuracy=0.63, lr=0.1] 10%|▉         | 8/83 [03:48<32:12, 25.76s/epoch, loss=1.23, accuracy=0.718, val_loss=1.88, val_accuracy=0.521, lr=0.1] 11%|█         | 9/83 [04:12<31:14, 25.33s/epoch, loss=1.22, accuracy=0.721, val_loss=2.18, val_accuracy=0.481, lr=0.1] 12%|█▏        | 10/83 [04:37<30:32, 25.10s/epoch, loss=1.21, accuracy=0.726, val_loss=2.1, val_accuracy=0.491, lr=0.1] 13%|█▎        | 11/83 [05:02<29:57, 24.96s/epoch, loss=1.2, accuracy=0.73, val_loss=1.67, val_accuracy=0.596, lr=0.1]  14%|█▍        | 12/83 [05:27<29:34, 24.99s/epoch, loss=1.19, accuracy=0.733, val_loss=2.11, val_accuracy=0.483, lr=0.0316] 16%|█▌        | 13/83 [05:51<29:07, 24.97s/epoch, loss=1.18, accuracy=0.738, val_loss=1.57, val_accuracy=0.592, lr=0.1]    17%|█▋        | 14/83 [06:16<28:42, 24.96s/epoch, loss=1.18, accuracy=0.739, val_loss=2.45, val_accuracy=0.491, lr=0.1] 18%|█▊        | 15/83 [06:41<28:12, 24.90s/epoch, loss=1.17, accuracy=0.741, val_loss=1.82, val_accuracy=0.549, lr=0.1] 19%|█▉        | 16/83 [07:07<27:58, 25.05s/epoch, loss=1.18, accuracy=0.739, val_loss=1.77, val_accuracy=0.566, lr=0.1] 20%|██        | 17/83 [07:32<27:34, 25.07s/epoch, loss=1.17, accuracy=0.742, val_loss=1.94, val_accuracy=0.541, lr=0.0316] 22%|██▏       | 18/83 [07:57<27:09, 25.07s/epoch, loss=1.17, accuracy=0.744, val_loss=1.56, val_accuracy=0.635, lr=0.1]    23%|██▎       | 19/83 [08:22<26:46, 25.10s/epoch, loss=1.17, accuracy=0.742, val_loss=1.95, val_accuracy=0.525, lr=0.1] 24%|██▍       | 20/83 [08:47<26:28, 25.21s/epoch, loss=1.16, accuracy=0.745, val_loss=1.82, val_accuracy=0.533, lr=0.1] 25%|██▌       | 21/83 [09:13<26:08, 25.30s/epoch, loss=1.16, accuracy=0.748, val_loss=2.12, val_accuracy=0.504, lr=0.1] 27%|██▋       | 22/83 [09:38<25:42, 25.28s/epoch, loss=1.16, accuracy=0.747, val_loss=2.97, val_accuracy=0.405, lr=0.0316] 28%|██▊       | 23/83 [10:03<25:11, 25.20s/epoch, loss=1.15, accuracy=0.75, val_loss=2.04, val_accuracy=0.469, lr=0.1]     29%|██▉       | 24/83 [10:28<24:39, 25.07s/epoch, loss=1.15, accuracy=0.748, val_loss=1.97, val_accuracy=0.506, lr=0.1] 30%|███       | 25/83 [10:53<24:13, 25.06s/epoch, loss=1.14, accuracy=0.75, val_loss=1.93, val_accuracy=0.521, lr=0.1]  31%|███▏      | 26/83 [11:18<23:53, 25.14s/epoch, loss=1.15, accuracy=0.749, val_loss=3.26, val_accuracy=0.327, lr=0.1] 33%|███▎      | 27/83 [11:44<23:30, 25.19s/epoch, loss=1.14, accuracy=0.752, val_loss=2.07, val_accuracy=0.461, lr=0.0316] 34%|███▎      | 28/83 [12:09<23:02, 25.14s/epoch, loss=1.15, accuracy=0.751, val_loss=3.04, val_accuracy=0.395, lr=0.1]    35%|███▍      | 29/83 [12:34<22:42, 25.23s/epoch, loss=1.14, accuracy=0.751, val_loss=2.18, val_accuracy=0.387, lr=0.1] 36%|███▌      | 30/83 [12:59<22:18, 25.26s/epoch, loss=1.14, accuracy=0.75, val_loss=2.37, val_accuracy=0.479, lr=0.1]  37%|███▋      | 31/83 [13:25<21:57, 25.34s/epoch, loss=1.14, accuracy=0.753, val_loss=2.45, val_accuracy=0.402, lr=0.1] 39%|███▊      | 32/83 [13:50<21:33, 25.36s/epoch, loss=1.14, accuracy=0.752, val_loss=2.15, val_accuracy=0.462, lr=0.0316] 40%|███▉      | 33/83 [14:16<21:05, 25.31s/epoch, loss=1.14, accuracy=0.751, val_loss=2.08, val_accuracy=0.467, lr=0.1]    41%|████      | 34/83 [14:40<20:24, 24.99s/epoch, loss=1.14, accuracy=0.751, val_loss=2.02, val_accuracy=0.518, lr=0.1] 42%|████▏     | 35/83 [15:04<19:55, 24.91s/epoch, loss=1.14, accuracy=0.752, val_loss=7.56, val_accuracy=0.188, lr=0.1] 43%|████▎     | 36/83 [15:29<19:27, 24.85s/epoch, loss=1.14, accuracy=0.752, val_loss=1.63, val_accuracy=0.602, lr=0.1] 45%|████▍     | 37/83 [15:54<19:04, 24.89s/epoch, loss=1.13, accuracy=0.755, val_loss=1.91, val_accuracy=0.534, lr=0.0316] 46%|████▌     | 38/83 [16:19<18:45, 25.01s/epoch, loss=1.14, accuracy=0.754, val_loss=2.34, val_accuracy=0.46, lr=0.1]     47%|████▋     | 39/83 [16:44<18:15, 24.89s/epoch, loss=1.14, accuracy=0.755, val_loss=2.53, val_accuracy=0.43, lr=0.1] 48%|████▊     | 40/83 [17:09<17:52, 24.95s/epoch, loss=1.13, accuracy=0.755, val_loss=1.61, val_accuracy=0.623, lr=0.1] 49%|████▉     | 41/83 [17:34<17:30, 25.00s/epoch, loss=1.13, accuracy=0.756, val_loss=2.31, val_accuracy=0.45, lr=0.1]  51%|█████     | 42/83 [17:59<17:06, 25.03s/epoch, loss=1.13, accuracy=0.756, val_loss=2.51, val_accuracy=0.438, lr=0.0316] 52%|█████▏    | 43/83 [18:25<16:44, 25.10s/epoch, loss=1.13, accuracy=0.757, val_loss=1.58, val_accuracy=0.609, lr=0.1]    53%|█████▎    | 44/83 [18:50<16:18, 25.08s/epoch, loss=1.12, accuracy=0.757, val_loss=1.88, val_accuracy=0.523, lr=0.1] 54%|█████▍    | 45/83 [19:15<15:53, 25.08s/epoch, loss=1.13, accuracy=0.758, val_loss=1.9, val_accuracy=0.513, lr=0.1]  55%|█████▌    | 46/83 [19:40<15:28, 25.09s/epoch, loss=1.12, accuracy=0.755, val_loss=2.07, val_accuracy=0.464, lr=0.1] 57%|█████▋    | 47/83 [20:05<15:01, 25.05s/epoch, loss=1.13, accuracy=0.754, val_loss=3.35, val_accuracy=0.175, lr=0.0316] 58%|█████▊    | 48/83 [20:30<14:33, 24.95s/epoch, loss=1.12, accuracy=0.755, val_loss=7.85, val_accuracy=0.212, lr=0.1]    59%|█████▉    | 49/83 [20:55<14:08, 24.97s/epoch, loss=1.12, accuracy=0.757, val_loss=2.04, val_accuracy=0.508, lr=0.1] 60%|██████    | 50/83 [21:19<13:42, 24.92s/epoch, loss=1.13, accuracy=0.755, val_loss=1.96, val_accuracy=0.488, lr=0.1] 61%|██████▏   | 51/83 [21:44<13:18, 24.96s/epoch, loss=1.12, accuracy=0.758, val_loss=3.33, val_accuracy=0.176, lr=0.1] 63%|██████▎   | 52/83 [22:09<12:46, 24.74s/epoch, loss=1.12, accuracy=0.758, val_loss=3.82, val_accuracy=0.3, lr=0.0316] 64%|██████▍   | 53/83 [22:33<12:19, 24.65s/epoch, loss=1.12, accuracy=0.758, val_loss=2.07, val_accuracy=0.479, lr=0.1]  65%|██████▌   | 54/83 [22:58<11:55, 24.67s/epoch, loss=1.12, accuracy=0.757, val_loss=2.34, val_accuracy=0.468, lr=0.1] 66%|██████▋   | 55/83 [23:23<11:32, 24.73s/epoch, loss=1.11, accuracy=0.758, val_loss=1.92, val_accuracy=0.504, lr=0.1] 67%|██████▋   | 56/83 [23:48<11:09, 24.80s/epoch, loss=1.11, accuracy=0.758, val_loss=4.97, val_accuracy=0.193, lr=0.1] 69%|██████▊   | 57/83 [24:13<10:45, 24.83s/epoch, loss=1.12, accuracy=0.759, val_loss=4.21, val_accuracy=0.279, lr=0.0316] 70%|██████▉   | 58/83 [24:38<10:21, 24.88s/epoch, loss=1.12, accuracy=0.756, val_loss=2.83, val_accuracy=0.426, lr=0.1]    71%|███████   | 59/83 [25:02<09:51, 24.63s/epoch, loss=1.12, accuracy=0.755, val_loss=1.8, val_accuracy=0.528, lr=0.1]  72%|███████▏  | 60/83 [25:26<09:27, 24.68s/epoch, loss=1.11, accuracy=0.757, val_loss=2.07, val_accuracy=0.5, lr=0.1]  73%|███████▎  | 61/83 [25:51<09:03, 24.71s/epoch, loss=1.11, accuracy=0.759, val_loss=1.62, val_accuracy=0.596, lr=0.1] 75%|███████▍  | 62/83 [26:16<08:38, 24.69s/epoch, loss=1.11, accuracy=0.76, val_loss=2.98, val_accuracy=0.405, lr=0.0316] 76%|███████▌  | 63/83 [26:40<08:12, 24.63s/epoch, loss=1.11, accuracy=0.758, val_loss=1.47, val_accuracy=0.62, lr=0.1]    77%|███████▋  | 64/83 [27:04<07:44, 24.46s/epoch, loss=1.11, accuracy=0.758, val_loss=4.62, val_accuracy=0.18, lr=0.1] 78%|███████▊  | 65/83 [27:29<07:22, 24.56s/epoch, loss=1.11, accuracy=0.758, val_loss=2.05, val_accuracy=0.496, lr=0.1] 80%|███████▉  | 66/83 [27:54<06:57, 24.56s/epoch, loss=1.11, accuracy=0.758, val_loss=2.47, val_accuracy=0.468, lr=0.1] 81%|████████  | 67/83 [28:18<06:31, 24.48s/epoch, loss=1.11, accuracy=0.758, val_loss=1.67, val_accuracy=0.59, lr=0.0316] 82%|████████▏ | 68/83 [28:43<06:08, 24.57s/epoch, loss=1.11, accuracy=0.757, val_loss=1.65, val_accuracy=0.572, lr=0.1]   83%|████████▎ | 69/83 [29:08<05:45, 24.68s/epoch, loss=1.11, accuracy=0.757, val_loss=2.03, val_accuracy=0.48, lr=0.1]  84%|████████▍ | 70/83 [29:32<05:20, 24.67s/epoch, loss=1.11, accuracy=0.758, val_loss=3.61, val_accuracy=0.358, lr=0.1] 86%|████████▌ | 71/83 [29:57<04:56, 24.68s/epoch, loss=1.11, accuracy=0.759, val_loss=3.42, val_accuracy=0.297, lr=0.1] 87%|████████▋ | 72/83 [30:22<04:32, 24.76s/epoch, loss=1.11, accuracy=0.757, val_loss=1.44, val_accuracy=0.635, lr=0.1] 88%|████████▊ | 73/83 [30:47<04:07, 24.75s/epoch, loss=1.12, accuracy=0.757, val_loss=1.84, val_accuracy=0.53, lr=0.1]  89%|████████▉ | 74/83 [31:11<03:41, 24.56s/epoch, loss=1.11, accuracy=0.76, val_loss=1.74, val_accuracy=0.539, lr=0.1] 90%|█████████ | 75/83 [31:36<03:16, 24.60s/epoch, loss=1.11, accuracy=0.757, val_loss=2.72, val_accuracy=0.404, lr=0.1] 92%|█████████▏| 76/83 [32:00<02:52, 24.63s/epoch, loss=1.1, accuracy=0.758, val_loss=1.74, val_accuracy=0.587, lr=0.1]  93%|█████████▎| 77/83 [32:25<02:27, 24.59s/epoch, loss=1.11, accuracy=0.759, val_loss=1.96, val_accuracy=0.48, lr=0.0316] 94%|█████████▍| 78/83 [32:50<02:03, 24.66s/epoch, loss=1.11, accuracy=0.759, val_loss=2.43, val_accuracy=0.453, lr=0.1]   95%|█████████▌| 79/83 [33:14<01:38, 24.70s/epoch, loss=1.1, accuracy=0.76, val_loss=2.4, val_accuracy=0.431, lr=0.1]    96%|█████████▋| 80/83 [33:39<01:14, 24.67s/epoch, loss=1.11, accuracy=0.758, val_loss=1.62, val_accuracy=0.585, lr=0.1] 98%|█████████▊| 81/83 [34:04<00:49, 24.70s/epoch, loss=1.11, accuracy=0.757, val_loss=3.97, val_accuracy=0.191, lr=0.1] 99%|█████████▉| 82/83 [34:28<00:24, 24.70s/epoch, loss=0.881, accuracy=0.822, val_loss=0.906, val_accuracy=0.796, lr=0.01]100%|██████████| 83/83 [34:53<00:00, 24.63s/epoch, loss=0.714, accuracy=0.849, val_loss=0.785, val_accuracy=0.815, lr=0.01]100%|██████████| 83/83 [34:53<00:00, 25.22s/epoch, loss=0.714, accuracy=0.849, val_loss=0.785, val_accuracy=0.815, lr=0.01]
Using real-time data augmentation.
Test loss: 0.7850140333175659
Test accuracy: 0.8151000142097473


* * * Run SGD for ID = 18_4. * * *


2024-02-15 15:45:39.551046: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 15:45:42.477108: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 15:45:42.478267: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-15 15:45:42.515451: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 15:45:42.515486: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 15:45:42.518166: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 15:45:42.518209: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 15:45:42.520549: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 15:45:42.521235: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 15:45:42.523668: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 15:45:42.525344: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 15:45:42.530028: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 15:45:42.530506: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 15:45:42.530623: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 15:45:43.752936: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-15 15:45:43.753950: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 15:45:43.754367: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 15:45:43.754398: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 15:45:43.754432: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 15:45:43.754449: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 15:45:43.754466: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 15:45:43.754484: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 15:45:43.754501: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 15:45:43.754518: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 15:45:43.754535: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 15:45:43.754939: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 15:45:43.754975: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 15:45:44.402906: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-15 15:45:44.402969: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-15 15:45:44.402980: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-15 15:45:44.403836: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:03:00.0, compute capability: 6.1)
{'id': 184, 'batch_size': 128, 'epochs': 83, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/83 [00:00<?, ?epoch/s]2024-02-15 15:45:45.317904: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-15 15:45:45.329724: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2200060000 Hz
2024-02-15 15:45:47.484843: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 15:45:47.787742: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 15:45:48.667275: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-15 15:45:48.711538: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/83 [00:56<1:16:50, 56.23s/epoch, loss=3.26, accuracy=0.288, val_loss=2.36, val_accuracy=0.279, lr=0.1]  2%|▏         | 2/83 [01:19<49:27, 36.64s/epoch, loss=1.57, accuracy=0.531, val_loss=2.63, val_accuracy=0.381, lr=0.1]    4%|▎         | 3/83 [01:41<40:11, 30.14s/epoch, loss=1.34, accuracy=0.645, val_loss=1.89, val_accuracy=0.514, lr=0.1]  5%|▍         | 4/83 [02:04<36:07, 27.43s/epoch, loss=1.26, accuracy=0.689, val_loss=2.45, val_accuracy=0.406, lr=0.1]  6%|▌         | 5/83 [02:29<34:14, 26.33s/epoch, loss=1.25, accuracy=0.705, val_loss=2.48, val_accuracy=0.385, lr=0.1]  7%|▋         | 6/83 [02:53<32:54, 25.64s/epoch, loss=1.23, accuracy=0.715, val_loss=1.72, val_accuracy=0.549, lr=0.1]  8%|▊         | 7/83 [03:17<31:54, 25.19s/epoch, loss=1.21, accuracy=0.725, val_loss=1.92, val_accuracy=0.498, lr=0.1] 10%|▉         | 8/83 [03:41<30:56, 24.76s/epoch, loss=1.21, accuracy=0.724, val_loss=2.4, val_accuracy=0.429, lr=0.1]  11%|█         | 9/83 [04:06<30:30, 24.73s/epoch, loss=1.21, accuracy=0.731, val_loss=1.74, val_accuracy=0.548, lr=0.1] 12%|█▏        | 10/83 [04:30<29:48, 24.51s/epoch, loss=1.2, accuracy=0.733, val_loss=1.95, val_accuracy=0.447, lr=0.1] 13%|█▎        | 11/83 [04:54<29:18, 24.43s/epoch, loss=1.19, accuracy=0.738, val_loss=2.99, val_accuracy=0.366, lr=0.0316] 14%|█▍        | 12/83 [05:18<28:54, 24.42s/epoch, loss=1.19, accuracy=0.739, val_loss=2.39, val_accuracy=0.448, lr=0.1]    16%|█▌        | 13/83 [05:43<28:34, 24.49s/epoch, loss=1.18, accuracy=0.74, val_loss=1.81, val_accuracy=0.524, lr=0.1]  17%|█▋        | 14/83 [06:08<28:13, 24.54s/epoch, loss=1.18, accuracy=0.743, val_loss=2.28, val_accuracy=0.38, lr=0.1] 18%|█▊        | 15/83 [06:33<27:57, 24.67s/epoch, loss=1.17, accuracy=0.745, val_loss=2.53, val_accuracy=0.423, lr=0.1] 19%|█▉        | 16/83 [06:57<27:33, 24.68s/epoch, loss=1.18, accuracy=0.743, val_loss=3.33, val_accuracy=0.305, lr=0.0316] 20%|██        | 17/83 [07:23<27:17, 24.81s/epoch, loss=1.17, accuracy=0.747, val_loss=2.52, val_accuracy=0.407, lr=0.1]    22%|██▏       | 18/83 [07:47<26:50, 24.77s/epoch, loss=1.17, accuracy=0.747, val_loss=2.35, val_accuracy=0.429, lr=0.1] 23%|██▎       | 19/83 [08:12<26:22, 24.72s/epoch, loss=1.17, accuracy=0.749, val_loss=2.47, val_accuracy=0.339, lr=0.1] 24%|██▍       | 20/83 [08:37<25:58, 24.74s/epoch, loss=1.16, accuracy=0.748, val_loss=2.96, val_accuracy=0.369, lr=0.1] 25%|██▌       | 21/83 [09:01<25:26, 24.63s/epoch, loss=1.15, accuracy=0.751, val_loss=2.97, val_accuracy=0.31, lr=0.0316] 27%|██▋       | 22/83 [09:26<25:08, 24.72s/epoch, loss=1.16, accuracy=0.748, val_loss=1.71, val_accuracy=0.558, lr=0.1]   28%|██▊       | 23/83 [09:50<24:37, 24.63s/epoch, loss=1.15, accuracy=0.751, val_loss=2.22, val_accuracy=0.391, lr=0.1] 29%|██▉       | 24/83 [10:15<24:09, 24.57s/epoch, loss=1.16, accuracy=0.75, val_loss=2.05, val_accuracy=0.506, lr=0.1]  30%|███       | 25/83 [10:38<23:29, 24.30s/epoch, loss=1.15, accuracy=0.752, val_loss=1.61, val_accuracy=0.582, lr=0.1] 31%|███▏      | 26/83 [11:03<23:10, 24.39s/epoch, loss=1.15, accuracy=0.751, val_loss=1.86, val_accuracy=0.49, lr=0.1]  33%|███▎      | 27/83 [11:28<22:53, 24.53s/epoch, loss=1.15, accuracy=0.748, val_loss=5.1, val_accuracy=0.306, lr=0.1] 34%|███▎      | 28/83 [11:53<22:31, 24.57s/epoch, loss=1.14, accuracy=0.754, val_loss=2.17, val_accuracy=0.452, lr=0.1] 35%|███▍      | 29/83 [12:16<21:54, 24.33s/epoch, loss=1.15, accuracy=0.753, val_loss=3.97, val_accuracy=0.289, lr=0.1] 36%|███▌      | 30/83 [12:41<21:37, 24.48s/epoch, loss=1.14, accuracy=0.757, val_loss=3.47, val_accuracy=0.367, lr=0.0316] 37%|███▋      | 31/83 [13:05<20:57, 24.19s/epoch, loss=1.15, accuracy=0.752, val_loss=1.58, val_accuracy=0.609, lr=0.1]    39%|███▊      | 32/83 [13:30<20:44, 24.41s/epoch, loss=1.14, accuracy=0.755, val_loss=2, val_accuracy=0.533, lr=0.1]    40%|███▉      | 33/83 [13:54<20:20, 24.42s/epoch, loss=1.13, accuracy=0.758, val_loss=1.56, val_accuracy=0.607, lr=0.1] 41%|████      | 34/83 [14:18<19:54, 24.38s/epoch, loss=1.14, accuracy=0.754, val_loss=1.73, val_accuracy=0.581, lr=0.1] 42%|████▏     | 35/83 [14:43<19:28, 24.34s/epoch, loss=1.14, accuracy=0.755, val_loss=1.82, val_accuracy=0.538, lr=0.1] 43%|████▎     | 36/83 [15:06<18:55, 24.16s/epoch, loss=1.14, accuracy=0.753, val_loss=1.86, val_accuracy=0.573, lr=0.1] 45%|████▍     | 37/83 [15:31<18:36, 24.27s/epoch, loss=1.14, accuracy=0.754, val_loss=2.74, val_accuracy=0.377, lr=0.1] 46%|████▌     | 38/83 [15:55<18:15, 24.34s/epoch, loss=1.13, accuracy=0.756, val_loss=1.37, val_accuracy=0.675, lr=0.1] 47%|████▋     | 39/83 [16:19<17:46, 24.25s/epoch, loss=1.13, accuracy=0.758, val_loss=2.28, val_accuracy=0.428, lr=0.1] 48%|████▊     | 40/83 [16:44<17:29, 24.40s/epoch, loss=1.14, accuracy=0.755, val_loss=2.75, val_accuracy=0.338, lr=0.1] 49%|████▉     | 41/83 [17:09<17:08, 24.50s/epoch, loss=1.12, accuracy=0.758, val_loss=2.01, val_accuracy=0.52, lr=0.1]  51%|█████     | 42/83 [17:33<16:38, 24.35s/epoch, loss=1.13, accuracy=0.756, val_loss=2.6, val_accuracy=0.448, lr=0.1] 52%|█████▏    | 43/83 [17:57<16:15, 24.40s/epoch, loss=1.13, accuracy=0.76, val_loss=2.16, val_accuracy=0.455, lr=0.0316] 53%|█████▎    | 44/83 [18:22<15:51, 24.39s/epoch, loss=1.13, accuracy=0.756, val_loss=2.19, val_accuracy=0.505, lr=0.1]   54%|█████▍    | 45/83 [18:46<15:23, 24.31s/epoch, loss=1.13, accuracy=0.758, val_loss=2.02, val_accuracy=0.491, lr=0.1] 55%|█████▌    | 46/83 [19:10<14:58, 24.28s/epoch, loss=1.13, accuracy=0.758, val_loss=1.86, val_accuracy=0.52, lr=0.1]  57%|█████▋    | 47/83 [19:35<14:37, 24.37s/epoch, loss=1.13, accuracy=0.755, val_loss=2.01, val_accuracy=0.496, lr=0.1] 58%|█████▊    | 48/83 [20:00<14:18, 24.53s/epoch, loss=1.13, accuracy=0.758, val_loss=2.62, val_accuracy=0.473, lr=0.0316] 59%|█████▉    | 49/83 [20:24<13:52, 24.47s/epoch, loss=1.12, accuracy=0.76, val_loss=1.87, val_accuracy=0.507, lr=0.1]     60%|██████    | 50/83 [20:48<13:28, 24.51s/epoch, loss=1.13, accuracy=0.758, val_loss=1.87, val_accuracy=0.523, lr=0.1] 61%|██████▏   | 51/83 [21:13<13:08, 24.65s/epoch, loss=1.12, accuracy=0.759, val_loss=2.21, val_accuracy=0.548, lr=0.1] 63%|██████▎   | 52/83 [21:38<12:43, 24.61s/epoch, loss=1.13, accuracy=0.759, val_loss=1.76, val_accuracy=0.528, lr=0.1] 64%|██████▍   | 53/83 [22:03<12:21, 24.72s/epoch, loss=1.12, accuracy=0.757, val_loss=1.68, val_accuracy=0.576, lr=0.0316] 65%|██████▌   | 54/83 [22:28<11:56, 24.70s/epoch, loss=1.12, accuracy=0.761, val_loss=2.86, val_accuracy=0.28, lr=0.1]     66%|██████▋   | 55/83 [22:52<11:30, 24.67s/epoch, loss=1.13, accuracy=0.759, val_loss=2.6, val_accuracy=0.343, lr=0.1] 67%|██████▋   | 56/83 [23:15<10:52, 24.18s/epoch, loss=1.12, accuracy=0.759, val_loss=2.87, val_accuracy=0.467, lr=0.1] 69%|██████▊   | 57/83 [23:39<10:25, 24.07s/epoch, loss=1.12, accuracy=0.758, val_loss=1.82, val_accuracy=0.555, lr=0.1] 70%|██████▉   | 58/83 [24:04<10:09, 24.37s/epoch, loss=1.13, accuracy=0.76, val_loss=2.25, val_accuracy=0.46, lr=0.0316] 71%|███████   | 59/83 [24:29<09:48, 24.50s/epoch, loss=1.12, accuracy=0.76, val_loss=1.72, val_accuracy=0.581, lr=0.1]   72%|███████▏  | 60/83 [24:52<09:16, 24.21s/epoch, loss=1.11, accuracy=0.759, val_loss=1.94, val_accuracy=0.503, lr=0.1] 73%|███████▎  | 61/83 [25:18<08:59, 24.53s/epoch, loss=1.12, accuracy=0.759, val_loss=2.6, val_accuracy=0.422, lr=0.1]  75%|███████▍  | 62/83 [25:43<08:42, 24.87s/epoch, loss=1.12, accuracy=0.757, val_loss=1.62, val_accuracy=0.593, lr=0.1] 76%|███████▌  | 63/83 [26:08<08:14, 24.70s/epoch, loss=1.12, accuracy=0.762, val_loss=3.52, val_accuracy=0.319, lr=0.0316] 77%|███████▋  | 64/83 [26:32<07:48, 24.65s/epoch, loss=1.11, accuracy=0.762, val_loss=1.97, val_accuracy=0.451, lr=0.1]    78%|███████▊  | 65/83 [26:57<07:23, 24.62s/epoch, loss=1.12, accuracy=0.76, val_loss=2.15, val_accuracy=0.479, lr=0.1]  80%|███████▉  | 66/83 [27:21<06:57, 24.58s/epoch, loss=1.12, accuracy=0.759, val_loss=2.12, val_accuracy=0.512, lr=0.1] 81%|████████  | 67/83 [27:46<06:34, 24.63s/epoch, loss=1.11, accuracy=0.761, val_loss=1.7, val_accuracy=0.574, lr=0.1]  82%|████████▏ | 68/83 [28:10<06:07, 24.49s/epoch, loss=1.12, accuracy=0.758, val_loss=2.08, val_accuracy=0.497, lr=0.0316] 83%|████████▎ | 69/83 [28:35<05:43, 24.52s/epoch, loss=1.12, accuracy=0.757, val_loss=1.72, val_accuracy=0.589, lr=0.1]    84%|████████▍ | 70/83 [28:59<05:18, 24.52s/epoch, loss=1.11, accuracy=0.76, val_loss=1.87, val_accuracy=0.584, lr=0.1]  86%|████████▌ | 71/83 [29:24<04:53, 24.47s/epoch, loss=1.12, accuracy=0.759, val_loss=2.12, val_accuracy=0.451, lr=0.1] 87%|████████▋ | 72/83 [29:48<04:28, 24.38s/epoch, loss=1.11, accuracy=0.761, val_loss=2.95, val_accuracy=0.309, lr=0.1] 88%|████████▊ | 73/83 [30:13<04:04, 24.49s/epoch, loss=1.13, accuracy=0.757, val_loss=2.18, val_accuracy=0.449, lr=0.0316] 89%|████████▉ | 74/83 [30:37<03:38, 24.32s/epoch, loss=1.12, accuracy=0.758, val_loss=3.49, val_accuracy=0.376, lr=0.1]    90%|█████████ | 75/83 [31:01<03:15, 24.45s/epoch, loss=1.11, accuracy=0.762, val_loss=2.45, val_accuracy=0.49, lr=0.1]  92%|█████████▏| 76/83 [31:26<02:51, 24.43s/epoch, loss=1.11, accuracy=0.759, val_loss=3.21, val_accuracy=0.375, lr=0.1] 93%|█████████▎| 77/83 [31:50<02:26, 24.44s/epoch, loss=1.11, accuracy=0.759, val_loss=2.11, val_accuracy=0.516, lr=0.1] 94%|█████████▍| 78/83 [32:15<02:02, 24.44s/epoch, loss=1.11, accuracy=0.759, val_loss=2.93, val_accuracy=0.379, lr=0.0316] 95%|█████████▌| 79/83 [32:39<01:37, 24.47s/epoch, loss=1.11, accuracy=0.76, val_loss=2.04, val_accuracy=0.5, lr=0.1]       96%|█████████▋| 80/83 [33:03<01:12, 24.31s/epoch, loss=1.12, accuracy=0.759, val_loss=4.42, val_accuracy=0.248, lr=0.1] 98%|█████████▊| 81/83 [33:27<00:48, 24.09s/epoch, loss=1.11, accuracy=0.76, val_loss=1.86, val_accuracy=0.528, lr=0.1]  99%|█████████▉| 82/83 [33:51<00:24, 24.09s/epoch, loss=0.904, accuracy=0.819, val_loss=0.984, val_accuracy=0.771, lr=0.01]100%|██████████| 83/83 [34:15<00:00, 24.13s/epoch, loss=0.723, accuracy=0.853, val_loss=0.838, val_accuracy=0.8, lr=0.01]  100%|██████████| 83/83 [34:15<00:00, 24.76s/epoch, loss=0.723, accuracy=0.853, val_loss=0.838, val_accuracy=0.8, lr=0.01]
Using real-time data augmentation.
Test loss: 0.8379884958267212
Test accuracy: 0.8004999756813049


* * * Run SGD for ID = 18_5. * * *


2024-02-15 16:20:03.291709: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 16:20:06.122032: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 16:20:06.123367: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-15 16:20:06.160512: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 16:20:06.160543: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 16:20:06.163443: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 16:20:06.163489: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 16:20:06.165617: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 16:20:06.166297: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 16:20:06.168587: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 16:20:06.170037: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 16:20:06.174531: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 16:20:06.175007: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 16:20:06.175098: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 16:20:07.456846: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-15 16:20:07.458330: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 16:20:07.458776: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 16:20:07.458809: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 16:20:07.458843: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 16:20:07.458880: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 16:20:07.458897: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 16:20:07.458913: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 16:20:07.458930: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 16:20:07.458953: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 16:20:07.458970: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 16:20:07.459409: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 16:20:07.459444: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 16:20:08.140319: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-15 16:20:08.140371: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-15 16:20:08.140380: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-15 16:20:08.141296: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:03:00.0, compute capability: 6.1)
{'id': 185, 'batch_size': 128, 'epochs': 83, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/83 [00:00<?, ?epoch/s]2024-02-15 16:20:08.937425: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-15 16:20:08.949698: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2200060000 Hz
2024-02-15 16:20:11.012188: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 16:20:11.266742: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 16:20:11.998725: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-15 16:20:12.036651: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/83 [00:54<1:14:12, 54.30s/epoch, loss=3.36, accuracy=0.289, val_loss=2.84, val_accuracy=0.161, lr=0.1]  2%|▏         | 2/83 [01:17<48:51, 36.19s/epoch, loss=1.67, accuracy=0.468, val_loss=2, val_accuracy=0.376, lr=0.1]       4%|▎         | 3/83 [01:42<41:20, 31.01s/epoch, loss=1.41, accuracy=0.602, val_loss=2.68, val_accuracy=0.361, lr=0.1]  5%|▍         | 4/83 [02:07<37:23, 28.39s/epoch, loss=1.31, accuracy=0.666, val_loss=1.95, val_accuracy=0.46, lr=0.1]   6%|▌         | 5/83 [02:32<35:19, 27.17s/epoch, loss=1.28, accuracy=0.693, val_loss=1.97, val_accuracy=0.482, lr=0.1]  7%|▋         | 6/83 [02:56<33:51, 26.39s/epoch, loss=1.25, accuracy=0.704, val_loss=1.97, val_accuracy=0.497, lr=0.1]  8%|▊         | 7/83 [03:21<32:40, 25.80s/epoch, loss=1.23, accuracy=0.715, val_loss=2.01, val_accuracy=0.526, lr=0.1] 10%|▉         | 8/83 [03:46<31:58, 25.57s/epoch, loss=1.23, accuracy=0.722, val_loss=1.76, val_accuracy=0.56, lr=0.1]  11%|█         | 9/83 [04:11<31:09, 25.26s/epoch, loss=1.22, accuracy=0.724, val_loss=2.78, val_accuracy=0.42, lr=0.1] 12%|█▏        | 10/83 [04:35<30:18, 24.91s/epoch, loss=1.2, accuracy=0.727, val_loss=3.83, val_accuracy=0.338, lr=0.1] 13%|█▎        | 11/83 [04:58<29:18, 24.42s/epoch, loss=1.21, accuracy=0.732, val_loss=1.83, val_accuracy=0.489, lr=0.1] 14%|█▍        | 12/83 [05:23<29:05, 24.59s/epoch, loss=1.2, accuracy=0.735, val_loss=1.64, val_accuracy=0.598, lr=0.1]  16%|█▌        | 13/83 [05:48<28:41, 24.60s/epoch, loss=1.2, accuracy=0.734, val_loss=3.93, val_accuracy=0.284, lr=0.1] 17%|█▋        | 14/83 [06:13<28:27, 24.75s/epoch, loss=1.19, accuracy=0.735, val_loss=1.51, val_accuracy=0.619, lr=0.1] 18%|█▊        | 15/83 [06:38<28:12, 24.89s/epoch, loss=1.19, accuracy=0.739, val_loss=2.34, val_accuracy=0.396, lr=0.1] 19%|█▉        | 16/83 [07:03<27:48, 24.90s/epoch, loss=1.19, accuracy=0.739, val_loss=2.8, val_accuracy=0.352, lr=0.1]  20%|██        | 17/83 [07:28<27:21, 24.87s/epoch, loss=1.17, accuracy=0.741, val_loss=3.72, val_accuracy=0.322, lr=0.1] 22%|██▏       | 18/83 [07:52<26:43, 24.67s/epoch, loss=1.18, accuracy=0.74, val_loss=2.3, val_accuracy=0.491, lr=0.1]   23%|██▎       | 19/83 [08:17<26:21, 24.71s/epoch, loss=1.18, accuracy=0.743, val_loss=2.76, val_accuracy=0.409, lr=0.0316] 24%|██▍       | 20/83 [08:41<25:49, 24.59s/epoch, loss=1.17, accuracy=0.743, val_loss=2.52, val_accuracy=0.235, lr=0.1]    25%|██▌       | 21/83 [09:06<25:30, 24.68s/epoch, loss=1.18, accuracy=0.743, val_loss=2.83, val_accuracy=0.311, lr=0.1] 27%|██▋       | 22/83 [09:30<24:51, 24.45s/epoch, loss=1.18, accuracy=0.743, val_loss=2.75, val_accuracy=0.417, lr=0.1] 28%|██▊       | 23/83 [09:54<24:24, 24.41s/epoch, loss=1.17, accuracy=0.743, val_loss=2.02, val_accuracy=0.506, lr=0.1] 29%|██▉       | 24/83 [10:19<24:09, 24.57s/epoch, loss=1.17, accuracy=0.746, val_loss=1.77, val_accuracy=0.544, lr=0.0316] 30%|███       | 25/83 [10:44<23:42, 24.53s/epoch, loss=1.17, accuracy=0.745, val_loss=1.87, val_accuracy=0.539, lr=0.1]    31%|███▏      | 26/83 [11:08<23:17, 24.52s/epoch, loss=1.16, accuracy=0.746, val_loss=1.78, val_accuracy=0.593, lr=0.1] 33%|███▎      | 27/83 [11:33<22:56, 24.58s/epoch, loss=1.16, accuracy=0.746, val_loss=1.73, val_accuracy=0.579, lr=0.1] 34%|███▎      | 28/83 [11:58<22:39, 24.73s/epoch, loss=1.16, accuracy=0.745, val_loss=2.43, val_accuracy=0.389, lr=0.1] 35%|███▍      | 29/83 [12:23<22:23, 24.88s/epoch, loss=1.16, accuracy=0.748, val_loss=2.53, val_accuracy=0.441, lr=0.0316] 36%|███▌      | 30/83 [12:48<21:57, 24.86s/epoch, loss=1.15, accuracy=0.75, val_loss=2.05, val_accuracy=0.437, lr=0.1]     37%|███▋      | 31/83 [13:12<21:27, 24.77s/epoch, loss=1.16, accuracy=0.751, val_loss=2.37, val_accuracy=0.486, lr=0.1] 39%|███▊      | 32/83 [13:37<20:54, 24.60s/epoch, loss=1.16, accuracy=0.749, val_loss=1.88, val_accuracy=0.557, lr=0.1] 40%|███▉      | 33/83 [14:01<20:33, 24.67s/epoch, loss=1.16, accuracy=0.749, val_loss=3.69, val_accuracy=0.335, lr=0.1] 41%|████      | 34/83 [14:26<20:06, 24.63s/epoch, loss=1.15, accuracy=0.754, val_loss=2.23, val_accuracy=0.526, lr=0.0316] 42%|████▏     | 35/83 [14:50<19:31, 24.42s/epoch, loss=1.15, accuracy=0.752, val_loss=1.92, val_accuracy=0.525, lr=0.1]    43%|████▎     | 36/83 [15:14<19:06, 24.38s/epoch, loss=1.16, accuracy=0.75, val_loss=1.65, val_accuracy=0.576, lr=0.1]  45%|████▍     | 37/83 [15:39<18:46, 24.48s/epoch, loss=1.15, accuracy=0.751, val_loss=1.66, val_accuracy=0.578, lr=0.1] 46%|████▌     | 38/83 [16:04<18:27, 24.61s/epoch, loss=1.15, accuracy=0.753, val_loss=1.68, val_accuracy=0.58, lr=0.1]  47%|████▋     | 39/83 [16:29<18:05, 24.66s/epoch, loss=1.15, accuracy=0.753, val_loss=2.29, val_accuracy=0.468, lr=0.0316] 48%|████▊     | 40/83 [16:53<17:39, 24.64s/epoch, loss=1.15, accuracy=0.752, val_loss=1.95, val_accuracy=0.515, lr=0.1]    49%|████▉     | 41/83 [17:18<17:18, 24.73s/epoch, loss=1.15, accuracy=0.752, val_loss=2.21, val_accuracy=0.403, lr=0.1] 51%|█████     | 42/83 [17:43<16:57, 24.80s/epoch, loss=1.16, accuracy=0.748, val_loss=1.87, val_accuracy=0.57, lr=0.1]  52%|█████▏    | 43/83 [18:08<16:29, 24.74s/epoch, loss=1.15, accuracy=0.752, val_loss=1.97, val_accuracy=0.536, lr=0.1] 53%|█████▎    | 44/83 [18:33<16:09, 24.85s/epoch, loss=1.14, accuracy=0.754, val_loss=2.18, val_accuracy=0.462, lr=0.0316] 54%|█████▍    | 45/83 [18:58<15:47, 24.94s/epoch, loss=1.15, accuracy=0.75, val_loss=1.73, val_accuracy=0.564, lr=0.1]     55%|█████▌    | 46/83 [19:23<15:23, 24.95s/epoch, loss=1.15, accuracy=0.753, val_loss=1.99, val_accuracy=0.525, lr=0.1] 57%|█████▋    | 47/83 [19:48<14:55, 24.88s/epoch, loss=1.14, accuracy=0.755, val_loss=1.52, val_accuracy=0.642, lr=0.1] 58%|█████▊    | 48/83 [20:12<14:22, 24.64s/epoch, loss=1.14, accuracy=0.754, val_loss=2.63, val_accuracy=0.464, lr=0.1] 59%|█████▉    | 49/83 [20:36<13:58, 24.66s/epoch, loss=1.15, accuracy=0.753, val_loss=1.61, val_accuracy=0.601, lr=0.0316] 60%|██████    | 50/83 [21:00<13:26, 24.44s/epoch, loss=1.14, accuracy=0.755, val_loss=3.53, val_accuracy=0.357, lr=0.1]    61%|██████▏   | 51/83 [21:25<13:02, 24.45s/epoch, loss=1.15, accuracy=0.753, val_loss=3.58, val_accuracy=0.397, lr=0.1] 63%|██████▎   | 52/83 [21:49<12:34, 24.32s/epoch, loss=1.14, accuracy=0.757, val_loss=2.87, val_accuracy=0.366, lr=0.1] 64%|██████▍   | 53/83 [22:13<12:07, 24.26s/epoch, loss=1.14, accuracy=0.753, val_loss=2.02, val_accuracy=0.456, lr=0.1] 65%|██████▌   | 54/83 [22:38<11:51, 24.52s/epoch, loss=1.14, accuracy=0.754, val_loss=1.68, val_accuracy=0.55, lr=0.0316] 66%|██████▋   | 55/83 [23:03<11:28, 24.60s/epoch, loss=1.14, accuracy=0.754, val_loss=2.91, val_accuracy=0.368, lr=0.1]   67%|██████▋   | 56/83 [23:28<11:05, 24.66s/epoch, loss=1.13, accuracy=0.757, val_loss=1.95, val_accuracy=0.515, lr=0.1] 69%|██████▊   | 57/83 [23:53<10:44, 24.81s/epoch, loss=1.14, accuracy=0.755, val_loss=1.42, val_accuracy=0.659, lr=0.1] 70%|██████▉   | 58/83 [24:18<10:19, 24.78s/epoch, loss=1.14, accuracy=0.756, val_loss=1.54, val_accuracy=0.616, lr=0.1] 71%|███████   | 59/83 [24:42<09:55, 24.80s/epoch, loss=1.14, accuracy=0.756, val_loss=1.86, val_accuracy=0.53, lr=0.1]  72%|███████▏  | 60/83 [25:07<09:29, 24.77s/epoch, loss=1.13, accuracy=0.755, val_loss=1.35, val_accuracy=0.676, lr=0.1] 73%|███████▎  | 61/83 [25:31<09:01, 24.63s/epoch, loss=1.13, accuracy=0.759, val_loss=1.81, val_accuracy=0.555, lr=0.1] 75%|███████▍  | 62/83 [25:55<08:29, 24.29s/epoch, loss=1.14, accuracy=0.757, val_loss=1.93, val_accuracy=0.485, lr=0.1] 76%|███████▌  | 63/83 [26:20<08:08, 24.42s/epoch, loss=1.13, accuracy=0.758, val_loss=4.41, val_accuracy=0.227, lr=0.1] 77%|███████▋  | 64/83 [26:44<07:44, 24.47s/epoch, loss=1.13, accuracy=0.758, val_loss=2.85, val_accuracy=0.382, lr=0.1] 78%|███████▊  | 65/83 [27:09<07:21, 24.53s/epoch, loss=1.14, accuracy=0.758, val_loss=1.89, val_accuracy=0.566, lr=0.0316] 80%|███████▉  | 66/83 [27:33<06:56, 24.48s/epoch, loss=1.14, accuracy=0.755, val_loss=2.46, val_accuracy=0.481, lr=0.1]    81%|████████  | 67/83 [27:57<06:27, 24.23s/epoch, loss=1.13, accuracy=0.758, val_loss=1.71, val_accuracy=0.579, lr=0.1] 82%|████████▏ | 68/83 [28:22<06:06, 24.42s/epoch, loss=1.13, accuracy=0.76, val_loss=1.76, val_accuracy=0.541, lr=0.1]  83%|████████▎ | 69/83 [28:46<05:41, 24.41s/epoch, loss=1.13, accuracy=0.757, val_loss=3.29, val_accuracy=0.315, lr=0.1] 84%|████████▍ | 70/83 [29:10<05:15, 24.25s/epoch, loss=1.13, accuracy=0.756, val_loss=2.35, val_accuracy=0.483, lr=0.0316] 86%|████████▌ | 71/83 [29:35<04:53, 24.43s/epoch, loss=1.13, accuracy=0.757, val_loss=1.71, val_accuracy=0.54, lr=0.1]     87%|████████▋ | 72/83 [29:59<04:27, 24.30s/epoch, loss=1.13, accuracy=0.755, val_loss=1.6, val_accuracy=0.581, lr=0.1] 88%|████████▊ | 73/83 [30:24<04:04, 24.50s/epoch, loss=1.13, accuracy=0.756, val_loss=2.15, val_accuracy=0.476, lr=0.1] 89%|████████▉ | 74/83 [30:49<03:40, 24.54s/epoch, loss=1.13, accuracy=0.757, val_loss=2.68, val_accuracy=0.464, lr=0.1] 90%|█████████ | 75/83 [31:13<03:16, 24.58s/epoch, loss=1.14, accuracy=0.754, val_loss=1.86, val_accuracy=0.509, lr=0.0316] 92%|█████████▏| 76/83 [31:38<02:51, 24.53s/epoch, loss=1.13, accuracy=0.755, val_loss=3.36, val_accuracy=0.373, lr=0.1]    93%|█████████▎| 77/83 [32:02<02:27, 24.61s/epoch, loss=1.13, accuracy=0.755, val_loss=1.99, val_accuracy=0.478, lr=0.1] 94%|█████████▍| 78/83 [32:27<02:03, 24.65s/epoch, loss=1.13, accuracy=0.756, val_loss=1.8, val_accuracy=0.584, lr=0.1]  95%|█████████▌| 79/83 [32:52<01:38, 24.66s/epoch, loss=1.13, accuracy=0.757, val_loss=2.48, val_accuracy=0.383, lr=0.1] 96%|█████████▋| 80/83 [33:17<01:14, 24.69s/epoch, loss=1.13, accuracy=0.757, val_loss=2.48, val_accuracy=0.446, lr=0.0316] 98%|█████████▊| 81/83 [33:41<00:49, 24.52s/epoch, loss=1.13, accuracy=0.755, val_loss=2.85, val_accuracy=0.363, lr=0.1]    99%|█████████▉| 82/83 [34:06<00:24, 24.66s/epoch, loss=0.921, accuracy=0.814, val_loss=0.941, val_accuracy=0.786, lr=0.01]100%|██████████| 83/83 [34:30<00:00, 24.41s/epoch, loss=0.735, accuracy=0.848, val_loss=0.778, val_accuracy=0.821, lr=0.01]100%|██████████| 83/83 [34:30<00:00, 24.94s/epoch, loss=0.735, accuracy=0.848, val_loss=0.778, val_accuracy=0.821, lr=0.01]
Using real-time data augmentation.
Test loss: 0.7775033116340637
Test accuracy: 0.820900022983551


* * * Run SGD for ID = 18_6. * * *


2024-02-15 16:54:41.404338: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 16:54:44.279753: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 16:54:44.281166: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-15 16:54:44.317935: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 16:54:44.317967: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 16:54:44.320689: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 16:54:44.320731: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 16:54:44.322849: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 16:54:44.323542: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 16:54:44.325903: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 16:54:44.327432: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 16:54:44.331843: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 16:54:44.332318: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 16:54:44.332410: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 16:54:45.612277: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-15 16:54:45.612850: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 16:54:45.613323: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 16:54:45.613354: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 16:54:45.613388: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 16:54:45.613406: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 16:54:45.613423: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 16:54:45.613439: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 16:54:45.613456: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 16:54:45.613482: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 16:54:45.613499: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 16:54:45.613984: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 16:54:45.614019: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 16:54:46.298667: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-15 16:54:46.298721: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-15 16:54:46.298739: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-15 16:54:46.300098: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:03:00.0, compute capability: 6.1)
{'id': 186, 'batch_size': 128, 'epochs': 83, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/83 [00:00<?, ?epoch/s]2024-02-15 16:54:47.117647: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-15 16:54:47.118193: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2200060000 Hz
2024-02-15 16:54:49.184393: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 16:54:49.462197: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 16:54:50.232970: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-15 16:54:50.268123: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/83 [00:56<1:16:35, 56.04s/epoch, loss=3.16, accuracy=0.31, val_loss=3.21, val_accuracy=0.196, lr=0.1]  2%|▏         | 2/83 [01:20<50:54, 37.71s/epoch, loss=1.58, accuracy=0.528, val_loss=5.31, val_accuracy=0.198, lr=0.1]   4%|▎         | 3/83 [01:45<42:01, 31.52s/epoch, loss=1.37, accuracy=0.634, val_loss=2.04, val_accuracy=0.441, lr=0.1]  5%|▍         | 4/83 [02:09<37:58, 28.84s/epoch, loss=1.29, accuracy=0.678, val_loss=2, val_accuracy=0.448, lr=0.1]     6%|▌         | 5/83 [02:34<35:22, 27.21s/epoch, loss=1.26, accuracy=0.697, val_loss=2.39, val_accuracy=0.447, lr=0.1]  7%|▋         | 6/83 [02:59<33:55, 26.44s/epoch, loss=1.25, accuracy=0.706, val_loss=1.37, val_accuracy=0.665, lr=0.1]  8%|▊         | 7/83 [03:23<32:33, 25.71s/epoch, loss=1.23, accuracy=0.713, val_loss=2.57, val_accuracy=0.396, lr=0.1] 10%|▉         | 8/83 [03:47<31:39, 25.32s/epoch, loss=1.22, accuracy=0.722, val_loss=2.28, val_accuracy=0.475, lr=0.1] 11%|█         | 9/83 [04:11<30:35, 24.80s/epoch, loss=1.21, accuracy=0.724, val_loss=1.86, val_accuracy=0.508, lr=0.1] 12%|█▏        | 10/83 [04:36<30:05, 24.74s/epoch, loss=1.2, accuracy=0.727, val_loss=3.42, val_accuracy=0.277, lr=0.1] 13%|█▎        | 11/83 [05:00<29:38, 24.70s/epoch, loss=1.19, accuracy=0.731, val_loss=1.95, val_accuracy=0.527, lr=0.0316] 14%|█▍        | 12/83 [05:25<29:16, 24.73s/epoch, loss=1.19, accuracy=0.735, val_loss=2.48, val_accuracy=0.409, lr=0.1]    16%|█▌        | 13/83 [05:49<28:46, 24.66s/epoch, loss=1.19, accuracy=0.735, val_loss=1.92, val_accuracy=0.555, lr=0.1] 17%|█▋        | 14/83 [06:14<28:21, 24.66s/epoch, loss=1.18, accuracy=0.738, val_loss=1.77, val_accuracy=0.55, lr=0.1]  18%|█▊        | 15/83 [06:37<27:30, 24.27s/epoch, loss=1.18, accuracy=0.74, val_loss=1.92, val_accuracy=0.545, lr=0.1] 19%|█▉        | 16/83 [07:02<27:10, 24.34s/epoch, loss=1.17, accuracy=0.739, val_loss=4.07, val_accuracy=0.27, lr=0.0316] 20%|██        | 17/83 [07:27<26:54, 24.46s/epoch, loss=1.17, accuracy=0.739, val_loss=1.68, val_accuracy=0.577, lr=0.1]   22%|██▏       | 18/83 [07:51<26:32, 24.50s/epoch, loss=1.17, accuracy=0.744, val_loss=1.53, val_accuracy=0.62, lr=0.1]  23%|██▎       | 19/83 [08:16<26:08, 24.50s/epoch, loss=1.16, accuracy=0.742, val_loss=2.4, val_accuracy=0.394, lr=0.1] 24%|██▍       | 20/83 [08:41<25:51, 24.62s/epoch, loss=1.16, accuracy=0.745, val_loss=1.7, val_accuracy=0.574, lr=0.1] 25%|██▌       | 21/83 [09:05<25:18, 24.49s/epoch, loss=1.15, accuracy=0.746, val_loss=2.32, val_accuracy=0.358, lr=0.0316] 27%|██▋       | 22/83 [09:30<25:02, 24.64s/epoch, loss=1.16, accuracy=0.745, val_loss=2.29, val_accuracy=0.46, lr=0.1]     28%|██▊       | 23/83 [09:54<24:35, 24.59s/epoch, loss=1.15, accuracy=0.747, val_loss=1.98, val_accuracy=0.531, lr=0.1] 29%|██▉       | 24/83 [10:19<24:11, 24.61s/epoch, loss=1.15, accuracy=0.747, val_loss=1.73, val_accuracy=0.572, lr=0.1] 30%|███       | 25/83 [10:44<23:47, 24.61s/epoch, loss=1.15, accuracy=0.747, val_loss=1.96, val_accuracy=0.571, lr=0.1] 31%|███▏      | 26/83 [11:09<23:28, 24.71s/epoch, loss=1.14, accuracy=0.749, val_loss=1.85, val_accuracy=0.535, lr=0.0316] 33%|███▎      | 27/83 [11:33<23:03, 24.71s/epoch, loss=1.14, accuracy=0.75, val_loss=1.89, val_accuracy=0.55, lr=0.1]      34%|███▎      | 28/83 [11:58<22:39, 24.71s/epoch, loss=1.14, accuracy=0.75, val_loss=2.34, val_accuracy=0.413, lr=0.1] 35%|███▍      | 29/83 [12:23<22:17, 24.77s/epoch, loss=1.14, accuracy=0.75, val_loss=2.14, val_accuracy=0.52, lr=0.1]  36%|███▌      | 30/83 [12:48<21:51, 24.75s/epoch, loss=1.14, accuracy=0.75, val_loss=2.48, val_accuracy=0.485, lr=0.1] 37%|███▋      | 31/83 [13:12<21:23, 24.69s/epoch, loss=1.13, accuracy=0.751, val_loss=1.79, val_accuracy=0.562, lr=0.0316] 39%|███▊      | 32/83 [13:37<20:58, 24.68s/epoch, loss=1.13, accuracy=0.751, val_loss=2.81, val_accuracy=0.377, lr=0.1]    40%|███▉      | 33/83 [14:01<20:29, 24.59s/epoch, loss=1.13, accuracy=0.751, val_loss=5.26, val_accuracy=0.293, lr=0.1] 41%|████      | 34/83 [14:26<20:02, 24.54s/epoch, loss=1.14, accuracy=0.751, val_loss=2.09, val_accuracy=0.484, lr=0.1] 42%|████▏     | 35/83 [14:51<19:43, 24.66s/epoch, loss=1.12, accuracy=0.756, val_loss=2.77, val_accuracy=0.388, lr=0.1] 43%|████▎     | 36/83 [15:15<19:22, 24.73s/epoch, loss=1.13, accuracy=0.754, val_loss=1.62, val_accuracy=0.595, lr=0.0316] 45%|████▍     | 37/83 [15:40<18:57, 24.72s/epoch, loss=1.13, accuracy=0.752, val_loss=3.24, val_accuracy=0.385, lr=0.1]    46%|████▌     | 38/83 [16:05<18:33, 24.75s/epoch, loss=1.13, accuracy=0.755, val_loss=1.54, val_accuracy=0.651, lr=0.1] 47%|████▋     | 39/83 [16:29<18:03, 24.63s/epoch, loss=1.13, accuracy=0.752, val_loss=1.74, val_accuracy=0.539, lr=0.1] 48%|████▊     | 40/83 [16:54<17:35, 24.54s/epoch, loss=1.13, accuracy=0.755, val_loss=1.78, val_accuracy=0.57, lr=0.1]  49%|████▉     | 41/83 [17:18<17:13, 24.62s/epoch, loss=1.13, accuracy=0.754, val_loss=2.2, val_accuracy=0.464, lr=0.0316] 51%|█████     | 42/83 [17:43<16:46, 24.55s/epoch, loss=1.12, accuracy=0.753, val_loss=2.5, val_accuracy=0.4, lr=0.1]      52%|█████▏    | 43/83 [18:06<16:11, 24.28s/epoch, loss=1.13, accuracy=0.753, val_loss=1.7, val_accuracy=0.608, lr=0.1] 53%|█████▎    | 44/83 [18:31<15:49, 24.35s/epoch, loss=1.12, accuracy=0.756, val_loss=2.09, val_accuracy=0.507, lr=0.1] 54%|█████▍    | 45/83 [18:56<15:28, 24.44s/epoch, loss=1.12, accuracy=0.755, val_loss=2.8, val_accuracy=0.379, lr=0.1]  55%|█████▌    | 46/83 [19:21<15:09, 24.59s/epoch, loss=1.12, accuracy=0.756, val_loss=2.7, val_accuracy=0.459, lr=0.0316] 57%|█████▋    | 47/83 [19:45<14:44, 24.57s/epoch, loss=1.12, accuracy=0.753, val_loss=1.53, val_accuracy=0.633, lr=0.1]   58%|█████▊    | 48/83 [20:10<14:22, 24.63s/epoch, loss=1.12, accuracy=0.757, val_loss=2.07, val_accuracy=0.55, lr=0.1]  59%|█████▉    | 49/83 [20:34<13:56, 24.59s/epoch, loss=1.12, accuracy=0.755, val_loss=1.58, val_accuracy=0.587, lr=0.1] 60%|██████    | 50/83 [20:59<13:34, 24.67s/epoch, loss=1.12, accuracy=0.754, val_loss=1.97, val_accuracy=0.495, lr=0.1] 61%|██████▏   | 51/83 [21:24<13:08, 24.63s/epoch, loss=1.12, accuracy=0.756, val_loss=2, val_accuracy=0.513, lr=0.0316] 63%|██████▎   | 52/83 [21:48<12:43, 24.62s/epoch, loss=1.11, accuracy=0.76, val_loss=2.77, val_accuracy=0.413, lr=0.1]  64%|██████▍   | 53/83 [22:13<12:20, 24.69s/epoch, loss=1.11, accuracy=0.756, val_loss=2.29, val_accuracy=0.372, lr=0.1] 65%|██████▌   | 54/83 [22:38<11:55, 24.67s/epoch, loss=1.12, accuracy=0.757, val_loss=1.66, val_accuracy=0.586, lr=0.1] 66%|██████▋   | 55/83 [23:03<11:31, 24.71s/epoch, loss=1.12, accuracy=0.757, val_loss=1.99, val_accuracy=0.453, lr=0.1] 67%|██████▋   | 56/83 [23:27<11:05, 24.66s/epoch, loss=1.12, accuracy=0.755, val_loss=2.39, val_accuracy=0.414, lr=0.0316] 69%|██████▊   | 57/83 [23:52<10:42, 24.72s/epoch, loss=1.11, accuracy=0.758, val_loss=2.06, val_accuracy=0.514, lr=0.1]    70%|██████▉   | 58/83 [24:17<10:17, 24.70s/epoch, loss=1.12, accuracy=0.755, val_loss=1.89, val_accuracy=0.529, lr=0.1] 71%|███████   | 59/83 [24:41<09:49, 24.55s/epoch, loss=1.11, accuracy=0.754, val_loss=2.13, val_accuracy=0.461, lr=0.1] 72%|███████▏  | 60/83 [25:05<09:24, 24.54s/epoch, loss=1.11, accuracy=0.758, val_loss=3.46, val_accuracy=0.293, lr=0.1] 73%|███████▎  | 61/83 [25:30<09:01, 24.59s/epoch, loss=1.1, accuracy=0.758, val_loss=2.14, val_accuracy=0.498, lr=0.0316] 75%|███████▍  | 62/83 [25:55<08:35, 24.53s/epoch, loss=1.11, accuracy=0.754, val_loss=2.01, val_accuracy=0.529, lr=0.1]   76%|███████▌  | 63/83 [26:19<08:09, 24.46s/epoch, loss=1.11, accuracy=0.757, val_loss=1.84, val_accuracy=0.583, lr=0.1] 77%|███████▋  | 64/83 [26:43<07:44, 24.43s/epoch, loss=1.12, accuracy=0.752, val_loss=1.35, val_accuracy=0.669, lr=0.1] 78%|███████▊  | 65/83 [27:08<07:20, 24.46s/epoch, loss=1.11, accuracy=0.756, val_loss=3.02, val_accuracy=0.343, lr=0.1] 80%|███████▉  | 66/83 [27:31<06:51, 24.23s/epoch, loss=1.1, accuracy=0.758, val_loss=2.04, val_accuracy=0.446, lr=0.1]  81%|████████  | 67/83 [27:56<06:28, 24.31s/epoch, loss=1.11, accuracy=0.759, val_loss=2.71, val_accuracy=0.345, lr=0.1] 82%|████████▏ | 68/83 [28:21<06:06, 24.41s/epoch, loss=1.11, accuracy=0.756, val_loss=1.79, val_accuracy=0.565, lr=0.1] 83%|████████▎ | 69/83 [28:45<05:43, 24.52s/epoch, loss=1.11, accuracy=0.756, val_loss=1.89, val_accuracy=0.503, lr=0.0316] 84%|████████▍ | 70/83 [29:10<05:18, 24.48s/epoch, loss=1.11, accuracy=0.757, val_loss=1.91, val_accuracy=0.498, lr=0.1]    86%|████████▌ | 71/83 [29:34<04:51, 24.29s/epoch, loss=1.11, accuracy=0.756, val_loss=1.64, val_accuracy=0.614, lr=0.1] 87%|████████▋ | 72/83 [29:58<04:26, 24.23s/epoch, loss=1.11, accuracy=0.755, val_loss=1.6, val_accuracy=0.59, lr=0.1]   88%|████████▊ | 73/83 [30:22<04:03, 24.36s/epoch, loss=1.11, accuracy=0.758, val_loss=2.18, val_accuracy=0.452, lr=0.1] 89%|████████▉ | 74/83 [30:47<03:39, 24.36s/epoch, loss=1.1, accuracy=0.757, val_loss=3.3, val_accuracy=0.237, lr=0.0316] 90%|█████████ | 75/83 [31:11<03:14, 24.32s/epoch, loss=1.11, accuracy=0.755, val_loss=2.83, val_accuracy=0.461, lr=0.1]  92%|█████████▏| 76/83 [31:35<02:50, 24.33s/epoch, loss=1.1, accuracy=0.756, val_loss=1.83, val_accuracy=0.531, lr=0.1]  93%|█████████▎| 77/83 [32:00<02:27, 24.51s/epoch, loss=1.11, accuracy=0.756, val_loss=2.35, val_accuracy=0.458, lr=0.1] 94%|█████████▍| 78/83 [32:25<02:03, 24.65s/epoch, loss=1.11, accuracy=0.756, val_loss=2.26, val_accuracy=0.498, lr=0.1] 95%|█████████▌| 79/83 [32:50<01:38, 24.59s/epoch, loss=1.11, accuracy=0.755, val_loss=1.95, val_accuracy=0.49, lr=0.0316] 96%|█████████▋| 80/83 [33:14<01:13, 24.46s/epoch, loss=1.11, accuracy=0.754, val_loss=1.64, val_accuracy=0.594, lr=0.1]   98%|█████████▊| 81/83 [33:38<00:48, 24.34s/epoch, loss=1.11, accuracy=0.758, val_loss=3.68, val_accuracy=0.225, lr=0.1] 99%|█████████▉| 82/83 [34:03<00:24, 24.48s/epoch, loss=0.896, accuracy=0.814, val_loss=0.941, val_accuracy=0.781, lr=0.01]100%|██████████| 83/83 [34:27<00:00, 24.46s/epoch, loss=0.721, accuracy=0.848, val_loss=0.777, val_accuracy=0.818, lr=0.01]100%|██████████| 83/83 [34:27<00:00, 24.91s/epoch, loss=0.721, accuracy=0.848, val_loss=0.777, val_accuracy=0.818, lr=0.01]
Using real-time data augmentation.
Test loss: 0.7769820094108582
Test accuracy: 0.817799985408783


* * * Run SGD for ID = 18_7. * * *


2024-02-15 17:29:17.155532: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 17:29:20.188863: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 17:29:20.190013: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-15 17:29:20.228824: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 17:29:20.228858: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 17:29:20.231745: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 17:29:20.231787: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 17:29:20.233990: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 17:29:20.234763: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 17:29:20.237228: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 17:29:20.238794: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 17:29:20.243499: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 17:29:20.244007: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 17:29:20.244086: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 17:29:21.534244: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-15 17:29:21.535366: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 17:29:21.535833: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 17:29:21.535880: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 17:29:21.535912: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 17:29:21.535932: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 17:29:21.535958: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 17:29:21.535977: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 17:29:21.535994: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 17:29:21.536010: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 17:29:21.536027: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 17:29:21.536450: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 17:29:21.536485: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 17:29:22.240721: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-15 17:29:22.240782: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-15 17:29:22.240793: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-15 17:29:22.242065: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:03:00.0, compute capability: 6.1)
{'id': 187, 'batch_size': 128, 'epochs': 83, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/83 [00:00<?, ?epoch/s]2024-02-15 17:29:23.039659: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-15 17:29:23.040221: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2200060000 Hz
2024-02-15 17:29:25.103143: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 17:29:25.387314: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 17:29:26.117157: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-15 17:29:26.158565: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/83 [01:12<1:38:44, 72.25s/epoch, loss=3.08, accuracy=0.336, val_loss=2.24, val_accuracy=0.299, lr=0.1]  2%|▏         | 2/83 [01:36<59:38, 44.17s/epoch, loss=1.54, accuracy=0.556, val_loss=2.14, val_accuracy=0.414, lr=0.1]    4%|▎         | 3/83 [02:01<46:57, 35.22s/epoch, loss=1.36, accuracy=0.64, val_loss=2.05, val_accuracy=0.444, lr=0.1]   5%|▍         | 4/83 [02:25<40:47, 30.99s/epoch, loss=1.28, accuracy=0.684, val_loss=1.9, val_accuracy=0.496, lr=0.1]  6%|▌         | 5/83 [02:50<37:24, 28.78s/epoch, loss=1.26, accuracy=0.7, val_loss=2.68, val_accuracy=0.366, lr=0.1]   7%|▋         | 6/83 [03:13<34:30, 26.88s/epoch, loss=1.24, accuracy=0.712, val_loss=2.45, val_accuracy=0.375, lr=0.1]  8%|▊         | 7/83 [03:38<33:06, 26.14s/epoch, loss=1.23, accuracy=0.719, val_loss=2.65, val_accuracy=0.398, lr=0.1] 10%|▉         | 8/83 [04:03<32:14, 25.79s/epoch, loss=1.22, accuracy=0.724, val_loss=1.63, val_accuracy=0.601, lr=0.1] 11%|█         | 9/83 [04:28<31:32, 25.57s/epoch, loss=1.22, accuracy=0.727, val_loss=2.02, val_accuracy=0.523, lr=0.1] 12%|█▏        | 10/83 [04:53<30:47, 25.30s/epoch, loss=1.21, accuracy=0.73, val_loss=2.31, val_accuracy=0.493, lr=0.1] 13%|█▎        | 11/83 [05:18<30:12, 25.17s/epoch, loss=1.2, accuracy=0.733, val_loss=2.52, val_accuracy=0.426, lr=0.1] 14%|█▍        | 12/83 [05:41<29:14, 24.72s/epoch, loss=1.2, accuracy=0.735, val_loss=1.88, val_accuracy=0.488, lr=0.1] 16%|█▌        | 13/83 [06:06<28:52, 24.75s/epoch, loss=1.19, accuracy=0.739, val_loss=2.18, val_accuracy=0.484, lr=0.0316] 17%|█▋        | 14/83 [06:29<27:56, 24.29s/epoch, loss=1.19, accuracy=0.739, val_loss=1.7, val_accuracy=0.549, lr=0.1]     18%|█▊        | 15/83 [06:54<27:30, 24.28s/epoch, loss=1.18, accuracy=0.74, val_loss=1.47, val_accuracy=0.656, lr=0.1] 19%|█▉        | 16/83 [07:18<27:13, 24.38s/epoch, loss=1.18, accuracy=0.743, val_loss=2.16, val_accuracy=0.421, lr=0.1] 20%|██        | 17/83 [07:43<26:57, 24.50s/epoch, loss=1.17, accuracy=0.746, val_loss=1.87, val_accuracy=0.497, lr=0.1] 22%|██▏       | 18/83 [08:07<26:30, 24.46s/epoch, loss=1.17, accuracy=0.746, val_loss=3.24, val_accuracy=0.344, lr=0.1] 23%|██▎       | 19/83 [08:33<26:18, 24.67s/epoch, loss=1.17, accuracy=0.745, val_loss=2.03, val_accuracy=0.474, lr=0.1] 24%|██▍       | 20/83 [08:57<25:52, 24.64s/epoch, loss=1.16, accuracy=0.748, val_loss=1.4, val_accuracy=0.67, lr=0.1]   25%|██▌       | 21/83 [09:22<25:25, 24.61s/epoch, loss=1.17, accuracy=0.745, val_loss=1.99, val_accuracy=0.451, lr=0.1] 27%|██▋       | 22/83 [09:46<25:02, 24.63s/epoch, loss=1.16, accuracy=0.747, val_loss=1.82, val_accuracy=0.547, lr=0.1] 28%|██▊       | 23/83 [10:11<24:42, 24.71s/epoch, loss=1.16, accuracy=0.749, val_loss=1.96, val_accuracy=0.518, lr=0.1] 29%|██▉       | 24/83 [10:36<24:25, 24.85s/epoch, loss=1.16, accuracy=0.748, val_loss=2.01, val_accuracy=0.495, lr=0.1] 30%|███       | 25/83 [11:02<24:04, 24.90s/epoch, loss=1.16, accuracy=0.748, val_loss=1.96, val_accuracy=0.481, lr=0.0316] 31%|███▏      | 26/83 [11:26<23:34, 24.82s/epoch, loss=1.17, accuracy=0.748, val_loss=1.81, val_accuracy=0.54, lr=0.1]     33%|███▎      | 27/83 [11:49<22:41, 24.31s/epoch, loss=1.16, accuracy=0.75, val_loss=1.76, val_accuracy=0.568, lr=0.1] 34%|███▎      | 28/83 [12:14<22:25, 24.46s/epoch, loss=1.16, accuracy=0.751, val_loss=1.85, val_accuracy=0.518, lr=0.1] 35%|███▍      | 29/83 [12:39<22:07, 24.58s/epoch, loss=1.16, accuracy=0.752, val_loss=3.08, val_accuracy=0.415, lr=0.1] 36%|███▌      | 30/83 [13:04<21:47, 24.67s/epoch, loss=1.16, accuracy=0.748, val_loss=1.96, val_accuracy=0.52, lr=0.0316] 37%|███▋      | 31/83 [13:29<21:23, 24.69s/epoch, loss=1.16, accuracy=0.749, val_loss=1.51, val_accuracy=0.627, lr=0.1]   39%|███▊      | 32/83 [13:53<21:01, 24.74s/epoch, loss=1.15, accuracy=0.752, val_loss=3.04, val_accuracy=0.335, lr=0.1] 40%|███▉      | 33/83 [14:18<20:33, 24.67s/epoch, loss=1.15, accuracy=0.751, val_loss=2.54, val_accuracy=0.412, lr=0.1] 41%|████      | 34/83 [14:43<20:14, 24.78s/epoch, loss=1.16, accuracy=0.753, val_loss=2.57, val_accuracy=0.271, lr=0.1] 42%|████▏     | 35/83 [15:07<19:45, 24.70s/epoch, loss=1.16, accuracy=0.75, val_loss=4.13, val_accuracy=0.393, lr=0.0316] 43%|████▎     | 36/83 [15:32<19:16, 24.60s/epoch, loss=1.16, accuracy=0.75, val_loss=1.8, val_accuracy=0.545, lr=0.1]     45%|████▍     | 37/83 [15:57<18:56, 24.70s/epoch, loss=1.15, accuracy=0.754, val_loss=2.3, val_accuracy=0.474, lr=0.1] 46%|████▌     | 38/83 [16:21<18:30, 24.67s/epoch, loss=1.15, accuracy=0.755, val_loss=1.66, val_accuracy=0.574, lr=0.1] 47%|████▋     | 39/83 [16:46<18:06, 24.70s/epoch, loss=1.15, accuracy=0.754, val_loss=2.02, val_accuracy=0.511, lr=0.1] 48%|████▊     | 40/83 [17:11<17:42, 24.71s/epoch, loss=1.16, accuracy=0.752, val_loss=2.03, val_accuracy=0.447, lr=0.0316] 49%|████▉     | 41/83 [17:36<17:22, 24.81s/epoch, loss=1.15, accuracy=0.751, val_loss=1.72, val_accuracy=0.547, lr=0.1]    51%|█████     | 42/83 [18:01<16:59, 24.88s/epoch, loss=1.14, accuracy=0.756, val_loss=2.31, val_accuracy=0.466, lr=0.1] 52%|█████▏    | 43/83 [18:26<16:35, 24.88s/epoch, loss=1.14, accuracy=0.755, val_loss=2, val_accuracy=0.495, lr=0.1]    53%|█████▎    | 44/83 [18:50<16:05, 24.77s/epoch, loss=1.15, accuracy=0.753, val_loss=3.76, val_accuracy=0.32, lr=0.1] 54%|█████▍    | 45/83 [19:15<15:43, 24.83s/epoch, loss=1.15, accuracy=0.754, val_loss=2.05, val_accuracy=0.481, lr=0.0316] 55%|█████▌    | 46/83 [19:40<15:14, 24.71s/epoch, loss=1.13, accuracy=0.755, val_loss=2.87, val_accuracy=0.429, lr=0.1]    57%|█████▋    | 47/83 [20:04<14:49, 24.71s/epoch, loss=1.15, accuracy=0.754, val_loss=1.46, val_accuracy=0.652, lr=0.1] 58%|█████▊    | 48/83 [20:29<14:19, 24.57s/epoch, loss=1.14, accuracy=0.754, val_loss=3.33, val_accuracy=0.352, lr=0.1] 59%|█████▉    | 49/83 [20:53<13:54, 24.55s/epoch, loss=1.15, accuracy=0.753, val_loss=1.6, val_accuracy=0.597, lr=0.1]  60%|██████    | 50/83 [21:18<13:35, 24.72s/epoch, loss=1.14, accuracy=0.754, val_loss=1.62, val_accuracy=0.595, lr=0.0316] 61%|██████▏   | 51/83 [21:43<13:12, 24.77s/epoch, loss=1.14, accuracy=0.754, val_loss=1.54, val_accuracy=0.632, lr=0.1]    63%|██████▎   | 52/83 [22:08<12:47, 24.75s/epoch, loss=1.14, accuracy=0.754, val_loss=2.03, val_accuracy=0.506, lr=0.1] 64%|██████▍   | 53/83 [22:33<12:24, 24.80s/epoch, loss=1.15, accuracy=0.752, val_loss=2.82, val_accuracy=0.377, lr=0.1] 65%|██████▌   | 54/83 [22:58<12:01, 24.87s/epoch, loss=1.14, accuracy=0.755, val_loss=1.86, val_accuracy=0.605, lr=0.1] 66%|██████▋   | 55/83 [23:23<11:35, 24.84s/epoch, loss=1.14, accuracy=0.756, val_loss=1.81, val_accuracy=0.53, lr=0.0316] 67%|██████▋   | 56/83 [23:47<11:08, 24.77s/epoch, loss=1.14, accuracy=0.757, val_loss=1.59, val_accuracy=0.596, lr=0.1]   69%|██████▊   | 57/83 [24:11<10:39, 24.61s/epoch, loss=1.14, accuracy=0.754, val_loss=3.73, val_accuracy=0.334, lr=0.1] 70%|██████▉   | 58/83 [24:36<10:18, 24.73s/epoch, loss=1.15, accuracy=0.755, val_loss=2.75, val_accuracy=0.447, lr=0.1] 71%|███████   | 59/83 [25:01<09:50, 24.59s/epoch, loss=1.14, accuracy=0.753, val_loss=2.31, val_accuracy=0.444, lr=0.1] 72%|███████▏  | 60/83 [25:25<09:24, 24.55s/epoch, loss=1.15, accuracy=0.753, val_loss=1.58, val_accuracy=0.586, lr=0.0316] 73%|███████▎  | 61/83 [25:50<09:04, 24.75s/epoch, loss=1.14, accuracy=0.755, val_loss=2.7, val_accuracy=0.411, lr=0.1]     75%|███████▍  | 62/83 [26:15<08:38, 24.71s/epoch, loss=1.14, accuracy=0.758, val_loss=2.54, val_accuracy=0.453, lr=0.1] 76%|███████▌  | 63/83 [26:40<08:14, 24.71s/epoch, loss=1.14, accuracy=0.756, val_loss=4.05, val_accuracy=0.226, lr=0.1] 77%|███████▋  | 64/83 [27:05<07:51, 24.80s/epoch, loss=1.14, accuracy=0.755, val_loss=2.47, val_accuracy=0.487, lr=0.1] 78%|███████▊  | 65/83 [27:30<07:27, 24.85s/epoch, loss=1.13, accuracy=0.758, val_loss=1.77, val_accuracy=0.571, lr=0.0316] 80%|███████▉  | 66/83 [27:54<06:59, 24.69s/epoch, loss=1.14, accuracy=0.755, val_loss=1.63, val_accuracy=0.587, lr=0.1]    81%|████████  | 67/83 [28:19<06:34, 24.64s/epoch, loss=1.14, accuracy=0.755, val_loss=1.71, val_accuracy=0.582, lr=0.1] 82%|████████▏ | 68/83 [28:43<06:10, 24.70s/epoch, loss=1.13, accuracy=0.757, val_loss=1.56, val_accuracy=0.624, lr=0.1] 83%|████████▎ | 69/83 [29:08<05:45, 24.65s/epoch, loss=1.15, accuracy=0.754, val_loss=2.12, val_accuracy=0.495, lr=0.1] 84%|████████▍ | 70/83 [29:33<05:20, 24.69s/epoch, loss=1.14, accuracy=0.755, val_loss=2.1, val_accuracy=0.414, lr=0.0316] 86%|████████▌ | 71/83 [29:57<04:55, 24.65s/epoch, loss=1.15, accuracy=0.755, val_loss=1.76, val_accuracy=0.572, lr=0.1]   87%|████████▋ | 72/83 [30:21<04:28, 24.43s/epoch, loss=1.14, accuracy=0.755, val_loss=1.85, val_accuracy=0.524, lr=0.1] 88%|████████▊ | 73/83 [30:46<04:05, 24.53s/epoch, loss=1.14, accuracy=0.756, val_loss=3.25, val_accuracy=0.331, lr=0.1] 89%|████████▉ | 74/83 [31:10<03:39, 24.41s/epoch, loss=1.14, accuracy=0.753, val_loss=2.1, val_accuracy=0.477, lr=0.1]  90%|█████████ | 75/83 [31:35<03:16, 24.54s/epoch, loss=1.14, accuracy=0.753, val_loss=2.24, val_accuracy=0.42, lr=0.0316] 92%|█████████▏| 76/83 [31:59<02:51, 24.46s/epoch, loss=1.14, accuracy=0.756, val_loss=3.15, val_accuracy=0.331, lr=0.1]   93%|█████████▎| 77/83 [32:23<02:26, 24.36s/epoch, loss=1.14, accuracy=0.753, val_loss=1.63, val_accuracy=0.583, lr=0.1] 94%|█████████▍| 78/83 [32:48<02:02, 24.44s/epoch, loss=1.14, accuracy=0.753, val_loss=2.49, val_accuracy=0.501, lr=0.1] 95%|█████████▌| 79/83 [33:12<01:37, 24.46s/epoch, loss=1.14, accuracy=0.758, val_loss=1.97, val_accuracy=0.49, lr=0.1]  96%|█████████▋| 80/83 [33:37<01:13, 24.55s/epoch, loss=1.14, accuracy=0.756, val_loss=2.22, val_accuracy=0.423, lr=0.0316] 98%|█████████▊| 81/83 [34:02<00:49, 24.63s/epoch, loss=1.13, accuracy=0.757, val_loss=2.32, val_accuracy=0.479, lr=0.1]    99%|█████████▉| 82/83 [34:27<00:24, 24.67s/epoch, loss=0.913, accuracy=0.82, val_loss=0.877, val_accuracy=0.818, lr=0.01]100%|██████████| 83/83 [34:51<00:00, 24.64s/epoch, loss=0.735, accuracy=0.849, val_loss=0.75, val_accuracy=0.832, lr=0.01]100%|██████████| 83/83 [34:51<00:00, 25.20s/epoch, loss=0.735, accuracy=0.849, val_loss=0.75, val_accuracy=0.832, lr=0.01]
Using real-time data augmentation.
Test loss: 0.7500901222229004
Test accuracy: 0.8321999907493591


* * * Run SGD for ID = 18_8. * * *


2024-02-15 18:04:17.265771: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 18:04:20.235693: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 18:04:20.236968: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-15 18:04:20.310493: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 18:04:20.310525: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 18:04:20.313480: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 18:04:20.313521: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 18:04:20.315960: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 18:04:20.316653: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 18:04:20.319200: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 18:04:20.320874: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 18:04:20.325845: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 18:04:20.326300: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 18:04:20.326396: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 18:04:21.541970: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-15 18:04:21.543078: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 18:04:21.543504: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 18:04:21.543544: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 18:04:21.543578: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 18:04:21.543624: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 18:04:21.543643: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 18:04:21.543660: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 18:04:21.543677: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 18:04:21.543694: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 18:04:21.543711: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 18:04:21.544118: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 18:04:21.544155: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 18:04:22.195727: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-15 18:04:22.195793: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-15 18:04:22.195805: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-15 18:04:22.196638: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:03:00.0, compute capability: 6.1)
{'id': 188, 'batch_size': 128, 'epochs': 83, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/83 [00:00<?, ?epoch/s]2024-02-15 18:04:22.987009: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-15 18:04:22.987611: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2200060000 Hz
2024-02-15 18:04:25.040302: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 18:04:25.309682: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 18:04:26.151438: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-15 18:04:26.193197: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/83 [01:04<1:28:17, 64.61s/epoch, loss=3.09, accuracy=0.341, val_loss=2.64, val_accuracy=0.231, lr=0.1]  2%|▏         | 2/83 [01:29<55:53, 41.40s/epoch, loss=1.48, accuracy=0.579, val_loss=2.25, val_accuracy=0.361, lr=0.1]    4%|▎         | 3/83 [01:54<44:47, 33.59s/epoch, loss=1.31, accuracy=0.659, val_loss=2.35, val_accuracy=0.397, lr=0.1]  5%|▍         | 4/83 [02:17<39:02, 29.65s/epoch, loss=1.26, accuracy=0.691, val_loss=2.02, val_accuracy=0.378, lr=0.1]  6%|▌         | 5/83 [02:42<36:20, 27.95s/epoch, loss=1.24, accuracy=0.705, val_loss=1.95, val_accuracy=0.474, lr=0.1]  7%|▋         | 6/83 [03:07<34:25, 26.82s/epoch, loss=1.22, accuracy=0.716, val_loss=1.6, val_accuracy=0.595, lr=0.1]   8%|▊         | 7/83 [03:32<33:08, 26.16s/epoch, loss=1.21, accuracy=0.723, val_loss=2.45, val_accuracy=0.402, lr=0.1] 10%|▉         | 8/83 [03:56<32:03, 25.64s/epoch, loss=1.2, accuracy=0.726, val_loss=2.1, val_accuracy=0.47, lr=0.1]    11%|█         | 9/83 [04:21<31:23, 25.46s/epoch, loss=1.2, accuracy=0.726, val_loss=2.38, val_accuracy=0.44, lr=0.1] 12%|█▏        | 10/83 [04:46<30:51, 25.36s/epoch, loss=1.19, accuracy=0.726, val_loss=3.44, val_accuracy=0.272, lr=0.1] 13%|█▎        | 11/83 [05:11<30:18, 25.25s/epoch, loss=1.18, accuracy=0.737, val_loss=1.62, val_accuracy=0.599, lr=0.0316] 14%|█▍        | 12/83 [05:36<29:43, 25.12s/epoch, loss=1.18, accuracy=0.736, val_loss=2.2, val_accuracy=0.427, lr=0.1]     16%|█▌        | 13/83 [06:01<29:17, 25.11s/epoch, loss=1.17, accuracy=0.74, val_loss=2.13, val_accuracy=0.421, lr=0.1] 17%|█▋        | 14/83 [06:26<28:50, 25.08s/epoch, loss=1.17, accuracy=0.74, val_loss=2.52, val_accuracy=0.42, lr=0.1]  18%|█▊        | 15/83 [06:51<28:28, 25.12s/epoch, loss=1.16, accuracy=0.742, val_loss=2.64, val_accuracy=0.44, lr=0.1] 19%|█▉        | 16/83 [07:16<27:45, 24.86s/epoch, loss=1.17, accuracy=0.743, val_loss=2.22, val_accuracy=0.473, lr=0.0316] 20%|██        | 17/83 [07:41<27:29, 25.00s/epoch, loss=1.16, accuracy=0.745, val_loss=3.26, val_accuracy=0.222, lr=0.1]    22%|██▏       | 18/83 [08:06<27:08, 25.05s/epoch, loss=1.16, accuracy=0.744, val_loss=2.13, val_accuracy=0.533, lr=0.1] 23%|██▎       | 19/83 [08:31<26:45, 25.09s/epoch, loss=1.15, accuracy=0.749, val_loss=4.61, val_accuracy=0.258, lr=0.1] 24%|██▍       | 20/83 [08:56<26:17, 25.03s/epoch, loss=1.15, accuracy=0.746, val_loss=1.87, val_accuracy=0.572, lr=0.1] 25%|██▌       | 21/83 [09:21<25:55, 25.10s/epoch, loss=1.14, accuracy=0.747, val_loss=1.75, val_accuracy=0.578, lr=0.0316] 27%|██▋       | 22/83 [09:46<25:27, 25.05s/epoch, loss=1.15, accuracy=0.748, val_loss=2.5, val_accuracy=0.459, lr=0.1]     28%|██▊       | 23/83 [10:11<25:02, 25.04s/epoch, loss=1.14, accuracy=0.749, val_loss=1.5, val_accuracy=0.646, lr=0.1] 29%|██▉       | 24/83 [10:37<24:38, 25.06s/epoch, loss=1.14, accuracy=0.748, val_loss=1.72, val_accuracy=0.53, lr=0.1] 30%|███       | 25/83 [11:02<24:11, 25.03s/epoch, loss=1.13, accuracy=0.753, val_loss=2.58, val_accuracy=0.388, lr=0.1] 31%|███▏      | 26/83 [11:27<23:46, 25.02s/epoch, loss=1.13, accuracy=0.752, val_loss=2.57, val_accuracy=0.398, lr=0.1] 33%|███▎      | 27/83 [11:52<23:23, 25.07s/epoch, loss=1.13, accuracy=0.754, val_loss=4.08, val_accuracy=0.257, lr=0.1] 34%|███▎      | 28/83 [12:17<22:59, 25.08s/epoch, loss=1.13, accuracy=0.756, val_loss=1.71, val_accuracy=0.538, lr=0.0316] 35%|███▍      | 29/83 [12:42<22:36, 25.12s/epoch, loss=1.13, accuracy=0.751, val_loss=1.9, val_accuracy=0.495, lr=0.1]     36%|███▌      | 30/83 [13:07<22:12, 25.15s/epoch, loss=1.13, accuracy=0.756, val_loss=2.09, val_accuracy=0.52, lr=0.1] 37%|███▋      | 31/83 [13:32<21:42, 25.05s/epoch, loss=1.12, accuracy=0.755, val_loss=3.54, val_accuracy=0.377, lr=0.1] 39%|███▊      | 32/83 [13:56<20:55, 24.63s/epoch, loss=1.13, accuracy=0.752, val_loss=1.79, val_accuracy=0.495, lr=0.1] 40%|███▉      | 33/83 [14:21<20:36, 24.73s/epoch, loss=1.13, accuracy=0.754, val_loss=2.17, val_accuracy=0.401, lr=0.0316] 41%|████      | 34/83 [14:46<20:17, 24.84s/epoch, loss=1.13, accuracy=0.755, val_loss=3.21, val_accuracy=0.421, lr=0.1]    42%|████▏     | 35/83 [15:10<19:47, 24.74s/epoch, loss=1.12, accuracy=0.754, val_loss=1.84, val_accuracy=0.519, lr=0.1] 43%|████▎     | 36/83 [15:35<19:25, 24.80s/epoch, loss=1.13, accuracy=0.754, val_loss=1.86, val_accuracy=0.563, lr=0.1] 45%|████▍     | 37/83 [16:00<19:04, 24.88s/epoch, loss=1.12, accuracy=0.756, val_loss=1.66, val_accuracy=0.596, lr=0.1] 46%|████▌     | 38/83 [16:25<18:42, 24.95s/epoch, loss=1.12, accuracy=0.754, val_loss=2.4, val_accuracy=0.379, lr=0.0316] 47%|████▋     | 39/83 [16:50<18:07, 24.70s/epoch, loss=1.12, accuracy=0.757, val_loss=1.8, val_accuracy=0.546, lr=0.1]    48%|████▊     | 40/83 [17:15<17:51, 24.92s/epoch, loss=1.12, accuracy=0.756, val_loss=3.02, val_accuracy=0.392, lr=0.1] 49%|████▉     | 41/83 [17:40<17:27, 24.93s/epoch, loss=1.12, accuracy=0.756, val_loss=2.04, val_accuracy=0.479, lr=0.1] 51%|█████     | 42/83 [18:05<17:04, 24.99s/epoch, loss=1.12, accuracy=0.756, val_loss=2, val_accuracy=0.529, lr=0.1]    52%|█████▏    | 43/83 [18:30<16:35, 24.89s/epoch, loss=1.12, accuracy=0.756, val_loss=3.29, val_accuracy=0.352, lr=0.0316] 53%|█████▎    | 44/83 [18:54<16:06, 24.77s/epoch, loss=1.12, accuracy=0.757, val_loss=1.81, val_accuracy=0.496, lr=0.1]    54%|█████▍    | 45/83 [19:19<15:43, 24.83s/epoch, loss=1.12, accuracy=0.757, val_loss=2.62, val_accuracy=0.386, lr=0.1] 55%|█████▌    | 46/83 [19:43<15:13, 24.69s/epoch, loss=1.11, accuracy=0.759, val_loss=1.6, val_accuracy=0.604, lr=0.1]  57%|█████▋    | 47/83 [20:08<14:50, 24.74s/epoch, loss=1.11, accuracy=0.758, val_loss=2.76, val_accuracy=0.387, lr=0.1] 58%|█████▊    | 48/83 [20:33<14:30, 24.86s/epoch, loss=1.12, accuracy=0.757, val_loss=2.84, val_accuracy=0.323, lr=0.0316] 59%|█████▉    | 49/83 [20:59<14:09, 25.00s/epoch, loss=1.12, accuracy=0.758, val_loss=2.12, val_accuracy=0.384, lr=0.1]    60%|██████    | 50/83 [21:24<13:45, 25.00s/epoch, loss=1.12, accuracy=0.756, val_loss=2.61, val_accuracy=0.387, lr=0.1] 61%|██████▏   | 51/83 [21:49<13:22, 25.07s/epoch, loss=1.12, accuracy=0.758, val_loss=3.42, val_accuracy=0.361, lr=0.1] 63%|██████▎   | 52/83 [22:14<12:56, 25.06s/epoch, loss=1.12, accuracy=0.755, val_loss=2.86, val_accuracy=0.354, lr=0.1] 64%|██████▍   | 53/83 [22:39<12:33, 25.13s/epoch, loss=1.11, accuracy=0.757, val_loss=2.23, val_accuracy=0.476, lr=0.0316] 65%|██████▌   | 54/83 [23:04<12:07, 25.07s/epoch, loss=1.12, accuracy=0.758, val_loss=1.72, val_accuracy=0.532, lr=0.1]    66%|██████▋   | 55/83 [23:30<11:45, 25.18s/epoch, loss=1.11, accuracy=0.757, val_loss=2.34, val_accuracy=0.423, lr=0.1] 67%|██████▋   | 56/83 [23:55<11:20, 25.20s/epoch, loss=1.11, accuracy=0.756, val_loss=2.88, val_accuracy=0.409, lr=0.1] 69%|██████▊   | 57/83 [24:20<10:56, 25.25s/epoch, loss=1.12, accuracy=0.757, val_loss=1.84, val_accuracy=0.529, lr=0.1] 70%|██████▉   | 58/83 [24:45<10:29, 25.17s/epoch, loss=1.12, accuracy=0.757, val_loss=2.19, val_accuracy=0.519, lr=0.0316] 71%|███████   | 59/83 [25:10<10:03, 25.14s/epoch, loss=1.11, accuracy=0.756, val_loss=1.83, val_accuracy=0.574, lr=0.1]    72%|███████▏  | 60/83 [25:35<09:32, 24.89s/epoch, loss=1.11, accuracy=0.758, val_loss=1.68, val_accuracy=0.571, lr=0.1] 73%|███████▎  | 61/83 [26:00<09:07, 24.90s/epoch, loss=1.12, accuracy=0.756, val_loss=3.21, val_accuracy=0.37, lr=0.1]  75%|███████▍  | 62/83 [26:25<08:47, 25.10s/epoch, loss=1.11, accuracy=0.759, val_loss=2.94, val_accuracy=0.397, lr=0.1] 76%|███████▌  | 63/83 [26:50<08:21, 25.05s/epoch, loss=1.11, accuracy=0.756, val_loss=1.57, val_accuracy=0.6, lr=0.0316] 77%|███████▋  | 64/83 [27:15<07:57, 25.12s/epoch, loss=1.12, accuracy=0.756, val_loss=2.79, val_accuracy=0.386, lr=0.1]  78%|███████▊  | 65/83 [27:41<07:32, 25.14s/epoch, loss=1.11, accuracy=0.76, val_loss=2.31, val_accuracy=0.435, lr=0.1]  80%|███████▉  | 66/83 [28:05<07:04, 24.97s/epoch, loss=1.11, accuracy=0.758, val_loss=1.73, val_accuracy=0.578, lr=0.1] 81%|████████  | 67/83 [28:30<06:39, 24.94s/epoch, loss=1.11, accuracy=0.757, val_loss=2.96, val_accuracy=0.37, lr=0.1]  82%|████████▏ | 68/83 [28:55<06:15, 25.01s/epoch, loss=1.11, accuracy=0.761, val_loss=1.87, val_accuracy=0.524, lr=0.0316] 83%|████████▎ | 69/83 [29:20<05:49, 24.99s/epoch, loss=1.11, accuracy=0.759, val_loss=2.8, val_accuracy=0.318, lr=0.1]     84%|████████▍ | 70/83 [29:45<05:24, 24.96s/epoch, loss=1.11, accuracy=0.759, val_loss=1.84, val_accuracy=0.555, lr=0.1] 86%|████████▌ | 71/83 [30:10<04:59, 24.96s/epoch, loss=1.11, accuracy=0.76, val_loss=2.2, val_accuracy=0.485, lr=0.1]   87%|████████▋ | 72/83 [30:35<04:33, 24.88s/epoch, loss=1.11, accuracy=0.757, val_loss=3.51, val_accuracy=0.295, lr=0.1] 88%|████████▊ | 73/83 [31:00<04:10, 25.00s/epoch, loss=1.11, accuracy=0.758, val_loss=1.55, val_accuracy=0.605, lr=0.0316] 89%|████████▉ | 74/83 [31:25<03:43, 24.87s/epoch, loss=1.11, accuracy=0.759, val_loss=2.98, val_accuracy=0.335, lr=0.1]    90%|█████████ | 75/83 [31:49<03:18, 24.83s/epoch, loss=1.1, accuracy=0.76, val_loss=2.07, val_accuracy=0.473, lr=0.1]   92%|█████████▏| 76/83 [32:14<02:53, 24.80s/epoch, loss=1.1, accuracy=0.76, val_loss=2.03, val_accuracy=0.445, lr=0.1] 93%|█████████▎| 77/83 [32:39<02:28, 24.78s/epoch, loss=1.11, accuracy=0.757, val_loss=1.34, val_accuracy=0.686, lr=0.1] 94%|█████████▍| 78/83 [33:04<02:04, 24.90s/epoch, loss=1.1, accuracy=0.76, val_loss=4.46, val_accuracy=0.282, lr=0.1]   95%|█████████▌| 79/83 [33:28<01:38, 24.51s/epoch, loss=1.1, accuracy=0.76, val_loss=5.05, val_accuracy=0.361, lr=0.1] 96%|█████████▋| 80/83 [33:53<01:14, 24.71s/epoch, loss=1.11, accuracy=0.756, val_loss=2.55, val_accuracy=0.422, lr=0.1] 98%|█████████▊| 81/83 [34:17<00:49, 24.69s/epoch, loss=1.1, accuracy=0.759, val_loss=2.27, val_accuracy=0.354, lr=0.1]  99%|█████████▉| 82/83 [34:42<00:24, 24.72s/epoch, loss=0.911, accuracy=0.815, val_loss=0.894, val_accuracy=0.804, lr=0.01]100%|██████████| 83/83 [35:06<00:00, 24.43s/epoch, loss=0.729, accuracy=0.848, val_loss=0.832, val_accuracy=0.798, lr=0.01]100%|██████████| 83/83 [35:06<00:00, 25.38s/epoch, loss=0.729, accuracy=0.848, val_loss=0.832, val_accuracy=0.798, lr=0.01]
Using real-time data augmentation.
Test loss: 0.8323665261268616
Test accuracy: 0.7983999848365784


* * * Run SGD for ID = 18_9. * * *


2024-02-15 18:39:32.173144: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 18:39:35.121444: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 18:39:35.122757: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-15 18:39:35.162045: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 18:39:35.162076: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 18:39:35.164913: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 18:39:35.164954: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 18:39:35.167264: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 18:39:35.167944: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 18:39:35.170305: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 18:39:35.171731: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 18:39:35.176417: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 18:39:35.176923: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 18:39:35.177016: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 18:39:36.418726: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-15 18:39:36.419284: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 18:39:36.419715: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 18:39:36.419748: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 18:39:36.419782: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 18:39:36.419800: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 18:39:36.419816: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 18:39:36.419833: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 18:39:36.419850: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 18:39:36.419867: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 18:39:36.419892: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 18:39:36.420290: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 18:39:36.420328: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 18:39:37.056525: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-15 18:39:37.056594: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-15 18:39:37.056606: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-15 18:39:37.057429: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:03:00.0, compute capability: 6.1)
{'id': 189, 'batch_size': 128, 'epochs': 83, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/83 [00:00<?, ?epoch/s]2024-02-15 18:39:37.851924: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-15 18:39:37.852688: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2200060000 Hz
2024-02-15 18:39:39.851233: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 18:39:40.147854: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 18:39:40.941068: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-15 18:39:41.036792: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/83 [00:55<1:15:59, 55.61s/epoch, loss=3.23, accuracy=0.339, val_loss=2.73, val_accuracy=0.221, lr=0.1]  2%|▏         | 2/83 [01:20<50:38, 37.51s/epoch, loss=1.58, accuracy=0.528, val_loss=2.35, val_accuracy=0.34, lr=0.1]     4%|▎         | 3/83 [01:44<41:45, 31.32s/epoch, loss=1.36, accuracy=0.634, val_loss=1.8, val_accuracy=0.505, lr=0.1]  5%|▍         | 4/83 [02:07<37:09, 28.22s/epoch, loss=1.28, accuracy=0.678, val_loss=2.59, val_accuracy=0.413, lr=0.1]  6%|▌         | 5/83 [02:32<34:48, 26.78s/epoch, loss=1.25, accuracy=0.699, val_loss=2.35, val_accuracy=0.374, lr=0.1]  7%|▋         | 6/83 [02:55<33:05, 25.78s/epoch, loss=1.24, accuracy=0.709, val_loss=1.72, val_accuracy=0.532, lr=0.1]  8%|▊         | 7/83 [03:19<31:52, 25.16s/epoch, loss=1.23, accuracy=0.719, val_loss=2.09, val_accuracy=0.512, lr=0.1] 10%|▉         | 8/83 [03:45<31:44, 25.39s/epoch, loss=1.22, accuracy=0.723, val_loss=2.52, val_accuracy=0.431, lr=0.1] 11%|█         | 9/83 [04:10<31:07, 25.24s/epoch, loss=1.21, accuracy=0.726, val_loss=4.48, val_accuracy=0.27, lr=0.1]  12%|█▏        | 10/83 [04:34<30:07, 24.75s/epoch, loss=1.21, accuracy=0.73, val_loss=1.79, val_accuracy=0.552, lr=0.1] 13%|█▎        | 11/83 [04:57<28:59, 24.16s/epoch, loss=1.21, accuracy=0.733, val_loss=2, val_accuracy=0.447, lr=0.0316] 14%|█▍        | 12/83 [05:22<28:54, 24.43s/epoch, loss=1.21, accuracy=0.732, val_loss=1.78, val_accuracy=0.58, lr=0.1]  16%|█▌        | 13/83 [05:46<28:38, 24.55s/epoch, loss=1.21, accuracy=0.736, val_loss=1.99, val_accuracy=0.507, lr=0.1] 17%|█▋        | 14/83 [06:10<27:50, 24.21s/epoch, loss=1.21, accuracy=0.737, val_loss=1.86, val_accuracy=0.499, lr=0.1] 18%|█▊        | 15/83 [06:35<27:35, 24.34s/epoch, loss=1.21, accuracy=0.737, val_loss=2.22, val_accuracy=0.501, lr=0.1] 19%|█▉        | 16/83 [06:59<27:08, 24.31s/epoch, loss=1.21, accuracy=0.738, val_loss=1.94, val_accuracy=0.5, lr=0.0316] 20%|██        | 17/83 [07:24<26:54, 24.46s/epoch, loss=1.2, accuracy=0.74, val_loss=2.16, val_accuracy=0.474, lr=0.1]    22%|██▏       | 18/83 [07:48<26:35, 24.54s/epoch, loss=1.2, accuracy=0.741, val_loss=2.39, val_accuracy=0.466, lr=0.1] 23%|██▎       | 19/83 [08:13<26:14, 24.60s/epoch, loss=1.2, accuracy=0.74, val_loss=1.73, val_accuracy=0.592, lr=0.1]  24%|██▍       | 20/83 [08:38<25:57, 24.72s/epoch, loss=1.2, accuracy=0.74, val_loss=2.27, val_accuracy=0.456, lr=0.1] 25%|██▌       | 21/83 [09:03<25:32, 24.72s/epoch, loss=1.2, accuracy=0.739, val_loss=1.73, val_accuracy=0.574, lr=0.0316] 27%|██▋       | 22/83 [09:28<25:16, 24.85s/epoch, loss=1.2, accuracy=0.744, val_loss=2.71, val_accuracy=0.268, lr=0.1]    28%|██▊       | 23/83 [09:52<24:42, 24.72s/epoch, loss=1.2, accuracy=0.743, val_loss=1.89, val_accuracy=0.501, lr=0.1] 29%|██▉       | 24/83 [10:15<23:39, 24.05s/epoch, loss=1.19, accuracy=0.742, val_loss=1.52, val_accuracy=0.626, lr=0.1] 30%|███       | 25/83 [10:39<23:21, 24.17s/epoch, loss=1.19, accuracy=0.745, val_loss=1.53, val_accuracy=0.628, lr=0.1] 31%|███▏      | 26/83 [11:04<23:07, 24.34s/epoch, loss=1.18, accuracy=0.746, val_loss=1.57, val_accuracy=0.613, lr=0.1] 33%|███▎      | 27/83 [11:29<22:53, 24.54s/epoch, loss=1.19, accuracy=0.744, val_loss=1.54, val_accuracy=0.614, lr=0.1] 34%|███▎      | 28/83 [11:53<22:27, 24.50s/epoch, loss=1.19, accuracy=0.744, val_loss=1.71, val_accuracy=0.554, lr=0.1] 35%|███▍      | 29/83 [12:18<22:07, 24.58s/epoch, loss=1.19, accuracy=0.744, val_loss=1.83, val_accuracy=0.582, lr=0.0316] 36%|███▌      | 30/83 [12:43<21:47, 24.67s/epoch, loss=1.18, accuracy=0.746, val_loss=2.35, val_accuracy=0.468, lr=0.1]    37%|███▋      | 31/83 [13:08<21:20, 24.63s/epoch, loss=1.18, accuracy=0.749, val_loss=6.38, val_accuracy=0.242, lr=0.1] 39%|███▊      | 32/83 [13:31<20:41, 24.34s/epoch, loss=1.18, accuracy=0.746, val_loss=2.21, val_accuracy=0.425, lr=0.1] 40%|███▉      | 33/83 [13:56<20:26, 24.52s/epoch, loss=1.18, accuracy=0.748, val_loss=2.25, val_accuracy=0.448, lr=0.1] 41%|████      | 34/83 [14:20<19:53, 24.35s/epoch, loss=1.18, accuracy=0.745, val_loss=1.86, val_accuracy=0.53, lr=0.0316] 42%|████▏     | 35/83 [14:45<19:30, 24.39s/epoch, loss=1.18, accuracy=0.748, val_loss=1.57, val_accuracy=0.619, lr=0.1]   43%|████▎     | 36/83 [15:09<19:09, 24.45s/epoch, loss=1.18, accuracy=0.745, val_loss=1.82, val_accuracy=0.536, lr=0.1] 45%|████▍     | 37/83 [15:33<18:38, 24.32s/epoch, loss=1.18, accuracy=0.748, val_loss=2.73, val_accuracy=0.387, lr=0.1] 46%|████▌     | 38/83 [15:58<18:17, 24.39s/epoch, loss=1.18, accuracy=0.75, val_loss=2.2, val_accuracy=0.382, lr=0.1]   47%|████▋     | 39/83 [16:22<17:56, 24.46s/epoch, loss=1.17, accuracy=0.751, val_loss=1.84, val_accuracy=0.524, lr=0.0316] 48%|████▊     | 40/83 [16:48<17:41, 24.69s/epoch, loss=1.16, accuracy=0.75, val_loss=3.18, val_accuracy=0.407, lr=0.1]     49%|████▉     | 41/83 [17:13<17:21, 24.79s/epoch, loss=1.18, accuracy=0.747, val_loss=1.77, val_accuracy=0.572, lr=0.1] 51%|█████     | 42/83 [17:38<17:02, 24.94s/epoch, loss=1.16, accuracy=0.751, val_loss=2.02, val_accuracy=0.516, lr=0.1] 52%|█████▏    | 43/83 [18:03<16:44, 25.10s/epoch, loss=1.16, accuracy=0.751, val_loss=1.75, val_accuracy=0.563, lr=0.1] 53%|█████▎    | 44/83 [18:28<16:15, 25.00s/epoch, loss=1.17, accuracy=0.748, val_loss=1.95, val_accuracy=0.511, lr=0.0316] 54%|█████▍    | 45/83 [18:53<15:49, 24.98s/epoch, loss=1.17, accuracy=0.749, val_loss=1.69, val_accuracy=0.597, lr=0.1]    55%|█████▌    | 46/83 [19:18<15:26, 25.03s/epoch, loss=1.17, accuracy=0.747, val_loss=1.62, val_accuracy=0.603, lr=0.1] 57%|█████▋    | 47/83 [19:43<14:59, 24.99s/epoch, loss=1.17, accuracy=0.751, val_loss=2.24, val_accuracy=0.387, lr=0.1] 58%|█████▊    | 48/83 [20:08<14:35, 25.02s/epoch, loss=1.17, accuracy=0.748, val_loss=2.34, val_accuracy=0.453, lr=0.1] 59%|█████▉    | 49/83 [20:34<14:13, 25.10s/epoch, loss=1.17, accuracy=0.749, val_loss=2, val_accuracy=0.494, lr=0.0316] 60%|██████    | 50/83 [20:58<13:42, 24.93s/epoch, loss=1.17, accuracy=0.75, val_loss=1.79, val_accuracy=0.511, lr=0.1]  61%|██████▏   | 51/83 [21:24<13:22, 25.08s/epoch, loss=1.16, accuracy=0.751, val_loss=1.99, val_accuracy=0.504, lr=0.1] 63%|██████▎   | 52/83 [21:48<12:55, 25.01s/epoch, loss=1.16, accuracy=0.753, val_loss=3.15, val_accuracy=0.333, lr=0.1] 64%|██████▍   | 53/83 [22:14<12:31, 25.06s/epoch, loss=1.17, accuracy=0.75, val_loss=2.05, val_accuracy=0.51, lr=0.1]   65%|██████▌   | 54/83 [22:38<11:58, 24.79s/epoch, loss=1.16, accuracy=0.751, val_loss=1.97, val_accuracy=0.506, lr=0.0316] 66%|██████▋   | 55/83 [23:02<11:34, 24.79s/epoch, loss=1.16, accuracy=0.753, val_loss=3.2, val_accuracy=0.298, lr=0.1]     67%|██████▋   | 56/83 [23:27<11:05, 24.65s/epoch, loss=1.17, accuracy=0.75, val_loss=4.54, val_accuracy=0.279, lr=0.1] 69%|██████▊   | 57/83 [23:52<10:41, 24.66s/epoch, loss=1.16, accuracy=0.751, val_loss=1.52, val_accuracy=0.626, lr=0.1] 70%|██████▉   | 58/83 [24:17<10:19, 24.79s/epoch, loss=1.17, accuracy=0.748, val_loss=1.92, val_accuracy=0.505, lr=0.1] 71%|███████   | 59/83 [24:41<09:52, 24.70s/epoch, loss=1.16, accuracy=0.75, val_loss=2.06, val_accuracy=0.452, lr=0.0316] 72%|███████▏  | 60/83 [25:06<09:26, 24.62s/epoch, loss=1.16, accuracy=0.751, val_loss=2.23, val_accuracy=0.462, lr=0.1]   73%|███████▎  | 61/83 [25:30<09:03, 24.71s/epoch, loss=1.16, accuracy=0.75, val_loss=1.83, val_accuracy=0.571, lr=0.1]  75%|███████▍  | 62/83 [25:55<08:38, 24.69s/epoch, loss=1.16, accuracy=0.75, val_loss=1.88, val_accuracy=0.561, lr=0.1] 76%|███████▌  | 63/83 [26:20<08:13, 24.66s/epoch, loss=1.15, accuracy=0.755, val_loss=1.74, val_accuracy=0.621, lr=0.1] 77%|███████▋  | 64/83 [26:44<07:44, 24.43s/epoch, loss=1.15, accuracy=0.753, val_loss=2.54, val_accuracy=0.468, lr=0.0316] 78%|███████▊  | 65/83 [27:08<07:17, 24.32s/epoch, loss=1.15, accuracy=0.752, val_loss=2.04, val_accuracy=0.492, lr=0.1]    80%|███████▉  | 66/83 [27:32<06:54, 24.37s/epoch, loss=1.15, accuracy=0.751, val_loss=1.56, val_accuracy=0.611, lr=0.1] 81%|████████  | 67/83 [27:57<06:31, 24.49s/epoch, loss=1.16, accuracy=0.751, val_loss=2.31, val_accuracy=0.415, lr=0.1] 82%|████████▏ | 68/83 [28:21<06:07, 24.50s/epoch, loss=1.16, accuracy=0.754, val_loss=2.11, val_accuracy=0.553, lr=0.1] 83%|████████▎ | 69/83 [28:46<05:44, 24.59s/epoch, loss=1.16, accuracy=0.753, val_loss=1.73, val_accuracy=0.518, lr=0.0316] 84%|████████▍ | 70/83 [29:11<05:20, 24.65s/epoch, loss=1.16, accuracy=0.751, val_loss=1.7, val_accuracy=0.585, lr=0.1]     86%|████████▌ | 71/83 [29:36<04:56, 24.71s/epoch, loss=1.16, accuracy=0.752, val_loss=1.96, val_accuracy=0.502, lr=0.1] 87%|████████▋ | 72/83 [30:01<04:31, 24.71s/epoch, loss=1.14, accuracy=0.755, val_loss=1.87, val_accuracy=0.499, lr=0.1] 88%|████████▊ | 73/83 [30:25<04:07, 24.75s/epoch, loss=1.15, accuracy=0.751, val_loss=2.17, val_accuracy=0.521, lr=0.1] 89%|████████▉ | 74/83 [30:50<03:42, 24.69s/epoch, loss=1.16, accuracy=0.753, val_loss=2.78, val_accuracy=0.333, lr=0.0316] 90%|█████████ | 75/83 [31:15<03:18, 24.87s/epoch, loss=1.16, accuracy=0.752, val_loss=1.69, val_accuracy=0.547, lr=0.1]    92%|█████████▏| 76/83 [31:40<02:53, 24.74s/epoch, loss=1.16, accuracy=0.751, val_loss=1.72, val_accuracy=0.577, lr=0.1] 93%|█████████▎| 77/83 [32:04<02:28, 24.71s/epoch, loss=1.16, accuracy=0.751, val_loss=2.51, val_accuracy=0.433, lr=0.1] 94%|█████████▍| 78/83 [32:29<02:03, 24.77s/epoch, loss=1.15, accuracy=0.753, val_loss=1.35, val_accuracy=0.687, lr=0.1] 95%|█████████▌| 79/83 [32:54<01:39, 24.81s/epoch, loss=1.15, accuracy=0.75, val_loss=1.5, val_accuracy=0.625, lr=0.1]   96%|█████████▋| 80/83 [33:19<01:14, 24.90s/epoch, loss=1.14, accuracy=0.753, val_loss=2.35, val_accuracy=0.472, lr=0.1] 98%|█████████▊| 81/83 [33:43<00:49, 24.65s/epoch, loss=1.16, accuracy=0.75, val_loss=1.88, val_accuracy=0.5, lr=0.1]    99%|█████████▉| 82/83 [34:08<00:24, 24.76s/epoch, loss=0.935, accuracy=0.813, val_loss=0.883, val_accuracy=0.814, lr=0.01]100%|██████████| 83/83 [34:33<00:00, 24.63s/epoch, loss=0.749, accuracy=0.845, val_loss=0.806, val_accuracy=0.816, lr=0.01]100%|██████████| 83/83 [34:33<00:00, 24.98s/epoch, loss=0.749, accuracy=0.845, val_loss=0.806, val_accuracy=0.816, lr=0.01]
Using real-time data augmentation.
Test loss: 0.8056215047836304
Test accuracy: 0.8163999915122986


* * * Run SGD for ID = 18_10. * * *


2024-02-15 19:14:14.807418: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 19:14:18.362900: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 19:14:18.364094: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-15 19:14:18.404559: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 19:14:18.404614: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 19:14:18.407631: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 19:14:18.407674: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 19:14:18.409914: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 19:14:18.410634: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 19:14:18.413091: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 19:14:18.414681: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 19:14:18.419615: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 19:14:18.421697: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 19:14:18.421778: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 19:14:19.703152: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-15 19:14:19.704237: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 19:14:19.704701: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 19:14:19.704750: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 19:14:19.704785: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 19:14:19.704804: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 19:14:19.704821: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 19:14:19.704838: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 19:14:19.704856: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 19:14:19.704873: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 19:14:19.704891: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 19:14:19.705357: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 19:14:19.705396: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 19:14:20.390145: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-15 19:14:20.390209: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-15 19:14:20.390220: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-15 19:14:20.391141: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:03:00.0, compute capability: 6.1)
{'id': 1810, 'batch_size': 128, 'epochs': 83, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/83 [00:00<?, ?epoch/s]2024-02-15 19:14:21.203682: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-15 19:14:21.204277: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2200060000 Hz
2024-02-15 19:14:23.272830: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 19:14:23.525235: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 19:14:24.446852: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-15 19:14:24.497204: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/83 [00:58<1:20:04, 58.59s/epoch, loss=3.58, accuracy=0.303, val_loss=2.11, val_accuracy=0.341, lr=0.1]  2%|▏         | 2/83 [01:22<51:44, 38.33s/epoch, loss=1.67, accuracy=0.488, val_loss=1.76, val_accuracy=0.452, lr=0.1]    4%|▎         | 3/83 [01:47<42:36, 31.96s/epoch, loss=1.47, accuracy=0.584, val_loss=1.78, val_accuracy=0.5, lr=0.1]    5%|▍         | 4/83 [02:12<38:35, 29.31s/epoch, loss=1.39, accuracy=0.637, val_loss=1.91, val_accuracy=0.489, lr=0.1]  6%|▌         | 5/83 [02:36<35:52, 27.60s/epoch, loss=1.32, accuracy=0.675, val_loss=3.48, val_accuracy=0.29, lr=0.1]   7%|▋         | 6/83 [03:01<34:10, 26.63s/epoch, loss=1.28, accuracy=0.696, val_loss=1.95, val_accuracy=0.473, lr=0.1]  8%|▊         | 7/83 [03:26<32:50, 25.93s/epoch, loss=1.27, accuracy=0.705, val_loss=2.38, val_accuracy=0.452, lr=0.0316] 10%|▉         | 8/83 [03:50<31:51, 25.49s/epoch, loss=1.25, accuracy=0.716, val_loss=1.61, val_accuracy=0.585, lr=0.1]    11%|█         | 9/83 [04:15<31:05, 25.21s/epoch, loss=1.25, accuracy=0.718, val_loss=2.26, val_accuracy=0.419, lr=0.1] 12%|█▏        | 10/83 [04:40<30:37, 25.17s/epoch, loss=1.24, accuracy=0.724, val_loss=1.92, val_accuracy=0.508, lr=0.1] 13%|█▎        | 11/83 [05:05<30:06, 25.09s/epoch, loss=1.23, accuracy=0.729, val_loss=2.06, val_accuracy=0.459, lr=0.1] 14%|█▍        | 12/83 [05:29<29:20, 24.80s/epoch, loss=1.22, accuracy=0.73, val_loss=2.06, val_accuracy=0.476, lr=0.1]  16%|█▌        | 13/83 [05:54<28:58, 24.83s/epoch, loss=1.22, accuracy=0.732, val_loss=1.59, val_accuracy=0.619, lr=0.1] 17%|█▋        | 14/83 [06:19<28:37, 24.89s/epoch, loss=1.21, accuracy=0.735, val_loss=1.91, val_accuracy=0.498, lr=0.1] 18%|█▊        | 15/83 [06:44<28:18, 24.97s/epoch, loss=1.21, accuracy=0.736, val_loss=4.11, val_accuracy=0.357, lr=0.1] 19%|█▉        | 16/83 [07:09<27:56, 25.03s/epoch, loss=1.21, accuracy=0.738, val_loss=1.84, val_accuracy=0.535, lr=0.1] 20%|██        | 17/83 [07:34<27:37, 25.11s/epoch, loss=1.21, accuracy=0.738, val_loss=2.16, val_accuracy=0.401, lr=0.1] 22%|██▏       | 18/83 [07:59<26:52, 24.81s/epoch, loss=1.2, accuracy=0.741, val_loss=2.17, val_accuracy=0.444, lr=0.0316] 23%|██▎       | 19/83 [08:24<26:33, 24.90s/epoch, loss=1.19, accuracy=0.743, val_loss=1.72, val_accuracy=0.583, lr=0.1]   24%|██▍       | 20/83 [08:49<26:08, 24.90s/epoch, loss=1.2, accuracy=0.741, val_loss=2.21, val_accuracy=0.523, lr=0.1]  25%|██▌       | 21/83 [09:13<25:35, 24.76s/epoch, loss=1.19, accuracy=0.742, val_loss=2.01, val_accuracy=0.531, lr=0.1] 27%|██▋       | 22/83 [09:37<25:01, 24.62s/epoch, loss=1.19, accuracy=0.746, val_loss=2.59, val_accuracy=0.428, lr=0.1] 28%|██▊       | 23/83 [10:02<24:31, 24.52s/epoch, loss=1.18, accuracy=0.745, val_loss=2.58, val_accuracy=0.452, lr=0.0316] 29%|██▉       | 24/83 [10:26<24:03, 24.46s/epoch, loss=1.18, accuracy=0.745, val_loss=2.68, val_accuracy=0.388, lr=0.1]    30%|███       | 25/83 [10:50<23:36, 24.42s/epoch, loss=1.18, accuracy=0.749, val_loss=2.86, val_accuracy=0.4, lr=0.1]   31%|███▏      | 26/83 [11:15<23:10, 24.40s/epoch, loss=1.17, accuracy=0.747, val_loss=3.06, val_accuracy=0.357, lr=0.1] 33%|███▎      | 27/83 [11:40<22:56, 24.57s/epoch, loss=1.17, accuracy=0.748, val_loss=2.02, val_accuracy=0.502, lr=0.1] 34%|███▎      | 28/83 [12:05<22:38, 24.70s/epoch, loss=1.17, accuracy=0.75, val_loss=1.92, val_accuracy=0.528, lr=0.0316] 35%|███▍      | 29/83 [12:29<22:15, 24.73s/epoch, loss=1.16, accuracy=0.751, val_loss=2.3, val_accuracy=0.456, lr=0.1]    36%|███▌      | 30/83 [12:54<21:55, 24.82s/epoch, loss=1.17, accuracy=0.751, val_loss=2.57, val_accuracy=0.456, lr=0.1] 37%|███▋      | 31/83 [13:19<21:29, 24.80s/epoch, loss=1.16, accuracy=0.752, val_loss=1.78, val_accuracy=0.551, lr=0.1] 39%|███▊      | 32/83 [13:44<21:07, 24.86s/epoch, loss=1.17, accuracy=0.753, val_loss=3.85, val_accuracy=0.259, lr=0.1] 40%|███▉      | 33/83 [14:09<20:45, 24.91s/epoch, loss=1.16, accuracy=0.754, val_loss=2.09, val_accuracy=0.47, lr=0.0316] 41%|████      | 34/83 [14:35<20:27, 25.06s/epoch, loss=1.16, accuracy=0.752, val_loss=1.6, val_accuracy=0.639, lr=0.1]    42%|████▏     | 35/83 [14:59<20:00, 25.01s/epoch, loss=1.15, accuracy=0.753, val_loss=1.61, val_accuracy=0.607, lr=0.1] 43%|████▎     | 36/83 [15:25<19:35, 25.01s/epoch, loss=1.15, accuracy=0.754, val_loss=2.11, val_accuracy=0.504, lr=0.1] 45%|████▍     | 37/83 [15:49<19:07, 24.94s/epoch, loss=1.16, accuracy=0.752, val_loss=2.02, val_accuracy=0.509, lr=0.1] 46%|████▌     | 38/83 [16:14<18:39, 24.88s/epoch, loss=1.15, accuracy=0.753, val_loss=1.67, val_accuracy=0.587, lr=0.0316] 47%|████▋     | 39/83 [16:39<18:13, 24.85s/epoch, loss=1.16, accuracy=0.752, val_loss=1.72, val_accuracy=0.551, lr=0.1]    48%|████▊     | 40/83 [17:03<17:41, 24.68s/epoch, loss=1.15, accuracy=0.755, val_loss=2.15, val_accuracy=0.489, lr=0.1] 49%|████▉     | 41/83 [17:27<17:06, 24.44s/epoch, loss=1.15, accuracy=0.754, val_loss=2.52, val_accuracy=0.379, lr=0.1] 51%|█████     | 42/83 [17:52<16:43, 24.47s/epoch, loss=1.14, accuracy=0.756, val_loss=1.94, val_accuracy=0.526, lr=0.1] 52%|█████▏    | 43/83 [18:16<16:20, 24.52s/epoch, loss=1.15, accuracy=0.755, val_loss=1.66, val_accuracy=0.623, lr=0.0316] 53%|█████▎    | 44/83 [18:40<15:53, 24.45s/epoch, loss=1.14, accuracy=0.757, val_loss=3.8, val_accuracy=0.292, lr=0.1]     54%|█████▍    | 45/83 [19:05<15:29, 24.46s/epoch, loss=1.14, accuracy=0.758, val_loss=1.55, val_accuracy=0.63, lr=0.1] 55%|█████▌    | 46/83 [19:29<14:59, 24.30s/epoch, loss=1.14, accuracy=0.757, val_loss=2.04, val_accuracy=0.436, lr=0.1] 57%|█████▋    | 47/83 [19:53<14:35, 24.32s/epoch, loss=1.14, accuracy=0.755, val_loss=1.94, val_accuracy=0.553, lr=0.1] 58%|█████▊    | 48/83 [20:17<14:10, 24.29s/epoch, loss=1.13, accuracy=0.76, val_loss=1.74, val_accuracy=0.547, lr=0.1]  59%|█████▉    | 49/83 [20:42<13:48, 24.37s/epoch, loss=1.14, accuracy=0.757, val_loss=1.53, val_accuracy=0.598, lr=0.1] 60%|██████    | 50/83 [21:07<13:25, 24.42s/epoch, loss=1.14, accuracy=0.754, val_loss=2.34, val_accuracy=0.429, lr=0.1] 61%|██████▏   | 51/83 [21:31<13:00, 24.40s/epoch, loss=1.14, accuracy=0.758, val_loss=1.99, val_accuracy=0.48, lr=0.1]  63%|██████▎   | 52/83 [21:56<12:38, 24.48s/epoch, loss=1.13, accuracy=0.758, val_loss=5.57, val_accuracy=0.234, lr=0.1] 64%|██████▍   | 53/83 [22:20<12:15, 24.50s/epoch, loss=1.13, accuracy=0.756, val_loss=1.59, val_accuracy=0.591, lr=0.1] 65%|██████▌   | 54/83 [22:44<11:48, 24.44s/epoch, loss=1.13, accuracy=0.762, val_loss=1.95, val_accuracy=0.536, lr=0.0316] 66%|██████▋   | 55/83 [23:09<11:27, 24.55s/epoch, loss=1.13, accuracy=0.759, val_loss=2.61, val_accuracy=0.398, lr=0.1]    67%|██████▋   | 56/83 [23:34<11:05, 24.63s/epoch, loss=1.14, accuracy=0.756, val_loss=2.11, val_accuracy=0.445, lr=0.1] 69%|██████▊   | 57/83 [23:58<10:39, 24.58s/epoch, loss=1.13, accuracy=0.759, val_loss=1.5, val_accuracy=0.613, lr=0.1]  70%|██████▉   | 58/83 [24:22<10:08, 24.36s/epoch, loss=1.13, accuracy=0.759, val_loss=1.85, val_accuracy=0.52, lr=0.1] 71%|███████   | 59/83 [24:47<09:47, 24.48s/epoch, loss=1.13, accuracy=0.757, val_loss=1.75, val_accuracy=0.553, lr=0.1] 72%|███████▏  | 60/83 [25:11<09:22, 24.44s/epoch, loss=1.14, accuracy=0.757, val_loss=1.63, val_accuracy=0.598, lr=0.1] 73%|███████▎  | 61/83 [25:35<08:51, 24.14s/epoch, loss=1.13, accuracy=0.758, val_loss=1.67, val_accuracy=0.572, lr=0.1] 75%|███████▍  | 62/83 [25:59<08:29, 24.24s/epoch, loss=1.12, accuracy=0.759, val_loss=2.84, val_accuracy=0.395, lr=0.0316] 76%|███████▌  | 63/83 [26:24<08:06, 24.33s/epoch, loss=1.13, accuracy=0.759, val_loss=1.73, val_accuracy=0.583, lr=0.1]    77%|███████▋  | 64/83 [26:48<07:42, 24.34s/epoch, loss=1.13, accuracy=0.756, val_loss=1.71, val_accuracy=0.576, lr=0.1] 78%|███████▊  | 65/83 [27:13<07:20, 24.50s/epoch, loss=1.13, accuracy=0.76, val_loss=1.59, val_accuracy=0.594, lr=0.1]  80%|███████▉  | 66/83 [27:38<06:56, 24.47s/epoch, loss=1.12, accuracy=0.759, val_loss=3.05, val_accuracy=0.339, lr=0.1] 81%|████████  | 67/83 [28:02<06:31, 24.46s/epoch, loss=1.12, accuracy=0.76, val_loss=2.68, val_accuracy=0.357, lr=0.0316] 82%|████████▏ | 68/83 [28:25<06:01, 24.11s/epoch, loss=1.13, accuracy=0.759, val_loss=2.23, val_accuracy=0.507, lr=0.1]   83%|████████▎ | 69/83 [28:50<05:39, 24.25s/epoch, loss=1.12, accuracy=0.759, val_loss=3.03, val_accuracy=0.426, lr=0.1] 84%|████████▍ | 70/83 [29:14<05:13, 24.13s/epoch, loss=1.13, accuracy=0.758, val_loss=2.22, val_accuracy=0.452, lr=0.1] 86%|████████▌ | 71/83 [29:38<04:50, 24.20s/epoch, loss=1.12, accuracy=0.761, val_loss=1.66, val_accuracy=0.548, lr=0.1] 87%|████████▋ | 72/83 [30:02<04:26, 24.23s/epoch, loss=1.12, accuracy=0.761, val_loss=1.71, val_accuracy=0.58, lr=0.0316] 88%|████████▊ | 73/83 [30:27<04:02, 24.29s/epoch, loss=1.13, accuracy=0.762, val_loss=2.32, val_accuracy=0.379, lr=0.1]   89%|████████▉ | 74/83 [30:51<03:38, 24.28s/epoch, loss=1.12, accuracy=0.761, val_loss=2.65, val_accuracy=0.341, lr=0.1] 90%|█████████ | 75/83 [31:15<03:14, 24.28s/epoch, loss=1.12, accuracy=0.76, val_loss=2.21, val_accuracy=0.392, lr=0.1]  92%|█████████▏| 76/83 [31:40<02:50, 24.42s/epoch, loss=1.12, accuracy=0.762, val_loss=2.55, val_accuracy=0.396, lr=0.1] 93%|█████████▎| 77/83 [32:05<02:26, 24.42s/epoch, loss=1.13, accuracy=0.761, val_loss=2.01, val_accuracy=0.515, lr=0.0316] 94%|█████████▍| 78/83 [32:29<02:02, 24.42s/epoch, loss=1.12, accuracy=0.761, val_loss=2.02, val_accuracy=0.443, lr=0.1]    95%|█████████▌| 79/83 [32:53<01:37, 24.44s/epoch, loss=1.12, accuracy=0.762, val_loss=1.57, val_accuracy=0.607, lr=0.1] 96%|█████████▋| 80/83 [33:18<01:13, 24.41s/epoch, loss=1.13, accuracy=0.758, val_loss=2.56, val_accuracy=0.486, lr=0.1] 98%|█████████▊| 81/83 [33:42<00:48, 24.48s/epoch, loss=1.12, accuracy=0.759, val_loss=1.98, val_accuracy=0.46, lr=0.1]  99%|█████████▉| 82/83 [34:07<00:24, 24.53s/epoch, loss=0.919, accuracy=0.817, val_loss=0.909, val_accuracy=0.803, lr=0.01]100%|██████████| 83/83 [34:31<00:00, 24.33s/epoch, loss=0.728, accuracy=0.852, val_loss=0.778, val_accuracy=0.825, lr=0.01]100%|██████████| 83/83 [34:31<00:00, 24.96s/epoch, loss=0.728, accuracy=0.852, val_loss=0.778, val_accuracy=0.825, lr=0.01]
Using real-time data augmentation.
Test loss: 0.7779631614685059
Test accuracy: 0.824999988079071


* * * Run SGD for ID = 18_11. * * *


2024-02-15 19:48:57.513867: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 19:49:00.803749: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 19:49:00.805034: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-15 19:49:00.842183: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 19:49:00.842219: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 19:49:00.844952: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 19:49:00.844995: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 19:49:00.847181: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 19:49:00.848198: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 19:49:00.850717: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 19:49:00.852304: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 19:49:00.857605: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 19:49:00.858173: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 19:49:00.858253: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 19:49:02.175244: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-15 19:49:02.175820: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 19:49:02.176262: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 19:49:02.176294: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 19:49:02.176328: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 19:49:02.176347: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 19:49:02.176365: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 19:49:02.176384: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 19:49:02.176402: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 19:49:02.176421: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 19:49:02.176440: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 19:49:02.176886: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 19:49:02.176921: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 19:49:02.859677: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-15 19:49:02.859732: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-15 19:49:02.859742: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-15 19:49:02.860603: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:03:00.0, compute capability: 6.1)
{'id': 1811, 'batch_size': 128, 'epochs': 83, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/83 [00:00<?, ?epoch/s]2024-02-15 19:49:03.674973: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-15 19:49:03.686713: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2200060000 Hz
2024-02-15 19:49:05.753030: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 19:49:06.070300: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 19:49:07.068027: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-15 19:49:07.129952: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/83 [00:57<1:17:58, 57.06s/epoch, loss=3.16, accuracy=0.278, val_loss=2.58, val_accuracy=0.204, lr=0.1]  2%|▏         | 2/83 [01:21<51:23, 38.07s/epoch, loss=1.59, accuracy=0.515, val_loss=2.13, val_accuracy=0.421, lr=0.1]    4%|▎         | 3/83 [01:47<43:06, 32.33s/epoch, loss=1.34, accuracy=0.644, val_loss=1.61, val_accuracy=0.555, lr=0.1]  5%|▍         | 4/83 [02:12<38:58, 29.60s/epoch, loss=1.27, accuracy=0.682, val_loss=2.16, val_accuracy=0.397, lr=0.1]  6%|▌         | 5/83 [02:38<36:28, 28.05s/epoch, loss=1.25, accuracy=0.7, val_loss=2.59, val_accuracy=0.43, lr=0.1]     7%|▋         | 6/83 [03:03<34:55, 27.21s/epoch, loss=1.22, accuracy=0.714, val_loss=1.64, val_accuracy=0.58, lr=0.1]  8%|▊         | 7/83 [03:29<33:43, 26.62s/epoch, loss=1.22, accuracy=0.721, val_loss=2.2, val_accuracy=0.501, lr=0.1] 10%|▉         | 8/83 [03:54<32:43, 26.18s/epoch, loss=1.21, accuracy=0.726, val_loss=2.24, val_accuracy=0.369, lr=0.0316] 11%|█         | 9/83 [04:19<32:03, 26.00s/epoch, loss=1.2, accuracy=0.727, val_loss=1.71, val_accuracy=0.547, lr=0.1]     12%|█▏        | 10/83 [04:44<31:08, 25.59s/epoch, loss=1.2, accuracy=0.727, val_loss=1.63, val_accuracy=0.601, lr=0.1] 13%|█▎        | 11/83 [05:09<30:35, 25.49s/epoch, loss=1.19, accuracy=0.732, val_loss=1.66, val_accuracy=0.561, lr=0.1] 14%|█▍        | 12/83 [05:35<30:07, 25.46s/epoch, loss=1.18, accuracy=0.735, val_loss=1.59, val_accuracy=0.61, lr=0.1]  16%|█▌        | 13/83 [06:00<29:37, 25.40s/epoch, loss=1.18, accuracy=0.735, val_loss=1.57, val_accuracy=0.612, lr=0.1] 17%|█▋        | 14/83 [06:25<29:04, 25.28s/epoch, loss=1.17, accuracy=0.739, val_loss=2.94, val_accuracy=0.389, lr=0.1] 18%|█▊        | 15/83 [06:50<28:42, 25.34s/epoch, loss=1.17, accuracy=0.741, val_loss=1.77, val_accuracy=0.533, lr=0.1] 19%|█▉        | 16/83 [07:16<28:24, 25.44s/epoch, loss=1.17, accuracy=0.741, val_loss=1.97, val_accuracy=0.518, lr=0.1] 20%|██        | 17/83 [07:42<28:02, 25.49s/epoch, loss=1.16, accuracy=0.744, val_loss=2.71, val_accuracy=0.427, lr=0.1] 22%|██▏       | 18/83 [08:06<27:20, 25.24s/epoch, loss=1.16, accuracy=0.744, val_loss=2.59, val_accuracy=0.407, lr=0.0316] 23%|██▎       | 19/83 [08:31<26:39, 25.00s/epoch, loss=1.16, accuracy=0.745, val_loss=1.67, val_accuracy=0.571, lr=0.1]    24%|██▍       | 20/83 [08:56<26:16, 25.03s/epoch, loss=1.16, accuracy=0.746, val_loss=1.78, val_accuracy=0.57, lr=0.1]  25%|██▌       | 21/83 [09:21<25:59, 25.15s/epoch, loss=1.15, accuracy=0.747, val_loss=1.54, val_accuracy=0.598, lr=0.1] 27%|██▋       | 22/83 [09:47<25:38, 25.22s/epoch, loss=1.15, accuracy=0.747, val_loss=1.72, val_accuracy=0.565, lr=0.1] 28%|██▊       | 23/83 [10:12<25:13, 25.23s/epoch, loss=1.14, accuracy=0.75, val_loss=2.12, val_accuracy=0.466, lr=0.1]  29%|██▉       | 24/83 [10:37<24:47, 25.21s/epoch, loss=1.15, accuracy=0.75, val_loss=2.06, val_accuracy=0.465, lr=0.1] 30%|███       | 25/83 [11:02<24:22, 25.22s/epoch, loss=1.15, accuracy=0.751, val_loss=1.78, val_accuracy=0.554, lr=0.1] 31%|███▏      | 26/83 [11:27<23:43, 24.98s/epoch, loss=1.14, accuracy=0.75, val_loss=1.65, val_accuracy=0.582, lr=0.0316] 33%|███▎      | 27/83 [11:52<23:22, 25.04s/epoch, loss=1.14, accuracy=0.751, val_loss=1.7, val_accuracy=0.584, lr=0.1]    34%|███▎      | 28/83 [12:17<23:02, 25.13s/epoch, loss=1.14, accuracy=0.753, val_loss=2.64, val_accuracy=0.38, lr=0.1] 35%|███▍      | 29/83 [12:43<22:42, 25.22s/epoch, loss=1.15, accuracy=0.754, val_loss=2.66, val_accuracy=0.503, lr=0.1] 36%|███▌      | 30/83 [13:09<22:24, 25.38s/epoch, loss=1.14, accuracy=0.752, val_loss=1.62, val_accuracy=0.634, lr=0.1] 37%|███▋      | 31/83 [13:34<21:59, 25.38s/epoch, loss=1.14, accuracy=0.751, val_loss=1.68, val_accuracy=0.573, lr=0.0316] 39%|███▊      | 32/83 [13:59<21:33, 25.37s/epoch, loss=1.14, accuracy=0.755, val_loss=1.9, val_accuracy=0.496, lr=0.1]     40%|███▉      | 33/83 [14:24<21:04, 25.30s/epoch, loss=1.14, accuracy=0.752, val_loss=1.88, val_accuracy=0.545, lr=0.1] 41%|████      | 34/83 [14:49<20:34, 25.19s/epoch, loss=1.14, accuracy=0.754, val_loss=1.66, val_accuracy=0.577, lr=0.1] 42%|████▏     | 35/83 [15:15<20:08, 25.18s/epoch, loss=1.14, accuracy=0.755, val_loss=2.63, val_accuracy=0.425, lr=0.1] 43%|████▎     | 36/83 [15:39<19:27, 24.84s/epoch, loss=1.13, accuracy=0.755, val_loss=3.5, val_accuracy=0.375, lr=0.0316] 45%|████▍     | 37/83 [16:04<19:08, 24.98s/epoch, loss=1.13, accuracy=0.757, val_loss=1.56, val_accuracy=0.61, lr=0.1]    46%|████▌     | 38/83 [16:29<18:44, 24.99s/epoch, loss=1.13, accuracy=0.756, val_loss=3.56, val_accuracy=0.35, lr=0.1] 47%|████▋     | 39/83 [16:54<18:20, 25.01s/epoch, loss=1.14, accuracy=0.754, val_loss=1.53, val_accuracy=0.625, lr=0.1] 48%|████▊     | 40/83 [17:19<17:57, 25.06s/epoch, loss=1.13, accuracy=0.757, val_loss=1.53, val_accuracy=0.605, lr=0.1] 49%|████▉     | 41/83 [17:44<17:35, 25.14s/epoch, loss=1.13, accuracy=0.757, val_loss=2.37, val_accuracy=0.497, lr=0.1] 51%|█████     | 42/83 [18:10<17:11, 25.17s/epoch, loss=1.14, accuracy=0.755, val_loss=1.35, val_accuracy=0.675, lr=0.1] 52%|█████▏    | 43/83 [18:35<16:45, 25.13s/epoch, loss=1.13, accuracy=0.754, val_loss=1.56, val_accuracy=0.62, lr=0.1]  53%|█████▎    | 44/83 [19:00<16:17, 25.06s/epoch, loss=1.13, accuracy=0.755, val_loss=1.65, val_accuracy=0.571, lr=0.1] 54%|█████▍    | 45/83 [19:24<15:39, 24.72s/epoch, loss=1.12, accuracy=0.755, val_loss=1.5, val_accuracy=0.637, lr=0.1]  55%|█████▌    | 46/83 [19:48<15:16, 24.76s/epoch, loss=1.13, accuracy=0.756, val_loss=1.78, val_accuracy=0.568, lr=0.1] 57%|█████▋    | 47/83 [20:13<14:52, 24.80s/epoch, loss=1.13, accuracy=0.755, val_loss=1.98, val_accuracy=0.545, lr=0.0316] 58%|█████▊    | 48/83 [20:38<14:29, 24.83s/epoch, loss=1.13, accuracy=0.753, val_loss=1.95, val_accuracy=0.485, lr=0.1]    59%|█████▉    | 49/83 [21:03<14:03, 24.82s/epoch, loss=1.13, accuracy=0.754, val_loss=2.05, val_accuracy=0.49, lr=0.1]  60%|██████    | 50/83 [21:28<13:41, 24.89s/epoch, loss=1.12, accuracy=0.756, val_loss=3.49, val_accuracy=0.248, lr=0.1] 61%|██████▏   | 51/83 [21:53<13:17, 24.93s/epoch, loss=1.13, accuracy=0.754, val_loss=2.66, val_accuracy=0.421, lr=0.1] 63%|██████▎   | 52/83 [22:17<12:45, 24.71s/epoch, loss=1.13, accuracy=0.755, val_loss=1.62, val_accuracy=0.603, lr=0.0316] 64%|██████▍   | 53/83 [22:42<12:24, 24.81s/epoch, loss=1.13, accuracy=0.756, val_loss=2.39, val_accuracy=0.456, lr=0.1]    65%|██████▌   | 54/83 [23:07<12:02, 24.91s/epoch, loss=1.12, accuracy=0.756, val_loss=2.35, val_accuracy=0.487, lr=0.1] 66%|██████▋   | 55/83 [23:33<11:40, 25.00s/epoch, loss=1.12, accuracy=0.756, val_loss=1.42, val_accuracy=0.648, lr=0.1] 67%|██████▋   | 56/83 [23:58<11:15, 25.02s/epoch, loss=1.12, accuracy=0.754, val_loss=1.64, val_accuracy=0.568, lr=0.1] 69%|██████▊   | 57/83 [24:23<10:50, 25.03s/epoch, loss=1.12, accuracy=0.758, val_loss=1.77, val_accuracy=0.546, lr=0.0316] 70%|██████▉   | 58/83 [24:48<10:25, 25.01s/epoch, loss=1.11, accuracy=0.761, val_loss=2.02, val_accuracy=0.441, lr=0.1]    71%|███████   | 59/83 [25:12<09:58, 24.94s/epoch, loss=1.12, accuracy=0.757, val_loss=2.01, val_accuracy=0.47, lr=0.1]  72%|███████▏  | 60/83 [25:37<09:33, 24.96s/epoch, loss=1.12, accuracy=0.756, val_loss=2.2, val_accuracy=0.471, lr=0.1] 73%|███████▎  | 61/83 [26:03<09:12, 25.10s/epoch, loss=1.11, accuracy=0.759, val_loss=2.36, val_accuracy=0.46, lr=0.1] 75%|███████▍  | 62/83 [26:29<08:50, 25.26s/epoch, loss=1.12, accuracy=0.755, val_loss=1.54, val_accuracy=0.647, lr=0.0316] 76%|███████▌  | 63/83 [26:54<08:25, 25.28s/epoch, loss=1.11, accuracy=0.758, val_loss=1.83, val_accuracy=0.506, lr=0.1]    77%|███████▋  | 64/83 [27:19<07:58, 25.21s/epoch, loss=1.11, accuracy=0.757, val_loss=1.98, val_accuracy=0.534, lr=0.1] 78%|███████▊  | 65/83 [27:44<07:33, 25.21s/epoch, loss=1.11, accuracy=0.758, val_loss=2.22, val_accuracy=0.43, lr=0.1]  80%|███████▉  | 66/83 [28:09<07:09, 25.24s/epoch, loss=1.11, accuracy=0.758, val_loss=1.78, val_accuracy=0.536, lr=0.1] 81%|████████  | 67/83 [28:34<06:42, 25.15s/epoch, loss=1.11, accuracy=0.757, val_loss=1.55, val_accuracy=0.606, lr=0.0316] 82%|████████▏ | 68/83 [28:59<06:13, 24.92s/epoch, loss=1.11, accuracy=0.758, val_loss=1.61, val_accuracy=0.59, lr=0.1]     83%|████████▎ | 69/83 [29:24<05:48, 24.92s/epoch, loss=1.11, accuracy=0.76, val_loss=1.75, val_accuracy=0.573, lr=0.1] 84%|████████▍ | 70/83 [29:49<05:24, 24.98s/epoch, loss=1.11, accuracy=0.757, val_loss=2.15, val_accuracy=0.45, lr=0.1] 86%|████████▌ | 71/83 [30:14<04:58, 24.90s/epoch, loss=1.11, accuracy=0.758, val_loss=2.24, val_accuracy=0.415, lr=0.1] 87%|████████▋ | 72/83 [30:38<04:30, 24.63s/epoch, loss=1.11, accuracy=0.758, val_loss=2.06, val_accuracy=0.486, lr=0.0316] 88%|████████▊ | 73/83 [31:02<04:07, 24.72s/epoch, loss=1.11, accuracy=0.758, val_loss=2.09, val_accuracy=0.472, lr=0.1]    89%|████████▉ | 74/83 [31:27<03:43, 24.79s/epoch, loss=1.11, accuracy=0.758, val_loss=1.44, val_accuracy=0.655, lr=0.1] 90%|█████████ | 75/83 [31:51<03:16, 24.52s/epoch, loss=1.11, accuracy=0.76, val_loss=1.9, val_accuracy=0.488, lr=0.1]   92%|█████████▏| 76/83 [32:16<02:52, 24.66s/epoch, loss=1.11, accuracy=0.759, val_loss=1.59, val_accuracy=0.598, lr=0.1] 93%|█████████▎| 77/83 [32:41<02:28, 24.80s/epoch, loss=1.11, accuracy=0.76, val_loss=2.43, val_accuracy=0.38, lr=0.0316] 94%|█████████▍| 78/83 [33:07<02:04, 24.92s/epoch, loss=1.12, accuracy=0.756, val_loss=1.85, val_accuracy=0.527, lr=0.1]  95%|█████████▌| 79/83 [33:32<01:39, 24.94s/epoch, loss=1.12, accuracy=0.756, val_loss=1.61, val_accuracy=0.586, lr=0.1] 96%|█████████▋| 80/83 [33:56<01:14, 24.90s/epoch, loss=1.11, accuracy=0.757, val_loss=1.61, val_accuracy=0.581, lr=0.1] 98%|█████████▊| 81/83 [34:21<00:49, 24.81s/epoch, loss=1.11, accuracy=0.759, val_loss=2.88, val_accuracy=0.41, lr=0.1]  99%|█████████▉| 82/83 [34:46<00:24, 24.76s/epoch, loss=0.911, accuracy=0.815, val_loss=0.844, val_accuracy=0.822, lr=0.01]100%|██████████| 83/83 [35:10<00:00, 24.59s/epoch, loss=0.731, accuracy=0.846, val_loss=0.75, val_accuracy=0.829, lr=0.01] 100%|██████████| 83/83 [35:10<00:00, 25.43s/epoch, loss=0.731, accuracy=0.846, val_loss=0.75, val_accuracy=0.829, lr=0.01]
Using real-time data augmentation.
Test loss: 0.7498890161514282
Test accuracy: 0.8292999863624573


* * * Run SGD for ID = 18_12. * * *


2024-02-15 20:24:16.369262: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 20:24:19.433349: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 20:24:19.434569: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-15 20:24:19.476181: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 20:24:19.476217: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 20:24:19.479343: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 20:24:19.479390: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 20:24:19.481810: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 20:24:19.482537: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 20:24:19.484999: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 20:24:19.486509: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 20:24:19.491306: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 20:24:19.491811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 20:24:19.492068: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 20:24:20.784806: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-15 20:24:20.785375: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 20:24:20.785990: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 20:24:20.786024: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 20:24:20.786059: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 20:24:20.786077: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 20:24:20.786094: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 20:24:20.786110: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 20:24:20.786127: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 20:24:20.786144: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 20:24:20.786171: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 20:24:20.786571: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 20:24:20.786632: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 20:24:21.453310: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-15 20:24:21.453364: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-15 20:24:21.453375: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-15 20:24:21.454274: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:03:00.0, compute capability: 6.1)
{'id': 1812, 'batch_size': 128, 'epochs': 83, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/83 [00:00<?, ?epoch/s]2024-02-15 20:24:22.273431: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-15 20:24:22.285719: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2200060000 Hz
2024-02-15 20:24:24.407579: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 20:24:24.693871: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 20:24:25.717803: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-15 20:24:25.786306: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/83 [01:15<1:43:08, 75.47s/epoch, loss=3.15, accuracy=0.284, val_loss=2.29, val_accuracy=0.275, lr=0.1]  2%|▏         | 2/83 [01:40<1:01:39, 45.67s/epoch, loss=1.65, accuracy=0.481, val_loss=2.27, val_accuracy=0.34, lr=0.1]   4%|▎         | 3/83 [02:05<48:19, 36.24s/epoch, loss=1.42, accuracy=0.592, val_loss=2.01, val_accuracy=0.45, lr=0.1]    5%|▍         | 4/83 [02:29<41:32, 31.55s/epoch, loss=1.31, accuracy=0.661, val_loss=2.07, val_accuracy=0.427, lr=0.1]  6%|▌         | 5/83 [02:54<37:54, 29.16s/epoch, loss=1.26, accuracy=0.688, val_loss=1.64, val_accuracy=0.551, lr=0.1]  7%|▋         | 6/83 [03:20<35:47, 27.89s/epoch, loss=1.24, accuracy=0.707, val_loss=1.62, val_accuracy=0.592, lr=0.1]  8%|▊         | 7/83 [03:45<34:12, 27.00s/epoch, loss=1.22, accuracy=0.715, val_loss=1.88, val_accuracy=0.525, lr=0.1] 10%|▉         | 8/83 [04:10<32:55, 26.34s/epoch, loss=1.21, accuracy=0.722, val_loss=7.6, val_accuracy=0.26, lr=0.1]   11%|█         | 9/83 [04:35<32:03, 26.00s/epoch, loss=1.21, accuracy=0.726, val_loss=1.94, val_accuracy=0.476, lr=0.1] 12%|█▏        | 10/83 [05:00<31:11, 25.64s/epoch, loss=1.21, accuracy=0.729, val_loss=2.13, val_accuracy=0.498, lr=0.1] 13%|█▎        | 11/83 [05:25<30:38, 25.53s/epoch, loss=1.2, accuracy=0.73, val_loss=2.83, val_accuracy=0.359, lr=0.0316] 14%|█▍        | 12/83 [05:50<30:02, 25.39s/epoch, loss=1.2, accuracy=0.734, val_loss=3.63, val_accuracy=0.408, lr=0.1]   16%|█▌        | 13/83 [06:15<29:19, 25.13s/epoch, loss=1.19, accuracy=0.736, val_loss=2.5, val_accuracy=0.454, lr=0.1] 17%|█▋        | 14/83 [06:40<29:00, 25.22s/epoch, loss=1.2, accuracy=0.737, val_loss=1.69, val_accuracy=0.574, lr=0.1] 18%|█▊        | 15/83 [07:05<28:39, 25.28s/epoch, loss=1.19, accuracy=0.737, val_loss=1.76, val_accuracy=0.577, lr=0.1] 19%|█▉        | 16/83 [07:31<28:15, 25.31s/epoch, loss=1.19, accuracy=0.739, val_loss=1.76, val_accuracy=0.537, lr=0.0316] 20%|██        | 17/83 [07:56<27:53, 25.36s/epoch, loss=1.19, accuracy=0.739, val_loss=1.9, val_accuracy=0.552, lr=0.1]     22%|██▏       | 18/83 [08:21<27:16, 25.18s/epoch, loss=1.17, accuracy=0.744, val_loss=2.98, val_accuracy=0.288, lr=0.1] 23%|██▎       | 19/83 [08:46<26:51, 25.18s/epoch, loss=1.18, accuracy=0.742, val_loss=2.22, val_accuracy=0.483, lr=0.1] 24%|██▍       | 20/83 [09:11<26:24, 25.14s/epoch, loss=1.17, accuracy=0.743, val_loss=1.99, val_accuracy=0.502, lr=0.1] 25%|██▌       | 21/83 [09:36<25:54, 25.08s/epoch, loss=1.17, accuracy=0.744, val_loss=1.65, val_accuracy=0.572, lr=0.0316] 27%|██▋       | 22/83 [10:02<25:34, 25.15s/epoch, loss=1.17, accuracy=0.744, val_loss=4.49, val_accuracy=0.284, lr=0.1]    28%|██▊       | 23/83 [10:26<25:00, 25.01s/epoch, loss=1.17, accuracy=0.745, val_loss=1.8, val_accuracy=0.576, lr=0.1]  29%|██▉       | 24/83 [10:51<24:33, 24.97s/epoch, loss=1.16, accuracy=0.745, val_loss=2.04, val_accuracy=0.533, lr=0.1] 30%|███       | 25/83 [11:16<24:15, 25.09s/epoch, loss=1.16, accuracy=0.749, val_loss=1.56, val_accuracy=0.612, lr=0.1] 31%|███▏      | 26/83 [11:41<23:43, 24.98s/epoch, loss=1.16, accuracy=0.749, val_loss=1.73, val_accuracy=0.557, lr=0.1] 33%|███▎      | 27/83 [12:06<23:21, 25.03s/epoch, loss=1.16, accuracy=0.746, val_loss=2.02, val_accuracy=0.506, lr=0.1] 34%|███▎      | 28/83 [12:32<23:01, 25.11s/epoch, loss=1.16, accuracy=0.748, val_loss=1.47, val_accuracy=0.651, lr=0.1] 35%|███▍      | 29/83 [12:57<22:38, 25.16s/epoch, loss=1.16, accuracy=0.75, val_loss=1.99, val_accuracy=0.437, lr=0.1]  36%|███▌      | 30/83 [13:23<22:20, 25.30s/epoch, loss=1.16, accuracy=0.746, val_loss=1.5, val_accuracy=0.614, lr=0.1] 37%|███▋      | 31/83 [13:48<22:00, 25.39s/epoch, loss=1.15, accuracy=0.748, val_loss=1.58, val_accuracy=0.596, lr=0.1] 39%|███▊      | 32/83 [14:13<21:27, 25.25s/epoch, loss=1.15, accuracy=0.747, val_loss=3.66, val_accuracy=0.343, lr=0.1] 40%|███▉      | 33/83 [14:38<21:04, 25.29s/epoch, loss=1.15, accuracy=0.747, val_loss=1.89, val_accuracy=0.529, lr=0.0316] 41%|████      | 34/83 [15:04<20:41, 25.33s/epoch, loss=1.14, accuracy=0.753, val_loss=1.65, val_accuracy=0.576, lr=0.1]    42%|████▏     | 35/83 [15:29<20:12, 25.27s/epoch, loss=1.15, accuracy=0.751, val_loss=1.92, val_accuracy=0.516, lr=0.1] 43%|████▎     | 36/83 [15:54<19:48, 25.29s/epoch, loss=1.15, accuracy=0.752, val_loss=2.83, val_accuracy=0.299, lr=0.1] 45%|████▍     | 37/83 [16:19<19:21, 25.25s/epoch, loss=1.15, accuracy=0.752, val_loss=2.11, val_accuracy=0.476, lr=0.1] 46%|████▌     | 38/83 [16:44<18:52, 25.16s/epoch, loss=1.15, accuracy=0.751, val_loss=1.7, val_accuracy=0.549, lr=0.0316] 47%|████▋     | 39/83 [17:10<18:29, 25.21s/epoch, loss=1.15, accuracy=0.751, val_loss=1.42, val_accuracy=0.645, lr=0.1]   48%|████▊     | 40/83 [17:34<17:47, 24.82s/epoch, loss=1.14, accuracy=0.752, val_loss=3.43, val_accuracy=0.241, lr=0.1] 49%|████▉     | 41/83 [17:59<17:25, 24.88s/epoch, loss=1.15, accuracy=0.751, val_loss=1.61, val_accuracy=0.57, lr=0.1]  51%|█████     | 42/83 [18:23<16:58, 24.83s/epoch, loss=1.15, accuracy=0.754, val_loss=3.38, val_accuracy=0.384, lr=0.1] 52%|█████▏    | 43/83 [18:48<16:35, 24.89s/epoch, loss=1.14, accuracy=0.752, val_loss=1.62, val_accuracy=0.593, lr=0.1] 53%|█████▎    | 44/83 [19:14<16:13, 24.97s/epoch, loss=1.15, accuracy=0.75, val_loss=1.8, val_accuracy=0.538, lr=0.0316] 54%|█████▍    | 45/83 [19:38<15:46, 24.91s/epoch, loss=1.14, accuracy=0.756, val_loss=1.92, val_accuracy=0.536, lr=0.1]  55%|█████▌    | 46/83 [20:03<15:20, 24.87s/epoch, loss=1.14, accuracy=0.752, val_loss=2.2, val_accuracy=0.451, lr=0.1]  57%|█████▋    | 47/83 [20:28<14:55, 24.89s/epoch, loss=1.14, accuracy=0.756, val_loss=1.96, val_accuracy=0.538, lr=0.1] 58%|█████▊    | 48/83 [20:52<14:26, 24.75s/epoch, loss=1.15, accuracy=0.754, val_loss=1.84, val_accuracy=0.484, lr=0.1] 59%|█████▉    | 49/83 [21:17<14:02, 24.78s/epoch, loss=1.15, accuracy=0.751, val_loss=1.75, val_accuracy=0.549, lr=0.0316] 60%|██████    | 50/83 [21:42<13:40, 24.87s/epoch, loss=1.15, accuracy=0.752, val_loss=2.14, val_accuracy=0.47, lr=0.1]     61%|██████▏   | 51/83 [22:08<13:20, 25.01s/epoch, loss=1.13, accuracy=0.753, val_loss=1.8, val_accuracy=0.529, lr=0.1] 63%|██████▎   | 52/83 [22:33<12:54, 24.98s/epoch, loss=1.14, accuracy=0.753, val_loss=1.66, val_accuracy=0.585, lr=0.1] 64%|██████▍   | 53/83 [22:58<12:32, 25.08s/epoch, loss=1.13, accuracy=0.756, val_loss=1.9, val_accuracy=0.534, lr=0.1]  65%|██████▌   | 54/83 [23:23<12:09, 25.15s/epoch, loss=1.14, accuracy=0.756, val_loss=3.02, val_accuracy=0.396, lr=0.0316] 66%|██████▋   | 55/83 [23:48<11:44, 25.15s/epoch, loss=1.14, accuracy=0.752, val_loss=1.64, val_accuracy=0.592, lr=0.1]    67%|██████▋   | 56/83 [24:14<11:19, 25.16s/epoch, loss=1.14, accuracy=0.753, val_loss=2.23, val_accuracy=0.517, lr=0.1] 69%|██████▊   | 57/83 [24:39<10:54, 25.19s/epoch, loss=1.13, accuracy=0.755, val_loss=2.02, val_accuracy=0.496, lr=0.1] 70%|██████▉   | 58/83 [25:04<10:28, 25.14s/epoch, loss=1.14, accuracy=0.753, val_loss=2.1, val_accuracy=0.43, lr=0.1]   71%|███████   | 59/83 [25:29<10:02, 25.10s/epoch, loss=1.13, accuracy=0.755, val_loss=2.46, val_accuracy=0.433, lr=0.0316] 72%|███████▏  | 60/83 [25:54<09:37, 25.09s/epoch, loss=1.13, accuracy=0.754, val_loss=2.16, val_accuracy=0.468, lr=0.1]    73%|███████▎  | 61/83 [26:19<09:12, 25.11s/epoch, loss=1.13, accuracy=0.756, val_loss=2.47, val_accuracy=0.292, lr=0.1] 75%|███████▍  | 62/83 [26:44<08:46, 25.06s/epoch, loss=1.13, accuracy=0.757, val_loss=2.42, val_accuracy=0.488, lr=0.1] 76%|███████▌  | 63/83 [27:09<08:21, 25.10s/epoch, loss=1.12, accuracy=0.755, val_loss=2.54, val_accuracy=0.38, lr=0.1]  77%|███████▋  | 64/83 [27:34<07:57, 25.12s/epoch, loss=1.12, accuracy=0.756, val_loss=2.09, val_accuracy=0.468, lr=0.0316] 78%|███████▊  | 65/83 [27:59<07:27, 24.87s/epoch, loss=1.13, accuracy=0.755, val_loss=1.82, val_accuracy=0.562, lr=0.1]    80%|███████▉  | 66/83 [28:24<07:03, 24.89s/epoch, loss=1.13, accuracy=0.753, val_loss=1.48, val_accuracy=0.621, lr=0.1] 81%|████████  | 67/83 [28:49<06:37, 24.87s/epoch, loss=1.12, accuracy=0.755, val_loss=2.49, val_accuracy=0.411, lr=0.1] 82%|████████▏ | 68/83 [29:13<06:12, 24.85s/epoch, loss=1.12, accuracy=0.757, val_loss=1.63, val_accuracy=0.59, lr=0.1]  83%|████████▎ | 69/83 [29:37<05:44, 24.60s/epoch, loss=1.13, accuracy=0.757, val_loss=5.36, val_accuracy=0.191, lr=0.0316] 84%|████████▍ | 70/83 [30:02<05:19, 24.60s/epoch, loss=1.13, accuracy=0.755, val_loss=1.45, val_accuracy=0.637, lr=0.1]    86%|████████▌ | 71/83 [30:26<04:53, 24.48s/epoch, loss=1.12, accuracy=0.757, val_loss=2.96, val_accuracy=0.405, lr=0.1] 87%|████████▋ | 72/83 [30:51<04:30, 24.59s/epoch, loss=1.13, accuracy=0.755, val_loss=1.69, val_accuracy=0.608, lr=0.1] 88%|████████▊ | 73/83 [31:16<04:06, 24.61s/epoch, loss=1.12, accuracy=0.755, val_loss=2.17, val_accuracy=0.52, lr=0.1]  89%|████████▉ | 74/83 [31:40<03:42, 24.68s/epoch, loss=1.12, accuracy=0.755, val_loss=1.43, val_accuracy=0.649, lr=0.0316] 90%|█████████ | 75/83 [32:06<03:18, 24.86s/epoch, loss=1.12, accuracy=0.76, val_loss=2.35, val_accuracy=0.376, lr=0.1]     92%|█████████▏| 76/83 [32:31<02:54, 24.88s/epoch, loss=1.12, accuracy=0.755, val_loss=2.5, val_accuracy=0.396, lr=0.1] 93%|█████████▎| 77/83 [32:55<02:28, 24.70s/epoch, loss=1.12, accuracy=0.759, val_loss=1.69, val_accuracy=0.573, lr=0.1] 94%|█████████▍| 78/83 [33:19<02:02, 24.54s/epoch, loss=1.12, accuracy=0.756, val_loss=1.79, val_accuracy=0.553, lr=0.1] 95%|█████████▌| 79/83 [33:44<01:38, 24.58s/epoch, loss=1.12, accuracy=0.758, val_loss=1.99, val_accuracy=0.497, lr=0.0316] 96%|█████████▋| 80/83 [34:08<01:13, 24.60s/epoch, loss=1.11, accuracy=0.757, val_loss=2.68, val_accuracy=0.471, lr=0.1]    98%|█████████▊| 81/83 [34:33<00:48, 24.44s/epoch, loss=1.12, accuracy=0.754, val_loss=1.67, val_accuracy=0.584, lr=0.1] 99%|█████████▉| 82/83 [34:57<00:24, 24.47s/epoch, loss=0.908, accuracy=0.818, val_loss=0.92, val_accuracy=0.794, lr=0.01]100%|██████████| 83/83 [35:22<00:00, 24.52s/epoch, loss=0.729, accuracy=0.849, val_loss=0.81, val_accuracy=0.806, lr=0.01]100%|██████████| 83/83 [35:22<00:00, 25.57s/epoch, loss=0.729, accuracy=0.849, val_loss=0.81, val_accuracy=0.806, lr=0.01]
Using real-time data augmentation.
Test loss: 0.8095642328262329
Test accuracy: 0.8057000041007996


* * * Run SGD for ID = 18_13. * * *


2024-02-15 20:59:46.923737: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 20:59:49.823856: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 20:59:49.824969: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-15 20:59:49.861929: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 20:59:49.861965: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 20:59:49.864772: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 20:59:49.864816: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 20:59:49.867045: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 20:59:49.867855: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 20:59:49.870311: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 20:59:49.871926: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 20:59:49.876865: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 20:59:49.877420: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 20:59:49.877499: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 20:59:51.140007: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-15 20:59:51.140981: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 20:59:51.141434: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 20:59:51.141464: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 20:59:51.141497: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 20:59:51.141514: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 20:59:51.141530: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 20:59:51.141546: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 20:59:51.141562: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 20:59:51.141578: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 20:59:51.141639: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 20:59:51.142110: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 20:59:51.142143: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 20:59:51.839512: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-15 20:59:51.839588: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-15 20:59:51.839599: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-15 20:59:51.840504: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:03:00.0, compute capability: 6.1)
{'id': 1813, 'batch_size': 128, 'epochs': 83, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/83 [00:00<?, ?epoch/s]2024-02-15 20:59:52.653551: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-15 20:59:52.665717: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2200060000 Hz
2024-02-15 20:59:54.736829: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 20:59:54.973128: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 20:59:55.726925: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-15 20:59:55.776959: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/83 [01:00<1:22:20, 60.25s/epoch, loss=3.51, accuracy=0.321, val_loss=3.02, val_accuracy=0.224, lr=0.1]  2%|▏         | 2/83 [01:25<53:51, 39.89s/epoch, loss=1.58, accuracy=0.526, val_loss=2.02, val_accuracy=0.397, lr=0.1]    4%|▎         | 3/83 [01:51<44:33, 33.42s/epoch, loss=1.35, accuracy=0.635, val_loss=2.08, val_accuracy=0.448, lr=0.1]  5%|▍         | 4/83 [02:17<39:50, 30.26s/epoch, loss=1.28, accuracy=0.678, val_loss=2.27, val_accuracy=0.453, lr=0.1]  6%|▌         | 5/83 [02:42<36:59, 28.46s/epoch, loss=1.25, accuracy=0.697, val_loss=1.86, val_accuracy=0.502, lr=0.1]  7%|▋         | 6/83 [03:07<35:02, 27.30s/epoch, loss=1.24, accuracy=0.711, val_loss=1.89, val_accuracy=0.467, lr=0.1]  8%|▊         | 7/83 [03:32<33:45, 26.65s/epoch, loss=1.23, accuracy=0.716, val_loss=2.18, val_accuracy=0.394, lr=0.1] 10%|▉         | 8/83 [03:57<32:24, 25.92s/epoch, loss=1.22, accuracy=0.722, val_loss=2.81, val_accuracy=0.276, lr=0.1] 11%|█         | 9/83 [04:22<31:45, 25.75s/epoch, loss=1.21, accuracy=0.724, val_loss=2.55, val_accuracy=0.456, lr=0.1] 12%|█▏        | 10/83 [04:47<31:04, 25.55s/epoch, loss=1.21, accuracy=0.729, val_loss=1.56, val_accuracy=0.612, lr=0.1] 13%|█▎        | 11/83 [05:12<30:33, 25.46s/epoch, loss=1.2, accuracy=0.732, val_loss=2.21, val_accuracy=0.475, lr=0.1]  14%|█▍        | 12/83 [05:38<30:05, 25.42s/epoch, loss=1.2, accuracy=0.734, val_loss=2.14, val_accuracy=0.535, lr=0.1] 16%|█▌        | 13/83 [06:03<29:29, 25.28s/epoch, loss=1.2, accuracy=0.733, val_loss=2.7, val_accuracy=0.268, lr=0.1]  17%|█▋        | 14/83 [06:28<29:03, 25.28s/epoch, loss=1.19, accuracy=0.736, val_loss=1.97, val_accuracy=0.515, lr=0.1] 18%|█▊        | 15/83 [06:53<28:37, 25.26s/epoch, loss=1.19, accuracy=0.736, val_loss=2.05, val_accuracy=0.529, lr=0.0316] 19%|█▉        | 16/83 [07:18<28:16, 25.32s/epoch, loss=1.19, accuracy=0.739, val_loss=1.55, val_accuracy=0.64, lr=0.1]     20%|██        | 17/83 [07:44<27:57, 25.42s/epoch, loss=1.19, accuracy=0.74, val_loss=2.02, val_accuracy=0.465, lr=0.1] 22%|██▏       | 18/83 [08:09<27:28, 25.36s/epoch, loss=1.18, accuracy=0.742, val_loss=1.47, val_accuracy=0.666, lr=0.1] 23%|██▎       | 19/83 [08:35<27:03, 25.37s/epoch, loss=1.19, accuracy=0.741, val_loss=3.32, val_accuracy=0.396, lr=0.1] 24%|██▍       | 20/83 [08:59<26:25, 25.16s/epoch, loss=1.18, accuracy=0.743, val_loss=2.72, val_accuracy=0.356, lr=0.1] 25%|██▌       | 21/83 [09:25<26:04, 25.24s/epoch, loss=1.17, accuracy=0.742, val_loss=1.89, val_accuracy=0.518, lr=0.1] 27%|██▋       | 22/83 [09:50<25:41, 25.27s/epoch, loss=1.18, accuracy=0.743, val_loss=3.14, val_accuracy=0.295, lr=0.1] 28%|██▊       | 23/83 [10:16<25:20, 25.34s/epoch, loss=1.18, accuracy=0.746, val_loss=2.96, val_accuracy=0.431, lr=0.0316] 29%|██▉       | 24/83 [10:41<25:01, 25.44s/epoch, loss=1.18, accuracy=0.747, val_loss=2.8, val_accuracy=0.297, lr=0.1]     30%|███       | 25/83 [11:07<24:35, 25.45s/epoch, loss=1.16, accuracy=0.746, val_loss=2.37, val_accuracy=0.49, lr=0.1] 31%|███▏      | 26/83 [11:32<24:11, 25.46s/epoch, loss=1.17, accuracy=0.746, val_loss=1.58, val_accuracy=0.608, lr=0.1] 33%|███▎      | 27/83 [11:58<23:49, 25.52s/epoch, loss=1.16, accuracy=0.751, val_loss=1.74, val_accuracy=0.537, lr=0.1] 34%|███▎      | 28/83 [12:23<23:20, 25.46s/epoch, loss=1.16, accuracy=0.749, val_loss=2.15, val_accuracy=0.503, lr=0.0316] 35%|███▍      | 29/83 [12:49<22:53, 25.44s/epoch, loss=1.18, accuracy=0.746, val_loss=1.61, val_accuracy=0.595, lr=0.1]    36%|███▌      | 30/83 [13:14<22:33, 25.54s/epoch, loss=1.17, accuracy=0.747, val_loss=3.39, val_accuracy=0.345, lr=0.1] 37%|███▋      | 31/83 [13:40<22:07, 25.53s/epoch, loss=1.17, accuracy=0.749, val_loss=2.49, val_accuracy=0.432, lr=0.1] 39%|███▊      | 32/83 [14:04<21:24, 25.18s/epoch, loss=1.16, accuracy=0.748, val_loss=2.08, val_accuracy=0.473, lr=0.1] 40%|███▉      | 33/83 [14:30<21:05, 25.31s/epoch, loss=1.16, accuracy=0.749, val_loss=2.21, val_accuracy=0.493, lr=0.0316] 41%|████      | 34/83 [14:55<20:39, 25.30s/epoch, loss=1.16, accuracy=0.749, val_loss=2.52, val_accuracy=0.319, lr=0.1]    42%|████▏     | 35/83 [15:20<20:08, 25.18s/epoch, loss=1.15, accuracy=0.751, val_loss=1.74, val_accuracy=0.554, lr=0.1] 43%|████▎     | 36/83 [15:46<19:48, 25.29s/epoch, loss=1.16, accuracy=0.75, val_loss=1.52, val_accuracy=0.618, lr=0.1]  45%|████▍     | 37/83 [16:11<19:26, 25.35s/epoch, loss=1.16, accuracy=0.751, val_loss=1.69, val_accuracy=0.55, lr=0.1] 46%|████▌     | 38/83 [16:36<18:58, 25.30s/epoch, loss=1.16, accuracy=0.753, val_loss=1.71, val_accuracy=0.569, lr=0.0316] 47%|████▋     | 39/83 [17:02<18:39, 25.44s/epoch, loss=1.16, accuracy=0.75, val_loss=2.68, val_accuracy=0.403, lr=0.1]     48%|████▊     | 40/83 [17:28<18:17, 25.52s/epoch, loss=1.15, accuracy=0.754, val_loss=2.04, val_accuracy=0.482, lr=0.1] 49%|████▉     | 41/83 [17:53<17:53, 25.55s/epoch, loss=1.15, accuracy=0.752, val_loss=1.99, val_accuracy=0.445, lr=0.1] 51%|█████     | 42/83 [18:19<17:26, 25.53s/epoch, loss=1.15, accuracy=0.752, val_loss=1.94, val_accuracy=0.52, lr=0.1]  52%|█████▏    | 43/83 [18:45<17:02, 25.56s/epoch, loss=1.14, accuracy=0.756, val_loss=1.98, val_accuracy=0.532, lr=0.0316] 53%|█████▎    | 44/83 [19:10<16:34, 25.51s/epoch, loss=1.15, accuracy=0.754, val_loss=2.13, val_accuracy=0.47, lr=0.1]     54%|█████▍    | 45/83 [19:35<16:08, 25.49s/epoch, loss=1.14, accuracy=0.754, val_loss=1.78, val_accuracy=0.58, lr=0.1] 55%|█████▌    | 46/83 [20:00<15:33, 25.22s/epoch, loss=1.14, accuracy=0.756, val_loss=1.91, val_accuracy=0.571, lr=0.1] 57%|█████▋    | 47/83 [20:25<15:02, 25.07s/epoch, loss=1.15, accuracy=0.751, val_loss=2.37, val_accuracy=0.364, lr=0.1] 58%|█████▊    | 48/83 [20:49<14:33, 24.95s/epoch, loss=1.14, accuracy=0.753, val_loss=2.11, val_accuracy=0.498, lr=0.0316] 59%|█████▉    | 49/83 [21:15<14:14, 25.12s/epoch, loss=1.15, accuracy=0.752, val_loss=4.49, val_accuracy=0.296, lr=0.1]    60%|██████    | 50/83 [21:40<13:45, 25.03s/epoch, loss=1.14, accuracy=0.754, val_loss=2.4, val_accuracy=0.42, lr=0.1]   61%|██████▏   | 51/83 [22:05<13:23, 25.10s/epoch, loss=1.14, accuracy=0.753, val_loss=1.86, val_accuracy=0.519, lr=0.1] 63%|██████▎   | 52/83 [22:30<12:57, 25.09s/epoch, loss=1.14, accuracy=0.753, val_loss=3.55, val_accuracy=0.411, lr=0.1] 64%|██████▍   | 53/83 [22:55<12:27, 24.93s/epoch, loss=1.14, accuracy=0.753, val_loss=1.86, val_accuracy=0.555, lr=0.0316] 65%|██████▌   | 54/83 [23:20<12:06, 25.06s/epoch, loss=1.13, accuracy=0.756, val_loss=2.24, val_accuracy=0.45, lr=0.1]     66%|██████▋   | 55/83 [23:45<11:39, 24.99s/epoch, loss=1.14, accuracy=0.753, val_loss=2.92, val_accuracy=0.403, lr=0.1] 67%|██████▋   | 56/83 [24:10<11:15, 25.03s/epoch, loss=1.14, accuracy=0.754, val_loss=4.28, val_accuracy=0.261, lr=0.1] 69%|██████▊   | 57/83 [24:35<10:51, 25.05s/epoch, loss=1.14, accuracy=0.753, val_loss=2.26, val_accuracy=0.507, lr=0.1] 70%|██████▉   | 58/83 [25:00<10:22, 24.90s/epoch, loss=1.14, accuracy=0.755, val_loss=2.06, val_accuracy=0.498, lr=0.0316] 71%|███████   | 59/83 [25:24<09:54, 24.79s/epoch, loss=1.13, accuracy=0.755, val_loss=1.54, val_accuracy=0.616, lr=0.1]    72%|███████▏  | 60/83 [25:48<09:27, 24.66s/epoch, loss=1.14, accuracy=0.754, val_loss=2.6, val_accuracy=0.432, lr=0.1]  73%|███████▎  | 61/83 [26:13<08:59, 24.53s/epoch, loss=1.13, accuracy=0.756, val_loss=2.13, val_accuracy=0.445, lr=0.1] 75%|███████▍  | 62/83 [26:38<08:38, 24.71s/epoch, loss=1.13, accuracy=0.755, val_loss=1.75, val_accuracy=0.549, lr=0.1] 76%|███████▌  | 63/83 [27:03<08:17, 24.88s/epoch, loss=1.14, accuracy=0.754, val_loss=3.2, val_accuracy=0.279, lr=0.0316] 77%|███████▋  | 64/83 [27:28<07:55, 25.01s/epoch, loss=1.13, accuracy=0.758, val_loss=1.67, val_accuracy=0.57, lr=0.1]    78%|███████▊  | 65/83 [27:54<07:31, 25.06s/epoch, loss=1.13, accuracy=0.756, val_loss=1.84, val_accuracy=0.549, lr=0.1] 80%|███████▉  | 66/83 [28:19<07:05, 25.05s/epoch, loss=1.13, accuracy=0.756, val_loss=3.67, val_accuracy=0.276, lr=0.1] 81%|████████  | 67/83 [28:43<06:39, 24.98s/epoch, loss=1.13, accuracy=0.756, val_loss=2.04, val_accuracy=0.506, lr=0.1] 82%|████████▏ | 68/83 [29:09<06:15, 25.02s/epoch, loss=1.14, accuracy=0.755, val_loss=2.66, val_accuracy=0.435, lr=0.0316] 83%|████████▎ | 69/83 [29:33<05:47, 24.84s/epoch, loss=1.13, accuracy=0.759, val_loss=1.55, val_accuracy=0.603, lr=0.1]    84%|████████▍ | 70/83 [29:58<05:23, 24.89s/epoch, loss=1.13, accuracy=0.754, val_loss=2.21, val_accuracy=0.394, lr=0.1] 86%|████████▌ | 71/83 [30:23<04:59, 24.96s/epoch, loss=1.13, accuracy=0.757, val_loss=2.19, val_accuracy=0.379, lr=0.1] 87%|████████▋ | 72/83 [30:48<04:35, 25.01s/epoch, loss=1.13, accuracy=0.758, val_loss=1.89, val_accuracy=0.53, lr=0.1]  88%|████████▊ | 73/83 [31:13<04:10, 25.02s/epoch, loss=1.13, accuracy=0.756, val_loss=1.89, val_accuracy=0.539, lr=0.0316] 89%|████████▉ | 74/83 [31:38<03:43, 24.79s/epoch, loss=1.13, accuracy=0.754, val_loss=1.56, val_accuracy=0.606, lr=0.1]    90%|█████████ | 75/83 [32:03<03:19, 24.94s/epoch, loss=1.13, accuracy=0.755, val_loss=1.68, val_accuracy=0.573, lr=0.1] 92%|█████████▏| 76/83 [32:27<02:53, 24.78s/epoch, loss=1.12, accuracy=0.758, val_loss=2.42, val_accuracy=0.445, lr=0.1] 93%|█████████▎| 77/83 [32:53<02:29, 24.94s/epoch, loss=1.13, accuracy=0.756, val_loss=2.84, val_accuracy=0.44, lr=0.1]  94%|█████████▍| 78/83 [33:18<02:05, 25.13s/epoch, loss=1.13, accuracy=0.754, val_loss=2.17, val_accuracy=0.405, lr=0.0316] 95%|█████████▌| 79/83 [33:43<01:40, 25.15s/epoch, loss=1.12, accuracy=0.757, val_loss=1.97, val_accuracy=0.559, lr=0.1]    96%|█████████▋| 80/83 [34:09<01:15, 25.17s/epoch, loss=1.12, accuracy=0.758, val_loss=1.98, val_accuracy=0.502, lr=0.1] 98%|█████████▊| 81/83 [34:32<00:49, 24.80s/epoch, loss=1.12, accuracy=0.758, val_loss=2.06, val_accuracy=0.468, lr=0.1] 99%|█████████▉| 82/83 [34:57<00:24, 24.82s/epoch, loss=0.913, accuracy=0.815, val_loss=0.875, val_accuracy=0.815, lr=0.01]100%|██████████| 83/83 [35:22<00:00, 24.72s/epoch, loss=0.731, accuracy=0.848, val_loss=0.854, val_accuracy=0.791, lr=0.01]100%|██████████| 83/83 [35:22<00:00, 25.57s/epoch, loss=0.731, accuracy=0.848, val_loss=0.854, val_accuracy=0.791, lr=0.01]
Using real-time data augmentation.
Test loss: 0.8535100817680359
Test accuracy: 0.7912999987602234


* * * Run SGD for ID = 18_14. * * *


2024-02-15 21:35:17.472687: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 21:35:20.387630: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 21:35:20.388796: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-15 21:35:20.426744: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 21:35:20.426775: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 21:35:20.430255: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 21:35:20.430299: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 21:35:20.432526: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 21:35:20.433238: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 21:35:20.435736: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 21:35:20.437328: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 21:35:20.442205: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 21:35:20.442715: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 21:35:20.442795: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 21:35:21.726963: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-15 21:35:21.727460: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 21:35:21.727956: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 21:35:21.727986: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 21:35:21.728018: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 21:35:21.728036: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 21:35:21.728051: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 21:35:21.728068: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 21:35:21.728084: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 21:35:21.728100: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 21:35:21.728116: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 21:35:21.728543: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 21:35:21.728577: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 21:35:22.395352: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-15 21:35:22.395405: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-15 21:35:22.395414: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-15 21:35:22.396330: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:03:00.0, compute capability: 6.1)
{'id': 1814, 'batch_size': 128, 'epochs': 83, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/83 [00:00<?, ?epoch/s]2024-02-15 21:35:23.212022: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-15 21:35:23.223744: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2200060000 Hz
2024-02-15 21:35:25.313091: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 21:35:25.539609: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 21:35:26.407102: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-15 21:35:26.450220: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/83 [00:56<1:17:15, 56.53s/epoch, loss=3.18, accuracy=0.305, val_loss=2.38, val_accuracy=0.239, lr=0.1]  2%|▏         | 2/83 [01:20<50:33, 37.45s/epoch, loss=1.57, accuracy=0.527, val_loss=2.04, val_accuracy=0.438, lr=0.1]    4%|▎         | 3/83 [01:45<42:14, 31.68s/epoch, loss=1.36, accuracy=0.634, val_loss=2.15, val_accuracy=0.421, lr=0.1]  5%|▍         | 4/83 [02:10<38:07, 28.95s/epoch, loss=1.29, accuracy=0.679, val_loss=1.83, val_accuracy=0.518, lr=0.1]  6%|▌         | 5/83 [02:35<35:45, 27.50s/epoch, loss=1.26, accuracy=0.7, val_loss=1.73, val_accuracy=0.533, lr=0.1]    7%|▋         | 6/83 [02:59<34:07, 26.59s/epoch, loss=1.25, accuracy=0.707, val_loss=2.42, val_accuracy=0.399, lr=0.1]  8%|▊         | 7/83 [03:24<33:01, 26.07s/epoch, loss=1.23, accuracy=0.716, val_loss=1.92, val_accuracy=0.488, lr=0.1] 10%|▉         | 8/83 [03:49<32:04, 25.66s/epoch, loss=1.22, accuracy=0.72, val_loss=1.84, val_accuracy=0.535, lr=0.1]  11%|█         | 9/83 [04:14<31:15, 25.34s/epoch, loss=1.22, accuracy=0.725, val_loss=1.66, val_accuracy=0.583, lr=0.1] 12%|█▏        | 10/83 [04:38<30:14, 24.85s/epoch, loss=1.21, accuracy=0.728, val_loss=1.62, val_accuracy=0.571, lr=0.1] 13%|█▎        | 11/83 [05:02<29:36, 24.67s/epoch, loss=1.2, accuracy=0.731, val_loss=1.8, val_accuracy=0.532, lr=0.1]   14%|█▍        | 12/83 [05:26<29:01, 24.52s/epoch, loss=1.21, accuracy=0.733, val_loss=2.32, val_accuracy=0.435, lr=0.1] 16%|█▌        | 13/83 [05:51<28:41, 24.59s/epoch, loss=1.19, accuracy=0.734, val_loss=4.29, val_accuracy=0.315, lr=0.1] 17%|█▋        | 14/83 [06:16<28:23, 24.69s/epoch, loss=1.2, accuracy=0.735, val_loss=1.54, val_accuracy=0.606, lr=0.1]  18%|█▊        | 15/83 [06:41<28:02, 24.74s/epoch, loss=1.18, accuracy=0.74, val_loss=2.58, val_accuracy=0.393, lr=0.1] 19%|█▉        | 16/83 [07:05<27:35, 24.70s/epoch, loss=1.18, accuracy=0.74, val_loss=1.68, val_accuracy=0.545, lr=0.1] 20%|██        | 17/83 [07:30<27:10, 24.70s/epoch, loss=1.18, accuracy=0.741, val_loss=1.47, val_accuracy=0.653, lr=0.1] 22%|██▏       | 18/83 [07:55<26:44, 24.68s/epoch, loss=1.19, accuracy=0.74, val_loss=1.74, val_accuracy=0.578, lr=0.1]  23%|██▎       | 19/83 [08:19<26:05, 24.46s/epoch, loss=1.18, accuracy=0.742, val_loss=2.29, val_accuracy=0.427, lr=0.1] 24%|██▍       | 20/83 [08:42<25:27, 24.25s/epoch, loss=1.18, accuracy=0.744, val_loss=1.72, val_accuracy=0.569, lr=0.1] 25%|██▌       | 21/83 [09:07<25:18, 24.49s/epoch, loss=1.18, accuracy=0.743, val_loss=2.74, val_accuracy=0.467, lr=0.1] 27%|██▋       | 22/83 [09:31<24:33, 24.15s/epoch, loss=1.17, accuracy=0.746, val_loss=3.13, val_accuracy=0.356, lr=0.0316] 28%|██▊       | 23/83 [09:55<24:15, 24.26s/epoch, loss=1.16, accuracy=0.748, val_loss=2.3, val_accuracy=0.454, lr=0.1]     29%|██▉       | 24/83 [10:20<24:01, 24.44s/epoch, loss=1.17, accuracy=0.747, val_loss=2.42, val_accuracy=0.497, lr=0.1] 30%|███       | 25/83 [10:44<23:35, 24.40s/epoch, loss=1.17, accuracy=0.746, val_loss=4.9, val_accuracy=0.355, lr=0.1]  31%|███▏      | 26/83 [11:09<23:10, 24.39s/epoch, loss=1.16, accuracy=0.749, val_loss=1.62, val_accuracy=0.558, lr=0.1] 33%|███▎      | 27/83 [11:34<22:53, 24.53s/epoch, loss=1.16, accuracy=0.748, val_loss=2.32, val_accuracy=0.448, lr=0.0316] 34%|███▎      | 28/83 [11:58<22:23, 24.43s/epoch, loss=1.16, accuracy=0.751, val_loss=2.83, val_accuracy=0.428, lr=0.1]    35%|███▍      | 29/83 [12:23<22:05, 24.54s/epoch, loss=1.16, accuracy=0.749, val_loss=1.96, val_accuracy=0.472, lr=0.1] 36%|███▌      | 30/83 [12:47<21:36, 24.46s/epoch, loss=1.16, accuracy=0.748, val_loss=1.81, val_accuracy=0.557, lr=0.1] 37%|███▋      | 31/83 [13:11<21:10, 24.44s/epoch, loss=1.16, accuracy=0.749, val_loss=1.7, val_accuracy=0.579, lr=0.1]  39%|███▊      | 32/83 [13:36<20:44, 24.41s/epoch, loss=1.15, accuracy=0.751, val_loss=1.44, val_accuracy=0.655, lr=0.1] 40%|███▉      | 33/83 [13:59<20:08, 24.17s/epoch, loss=1.16, accuracy=0.747, val_loss=2.35, val_accuracy=0.481, lr=0.1] 41%|████      | 34/83 [14:23<19:45, 24.19s/epoch, loss=1.15, accuracy=0.752, val_loss=2.59, val_accuracy=0.423, lr=0.1] 42%|████▏     | 35/83 [14:48<19:29, 24.36s/epoch, loss=1.16, accuracy=0.749, val_loss=2.05, val_accuracy=0.488, lr=0.1] 43%|████▎     | 36/83 [15:13<19:10, 24.48s/epoch, loss=1.15, accuracy=0.751, val_loss=1.6, val_accuracy=0.607, lr=0.1]  45%|████▍     | 37/83 [15:38<18:53, 24.63s/epoch, loss=1.15, accuracy=0.75, val_loss=2.33, val_accuracy=0.471, lr=0.0316] 46%|████▌     | 38/83 [16:03<18:31, 24.71s/epoch, loss=1.15, accuracy=0.75, val_loss=1.56, val_accuracy=0.633, lr=0.1]    47%|████▋     | 39/83 [16:28<18:07, 24.72s/epoch, loss=1.15, accuracy=0.75, val_loss=1.68, val_accuracy=0.577, lr=0.1] 48%|████▊     | 40/83 [16:52<17:45, 24.77s/epoch, loss=1.14, accuracy=0.754, val_loss=4.57, val_accuracy=0.27, lr=0.1] 49%|████▉     | 41/83 [17:17<17:19, 24.76s/epoch, loss=1.15, accuracy=0.753, val_loss=1.86, val_accuracy=0.559, lr=0.1] 51%|█████     | 42/83 [17:42<16:56, 24.79s/epoch, loss=1.15, accuracy=0.754, val_loss=3.11, val_accuracy=0.372, lr=0.0316] 52%|█████▏    | 43/83 [18:07<16:29, 24.74s/epoch, loss=1.14, accuracy=0.752, val_loss=2.18, val_accuracy=0.46, lr=0.1]     53%|█████▎    | 44/83 [18:31<16:02, 24.68s/epoch, loss=1.15, accuracy=0.751, val_loss=2.21, val_accuracy=0.467, lr=0.1] 54%|█████▍    | 45/83 [18:55<15:28, 24.43s/epoch, loss=1.14, accuracy=0.752, val_loss=7.18, val_accuracy=0.162, lr=0.1] 55%|█████▌    | 46/83 [19:20<15:08, 24.57s/epoch, loss=1.15, accuracy=0.752, val_loss=2.13, val_accuracy=0.516, lr=0.1] 57%|█████▋    | 47/83 [19:45<14:47, 24.65s/epoch, loss=1.14, accuracy=0.754, val_loss=2.82, val_accuracy=0.263, lr=0.0316] 58%|█████▊    | 48/83 [20:09<14:21, 24.63s/epoch, loss=1.14, accuracy=0.753, val_loss=2.26, val_accuracy=0.446, lr=0.1]    59%|█████▉    | 49/83 [20:34<13:53, 24.51s/epoch, loss=1.14, accuracy=0.755, val_loss=2.67, val_accuracy=0.37, lr=0.1]  60%|██████    | 50/83 [20:58<13:25, 24.40s/epoch, loss=1.13, accuracy=0.756, val_loss=2.14, val_accuracy=0.437, lr=0.1] 61%|██████▏   | 51/83 [21:22<12:56, 24.27s/epoch, loss=1.14, accuracy=0.751, val_loss=1.63, val_accuracy=0.606, lr=0.1] 63%|██████▎   | 52/83 [21:45<12:27, 24.11s/epoch, loss=1.14, accuracy=0.752, val_loss=2.21, val_accuracy=0.455, lr=0.0316] 64%|██████▍   | 53/83 [22:10<12:03, 24.12s/epoch, loss=1.13, accuracy=0.751, val_loss=2.34, val_accuracy=0.474, lr=0.1]    65%|██████▌   | 54/83 [22:33<11:34, 23.95s/epoch, loss=1.14, accuracy=0.753, val_loss=1.99, val_accuracy=0.499, lr=0.1] 66%|██████▋   | 55/83 [22:57<11:13, 24.07s/epoch, loss=1.14, accuracy=0.755, val_loss=2.1, val_accuracy=0.493, lr=0.1]  67%|██████▋   | 56/83 [23:22<10:52, 24.15s/epoch, loss=1.14, accuracy=0.751, val_loss=2, val_accuracy=0.547, lr=0.1]   69%|██████▊   | 57/83 [23:45<10:20, 23.85s/epoch, loss=1.14, accuracy=0.753, val_loss=2.6, val_accuracy=0.374, lr=0.0316] 70%|██████▉   | 58/83 [24:09<09:59, 23.96s/epoch, loss=1.15, accuracy=0.754, val_loss=3.3, val_accuracy=0.375, lr=0.1]    71%|███████   | 59/83 [24:34<09:39, 24.13s/epoch, loss=1.14, accuracy=0.753, val_loss=1.57, val_accuracy=0.602, lr=0.1] 72%|███████▏  | 60/83 [24:57<09:08, 23.86s/epoch, loss=1.14, accuracy=0.752, val_loss=2.17, val_accuracy=0.462, lr=0.1] 73%|███████▎  | 61/83 [25:21<08:46, 23.92s/epoch, loss=1.14, accuracy=0.755, val_loss=1.82, val_accuracy=0.526, lr=0.1] 75%|███████▍  | 62/83 [25:44<08:19, 23.79s/epoch, loss=1.14, accuracy=0.753, val_loss=2.06, val_accuracy=0.406, lr=0.0316] 76%|███████▌  | 63/83 [26:08<07:53, 23.67s/epoch, loss=1.13, accuracy=0.756, val_loss=2.12, val_accuracy=0.516, lr=0.1]    77%|███████▋  | 64/83 [26:32<07:34, 23.95s/epoch, loss=1.15, accuracy=0.752, val_loss=2.84, val_accuracy=0.43, lr=0.1]  78%|███████▊  | 65/83 [26:57<07:13, 24.07s/epoch, loss=1.14, accuracy=0.753, val_loss=1.91, val_accuracy=0.51, lr=0.1] 80%|███████▉  | 66/83 [27:21<06:50, 24.14s/epoch, loss=1.14, accuracy=0.754, val_loss=1.74, val_accuracy=0.567, lr=0.1] 81%|████████  | 67/83 [27:45<06:25, 24.11s/epoch, loss=1.13, accuracy=0.755, val_loss=1.98, val_accuracy=0.567, lr=0.0316] 82%|████████▏ | 68/83 [28:09<06:02, 24.13s/epoch, loss=1.13, accuracy=0.753, val_loss=2, val_accuracy=0.508, lr=0.1]       83%|████████▎ | 69/83 [28:33<05:37, 24.13s/epoch, loss=1.14, accuracy=0.753, val_loss=2.11, val_accuracy=0.471, lr=0.1] 84%|████████▍ | 70/83 [28:58<05:14, 24.22s/epoch, loss=1.14, accuracy=0.753, val_loss=1.59, val_accuracy=0.6, lr=0.1]   86%|████████▌ | 71/83 [29:22<04:50, 24.21s/epoch, loss=1.13, accuracy=0.755, val_loss=1.54, val_accuracy=0.633, lr=0.1] 87%|████████▋ | 72/83 [29:46<04:26, 24.25s/epoch, loss=1.13, accuracy=0.753, val_loss=2.62, val_accuracy=0.438, lr=0.0316] 88%|████████▊ | 73/83 [30:11<04:03, 24.30s/epoch, loss=1.14, accuracy=0.753, val_loss=1.86, val_accuracy=0.534, lr=0.1]    89%|████████▉ | 74/83 [30:35<03:37, 24.13s/epoch, loss=1.13, accuracy=0.754, val_loss=2.19, val_accuracy=0.42, lr=0.1]  90%|█████████ | 75/83 [30:58<03:12, 24.01s/epoch, loss=1.13, accuracy=0.756, val_loss=3.86, val_accuracy=0.298, lr=0.1] 92%|█████████▏| 76/83 [31:23<02:49, 24.15s/epoch, loss=1.13, accuracy=0.755, val_loss=2.35, val_accuracy=0.356, lr=0.1] 93%|█████████▎| 77/83 [31:47<02:25, 24.32s/epoch, loss=1.13, accuracy=0.755, val_loss=8.04, val_accuracy=0.189, lr=0.0316] 94%|█████████▍| 78/83 [32:11<02:00, 24.19s/epoch, loss=1.13, accuracy=0.756, val_loss=1.5, val_accuracy=0.622, lr=0.1]     95%|█████████▌| 79/83 [32:36<01:36, 24.17s/epoch, loss=1.14, accuracy=0.753, val_loss=2.16, val_accuracy=0.518, lr=0.1] 96%|█████████▋| 80/83 [33:00<01:12, 24.31s/epoch, loss=1.14, accuracy=0.753, val_loss=2.17, val_accuracy=0.457, lr=0.1] 98%|█████████▊| 81/83 [33:24<00:48, 24.23s/epoch, loss=1.13, accuracy=0.757, val_loss=13.3, val_accuracy=0.133, lr=0.1] 99%|█████████▉| 82/83 [33:48<00:24, 24.24s/epoch, loss=0.916, accuracy=0.813, val_loss=1.02, val_accuracy=0.755, lr=0.01]100%|██████████| 83/83 [34:13<00:00, 24.28s/epoch, loss=0.738, accuracy=0.845, val_loss=0.894, val_accuracy=0.781, lr=0.01]100%|██████████| 83/83 [34:13<00:00, 24.74s/epoch, loss=0.738, accuracy=0.845, val_loss=0.894, val_accuracy=0.781, lr=0.01]
Using real-time data augmentation.
Test loss: 0.8942466974258423
Test accuracy: 0.7810999751091003


* * * Run SGD for ID = 18_15. * * *


2024-02-15 22:09:39.252705: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 22:09:42.293398: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 22:09:42.294624: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-15 22:09:42.333875: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 22:09:42.333967: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 22:09:42.336824: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 22:09:42.336867: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 22:09:42.339193: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 22:09:42.339920: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 22:09:42.342219: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 22:09:42.343684: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 22:09:42.348639: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 22:09:42.349093: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 22:09:42.349184: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 22:09:43.601296: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-15 22:09:43.602382: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 22:09:43.602858: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 22:09:43.602910: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 22:09:43.602943: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 22:09:43.602960: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 22:09:43.602976: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 22:09:43.602992: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 22:09:43.603009: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 22:09:43.603025: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 22:09:43.603042: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 22:09:43.603450: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 22:09:43.603487: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 22:09:44.247697: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-15 22:09:44.247761: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-15 22:09:44.247773: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-15 22:09:44.248632: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:03:00.0, compute capability: 6.1)
{'id': 1815, 'batch_size': 128, 'epochs': 83, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/83 [00:00<?, ?epoch/s]2024-02-15 22:09:45.066772: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-15 22:09:45.067468: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2200060000 Hz
2024-02-15 22:09:47.181723: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 22:09:47.444039: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 22:09:48.711648: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-15 22:09:48.762381: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/83 [01:02<1:25:51, 62.83s/epoch, loss=3.18, accuracy=0.287, val_loss=2.44, val_accuracy=0.278, lr=0.1]  2%|▏         | 2/83 [01:25<53:06, 39.34s/epoch, loss=1.56, accuracy=0.522, val_loss=2.1, val_accuracy=0.399, lr=0.1]     4%|▎         | 3/83 [01:50<43:37, 32.72s/epoch, loss=1.35, accuracy=0.625, val_loss=2.45, val_accuracy=0.34, lr=0.1]  5%|▍         | 4/83 [02:13<38:13, 29.03s/epoch, loss=1.27, accuracy=0.675, val_loss=2.02, val_accuracy=0.496, lr=0.1]  6%|▌         | 5/83 [02:36<34:54, 26.85s/epoch, loss=1.25, accuracy=0.697, val_loss=2.1, val_accuracy=0.424, lr=0.1]   7%|▋         | 6/83 [03:00<32:54, 25.64s/epoch, loss=1.24, accuracy=0.705, val_loss=1.73, val_accuracy=0.567, lr=0.1]  8%|▊         | 7/83 [03:25<32:14, 25.46s/epoch, loss=1.22, accuracy=0.711, val_loss=1.94, val_accuracy=0.46, lr=0.1]  10%|▉         | 8/83 [03:50<31:42, 25.37s/epoch, loss=1.22, accuracy=0.718, val_loss=1.59, val_accuracy=0.596, lr=0.1] 11%|█         | 9/83 [04:15<31:11, 25.29s/epoch, loss=1.22, accuracy=0.724, val_loss=3.92, val_accuracy=0.339, lr=0.1] 12%|█▏        | 10/83 [04:40<30:39, 25.19s/epoch, loss=1.21, accuracy=0.728, val_loss=7.23, val_accuracy=0.188, lr=0.1] 13%|█▎        | 11/83 [05:05<30:12, 25.17s/epoch, loss=1.21, accuracy=0.727, val_loss=1.73, val_accuracy=0.53, lr=0.1]  14%|█▍        | 12/83 [05:30<29:37, 25.04s/epoch, loss=1.2, accuracy=0.732, val_loss=1.86, val_accuracy=0.535, lr=0.1] 16%|█▌        | 13/83 [05:55<29:08, 24.97s/epoch, loss=1.2, accuracy=0.732, val_loss=1.99, val_accuracy=0.51, lr=0.0316] 17%|█▋        | 14/83 [06:19<28:25, 24.71s/epoch, loss=1.19, accuracy=0.734, val_loss=1.59, val_accuracy=0.614, lr=0.1]  18%|█▊        | 15/83 [06:43<27:50, 24.57s/epoch, loss=1.19, accuracy=0.735, val_loss=2.69, val_accuracy=0.377, lr=0.1] 19%|█▉        | 16/83 [07:08<27:38, 24.75s/epoch, loss=1.18, accuracy=0.738, val_loss=2.41, val_accuracy=0.451, lr=0.1] 20%|██        | 17/83 [07:33<27:20, 24.85s/epoch, loss=1.18, accuracy=0.74, val_loss=1.91, val_accuracy=0.504, lr=0.1]  22%|██▏       | 18/83 [07:58<26:55, 24.86s/epoch, loss=1.17, accuracy=0.744, val_loss=2.08, val_accuracy=0.494, lr=0.1] 23%|██▎       | 19/83 [08:23<26:20, 24.69s/epoch, loss=1.17, accuracy=0.74, val_loss=1.86, val_accuracy=0.531, lr=0.0316] 24%|██▍       | 20/83 [08:48<26:02, 24.80s/epoch, loss=1.18, accuracy=0.744, val_loss=1.65, val_accuracy=0.588, lr=0.1]   25%|██▌       | 21/83 [09:12<25:36, 24.79s/epoch, loss=1.17, accuracy=0.743, val_loss=2.29, val_accuracy=0.507, lr=0.1] 27%|██▋       | 22/83 [09:37<25:14, 24.83s/epoch, loss=1.17, accuracy=0.74, val_loss=2.03, val_accuracy=0.545, lr=0.1]  28%|██▊       | 23/83 [10:02<24:44, 24.74s/epoch, loss=1.17, accuracy=0.744, val_loss=1.74, val_accuracy=0.561, lr=0.1] 29%|██▉       | 24/83 [10:27<24:21, 24.77s/epoch, loss=1.16, accuracy=0.743, val_loss=1.5, val_accuracy=0.624, lr=0.1]  30%|███       | 25/83 [10:51<23:44, 24.56s/epoch, loss=1.16, accuracy=0.744, val_loss=2.18, val_accuracy=0.5, lr=0.1]  31%|███▏      | 26/83 [11:16<23:28, 24.71s/epoch, loss=1.17, accuracy=0.744, val_loss=2.1, val_accuracy=0.489, lr=0.1] 33%|███▎      | 27/83 [11:41<23:05, 24.75s/epoch, loss=1.16, accuracy=0.745, val_loss=1.85, val_accuracy=0.568, lr=0.1] 34%|███▎      | 28/83 [12:05<22:41, 24.76s/epoch, loss=1.16, accuracy=0.749, val_loss=1.38, val_accuracy=0.671, lr=0.1] 35%|███▍      | 29/83 [12:31<22:25, 24.91s/epoch, loss=1.16, accuracy=0.748, val_loss=2.43, val_accuracy=0.463, lr=0.1] 36%|███▌      | 30/83 [12:56<22:07, 25.04s/epoch, loss=1.15, accuracy=0.747, val_loss=1.88, val_accuracy=0.556, lr=0.1] 37%|███▋      | 31/83 [13:21<21:42, 25.05s/epoch, loss=1.16, accuracy=0.75, val_loss=2.85, val_accuracy=0.429, lr=0.1]  39%|███▊      | 32/83 [13:46<21:21, 25.14s/epoch, loss=1.15, accuracy=0.749, val_loss=1.64, val_accuracy=0.601, lr=0.1] 40%|███▉      | 33/83 [14:12<20:59, 25.19s/epoch, loss=1.15, accuracy=0.75, val_loss=4.61, val_accuracy=0.335, lr=0.0316] 41%|████      | 34/83 [14:36<20:15, 24.80s/epoch, loss=1.15, accuracy=0.748, val_loss=2.65, val_accuracy=0.443, lr=0.1]   42%|████▏     | 35/83 [15:01<19:54, 24.90s/epoch, loss=1.16, accuracy=0.75, val_loss=1.69, val_accuracy=0.577, lr=0.1]  43%|████▎     | 36/83 [15:26<19:31, 24.93s/epoch, loss=1.15, accuracy=0.749, val_loss=3.24, val_accuracy=0.359, lr=0.1] 45%|████▍     | 37/83 [15:51<19:12, 25.05s/epoch, loss=1.15, accuracy=0.749, val_loss=1.82, val_accuracy=0.553, lr=0.1]