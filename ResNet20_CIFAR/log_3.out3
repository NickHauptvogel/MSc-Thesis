Fri Mar 22 13:17:47 2024       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 545.23.08              Driver Version: 545.23.08    CUDA Version: 12.3     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA TITAN Xp                Off | 00000000:86:00.0 Off |                  N/A |
| 23%   27C    P8               9W / 250W |      0MiB / 12288MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|  No running processes found                                                           |
+---------------------------------------------------------------------------------------+


* * * Run SGD for ID = 3. * * *


2024-03-22 13:17:50.892187: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-22 13:18:47.020936: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-22 13:18:47.023086: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-22 13:18:47.059248: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:86:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-22 13:18:47.059295: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-22 13:18:47.126769: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-22 13:18:47.126892: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-22 13:18:47.186415: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-22 13:18:47.235577: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-22 13:18:47.286293: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-22 13:18:47.321936: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-22 13:18:47.406487: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-22 13:18:47.407682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-22 13:18:47.407793: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-22 13:20:00.540414: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-22 13:20:00.541349: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-22 13:20:00.565766: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:86:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-22 13:20:00.565806: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-22 13:20:00.565852: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-22 13:20:00.565866: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-22 13:20:00.565878: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-22 13:20:00.565891: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-22 13:20:00.565904: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-22 13:20:00.565918: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-22 13:20:00.565931: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-22 13:20:00.567916: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-22 13:20:00.567954: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-22 13:20:02.921577: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-22 13:20:02.921639: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-22 13:20:02.921649: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-22 13:20:02.922675: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:86:00.0, compute capability: 6.1)
{'id': '03', 'seed': 3, 'out_folder': 'results/retinopathy/resnet50/10_independent_smallerlr_full_val_512', 'batch_size': 8, 'epochs': 90, 'validation_split': 0.1, 'checkpointing': False, 'checkpoint_every': -1, 'hold_out_validation_split': 0.0, 'model_type': 'ResNet50v1', 'data_augmentation': False, 'augm_shift': 4, 'initial_lr': 0.00023072, 'l2_reg': 0.00010674, 'optimizer': 'sgd', 'momentum': 0.9901533, 'nesterov': True, 'bootstrapping': False, 'use_case': 'retinopathy', 'lr_schedule': 'retinopathy', 'test_time_augmentation': False, 'store_models': False, 'debug': False, 'evaluate': None, 'model': 'ResNet50v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Found 35126 images belonging to 2 classes.
Found 10906 images belonging to 2 classes.
Found 10906 images belonging to 2 classes.
Found 42670 images belonging to 2 classes.
Found 42670 images belonging to 2 classes.
x_train samples: 35126
x_val samples: 10906
x_test samples: 42670
x_train shape: (8, 512, 512, 3)
y_train shape: (8,)
ResNet50v1
0epoch [00:00, ?epoch/s]  0%|          | 0/90 [00:00<?, ?epoch/s]2024-03-22 13:20:03.853281: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-22 13:20:03.853769: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2100000000 Hz
WARNING:tensorflow:AutoGraph could not transform <function weighted_binary_cross_entropy.<locals>.weighted_cross_entropy_fn at 0x7fbe412bcee0> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: module 'gast' has no attribute 'Index'
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
2024-03-22 13:20:08.924980: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-22 13:20:09.215064: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-22 13:20:11.377730: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-22 13:20:11.452432: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1916s vs `on_train_batch_end` time: 0.2650s). Check your callbacks.
  1%|          | 1/90 [43:32<64:35:43, 2612.84s/epoch, loss=2.02, accuracy=0.598, auc=0.516, precision=0.202, recall=0.356, val_loss=1.99, val_accuracy=0.594, val_auc=0.504, val_precision=0.188, val_recall=0.347, lr=0]  2%|▏         | 2/90 [1:26:22<63:15:01, 2587.51s/epoch, loss=1.24, accuracy=0.493, auc=0.546, precision=0.216, recall=0.603, val_loss=1.08, val_accuracy=0.629, val_auc=0.587, val_precision=0.241, val_recall=0.448, lr=0.000231]  3%|▎         | 3/90 [2:09:25<62:28:39, 2585.28s/epoch, loss=1.08, accuracy=0.547, auc=0.595, precision=0.239, recall=0.603, val_loss=1.05, val_accuracy=0.607, val_auc=0.622, val_precision=0.253, val_recall=0.554, lr=0.000231]  4%|▍         | 4/90 [2:53:23<62:15:47, 2606.36s/epoch, loss=1.03, accuracy=0.604, auc=0.661, precision=0.277, recall=0.635, val_loss=1.53, val_accuracy=0.811, val_auc=0.643, val_precision=0.5, val_recall=0.00195, lr=0.000231]  6%|▌         | 5/90 [3:36:42<61:28:11, 2603.43s/epoch, loss=0.959, accuracy=0.726, auc=0.747, precision=0.377, recall=0.612, val_loss=0.929, val_accuracy=0.785, val_auc=0.769, val_precision=0.445, val_recall=0.573, lr=0.000231]  7%|▋         | 6/90 [4:21:02<61:11:40, 2622.63s/epoch, loss=0.908, accuracy=0.77, auc=0.786, precision=0.439, recall=0.624, val_loss=0.92, val_accuracy=0.841, val_auc=0.772, val_precision=0.613, val_recall=0.429, lr=0.000231]    8%|▊         | 7/90 [5:06:18<61:10:31, 2653.39s/epoch, loss=0.878, accuracy=0.778, auc=0.8, precision=0.453, recall=0.643, val_loss=0.889, val_accuracy=0.828, val_auc=0.778, val_precision=0.55, val_recall=0.489, lr=0.000231]   9%|▉         | 8/90 [5:49:06<59:49:14, 2626.27s/epoch, loss=0.851, accuracy=0.782, auc=0.812, precision=0.46, recall=0.658, val_loss=1.01, val_accuracy=0.837, val_auc=0.731, val_precision=0.644, val_recall=0.298, lr=0.000231] 10%|█         | 9/90 [6:31:57<58:41:46, 2608.72s/epoch, loss=0.829, accuracy=0.79, auc=0.819, precision=0.474, recall=0.667, val_loss=0.834, val_accuracy=0.797, val_auc=0.797, val_precision=0.471, val_recall=0.633, lr=0.000231] 11%|█         | 10/90 [7:15:15<57:54:14, 2605.68s/epoch, loss=0.802, accuracy=0.793, auc=0.831, precision=0.48, recall=0.685, val_loss=0.907, val_accuracy=0.834, val_auc=0.754, val_precision=0.588, val_recall=0.402, lr=0.000231] 12%|█▏        | 11/90 [7:57:40<56:46:00, 2586.84s/epoch, loss=0.784, accuracy=0.794, auc=0.837, precision=0.482, recall=0.698, val_loss=0.806, val_accuracy=0.752, val_auc=0.803, val_precision=0.407, val_recall=0.692, lr=0.000231] 13%|█▎        | 12/90 [8:40:37<55:59:19, 2584.09s/epoch, loss=0.765, accuracy=0.797, auc=0.843, precision=0.486, recall=0.7, val_loss=0.823, val_accuracy=0.829, val_auc=0.801, val_precision=0.543, val_recall=0.575, lr=0.000231]   14%|█▍        | 13/90 [9:23:22<55:08:42, 2578.21s/epoch, loss=0.742, accuracy=0.8, auc=0.852, precision=0.492, recall=0.721, val_loss=0.832, val_accuracy=0.829, val_auc=0.777, val_precision=0.55, val_recall=0.498, lr=0.000231]  16%|█▌        | 14/90 [10:06:02<54:18:38, 2572.61s/epoch, loss=0.728, accuracy=0.801, auc=0.854, precision=0.494, recall=0.715, val_loss=0.93, val_accuracy=0.583, val_auc=0.631, val_precision=0.249, val_recall=0.602, lr=0.000231] 17%|█▋        | 15/90 [10:48:32<53:27:29, 2566.00s/epoch, loss=0.709, accuracy=0.804, auc=0.862, precision=0.5, recall=0.731, val_loss=0.77, val_accuracy=0.811, val_auc=0.802, val_precision=0.498, val_recall=0.603, lr=0.000231]   18%|█▊        | 16/90 [11:32:29<53:11:01, 2587.32s/epoch, loss=0.693, accuracy=0.809, auc=0.867, precision=0.509, recall=0.744, val_loss=0.879, val_accuracy=0.688, val_auc=0.699, val_precision=0.316, val_recall=0.564, lr=0.000231] 19%|█▉        | 17/90 [12:15:07<52:17:03, 2578.40s/epoch, loss=0.674, accuracy=0.811, auc=0.873, precision=0.512, recall=0.753, val_loss=0.821, val_accuracy=0.701, val_auc=0.788, val_precision=0.359, val_recall=0.74, lr=0.000231]  20%|██        | 18/90 [12:57:50<51:28:27, 2573.71s/epoch, loss=0.655, accuracy=0.816, auc=0.88, precision=0.52, recall=0.762, val_loss=0.753, val_accuracy=0.73, val_auc=0.81, val_precision=0.386, val_recall=0.731, lr=0.000231]    21%|██        | 19/90 [13:40:20<50:37:16, 2566.71s/epoch, loss=0.643, accuracy=0.815, auc=0.882, precision=0.518, recall=0.765, val_loss=0.769, val_accuracy=0.83, val_auc=0.803, val_precision=0.548, val_recall=0.559, lr=0.000231] 22%|██▏       | 20/90 [14:22:43<49:46:08, 2559.55s/epoch, loss=0.627, accuracy=0.822, auc=0.889, precision=0.53, recall=0.776, val_loss=0.816, val_accuracy=0.738, val_auc=0.737, val_precision=0.374, val_recall=0.579, lr=0.000231] 23%|██▎       | 21/90 [15:05:21<49:02:53, 2559.04s/epoch, loss=0.612, accuracy=0.825, auc=0.893, precision=0.536, recall=0.78, val_loss=0.975, val_accuracy=0.575, val_auc=0.797, val_precision=0.287, val_recall=0.849, lr=0.000231] 24%|██▍       | 22/90 [15:47:45<48:15:07, 2554.52s/epoch, loss=0.595, accuracy=0.829, auc=0.9, precision=0.543, recall=0.791, val_loss=0.821, val_accuracy=0.693, val_auc=0.784, val_precision=0.347, val_recall=0.713, lr=0.000231]  26%|██▌       | 23/90 [16:30:24<47:34:05, 2555.90s/epoch, loss=0.581, accuracy=0.832, auc=0.904, precision=0.548, recall=0.8, val_loss=0.801, val_accuracy=0.664, val_auc=0.767, val_precision=0.326, val_recall=0.732, lr=0.000231] 27%|██▋       | 24/90 [17:12:51<46:48:31, 2553.20s/epoch, loss=0.564, accuracy=0.837, auc=0.91, precision=0.557, recall=0.809, val_loss=0.851, val_accuracy=0.827, val_auc=0.79, val_precision=0.541, val_recall=0.529, lr=0.000231] 28%|██▊       | 25/90 [17:55:21<46:04:56, 2552.26s/epoch, loss=0.545, accuracy=0.84, auc=0.917, precision=0.562, recall=0.813, val_loss=0.777, val_accuracy=0.733, val_auc=0.762, val_precision=0.375, val_recall=0.624, lr=0.000231] 29%|██▉       | 26/90 [18:37:49<45:20:57, 2550.90s/epoch, loss=0.534, accuracy=0.843, auc=0.92, precision=0.568, recall=0.827, val_loss=0.838, val_accuracy=0.836, val_auc=0.791, val_precision=0.573, val_recall=0.514, lr=0.000231] 30%|███       | 27/90 [19:20:18<44:38:04, 2550.54s/epoch, loss=0.508, accuracy=0.854, auc=0.93, precision=0.589, recall=0.84, val_loss=0.807, val_accuracy=0.664, val_auc=0.735, val_precision=0.317, val_recall=0.676, lr=0.000231]  31%|███       | 28/90 [20:02:52<43:56:34, 2551.53s/epoch, loss=0.499, accuracy=0.857, auc=0.932, precision=0.595, recall=0.847, val_loss=0.916, val_accuracy=0.834, val_auc=0.78, val_precision=0.574, val_recall=0.459, lr=0.000231] 32%|███▏      | 29/90 [20:45:23<43:13:41, 2551.17s/epoch, loss=0.48, accuracy=0.862, auc=0.939, precision=0.605, recall=0.855, val_loss=0.805, val_accuracy=0.707, val_auc=0.77, val_precision=0.357, val_recall=0.693, lr=0.000231]  33%|███▎      | 30/90 [21:27:56<42:31:45, 2551.76s/epoch, loss=0.468, accuracy=0.868, auc=0.942, precision=0.616, recall=0.862, val_loss=0.775, val_accuracy=0.74, val_auc=0.787, val_precision=0.39, val_recall=0.675, lr=0.000231] 34%|███▍      | 31/90 [22:10:38<41:52:17, 2554.87s/epoch, loss=0.374, accuracy=0.914, auc=0.974, precision=0.72, recall=0.916, val_loss=0.889, val_accuracy=0.771, val_auc=0.808, val_precision=0.432, val_recall=0.679, lr=4.61e-5] 36%|███▌      | 32/90 [22:53:28<41:14:10, 2559.49s/epoch, loss=0.326, accuracy=0.932, auc=0.983, precision=0.764, recall=0.945, val_loss=1.09, val_accuracy=0.831, val_auc=0.793, val_precision=0.552, val_recall=0.537, lr=4.61e-5] 37%|███▋      | 33/90 [23:36:03<40:30:20, 2558.25s/epoch, loss=0.308, accuracy=0.938, auc=0.986, precision=0.779, recall=0.953, val_loss=1, val_accuracy=0.786, val_auc=0.803, val_precision=0.452, val_recall=0.643, lr=4.61e-5]    38%|███▊      | 34/90 [24:18:48<39:49:35, 2560.29s/epoch, loss=0.29, accuracy=0.945, auc=0.989, precision=0.8, recall=0.959, val_loss=1.05, val_accuracy=0.783, val_auc=0.803, val_precision=0.448, val_recall=0.658, lr=4.61e-5] 39%|███▉      | 35/90 [25:01:25<39:05:53, 2559.16s/epoch, loss=0.276, accuracy=0.951, auc=0.991, precision=0.82, recall=0.962, val_loss=1.41, val_accuracy=0.834, val_auc=0.77, val_precision=0.571, val_recall=0.48, lr=4.61e-5] 40%|████      | 36/90 [25:43:53<38:20:08, 2555.71s/epoch, loss=0.259, accuracy=0.957, auc=0.993, precision=0.837, recall=0.97, val_loss=1.15, val_accuracy=0.799, val_auc=0.797, val_precision=0.474, val_recall=0.619, lr=4.61e-5] 41%|████      | 37/90 [26:26:27<37:37:18, 2555.44s/epoch, loss=0.249, accuracy=0.961, auc=0.994, precision=0.85, recall=0.972, val_loss=1.31, val_accuracy=0.812, val_auc=0.788, val_precision=0.502, val_recall=0.591, lr=4.61e-5] 42%|████▏     | 38/90 [27:08:47<36:50:30, 2550.59s/epoch, loss=0.236, accuracy=0.967, auc=0.995, precision=0.87, recall=0.979, val_loss=1.31, val_accuracy=0.814, val_auc=0.8, val_precision=0.505, val_recall=0.609, lr=4.61e-5]   43%|████▎     | 39/90 [27:51:14<36:07:10, 2549.61s/epoch, loss=0.229, accuracy=0.97, auc=0.996, precision=0.882, recall=0.979, val_loss=1.26, val_accuracy=0.767, val_auc=0.78, val_precision=0.421, val_recall=0.63, lr=4.61e-5] 44%|████▍     | 40/90 [28:33:45<35:24:56, 2549.93s/epoch, loss=0.223, accuracy=0.972, auc=0.996, precision=0.889, recall=0.98, val_loss=1.52, val_accuracy=0.823, val_auc=0.783, val_precision=0.529, val_recall=0.555, lr=4.61e-5] 46%|████▌     | 41/90 [29:16:14<34:42:22, 2549.84s/epoch, loss=0.215, accuracy=0.973, auc=0.997, precision=0.894, recall=0.979, val_loss=1.67, val_accuracy=0.835, val_auc=0.771, val_precision=0.572, val_recall=0.496, lr=4.61e-5] 47%|████▋     | 42/90 [29:58:49<34:01:01, 2551.28s/epoch, loss=0.219, accuracy=0.973, auc=0.997, precision=0.891, recall=0.981, val_loss=1.52, val_accuracy=0.81, val_auc=0.776, val_precision=0.497, val_recall=0.56, lr=4.61e-5]   48%|████▊     | 43/90 [30:41:23<33:19:13, 2552.20s/epoch, loss=0.207, accuracy=0.977, auc=0.997, precision=0.906, recall=0.984, val_loss=1.88, val_accuracy=0.826, val_auc=0.752, val_precision=0.544, val_recall=0.467, lr=4.61e-5] 49%|████▉     | 44/90 [31:23:45<32:34:12, 2548.96s/epoch, loss=0.205, accuracy=0.978, auc=0.997, precision=0.909, recall=0.984, val_loss=1.52, val_accuracy=0.81, val_auc=0.786, val_precision=0.496, val_recall=0.589, lr=4.61e-5]  50%|█████     | 45/90 [32:06:14<31:51:52, 2549.16s/epoch, loss=0.197, accuracy=0.98, auc=0.998, precision=0.92, recall=0.986, val_loss=1.64, val_accuracy=0.822, val_auc=0.777, val_precision=0.527, val_recall=0.559, lr=4.61e-5]  51%|█████     | 46/90 [32:48:25<31:05:12, 2543.46s/epoch, loss=0.188, accuracy=0.985, auc=0.998, precision=0.939, recall=0.988, val_loss=1.81, val_accuracy=0.823, val_auc=0.761, val_precision=0.531, val_recall=0.51, lr=4.61e-5] 52%|█████▏    | 47/90 [33:30:49<30:23:05, 2543.85s/epoch, loss=0.192, accuracy=0.981, auc=0.998, precision=0.925, recall=0.985, val_loss=1.61, val_accuracy=0.796, val_auc=0.797, val_precision=0.471, val_recall=0.644, lr=4.61e-5] 53%|█████▎    | 48/90 [34:13:05<29:38:56, 2541.34s/epoch, loss=0.19, accuracy=0.982, auc=0.998, precision=0.928, recall=0.987, val_loss=1.83, val_accuracy=0.822, val_auc=0.767, val_precision=0.529, val_recall=0.528, lr=4.61e-5]  54%|█████▍    | 49/90 [34:55:23<28:56:01, 2540.52s/epoch, loss=0.185, accuracy=0.983, auc=0.999, precision=0.932, recall=0.987, val_loss=1.89, val_accuracy=0.834, val_auc=0.779, val_precision=0.564, val_recall=0.524, lr=4.61e-5] 56%|█████▌    | 50/90 [35:37:55<28:15:52, 2543.81s/epoch, loss=0.183, accuracy=0.984, auc=0.999, precision=0.937, recall=0.987, val_loss=1.79, val_accuracy=0.825, val_auc=0.767, val_precision=0.535, val_recall=0.532, lr=4.61e-5] 57%|█████▋    | 51/90 [36:20:10<27:31:50, 2541.29s/epoch, loss=0.191, accuracy=0.981, auc=0.998, precision=0.926, recall=0.984, val_loss=1.84, val_accuracy=0.821, val_auc=0.757, val_precision=0.526, val_recall=0.503, lr=4.61e-5] 58%|█████▊    | 52/90 [37:02:38<26:50:45, 2543.30s/epoch, loss=0.179, accuracy=0.985, auc=0.999, precision=0.941, recall=0.987, val_loss=2.04, val_accuracy=0.828, val_auc=0.752, val_precision=0.552, val_recall=0.478, lr=4.61e-5] 59%|█████▉    | 53/90 [37:44:58<26:07:43, 2542.27s/epoch, loss=0.177, accuracy=0.985, auc=0.999, precision=0.941, recall=0.987, val_loss=1.78, val_accuracy=0.801, val_auc=0.783, val_precision=0.479, val_recall=0.608, lr=4.61e-5] 60%|██████    | 54/90 [38:27:15<25:24:24, 2540.68s/epoch, loss=0.174, accuracy=0.987, auc=0.999, precision=0.944, recall=0.99, val_loss=1.92, val_accuracy=0.821, val_auc=0.767, val_precision=0.524, val_recall=0.518, lr=4.61e-5]  61%|██████    | 55/90 [39:09:40<24:42:52, 2542.08s/epoch, loss=0.174, accuracy=0.987, auc=0.999, precision=0.946, recall=0.99, val_loss=1.93, val_accuracy=0.828, val_auc=0.776, val_precision=0.544, val_recall=0.54, lr=4.61e-5]  62%|██████▏   | 56/90 [39:51:57<23:59:36, 2540.47s/epoch, loss=0.169, accuracy=0.988, auc=0.999, precision=0.952, recall=0.989, val_loss=2.01, val_accuracy=0.818, val_auc=0.766, val_precision=0.516, val_recall=0.538, lr=4.61e-5] 63%|██████▎   | 57/90 [40:34:15<23:16:47, 2539.63s/epoch, loss=0.178, accuracy=0.986, auc=0.999, precision=0.942, recall=0.988, val_loss=1.99, val_accuracy=0.83, val_auc=0.778, val_precision=0.551, val_recall=0.542, lr=4.61e-5]  64%|██████▍   | 58/90 [41:16:34<22:34:19, 2539.35s/epoch, loss=0.17, accuracy=0.988, auc=0.999, precision=0.95, recall=0.989, val_loss=2.05, val_accuracy=0.821, val_auc=0.747, val_precision=0.529, val_recall=0.476, lr=4.61e-5]  66%|██████▌   | 59/90 [41:58:57<21:52:35, 2540.51s/epoch, loss=0.172, accuracy=0.987, auc=0.999, precision=0.946, recall=0.988, val_loss=2.04, val_accuracy=0.838, val_auc=0.775, val_precision=0.576, val_recall=0.528, lr=4.61e-5] 67%|██████▋   | 60/90 [42:41:19<21:10:29, 2540.97s/epoch, loss=0.172, accuracy=0.987, auc=0.999, precision=0.946, recall=0.988, val_loss=1.9, val_accuracy=0.817, val_auc=0.767, val_precision=0.515, val_recall=0.529, lr=4.61e-5]  68%|██████▊   | 61/90 [43:23:29<20:26:34, 2537.75s/epoch, loss=0.149, accuracy=0.996, auc=1, precision=0.981, recall=0.997, val_loss=2.09, val_accuracy=0.834, val_auc=0.769, val_precision=0.567, val_recall=0.515, lr=9.23e-6]    69%|██████▉   | 62/90 [44:05:54<19:45:20, 2540.02s/epoch, loss=0.143, accuracy=0.998, auc=1, precision=0.99, recall=0.998, val_loss=2.15, val_accuracy=0.833, val_auc=0.768, val_precision=0.563, val_recall=0.509, lr=9.23e-6]  70%|███████   | 63/90 [44:48:14<19:02:54, 2539.78s/epoch, loss=0.139, accuracy=0.999, auc=1, precision=0.995, recall=0.999, val_loss=2.11, val_accuracy=0.832, val_auc=0.774, val_precision=0.557, val_recall=0.54, lr=9.23e-6] 71%|███████   | 64/90 [45:30:38<18:21:11, 2541.22s/epoch, loss=0.138, accuracy=0.999, auc=1, precision=0.996, recall=0.999, val_loss=2.23, val_accuracy=0.837, val_auc=0.77, val_precision=0.575, val_recall=0.52, lr=9.23e-6]  72%|███████▏  | 65/90 [46:13:03<17:39:15, 2542.23s/epoch, loss=0.137, accuracy=0.999, auc=1, precision=0.996, recall=1, val_loss=2.18, val_accuracy=0.832, val_auc=0.773, val_precision=0.557, val_recall=0.543, lr=9.23e-6]   73%|███████▎  | 66/90 [46:55:46<16:59:25, 2548.56s/epoch, loss=0.137, accuracy=0.999, auc=1, precision=0.996, recall=1, val_loss=2.36, val_accuracy=0.837, val_auc=0.766, val_precision=0.578, val_recall=0.509, lr=9.23e-6] 74%|███████▍  | 67/90 [47:38:08<16:16:10, 2546.52s/epoch, loss=0.136, accuracy=0.999, auc=1, precision=0.997, recall=0.999, val_loss=2.32, val_accuracy=0.837, val_auc=0.767, val_precision=0.573, val_recall=0.524, lr=9.23e-6] 76%|███████▌  | 68/90 [48:20:36<15:33:56, 2547.10s/epoch, loss=0.136, accuracy=0.999, auc=1, precision=0.997, recall=0.999, val_loss=2.46, val_accuracy=0.842, val_auc=0.765, val_precision=0.597, val_recall=0.498, lr=9.23e-6] 77%|███████▋  | 69/90 [49:03:05<14:51:40, 2547.63s/epoch, loss=0.135, accuracy=1, auc=1, precision=0.998, recall=1, val_loss=2.41, val_accuracy=0.84, val_auc=0.769, val_precision=0.586, val_recall=0.519, lr=9.23e-6]          78%|███████▊  | 70/90 [49:45:45<14:10:24, 2551.25s/epoch, loss=0.134, accuracy=0.999, auc=1, precision=0.998, recall=0.999, val_loss=2.37, val_accuracy=0.837, val_auc=0.767, val_precision=0.573, val_recall=0.522, lr=9.23e-6] 79%|███████▉  | 71/90 [50:28:11<13:27:26, 2549.80s/epoch, loss=0.134, accuracy=1, auc=1, precision=0.998, recall=1, val_loss=2.39, val_accuracy=0.836, val_auc=0.769, val_precision=0.57, val_recall=0.523, lr=9.23e-6]          80%|████████  | 72/90 [51:10:53<12:45:59, 2553.32s/epoch, loss=0.133, accuracy=1, auc=1, precision=0.998, recall=1, val_loss=2.35, val_accuracy=0.834, val_auc=0.77, val_precision=0.565, val_recall=0.53, lr=9.23e-6]  81%|████████  | 73/90 [51:53:18<12:02:42, 2550.76s/epoch, loss=0.133, accuracy=1, auc=1, precision=0.999, recall=1, val_loss=2.6, val_accuracy=0.842, val_auc=0.76, val_precision=0.596, val_recall=0.493, lr=9.23e-6] 82%|████████▏ | 74/90 [52:35:50<11:20:22, 2551.39s/epoch, loss=0.133, accuracy=0.999, auc=1, precision=0.998, recall=1, val_loss=2.54, val_accuracy=0.842, val_auc=0.767, val_precision=0.594, val_recall=0.514, lr=9.23e-6] 83%|████████▎ | 75/90 [53:18:25<10:38:03, 2552.21s/epoch, loss=0.133, accuracy=1, auc=1, precision=0.998, recall=1, val_loss=2.57, val_accuracy=0.843, val_auc=0.763, val_precision=0.598, val_recall=0.506, lr=9.23e-6]     84%|████████▍ | 76/90 [54:00:59<9:55:40, 2552.91s/epoch, loss=0.133, accuracy=0.999, auc=1, precision=0.998, recall=1, val_loss=2.62, val_accuracy=0.844, val_auc=0.761, val_precision=0.604, val_recall=0.502, lr=9.23e-6] 86%|████████▌ | 77/90 [54:43:33<9:13:10, 2553.09s/epoch, loss=0.132, accuracy=1, auc=1, precision=0.999, recall=1, val_loss=2.53, val_accuracy=0.839, val_auc=0.766, val_precision=0.582, val_recall=0.516, lr=9.23e-6]     87%|████████▋ | 78/90 [55:26:02<8:30:24, 2552.01s/epoch, loss=0.132, accuracy=1, auc=1, precision=0.999, recall=1, val_loss=2.59, val_accuracy=0.841, val_auc=0.765, val_precision=0.59, val_recall=0.513, lr=9.23e-6]  88%|████████▊ | 79/90 [56:08:31<7:47:42, 2551.16s/epoch, loss=0.131, accuracy=1, auc=1, precision=1, recall=1, val_loss=2.6, val_accuracy=0.841, val_auc=0.764, val_precision=0.59, val_recall=0.514, lr=9.23e-6]      89%|████████▉ | 80/90 [56:51:06<7:05:23, 2552.34s/epoch, loss=0.131, accuracy=1, auc=1, precision=0.999, recall=1, val_loss=2.61, val_accuracy=0.84, val_auc=0.762, val_precision=0.588, val_recall=0.509, lr=9.23e-6] 90%|█████████ | 81/90 [57:33:36<6:22:43, 2551.47s/epoch, loss=0.131, accuracy=1, auc=1, precision=0.999, recall=1, val_loss=2.41, val_accuracy=0.83, val_auc=0.77, val_precision=0.55, val_recall=0.546, lr=9.23e-6]   91%|█████████ | 82/90 [58:16:17<5:40:33, 2554.24s/epoch, loss=0.13, accuracy=1, auc=1, precision=0.999, recall=1, val_loss=2.73, val_accuracy=0.843, val_auc=0.76, val_precision=0.602, val_recall=0.49, lr=9.23e-6] 92%|█████████▏| 83/90 [58:58:52<4:58:02, 2554.65s/epoch, loss=0.13, accuracy=1, auc=1, precision=0.999, recall=1, val_loss=2.65, val_accuracy=0.843, val_auc=0.763, val_precision=0.598, val_recall=0.513, lr=9.23e-6] 93%|█████████▎| 84/90 [59:41:23<4:15:20, 2553.47s/epoch, loss=0.131, accuracy=1, auc=1, precision=0.998, recall=1, val_loss=2.49, val_accuracy=0.831, val_auc=0.763, val_precision=0.555, val_recall=0.526, lr=9.23e-6] 94%|█████████▍| 85/90 [60:23:59<3:32:51, 2554.36s/epoch, loss=0.13, accuracy=1, auc=1, precision=0.999, recall=1, val_loss=2.62, val_accuracy=0.84, val_auc=0.762, val_precision=0.586, val_recall=0.512, lr=9.23e-6]   96%|█████████▌| 86/90 [61:06:30<2:50:13, 2553.33s/epoch, loss=0.129, accuracy=1, auc=1, precision=0.999, recall=1, val_loss=2.64, val_accuracy=0.84, val_auc=0.764, val_precision=0.585, val_recall=0.513, lr=9.23e-6] 97%|█████████▋| 87/90 [61:49:11<2:07:46, 2555.43s/epoch, loss=0.129, accuracy=1, auc=1, precision=1, recall=1, val_loss=2.59, val_accuracy=0.839, val_auc=0.765, val_precision=0.579, val_recall=0.525, lr=9.23e-6]    98%|█████████▊| 88/90 [62:31:48<1:25:11, 2555.98s/epoch, loss=0.129, accuracy=1, auc=1, precision=0.999, recall=1, val_loss=2.46, val_accuracy=0.829, val_auc=0.769, val_precision=0.548, val_recall=0.549, lr=9.23e-6] 99%|█████████▉| 89/90 [63:14:05<42:30, 2550.41s/epoch, loss=0.128, accuracy=1, auc=1, precision=0.999, recall=1, val_loss=2.67, val_accuracy=0.842, val_auc=0.764, val_precision=0.591, val_recall=0.519, lr=9.23e-6]  100%|██████████| 90/90 [63:56:33<00:00, 2549.60s/epoch, loss=0.128, accuracy=1, auc=1, precision=1, recall=1, val_loss=2.75, val_accuracy=0.842, val_auc=0.758, val_precision=0.596, val_recall=0.503, lr=9.23e-6]    100%|██████████| 90/90 [63:56:33<00:00, 2557.70s/epoch, loss=0.128, accuracy=1, auc=1, precision=1, recall=1, val_loss=2.75, val_accuracy=0.842, val_auc=0.758, val_precision=0.596, val_recall=0.503, lr=9.23e-6]
Only one model saved

Loading model: 03_retinopathy_ResNet50v1.h5
Test score: 2.761476993560791
Test accuracy: 0.8395125269889832
Val score: 2.745988368988037
Val accuracy: 0.8420135974884033
