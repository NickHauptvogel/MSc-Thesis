Wed Feb 14 14:52:47 2024       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA TITAN X (Pascal)        Off | 00000000:03:00.0 Off |                  N/A |
| 46%   64C    P8              16W / 250W |      0MiB / 12288MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|  No running processes found                                                           |
+---------------------------------------------------------------------------------------+


* * * Run SGD for seed = 21. * * *


2024-02-14 14:52:49.018327: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-14 14:53:03.521868: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-14 14:53:03.523220: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-14 14:53:03.563888: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-14 14:53:03.563915: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-14 14:53:03.643996: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-14 14:53:03.644069: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-14 14:53:03.735270: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-14 14:53:03.899960: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-14 14:53:04.011817: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-14 14:53:04.077686: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-14 14:53:04.253051: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-14 14:53:04.254103: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-14 14:53:04.254203: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-14 14:53:06.215698: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-14 14:53:06.216596: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-14 14:53:06.217037: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-14 14:53:06.217069: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-14 14:53:06.217101: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-14 14:53:06.217118: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-14 14:53:06.217135: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-14 14:53:06.217151: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-14 14:53:06.217167: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-14 14:53:06.217184: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-14 14:53:06.217200: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-14 14:53:06.217692: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-14 14:53:06.217726: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-14 14:53:07.320253: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-14 14:53:07.320347: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-14 14:53:07.320359: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-14 14:53:07.321599: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:03:00.0, compute capability: 6.1)
{'seed': 21, 'batch_size': 128, 'epochs': 200, 'data_augmentation': True, 'augm_shift': 0.1, 'initial_lr': 0.001, 'l2_reg': 0.0001, 'optimizer': 'adam', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 test samples
y_train shape: (50000, 1)
Learning rate:  0.001
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/200 [00:00<?, ?epoch/s]2024-02-14 14:53:08.042705: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-14 14:53:08.043109: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2599900000 Hz
2024-02-14 14:53:09.913914: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-14 14:53:10.162569: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-14 14:53:10.997416: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-14 14:53:11.026085: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  0%|          | 1/200 [00:51<2:49:20, 51.06s/epoch, loss=1.65, accuracy=0.453, val_loss=1.64, val_accuracy=0.479, lr=0.001]  1%|          | 2/200 [01:09<1:44:53, 31.79s/epoch, loss=1.26, accuracy=0.601, val_loss=1.46, val_accuracy=0.552, lr=0.001]  2%|▏         | 3/200 [01:27<1:23:18, 25.37s/epoch, loss=1.08, accuracy=0.673, val_loss=1.15, val_accuracy=0.65, lr=0.001]   2%|▏         | 4/200 [01:44<1:12:47, 22.28s/epoch, loss=0.962, accuracy=0.714, val_loss=1.19, val_accuracy=0.641, lr=0.001]  2%|▎         | 5/200 [02:02<1:06:54, 20.59s/epoch, loss=0.879, accuracy=0.744, val_loss=1.19, val_accuracy=0.671, lr=0.001]  3%|▎         | 6/200 [02:19<1:03:13, 19.55s/epoch, loss=0.82, accuracy=0.764, val_loss=0.992, val_accuracy=0.714, lr=0.001]  4%|▎         | 7/200 [02:37<1:00:55, 18.94s/epoch, loss=0.779, accuracy=0.779, val_loss=0.931, val_accuracy=0.736, lr=0.001]  4%|▍         | 8/200 [02:55<59:25, 18.57s/epoch, loss=0.739, accuracy=0.793, val_loss=1.01, val_accuracy=0.699, lr=0.001]     4%|▍         | 9/200 [03:12<58:06, 18.25s/epoch, loss=0.71, accuracy=0.804, val_loss=1.11, val_accuracy=0.681, lr=0.001]   5%|▌         | 10/200 [03:30<57:13, 18.07s/epoch, loss=0.683, accuracy=0.814, val_loss=0.945, val_accuracy=0.733, lr=0.001]  6%|▌         | 11/200 [03:48<56:29, 17.93s/epoch, loss=0.658, accuracy=0.82, val_loss=0.795, val_accuracy=0.786, lr=0.001]   6%|▌         | 12/200 [04:05<55:43, 17.79s/epoch, loss=0.646, accuracy=0.827, val_loss=0.891, val_accuracy=0.751, lr=0.001]  6%|▋         | 13/200 [04:22<55:03, 17.66s/epoch, loss=0.616, accuracy=0.835, val_loss=0.803, val_accuracy=0.777, lr=0.001]  7%|▋         | 14/200 [04:40<54:46, 17.67s/epoch, loss=0.602, accuracy=0.843, val_loss=0.773, val_accuracy=0.797, lr=0.001]  8%|▊         | 15/200 [04:58<54:42, 17.74s/epoch, loss=0.591, accuracy=0.846, val_loss=0.805, val_accuracy=0.784, lr=0.001]  8%|▊         | 16/200 [05:16<54:18, 17.71s/epoch, loss=0.58, accuracy=0.85, val_loss=0.703, val_accuracy=0.816, lr=0.001]    8%|▊         | 17/200 [05:33<53:40, 17.60s/epoch, loss=0.561, accuracy=0.856, val_loss=0.809, val_accuracy=0.783, lr=0.001]  9%|▉         | 18/200 [05:50<53:10, 17.53s/epoch, loss=0.551, accuracy=0.859, val_loss=0.872, val_accuracy=0.775, lr=0.001] 10%|▉         | 19/200 [06:08<52:52, 17.53s/epoch, loss=0.545, accuracy=0.863, val_loss=0.86, val_accuracy=0.771, lr=0.001]  10%|█         | 20/200 [06:25<52:37, 17.54s/epoch, loss=0.531, accuracy=0.867, val_loss=0.9, val_accuracy=0.765, lr=0.001]  10%|█         | 21/200 [06:43<52:24, 17.57s/epoch, loss=0.523, accuracy=0.869, val_loss=0.686, val_accuracy=0.826, lr=0.001] 11%|█         | 22/200 [07:00<51:56, 17.51s/epoch, loss=0.517, accuracy=0.872, val_loss=0.845, val_accuracy=0.787, lr=0.001] 12%|█▏        | 23/200 [07:18<51:35, 17.49s/epoch, loss=0.511, accuracy=0.875, val_loss=0.825, val_accuracy=0.772, lr=0.001] 12%|█▏        | 24/200 [07:35<51:14, 17.47s/epoch, loss=0.501, accuracy=0.877, val_loss=0.736, val_accuracy=0.816, lr=0.001] 12%|█▎        | 25/200 [07:53<50:52, 17.44s/epoch, loss=0.498, accuracy=0.877, val_loss=0.821, val_accuracy=0.799, lr=0.001] 13%|█▎        | 26/200 [08:10<50:39, 17.47s/epoch, loss=0.491, accuracy=0.881, val_loss=1.03, val_accuracy=0.727, lr=0.000316] 14%|█▎        | 27/200 [08:28<50:24, 17.49s/epoch, loss=0.482, accuracy=0.884, val_loss=0.789, val_accuracy=0.799, lr=0.001]   14%|█▍        | 28/200 [08:45<50:09, 17.49s/epoch, loss=0.483, accuracy=0.882, val_loss=0.724, val_accuracy=0.814, lr=0.001] 14%|█▍        | 29/200 [09:03<50:00, 17.55s/epoch, loss=0.472, accuracy=0.887, val_loss=0.673, val_accuracy=0.831, lr=0.001] 15%|█▌        | 30/200 [09:20<49:33, 17.49s/epoch, loss=0.461, accuracy=0.892, val_loss=0.722, val_accuracy=0.823, lr=0.001] 16%|█▌        | 31/200 [09:38<49:13, 17.47s/epoch, loss=0.463, accuracy=0.892, val_loss=0.767, val_accuracy=0.813, lr=0.001] 16%|█▌        | 32/200 [09:55<48:54, 17.47s/epoch, loss=0.457, accuracy=0.893, val_loss=0.875, val_accuracy=0.78, lr=0.001]  16%|█▋        | 33/200 [10:13<48:37, 17.47s/epoch, loss=0.454, accuracy=0.895, val_loss=0.839, val_accuracy=0.796, lr=0.001] 17%|█▋        | 34/200 [10:30<48:29, 17.53s/epoch, loss=0.446, accuracy=0.898, val_loss=0.803, val_accuracy=0.804, lr=0.000316] 18%|█▊        | 35/200 [10:48<48:18, 17.57s/epoch, loss=0.45, accuracy=0.897, val_loss=0.583, val_accuracy=0.859, lr=0.001]     18%|█▊        | 36/200 [11:06<48:14, 17.65s/epoch, loss=0.442, accuracy=0.898, val_loss=0.764, val_accuracy=0.807, lr=0.001] 18%|█▊        | 37/200 [11:23<47:44, 17.57s/epoch, loss=0.435, accuracy=0.901, val_loss=0.746, val_accuracy=0.817, lr=0.001] 19%|█▉        | 38/200 [11:41<47:31, 17.60s/epoch, loss=0.435, accuracy=0.901, val_loss=0.659, val_accuracy=0.838, lr=0.001] 20%|█▉        | 39/200 [11:58<47:01, 17.53s/epoch, loss=0.43, accuracy=0.901, val_loss=0.814, val_accuracy=0.808, lr=0.001]  20%|██        | 40/200 [12:16<46:51, 17.57s/epoch, loss=0.434, accuracy=0.903, val_loss=0.778, val_accuracy=0.809, lr=0.000316] 20%|██        | 41/200 [12:34<46:41, 17.62s/epoch, loss=0.421, accuracy=0.907, val_loss=0.665, val_accuracy=0.839, lr=0.001]    21%|██        | 42/200 [12:51<46:18, 17.59s/epoch, loss=0.423, accuracy=0.905, val_loss=0.64, val_accuracy=0.841, lr=0.001]  22%|██▏       | 43/200 [13:09<45:54, 17.54s/epoch, loss=0.418, accuracy=0.907, val_loss=0.692, val_accuracy=0.836, lr=0.001] 22%|██▏       | 44/200 [13:26<45:29, 17.50s/epoch, loss=0.418, accuracy=0.908, val_loss=0.746, val_accuracy=0.819, lr=0.001] 22%|██▎       | 45/200 [13:44<45:16, 17.53s/epoch, loss=0.417, accuracy=0.908, val_loss=0.762, val_accuracy=0.821, lr=0.000316] 23%|██▎       | 46/200 [14:01<44:58, 17.52s/epoch, loss=0.414, accuracy=0.91, val_loss=0.687, val_accuracy=0.838, lr=0.001]     24%|██▎       | 47/200 [14:19<44:37, 17.50s/epoch, loss=0.406, accuracy=0.911, val_loss=0.895, val_accuracy=0.783, lr=0.001] 24%|██▍       | 48/200 [14:36<44:19, 17.49s/epoch, loss=0.407, accuracy=0.912, val_loss=0.721, val_accuracy=0.829, lr=0.001] 24%|██▍       | 49/200 [14:54<44:16, 17.60s/epoch, loss=0.405, accuracy=0.912, val_loss=0.639, val_accuracy=0.85, lr=0.001]  25%|██▌       | 50/200 [15:11<43:57, 17.59s/epoch, loss=0.402, accuracy=0.914, val_loss=0.613, val_accuracy=0.857, lr=0.000316] 26%|██▌       | 51/200 [15:29<43:42, 17.60s/epoch, loss=0.402, accuracy=0.914, val_loss=0.774, val_accuracy=0.818, lr=0.001]    26%|██▌       | 52/200 [15:47<43:20, 17.57s/epoch, loss=0.401, accuracy=0.915, val_loss=0.736, val_accuracy=0.831, lr=0.001] 26%|██▋       | 53/200 [16:04<42:57, 17.53s/epoch, loss=0.398, accuracy=0.915, val_loss=0.878, val_accuracy=0.788, lr=0.001] 27%|██▋       | 54/200 [16:21<42:37, 17.51s/epoch, loss=0.396, accuracy=0.916, val_loss=0.642, val_accuracy=0.852, lr=0.001] 28%|██▊       | 55/200 [16:39<42:19, 17.52s/epoch, loss=0.391, accuracy=0.919, val_loss=0.752, val_accuracy=0.823, lr=0.000316] 28%|██▊       | 56/200 [16:57<42:11, 17.58s/epoch, loss=0.393, accuracy=0.917, val_loss=0.621, val_accuracy=0.86, lr=0.001]     28%|██▊       | 57/200 [17:14<41:57, 17.60s/epoch, loss=0.391, accuracy=0.917, val_loss=0.682, val_accuracy=0.839, lr=0.001] 29%|██▉       | 58/200 [17:32<41:35, 17.57s/epoch, loss=0.394, accuracy=0.918, val_loss=0.662, val_accuracy=0.848, lr=0.001] 30%|██▉       | 59/200 [17:50<41:25, 17.63s/epoch, loss=0.385, accuracy=0.921, val_loss=0.727, val_accuracy=0.838, lr=0.001] 30%|███       | 60/200 [18:07<41:06, 17.62s/epoch, loss=0.384, accuracy=0.921, val_loss=0.785, val_accuracy=0.819, lr=0.000316] 30%|███       | 61/200 [18:25<40:42, 17.57s/epoch, loss=0.386, accuracy=0.92, val_loss=0.872, val_accuracy=0.794, lr=0.001]     31%|███       | 62/200 [18:42<40:22, 17.55s/epoch, loss=0.385, accuracy=0.921, val_loss=0.623, val_accuracy=0.856, lr=0.001] 32%|███▏      | 63/200 [19:00<40:13, 17.61s/epoch, loss=0.383, accuracy=0.922, val_loss=0.63, val_accuracy=0.856, lr=0.001]  32%|███▏      | 64/200 [19:17<39:50, 17.58s/epoch, loss=0.38, accuracy=0.922, val_loss=0.728, val_accuracy=0.835, lr=0.001] 32%|███▎      | 65/200 [19:35<39:30, 17.56s/epoch, loss=0.383, accuracy=0.922, val_loss=0.676, val_accuracy=0.841, lr=0.000316] 33%|███▎      | 66/200 [19:52<39:09, 17.54s/epoch, loss=0.379, accuracy=0.923, val_loss=0.677, val_accuracy=0.841, lr=0.001]    34%|███▎      | 67/200 [20:10<38:54, 17.55s/epoch, loss=0.376, accuracy=0.924, val_loss=0.743, val_accuracy=0.83, lr=0.001]  34%|███▍      | 68/200 [20:27<38:32, 17.52s/epoch, loss=0.369, accuracy=0.926, val_loss=0.774, val_accuracy=0.83, lr=0.001] 34%|███▍      | 69/200 [20:45<38:10, 17.48s/epoch, loss=0.375, accuracy=0.926, val_loss=0.719, val_accuracy=0.837, lr=0.001] 35%|███▌      | 70/200 [21:02<37:49, 17.46s/epoch, loss=0.373, accuracy=0.926, val_loss=0.705, val_accuracy=0.842, lr=0.000316] 36%|███▌      | 71/200 [21:20<37:47, 17.58s/epoch, loss=0.376, accuracy=0.925, val_loss=0.633, val_accuracy=0.852, lr=0.001]    36%|███▌      | 72/200 [21:38<37:23, 17.53s/epoch, loss=0.371, accuracy=0.926, val_loss=0.747, val_accuracy=0.841, lr=0.001] 36%|███▋      | 73/200 [21:55<37:04, 17.52s/epoch, loss=0.372, accuracy=0.927, val_loss=0.681, val_accuracy=0.847, lr=0.001] 37%|███▋      | 74/200 [22:12<36:44, 17.50s/epoch, loss=0.37, accuracy=0.927, val_loss=0.69, val_accuracy=0.842, lr=0.001]   38%|███▊      | 75/200 [22:30<36:40, 17.61s/epoch, loss=0.37, accuracy=0.927, val_loss=0.862, val_accuracy=0.807, lr=0.000316] 38%|███▊      | 76/200 [22:48<36:25, 17.62s/epoch, loss=0.365, accuracy=0.929, val_loss=0.63, val_accuracy=0.861, lr=0.001]    38%|███▊      | 77/200 [23:05<36:00, 17.56s/epoch, loss=0.367, accuracy=0.928, val_loss=0.693, val_accuracy=0.838, lr=0.001] 39%|███▉      | 78/200 [23:23<35:40, 17.54s/epoch, loss=0.367, accuracy=0.928, val_loss=0.723, val_accuracy=0.831, lr=0.001] 40%|███▉      | 79/200 [23:40<35:15, 17.48s/epoch, loss=0.36, accuracy=0.93, val_loss=0.69, val_accuracy=0.846, lr=0.001]    40%|████      | 80/200 [23:58<35:12, 17.60s/epoch, loss=0.361, accuracy=0.93, val_loss=0.685, val_accuracy=0.845, lr=0.000316] 40%|████      | 81/200 [24:16<34:51, 17.57s/epoch, loss=0.361, accuracy=0.931, val_loss=0.765, val_accuracy=0.831, lr=0.001]   41%|████      | 82/200 [24:34<34:44, 17.66s/epoch, loss=0.301, accuracy=0.952, val_loss=0.495, val_accuracy=0.894, lr=1e-04] 42%|████▏     | 83/200 [24:51<34:29, 17.69s/epoch, loss=0.277, accuracy=0.961, val_loss=0.487, val_accuracy=0.898, lr=1e-04] 42%|████▏     | 84/200 [25:09<34:02, 17.61s/epoch, loss=0.266, accuracy=0.964, val_loss=0.483, val_accuracy=0.896, lr=1e-04] 42%|████▎     | 85/200 [25:26<33:39, 17.56s/epoch, loss=0.257, accuracy=0.967, val_loss=0.494, val_accuracy=0.897, lr=1e-04] 43%|████▎     | 86/200 [25:44<33:20, 17.55s/epoch, loss=0.25, accuracy=0.97, val_loss=0.485, val_accuracy=0.897, lr=1e-04]   44%|████▎     | 87/200 [26:03<34:02, 18.07s/epoch, loss=0.246, accuracy=0.971, val_loss=0.494, val_accuracy=0.899, lr=1e-04] 44%|████▍     | 88/200 [26:20<33:24, 17.89s/epoch, loss=0.242, accuracy=0.971, val_loss=0.5, val_accuracy=0.898, lr=1e-04]   44%|████▍     | 89/200 [26:38<33:00, 17.85s/epoch, loss=0.239, accuracy=0.972, val_loss=0.493, val_accuracy=0.898, lr=3.16e-5] 45%|████▌     | 90/200 [26:56<32:53, 17.94s/epoch, loss=0.235, accuracy=0.973, val_loss=0.493, val_accuracy=0.9, lr=1e-04]     46%|████▌     | 91/200 [27:14<32:20, 17.80s/epoch, loss=0.23, accuracy=0.974, val_loss=0.502, val_accuracy=0.897, lr=1e-04] 46%|████▌     | 92/200 [27:31<31:52, 17.71s/epoch, loss=0.23, accuracy=0.974, val_loss=0.498, val_accuracy=0.897, lr=1e-04] 46%|████▋     | 93/200 [27:50<31:53, 17.89s/epoch, loss=0.226, accuracy=0.975, val_loss=0.498, val_accuracy=0.901, lr=1e-04] 47%|████▋     | 94/200 [28:07<31:23, 17.76s/epoch, loss=0.221, accuracy=0.976, val_loss=0.501, val_accuracy=0.901, lr=3.16e-5] 48%|████▊     | 95/200 [28:25<30:59, 17.71s/epoch, loss=0.219, accuracy=0.977, val_loss=0.503, val_accuracy=0.9, lr=1e-04]     48%|████▊     | 96/200 [28:42<30:40, 17.69s/epoch, loss=0.217, accuracy=0.977, val_loss=0.505, val_accuracy=0.9, lr=1e-04] 48%|████▊     | 97/200 [29:00<30:19, 17.67s/epoch, loss=0.215, accuracy=0.977, val_loss=0.518, val_accuracy=0.894, lr=1e-04] 49%|████▉     | 98/200 [29:17<29:55, 17.60s/epoch, loss=0.211, accuracy=0.978, val_loss=0.517, val_accuracy=0.897, lr=1e-04] 50%|████▉     | 99/200 [29:35<29:31, 17.54s/epoch, loss=0.208, accuracy=0.979, val_loss=0.503, val_accuracy=0.898, lr=3.16e-5] 50%|█████     | 100/200 [29:52<29:12, 17.52s/epoch, loss=0.211, accuracy=0.978, val_loss=0.517, val_accuracy=0.899, lr=1e-04]  50%|█████     | 101/200 [30:10<28:51, 17.49s/epoch, loss=0.205, accuracy=0.979, val_loss=0.516, val_accuracy=0.896, lr=1e-04] 51%|█████     | 102/200 [30:27<28:28, 17.43s/epoch, loss=0.205, accuracy=0.979, val_loss=0.5, val_accuracy=0.899, lr=1e-04]   52%|█████▏    | 103/200 [30:44<28:08, 17.41s/epoch, loss=0.202, accuracy=0.979, val_loss=0.514, val_accuracy=0.898, lr=1e-04] 52%|█████▏    | 104/200 [31:02<27:49, 17.39s/epoch, loss=0.2, accuracy=0.979, val_loss=0.504, val_accuracy=0.901, lr=3.16e-5] 52%|█████▎    | 105/200 [31:19<27:39, 17.46s/epoch, loss=0.199, accuracy=0.98, val_loss=0.52, val_accuracy=0.897, lr=1e-04]   53%|█████▎    | 106/200 [31:37<27:18, 17.43s/epoch, loss=0.195, accuracy=0.981, val_loss=0.513, val_accuracy=0.9, lr=1e-04] 54%|█████▎    | 107/200 [31:54<27:00, 17.42s/epoch, loss=0.194, accuracy=0.98, val_loss=0.521, val_accuracy=0.898, lr=1e-04] 54%|█████▍    | 108/200 [32:12<26:44, 17.44s/epoch, loss=0.193, accuracy=0.981, val_loss=0.529, val_accuracy=0.899, lr=1e-04] 55%|█████▍    | 109/200 [32:29<26:24, 17.41s/epoch, loss=0.192, accuracy=0.981, val_loss=0.514, val_accuracy=0.901, lr=3.16e-5] 55%|█████▌    | 110/200 [32:46<26:05, 17.39s/epoch, loss=0.187, accuracy=0.983, val_loss=0.52, val_accuracy=0.9, lr=1e-04]      56%|█████▌    | 111/200 [33:04<25:45, 17.37s/epoch, loss=0.187, accuracy=0.982, val_loss=0.529, val_accuracy=0.897, lr=1e-04] 56%|█████▌    | 112/200 [33:21<25:38, 17.49s/epoch, loss=0.186, accuracy=0.982, val_loss=0.517, val_accuracy=0.9, lr=1e-04]   56%|█████▋    | 113/200 [33:39<25:27, 17.56s/epoch, loss=0.185, accuracy=0.983, val_loss=0.527, val_accuracy=0.901, lr=1e-04] 57%|█████▋    | 114/200 [33:57<25:13, 17.60s/epoch, loss=0.184, accuracy=0.983, val_loss=0.529, val_accuracy=0.903, lr=3.16e-5] 57%|█████▊    | 115/200 [34:14<24:51, 17.54s/epoch, loss=0.181, accuracy=0.983, val_loss=0.536, val_accuracy=0.898, lr=1e-04]   58%|█████▊    | 116/200 [34:32<24:35, 17.56s/epoch, loss=0.178, accuracy=0.985, val_loss=0.529, val_accuracy=0.899, lr=1e-04] 58%|█████▊    | 117/200 [34:49<24:15, 17.54s/epoch, loss=0.18, accuracy=0.983, val_loss=0.536, val_accuracy=0.896, lr=1e-04]  59%|█████▉    | 118/200 [35:07<23:52, 17.47s/epoch, loss=0.178, accuracy=0.984, val_loss=0.539, val_accuracy=0.9, lr=1e-04]  60%|█████▉    | 119/200 [35:24<23:41, 17.55s/epoch, loss=0.177, accuracy=0.984, val_loss=0.53, val_accuracy=0.899, lr=3.16e-5] 60%|██████    | 120/200 [35:42<23:21, 17.52s/epoch, loss=0.175, accuracy=0.985, val_loss=0.533, val_accuracy=0.896, lr=1e-04]  60%|██████    | 121/200 [35:59<23:01, 17.49s/epoch, loss=0.173, accuracy=0.985, val_loss=0.535, val_accuracy=0.897, lr=1e-04] 61%|██████    | 122/200 [36:17<22:44, 17.50s/epoch, loss=0.171, accuracy=0.985, val_loss=0.519, val_accuracy=0.899, lr=1e-5]  62%|██████▏   | 123/200 [36:34<22:26, 17.48s/epoch, loss=0.167, accuracy=0.987, val_loss=0.515, val_accuracy=0.9, lr=1e-5]   62%|██████▏   | 124/200 [36:52<22:09, 17.50s/epoch, loss=0.164, accuracy=0.989, val_loss=0.52, val_accuracy=0.899, lr=3.16e-6] 62%|██████▎   | 125/200 [37:09<21:50, 17.47s/epoch, loss=0.166, accuracy=0.988, val_loss=0.519, val_accuracy=0.901, lr=1e-5]   63%|██████▎   | 126/200 [37:26<21:31, 17.46s/epoch, loss=0.165, accuracy=0.989, val_loss=0.516, val_accuracy=0.901, lr=1e-5] 64%|██████▎   | 127/200 [37:44<21:14, 17.46s/epoch, loss=0.164, accuracy=0.989, val_loss=0.518, val_accuracy=0.9, lr=1e-5]   64%|██████▍   | 128/200 [38:01<20:57, 17.47s/epoch, loss=0.165, accuracy=0.988, val_loss=0.518, val_accuracy=0.9, lr=1e-5] 64%|██████▍   | 129/200 [38:19<20:40, 17.47s/epoch, loss=0.162, accuracy=0.989, val_loss=0.52, val_accuracy=0.901, lr=3.16e-6] 65%|██████▌   | 130/200 [38:36<20:24, 17.49s/epoch, loss=0.163, accuracy=0.989, val_loss=0.521, val_accuracy=0.9, lr=1e-5]     66%|██████▌   | 131/200 [38:55<20:20, 17.68s/epoch, loss=0.163, accuracy=0.989, val_loss=0.522, val_accuracy=0.899, lr=1e-5] 66%|██████▌   | 132/200 [39:13<20:07, 17.76s/epoch, loss=0.161, accuracy=0.989, val_loss=0.518, val_accuracy=0.901, lr=1e-5] 66%|██████▋   | 133/200 [39:30<19:45, 17.69s/epoch, loss=0.163, accuracy=0.988, val_loss=0.518, val_accuracy=0.901, lr=1e-5] 67%|██████▋   | 134/200 [39:48<19:28, 17.70s/epoch, loss=0.163, accuracy=0.988, val_loss=0.518, val_accuracy=0.901, lr=3.16e-6] 68%|██████▊   | 135/200 [40:05<19:08, 17.67s/epoch, loss=0.161, accuracy=0.99, val_loss=0.52, val_accuracy=0.901, lr=1e-5]      68%|██████▊   | 136/200 [40:23<18:46, 17.59s/epoch, loss=0.161, accuracy=0.989, val_loss=0.52, val_accuracy=0.9, lr=1e-5]  68%|██████▊   | 137/200 [40:40<18:30, 17.63s/epoch, loss=0.161, accuracy=0.989, val_loss=0.52, val_accuracy=0.9, lr=1e-5] 69%|██████▉   | 138/200 [40:58<18:09, 17.57s/epoch, loss=0.161, accuracy=0.988, val_loss=0.524, val_accuracy=0.9, lr=1e-5] 70%|██████▉   | 139/200 [41:15<17:49, 17.54s/epoch, loss=0.161, accuracy=0.989, val_loss=0.523, val_accuracy=0.9, lr=3.16e-6] 70%|███████   | 140/200 [41:33<17:38, 17.64s/epoch, loss=0.162, accuracy=0.989, val_loss=0.524, val_accuracy=0.9, lr=1e-5]    70%|███████   | 141/200 [41:51<17:17, 17.58s/epoch, loss=0.16, accuracy=0.989, val_loss=0.522, val_accuracy=0.9, lr=1e-5]  71%|███████   | 142/200 [42:08<16:56, 17.53s/epoch, loss=0.161, accuracy=0.989, val_loss=0.522, val_accuracy=0.901, lr=1e-5] 72%|███████▏  | 143/200 [42:25<16:36, 17.48s/epoch, loss=0.16, accuracy=0.989, val_loss=0.521, val_accuracy=0.9, lr=1e-5]    72%|███████▏  | 144/200 [42:43<16:19, 17.48s/epoch, loss=0.16, accuracy=0.989, val_loss=0.526, val_accuracy=0.9, lr=3.16e-6] 72%|███████▎  | 145/200 [43:00<16:00, 17.47s/epoch, loss=0.16, accuracy=0.989, val_loss=0.522, val_accuracy=0.901, lr=1e-5]  73%|███████▎  | 146/200 [43:18<15:41, 17.44s/epoch, loss=0.157, accuracy=0.991, val_loss=0.523, val_accuracy=0.901, lr=1e-5] 74%|███████▎  | 147/200 [43:35<15:26, 17.47s/epoch, loss=0.159, accuracy=0.989, val_loss=0.524, val_accuracy=0.9, lr=1e-5]   74%|███████▍  | 148/200 [43:53<15:07, 17.46s/epoch, loss=0.159, accuracy=0.989, val_loss=0.524, val_accuracy=0.9, lr=1e-5] 74%|███████▍  | 149/200 [44:10<14:49, 17.44s/epoch, loss=0.157, accuracy=0.99, val_loss=0.524, val_accuracy=0.901, lr=3.16e-6] 75%|███████▌  | 150/200 [44:28<14:32, 17.46s/epoch, loss=0.157, accuracy=0.99, val_loss=0.525, val_accuracy=0.902, lr=1e-5]    76%|███████▌  | 151/200 [44:45<14:21, 17.58s/epoch, loss=0.16, accuracy=0.988, val_loss=0.523, val_accuracy=0.901, lr=1e-5] 76%|███████▌  | 152/200 [45:03<14:06, 17.64s/epoch, loss=0.159, accuracy=0.989, val_loss=0.523, val_accuracy=0.902, lr=1e-5] 76%|███████▋  | 153/200 [45:21<13:46, 17.59s/epoch, loss=0.158, accuracy=0.99, val_loss=0.525, val_accuracy=0.901, lr=1e-5]  77%|███████▋  | 154/200 [45:38<13:26, 17.53s/epoch, loss=0.158, accuracy=0.99, val_loss=0.524, val_accuracy=0.901, lr=3.16e-6] 78%|███████▊  | 155/200 [45:56<13:10, 17.56s/epoch, loss=0.156, accuracy=0.99, val_loss=0.527, val_accuracy=0.901, lr=1e-5]    78%|███████▊  | 156/200 [46:13<12:50, 17.52s/epoch, loss=0.157, accuracy=0.99, val_loss=0.525, val_accuracy=0.9, lr=1e-5]   78%|███████▊  | 157/200 [46:31<12:33, 17.52s/epoch, loss=0.158, accuracy=0.99, val_loss=0.526, val_accuracy=0.902, lr=1e-5] 79%|███████▉  | 158/200 [46:48<12:14, 17.48s/epoch, loss=0.157, accuracy=0.99, val_loss=0.525, val_accuracy=0.901, lr=1e-5] 80%|███████▉  | 159/200 [47:06<11:56, 17.47s/epoch, loss=0.156, accuracy=0.99, val_loss=0.525, val_accuracy=0.901, lr=3.16e-6] 80%|████████  | 160/200 [47:23<11:36, 17.41s/epoch, loss=0.156, accuracy=0.99, val_loss=0.527, val_accuracy=0.901, lr=1e-5]    80%|████████  | 161/200 [47:40<11:19, 17.42s/epoch, loss=0.156, accuracy=0.991, val_loss=0.526, val_accuracy=0.901, lr=1e-5] 81%|████████  | 162/200 [47:58<11:03, 17.47s/epoch, loss=0.156, accuracy=0.99, val_loss=0.526, val_accuracy=0.902, lr=1e-6]  82%|████████▏ | 163/200 [48:15<10:45, 17.45s/epoch, loss=0.157, accuracy=0.99, val_loss=0.526, val_accuracy=0.901, lr=1e-6] 82%|████████▏ | 164/200 [48:33<10:32, 17.57s/epoch, loss=0.155, accuracy=0.99, val_loss=0.526, val_accuracy=0.901, lr=5e-7] 82%|████████▎ | 165/200 [48:50<10:12, 17.50s/epoch, loss=0.155, accuracy=0.991, val_loss=0.527, val_accuracy=0.901, lr=1e-6] 83%|████████▎ | 166/200 [49:08<09:55, 17.50s/epoch, loss=0.154, accuracy=0.991, val_loss=0.526, val_accuracy=0.901, lr=1e-6] 84%|████████▎ | 167/200 [49:26<09:39, 17.57s/epoch, loss=0.155, accuracy=0.99, val_loss=0.527, val_accuracy=0.901, lr=1e-6]  84%|████████▍ | 168/200 [49:43<09:22, 17.58s/epoch, loss=0.156, accuracy=0.99, val_loss=0.527, val_accuracy=0.901, lr=1e-6] 84%|████████▍ | 169/200 [50:01<09:03, 17.52s/epoch, loss=0.156, accuracy=0.99, val_loss=0.527, val_accuracy=0.901, lr=5e-7] 85%|████████▌ | 170/200 [50:18<08:44, 17.49s/epoch, loss=0.156, accuracy=0.99, val_loss=0.527, val_accuracy=0.901, lr=1e-6] 86%|████████▌ | 171/200 [50:36<08:27, 17.52s/epoch, loss=0.155, accuracy=0.99, val_loss=0.526, val_accuracy=0.901, lr=1e-6] 86%|████████▌ | 172/200 [50:54<08:13, 17.62s/epoch, loss=0.155, accuracy=0.99, val_loss=0.526, val_accuracy=0.9, lr=1e-6]   86%|████████▋ | 173/200 [51:11<07:54, 17.58s/epoch, loss=0.156, accuracy=0.99, val_loss=0.526, val_accuracy=0.9, lr=1e-6] 87%|████████▋ | 174/200 [51:28<07:35, 17.52s/epoch, loss=0.157, accuracy=0.99, val_loss=0.526, val_accuracy=0.901, lr=5e-7] 88%|████████▊ | 175/200 [51:46<07:18, 17.52s/epoch, loss=0.156, accuracy=0.99, val_loss=0.527, val_accuracy=0.9, lr=1e-6]   88%|████████▊ | 176/200 [52:03<07:00, 17.51s/epoch, loss=0.155, accuracy=0.99, val_loss=0.526, val_accuracy=0.9, lr=1e-6] 88%|████████▊ | 177/200 [52:21<06:42, 17.50s/epoch, loss=0.154, accuracy=0.991, val_loss=0.526, val_accuracy=0.9, lr=1e-6] 89%|████████▉ | 178/200 [52:38<06:24, 17.50s/epoch, loss=0.155, accuracy=0.99, val_loss=0.527, val_accuracy=0.9, lr=1e-6]  90%|████████▉ | 179/200 [52:56<06:07, 17.49s/epoch, loss=0.155, accuracy=0.99, val_loss=0.526, val_accuracy=0.9, lr=5e-7] 90%|█████████ | 180/200 [53:13<05:49, 17.48s/epoch, loss=0.155, accuracy=0.99, val_loss=0.526, val_accuracy=0.901, lr=1e-6] 90%|█████████ | 181/200 [53:31<05:31, 17.46s/epoch, loss=0.156, accuracy=0.99, val_loss=0.527, val_accuracy=0.9, lr=1e-6]   91%|█████████ | 182/200 [53:48<05:13, 17.43s/epoch, loss=0.155, accuracy=0.991, val_loss=0.527, val_accuracy=0.9, lr=5e-7] 92%|█████████▏| 183/200 [54:05<04:56, 17.42s/epoch, loss=0.154, accuracy=0.991, val_loss=0.527, val_accuracy=0.9, lr=5e-7] 92%|█████████▏| 184/200 [54:23<04:38, 17.39s/epoch, loss=0.155, accuracy=0.991, val_loss=0.526, val_accuracy=0.901, lr=5e-7] 92%|█████████▎| 185/200 [54:40<04:22, 17.47s/epoch, loss=0.156, accuracy=0.99, val_loss=0.525, val_accuracy=0.901, lr=5e-7]  93%|█████████▎| 186/200 [54:58<04:05, 17.55s/epoch, loss=0.154, accuracy=0.991, val_loss=0.525, val_accuracy=0.9, lr=5e-7]  94%|█████████▎| 187/200 [55:16<03:48, 17.58s/epoch, loss=0.154, accuracy=0.99, val_loss=0.526, val_accuracy=0.9, lr=5e-7]  94%|█████████▍| 188/200 [55:33<03:30, 17.55s/epoch, loss=0.156, accuracy=0.99, val_loss=0.526, val_accuracy=0.901, lr=5e-7] 94%|█████████▍| 189/200 [55:51<03:12, 17.53s/epoch, loss=0.155, accuracy=0.99, val_loss=0.525, val_accuracy=0.9, lr=5e-7]   95%|█████████▌| 190/200 [56:08<02:55, 17.51s/epoch, loss=0.155, accuracy=0.99, val_loss=0.525, val_accuracy=0.9, lr=5e-7] 96%|█████████▌| 191/200 [56:26<02:37, 17.50s/epoch, loss=0.156, accuracy=0.99, val_loss=0.527, val_accuracy=0.9, lr=5e-7] 96%|█████████▌| 192/200 [56:43<02:19, 17.47s/epoch, loss=0.156, accuracy=0.99, val_loss=0.527, val_accuracy=0.9, lr=5e-7] 96%|█████████▋| 193/200 [57:01<02:02, 17.46s/epoch, loss=0.155, accuracy=0.991, val_loss=0.525, val_accuracy=0.901, lr=5e-7] 97%|█████████▋| 194/200 [57:18<01:44, 17.46s/epoch, loss=0.156, accuracy=0.99, val_loss=0.527, val_accuracy=0.9, lr=5e-7]    98%|█████████▊| 195/200 [57:36<01:27, 17.55s/epoch, loss=0.155, accuracy=0.99, val_loss=0.527, val_accuracy=0.9, lr=5e-7] 98%|█████████▊| 196/200 [57:53<01:10, 17.53s/epoch, loss=0.156, accuracy=0.99, val_loss=0.526, val_accuracy=0.9, lr=5e-7] 98%|█████████▊| 197/200 [58:11<00:52, 17.51s/epoch, loss=0.155, accuracy=0.99, val_loss=0.526, val_accuracy=0.9, lr=5e-7] 99%|█████████▉| 198/200 [58:32<00:36, 18.49s/epoch, loss=0.153, accuracy=0.991, val_loss=0.525, val_accuracy=0.901, lr=5e-7]100%|█████████▉| 199/200 [58:49<00:18, 18.33s/epoch, loss=0.155, accuracy=0.991, val_loss=0.525, val_accuracy=0.901, lr=5e-7]100%|██████████| 200/200 [59:08<00:00, 18.48s/epoch, loss=0.155, accuracy=0.99, val_loss=0.526, val_accuracy=0.9, lr=5e-7]   100%|██████████| 200/200 [59:08<00:00, 17.74s/epoch, loss=0.155, accuracy=0.99, val_loss=0.526, val_accuracy=0.9, lr=5e-7]
Using real-time data augmentation.
Learning rate:  0.001
Learning rate:  0.001
Learning rate:  0.001
Learning rate:  0.001
Learning rate:  0.001
Learning rate:  0.001
Learning rate:  0.001
Learning rate:  0.001
Learning rate:  0.001
Learning rate:  0.001
Learning rate:  0.001
Learning rate:  0.001
Learning rate:  0.001
Learning rate:  0.001
Learning rate:  0.001
Learning rate:  0.001
Learning rate:  0.001
Learning rate:  0.001
Learning rate:  0.001
Learning rate:  0.001
Learning rate:  0.001
Learning rate:  0.001
Learning rate:  0.001
Learning rate:  0.001
Learning rate:  0.001
Learning rate:  0.001
Learning rate:  0.001
Learning rate:  0.001
Learning rate:  0.001
Learning rate:  0.001
Learning rate:  0.001
Learning rate:  0.001
Learning rate:  0.001
Learning rate:  0.001
Learning rate:  0.001
Learning rate:  0.001
Learning rate:  0.001
Learning rate:  0.001
Learning rate:  0.001
Learning rate:  0.001
Learning rate:  0.001
Learning rate:  0.001
Learning rate:  0.001
Learning rate:  0.001
Learning rate:  0.001
Learning rate:  0.001
Learning rate:  0.001
Learning rate:  0.001
Learning rate:  0.001
Learning rate:  0.001
Learning rate:  0.001
Learning rate:  0.001
Learning rate:  0.001
Learning rate:  0.001
Learning rate:  0.001
Learning rate:  0.001
Learning rate:  0.001
Learning rate:  0.001
Learning rate:  0.001
Learning rate:  0.001
Learning rate:  0.001
Learning rate:  0.001
Learning rate:  0.001
Learning rate:  0.001
Learning rate:  0.001
Learning rate:  0.001
Learning rate:  0.001
Learning rate:  0.001
Learning rate:  0.001
Learning rate:  0.001
Learning rate:  0.001
Learning rate:  0.001
Learning rate:  0.001
Learning rate:  0.001
Learning rate:  0.001
Learning rate:  0.001
Learning rate:  0.001
Learning rate:  0.001
Learning rate:  0.001
Learning rate:  0.001
Learning rate:  0.001
Learning rate:  0.0001
Learning rate:  0.0001
Learning rate:  0.0001
Learning rate:  0.0001
Learning rate:  0.0001
Learning rate:  0.0001
Learning rate:  0.0001
Learning rate:  0.0001
Learning rate:  0.0001
Learning rate:  0.0001
Learning rate:  0.0001
Learning rate:  0.0001
Learning rate:  0.0001
Learning rate:  0.0001
Learning rate:  0.0001
Learning rate:  0.0001
Learning rate:  0.0001
Learning rate:  0.0001
Learning rate:  0.0001
Learning rate:  0.0001
Learning rate:  0.0001
Learning rate:  0.0001
Learning rate:  0.0001
Learning rate:  0.0001
Learning rate:  0.0001
Learning rate:  0.0001
Learning rate:  0.0001
Learning rate:  0.0001
Learning rate:  0.0001
Learning rate:  0.0001
Learning rate:  0.0001
Learning rate:  0.0001
Learning rate:  0.0001
Learning rate:  0.0001
Learning rate:  0.0001
Learning rate:  0.0001
Learning rate:  0.0001
Learning rate:  0.0001
Learning rate:  0.0001
Learning rate:  0.0001
Learning rate:  1e-05
Learning rate:  1e-05
Learning rate:  1e-05
Learning rate:  1e-05
Learning rate:  1e-05
Learning rate:  1e-05
Learning rate:  1e-05
Learning rate:  1e-05
Learning rate:  1e-05
Learning rate:  1e-05
Learning rate:  1e-05
Learning rate:  1e-05
Learning rate:  1e-05
Learning rate:  1e-05
Learning rate:  1e-05
Learning rate:  1e-05
Learning rate:  1e-05
Learning rate:  1e-05
Learning rate:  1e-05
Learning rate:  1e-05
Learning rate:  1e-05
Learning rate:  1e-05
Learning rate:  1e-05
Learning rate:  1e-05
Learning rate:  1e-05
Learning rate:  1e-05
Learning rate:  1e-05
Learning rate:  1e-05
Learning rate:  1e-05
Learning rate:  1e-05
Learning rate:  1e-05
Learning rate:  1e-05
Learning rate:  1e-05
Learning rate:  1e-05
Learning rate:  1e-05
Learning rate:  1e-05
Learning rate:  1e-05
Learning rate:  1e-05
Learning rate:  1e-05
Learning rate:  1e-05
Learning rate:  1e-06
Learning rate:  1e-06
Learning rate:  1e-06
Learning rate:  1e-06
Learning rate:  1e-06
Learning rate:  1e-06
Learning rate:  1e-06
Learning rate:  1e-06
Learning rate:  1e-06
Learning rate:  1e-06
Learning rate:  1e-06
Learning rate:  1e-06
Learning rate:  1e-06
Learning rate:  1e-06
Learning rate:  1e-06
Learning rate:  1e-06
Learning rate:  1e-06
Learning rate:  1e-06
Learning rate:  1e-06
Learning rate:  1e-06
Learning rate:  5e-07
Learning rate:  5e-07
Learning rate:  5e-07
Learning rate:  5e-07
Learning rate:  5e-07
Learning rate:  5e-07
Learning rate:  5e-07
Learning rate:  5e-07
Learning rate:  5e-07
Learning rate:  5e-07
Learning rate:  5e-07
Learning rate:  5e-07
Learning rate:  5e-07
Learning rate:  5e-07
Learning rate:  5e-07
Learning rate:  5e-07
Learning rate:  5e-07
Learning rate:  5e-07
Learning rate:  5e-07
Test loss: 0.5262525677680969
Test accuracy: 0.9002000093460083
