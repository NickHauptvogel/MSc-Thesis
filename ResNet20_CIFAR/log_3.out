Tue Mar 12 08:06:04 2024       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 545.23.08              Driver Version: 545.23.08    CUDA Version: 12.3     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA TITAN Xp                Off | 00000000:83:00.0 Off |                  N/A |
| 23%   25C    P8               8W / 250W |      0MiB / 12288MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|  No running processes found                                                           |
+---------------------------------------------------------------------------------------+


* * * Run SGD for ID = 3. * * *


2024-03-12 08:06:13.002739: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-12 08:10:23.746550: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-12 08:10:23.749627: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-12 08:10:23.837328: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-12 08:10:23.837367: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-12 08:10:27.781193: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-12 08:10:27.781254: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-12 08:10:31.078173: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-12 08:10:53.575036: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-12 08:10:56.849486: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-12 08:10:57.305851: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-12 08:10:58.851720: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-12 08:10:58.852856: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-12 08:10:58.852968: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-12 08:11:05.585779: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-12 08:11:05.586793: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-12 08:11:05.638600: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-12 08:11:05.638645: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-12 08:11:05.638701: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-12 08:11:05.638720: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-12 08:11:05.638738: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-12 08:11:05.638756: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-12 08:11:05.638775: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-12 08:11:05.638792: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-12 08:11:05.638810: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-12 08:11:05.723869: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-12 08:11:05.723945: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-12 08:11:11.971950: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-12 08:11:11.972001: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-12 08:11:11.972010: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-12 08:11:11.973054: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': '03', 'seed': 3, 'out_folder': 'results/10_snapshot_every_40_wenzel_0_2_val', 'batch_size': 128, 'epochs': 200, 'validation_split': 0.2, 'checkpointing': True, 'checkpoint_every': 40, 'hold_out_validation_split': 0.0, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.2, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'bootstrapping': False, 'num_classes': 10, 'SSE_lr': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
x_train shape: (40000, 32, 32, 3)
40000 train samples
10000 validation samples
10000 test samples
y_train shape: (40000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/200 [00:00<?, ?epoch/s]2024-03-12 08:11:12.932332: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-12 08:11:12.932732: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199945000 Hz
2024-03-12 08:11:15.053834: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-12 08:11:15.566128: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-12 08:11:21.102519: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-12 08:11:21.273016: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  0%|          | 1/200 [02:08<7:05:26, 128.27s/epoch, loss=3.45, accuracy=0.198, val_loss=9.88, val_accuracy=0.111, lr=0.2]  1%|          | 2/200 [02:25<3:27:35, 62.90s/epoch, loss=1.85, accuracy=0.383, val_loss=2.35, val_accuracy=0.231, lr=0.2]   2%|▏         | 3/200 [02:42<2:17:54, 42.00s/epoch, loss=1.81, accuracy=0.43, val_loss=2.1, val_accuracy=0.322, lr=0.199]  2%|▏         | 4/200 [02:59<1:45:04, 32.16s/epoch, loss=1.63, accuracy=0.503, val_loss=2.59, val_accuracy=0.235, lr=0.197]  2%|▎         | 5/200 [03:17<1:27:27, 26.91s/epoch, loss=1.54, accuracy=0.561, val_loss=2.91, val_accuracy=0.249, lr=0.195]  3%|▎         | 6/200 [03:34<1:16:17, 23.60s/epoch, loss=1.49, accuracy=0.592, val_loss=3.72, val_accuracy=0.114, lr=0.192]  4%|▎         | 7/200 [03:51<1:09:00, 21.45s/epoch, loss=1.43, accuracy=0.626, val_loss=2.07, val_accuracy=0.398, lr=0.189]  4%|▍         | 8/200 [04:08<1:04:17, 20.09s/epoch, loss=1.4, accuracy=0.649, val_loss=2.5, val_accuracy=0.391, lr=0.185]    4%|▍         | 9/200 [04:25<1:00:55, 19.14s/epoch, loss=1.38, accuracy=0.662, val_loss=5.56, val_accuracy=0.177, lr=0.181]  5%|▌         | 10/200 [04:43<59:16, 18.72s/epoch, loss=1.37, accuracy=0.67, val_loss=2.88, val_accuracy=0.325, lr=0.176]    6%|▌         | 11/200 [05:01<57:52, 18.38s/epoch, loss=1.34, accuracy=0.677, val_loss=2.75, val_accuracy=0.333, lr=0.171]  6%|▌         | 12/200 [05:18<56:20, 17.98s/epoch, loss=1.34, accuracy=0.681, val_loss=5.05, val_accuracy=0.234, lr=0.165]  6%|▋         | 13/200 [05:37<57:08, 18.33s/epoch, loss=1.32, accuracy=0.686, val_loss=11.8, val_accuracy=0.157, lr=0.159]  7%|▋         | 14/200 [05:54<55:58, 18.06s/epoch, loss=1.3, accuracy=0.692, val_loss=2.24, val_accuracy=0.339, lr=0.152]   8%|▊         | 15/200 [06:11<54:48, 17.78s/epoch, loss=1.28, accuracy=0.698, val_loss=3.6, val_accuracy=0.187, lr=0.145]  8%|▊         | 16/200 [06:29<54:15, 17.69s/epoch, loss=1.26, accuracy=0.704, val_loss=2.75, val_accuracy=0.324, lr=0.138]  8%|▊         | 17/200 [06:46<53:27, 17.53s/epoch, loss=1.24, accuracy=0.712, val_loss=2.43, val_accuracy=0.379, lr=0.131]  9%|▉         | 18/200 [07:03<52:42, 17.38s/epoch, loss=1.22, accuracy=0.713, val_loss=2.02, val_accuracy=0.52, lr=0.123]  10%|▉         | 19/200 [07:22<54:19, 18.01s/epoch, loss=1.2, accuracy=0.719, val_loss=2.68, val_accuracy=0.317, lr=0.116] 10%|█         | 20/200 [07:41<54:43, 18.24s/epoch, loss=1.18, accuracy=0.725, val_loss=2.57, val_accuracy=0.299, lr=0.108] 10%|█         | 21/200 [07:58<53:21, 17.89s/epoch, loss=1.15, accuracy=0.733, val_loss=1.64, val_accuracy=0.566, lr=0.1]   11%|█         | 22/200 [08:15<52:17, 17.62s/epoch, loss=1.13, accuracy=0.738, val_loss=3.45, val_accuracy=0.361, lr=0.0922] 12%|█▏        | 23/200 [08:33<52:08, 17.68s/epoch, loss=1.09, accuracy=0.744, val_loss=2.11, val_accuracy=0.378, lr=0.0844] 12%|█▏        | 24/200 [08:55<55:18, 18.86s/epoch, loss=1.07, accuracy=0.751, val_loss=1.56, val_accuracy=0.602, lr=0.0767] 12%|█▎        | 25/200 [09:14<55:05, 18.89s/epoch, loss=1.04, accuracy=0.757, val_loss=1.8, val_accuracy=0.53, lr=0.0691]   13%|█▎        | 26/200 [09:32<53:55, 18.60s/epoch, loss=1, accuracy=0.768, val_loss=1.48, val_accuracy=0.619, lr=0.0617]  14%|█▎        | 27/200 [09:49<52:41, 18.28s/epoch, loss=0.977, accuracy=0.77, val_loss=1.39, val_accuracy=0.611, lr=0.0546] 14%|█▍        | 28/200 [10:07<51:48, 18.07s/epoch, loss=0.942, accuracy=0.779, val_loss=2.13, val_accuracy=0.417, lr=0.0478] 14%|█▍        | 29/200 [10:24<50:40, 17.78s/epoch, loss=0.899, accuracy=0.793, val_loss=1.28, val_accuracy=0.675, lr=0.0412] 15%|█▌        | 30/200 [10:41<49:47, 17.58s/epoch, loss=0.86, accuracy=0.799, val_loss=1.58, val_accuracy=0.583, lr=0.0351]  16%|█▌        | 31/200 [10:59<49:36, 17.61s/epoch, loss=0.818, accuracy=0.809, val_loss=1.76, val_accuracy=0.517, lr=0.0293] 16%|█▌        | 32/200 [11:16<48:47, 17.43s/epoch, loss=0.781, accuracy=0.817, val_loss=2.27, val_accuracy=0.46, lr=0.024]   16%|█▋        | 33/200 [11:34<48:57, 17.59s/epoch, loss=0.728, accuracy=0.832, val_loss=1.01, val_accuracy=0.741, lr=0.0191] 17%|█▋        | 34/200 [11:51<48:15, 17.44s/epoch, loss=0.683, accuracy=0.841, val_loss=1.88, val_accuracy=0.511, lr=0.0147] 18%|█▊        | 35/200 [12:08<47:45, 17.36s/epoch, loss=0.631, accuracy=0.852, val_loss=1.33, val_accuracy=0.628, lr=0.0109] 18%|█▊        | 36/200 [12:25<47:22, 17.33s/epoch, loss=0.58, accuracy=0.868, val_loss=0.796, val_accuracy=0.793, lr=0.00761] 18%|█▊        | 37/200 [12:42<46:57, 17.28s/epoch, loss=0.527, accuracy=0.881, val_loss=0.696, val_accuracy=0.82, lr=0.00489] 19%|█▉        | 38/200 [12:59<46:34, 17.25s/epoch, loss=0.477, accuracy=0.897, val_loss=0.618, val_accuracy=0.845, lr=0.00276] 20%|█▉        | 39/200 [13:17<46:10, 17.21s/epoch, loss=0.439, accuracy=0.906, val_loss=0.579, val_accuracy=0.858, lr=0.00123] 20%|██        | 40/200 [13:34<45:47, 17.17s/epoch, loss=0.42, accuracy=0.912, val_loss=0.519, val_accuracy=0.876, lr=0.000308] 20%|██        | 41/200 [13:53<46:56, 17.71s/epoch, loss=3.2, accuracy=0.293, val_loss=2.75, val_accuracy=0.106, lr=0.2]        21%|██        | 42/200 [14:10<46:29, 17.66s/epoch, loss=1.63, accuracy=0.507, val_loss=2.97, val_accuracy=0.338, lr=0.2] 22%|██▏       | 43/200 [14:27<45:52, 17.53s/epoch, loss=1.48, accuracy=0.61, val_loss=3.51, val_accuracy=0.268, lr=0.199] 22%|██▏       | 44/200 [14:44<45:13, 17.40s/epoch, loss=1.43, accuracy=0.642, val_loss=2.23, val_accuracy=0.386, lr=0.197] 22%|██▎       | 45/200 [15:02<44:43, 17.31s/epoch, loss=1.41, accuracy=0.654, val_loss=4, val_accuracy=0.25, lr=0.195]     23%|██▎       | 46/200 [15:19<44:14, 17.24s/epoch, loss=1.4, accuracy=0.662, val_loss=5.31, val_accuracy=0.161, lr=0.192] 24%|██▎       | 47/200 [15:37<45:08, 17.70s/epoch, loss=1.39, accuracy=0.665, val_loss=4.04, val_accuracy=0.112, lr=0.189] 24%|██▍       | 48/200 [15:56<45:11, 17.84s/epoch, loss=1.35, accuracy=0.671, val_loss=4.05, val_accuracy=0.281, lr=0.185] 24%|██▍       | 49/200 [16:13<44:21, 17.62s/epoch, loss=1.35, accuracy=0.671, val_loss=2.82, val_accuracy=0.327, lr=0.181] 25%|██▌       | 50/200 [16:30<43:39, 17.46s/epoch, loss=1.33, accuracy=0.677, val_loss=2.89, val_accuracy=0.338, lr=0.176] 26%|██▌       | 51/200 [16:49<44:44, 18.01s/epoch, loss=1.32, accuracy=0.683, val_loss=5.68, val_accuracy=0.214, lr=0.171] 26%|██▌       | 52/200 [17:06<43:47, 17.75s/epoch, loss=1.31, accuracy=0.683, val_loss=3.24, val_accuracy=0.284, lr=0.165] 26%|██▋       | 53/200 [17:23<43:03, 17.57s/epoch, loss=1.3, accuracy=0.687, val_loss=3.13, val_accuracy=0.278, lr=0.159]  27%|██▋       | 54/200 [17:41<42:30, 17.47s/epoch, loss=1.27, accuracy=0.692, val_loss=2.92, val_accuracy=0.369, lr=0.152] 28%|██▊       | 55/200 [17:58<42:05, 17.42s/epoch, loss=1.27, accuracy=0.694, val_loss=4.88, val_accuracy=0.102, lr=0.145] 28%|██▊       | 56/200 [18:24<48:22, 20.16s/epoch, loss=1.24, accuracy=0.703, val_loss=6.26, val_accuracy=0.307, lr=0.138] 28%|██▊       | 57/200 [18:42<45:55, 19.27s/epoch, loss=1.21, accuracy=0.71, val_loss=1.71, val_accuracy=0.53, lr=0.131]   29%|██▉       | 58/200 [18:59<44:10, 18.66s/epoch, loss=1.21, accuracy=0.712, val_loss=2.25, val_accuracy=0.44, lr=0.123] 30%|██▉       | 59/200 [19:16<42:42, 18.17s/epoch, loss=1.18, accuracy=0.719, val_loss=3.93, val_accuracy=0.231, lr=0.116] 30%|███       | 60/200 [19:33<41:56, 17.97s/epoch, loss=1.16, accuracy=0.724, val_loss=3.18, val_accuracy=0.202, lr=0.108] 30%|███       | 61/200 [19:51<41:09, 17.77s/epoch, loss=1.14, accuracy=0.729, val_loss=1.71, val_accuracy=0.519, lr=0.1]   31%|███       | 62/200 [20:08<40:25, 17.58s/epoch, loss=1.12, accuracy=0.734, val_loss=2.5, val_accuracy=0.339, lr=0.0922] 32%|███▏      | 63/200 [20:26<40:46, 17.86s/epoch, loss=1.09, accuracy=0.741, val_loss=2.05, val_accuracy=0.445, lr=0.0844] 32%|███▏      | 64/200 [20:46<41:36, 18.36s/epoch, loss=1.06, accuracy=0.748, val_loss=1.92, val_accuracy=0.521, lr=0.0767] 32%|███▎      | 65/200 [21:04<41:02, 18.24s/epoch, loss=1.03, accuracy=0.754, val_loss=3.99, val_accuracy=0.167, lr=0.0691] 33%|███▎      | 66/200 [21:24<41:55, 18.77s/epoch, loss=0.998, accuracy=0.763, val_loss=1.69, val_accuracy=0.529, lr=0.0617] 34%|███▎      | 67/200 [21:41<40:27, 18.25s/epoch, loss=0.97, accuracy=0.77, val_loss=1.33, val_accuracy=0.647, lr=0.0546]   34%|███▍      | 68/200 [21:58<39:24, 17.91s/epoch, loss=0.934, accuracy=0.776, val_loss=2.4, val_accuracy=0.424, lr=0.0478] 34%|███▍      | 69/200 [22:18<40:13, 18.43s/epoch, loss=0.901, accuracy=0.785, val_loss=1.79, val_accuracy=0.548, lr=0.0412] 35%|███▌      | 70/200 [22:37<40:34, 18.73s/epoch, loss=0.859, accuracy=0.796, val_loss=1.28, val_accuracy=0.642, lr=0.0351] 36%|███▌      | 71/200 [22:58<41:45, 19.43s/epoch, loss=0.825, accuracy=0.802, val_loss=1.39, val_accuracy=0.627, lr=0.0293] 36%|███▌      | 72/200 [23:16<40:32, 19.01s/epoch, loss=0.773, accuracy=0.816, val_loss=1.11, val_accuracy=0.706, lr=0.024]  36%|███▋      | 73/200 [23:33<39:01, 18.44s/epoch, loss=0.733, accuracy=0.825, val_loss=0.897, val_accuracy=0.767, lr=0.0191] 37%|███▋      | 74/200 [23:50<37:52, 18.04s/epoch, loss=0.691, accuracy=0.835, val_loss=1.24, val_accuracy=0.66, lr=0.0147]   38%|███▊      | 75/200 [24:09<38:12, 18.34s/epoch, loss=0.639, accuracy=0.847, val_loss=1.23, val_accuracy=0.657, lr=0.0109] 38%|███▊      | 76/200 [24:27<37:09, 17.98s/epoch, loss=0.58, accuracy=0.864, val_loss=1.3, val_accuracy=0.667, lr=0.00761]  38%|███▊      | 77/200 [24:44<36:15, 17.68s/epoch, loss=0.536, accuracy=0.874, val_loss=0.801, val_accuracy=0.785, lr=0.00489] 39%|███▉      | 78/200 [25:01<35:44, 17.58s/epoch, loss=0.488, accuracy=0.889, val_loss=0.582, val_accuracy=0.858, lr=0.00276] 40%|███▉      | 79/200 [25:18<35:04, 17.39s/epoch, loss=0.452, accuracy=0.898, val_loss=0.562, val_accuracy=0.865, lr=0.00123] 40%|████      | 80/200 [25:37<36:02, 18.02s/epoch, loss=0.429, accuracy=0.906, val_loss=0.527, val_accuracy=0.876, lr=0.000308] 40%|████      | 81/200 [25:55<35:15, 17.78s/epoch, loss=2.83, accuracy=0.335, val_loss=2.93, val_accuracy=0.132, lr=0.2]        41%|████      | 82/200 [26:12<34:29, 17.54s/epoch, loss=1.54, accuracy=0.538, val_loss=2.78, val_accuracy=0.182, lr=0.2] 42%|████▏     | 83/200 [26:29<34:01, 17.45s/epoch, loss=1.44, accuracy=0.604, val_loss=5, val_accuracy=0.154, lr=0.199]  42%|████▏     | 84/200 [26:48<34:55, 18.07s/epoch, loss=1.41, accuracy=0.633, val_loss=2.76, val_accuracy=0.361, lr=0.197] 42%|████▎     | 85/200 [27:05<34:02, 17.76s/epoch, loss=1.38, accuracy=0.65, val_loss=2.68, val_accuracy=0.322, lr=0.195]  43%|████▎     | 86/200 [27:22<33:21, 17.56s/epoch, loss=1.37, accuracy=0.661, val_loss=1.97, val_accuracy=0.478, lr=0.192] 44%|████▎     | 87/200 [27:40<32:48, 17.42s/epoch, loss=1.36, accuracy=0.668, val_loss=2.74, val_accuracy=0.203, lr=0.189] 44%|████▍     | 88/200 [27:57<32:20, 17.33s/epoch, loss=1.35, accuracy=0.673, val_loss=2.85, val_accuracy=0.278, lr=0.185] 44%|████▍     | 89/200 [28:14<31:59, 17.29s/epoch, loss=1.34, accuracy=0.675, val_loss=6.24, val_accuracy=0.196, lr=0.181] 45%|████▌     | 90/200 [28:31<31:37, 17.25s/epoch, loss=1.32, accuracy=0.68, val_loss=3.79, val_accuracy=0.254, lr=0.176]  46%|████▌     | 91/200 [28:49<31:35, 17.39s/epoch, loss=1.31, accuracy=0.684, val_loss=1.97, val_accuracy=0.472, lr=0.171] 46%|████▌     | 92/200 [29:08<32:19, 17.96s/epoch, loss=1.29, accuracy=0.685, val_loss=1.93, val_accuracy=0.466, lr=0.165] 46%|████▋     | 93/200 [29:25<31:35, 17.71s/epoch, loss=1.28, accuracy=0.69, val_loss=5.35, val_accuracy=0.203, lr=0.159]  47%|████▋     | 94/200 [29:42<30:56, 17.52s/epoch, loss=1.27, accuracy=0.695, val_loss=5.27, val_accuracy=0.176, lr=0.152] 48%|████▊     | 95/200 [29:59<30:29, 17.42s/epoch, loss=1.25, accuracy=0.699, val_loss=3.16, val_accuracy=0.358, lr=0.145] 48%|████▊     | 96/200 [30:17<30:02, 17.33s/epoch, loss=1.24, accuracy=0.703, val_loss=3.36, val_accuracy=0.343, lr=0.138] 48%|████▊     | 97/200 [30:36<30:59, 18.05s/epoch, loss=1.22, accuracy=0.71, val_loss=4.06, val_accuracy=0.219, lr=0.131]  49%|████▉     | 98/200 [30:54<30:28, 17.93s/epoch, loss=1.2, accuracy=0.711, val_loss=1.64, val_accuracy=0.551, lr=0.123] 50%|████▉     | 99/200 [31:11<29:42, 17.65s/epoch, loss=1.17, accuracy=0.718, val_loss=2.09, val_accuracy=0.405, lr=0.116] 50%|█████     | 100/200 [31:28<29:09, 17.50s/epoch, loss=1.15, accuracy=0.724, val_loss=2.41, val_accuracy=0.301, lr=0.108] 50%|█████     | 101/200 [31:50<31:12, 18.91s/epoch, loss=1.12, accuracy=0.729, val_loss=1.93, val_accuracy=0.477, lr=0.1]   51%|█████     | 102/200 [32:07<29:55, 18.32s/epoch, loss=1.1, accuracy=0.738, val_loss=2.37, val_accuracy=0.396, lr=0.0922] 52%|█████▏    | 103/200 [32:24<28:57, 17.91s/epoch, loss=1.08, accuracy=0.742, val_loss=4.64, val_accuracy=0.299, lr=0.0844] 52%|█████▏    | 104/200 [32:42<28:25, 17.77s/epoch, loss=1.05, accuracy=0.748, val_loss=2.22, val_accuracy=0.358, lr=0.0767] 52%|█████▎    | 105/200 [32:59<27:58, 17.67s/epoch, loss=1.02, accuracy=0.752, val_loss=2.69, val_accuracy=0.246, lr=0.0691] 53%|█████▎    | 106/200 [33:19<28:37, 18.27s/epoch, loss=0.996, accuracy=0.758, val_loss=1.8, val_accuracy=0.494, lr=0.0617] 54%|█████▎    | 107/200 [33:41<30:09, 19.46s/epoch, loss=0.964, accuracy=0.767, val_loss=3.8, val_accuracy=0.235, lr=0.0546] 54%|█████▍    | 108/200 [34:01<30:12, 19.70s/epoch, loss=0.927, accuracy=0.775, val_loss=1.66, val_accuracy=0.559, lr=0.0478] 55%|█████▍    | 109/200 [34:18<28:40, 18.91s/epoch, loss=0.894, accuracy=0.782, val_loss=1.42, val_accuracy=0.641, lr=0.0412] 55%|█████▌    | 110/200 [34:35<27:30, 18.34s/epoch, loss=0.861, accuracy=0.788, val_loss=1.55, val_accuracy=0.577, lr=0.0351] 56%|█████▌    | 111/200 [34:53<26:42, 18.01s/epoch, loss=0.827, accuracy=0.798, val_loss=1, val_accuracy=0.734, lr=0.0293]    56%|█████▌    | 112/200 [35:10<26:06, 17.80s/epoch, loss=0.782, accuracy=0.808, val_loss=1.14, val_accuracy=0.692, lr=0.024] 56%|█████▋    | 113/200 [35:30<26:39, 18.39s/epoch, loss=0.74, accuracy=0.817, val_loss=1.08, val_accuracy=0.703, lr=0.0191] 57%|█████▋    | 114/200 [35:48<26:11, 18.27s/epoch, loss=0.697, accuracy=0.828, val_loss=1.32, val_accuracy=0.665, lr=0.0147] 57%|█████▊    | 115/200 [36:05<25:40, 18.13s/epoch, loss=0.649, accuracy=0.84, val_loss=0.82, val_accuracy=0.783, lr=0.0109]  58%|█████▊    | 116/200 [36:23<25:02, 17.88s/epoch, loss=0.598, accuracy=0.853, val_loss=0.802, val_accuracy=0.789, lr=0.00761] 58%|█████▊    | 117/200 [36:42<25:28, 18.41s/epoch, loss=0.554, accuracy=0.864, val_loss=0.656, val_accuracy=0.834, lr=0.00489] 59%|█████▉    | 118/200 [37:02<25:50, 18.91s/epoch, loss=0.509, accuracy=0.879, val_loss=0.624, val_accuracy=0.838, lr=0.00276] 60%|█████▉    | 119/200 [37:19<24:44, 18.33s/epoch, loss=0.477, accuracy=0.886, val_loss=0.577, val_accuracy=0.854, lr=0.00123] 60%|██████    | 120/200 [37:40<25:11, 18.90s/epoch, loss=0.452, accuracy=0.896, val_loss=0.544, val_accuracy=0.864, lr=0.000308] 60%|██████    | 121/200 [37:59<25:01, 19.01s/epoch, loss=2.74, accuracy=0.352, val_loss=3.26, val_accuracy=0.137, lr=0.2]        61%|██████    | 122/200 [38:18<24:48, 19.08s/epoch, loss=1.61, accuracy=0.514, val_loss=3.55, val_accuracy=0.257, lr=0.2] 62%|██████▏   | 123/200 [38:35<23:47, 18.54s/epoch, loss=1.45, accuracy=0.606, val_loss=1.99, val_accuracy=0.442, lr=0.199] 62%|██████▏   | 124/200 [38:54<23:33, 18.59s/epoch, loss=1.4, accuracy=0.639, val_loss=2.36, val_accuracy=0.398, lr=0.197]  62%|██████▎   | 125/200 [39:13<23:29, 18.80s/epoch, loss=1.38, accuracy=0.653, val_loss=2.79, val_accuracy=0.282, lr=0.195] 63%|██████▎   | 126/200 [39:32<23:01, 18.67s/epoch, loss=1.36, accuracy=0.662, val_loss=2.72, val_accuracy=0.262, lr=0.192] 64%|██████▎   | 127/200 [39:51<22:54, 18.82s/epoch, loss=1.35, accuracy=0.664, val_loss=2.04, val_accuracy=0.413, lr=0.189] 64%|██████▍   | 128/200 [40:11<23:00, 19.18s/epoch, loss=1.34, accuracy=0.672, val_loss=8.64, val_accuracy=0.178, lr=0.185] 64%|██████▍   | 129/200 [40:30<22:38, 19.13s/epoch, loss=1.32, accuracy=0.673, val_loss=6.61, val_accuracy=0.226, lr=0.181] 65%|██████▌   | 130/200 [40:47<21:38, 18.54s/epoch, loss=1.31, accuracy=0.678, val_loss=3.65, val_accuracy=0.193, lr=0.176] 66%|██████▌   | 131/200 [41:04<20:47, 18.08s/epoch, loss=1.3, accuracy=0.68, val_loss=13, val_accuracy=0.123, lr=0.171]     66%|██████▌   | 132/200 [41:21<20:06, 17.75s/epoch, loss=1.29, accuracy=0.683, val_loss=2.61, val_accuracy=0.331, lr=0.165] 66%|██████▋   | 133/200 [41:39<20:01, 17.94s/epoch, loss=1.28, accuracy=0.685, val_loss=1.97, val_accuracy=0.462, lr=0.159] 67%|██████▋   | 134/200 [41:56<19:24, 17.64s/epoch, loss=1.26, accuracy=0.694, val_loss=3.27, val_accuracy=0.289, lr=0.152] 68%|██████▊   | 135/200 [42:14<19:03, 17.60s/epoch, loss=1.24, accuracy=0.697, val_loss=3.34, val_accuracy=0.215, lr=0.145] 68%|██████▊   | 136/200 [42:32<18:46, 17.61s/epoch, loss=1.22, accuracy=0.705, val_loss=3.61, val_accuracy=0.336, lr=0.138] 68%|██████▊   | 137/200 [42:49<18:19, 17.45s/epoch, loss=1.2, accuracy=0.707, val_loss=3.2, val_accuracy=0.328, lr=0.131]   69%|██████▉   | 138/200 [43:06<17:54, 17.33s/epoch, loss=1.19, accuracy=0.714, val_loss=2.11, val_accuracy=0.48, lr=0.123] 70%|██████▉   | 139/200 [43:23<17:34, 17.29s/epoch, loss=1.16, accuracy=0.718, val_loss=4.07, val_accuracy=0.293, lr=0.116] 70%|███████   | 140/200 [43:44<18:28, 18.47s/epoch, loss=1.15, accuracy=0.718, val_loss=1.97, val_accuracy=0.446, lr=0.108] 70%|███████   | 141/200 [44:02<17:58, 18.29s/epoch, loss=1.12, accuracy=0.726, val_loss=3.23, val_accuracy=0.302, lr=0.1]   71%|███████   | 142/200 [44:19<17:18, 17.91s/epoch, loss=1.11, accuracy=0.733, val_loss=7.59, val_accuracy=0.196, lr=0.0922] 72%|███████▏  | 143/200 [44:36<16:47, 17.68s/epoch, loss=1.08, accuracy=0.736, val_loss=1.89, val_accuracy=0.437, lr=0.0844] 72%|███████▏  | 144/200 [44:54<16:24, 17.58s/epoch, loss=1.04, accuracy=0.747, val_loss=2.67, val_accuracy=0.394, lr=0.0767] 72%|███████▎  | 145/200 [45:14<16:58, 18.52s/epoch, loss=1.02, accuracy=0.75, val_loss=1.64, val_accuracy=0.572, lr=0.0691]  73%|███████▎  | 146/200 [45:31<16:17, 18.10s/epoch, loss=0.991, accuracy=0.757, val_loss=1.73, val_accuracy=0.539, lr=0.0617] 74%|███████▎  | 147/200 [45:52<16:37, 18.83s/epoch, loss=0.956, accuracy=0.767, val_loss=9.67, val_accuracy=0.126, lr=0.0546] 74%|███████▍  | 148/200 [46:09<15:49, 18.27s/epoch, loss=0.927, accuracy=0.773, val_loss=2.3, val_accuracy=0.42, lr=0.0478]   74%|███████▍  | 149/200 [46:27<15:34, 18.33s/epoch, loss=0.894, accuracy=0.779, val_loss=1.75, val_accuracy=0.467, lr=0.0412] 75%|███████▌  | 150/200 [46:44<14:57, 17.95s/epoch, loss=0.853, accuracy=0.79, val_loss=2.21, val_accuracy=0.347, lr=0.0351]  76%|███████▌  | 151/200 [47:01<14:26, 17.67s/epoch, loss=0.826, accuracy=0.795, val_loss=1.78, val_accuracy=0.566, lr=0.0293] 76%|███████▌  | 152/200 [47:20<14:22, 17.97s/epoch, loss=0.781, accuracy=0.804, val_loss=1.07, val_accuracy=0.714, lr=0.024]  76%|███████▋  | 153/200 [47:37<13:52, 17.72s/epoch, loss=0.74, accuracy=0.815, val_loss=1.01, val_accuracy=0.722, lr=0.0191] 77%|███████▋  | 154/200 [47:54<13:24, 17.49s/epoch, loss=0.695, accuracy=0.825, val_loss=1.03, val_accuracy=0.726, lr=0.0147] 78%|███████▊  | 155/200 [48:11<13:00, 17.34s/epoch, loss=0.647, accuracy=0.837, val_loss=1.09, val_accuracy=0.707, lr=0.0109] 78%|███████▊  | 156/200 [48:28<12:39, 17.26s/epoch, loss=0.601, accuracy=0.85, val_loss=0.744, val_accuracy=0.807, lr=0.00761] 78%|███████▊  | 157/200 [48:46<12:32, 17.51s/epoch, loss=0.559, accuracy=0.862, val_loss=0.752, val_accuracy=0.798, lr=0.00489] 79%|███████▉  | 158/200 [49:04<12:12, 17.43s/epoch, loss=0.515, accuracy=0.874, val_loss=0.589, val_accuracy=0.85, lr=0.00276]  80%|███████▉  | 159/200 [49:21<11:49, 17.31s/epoch, loss=0.481, accuracy=0.884, val_loss=0.557, val_accuracy=0.858, lr=0.00123] 80%|████████  | 160/200 [49:41<12:05, 18.14s/epoch, loss=0.462, accuracy=0.89, val_loss=0.538, val_accuracy=0.867, lr=0.000308] 80%|████████  | 161/200 [49:58<11:34, 17.81s/epoch, loss=3.65, accuracy=0.305, val_loss=2.78, val_accuracy=0.16, lr=0.2]        81%|████████  | 162/200 [50:16<11:18, 17.85s/epoch, loss=1.65, accuracy=0.496, val_loss=5.95, val_accuracy=0.21, lr=0.2] 82%|████████▏ | 163/200 [50:34<11:11, 18.15s/epoch, loss=1.48, accuracy=0.592, val_loss=2.99, val_accuracy=0.221, lr=0.199] 82%|████████▏ | 164/200 [50:51<10:39, 17.77s/epoch, loss=1.41, accuracy=0.631, val_loss=3.02, val_accuracy=0.195, lr=0.197] 82%|████████▎ | 165/200 [51:11<10:39, 18.27s/epoch, loss=1.37, accuracy=0.65, val_loss=5.8, val_accuracy=0.163, lr=0.195]   83%|████████▎ | 166/200 [51:28<10:14, 18.06s/epoch, loss=1.35, accuracy=0.66, val_loss=2.11, val_accuracy=0.455, lr=0.192] 84%|████████▎ | 167/200 [51:45<09:46, 17.76s/epoch, loss=1.33, accuracy=0.668, val_loss=3.12, val_accuracy=0.289, lr=0.189] 84%|████████▍ | 168/200 [52:04<09:34, 17.96s/epoch, loss=1.32, accuracy=0.671, val_loss=3.21, val_accuracy=0.237, lr=0.185] 84%|████████▍ | 169/200 [52:21<09:09, 17.71s/epoch, loss=1.31, accuracy=0.675, val_loss=2.16, val_accuracy=0.489, lr=0.181] 85%|████████▌ | 170/200 [52:40<09:06, 18.22s/epoch, loss=1.3, accuracy=0.677, val_loss=2.48, val_accuracy=0.323, lr=0.176]  86%|████████▌ | 171/200 [52:59<08:49, 18.25s/epoch, loss=1.29, accuracy=0.682, val_loss=9.41, val_accuracy=0.151, lr=0.171] 86%|████████▌ | 172/200 [53:16<08:25, 18.05s/epoch, loss=1.27, accuracy=0.687, val_loss=2.27, val_accuracy=0.34, lr=0.165]  86%|████████▋ | 173/200 [53:33<08:00, 17.79s/epoch, loss=1.26, accuracy=0.69, val_loss=2.37, val_accuracy=0.376, lr=0.159] 87%|████████▋ | 174/200 [53:50<07:35, 17.54s/epoch, loss=1.25, accuracy=0.692, val_loss=6.99, val_accuracy=0.19, lr=0.152] 88%|████████▊ | 175/200 [54:07<07:14, 17.36s/epoch, loss=1.23, accuracy=0.697, val_loss=3.38, val_accuracy=0.214, lr=0.145] 88%|████████▊ | 176/200 [54:24<06:53, 17.24s/epoch, loss=1.22, accuracy=0.7, val_loss=2.75, val_accuracy=0.396, lr=0.138]   88%|████████▊ | 177/200 [54:43<06:47, 17.72s/epoch, loss=1.19, accuracy=0.707, val_loss=2.7, val_accuracy=0.405, lr=0.131] 89%|████████▉ | 178/200 [55:02<06:39, 18.14s/epoch, loss=1.18, accuracy=0.712, val_loss=1.55, val_accuracy=0.59, lr=0.123] 90%|████████▉ | 179/200 [55:20<06:15, 17.88s/epoch, loss=1.16, accuracy=0.715, val_loss=2.21, val_accuracy=0.461, lr=0.116] 90%|█████████ | 180/200 [55:37<05:57, 17.86s/epoch, loss=1.14, accuracy=0.718, val_loss=2.56, val_accuracy=0.372, lr=0.108] 90%|█████████ | 181/200 [55:54<05:33, 17.57s/epoch, loss=1.12, accuracy=0.723, val_loss=2.08, val_accuracy=0.419, lr=0.1]   91%|█████████ | 182/200 [56:11<05:13, 17.39s/epoch, loss=1.1, accuracy=0.731, val_loss=2.39, val_accuracy=0.438, lr=0.0922] 92%|█████████▏| 183/200 [56:30<05:03, 17.86s/epoch, loss=1.07, accuracy=0.736, val_loss=1.91, val_accuracy=0.486, lr=0.0844] 92%|█████████▏| 184/200 [56:47<04:42, 17.64s/epoch, loss=1.04, accuracy=0.745, val_loss=2.34, val_accuracy=0.41, lr=0.0767]  92%|█████████▎| 185/200 [57:04<04:21, 17.41s/epoch, loss=1.02, accuracy=0.744, val_loss=3.4, val_accuracy=0.362, lr=0.0691] 93%|█████████▎| 186/200 [57:21<04:03, 17.37s/epoch, loss=0.986, accuracy=0.757, val_loss=1.58, val_accuracy=0.574, lr=0.0617] 94%|█████████▎| 187/200 [57:38<03:44, 17.24s/epoch, loss=0.964, accuracy=0.761, val_loss=1.6, val_accuracy=0.572, lr=0.0546]  94%|█████████▍| 188/200 [57:55<03:26, 17.19s/epoch, loss=0.926, accuracy=0.769, val_loss=1.79, val_accuracy=0.538, lr=0.0478] 94%|█████████▍| 189/200 [58:13<03:08, 17.14s/epoch, loss=0.897, accuracy=0.776, val_loss=1.83, val_accuracy=0.445, lr=0.0412] 95%|█████████▌| 190/200 [58:30<02:51, 17.13s/epoch, loss=0.86, accuracy=0.785, val_loss=1.64, val_accuracy=0.549, lr=0.0351]  96%|█████████▌| 191/200 [58:47<02:34, 17.14s/epoch, loss=0.828, accuracy=0.792, val_loss=1.18, val_accuracy=0.665, lr=0.0293] 96%|█████████▌| 192/200 [59:04<02:17, 17.16s/epoch, loss=0.788, accuracy=0.802, val_loss=1.85, val_accuracy=0.493, lr=0.024]  96%|█████████▋| 193/200 [59:21<01:59, 17.09s/epoch, loss=0.745, accuracy=0.813, val_loss=1.36, val_accuracy=0.627, lr=0.0191] 97%|█████████▋| 194/200 [59:38<01:42, 17.11s/epoch, loss=0.703, accuracy=0.822, val_loss=0.997, val_accuracy=0.73, lr=0.0147] 98%|█████████▊| 195/200 [59:55<01:25, 17.07s/epoch, loss=0.66, accuracy=0.833, val_loss=0.919, val_accuracy=0.742, lr=0.0109] 98%|█████████▊| 196/200 [1:00:12<01:08, 17.05s/epoch, loss=0.617, accuracy=0.844, val_loss=0.754, val_accuracy=0.795, lr=0.00761] 98%|█████████▊| 197/200 [1:00:31<00:52, 17.48s/epoch, loss=0.568, accuracy=0.857, val_loss=0.678, val_accuracy=0.819, lr=0.00489] 99%|█████████▉| 198/200 [1:00:48<00:34, 17.36s/epoch, loss=0.531, accuracy=0.868, val_loss=0.598, val_accuracy=0.844, lr=0.00276]100%|█████████▉| 199/200 [1:01:05<00:17, 17.29s/epoch, loss=0.497, accuracy=0.879, val_loss=0.592, val_accuracy=0.846, lr=0.00123]100%|██████████| 200/200 [1:01:22<00:00, 17.21s/epoch, loss=0.481, accuracy=0.883, val_loss=0.554, val_accuracy=0.859, lr=0.000308]100%|██████████| 200/200 [1:01:22<00:00, 18.41s/epoch, loss=0.481, accuracy=0.883, val_loss=0.554, val_accuracy=0.859, lr=0.000308]
Using real-time data augmentation.
Epoch 0, LR: 0.2
Epoch 1, LR: 0.1996917333733128
Epoch 2, LR: 0.1987688340595138
Epoch 3, LR: 0.19723699203976766
Epoch 4, LR: 0.19510565162951538
Epoch 5, LR: 0.19238795325112867
Epoch 6, LR: 0.18910065241883678
Epoch 7, LR: 0.18526401643540924
Epoch 8, LR: 0.18090169943749476
Epoch 9, LR: 0.17604059656000312
Epoch 10, LR: 0.17071067811865476
Epoch 11, LR: 0.1649448048330184
Epoch 12, LR: 0.15877852522924732
Epoch 13, LR: 0.1522498564715949
Epoch 14, LR: 0.14539904997395467
Epoch 15, LR: 0.138268343236509
Epoch 16, LR: 0.13090169943749475
Epoch 17, LR: 0.12334453638559056
Epoch 18, LR: 0.1156434465040231
Epoch 19, LR: 0.1078459095727845
Epoch 20, LR: 0.1
Epoch 21, LR: 0.09215409042721552
Epoch 22, LR: 0.08435655349597694
Epoch 23, LR: 0.07665546361440947
Epoch 24, LR: 0.06909830056250527
Epoch 25, LR: 0.06173165676349103
Epoch 26, LR: 0.05460095002604533
Epoch 27, LR: 0.04775014352840512
Epoch 28, LR: 0.0412214747707527
Epoch 29, LR: 0.03505519516698165
Epoch 30, LR: 0.029289321881345254
Epoch 31, LR: 0.023959403439996908
Epoch 32, LR: 0.019098300562505267
Epoch 33, LR: 0.014735983564590783
Epoch 34, LR: 0.010899347581163222
Epoch 35, LR: 0.007612046748871327
Epoch 36, LR: 0.004894348370484647
Epoch 37, LR: 0.0027630079602323446
Epoch 38, LR: 0.0012311659404862342
Epoch 39, LR: 0.0003082666266872036
Epoch 40, LR: 0.2
Epoch 41, LR: 0.1996917333733128
Epoch 42, LR: 0.1987688340595138
Epoch 43, LR: 0.19723699203976766
Epoch 44, LR: 0.19510565162951538
Epoch 45, LR: 0.19238795325112867
Epoch 46, LR: 0.18910065241883678
Epoch 47, LR: 0.18526401643540924
Epoch 48, LR: 0.18090169943749476
Epoch 49, LR: 0.17604059656000312
Epoch 50, LR: 0.17071067811865476
Epoch 51, LR: 0.1649448048330184
Epoch 52, LR: 0.15877852522924732
Epoch 53, LR: 0.1522498564715949
Epoch 54, LR: 0.14539904997395467
Epoch 55, LR: 0.138268343236509
Epoch 56, LR: 0.13090169943749475
Epoch 57, LR: 0.12334453638559056
Epoch 58, LR: 0.1156434465040231
Epoch 59, LR: 0.1078459095727845
Epoch 60, LR: 0.1
Epoch 61, LR: 0.09215409042721552
Epoch 62, LR: 0.08435655349597694
Epoch 63, LR: 0.07665546361440947
Epoch 64, LR: 0.06909830056250527
Epoch 65, LR: 0.06173165676349103
Epoch 66, LR: 0.05460095002604533
Epoch 67, LR: 0.04775014352840512
Epoch 68, LR: 0.0412214747707527
Epoch 69, LR: 0.03505519516698165
Epoch 70, LR: 0.029289321881345254
Epoch 71, LR: 0.023959403439996908
Epoch 72, LR: 0.019098300562505267
Epoch 73, LR: 0.014735983564590783
Epoch 74, LR: 0.010899347581163222
Epoch 75, LR: 0.007612046748871327
Epoch 76, LR: 0.004894348370484647
Epoch 77, LR: 0.0027630079602323446
Epoch 78, LR: 0.0012311659404862342
Epoch 79, LR: 0.0003082666266872036
Epoch 80, LR: 0.2
Epoch 81, LR: 0.1996917333733128
Epoch 82, LR: 0.1987688340595138
Epoch 83, LR: 0.19723699203976766
Epoch 84, LR: 0.19510565162951538
Epoch 85, LR: 0.19238795325112867
Epoch 86, LR: 0.18910065241883678
Epoch 87, LR: 0.18526401643540924
Epoch 88, LR: 0.18090169943749476
Epoch 89, LR: 0.17604059656000312
Epoch 90, LR: 0.17071067811865476
Epoch 91, LR: 0.1649448048330184
Epoch 92, LR: 0.15877852522924732
Epoch 93, LR: 0.1522498564715949
Epoch 94, LR: 0.14539904997395467
Epoch 95, LR: 0.138268343236509
Epoch 96, LR: 0.13090169943749475
Epoch 97, LR: 0.12334453638559056
Epoch 98, LR: 0.1156434465040231
Epoch 99, LR: 0.1078459095727845
Epoch 100, LR: 0.1
Epoch 101, LR: 0.09215409042721552
Epoch 102, LR: 0.08435655349597694
Epoch 103, LR: 0.07665546361440947
Epoch 104, LR: 0.06909830056250527
Epoch 105, LR: 0.06173165676349103
Epoch 106, LR: 0.05460095002604533
Epoch 107, LR: 0.04775014352840512
Epoch 108, LR: 0.0412214747707527
Epoch 109, LR: 0.03505519516698165
Epoch 110, LR: 0.029289321881345254
Epoch 111, LR: 0.023959403439996908
Epoch 112, LR: 0.019098300562505267
Epoch 113, LR: 0.014735983564590783
Epoch 114, LR: 0.010899347581163222
Epoch 115, LR: 0.007612046748871327
Epoch 116, LR: 0.004894348370484647
Epoch 117, LR: 0.0027630079602323446
Epoch 118, LR: 0.0012311659404862342
Epoch 119, LR: 0.0003082666266872036
Epoch 120, LR: 0.2
Epoch 121, LR: 0.1996917333733128
Epoch 122, LR: 0.1987688340595138
Epoch 123, LR: 0.19723699203976766
Epoch 124, LR: 0.19510565162951538
Epoch 125, LR: 0.19238795325112867
Epoch 126, LR: 0.18910065241883678
Epoch 127, LR: 0.18526401643540924
Epoch 128, LR: 0.18090169943749476
Epoch 129, LR: 0.17604059656000312
Epoch 130, LR: 0.17071067811865476
Epoch 131, LR: 0.1649448048330184
Epoch 132, LR: 0.15877852522924732
Epoch 133, LR: 0.1522498564715949
Epoch 134, LR: 0.14539904997395467
Epoch 135, LR: 0.138268343236509
Epoch 136, LR: 0.13090169943749475
Epoch 137, LR: 0.12334453638559056
Epoch 138, LR: 0.1156434465040231
Epoch 139, LR: 0.1078459095727845
Epoch 140, LR: 0.1
Epoch 141, LR: 0.09215409042721552
Epoch 142, LR: 0.08435655349597694
Epoch 143, LR: 0.07665546361440947
Epoch 144, LR: 0.06909830056250527
Epoch 145, LR: 0.06173165676349103
Epoch 146, LR: 0.05460095002604533
Epoch 147, LR: 0.04775014352840512
Epoch 148, LR: 0.0412214747707527
Epoch 149, LR: 0.03505519516698165
Epoch 150, LR: 0.029289321881345254
Epoch 151, LR: 0.023959403439996908
Epoch 152, LR: 0.019098300562505267
Epoch 153, LR: 0.014735983564590783
Epoch 154, LR: 0.010899347581163222
Epoch 155, LR: 0.007612046748871327
Epoch 156, LR: 0.004894348370484647
Epoch 157, LR: 0.0027630079602323446
Epoch 158, LR: 0.0012311659404862342
Epoch 159, LR: 0.0003082666266872036
Epoch 160, LR: 0.2
Epoch 161, LR: 0.1996917333733128
Epoch 162, LR: 0.1987688340595138
Epoch 163, LR: 0.19723699203976766
Epoch 164, LR: 0.19510565162951538
Epoch 165, LR: 0.19238795325112867
Epoch 166, LR: 0.18910065241883678
Epoch 167, LR: 0.18526401643540924
Epoch 168, LR: 0.18090169943749476
Epoch 169, LR: 0.17604059656000312
Epoch 170, LR: 0.17071067811865476
Epoch 171, LR: 0.1649448048330184
Epoch 172, LR: 0.15877852522924732
Epoch 173, LR: 0.1522498564715949
Epoch 174, LR: 0.14539904997395467
Epoch 175, LR: 0.138268343236509
Epoch 176, LR: 0.13090169943749475
Epoch 177, LR: 0.12334453638559056
Epoch 178, LR: 0.1156434465040231
Epoch 179, LR: 0.1078459095727845
Epoch 180, LR: 0.1
Epoch 181, LR: 0.09215409042721552
Epoch 182, LR: 0.08435655349597694
Epoch 183, LR: 0.07665546361440947
Epoch 184, LR: 0.06909830056250527
Epoch 185, LR: 0.06173165676349103
Epoch 186, LR: 0.05460095002604533
Epoch 187, LR: 0.04775014352840512
Epoch 188, LR: 0.0412214747707527
Epoch 189, LR: 0.03505519516698165
Epoch 190, LR: 0.029289321881345254
Epoch 191, LR: 0.023959403439996908
Epoch 192, LR: 0.019098300562505267
Epoch 193, LR: 0.014735983564590783
Epoch 194, LR: 0.010899347581163222
Epoch 195, LR: 0.007612046748871327
Epoch 196, LR: 0.004894348370484647
Epoch 197, LR: 0.0027630079602323446
Epoch 198, LR: 0.0012311659404862342
Epoch 199, LR: 0.0003082666266872036

Loading model: 03_cifar10_ResNet20v1_040.h5
Test score: 0.5290533900260925
Test accuracy: 0.8766000270843506
Val score: 0.5192649960517883
Val accuracy: 0.8759999871253967

Loading model: 03_cifar10_ResNet20v1_080.h5
Test score: 0.5411555171012878
Test accuracy: 0.8693000078201294
Val score: 0.5270218849182129
Val accuracy: 0.8762000203132629

Loading model: 03_cifar10_ResNet20v1_120.h5
Test score: 0.5442480444908142
Test accuracy: 0.864300012588501
Val score: 0.5444926619529724
Val accuracy: 0.8636999726295471

Loading model: 03_cifar10_ResNet20v1_160.h5
Test score: 0.5566291809082031
Test accuracy: 0.8605999946594238
Val score: 0.5380690693855286
Val accuracy: 0.8672999739646912

Loading model: 03_cifar10_ResNet20v1_200.h5
Test score: 0.5620105266571045
Test accuracy: 0.859000027179718
Val score: 0.5540986061096191
Val accuracy: 0.8592000007629395
