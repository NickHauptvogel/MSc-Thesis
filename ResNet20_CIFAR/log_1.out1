Mon Mar 18 15:22:42 2024       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 545.23.08              Driver Version: 545.23.08    CUDA Version: 12.3     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA TITAN Xp                Off | 00000000:86:00.0 Off |                  N/A |
| 23%   34C    P8               9W / 250W |      0MiB / 12288MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|  No running processes found                                                           |
+---------------------------------------------------------------------------------------+


* * * Run SGD for ID = 1. * * *


2024-03-18 15:22:50.210306: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-18 15:23:09.988132: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-18 15:23:09.989990: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-18 15:23:10.059153: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:86:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-18 15:23:10.059192: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-18 15:23:10.103826: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-18 15:23:10.103925: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-18 15:23:10.131971: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-18 15:23:10.226283: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-18 15:23:10.304418: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-18 15:23:10.353721: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-18 15:23:10.474327: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-18 15:23:10.475250: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-18 15:23:10.475355: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-18 15:24:18.831210: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-18 15:24:18.832408: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-18 15:24:18.832980: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:86:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-18 15:24:18.833027: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-18 15:24:18.833059: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-18 15:24:18.833071: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-18 15:24:18.833082: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-18 15:24:18.833094: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-18 15:24:18.833106: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-18 15:24:18.833117: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-18 15:24:18.833129: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-18 15:24:18.833654: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-18 15:24:18.833683: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-18 15:24:19.868412: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-18 15:24:19.868462: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-18 15:24:19.868471: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-18 15:24:19.869474: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:86:00.0, compute capability: 6.1)
{'id': '01', 'seed': 1, 'out_folder': 'results/retinopathy/resnet50/10_independent_smalllr_full_val', 'batch_size': 32, 'epochs': 90, 'validation_split': 0.1, 'checkpointing': False, 'checkpoint_every': -1, 'hold_out_validation_split': 0.0, 'model_type': 'ResNet50v1', 'data_augmentation': False, 'augm_shift': 4, 'initial_lr': 0.0023072, 'l2_reg': 0.00010674, 'optimizer': 'sgd', 'momentum': 0.9901533, 'nesterov': True, 'bootstrapping': False, 'use_case': 'retinopathy', 'lr_schedule': 'retinopathy', 'test_time_augmentation': False, 'store_models': False, 'debug': False, 'model': 'ResNet50v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Found 35126 images belonging to 2 classes.
Found 10906 images belonging to 2 classes.
Found 10906 images belonging to 2 classes.
Found 42670 images belonging to 2 classes.
Found 42670 images belonging to 2 classes.
x_train samples: 35126
x_val samples: 10906
x_test samples: 42670
x_train shape: (32, 256, 256, 3)
y_train shape: (32,)
ResNet50v1
0epoch [00:00, ?epoch/s]  0%|          | 0/90 [00:00<?, ?epoch/s]2024-03-18 15:24:20.896771: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-18 15:24:20.909166: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2100000000 Hz
WARNING:tensorflow:AutoGraph could not transform <function weighted_binary_cross_entropy.<locals>.weighted_cross_entropy_fn at 0x7fb640831040> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: module 'gast' has no attribute 'Index'
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
2024-03-18 15:24:25.973364: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-18 15:24:26.390063: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-18 15:24:28.330679: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-18 15:24:28.373743: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1753s vs `on_train_batch_end` time: 0.2816s). Check your callbacks.
  1%|          | 1/90 [13:37<20:13:18, 817.96s/epoch, loss=2.41, accuracy=0.322, auc=0.526, precision=0.203, recall=0.839, val_loss=2.4, val_accuracy=0.32, val_auc=0.528, val_precision=0.197, val_recall=0.851, lr=0]  2%|▏         | 2/90 [24:29<17:36:01, 720.02s/epoch, loss=1.29, accuracy=0.468, auc=0.53, precision=0.209, recall=0.617, val_loss=1.11, val_accuracy=0.6, val_auc=0.567, val_precision=0.225, val_recall=0.458, lr=0.00231]  3%|▎         | 3/90 [35:20<16:38:19, 688.50s/epoch, loss=1.09, accuracy=0.497, auc=0.559, precision=0.22, recall=0.618, val_loss=1.07, val_accuracy=0.268, val_auc=0.572, val_precision=0.197, val_recall=0.939, lr=0.00231]  4%|▍         | 4/90 [46:11<16:05:52, 673.87s/epoch, loss=1.05, accuracy=0.511, auc=0.583, precision=0.229, recall=0.633, val_loss=1.01, val_accuracy=0.457, val_auc=0.622, val_precision=0.228, val_recall=0.79, lr=0.00231]  6%|▌         | 5/90 [57:02<15:42:50, 665.54s/epoch, loss=0.992, accuracy=0.554, auc=0.634, precision=0.255, recall=0.667, val_loss=1, val_accuracy=0.365, val_auc=0.621, val_precision=0.212, val_recall=0.87, lr=0.00231]    7%|▋         | 6/90 [1:08:00<15:28:00, 662.86s/epoch, loss=0.947, accuracy=0.596, auc=0.66, precision=0.275, recall=0.65, val_loss=0.928, val_accuracy=0.661, val_auc=0.653, val_precision=0.285, val_recall=0.528, lr=0.00231]  8%|▊         | 7/90 [1:18:51<15:11:42, 659.07s/epoch, loss=0.9, accuracy=0.645, auc=0.689, precision=0.305, recall=0.638, val_loss=0.935, val_accuracy=0.417, val_auc=0.664, val_precision=0.225, val_recall=0.858, lr=0.00231]  9%|▉         | 8/90 [1:29:45<14:58:20, 657.32s/epoch, loss=0.852, accuracy=0.679, auc=0.721, precision=0.333, recall=0.637, val_loss=0.835, val_accuracy=0.646, val_auc=0.742, val_precision=0.31, val_recall=0.714, lr=0.00231] 10%|█         | 9/90 [1:40:50<14:50:39, 659.75s/epoch, loss=0.782, accuracy=0.742, auc=0.776, precision=0.4, recall=0.646, val_loss=0.754, val_accuracy=0.819, val_auc=0.792, val_precision=0.518, val_recall=0.55, lr=0.00231]   11%|█         | 10/90 [1:51:42<14:36:46, 657.58s/epoch, loss=0.734, accuracy=0.774, auc=0.802, precision=0.447, recall=0.658, val_loss=0.868, val_accuracy=0.825, val_auc=0.707, val_precision=0.582, val_recall=0.253, lr=0.00231] 12%|█▏        | 11/90 [2:02:29<14:21:25, 654.24s/epoch, loss=0.696, accuracy=0.789, auc=0.817, precision=0.472, recall=0.666, val_loss=0.756, val_accuracy=0.765, val_auc=0.752, val_precision=0.41, val_recall=0.565, lr=0.00231]  13%|█▎        | 12/90 [2:13:20<14:09:01, 653.10s/epoch, loss=0.674, accuracy=0.796, auc=0.822, precision=0.485, recall=0.677, val_loss=0.877, val_accuracy=0.825, val_auc=0.691, val_precision=0.732, val_recall=0.112, lr=0.00231] 14%|█▍        | 13/90 [2:24:09<13:56:48, 652.06s/epoch, loss=0.646, accuracy=0.802, auc=0.834, precision=0.496, recall=0.685, val_loss=0.933, val_accuracy=0.816, val_auc=0.665, val_precision=0.788, val_recall=0.0326, lr=0.00231] 16%|█▌        | 14/90 [2:35:02<13:46:15, 652.31s/epoch, loss=0.62, accuracy=0.808, auc=0.843, precision=0.507, recall=0.692, val_loss=0.683, val_accuracy=0.816, val_auc=0.767, val_precision=0.512, val_recall=0.507, lr=0.00231]   17%|█▋        | 15/90 [2:45:50<13:33:32, 650.84s/epoch, loss=0.596, accuracy=0.822, auc=0.853, precision=0.534, recall=0.7, val_loss=1.01, val_accuracy=0.446, val_auc=0.805, val_precision=0.244, val_recall=0.921, lr=0.00231]   18%|█▊        | 16/90 [2:56:38<13:21:37, 649.97s/epoch, loss=0.564, accuracy=0.832, auc=0.868, precision=0.555, recall=0.725, val_loss=0.727, val_accuracy=0.854, val_auc=0.771, val_precision=0.774, val_recall=0.316, lr=0.00231] 19%|█▉        | 17/90 [3:07:27<13:10:28, 649.71s/epoch, loss=0.546, accuracy=0.842, auc=0.875, precision=0.575, recall=0.735, val_loss=0.839, val_accuracy=0.841, val_auc=0.746, val_precision=0.893, val_recall=0.175, lr=0.00231] 20%|██        | 18/90 [3:18:15<12:59:10, 649.31s/epoch, loss=0.527, accuracy=0.844, auc=0.884, precision=0.578, recall=0.745, val_loss=0.683, val_accuracy=0.874, val_auc=0.833, val_precision=0.854, val_recall=0.402, lr=0.00231] 21%|██        | 19/90 [3:29:21<12:54:20, 654.37s/epoch, loss=0.508, accuracy=0.852, auc=0.891, precision=0.595, recall=0.756, val_loss=0.76, val_accuracy=0.862, val_auc=0.789, val_precision=0.794, val_recall=0.361, lr=0.00231]  22%|██▏       | 20/90 [3:40:10<12:41:32, 652.74s/epoch, loss=0.503, accuracy=0.847, auc=0.891, precision=0.584, recall=0.756, val_loss=0.679, val_accuracy=0.879, val_auc=0.841, val_precision=0.835, val_recall=0.444, lr=0.00231] 23%|██▎       | 21/90 [3:50:59<12:29:14, 651.51s/epoch, loss=0.486, accuracy=0.855, auc=0.898, precision=0.601, recall=0.766, val_loss=0.514, val_accuracy=0.839, val_auc=0.874, val_precision=0.556, val_recall=0.735, lr=0.00231] 24%|██▍       | 22/90 [4:01:50<12:18:19, 651.46s/epoch, loss=0.478, accuracy=0.854, auc=0.901, precision=0.599, recall=0.77, val_loss=0.716, val_accuracy=0.718, val_auc=0.656, val_precision=0.317, val_recall=0.429, lr=0.00231]  26%|██▌       | 23/90 [4:12:38<12:06:18, 650.42s/epoch, loss=0.466, accuracy=0.86, auc=0.906, precision=0.612, recall=0.774, val_loss=0.756, val_accuracy=0.772, val_auc=0.645, val_precision=0.37, val_recall=0.301, lr=0.00231]  27%|██▋       | 24/90 [4:23:29<11:55:30, 650.47s/epoch, loss=0.459, accuracy=0.858, auc=0.908, precision=0.607, recall=0.775, val_loss=0.571, val_accuracy=0.818, val_auc=0.827, val_precision=0.514, val_recall=0.669, lr=0.00231] 28%|██▊       | 25/90 [4:34:17<11:44:00, 649.85s/epoch, loss=0.451, accuracy=0.862, auc=0.912, precision=0.615, recall=0.788, val_loss=0.793, val_accuracy=0.856, val_auc=0.777, val_precision=0.838, val_recall=0.291, lr=0.00231] 29%|██▉       | 26/90 [4:45:08<11:33:25, 650.08s/epoch, loss=0.435, accuracy=0.87, auc=0.919, precision=0.632, recall=0.798, val_loss=0.635, val_accuracy=0.729, val_auc=0.807, val_precision=0.384, val_recall=0.719, lr=0.00231]  30%|███       | 27/90 [4:55:57<11:22:17, 649.81s/epoch, loss=0.43, accuracy=0.869, auc=0.921, precision=0.63, recall=0.798, val_loss=0.607, val_accuracy=0.771, val_auc=0.799, val_precision=0.432, val_recall=0.683, lr=0.00231]  31%|███       | 28/90 [5:06:45<11:10:53, 649.25s/epoch, loss=0.431, accuracy=0.867, auc=0.921, precision=0.625, recall=0.797, val_loss=0.647, val_accuracy=0.842, val_auc=0.802, val_precision=0.596, val_recall=0.495, lr=0.00231] 32%|███▏      | 29/90 [5:17:33<10:59:41, 648.88s/epoch, loss=0.417, accuracy=0.873, auc=0.927, precision=0.637, recall=0.809, val_loss=0.518, val_accuracy=0.857, val_auc=0.873, val_precision=0.607, val_recall=0.69, lr=0.00231]  33%|███▎      | 30/90 [5:28:24<10:49:40, 649.67s/epoch, loss=0.415, accuracy=0.87, auc=0.928, precision=0.629, recall=0.814, val_loss=0.634, val_accuracy=0.855, val_auc=0.827, val_precision=0.64, val_recall=0.533, lr=0.00231]  34%|███▍      | 31/90 [5:39:13<10:38:29, 649.32s/epoch, loss=0.362, accuracy=0.899, auc=0.952, precision=0.702, recall=0.845, val_loss=0.567, val_accuracy=0.881, val_auc=0.866, val_precision=0.712, val_recall=0.622, lr=0.000461] 36%|███▌      | 32/90 [5:49:57<10:26:05, 647.67s/epoch, loss=0.316, accuracy=0.912, auc=0.966, precision=0.728, recall=0.878, val_loss=0.523, val_accuracy=0.864, val_auc=0.875, val_precision=0.62, val_recall=0.714, lr=0.000461]  37%|███▋      | 33/90 [6:00:47<10:15:55, 648.34s/epoch, loss=0.299, accuracy=0.915, auc=0.97, precision=0.731, recall=0.893, val_loss=0.522, val_accuracy=0.852, val_auc=0.882, val_precision=0.583, val_recall=0.745, lr=0.000461] 38%|███▊      | 34/90 [6:11:36<10:05:30, 648.77s/epoch, loss=0.273, accuracy=0.925, auc=0.977, precision=0.755, recall=0.914, val_loss=0.59, val_accuracy=0.842, val_auc=0.882, val_precision=0.561, val_recall=0.75, lr=0.000461]  39%|███▉      | 35/90 [6:22:26<9:54:53, 648.98s/epoch, loss=0.256, accuracy=0.929, auc=0.98, precision=0.765, recall=0.922, val_loss=0.624, val_accuracy=0.785, val_auc=0.878, val_precision=0.461, val_recall=0.818, lr=0.000461] 40%|████      | 36/90 [6:33:18<9:44:51, 649.85s/epoch, loss=0.243, accuracy=0.934, auc=0.983, precision=0.779, recall=0.928, val_loss=0.593, val_accuracy=0.847, val_auc=0.882, val_precision=0.571, val_recall=0.755, lr=0.000461] 41%|████      | 37/90 [6:44:06<9:33:41, 649.47s/epoch, loss=0.226, accuracy=0.942, auc=0.986, precision=0.796, recall=0.943, val_loss=0.792, val_accuracy=0.882, val_auc=0.86, val_precision=0.734, val_recall=0.59, lr=0.000461]   42%|████▏     | 38/90 [6:54:57<9:23:17, 649.96s/epoch, loss=0.212, accuracy=0.946, auc=0.988, precision=0.809, recall=0.947, val_loss=0.675, val_accuracy=0.829, val_auc=0.845, val_precision=0.538, val_recall=0.669, lr=0.000461] 43%|████▎     | 39/90 [7:05:49<9:12:46, 650.32s/epoch, loss=0.203, accuracy=0.949, auc=0.99, precision=0.819, recall=0.95, val_loss=0.781, val_accuracy=0.864, val_auc=0.862, val_precision=0.636, val_recall=0.647, lr=0.000461]   44%|████▍     | 40/90 [7:16:37<9:01:32, 649.85s/epoch, loss=0.193, accuracy=0.954, auc=0.991, precision=0.832, recall=0.957, val_loss=0.848, val_accuracy=0.873, val_auc=0.855, val_precision=0.683, val_recall=0.61, lr=0.000461] 46%|████▌     | 41/90 [7:27:28<8:50:49, 649.99s/epoch, loss=0.186, accuracy=0.956, auc=0.992, precision=0.839, recall=0.96, val_loss=0.86, val_accuracy=0.865, val_auc=0.86, val_precision=0.634, val_recall=0.675, lr=0.000461]   47%|████▋     | 42/90 [7:38:18<8:39:59, 650.00s/epoch, loss=0.175, accuracy=0.961, auc=0.994, precision=0.855, recall=0.964, val_loss=0.93, val_accuracy=0.872, val_auc=0.865, val_precision=0.659, val_recall=0.664, lr=0.000461] 48%|████▊     | 43/90 [7:49:09<8:29:28, 650.38s/epoch, loss=0.179, accuracy=0.96, auc=0.993, precision=0.855, recall=0.961, val_loss=0.842, val_accuracy=0.852, val_auc=0.857, val_precision=0.592, val_recall=0.682, lr=0.000461] 49%|████▉     | 44/90 [8:00:00<8:18:53, 650.73s/epoch, loss=0.169, accuracy=0.963, auc=0.994, precision=0.862, recall=0.967, val_loss=0.897, val_accuracy=0.833, val_auc=0.852, val_precision=0.543, val_recall=0.706, lr=0.000461] 50%|█████     | 45/90 [8:10:52<8:08:19, 651.10s/epoch, loss=0.164, accuracy=0.967, auc=0.995, precision=0.875, recall=0.967, val_loss=0.872, val_accuracy=0.803, val_auc=0.845, val_precision=0.485, val_recall=0.732, lr=0.000461] 51%|█████     | 46/90 [8:21:44<7:57:39, 651.35s/epoch, loss=0.158, accuracy=0.968, auc=0.996, precision=0.877, recall=0.974, val_loss=1.33, val_accuracy=0.887, val_auc=0.833, val_precision=0.813, val_recall=0.52, lr=0.000461]   52%|█████▏    | 47/90 [8:32:36<7:46:50, 651.40s/epoch, loss=0.149, accuracy=0.973, auc=0.997, precision=0.894, recall=0.975, val_loss=0.975, val_accuracy=0.859, val_auc=0.847, val_precision=0.621, val_recall=0.642, lr=0.000461] 53%|█████▎    | 48/90 [8:43:28<7:36:08, 651.63s/epoch, loss=0.155, accuracy=0.972, auc=0.996, precision=0.892, recall=0.974, val_loss=1.04, val_accuracy=0.837, val_auc=0.834, val_precision=0.559, val_recall=0.638, lr=0.000461]  54%|█████▍    | 49/90 [8:54:19<7:25:02, 651.28s/epoch, loss=0.151, accuracy=0.973, auc=0.997, precision=0.896, recall=0.973, val_loss=0.949, val_accuracy=0.844, val_auc=0.858, val_precision=0.569, val_recall=0.713, lr=0.000461] 56%|█████▌    | 50/90 [9:05:09<7:14:06, 651.17s/epoch, loss=0.144, accuracy=0.976, auc=0.997, precision=0.905, recall=0.978, val_loss=1.07, val_accuracy=0.861, val_auc=0.843, val_precision=0.632, val_recall=0.625, lr=0.000461]  57%|█████▋    | 51/90 [9:16:02<7:03:36, 651.71s/epoch, loss=0.14, accuracy=0.977, auc=0.998, precision=0.91, recall=0.98, val_loss=1.34, val_accuracy=0.877, val_auc=0.833, val_precision=0.724, val_recall=0.563, lr=0.000461]    58%|█████▊    | 52/90 [9:26:53<6:52:28, 651.29s/epoch, loss=0.15, accuracy=0.974, auc=0.997, precision=0.9, recall=0.975, val_loss=1.32, val_accuracy=0.87, val_auc=0.821, val_precision=0.694, val_recall=0.554, lr=0.000461]  59%|█████▉    | 53/90 [9:37:45<6:41:49, 651.60s/epoch, loss=0.135, accuracy=0.98, auc=0.998, precision=0.92, recall=0.982, val_loss=1.02, val_accuracy=0.809, val_auc=0.867, val_precision=0.495, val_recall=0.792, lr=0.000461] 60%|██████    | 54/90 [9:48:36<6:30:54, 651.53s/epoch, loss=0.138, accuracy=0.98, auc=0.998, precision=0.921, recall=0.982, val_loss=1.44, val_accuracy=0.883, val_auc=0.843, val_precision=0.725, val_recall=0.61, lr=0.000461] 61%|██████    | 55/90 [9:59:29<6:20:14, 651.85s/epoch, loss=0.136, accuracy=0.98, auc=0.998, precision=0.921, recall=0.979, val_loss=1.03, val_accuracy=0.843, val_auc=0.862, val_precision=0.566, val_recall=0.725, lr=0.000461] 62%|██████▏   | 56/90 [10:10:19<6:09:08, 651.42s/epoch, loss=0.132, accuracy=0.981, auc=0.998, precision=0.925, recall=0.982, val_loss=1.19, val_accuracy=0.87, val_auc=0.835, val_precision=0.684, val_recall=0.58, lr=0.000461] 63%|██████▎   | 57/90 [10:21:10<5:58:05, 651.09s/epoch, loss=0.133, accuracy=0.981, auc=0.998, precision=0.925, recall=0.982, val_loss=2.01, val_accuracy=0.88, val_auc=0.796, val_precision=0.854, val_recall=0.435, lr=0.000461] 64%|██████▍   | 58/90 [10:31:59<5:47:01, 650.67s/epoch, loss=0.127, accuracy=0.984, auc=0.999, precision=0.937, recall=0.985, val_loss=1.76, val_accuracy=0.874, val_auc=0.806, val_precision=0.721, val_recall=0.544, lr=0.000461] 66%|██████▌   | 59/90 [10:42:51<5:36:20, 650.98s/epoch, loss=0.134, accuracy=0.982, auc=0.998, precision=0.93, recall=0.982, val_loss=1.04, val_accuracy=0.821, val_auc=0.854, val_precision=0.517, val_recall=0.748, lr=0.000461]  67%|██████▋   | 60/90 [10:53:40<5:25:12, 650.42s/epoch, loss=0.128, accuracy=0.984, auc=0.999, precision=0.936, recall=0.984, val_loss=1.66, val_accuracy=0.881, val_auc=0.824, val_precision=0.78, val_recall=0.517, lr=0.000461] 68%|██████▊   | 61/90 [11:04:31<5:14:22, 650.42s/epoch, loss=0.115, accuracy=0.989, auc=0.999, precision=0.953, recall=0.991, val_loss=1.34, val_accuracy=0.886, val_auc=0.85, val_precision=0.731, val_recall=0.629, lr=9.23e-5]  69%|██████▉   | 62/90 [11:15:23<5:03:46, 650.94s/epoch, loss=0.0906, accuracy=0.999, auc=1, precision=0.996, recall=0.999, val_loss=1.43, val_accuracy=0.889, val_auc=0.851, val_precision=0.739, val_recall=0.635, lr=9.23e-5]   70%|███████   | 63/90 [11:26:12<4:52:41, 650.42s/epoch, loss=0.0878, accuracy=1, auc=1, precision=0.999, recall=1, val_loss=1.39, val_accuracy=0.886, val_auc=0.854, val_precision=0.717, val_recall=0.656, lr=9.23e-5]         71%|███████   | 64/90 [11:37:02<4:41:46, 650.24s/epoch, loss=0.0865, accuracy=1, auc=1, precision=0.999, recall=1, val_loss=1.43, val_accuracy=0.883, val_auc=0.853, val_precision=0.705, val_recall=0.653, lr=9.23e-5] 72%|███████▏  | 65/90 [11:47:51<4:30:49, 649.97s/epoch, loss=0.0854, accuracy=1, auc=1, precision=1, recall=1, val_loss=1.5, val_accuracy=0.888, val_auc=0.853, val_precision=0.728, val_recall=0.649, lr=9.23e-5]      73%|███████▎  | 66/90 [11:58:43<4:20:10, 650.42s/epoch, loss=0.0845, accuracy=1, auc=1, precision=0.999, recall=1, val_loss=1.57, val_accuracy=0.889, val_auc=0.851, val_precision=0.737, val_recall=0.64, lr=9.23e-5] 74%|███████▍  | 67/90 [12:09:33<4:09:18, 650.38s/epoch, loss=0.084, accuracy=1, auc=1, precision=1, recall=1, val_loss=1.59, val_accuracy=0.889, val_auc=0.851, val_precision=0.733, val_recall=0.645, lr=9.23e-5]     76%|███████▌  | 68/90 [12:20:22<3:58:18, 649.91s/epoch, loss=0.0833, accuracy=1, auc=1, precision=1, recall=1, val_loss=1.65, val_accuracy=0.889, val_auc=0.847, val_precision=0.742, val_recall=0.634, lr=9.23e-5] 77%|███████▋  | 69/90 [12:31:11<3:47:25, 649.78s/epoch, loss=0.0827, accuracy=1, auc=1, precision=1, recall=1, val_loss=1.68, val_accuracy=0.89, val_auc=0.847, val_precision=0.744, val_recall=0.633, lr=9.23e-5]  78%|███████▊  | 70/90 [12:42:02<3:36:43, 650.16s/epoch, loss=0.0823, accuracy=1, auc=1, precision=1, recall=1, val_loss=1.68, val_accuracy=0.89, val_auc=0.847, val_precision=0.739, val_recall=0.643, lr=9.23e-5] 79%|███████▉  | 71/90 [12:52:48<3:25:25, 648.74s/epoch, loss=0.0817, accuracy=1, auc=1, precision=1, recall=1, val_loss=1.81, val_accuracy=0.893, val_auc=0.841, val_precision=0.769, val_recall=0.62, lr=9.23e-5] 80%|████████  | 72/90 [13:03:38<3:14:46, 649.24s/epoch, loss=0.0813, accuracy=1, auc=1, precision=1, recall=1, val_loss=1.72, val_accuracy=0.889, val_auc=0.846, val_precision=0.737, val_recall=0.637, lr=9.23e-5] 81%|████████  | 73/90 [13:14:26<3:03:52, 648.95s/epoch, loss=0.0809, accuracy=1, auc=1, precision=1, recall=1, val_loss=1.72, val_accuracy=0.889, val_auc=0.847, val_precision=0.737, val_recall=0.64, lr=9.23e-5]  82%|████████▏ | 74/90 [13:25:16<2:53:07, 649.22s/epoch, loss=0.0805, accuracy=1, auc=1, precision=1, recall=1, val_loss=1.8, val_accuracy=0.891, val_auc=0.843, val_precision=0.753, val_recall=0.629, lr=9.23e-5] 83%|████████▎ | 75/90 [13:36:03<2:42:09, 648.63s/epoch, loss=0.0802, accuracy=1, auc=1, precision=1, recall=1, val_loss=1.8, val_accuracy=0.891, val_auc=0.844, val_precision=0.751, val_recall=0.629, lr=9.23e-5] 84%|████████▍ | 76/90 [13:46:53<2:31:24, 648.88s/epoch, loss=0.0797, accuracy=1, auc=1, precision=1, recall=1, val_loss=1.82, val_accuracy=0.892, val_auc=0.843, val_precision=0.754, val_recall=0.63, lr=9.23e-5] 86%|████████▌ | 77/90 [13:57:43<2:20:39, 649.22s/epoch, loss=0.0793, accuracy=1, auc=1, precision=1, recall=1, val_loss=1.78, val_accuracy=0.889, val_auc=0.845, val_precision=0.737, val_recall=0.64, lr=9.23e-5] 87%|████████▋ | 78/90 [14:08:31<2:09:47, 648.96s/epoch, loss=0.079, accuracy=1, auc=1, precision=1, recall=1, val_loss=1.75, val_accuracy=0.888, val_auc=0.847, val_precision=0.728, val_recall=0.647, lr=9.23e-5] 88%|████████▊ | 79/90 [14:19:31<1:59:34, 652.27s/epoch, loss=0.0785, accuracy=1, auc=1, precision=1, recall=1, val_loss=1.8, val_accuracy=0.889, val_auc=0.845, val_precision=0.735, val_recall=0.641, lr=9.23e-5] 89%|████████▉ | 80/90 [14:30:21<1:48:35, 651.58s/epoch, loss=0.0781, accuracy=1, auc=1, precision=1, recall=1, val_loss=1.88, val_accuracy=0.892, val_auc=0.842, val_precision=0.754, val_recall=0.63, lr=9.23e-5] 90%|█████████ | 81/90 [14:41:12<1:37:43, 651.47s/epoch, loss=0.0777, accuracy=1, auc=1, precision=1, recall=1, val_loss=1.86, val_accuracy=0.889, val_auc=0.844, val_precision=0.739, val_recall=0.634, lr=9.23e-5] 91%|█████████ | 82/90 [14:52:02<1:26:46, 650.80s/epoch, loss=0.0774, accuracy=1, auc=1, precision=1, recall=1, val_loss=1.86, val_accuracy=0.89, val_auc=0.845, val_precision=0.741, val_recall=0.636, lr=9.23e-5]  92%|█████████▏| 83/90 [15:02:52<1:15:55, 650.72s/epoch, loss=0.077, accuracy=1, auc=1, precision=1, recall=1, val_loss=1.85, val_accuracy=0.889, val_auc=0.846, val_precision=0.737, val_recall=0.641, lr=9.23e-5] 93%|█████████▎| 84/90 [15:13:43<1:05:04, 650.72s/epoch, loss=0.0767, accuracy=1, auc=1, precision=1, recall=1, val_loss=1.86, val_accuracy=0.889, val_auc=0.844, val_precision=0.739, val_recall=0.638, lr=9.23e-5] 94%|█████████▍| 85/90 [15:24:32<54:11, 650.26s/epoch, loss=0.0763, accuracy=1, auc=1, precision=1, recall=1, val_loss=1.94, val_accuracy=0.891, val_auc=0.839, val_precision=0.757, val_recall=0.623, lr=9.23e-5]   96%|█████████▌| 86/90 [15:35:24<43:22, 650.75s/epoch, loss=0.0761, accuracy=1, auc=1, precision=1, recall=1, val_loss=2.02, val_accuracy=0.893, val_auc=0.837, val_precision=0.77, val_recall=0.614, lr=9.23e-5]  97%|█████████▋| 87/90 [15:46:15<32:32, 650.85s/epoch, loss=0.0758, accuracy=1, auc=1, precision=1, recall=1, val_loss=1.91, val_accuracy=0.889, val_auc=0.841, val_precision=0.742, val_recall=0.632, lr=9.23e-5] 98%|█████████▊| 88/90 [15:57:06<21:41, 650.74s/epoch, loss=0.0753, accuracy=1, auc=1, precision=1, recall=1, val_loss=1.98, val_accuracy=0.891, val_auc=0.84, val_precision=0.758, val_recall=0.622, lr=9.23e-5]  99%|█████████▉| 89/90 [16:07:56<10:50, 650.54s/epoch, loss=0.075, accuracy=1, auc=1, precision=1, recall=1, val_loss=1.93, val_accuracy=0.89, val_auc=0.841, val_precision=0.746, val_recall=0.634, lr=9.23e-5] 100%|██████████| 90/90 [16:18:43<00:00, 649.61s/epoch, loss=0.0747, accuracy=1, auc=1, precision=1, recall=1, val_loss=1.94, val_accuracy=0.891, val_auc=0.843, val_precision=0.747, val_recall=0.636, lr=9.23e-5]100%|██████████| 90/90 [16:18:43<00:00, 652.48s/epoch, loss=0.0747, accuracy=1, auc=1, precision=1, recall=1, val_loss=1.94, val_accuracy=0.891, val_auc=0.843, val_precision=0.747, val_recall=0.636, lr=9.23e-5]
Traceback (most recent call last):
  File "/home/gkb738/.conda/envs/TF_KERAS_GPU/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/gkb738/.conda/envs/TF_KERAS_GPU/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/gkb738/MSc-Thesis/ResNet20_CIFAR/sgd_baseline.py", line 378, in <module>
    score, acc = model.evaluate(test_loader, verbose=0)
ValueError: too many values to unpack (expected 2)
Only one model saved

Loading model: 01_retinopathy_ResNet50v1.h5
