Tue Mar  5 09:28:41 2024       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 545.23.08              Driver Version: 545.23.08    CUDA Version: 12.3     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA TITAN X (Pascal)        Off | 00000000:02:00.0 Off |                  N/A |
| 49%   73C    P0              58W / 250W |      0MiB / 12288MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|  No running processes found                                                           |
+---------------------------------------------------------------------------------------+


* * * Run SGD for cluster size = 17. * * *


Budget: 88


* * * Run SGD for ID = 17_1. * * *


2024-03-05 09:28:41.899165: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 09:28:46.884676: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 09:28:46.886436: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-05 09:28:46.924698: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-03-05 09:28:46.925022: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 09:28:46.975632: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 09:28:46.975740: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 09:28:46.996208: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 09:28:47.015278: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 09:28:47.101157: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 09:28:47.141748: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 09:28:47.175681: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 09:28:47.176368: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 09:28:47.176461: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 09:28:48.482124: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-05 09:28:48.483164: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 09:28:48.483753: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-03-05 09:28:48.483787: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 09:28:48.483828: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 09:28:48.483846: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 09:28:48.483861: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 09:28:48.483875: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 09:28:48.483890: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 09:28:48.483904: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 09:28:48.483919: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 09:28:48.484362: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 09:28:48.484406: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 09:28:49.316653: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-05 09:28:49.316710: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-05 09:28:49.316718: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-05 09:28:49.317639: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:02:00.0, compute capability: 6.1)
{'id': '17_01', 'seed': 1, 'out_folder': 'results/epoch_budget', 'batch_size': 128, 'epochs': 88, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'bootstrapping': False, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/88 [00:00<?, ?epoch/s]2024-03-05 09:28:50.182030: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-05 09:28:50.194109: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600020000 Hz
2024-03-05 09:28:52.211152: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 09:28:52.465147: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 09:28:53.394239: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-05 09:28:53.460738: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/88 [01:03<1:32:15, 63.63s/epoch, loss=3.16, accuracy=0.3, val_loss=2.55, val_accuracy=0.187, lr=0.1]  2%|▏         | 2/88 [01:24<54:51, 38.27s/epoch, loss=1.62, accuracy=0.503, val_loss=2.27, val_accuracy=0.36, lr=0.1]   3%|▎         | 3/88 [01:44<42:31, 30.02s/epoch, loss=1.38, accuracy=0.619, val_loss=2.31, val_accuracy=0.377, lr=0.1]  5%|▍         | 4/88 [02:04<36:41, 26.21s/epoch, loss=1.27, accuracy=0.674, val_loss=2.33, val_accuracy=0.4, lr=0.1]    6%|▌         | 5/88 [02:24<33:09, 23.97s/epoch, loss=1.25, accuracy=0.696, val_loss=2.32, val_accuracy=0.411, lr=0.1]  7%|▋         | 6/88 [02:44<30:58, 22.66s/epoch, loss=1.22, accuracy=0.709, val_loss=2.08, val_accuracy=0.44, lr=0.1]   8%|▊         | 7/88 [03:04<29:28, 21.83s/epoch, loss=1.22, accuracy=0.716, val_loss=2.15, val_accuracy=0.441, lr=0.1]  9%|▉         | 8/88 [03:25<28:22, 21.28s/epoch, loss=1.21, accuracy=0.721, val_loss=2.42, val_accuracy=0.31, lr=0.1]  10%|█         | 9/88 [03:45<27:31, 20.91s/epoch, loss=1.21, accuracy=0.727, val_loss=2.39, val_accuracy=0.408, lr=0.1] 11%|█▏        | 10/88 [04:05<26:51, 20.66s/epoch, loss=1.2, accuracy=0.73, val_loss=1.66, val_accuracy=0.59, lr=0.1]   12%|█▎        | 11/88 [04:25<26:19, 20.51s/epoch, loss=1.2, accuracy=0.733, val_loss=1.58, val_accuracy=0.583, lr=0.1] 14%|█▎        | 12/88 [04:45<25:48, 20.38s/epoch, loss=1.19, accuracy=0.734, val_loss=1.69, val_accuracy=0.562, lr=0.1] 15%|█▍        | 13/88 [05:05<25:22, 20.30s/epoch, loss=1.19, accuracy=0.736, val_loss=2.02, val_accuracy=0.535, lr=0.1] 16%|█▌        | 14/88 [05:25<24:58, 20.25s/epoch, loss=1.2, accuracy=0.738, val_loss=1.8, val_accuracy=0.549, lr=0.1]   17%|█▋        | 15/88 [05:45<24:36, 20.22s/epoch, loss=1.2, accuracy=0.737, val_loss=1.71, val_accuracy=0.58, lr=0.1] 18%|█▊        | 16/88 [06:06<24:18, 20.26s/epoch, loss=1.19, accuracy=0.741, val_loss=2.15, val_accuracy=0.434, lr=0.0316] 19%|█▉        | 17/88 [06:26<23:54, 20.21s/epoch, loss=1.19, accuracy=0.741, val_loss=3.04, val_accuracy=0.415, lr=0.1]    20%|██        | 18/88 [06:46<23:31, 20.17s/epoch, loss=1.19, accuracy=0.742, val_loss=2.73, val_accuracy=0.309, lr=0.1] 22%|██▏       | 19/88 [07:06<23:12, 20.18s/epoch, loss=1.19, accuracy=0.742, val_loss=2.62, val_accuracy=0.448, lr=0.1] 23%|██▎       | 20/88 [07:26<22:37, 19.97s/epoch, loss=1.18, accuracy=0.745, val_loss=2.86, val_accuracy=0.405, lr=0.1] 24%|██▍       | 21/88 [07:46<22:16, 19.95s/epoch, loss=1.18, accuracy=0.746, val_loss=3.81, val_accuracy=0.196, lr=0.0316] 25%|██▌       | 22/88 [08:06<22:06, 20.10s/epoch, loss=1.18, accuracy=0.745, val_loss=1.52, val_accuracy=0.628, lr=0.1]    26%|██▌       | 23/88 [08:26<21:47, 20.11s/epoch, loss=1.18, accuracy=0.747, val_loss=1.58, val_accuracy=0.614, lr=0.1] 27%|██▋       | 24/88 [08:46<21:30, 20.17s/epoch, loss=1.18, accuracy=0.747, val_loss=1.7, val_accuracy=0.563, lr=0.1]  28%|██▊       | 25/88 [09:06<21:09, 20.14s/epoch, loss=1.18, accuracy=0.749, val_loss=3.31, val_accuracy=0.255, lr=0.1] 30%|██▉       | 26/88 [09:27<20:48, 20.14s/epoch, loss=1.18, accuracy=0.748, val_loss=1.86, val_accuracy=0.502, lr=0.1] 31%|███       | 27/88 [09:47<20:28, 20.14s/epoch, loss=1.17, accuracy=0.748, val_loss=1.98, val_accuracy=0.447, lr=0.0316] 32%|███▏      | 28/88 [10:07<20:06, 20.11s/epoch, loss=1.17, accuracy=0.751, val_loss=2.7, val_accuracy=0.358, lr=0.1]     33%|███▎      | 29/88 [10:27<19:46, 20.10s/epoch, loss=1.16, accuracy=0.749, val_loss=2.02, val_accuracy=0.51, lr=0.1] 34%|███▍      | 30/88 [10:47<19:21, 20.03s/epoch, loss=1.17, accuracy=0.75, val_loss=3.33, val_accuracy=0.37, lr=0.1]  35%|███▌      | 31/88 [11:07<19:02, 20.04s/epoch, loss=1.16, accuracy=0.752, val_loss=1.52, val_accuracy=0.626, lr=0.1] 36%|███▋      | 32/88 [11:27<18:43, 20.06s/epoch, loss=1.16, accuracy=0.751, val_loss=1.74, val_accuracy=0.592, lr=0.0316] 38%|███▊      | 33/88 [11:47<18:24, 20.08s/epoch, loss=1.16, accuracy=0.75, val_loss=2.75, val_accuracy=0.474, lr=0.1]     39%|███▊      | 34/88 [12:07<18:00, 20.02s/epoch, loss=1.16, accuracy=0.75, val_loss=3.34, val_accuracy=0.305, lr=0.1] 40%|███▉      | 35/88 [12:27<17:40, 20.02s/epoch, loss=1.16, accuracy=0.751, val_loss=2.54, val_accuracy=0.47, lr=0.1] 41%|████      | 36/88 [12:47<17:19, 19.99s/epoch, loss=1.16, accuracy=0.751, val_loss=2.15, val_accuracy=0.437, lr=0.1] 42%|████▏     | 37/88 [13:07<16:59, 20.00s/epoch, loss=1.16, accuracy=0.749, val_loss=2.61, val_accuracy=0.411, lr=0.0316] 43%|████▎     | 38/88 [13:27<16:41, 20.03s/epoch, loss=1.16, accuracy=0.752, val_loss=2.4, val_accuracy=0.443, lr=0.1]     44%|████▍     | 39/88 [13:47<16:21, 20.04s/epoch, loss=1.15, accuracy=0.754, val_loss=4.14, val_accuracy=0.275, lr=0.1] 45%|████▌     | 40/88 [14:07<15:59, 19.99s/epoch, loss=1.15, accuracy=0.756, val_loss=2.35, val_accuracy=0.395, lr=0.1] 47%|████▋     | 41/88 [14:27<15:39, 19.98s/epoch, loss=1.15, accuracy=0.754, val_loss=1.7, val_accuracy=0.592, lr=0.1]  48%|████▊     | 42/88 [14:47<15:21, 20.04s/epoch, loss=1.15, accuracy=0.753, val_loss=2.76, val_accuracy=0.409, lr=0.0316] 49%|████▉     | 43/88 [15:07<15:00, 20.01s/epoch, loss=1.15, accuracy=0.754, val_loss=2.09, val_accuracy=0.493, lr=0.1]    50%|█████     | 44/88 [15:27<14:40, 20.01s/epoch, loss=1.15, accuracy=0.752, val_loss=2.62, val_accuracy=0.327, lr=0.1] 51%|█████     | 45/88 [15:47<14:20, 20.00s/epoch, loss=1.14, accuracy=0.756, val_loss=1.69, val_accuracy=0.609, lr=0.1] 52%|█████▏    | 46/88 [16:07<14:01, 20.04s/epoch, loss=1.15, accuracy=0.754, val_loss=2.97, val_accuracy=0.479, lr=0.1] 53%|█████▎    | 47/88 [16:27<13:42, 20.06s/epoch, loss=1.15, accuracy=0.754, val_loss=2.59, val_accuracy=0.434, lr=0.0316] 55%|█████▍    | 48/88 [16:47<13:21, 20.03s/epoch, loss=1.15, accuracy=0.754, val_loss=3.61, val_accuracy=0.266, lr=0.1]    56%|█████▌    | 49/88 [17:07<13:01, 20.05s/epoch, loss=1.14, accuracy=0.755, val_loss=2.51, val_accuracy=0.415, lr=0.1] 57%|█████▋    | 50/88 [17:27<12:42, 20.07s/epoch, loss=1.15, accuracy=0.754, val_loss=4.03, val_accuracy=0.236, lr=0.1] 58%|█████▊    | 51/88 [17:47<12:21, 20.04s/epoch, loss=1.14, accuracy=0.754, val_loss=1.63, val_accuracy=0.633, lr=0.1] 59%|█████▉    | 52/88 [18:08<12:02, 20.08s/epoch, loss=1.14, accuracy=0.755, val_loss=2.15, val_accuracy=0.434, lr=0.0316] 60%|██████    | 53/88 [18:28<11:45, 20.15s/epoch, loss=1.14, accuracy=0.752, val_loss=3.49, val_accuracy=0.343, lr=0.1]    61%|██████▏   | 54/88 [18:48<11:25, 20.17s/epoch, loss=1.14, accuracy=0.756, val_loss=2.3, val_accuracy=0.453, lr=0.1]  62%|██████▎   | 55/88 [19:08<11:06, 20.19s/epoch, loss=1.14, accuracy=0.756, val_loss=1.74, val_accuracy=0.561, lr=0.1] 64%|██████▎   | 56/88 [19:28<10:46, 20.19s/epoch, loss=1.14, accuracy=0.756, val_loss=4.57, val_accuracy=0.24, lr=0.1]  65%|██████▍   | 57/88 [19:49<10:27, 20.24s/epoch, loss=1.14, accuracy=0.754, val_loss=1.83, val_accuracy=0.562, lr=0.0316] 66%|██████▌   | 58/88 [20:09<10:07, 20.23s/epoch, loss=1.14, accuracy=0.756, val_loss=3.1, val_accuracy=0.292, lr=0.1]     67%|██████▋   | 59/88 [20:29<09:47, 20.27s/epoch, loss=1.14, accuracy=0.754, val_loss=2.32, val_accuracy=0.494, lr=0.1] 68%|██████▊   | 60/88 [20:50<09:26, 20.25s/epoch, loss=1.13, accuracy=0.756, val_loss=3.03, val_accuracy=0.41, lr=0.1]  69%|██████▉   | 61/88 [21:10<09:05, 20.22s/epoch, loss=1.14, accuracy=0.756, val_loss=2.49, val_accuracy=0.44, lr=0.1] 70%|███████   | 62/88 [21:30<08:44, 20.17s/epoch, loss=1.13, accuracy=0.758, val_loss=2.2, val_accuracy=0.494, lr=0.0316] 72%|███████▏  | 63/88 [21:50<08:23, 20.14s/epoch, loss=1.13, accuracy=0.757, val_loss=2.18, val_accuracy=0.456, lr=0.1]   73%|███████▎  | 64/88 [22:10<08:01, 20.07s/epoch, loss=1.13, accuracy=0.755, val_loss=5.62, val_accuracy=0.229, lr=0.1] 74%|███████▍  | 65/88 [22:30<07:42, 20.13s/epoch, loss=1.13, accuracy=0.757, val_loss=1.9, val_accuracy=0.534, lr=0.1]  75%|███████▌  | 66/88 [22:50<07:23, 20.14s/epoch, loss=1.13, accuracy=0.757, val_loss=2.14, val_accuracy=0.457, lr=0.1] 76%|███████▌  | 67/88 [23:10<07:02, 20.11s/epoch, loss=1.14, accuracy=0.755, val_loss=2.75, val_accuracy=0.412, lr=0.0316] 77%|███████▋  | 68/88 [23:30<06:41, 20.09s/epoch, loss=1.14, accuracy=0.754, val_loss=2.3, val_accuracy=0.392, lr=0.1]     78%|███████▊  | 69/88 [23:50<06:21, 20.06s/epoch, loss=1.13, accuracy=0.753, val_loss=2.09, val_accuracy=0.517, lr=0.1] 80%|███████▉  | 70/88 [24:10<06:00, 20.05s/epoch, loss=1.13, accuracy=0.758, val_loss=1.95, val_accuracy=0.518, lr=0.1] 81%|████████  | 71/88 [24:30<05:39, 19.98s/epoch, loss=1.13, accuracy=0.754, val_loss=1.57, val_accuracy=0.614, lr=0.1] 82%|████████▏ | 72/88 [24:50<05:17, 19.83s/epoch, loss=1.13, accuracy=0.758, val_loss=1.49, val_accuracy=0.646, lr=0.1] 83%|████████▎ | 73/88 [25:09<04:55, 19.73s/epoch, loss=1.13, accuracy=0.758, val_loss=2.49, val_accuracy=0.439, lr=0.1] 84%|████████▍ | 74/88 [25:29<04:36, 19.72s/epoch, loss=1.13, accuracy=0.757, val_loss=1.35, val_accuracy=0.68, lr=0.1]  85%|████████▌ | 75/88 [25:48<04:16, 19.70s/epoch, loss=1.13, accuracy=0.758, val_loss=1.61, val_accuracy=0.599, lr=0.1] 86%|████████▋ | 76/88 [26:08<03:57, 19.76s/epoch, loss=1.12, accuracy=0.756, val_loss=2.17, val_accuracy=0.376, lr=0.1] 88%|████████▊ | 77/88 [26:29<03:39, 19.91s/epoch, loss=1.13, accuracy=0.755, val_loss=1.99, val_accuracy=0.521, lr=0.1] 89%|████████▊ | 78/88 [26:49<03:19, 19.99s/epoch, loss=1.13, accuracy=0.759, val_loss=1.79, val_accuracy=0.564, lr=0.1] 90%|████████▉ | 79/88 [27:09<03:01, 20.12s/epoch, loss=1.13, accuracy=0.758, val_loss=2.62, val_accuracy=0.522, lr=0.0316] 91%|█████████ | 80/88 [27:29<02:41, 20.13s/epoch, loss=1.13, accuracy=0.757, val_loss=2.62, val_accuracy=0.349, lr=0.1]    92%|█████████▏| 81/88 [27:49<02:20, 20.05s/epoch, loss=1.12, accuracy=0.759, val_loss=2.34, val_accuracy=0.499, lr=0.1] 93%|█████████▎| 82/88 [28:09<02:00, 20.05s/epoch, loss=0.905, accuracy=0.819, val_loss=0.884, val_accuracy=0.811, lr=0.01] 94%|█████████▍| 83/88 [28:29<01:39, 20.00s/epoch, loss=0.731, accuracy=0.85, val_loss=0.831, val_accuracy=0.801, lr=0.01]  95%|█████████▌| 84/88 [28:49<01:20, 20.00s/epoch, loss=0.651, accuracy=0.858, val_loss=0.724, val_accuracy=0.826, lr=0.01] 97%|█████████▋| 85/88 [29:09<01:00, 20.00s/epoch, loss=0.605, accuracy=0.86, val_loss=0.78, val_accuracy=0.799, lr=0.01]   98%|█████████▊| 86/88 [29:29<00:39, 19.98s/epoch, loss=0.584, accuracy=0.863, val_loss=0.727, val_accuracy=0.82, lr=0.01] 99%|█████████▉| 87/88 [29:49<00:19, 19.95s/epoch, loss=0.579, accuracy=0.863, val_loss=0.832, val_accuracy=0.778, lr=0.01]100%|██████████| 88/88 [30:09<00:00, 19.90s/epoch, loss=0.571, accuracy=0.863, val_loss=1.29, val_accuracy=0.659, lr=0.01] 100%|██████████| 88/88 [30:09<00:00, 20.56s/epoch, loss=0.571, accuracy=0.863, val_loss=1.29, val_accuracy=0.659, lr=0.01]
Using real-time data augmentation.
Test score: 1.2906935214996338
Test accuracy: 0.6589000225067139


* * * Run SGD for ID = 17_2. * * *


2024-03-05 09:59:03.460440: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 09:59:06.181269: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 09:59:06.182393: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-05 09:59:06.219157: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-03-05 09:59:06.219202: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 09:59:06.221946: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 09:59:06.221995: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 09:59:06.224080: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 09:59:06.225009: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 09:59:06.227201: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 09:59:06.228531: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 09:59:06.232945: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 09:59:06.233538: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 09:59:06.233635: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 09:59:07.488967: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-05 09:59:07.489921: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 09:59:07.490704: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-03-05 09:59:07.490736: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 09:59:07.490772: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 09:59:07.490789: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 09:59:07.490803: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 09:59:07.490819: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 09:59:07.490833: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 09:59:07.490847: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 09:59:07.490861: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 09:59:07.491323: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 09:59:07.491361: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 09:59:08.141476: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-05 09:59:08.141525: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-05 09:59:08.141534: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-05 09:59:08.142459: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:02:00.0, compute capability: 6.1)
{'id': '17_02', 'seed': 2, 'out_folder': 'results/epoch_budget', 'batch_size': 128, 'epochs': 88, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'bootstrapping': False, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/88 [00:00<?, ?epoch/s]2024-03-05 09:59:09.015366: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-05 09:59:09.015844: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600020000 Hz
2024-03-05 09:59:11.018650: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 09:59:11.235779: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 09:59:11.930749: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-05 09:59:11.998776: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/88 [01:10<1:41:46, 70.19s/epoch, loss=3.02, accuracy=0.356, val_loss=2.44, val_accuracy=0.268, lr=0.1]  2%|▏         | 2/88 [01:31<59:07, 41.24s/epoch, loss=1.52, accuracy=0.56, val_loss=2.68, val_accuracy=0.337, lr=0.1]     3%|▎         | 3/88 [01:51<44:54, 31.70s/epoch, loss=1.31, accuracy=0.653, val_loss=1.9, val_accuracy=0.465, lr=0.1]  5%|▍         | 4/88 [02:11<38:00, 27.15s/epoch, loss=1.26, accuracy=0.688, val_loss=2.19, val_accuracy=0.432, lr=0.1]  6%|▌         | 5/88 [02:31<34:08, 24.68s/epoch, loss=1.24, accuracy=0.705, val_loss=1.79, val_accuracy=0.525, lr=0.1]  7%|▋         | 6/88 [02:52<31:36, 23.13s/epoch, loss=1.22, accuracy=0.713, val_loss=1.66, val_accuracy=0.547, lr=0.1]  8%|▊         | 7/88 [03:12<29:57, 22.19s/epoch, loss=1.21, accuracy=0.721, val_loss=1.66, val_accuracy=0.562, lr=0.1]  9%|▉         | 8/88 [03:32<28:46, 21.58s/epoch, loss=1.2, accuracy=0.727, val_loss=2.13, val_accuracy=0.489, lr=0.1]  10%|█         | 9/88 [03:52<27:53, 21.19s/epoch, loss=1.2, accuracy=0.73, val_loss=1.78, val_accuracy=0.529, lr=0.1]  11%|█▏        | 10/88 [04:13<27:08, 20.88s/epoch, loss=1.2, accuracy=0.733, val_loss=1.62, val_accuracy=0.614, lr=0.1] 12%|█▎        | 11/88 [04:33<26:27, 20.62s/epoch, loss=1.19, accuracy=0.733, val_loss=2.17, val_accuracy=0.496, lr=0.1] 14%|█▎        | 12/88 [04:53<26:01, 20.54s/epoch, loss=1.18, accuracy=0.736, val_loss=2.48, val_accuracy=0.375, lr=0.1] 15%|█▍        | 13/88 [05:13<25:37, 20.51s/epoch, loss=1.17, accuracy=0.739, val_loss=1.78, val_accuracy=0.535, lr=0.1] 16%|█▌        | 14/88 [05:34<25:11, 20.42s/epoch, loss=1.18, accuracy=0.741, val_loss=1.49, val_accuracy=0.622, lr=0.1] 17%|█▋        | 15/88 [05:54<24:48, 20.40s/epoch, loss=1.17, accuracy=0.741, val_loss=1.7, val_accuracy=0.566, lr=0.1]  18%|█▊        | 16/88 [06:15<24:31, 20.43s/epoch, loss=1.16, accuracy=0.744, val_loss=1.75, val_accuracy=0.562, lr=0.1] 19%|█▉        | 17/88 [06:35<24:14, 20.48s/epoch, loss=1.16, accuracy=0.744, val_loss=2.52, val_accuracy=0.397, lr=0.1] 20%|██        | 18/88 [06:56<23:54, 20.49s/epoch, loss=1.16, accuracy=0.747, val_loss=1.61, val_accuracy=0.598, lr=0.1] 22%|██▏       | 19/88 [07:16<23:31, 20.46s/epoch, loss=1.16, accuracy=0.746, val_loss=2.31, val_accuracy=0.484, lr=0.0316] 23%|██▎       | 20/88 [07:36<23:08, 20.41s/epoch, loss=1.15, accuracy=0.746, val_loss=1.68, val_accuracy=0.585, lr=0.1]    24%|██▍       | 21/88 [07:57<22:48, 20.42s/epoch, loss=1.16, accuracy=0.745, val_loss=2.13, val_accuracy=0.441, lr=0.1] 25%|██▌       | 22/88 [08:17<22:27, 20.42s/epoch, loss=1.15, accuracy=0.746, val_loss=1.62, val_accuracy=0.6, lr=0.1]   26%|██▌       | 23/88 [08:38<22:12, 20.51s/epoch, loss=1.15, accuracy=0.75, val_loss=2.23, val_accuracy=0.503, lr=0.1] 27%|██▋       | 24/88 [08:58<21:52, 20.51s/epoch, loss=1.16, accuracy=0.749, val_loss=1.51, val_accuracy=0.624, lr=0.0316] 28%|██▊       | 25/88 [09:19<21:30, 20.49s/epoch, loss=1.14, accuracy=0.752, val_loss=2.05, val_accuracy=0.522, lr=0.1]    30%|██▉       | 26/88 [09:39<21:07, 20.44s/epoch, loss=1.16, accuracy=0.75, val_loss=2.32, val_accuracy=0.391, lr=0.1]  31%|███       | 27/88 [10:00<20:45, 20.42s/epoch, loss=1.16, accuracy=0.748, val_loss=3.63, val_accuracy=0.238, lr=0.1] 32%|███▏      | 28/88 [10:20<20:33, 20.55s/epoch, loss=1.15, accuracy=0.751, val_loss=1.3, val_accuracy=0.698, lr=0.1]  33%|███▎      | 29/88 [10:41<20:16, 20.61s/epoch, loss=1.14, accuracy=0.75, val_loss=3.01, val_accuracy=0.311, lr=0.1] 34%|███▍      | 30/88 [11:02<19:56, 20.62s/epoch, loss=1.14, accuracy=0.753, val_loss=2.65, val_accuracy=0.445, lr=0.1] 35%|███▌      | 31/88 [11:22<19:32, 20.57s/epoch, loss=1.15, accuracy=0.75, val_loss=1.99, val_accuracy=0.492, lr=0.1]  36%|███▋      | 32/88 [11:43<19:14, 20.61s/epoch, loss=1.14, accuracy=0.755, val_loss=2.83, val_accuracy=0.405, lr=0.1] 38%|███▊      | 33/88 [12:04<18:52, 20.60s/epoch, loss=1.14, accuracy=0.752, val_loss=1.55, val_accuracy=0.623, lr=0.0316] 39%|███▊      | 34/88 [12:24<18:34, 20.64s/epoch, loss=1.14, accuracy=0.754, val_loss=2.53, val_accuracy=0.443, lr=0.1]    40%|███▉      | 35/88 [12:45<18:14, 20.64s/epoch, loss=1.14, accuracy=0.752, val_loss=2.34, val_accuracy=0.453, lr=0.1] 41%|████      | 36/88 [13:06<17:52, 20.63s/epoch, loss=1.14, accuracy=0.754, val_loss=1.84, val_accuracy=0.558, lr=0.1] 42%|████▏     | 37/88 [13:26<17:30, 20.59s/epoch, loss=1.14, accuracy=0.755, val_loss=2.18, val_accuracy=0.501, lr=0.1] 43%|████▎     | 38/88 [13:47<17:07, 20.56s/epoch, loss=1.14, accuracy=0.756, val_loss=1.46, val_accuracy=0.632, lr=0.0316] 44%|████▍     | 39/88 [14:07<16:46, 20.54s/epoch, loss=1.14, accuracy=0.755, val_loss=2.38, val_accuracy=0.48, lr=0.1]     45%|████▌     | 40/88 [14:27<16:22, 20.47s/epoch, loss=1.14, accuracy=0.753, val_loss=1.62, val_accuracy=0.593, lr=0.1] 47%|████▋     | 41/88 [14:48<16:02, 20.49s/epoch, loss=1.14, accuracy=0.755, val_loss=2.42, val_accuracy=0.456, lr=0.1] 48%|████▊     | 42/88 [15:08<15:41, 20.47s/epoch, loss=1.14, accuracy=0.757, val_loss=1.6, val_accuracy=0.598, lr=0.1]  49%|████▉     | 43/88 [15:29<15:21, 20.49s/epoch, loss=1.14, accuracy=0.754, val_loss=2.53, val_accuracy=0.351, lr=0.0316] 50%|█████     | 44/88 [15:49<15:00, 20.46s/epoch, loss=1.13, accuracy=0.756, val_loss=2.18, val_accuracy=0.432, lr=0.1]    51%|█████     | 45/88 [16:10<14:40, 20.47s/epoch, loss=1.14, accuracy=0.754, val_loss=3.12, val_accuracy=0.457, lr=0.1] 52%|█████▏    | 46/88 [16:30<14:18, 20.44s/epoch, loss=1.14, accuracy=0.756, val_loss=2.12, val_accuracy=0.523, lr=0.1] 53%|█████▎    | 47/88 [16:51<13:58, 20.46s/epoch, loss=1.13, accuracy=0.755, val_loss=5.76, val_accuracy=0.172, lr=0.1] 55%|█████▍    | 48/88 [17:11<13:38, 20.47s/epoch, loss=1.13, accuracy=0.757, val_loss=2.11, val_accuracy=0.426, lr=0.0316] 56%|█████▌    | 49/88 [17:31<13:17, 20.46s/epoch, loss=1.14, accuracy=0.756, val_loss=2.07, val_accuracy=0.508, lr=0.1]    57%|█████▋    | 50/88 [17:52<12:55, 20.41s/epoch, loss=1.14, accuracy=0.755, val_loss=1.66, val_accuracy=0.591, lr=0.1] 58%|█████▊    | 51/88 [18:12<12:36, 20.44s/epoch, loss=1.13, accuracy=0.758, val_loss=2.01, val_accuracy=0.511, lr=0.1] 59%|█████▉    | 52/88 [18:33<12:14, 20.41s/epoch, loss=1.13, accuracy=0.756, val_loss=2.28, val_accuracy=0.466, lr=0.1] 60%|██████    | 53/88 [18:53<11:56, 20.48s/epoch, loss=1.13, accuracy=0.757, val_loss=1.58, val_accuracy=0.585, lr=0.0316] 61%|██████▏   | 54/88 [19:14<11:36, 20.48s/epoch, loss=1.13, accuracy=0.756, val_loss=2.44, val_accuracy=0.396, lr=0.1]    62%|██████▎   | 55/88 [19:34<11:16, 20.49s/epoch, loss=1.14, accuracy=0.754, val_loss=1.76, val_accuracy=0.576, lr=0.1] 64%|██████▎   | 56/88 [19:55<10:54, 20.47s/epoch, loss=1.12, accuracy=0.759, val_loss=2.27, val_accuracy=0.396, lr=0.1] 65%|██████▍   | 57/88 [20:15<10:33, 20.43s/epoch, loss=1.13, accuracy=0.758, val_loss=2.57, val_accuracy=0.447, lr=0.1] 66%|██████▌   | 58/88 [20:35<10:12, 20.42s/epoch, loss=1.14, accuracy=0.755, val_loss=1.4, val_accuracy=0.66, lr=0.0316] 67%|██████▋   | 59/88 [20:56<09:51, 20.39s/epoch, loss=1.13, accuracy=0.758, val_loss=3.03, val_accuracy=0.303, lr=0.1]  68%|██████▊   | 60/88 [21:16<09:31, 20.40s/epoch, loss=1.13, accuracy=0.756, val_loss=2.3, val_accuracy=0.431, lr=0.1]  69%|██████▉   | 61/88 [21:37<09:11, 20.42s/epoch, loss=1.13, accuracy=0.758, val_loss=1.56, val_accuracy=0.594, lr=0.1] 70%|███████   | 62/88 [21:57<08:50, 20.41s/epoch, loss=1.13, accuracy=0.756, val_loss=2.19, val_accuracy=0.545, lr=0.1] 72%|███████▏  | 63/88 [22:17<08:29, 20.36s/epoch, loss=1.13, accuracy=0.756, val_loss=1.71, val_accuracy=0.577, lr=0.0316] 73%|███████▎  | 64/88 [22:38<08:08, 20.35s/epoch, loss=1.13, accuracy=0.757, val_loss=1.58, val_accuracy=0.622, lr=0.1]    74%|███████▍  | 65/88 [22:58<07:46, 20.27s/epoch, loss=1.12, accuracy=0.759, val_loss=1.93, val_accuracy=0.51, lr=0.1]  75%|███████▌  | 66/88 [23:18<07:24, 20.19s/epoch, loss=1.12, accuracy=0.757, val_loss=5.07, val_accuracy=0.218, lr=0.1] 76%|███████▌  | 67/88 [23:38<07:03, 20.18s/epoch, loss=1.12, accuracy=0.759, val_loss=1.59, val_accuracy=0.603, lr=0.1] 77%|███████▋  | 68/88 [23:58<06:42, 20.12s/epoch, loss=1.13, accuracy=0.756, val_loss=1.79, val_accuracy=0.516, lr=0.0316] 78%|███████▊  | 69/88 [24:18<06:21, 20.07s/epoch, loss=1.12, accuracy=0.758, val_loss=1.87, val_accuracy=0.487, lr=0.1]    80%|███████▉  | 70/88 [24:38<06:01, 20.10s/epoch, loss=1.12, accuracy=0.756, val_loss=2.9, val_accuracy=0.451, lr=0.1]  81%|████████  | 71/88 [24:58<05:40, 20.01s/epoch, loss=1.12, accuracy=0.755, val_loss=2.29, val_accuracy=0.461, lr=0.1] 82%|████████▏ | 72/88 [25:18<05:22, 20.17s/epoch, loss=1.12, accuracy=0.758, val_loss=1.68, val_accuracy=0.577, lr=0.1] 83%|████████▎ | 73/88 [25:38<05:02, 20.18s/epoch, loss=1.12, accuracy=0.757, val_loss=2.8, val_accuracy=0.366, lr=0.0316] 84%|████████▍ | 74/88 [25:59<04:42, 20.17s/epoch, loss=1.12, accuracy=0.755, val_loss=2.08, val_accuracy=0.504, lr=0.1]   85%|████████▌ | 75/88 [26:19<04:22, 20.16s/epoch, loss=1.12, accuracy=0.759, val_loss=1.71, val_accuracy=0.582, lr=0.1] 86%|████████▋ | 76/88 [26:39<04:01, 20.16s/epoch, loss=1.12, accuracy=0.755, val_loss=3.16, val_accuracy=0.321, lr=0.1] 88%|████████▊ | 77/88 [26:59<03:41, 20.17s/epoch, loss=1.12, accuracy=0.757, val_loss=1.59, val_accuracy=0.601, lr=0.1] 89%|████████▊ | 78/88 [27:19<03:22, 20.23s/epoch, loss=1.12, accuracy=0.757, val_loss=2.12, val_accuracy=0.494, lr=0.0316] 90%|████████▉ | 79/88 [27:40<03:02, 20.26s/epoch, loss=1.12, accuracy=0.756, val_loss=2.31, val_accuracy=0.418, lr=0.1]    91%|█████████ | 80/88 [28:00<02:42, 20.28s/epoch, loss=1.12, accuracy=0.759, val_loss=1.79, val_accuracy=0.53, lr=0.1]  92%|█████████▏| 81/88 [28:20<02:21, 20.26s/epoch, loss=1.12, accuracy=0.758, val_loss=1.76, val_accuracy=0.557, lr=0.1] 93%|█████████▎| 82/88 [28:41<02:01, 20.27s/epoch, loss=0.91, accuracy=0.815, val_loss=0.913, val_accuracy=0.8, lr=0.01] 94%|█████████▍| 83/88 [29:01<01:41, 20.27s/epoch, loss=0.731, accuracy=0.846, val_loss=0.758, val_accuracy=0.827, lr=0.01] 95%|█████████▌| 84/88 [29:21<01:20, 20.15s/epoch, loss=0.65, accuracy=0.857, val_loss=0.703, val_accuracy=0.832, lr=0.01]  97%|█████████▋| 85/88 [29:41<01:00, 20.18s/epoch, loss=0.609, accuracy=0.857, val_loss=0.864, val_accuracy=0.765, lr=0.01] 98%|█████████▊| 86/88 [30:01<00:40, 20.20s/epoch, loss=0.586, accuracy=0.86, val_loss=0.69, val_accuracy=0.825, lr=0.01]   99%|█████████▉| 87/88 [30:22<00:20, 20.22s/epoch, loss=0.581, accuracy=0.86, val_loss=0.812, val_accuracy=0.787, lr=0.01]100%|██████████| 88/88 [30:42<00:00, 20.20s/epoch, loss=0.57, accuracy=0.863, val_loss=0.854, val_accuracy=0.773, lr=0.01]100%|██████████| 88/88 [30:42<00:00, 20.93s/epoch, loss=0.57, accuracy=0.863, val_loss=0.854, val_accuracy=0.773, lr=0.01]
Using real-time data augmentation.
Test score: 0.8539943099021912
Test accuracy: 0.7732999920845032


* * * Run SGD for ID = 17_3. * * *


2024-03-05 10:29:54.857075: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 10:29:58.092793: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 10:29:58.093843: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-05 10:29:58.131259: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-03-05 10:29:58.131304: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 10:29:58.135711: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 10:29:58.135753: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 10:29:58.138095: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 10:29:58.138733: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 10:29:58.141238: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 10:29:58.143182: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 10:29:58.148102: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 10:29:58.148715: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 10:29:58.148797: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 10:29:59.390464: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-05 10:29:59.391524: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 10:29:59.392303: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-03-05 10:29:59.392335: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 10:29:59.392374: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 10:29:59.392391: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 10:29:59.392406: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 10:29:59.392421: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 10:29:59.392438: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 10:29:59.392455: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 10:29:59.392472: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 10:29:59.392902: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 10:29:59.392933: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 10:30:00.043620: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-05 10:30:00.043671: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-05 10:30:00.043681: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-05 10:30:00.044612: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:02:00.0, compute capability: 6.1)
{'id': '17_03', 'seed': 3, 'out_folder': 'results/epoch_budget', 'batch_size': 128, 'epochs': 88, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'bootstrapping': False, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/88 [00:00<?, ?epoch/s]2024-03-05 10:30:00.900150: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-05 10:30:00.912154: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600020000 Hz
2024-03-05 10:30:02.843694: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 10:30:03.075177: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 10:30:03.795145: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-05 10:30:03.840892: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/88 [01:02<1:30:03, 62.11s/epoch, loss=2.95, accuracy=0.367, val_loss=2.97, val_accuracy=0.197, lr=0.1]  2%|▏         | 2/88 [01:23<54:20, 37.91s/epoch, loss=1.54, accuracy=0.552, val_loss=1.64, val_accuracy=0.52, lr=0.1]     3%|▎         | 3/88 [01:43<42:25, 29.94s/epoch, loss=1.35, accuracy=0.642, val_loss=2.23, val_accuracy=0.408, lr=0.1]  5%|▍         | 4/88 [02:03<36:38, 26.17s/epoch, loss=1.28, accuracy=0.682, val_loss=1.69, val_accuracy=0.548, lr=0.1]  6%|▌         | 5/88 [02:24<33:17, 24.06s/epoch, loss=1.25, accuracy=0.701, val_loss=2.05, val_accuracy=0.483, lr=0.1]  7%|▋         | 6/88 [02:44<31:11, 22.82s/epoch, loss=1.24, accuracy=0.711, val_loss=1.69, val_accuracy=0.543, lr=0.1]  8%|▊         | 7/88 [03:05<29:43, 22.02s/epoch, loss=1.23, accuracy=0.716, val_loss=1.92, val_accuracy=0.489, lr=0.0316]  9%|▉         | 8/88 [03:25<28:35, 21.44s/epoch, loss=1.21, accuracy=0.725, val_loss=1.85, val_accuracy=0.517, lr=0.1]    10%|█         | 9/88 [03:45<27:44, 21.08s/epoch, loss=1.2, accuracy=0.728, val_loss=1.87, val_accuracy=0.522, lr=0.1]  11%|█▏        | 10/88 [04:05<27:06, 20.85s/epoch, loss=1.2, accuracy=0.73, val_loss=2.37, val_accuracy=0.509, lr=0.1] 12%|█▎        | 11/88 [04:26<26:33, 20.70s/epoch, loss=1.19, accuracy=0.733, val_loss=2.56, val_accuracy=0.449, lr=0.1] 14%|█▎        | 12/88 [04:46<26:04, 20.59s/epoch, loss=1.2, accuracy=0.732, val_loss=1.58, val_accuracy=0.596, lr=0.1]  15%|█▍        | 13/88 [05:07<25:41, 20.55s/epoch, loss=1.19, accuracy=0.738, val_loss=1.7, val_accuracy=0.589, lr=0.1] 16%|█▌        | 14/88 [05:27<25:14, 20.47s/epoch, loss=1.19, accuracy=0.739, val_loss=2.26, val_accuracy=0.513, lr=0.1] 17%|█▋        | 15/88 [05:47<24:46, 20.37s/epoch, loss=1.18, accuracy=0.736, val_loss=1.58, val_accuracy=0.613, lr=0.1] 18%|█▊        | 16/88 [06:07<24:24, 20.34s/epoch, loss=1.18, accuracy=0.741, val_loss=2.22, val_accuracy=0.477, lr=0.1] 19%|█▉        | 17/88 [06:27<24:00, 20.28s/epoch, loss=1.18, accuracy=0.742, val_loss=2.72, val_accuracy=0.383, lr=0.0316] 20%|██        | 18/88 [06:48<23:40, 20.30s/epoch, loss=1.18, accuracy=0.743, val_loss=1.59, val_accuracy=0.592, lr=0.1]    22%|██▏       | 19/88 [07:08<23:19, 20.29s/epoch, loss=1.17, accuracy=0.742, val_loss=2.16, val_accuracy=0.441, lr=0.1] 23%|██▎       | 20/88 [07:28<22:58, 20.27s/epoch, loss=1.17, accuracy=0.744, val_loss=1.9, val_accuracy=0.554, lr=0.1]  24%|██▍       | 21/88 [07:48<22:38, 20.28s/epoch, loss=1.16, accuracy=0.745, val_loss=3.98, val_accuracy=0.291, lr=0.1] 25%|██▌       | 22/88 [08:09<22:18, 20.27s/epoch, loss=1.16, accuracy=0.745, val_loss=3.22, val_accuracy=0.402, lr=0.0316] 26%|██▌       | 23/88 [08:29<21:59, 20.30s/epoch, loss=1.16, accuracy=0.747, val_loss=2.11, val_accuracy=0.51, lr=0.1]     27%|██▋       | 24/88 [08:49<21:36, 20.26s/epoch, loss=1.16, accuracy=0.748, val_loss=2.44, val_accuracy=0.42, lr=0.1] 28%|██▊       | 25/88 [09:10<21:17, 20.28s/epoch, loss=1.16, accuracy=0.747, val_loss=1.75, val_accuracy=0.584, lr=0.1] 30%|██▉       | 26/88 [09:30<20:56, 20.27s/epoch, loss=1.16, accuracy=0.745, val_loss=2.21, val_accuracy=0.505, lr=0.1] 31%|███       | 27/88 [09:50<20:34, 20.24s/epoch, loss=1.15, accuracy=0.747, val_loss=2.01, val_accuracy=0.541, lr=0.0316] 32%|███▏      | 28/88 [10:10<20:16, 20.28s/epoch, loss=1.15, accuracy=0.748, val_loss=2.16, val_accuracy=0.51, lr=0.1]     33%|███▎      | 29/88 [10:31<19:55, 20.27s/epoch, loss=1.15, accuracy=0.749, val_loss=2.08, val_accuracy=0.491, lr=0.1] 34%|███▍      | 30/88 [10:51<19:34, 20.25s/epoch, loss=1.16, accuracy=0.748, val_loss=2.76, val_accuracy=0.498, lr=0.1] 35%|███▌      | 31/88 [11:11<19:15, 20.27s/epoch, loss=1.14, accuracy=0.751, val_loss=1.5, val_accuracy=0.653, lr=0.1]  36%|███▋      | 32/88 [11:31<18:54, 20.26s/epoch, loss=1.14, accuracy=0.751, val_loss=1.6, val_accuracy=0.601, lr=0.1] 38%|███▊      | 33/88 [11:52<18:34, 20.27s/epoch, loss=1.15, accuracy=0.751, val_loss=1.83, val_accuracy=0.529, lr=0.1] 39%|███▊      | 34/88 [12:12<18:13, 20.25s/epoch, loss=1.14, accuracy=0.751, val_loss=1.87, val_accuracy=0.509, lr=0.1] 40%|███▉      | 35/88 [12:32<17:52, 20.24s/epoch, loss=1.15, accuracy=0.748, val_loss=1.88, val_accuracy=0.521, lr=0.1] 41%|████      | 36/88 [12:52<17:30, 20.20s/epoch, loss=1.15, accuracy=0.748, val_loss=2.1, val_accuracy=0.479, lr=0.0316] 42%|████▏     | 37/88 [13:12<17:10, 20.21s/epoch, loss=1.14, accuracy=0.75, val_loss=1.69, val_accuracy=0.6, lr=0.1]      43%|████▎     | 38/88 [13:33<16:50, 20.21s/epoch, loss=1.13, accuracy=0.754, val_loss=2.04, val_accuracy=0.51, lr=0.1] 44%|████▍     | 39/88 [13:53<16:29, 20.19s/epoch, loss=1.14, accuracy=0.753, val_loss=1.69, val_accuracy=0.575, lr=0.1] 45%|████▌     | 40/88 [14:13<16:09, 20.21s/epoch, loss=1.13, accuracy=0.755, val_loss=2.33, val_accuracy=0.358, lr=0.1] 47%|████▋     | 41/88 [14:33<15:49, 20.21s/epoch, loss=1.14, accuracy=0.752, val_loss=1.66, val_accuracy=0.584, lr=0.0316] 48%|████▊     | 42/88 [14:53<15:28, 20.18s/epoch, loss=1.14, accuracy=0.755, val_loss=2.35, val_accuracy=0.481, lr=0.1]    49%|████▉     | 43/88 [15:13<15:06, 20.15s/epoch, loss=1.14, accuracy=0.753, val_loss=1.65, val_accuracy=0.617, lr=0.1] 50%|█████     | 44/88 [15:34<14:46, 20.15s/epoch, loss=1.13, accuracy=0.754, val_loss=3.05, val_accuracy=0.314, lr=0.1] 51%|█████     | 45/88 [15:54<14:27, 20.18s/epoch, loss=1.13, accuracy=0.754, val_loss=2.45, val_accuracy=0.333, lr=0.1] 52%|█████▏    | 46/88 [16:14<14:07, 20.17s/epoch, loss=1.13, accuracy=0.753, val_loss=2.06, val_accuracy=0.489, lr=0.0316] 53%|█████▎    | 47/88 [16:34<13:48, 20.20s/epoch, loss=1.13, accuracy=0.755, val_loss=1.65, val_accuracy=0.612, lr=0.1]    55%|█████▍    | 48/88 [16:55<13:28, 20.22s/epoch, loss=1.13, accuracy=0.756, val_loss=1.79, val_accuracy=0.584, lr=0.1] 56%|█████▌    | 49/88 [17:15<13:10, 20.28s/epoch, loss=1.13, accuracy=0.754, val_loss=2.03, val_accuracy=0.508, lr=0.1] 57%|█████▋    | 50/88 [17:35<12:51, 20.31s/epoch, loss=1.14, accuracy=0.754, val_loss=2.58, val_accuracy=0.409, lr=0.1] 58%|█████▊    | 51/88 [17:56<12:31, 20.30s/epoch, loss=1.13, accuracy=0.755, val_loss=1.91, val_accuracy=0.548, lr=0.0316] 59%|█████▉    | 52/88 [18:16<12:10, 20.29s/epoch, loss=1.13, accuracy=0.755, val_loss=6.1, val_accuracy=0.197, lr=0.1]     60%|██████    | 53/88 [18:36<11:51, 20.32s/epoch, loss=1.13, accuracy=0.755, val_loss=3.18, val_accuracy=0.361, lr=0.1] 61%|██████▏   | 54/88 [18:57<11:32, 20.37s/epoch, loss=1.13, accuracy=0.756, val_loss=1.51, val_accuracy=0.618, lr=0.1] 62%|██████▎   | 55/88 [19:17<11:13, 20.40s/epoch, loss=1.13, accuracy=0.754, val_loss=3.09, val_accuracy=0.376, lr=0.1] 64%|██████▎   | 56/88 [19:37<10:50, 20.31s/epoch, loss=1.12, accuracy=0.756, val_loss=1.82, val_accuracy=0.537, lr=0.0316] 65%|██████▍   | 57/88 [19:58<10:30, 20.34s/epoch, loss=1.13, accuracy=0.754, val_loss=1.57, val_accuracy=0.615, lr=0.1]    66%|██████▌   | 58/88 [20:18<10:07, 20.25s/epoch, loss=1.12, accuracy=0.756, val_loss=1.63, val_accuracy=0.598, lr=0.1] 67%|██████▋   | 59/88 [20:38<09:48, 20.29s/epoch, loss=1.12, accuracy=0.755, val_loss=2.33, val_accuracy=0.474, lr=0.1] 68%|██████▊   | 60/88 [20:58<09:26, 20.22s/epoch, loss=1.12, accuracy=0.757, val_loss=1.48, val_accuracy=0.647, lr=0.1] 69%|██████▉   | 61/88 [21:18<09:04, 20.16s/epoch, loss=1.12, accuracy=0.756, val_loss=2.72, val_accuracy=0.435, lr=0.1] 70%|███████   | 62/88 [21:38<08:44, 20.16s/epoch, loss=1.12, accuracy=0.758, val_loss=1.51, val_accuracy=0.632, lr=0.1] 72%|███████▏  | 63/88 [21:58<08:23, 20.15s/epoch, loss=1.12, accuracy=0.756, val_loss=1.51, val_accuracy=0.607, lr=0.1] 73%|███████▎  | 64/88 [22:19<08:05, 20.21s/epoch, loss=1.12, accuracy=0.756, val_loss=2.33, val_accuracy=0.43, lr=0.1]  74%|███████▍  | 65/88 [22:39<07:44, 20.21s/epoch, loss=1.11, accuracy=0.759, val_loss=1.7, val_accuracy=0.524, lr=0.0316] 75%|███████▌  | 66/88 [22:59<07:25, 20.23s/epoch, loss=1.11, accuracy=0.759, val_loss=1.91, val_accuracy=0.559, lr=0.1]   76%|███████▌  | 67/88 [23:20<07:04, 20.23s/epoch, loss=1.12, accuracy=0.756, val_loss=2.69, val_accuracy=0.278, lr=0.1] 77%|███████▋  | 68/88 [23:40<06:44, 20.21s/epoch, loss=1.12, accuracy=0.756, val_loss=3.3, val_accuracy=0.268, lr=0.1]  78%|███████▊  | 69/88 [24:00<06:24, 20.24s/epoch, loss=1.11, accuracy=0.762, val_loss=2.28, val_accuracy=0.377, lr=0.1] 80%|███████▉  | 70/88 [24:20<06:04, 20.24s/epoch, loss=1.11, accuracy=0.76, val_loss=1.87, val_accuracy=0.513, lr=0.0316] 81%|████████  | 71/88 [24:41<05:44, 20.26s/epoch, loss=1.11, accuracy=0.758, val_loss=3, val_accuracy=0.452, lr=0.1]      82%|████████▏ | 72/88 [25:01<05:23, 20.21s/epoch, loss=1.11, accuracy=0.76, val_loss=2.08, val_accuracy=0.455, lr=0.1] 83%|████████▎ | 73/88 [25:21<05:02, 20.20s/epoch, loss=1.12, accuracy=0.758, val_loss=2.14, val_accuracy=0.539, lr=0.1] 84%|████████▍ | 74/88 [25:41<04:42, 20.15s/epoch, loss=1.12, accuracy=0.754, val_loss=1.84, val_accuracy=0.536, lr=0.1] 85%|████████▌ | 75/88 [26:01<04:21, 20.14s/epoch, loss=1.12, accuracy=0.755, val_loss=2.63, val_accuracy=0.381, lr=0.0316] 86%|████████▋ | 76/88 [26:21<04:02, 20.20s/epoch, loss=1.1, accuracy=0.759, val_loss=1.51, val_accuracy=0.62, lr=0.1]      88%|████████▊ | 77/88 [26:41<03:41, 20.16s/epoch, loss=1.12, accuracy=0.758, val_loss=3.18, val_accuracy=0.386, lr=0.1] 89%|████████▊ | 78/88 [27:02<03:21, 20.19s/epoch, loss=1.11, accuracy=0.757, val_loss=1.55, val_accuracy=0.605, lr=0.1] 90%|████████▉ | 79/88 [27:22<03:01, 20.20s/epoch, loss=1.11, accuracy=0.757, val_loss=1.98, val_accuracy=0.535, lr=0.1] 91%|█████████ | 80/88 [27:42<02:41, 20.13s/epoch, loss=1.11, accuracy=0.759, val_loss=1.84, val_accuracy=0.526, lr=0.0316] 92%|█████████▏| 81/88 [28:02<02:21, 20.21s/epoch, loss=1.11, accuracy=0.756, val_loss=2.15, val_accuracy=0.429, lr=0.1]    93%|█████████▎| 82/88 [28:22<02:01, 20.21s/epoch, loss=0.895, accuracy=0.817, val_loss=0.929, val_accuracy=0.793, lr=0.01] 94%|█████████▍| 83/88 [28:43<01:40, 20.17s/epoch, loss=0.718, accuracy=0.851, val_loss=0.828, val_accuracy=0.801, lr=0.01] 95%|█████████▌| 84/88 [29:02<01:20, 20.11s/epoch, loss=0.639, accuracy=0.858, val_loss=0.754, val_accuracy=0.805, lr=0.01] 97%|█████████▋| 85/88 [29:23<01:00, 20.12s/epoch, loss=0.601, accuracy=0.861, val_loss=0.759, val_accuracy=0.8, lr=0.01]   98%|█████████▊| 86/88 [29:43<00:40, 20.11s/epoch, loss=0.586, accuracy=0.86, val_loss=0.734, val_accuracy=0.808, lr=0.01] 99%|█████████▉| 87/88 [30:03<00:20, 20.13s/epoch, loss=0.57, accuracy=0.862, val_loss=0.9, val_accuracy=0.764, lr=0.01]  100%|██████████| 88/88 [30:23<00:00, 20.17s/epoch, loss=0.563, accuracy=0.865, val_loss=0.746, val_accuracy=0.807, lr=0.01]100%|██████████| 88/88 [30:23<00:00, 20.72s/epoch, loss=0.563, accuracy=0.865, val_loss=0.746, val_accuracy=0.807, lr=0.01]
Using real-time data augmentation.
Test score: 0.7455705404281616
Test accuracy: 0.8072999715805054


* * * Run SGD for ID = 17_4. * * *


2024-03-05 11:00:28.391680: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 11:00:33.341901: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 11:00:33.342943: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-05 11:00:33.382058: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-03-05 11:00:33.382103: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 11:00:33.386942: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 11:00:33.387011: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 11:00:33.390751: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 11:00:33.393000: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 11:00:33.396625: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 11:00:33.399166: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 11:00:33.404988: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 11:00:33.405626: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 11:00:33.405728: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 11:00:34.665702: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-05 11:00:34.666287: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 11:00:34.667314: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-03-05 11:00:34.667346: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 11:00:34.667385: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 11:00:34.667404: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 11:00:34.667420: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 11:00:34.667437: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 11:00:34.667453: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 11:00:34.667468: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 11:00:34.667484: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 11:00:34.667915: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 11:00:34.667980: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 11:00:35.325216: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-05 11:00:35.325267: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-05 11:00:35.325276: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-05 11:00:35.326242: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:02:00.0, compute capability: 6.1)
{'id': '17_04', 'seed': 4, 'out_folder': 'results/epoch_budget', 'batch_size': 128, 'epochs': 88, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'bootstrapping': False, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/88 [00:00<?, ?epoch/s]2024-03-05 11:00:36.192628: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-05 11:00:36.205137: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600020000 Hz
2024-03-05 11:00:38.193823: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 11:00:38.422592: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 11:00:39.099517: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-05 11:00:39.164271: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/88 [01:10<1:41:39, 70.11s/epoch, loss=2.81, accuracy=0.411, val_loss=3.05, val_accuracy=0.233, lr=0.1]  2%|▏         | 2/88 [01:30<58:37, 40.91s/epoch, loss=1.43, accuracy=0.613, val_loss=2.4, val_accuracy=0.402, lr=0.1]     3%|▎         | 3/88 [01:50<44:37, 31.50s/epoch, loss=1.29, accuracy=0.674, val_loss=1.76, val_accuracy=0.507, lr=0.1]  5%|▍         | 4/88 [02:11<37:55, 27.08s/epoch, loss=1.24, accuracy=0.697, val_loss=1.84, val_accuracy=0.513, lr=0.1]  6%|▌         | 5/88 [02:31<33:59, 24.57s/epoch, loss=1.23, accuracy=0.711, val_loss=1.79, val_accuracy=0.514, lr=0.1]  7%|▋         | 6/88 [02:51<31:30, 23.05s/epoch, loss=1.22, accuracy=0.718, val_loss=1.89, val_accuracy=0.484, lr=0.1]  8%|▊         | 7/88 [03:11<29:51, 22.11s/epoch, loss=1.21, accuracy=0.725, val_loss=1.44, val_accuracy=0.641, lr=0.1]  9%|▉         | 8/88 [03:31<28:40, 21.51s/epoch, loss=1.21, accuracy=0.727, val_loss=1.52, val_accuracy=0.626, lr=0.1] 10%|█         | 9/88 [03:51<27:46, 21.10s/epoch, loss=1.21, accuracy=0.727, val_loss=1.53, val_accuracy=0.629, lr=0.1] 11%|█▏        | 10/88 [04:12<27:08, 20.88s/epoch, loss=1.2, accuracy=0.734, val_loss=2.62, val_accuracy=0.354, lr=0.1] 12%|█▎        | 11/88 [04:32<26:34, 20.71s/epoch, loss=1.18, accuracy=0.738, val_loss=1.95, val_accuracy=0.53, lr=0.1] 14%|█▎        | 12/88 [04:52<26:03, 20.58s/epoch, loss=1.18, accuracy=0.737, val_loss=1.76, val_accuracy=0.572, lr=0.0316] 15%|█▍        | 13/88 [05:13<25:35, 20.48s/epoch, loss=1.18, accuracy=0.738, val_loss=2.07, val_accuracy=0.506, lr=0.1]    16%|█▌        | 14/88 [05:33<25:11, 20.42s/epoch, loss=1.18, accuracy=0.738, val_loss=1.53, val_accuracy=0.62, lr=0.1]  17%|█▋        | 15/88 [05:53<24:47, 20.38s/epoch, loss=1.17, accuracy=0.742, val_loss=1.73, val_accuracy=0.557, lr=0.1] 18%|█▊        | 16/88 [06:14<24:24, 20.34s/epoch, loss=1.18, accuracy=0.744, val_loss=1.86, val_accuracy=0.524, lr=0.1] 19%|█▉        | 17/88 [06:34<24:01, 20.30s/epoch, loss=1.17, accuracy=0.744, val_loss=1.66, val_accuracy=0.584, lr=0.0316] 20%|██        | 18/88 [06:54<23:45, 20.37s/epoch, loss=1.16, accuracy=0.746, val_loss=1.68, val_accuracy=0.592, lr=0.1]    22%|██▏       | 19/88 [07:15<23:27, 20.39s/epoch, loss=1.16, accuracy=0.747, val_loss=3.13, val_accuracy=0.365, lr=0.1] 23%|██▎       | 20/88 [07:35<23:05, 20.38s/epoch, loss=1.16, accuracy=0.749, val_loss=2.14, val_accuracy=0.518, lr=0.1] 24%|██▍       | 21/88 [07:55<22:45, 20.39s/epoch, loss=1.16, accuracy=0.748, val_loss=2.18, val_accuracy=0.517, lr=0.1] 25%|██▌       | 22/88 [08:16<22:27, 20.42s/epoch, loss=1.15, accuracy=0.75, val_loss=1.75, val_accuracy=0.576, lr=0.0316] 26%|██▌       | 23/88 [08:36<22:06, 20.40s/epoch, loss=1.15, accuracy=0.751, val_loss=2.08, val_accuracy=0.526, lr=0.1]   27%|██▋       | 24/88 [08:57<21:42, 20.35s/epoch, loss=1.15, accuracy=0.752, val_loss=1.71, val_accuracy=0.606, lr=0.1] 28%|██▊       | 25/88 [09:17<21:21, 20.35s/epoch, loss=1.15, accuracy=0.75, val_loss=1.8, val_accuracy=0.559, lr=0.1]   30%|██▉       | 26/88 [09:37<21:00, 20.33s/epoch, loss=1.15, accuracy=0.753, val_loss=1.4, val_accuracy=0.654, lr=0.1] 31%|███       | 27/88 [09:58<20:41, 20.35s/epoch, loss=1.15, accuracy=0.749, val_loss=2.43, val_accuracy=0.474, lr=0.1] 32%|███▏      | 28/88 [10:18<20:20, 20.34s/epoch, loss=1.15, accuracy=0.751, val_loss=2.42, val_accuracy=0.503, lr=0.1] 33%|███▎      | 29/88 [10:39<20:06, 20.44s/epoch, loss=1.15, accuracy=0.751, val_loss=1.55, val_accuracy=0.622, lr=0.1] 34%|███▍      | 30/88 [10:59<19:48, 20.50s/epoch, loss=1.14, accuracy=0.753, val_loss=3.19, val_accuracy=0.38, lr=0.1]  35%|███▌      | 31/88 [11:20<19:25, 20.45s/epoch, loss=1.14, accuracy=0.756, val_loss=1.77, val_accuracy=0.597, lr=0.0316] 36%|███▋      | 32/88 [11:40<19:02, 20.40s/epoch, loss=1.13, accuracy=0.756, val_loss=2.62, val_accuracy=0.466, lr=0.1]    38%|███▊      | 33/88 [12:00<18:41, 20.39s/epoch, loss=1.14, accuracy=0.754, val_loss=3.5, val_accuracy=0.404, lr=0.1]  39%|███▊      | 34/88 [12:21<18:20, 20.38s/epoch, loss=1.14, accuracy=0.756, val_loss=1.59, val_accuracy=0.65, lr=0.1] 40%|███▉      | 35/88 [12:41<17:59, 20.37s/epoch, loss=1.13, accuracy=0.756, val_loss=1.65, val_accuracy=0.574, lr=0.1] 41%|████      | 36/88 [13:01<17:39, 20.38s/epoch, loss=1.13, accuracy=0.755, val_loss=2.68, val_accuracy=0.419, lr=0.0316] 42%|████▏     | 37/88 [13:22<17:18, 20.37s/epoch, loss=1.13, accuracy=0.755, val_loss=2.25, val_accuracy=0.353, lr=0.1]    43%|████▎     | 38/88 [13:42<16:56, 20.34s/epoch, loss=1.13, accuracy=0.755, val_loss=1.58, val_accuracy=0.62, lr=0.1]  44%|████▍     | 39/88 [14:02<16:36, 20.34s/epoch, loss=1.13, accuracy=0.758, val_loss=2.02, val_accuracy=0.437, lr=0.1] 45%|████▌     | 40/88 [14:23<16:15, 20.32s/epoch, loss=1.12, accuracy=0.759, val_loss=3.8, val_accuracy=0.327, lr=0.1]  47%|████▋     | 41/88 [14:43<15:52, 20.28s/epoch, loss=1.13, accuracy=0.756, val_loss=1.9, val_accuracy=0.503, lr=0.0316] 48%|████▊     | 42/88 [15:03<15:32, 20.27s/epoch, loss=1.14, accuracy=0.756, val_loss=3.06, val_accuracy=0.374, lr=0.1]   49%|████▉     | 43/88 [15:23<15:10, 20.24s/epoch, loss=1.13, accuracy=0.758, val_loss=2.4, val_accuracy=0.486, lr=0.1]  50%|█████     | 44/88 [15:43<14:49, 20.23s/epoch, loss=1.13, accuracy=0.754, val_loss=1.57, val_accuracy=0.617, lr=0.1] 51%|█████     | 45/88 [16:04<14:30, 20.25s/epoch, loss=1.12, accuracy=0.758, val_loss=1.37, val_accuracy=0.674, lr=0.1] 52%|█████▏    | 46/88 [16:24<14:10, 20.24s/epoch, loss=1.12, accuracy=0.757, val_loss=2.65, val_accuracy=0.474, lr=0.1] 53%|█████▎    | 47/88 [16:44<13:48, 20.21s/epoch, loss=1.12, accuracy=0.758, val_loss=1.73, val_accuracy=0.557, lr=0.1] 55%|█████▍    | 48/88 [17:04<13:29, 20.24s/epoch, loss=1.12, accuracy=0.759, val_loss=2.36, val_accuracy=0.432, lr=0.1] 56%|█████▌    | 49/88 [17:25<13:10, 20.26s/epoch, loss=1.12, accuracy=0.759, val_loss=2.32, val_accuracy=0.473, lr=0.1] 57%|█████▋    | 50/88 [17:45<12:52, 20.32s/epoch, loss=1.12, accuracy=0.759, val_loss=1.82, val_accuracy=0.523, lr=0.0316] 58%|█████▊    | 51/88 [18:05<12:28, 20.22s/epoch, loss=1.13, accuracy=0.76, val_loss=2.31, val_accuracy=0.496, lr=0.1]     59%|█████▉    | 52/88 [18:25<12:07, 20.20s/epoch, loss=1.11, accuracy=0.761, val_loss=1.54, val_accuracy=0.617, lr=0.1] 60%|██████    | 53/88 [18:45<11:44, 20.12s/epoch, loss=1.12, accuracy=0.759, val_loss=2.16, val_accuracy=0.439, lr=0.1] 61%|██████▏   | 54/88 [19:05<11:25, 20.16s/epoch, loss=1.12, accuracy=0.759, val_loss=2.32, val_accuracy=0.536, lr=0.1] 62%|██████▎   | 55/88 [19:26<11:05, 20.16s/epoch, loss=1.11, accuracy=0.762, val_loss=1.77, val_accuracy=0.573, lr=0.0316] 64%|██████▎   | 56/88 [19:46<10:43, 20.10s/epoch, loss=1.11, accuracy=0.76, val_loss=2.14, val_accuracy=0.463, lr=0.1]     65%|██████▍   | 57/88 [20:06<10:23, 20.12s/epoch, loss=1.12, accuracy=0.759, val_loss=1.57, val_accuracy=0.625, lr=0.1] 66%|██████▌   | 58/88 [20:26<10:04, 20.16s/epoch, loss=1.12, accuracy=0.758, val_loss=2.29, val_accuracy=0.476, lr=0.1] 67%|██████▋   | 59/88 [20:46<09:44, 20.16s/epoch, loss=1.12, accuracy=0.76, val_loss=1.88, val_accuracy=0.551, lr=0.1]  68%|██████▊   | 60/88 [21:06<09:24, 20.16s/epoch, loss=1.11, accuracy=0.76, val_loss=3.44, val_accuracy=0.349, lr=0.0316] 69%|██████▉   | 61/88 [21:26<09:03, 20.12s/epoch, loss=1.11, accuracy=0.76, val_loss=3.01, val_accuracy=0.423, lr=0.1]    70%|███████   | 62/88 [21:46<08:42, 20.10s/epoch, loss=1.12, accuracy=0.76, val_loss=2.16, val_accuracy=0.469, lr=0.1] 72%|███████▏  | 63/88 [22:06<08:21, 20.07s/epoch, loss=1.12, accuracy=0.759, val_loss=2.15, val_accuracy=0.531, lr=0.1] 73%|███████▎  | 64/88 [22:26<08:01, 20.07s/epoch, loss=1.12, accuracy=0.759, val_loss=1.56, val_accuracy=0.633, lr=0.1] 74%|███████▍  | 65/88 [22:47<07:41, 20.07s/epoch, loss=1.11, accuracy=0.761, val_loss=1.74, val_accuracy=0.595, lr=0.0316] 75%|███████▌  | 66/88 [23:07<07:21, 20.06s/epoch, loss=1.11, accuracy=0.761, val_loss=2.05, val_accuracy=0.491, lr=0.1]    76%|███████▌  | 67/88 [23:27<07:01, 20.09s/epoch, loss=1.11, accuracy=0.759, val_loss=2.12, val_accuracy=0.475, lr=0.1] 77%|███████▋  | 68/88 [23:47<06:41, 20.05s/epoch, loss=1.12, accuracy=0.759, val_loss=1.94, val_accuracy=0.522, lr=0.1] 78%|███████▊  | 69/88 [24:07<06:21, 20.06s/epoch, loss=1.11, accuracy=0.76, val_loss=2.47, val_accuracy=0.41, lr=0.1]   80%|███████▉  | 70/88 [24:27<05:59, 19.99s/epoch, loss=1.11, accuracy=0.759, val_loss=2.41, val_accuracy=0.36, lr=0.0316] 81%|████████  | 71/88 [24:47<05:39, 19.98s/epoch, loss=1.12, accuracy=0.757, val_loss=6.6, val_accuracy=0.235, lr=0.1]    82%|████████▏ | 72/88 [25:07<05:20, 20.05s/epoch, loss=1.11, accuracy=0.76, val_loss=2.1, val_accuracy=0.505, lr=0.1]  83%|████████▎ | 73/88 [25:27<05:01, 20.10s/epoch, loss=1.11, accuracy=0.759, val_loss=2.96, val_accuracy=0.395, lr=0.1] 84%|████████▍ | 74/88 [25:47<04:41, 20.12s/epoch, loss=1.11, accuracy=0.758, val_loss=1.7, val_accuracy=0.546, lr=0.1]  85%|████████▌ | 75/88 [26:07<04:22, 20.18s/epoch, loss=1.11, accuracy=0.761, val_loss=1.63, val_accuracy=0.564, lr=0.0316] 86%|████████▋ | 76/88 [26:28<04:02, 20.20s/epoch, loss=1.11, accuracy=0.761, val_loss=1.58, val_accuracy=0.599, lr=0.1]    88%|████████▊ | 77/88 [26:48<03:42, 20.21s/epoch, loss=1.11, accuracy=0.761, val_loss=2.2, val_accuracy=0.449, lr=0.1]  89%|████████▊ | 78/88 [27:08<03:22, 20.21s/epoch, loss=1.11, accuracy=0.761, val_loss=1.63, val_accuracy=0.577, lr=0.1] 90%|████████▉ | 79/88 [27:28<03:01, 20.20s/epoch, loss=1.11, accuracy=0.76, val_loss=1.68, val_accuracy=0.54, lr=0.1]   91%|█████████ | 80/88 [27:48<02:41, 20.18s/epoch, loss=1.11, accuracy=0.758, val_loss=2.08, val_accuracy=0.481, lr=0.0316] 92%|█████████▏| 81/88 [28:09<02:21, 20.22s/epoch, loss=1.1, accuracy=0.764, val_loss=2, val_accuracy=0.513, lr=0.1]        93%|█████████▎| 82/88 [28:29<02:01, 20.21s/epoch, loss=0.897, accuracy=0.821, val_loss=0.893, val_accuracy=0.801, lr=0.01] 94%|█████████▍| 83/88 [28:49<01:41, 20.20s/epoch, loss=0.722, accuracy=0.851, val_loss=0.784, val_accuracy=0.817, lr=0.01] 95%|█████████▌| 84/88 [29:10<01:21, 20.26s/epoch, loss=0.642, accuracy=0.858, val_loss=0.735, val_accuracy=0.82, lr=0.01]  97%|█████████▋| 85/88 [29:30<01:00, 20.21s/epoch, loss=0.597, accuracy=0.863, val_loss=0.692, val_accuracy=0.829, lr=0.01] 98%|█████████▊| 86/88 [29:50<00:40, 20.24s/epoch, loss=0.582, accuracy=0.862, val_loss=0.721, val_accuracy=0.816, lr=0.01] 99%|█████████▉| 87/88 [30:10<00:20, 20.27s/epoch, loss=0.565, accuracy=0.865, val_loss=0.768, val_accuracy=0.799, lr=0.01]100%|██████████| 88/88 [30:31<00:00, 20.26s/epoch, loss=0.56, accuracy=0.866, val_loss=0.858, val_accuracy=0.781, lr=0.01] 100%|██████████| 88/88 [30:31<00:00, 20.81s/epoch, loss=0.56, accuracy=0.866, val_loss=0.858, val_accuracy=0.781, lr=0.01]
Using real-time data augmentation.
Test score: 0.8578373193740845
Test accuracy: 0.7811999917030334


* * * Run SGD for ID = 17_5. * * *


2024-03-05 11:31:10.970028: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 11:31:15.279031: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 11:31:15.280254: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-05 11:31:15.318543: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-03-05 11:31:15.318590: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 11:31:15.323325: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 11:31:15.323385: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 11:31:15.325911: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 11:31:15.326853: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 11:31:15.329695: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 11:31:15.331710: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 11:31:15.336640: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 11:31:15.337339: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 11:31:15.337459: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 11:31:16.631693: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-05 11:31:16.632364: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 11:31:16.633583: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-03-05 11:31:16.633616: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 11:31:16.633664: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 11:31:16.633682: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 11:31:16.633698: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 11:31:16.633715: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 11:31:16.633734: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 11:31:16.633748: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 11:31:16.633764: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 11:31:16.635487: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 11:31:16.635525: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 11:31:17.323303: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-05 11:31:17.323355: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-05 11:31:17.323372: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-05 11:31:17.324315: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:02:00.0, compute capability: 6.1)
{'id': '17_05', 'seed': 5, 'out_folder': 'results/epoch_budget', 'batch_size': 128, 'epochs': 88, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'bootstrapping': False, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/88 [00:00<?, ?epoch/s]2024-03-05 11:31:18.207211: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-05 11:31:18.219121: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600020000 Hz
2024-03-05 11:31:20.298074: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 11:31:20.547699: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 11:31:21.317508: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-05 11:31:21.371253: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/88 [01:00<1:27:21, 60.24s/epoch, loss=2.99, accuracy=0.311, val_loss=2.26, val_accuracy=0.297, lr=0.1]  2%|▏         | 2/88 [01:21<53:12, 37.12s/epoch, loss=1.52, accuracy=0.555, val_loss=1.88, val_accuracy=0.436, lr=0.1]    3%|▎         | 3/88 [01:41<41:40, 29.41s/epoch, loss=1.32, accuracy=0.648, val_loss=2.78, val_accuracy=0.409, lr=0.1]  5%|▍         | 4/88 [02:02<36:18, 25.93s/epoch, loss=1.26, accuracy=0.685, val_loss=1.53, val_accuracy=0.582, lr=0.1]  6%|▌         | 5/88 [02:22<33:01, 23.87s/epoch, loss=1.24, accuracy=0.703, val_loss=2, val_accuracy=0.479, lr=0.1]     7%|▋         | 6/88 [02:42<31:03, 22.72s/epoch, loss=1.22, accuracy=0.712, val_loss=2.35, val_accuracy=0.468, lr=0.1]  8%|▊         | 7/88 [03:03<29:37, 21.95s/epoch, loss=1.2, accuracy=0.721, val_loss=1.6, val_accuracy=0.571, lr=0.1]    9%|▉         | 8/88 [03:23<28:31, 21.39s/epoch, loss=1.2, accuracy=0.725, val_loss=1.58, val_accuracy=0.573, lr=0.1] 10%|█         | 9/88 [03:43<27:41, 21.04s/epoch, loss=1.19, accuracy=0.729, val_loss=1.55, val_accuracy=0.595, lr=0.0316] 11%|█▏        | 10/88 [04:04<27:07, 20.86s/epoch, loss=1.18, accuracy=0.733, val_loss=1.77, val_accuracy=0.545, lr=0.1]   12%|█▎        | 11/88 [04:24<26:32, 20.68s/epoch, loss=1.18, accuracy=0.734, val_loss=2.14, val_accuracy=0.464, lr=0.1] 14%|█▎        | 12/88 [04:44<25:59, 20.52s/epoch, loss=1.18, accuracy=0.735, val_loss=1.75, val_accuracy=0.527, lr=0.1] 15%|█▍        | 13/88 [05:04<25:31, 20.42s/epoch, loss=1.17, accuracy=0.737, val_loss=1.94, val_accuracy=0.427, lr=0.1] 16%|█▌        | 14/88 [05:24<25:06, 20.36s/epoch, loss=1.17, accuracy=0.739, val_loss=2.01, val_accuracy=0.5, lr=0.0316] 17%|█▋        | 15/88 [05:45<24:44, 20.33s/epoch, loss=1.16, accuracy=0.739, val_loss=1.65, val_accuracy=0.592, lr=0.1]  18%|█▊        | 16/88 [06:05<24:23, 20.32s/epoch, loss=1.16, accuracy=0.743, val_loss=1.64, val_accuracy=0.557, lr=0.1] 19%|█▉        | 17/88 [06:25<24:00, 20.28s/epoch, loss=1.15, accuracy=0.745, val_loss=2.19, val_accuracy=0.435, lr=0.1] 20%|██        | 18/88 [06:45<23:36, 20.23s/epoch, loss=1.15, accuracy=0.746, val_loss=1.83, val_accuracy=0.513, lr=0.1] 22%|██▏       | 19/88 [07:05<23:13, 20.20s/epoch, loss=1.15, accuracy=0.745, val_loss=2.37, val_accuracy=0.394, lr=0.0316] 23%|██▎       | 20/88 [07:25<22:50, 20.16s/epoch, loss=1.15, accuracy=0.748, val_loss=1.97, val_accuracy=0.517, lr=0.1]    24%|██▍       | 21/88 [07:46<22:32, 20.19s/epoch, loss=1.14, accuracy=0.749, val_loss=3.2, val_accuracy=0.345, lr=0.1]  25%|██▌       | 22/88 [08:06<22:14, 20.22s/epoch, loss=1.14, accuracy=0.747, val_loss=2.6, val_accuracy=0.457, lr=0.1] 26%|██▌       | 23/88 [08:26<21:57, 20.26s/epoch, loss=1.15, accuracy=0.748, val_loss=1.88, val_accuracy=0.516, lr=0.1] 27%|██▋       | 24/88 [08:46<21:35, 20.24s/epoch, loss=1.14, accuracy=0.749, val_loss=1.38, val_accuracy=0.666, lr=0.1] 28%|██▊       | 25/88 [09:07<21:15, 20.25s/epoch, loss=1.14, accuracy=0.749, val_loss=1.39, val_accuracy=0.658, lr=0.1] 30%|██▉       | 26/88 [09:27<20:55, 20.25s/epoch, loss=1.14, accuracy=0.75, val_loss=1.35, val_accuracy=0.674, lr=0.1]  31%|███       | 27/88 [09:47<20:35, 20.26s/epoch, loss=1.14, accuracy=0.751, val_loss=1.6, val_accuracy=0.632, lr=0.1] 32%|███▏      | 28/88 [10:08<20:15, 20.26s/epoch, loss=1.14, accuracy=0.751, val_loss=1.66, val_accuracy=0.545, lr=0.1] 33%|███▎      | 29/88 [10:28<19:55, 20.27s/epoch, loss=1.13, accuracy=0.754, val_loss=2.07, val_accuracy=0.511, lr=0.1] 34%|███▍      | 30/88 [10:48<19:34, 20.25s/epoch, loss=1.14, accuracy=0.753, val_loss=3.14, val_accuracy=0.254, lr=0.1] 35%|███▌      | 31/88 [11:08<19:13, 20.23s/epoch, loss=1.13, accuracy=0.756, val_loss=2.95, val_accuracy=0.386, lr=0.0316] 36%|███▋      | 32/88 [11:28<18:52, 20.23s/epoch, loss=1.12, accuracy=0.756, val_loss=1.84, val_accuracy=0.522, lr=0.1]    38%|███▊      | 33/88 [11:49<18:34, 20.26s/epoch, loss=1.13, accuracy=0.752, val_loss=1.51, val_accuracy=0.609, lr=0.1] 39%|███▊      | 34/88 [12:09<18:14, 20.27s/epoch, loss=1.12, accuracy=0.754, val_loss=1.87, val_accuracy=0.499, lr=0.1] 40%|███▉      | 35/88 [12:29<17:54, 20.26s/epoch, loss=1.12, accuracy=0.752, val_loss=1.79, val_accuracy=0.564, lr=0.1] 41%|████      | 36/88 [12:50<17:34, 20.29s/epoch, loss=1.13, accuracy=0.752, val_loss=2.37, val_accuracy=0.415, lr=0.0316] 42%|████▏     | 37/88 [13:10<17:14, 20.28s/epoch, loss=1.12, accuracy=0.754, val_loss=2.87, val_accuracy=0.354, lr=0.1]    43%|████▎     | 38/88 [13:30<16:51, 20.24s/epoch, loss=1.12, accuracy=0.753, val_loss=2.43, val_accuracy=0.51, lr=0.1]  44%|████▍     | 39/88 [13:50<16:31, 20.24s/epoch, loss=1.12, accuracy=0.756, val_loss=3.16, val_accuracy=0.338, lr=0.1] 45%|████▌     | 40/88 [14:11<16:14, 20.29s/epoch, loss=1.12, accuracy=0.757, val_loss=2.7, val_accuracy=0.426, lr=0.1]  47%|████▋     | 41/88 [14:31<15:52, 20.27s/epoch, loss=1.12, accuracy=0.753, val_loss=1.42, val_accuracy=0.653, lr=0.0316] 48%|████▊     | 42/88 [14:51<15:32, 20.28s/epoch, loss=1.12, accuracy=0.753, val_loss=1.97, val_accuracy=0.51, lr=0.1]     49%|████▉     | 43/88 [15:12<15:12, 20.27s/epoch, loss=1.12, accuracy=0.753, val_loss=2.26, val_accuracy=0.479, lr=0.1] 50%|█████     | 44/88 [15:32<14:52, 20.29s/epoch, loss=1.12, accuracy=0.754, val_loss=1.63, val_accuracy=0.605, lr=0.1] 51%|█████     | 45/88 [15:52<14:33, 20.32s/epoch, loss=1.11, accuracy=0.758, val_loss=2.05, val_accuracy=0.499, lr=0.1] 52%|█████▏    | 46/88 [16:13<14:14, 20.34s/epoch, loss=1.11, accuracy=0.754, val_loss=1.99, val_accuracy=0.533, lr=0.0316] 53%|█████▎    | 47/88 [16:33<13:54, 20.36s/epoch, loss=1.12, accuracy=0.755, val_loss=1.9, val_accuracy=0.503, lr=0.1]     55%|█████▍    | 48/88 [16:53<13:34, 20.35s/epoch, loss=1.12, accuracy=0.757, val_loss=1.84, val_accuracy=0.561, lr=0.1] 56%|█████▌    | 49/88 [17:14<13:14, 20.37s/epoch, loss=1.12, accuracy=0.756, val_loss=2.3, val_accuracy=0.366, lr=0.1]  57%|█████▋    | 50/88 [17:34<12:47, 20.20s/epoch, loss=1.12, accuracy=0.758, val_loss=1.82, val_accuracy=0.561, lr=0.1] 58%|█████▊    | 51/88 [17:53<12:22, 20.07s/epoch, loss=1.12, accuracy=0.753, val_loss=2.01, val_accuracy=0.512, lr=0.0316] 59%|█████▉    | 52/88 [18:14<12:07, 20.21s/epoch, loss=1.11, accuracy=0.757, val_loss=2.59, val_accuracy=0.336, lr=0.1]    60%|██████    | 53/88 [18:34<11:48, 20.23s/epoch, loss=1.11, accuracy=0.759, val_loss=2.29, val_accuracy=0.399, lr=0.1] 61%|██████▏   | 54/88 [18:54<11:28, 20.24s/epoch, loss=1.11, accuracy=0.758, val_loss=2.32, val_accuracy=0.36, lr=0.1]  62%|██████▎   | 55/88 [19:15<11:07, 20.22s/epoch, loss=1.11, accuracy=0.757, val_loss=2.35, val_accuracy=0.432, lr=0.1] 64%|██████▎   | 56/88 [19:35<10:48, 20.27s/epoch, loss=1.12, accuracy=0.757, val_loss=2.76, val_accuracy=0.386, lr=0.0316] 65%|██████▍   | 57/88 [19:55<10:27, 20.26s/epoch, loss=1.11, accuracy=0.758, val_loss=9.55, val_accuracy=0.159, lr=0.1]    66%|██████▌   | 58/88 [20:15<10:07, 20.25s/epoch, loss=1.11, accuracy=0.759, val_loss=1.87, val_accuracy=0.498, lr=0.1] 67%|██████▋   | 59/88 [20:36<09:47, 20.25s/epoch, loss=1.1, accuracy=0.758, val_loss=2.49, val_accuracy=0.378, lr=0.1]  68%|██████▊   | 60/88 [20:56<09:26, 20.24s/epoch, loss=1.11, accuracy=0.757, val_loss=1.67, val_accuracy=0.533, lr=0.1] 69%|██████▉   | 61/88 [21:16<09:06, 20.25s/epoch, loss=1.11, accuracy=0.758, val_loss=1.7, val_accuracy=0.579, lr=0.0316] 70%|███████   | 62/88 [21:36<08:46, 20.24s/epoch, loss=1.11, accuracy=0.756, val_loss=2.85, val_accuracy=0.421, lr=0.1]   72%|███████▏  | 63/88 [21:57<08:27, 20.30s/epoch, loss=1.11, accuracy=0.758, val_loss=1.65, val_accuracy=0.565, lr=0.1] 73%|███████▎  | 64/88 [22:17<08:06, 20.28s/epoch, loss=1.11, accuracy=0.756, val_loss=2.04, val_accuracy=0.477, lr=0.1] 74%|███████▍  | 65/88 [22:37<07:45, 20.22s/epoch, loss=1.11, accuracy=0.758, val_loss=2.51, val_accuracy=0.431, lr=0.1] 75%|███████▌  | 66/88 [22:57<07:23, 20.16s/epoch, loss=1.11, accuracy=0.759, val_loss=1.97, val_accuracy=0.544, lr=0.0316] 76%|███████▌  | 67/88 [23:17<07:03, 20.15s/epoch, loss=1.11, accuracy=0.759, val_loss=2.86, val_accuracy=0.384, lr=0.1]    77%|███████▋  | 68/88 [23:37<06:42, 20.12s/epoch, loss=1.11, accuracy=0.758, val_loss=2.71, val_accuracy=0.349, lr=0.1] 78%|███████▊  | 69/88 [23:57<06:21, 20.08s/epoch, loss=1.1, accuracy=0.761, val_loss=3.16, val_accuracy=0.322, lr=0.1]  80%|███████▉  | 70/88 [24:17<06:01, 20.08s/epoch, loss=1.11, accuracy=0.757, val_loss=1.85, val_accuracy=0.548, lr=0.1] 81%|████████  | 71/88 [24:37<05:41, 20.06s/epoch, loss=1.12, accuracy=0.757, val_loss=3.39, val_accuracy=0.387, lr=0.0316] 82%|████████▏ | 72/88 [24:58<05:21, 20.08s/epoch, loss=1.11, accuracy=0.759, val_loss=2.42, val_accuracy=0.442, lr=0.1]    83%|████████▎ | 73/88 [25:18<05:00, 20.07s/epoch, loss=1.11, accuracy=0.757, val_loss=5.27, val_accuracy=0.25, lr=0.1]  84%|████████▍ | 74/88 [25:38<04:40, 20.06s/epoch, loss=1.11, accuracy=0.759, val_loss=1.87, val_accuracy=0.536, lr=0.1] 85%|████████▌ | 75/88 [25:58<04:20, 20.07s/epoch, loss=1.1, accuracy=0.757, val_loss=1.37, val_accuracy=0.676, lr=0.1]  86%|████████▋ | 76/88 [26:18<04:01, 20.11s/epoch, loss=1.1, accuracy=0.761, val_loss=2.42, val_accuracy=0.308, lr=0.0316] 88%|████████▊ | 77/88 [26:38<03:41, 20.13s/epoch, loss=1.11, accuracy=0.76, val_loss=3.75, val_accuracy=0.224, lr=0.1]    89%|████████▊ | 78/88 [26:58<03:21, 20.11s/epoch, loss=1.11, accuracy=0.758, val_loss=2.3, val_accuracy=0.398, lr=0.1] 90%|████████▉ | 79/88 [27:18<03:00, 20.08s/epoch, loss=1.11, accuracy=0.759, val_loss=1.86, val_accuracy=0.561, lr=0.1] 91%|█████████ | 80/88 [27:38<02:40, 20.06s/epoch, loss=1.1, accuracy=0.759, val_loss=2.22, val_accuracy=0.447, lr=0.1]  92%|█████████▏| 81/88 [27:58<02:20, 20.07s/epoch, loss=1.1, accuracy=0.759, val_loss=2.3, val_accuracy=0.405, lr=0.0316] 93%|█████████▎| 82/88 [28:18<02:00, 20.05s/epoch, loss=0.896, accuracy=0.818, val_loss=0.905, val_accuracy=0.796, lr=0.01] 94%|█████████▍| 83/88 [28:38<01:40, 20.02s/epoch, loss=0.722, accuracy=0.848, val_loss=0.828, val_accuracy=0.795, lr=0.01] 95%|█████████▌| 84/88 [28:58<01:20, 20.02s/epoch, loss=0.641, accuracy=0.858, val_loss=0.937, val_accuracy=0.743, lr=0.01] 97%|█████████▋| 85/88 [29:18<00:59, 19.98s/epoch, loss=0.596, accuracy=0.861, val_loss=0.738, val_accuracy=0.814, lr=0.01] 98%|█████████▊| 86/88 [29:38<00:40, 20.00s/epoch, loss=0.577, accuracy=0.862, val_loss=1.14, val_accuracy=0.713, lr=0.01]  99%|█████████▉| 87/88 [29:58<00:19, 19.97s/epoch, loss=0.568, accuracy=0.862, val_loss=0.756, val_accuracy=0.798, lr=0.01]100%|██████████| 88/88 [30:18<00:00, 20.00s/epoch, loss=0.562, accuracy=0.864, val_loss=0.789, val_accuracy=0.78, lr=0.01] 100%|██████████| 88/88 [30:18<00:00, 20.67s/epoch, loss=0.562, accuracy=0.864, val_loss=0.789, val_accuracy=0.78, lr=0.01]
Using real-time data augmentation.
Test score: 0.7890866994857788
Test accuracy: 0.779699981212616


* * * Run SGD for ID = 17_6. * * *


2024-03-05 12:01:40.316378: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 12:01:42.944570: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 12:01:42.945662: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-05 12:01:42.991797: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-03-05 12:01:42.991842: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 12:01:42.994929: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 12:01:42.994991: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 12:01:42.997348: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 12:01:42.998037: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 12:01:43.000526: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 12:01:43.001964: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 12:01:43.006710: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 12:01:43.007323: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 12:01:43.007410: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 12:01:44.248188: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-05 12:01:44.248767: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 12:01:44.249524: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-03-05 12:01:44.249554: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 12:01:44.249591: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 12:01:44.249609: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 12:01:44.249625: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 12:01:44.249641: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 12:01:44.249657: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 12:01:44.249672: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 12:01:44.249697: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 12:01:44.250155: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 12:01:44.250196: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 12:01:44.896751: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-05 12:01:44.896799: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-05 12:01:44.896808: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-05 12:01:44.897713: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:02:00.0, compute capability: 6.1)
{'id': '17_06', 'seed': 6, 'out_folder': 'results/epoch_budget', 'batch_size': 128, 'epochs': 88, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'bootstrapping': False, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/88 [00:00<?, ?epoch/s]2024-03-05 12:01:45.755166: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-05 12:01:45.767131: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600020000 Hz
2024-03-05 12:01:47.756521: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 12:01:47.945216: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 12:01:48.637546: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-05 12:01:48.699342: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/88 [01:00<1:27:04, 60.05s/epoch, loss=3.33, accuracy=0.293, val_loss=2.42, val_accuracy=0.217, lr=0.1]  2%|▏         | 2/88 [01:20<52:57, 36.95s/epoch, loss=1.63, accuracy=0.493, val_loss=2.18, val_accuracy=0.38, lr=0.1]     3%|▎         | 3/88 [01:41<41:31, 29.31s/epoch, loss=1.35, accuracy=0.63, val_loss=1.83, val_accuracy=0.479, lr=0.1]  5%|▍         | 4/88 [02:01<36:02, 25.74s/epoch, loss=1.27, accuracy=0.681, val_loss=1.53, val_accuracy=0.595, lr=0.1]  6%|▌         | 5/88 [02:21<32:49, 23.73s/epoch, loss=1.24, accuracy=0.703, val_loss=1.83, val_accuracy=0.547, lr=0.1]  7%|▋         | 6/88 [02:41<30:46, 22.52s/epoch, loss=1.22, accuracy=0.712, val_loss=1.71, val_accuracy=0.543, lr=0.1]  8%|▊         | 7/88 [03:02<29:31, 21.87s/epoch, loss=1.21, accuracy=0.72, val_loss=3.24, val_accuracy=0.272, lr=0.1]   9%|▉         | 8/88 [03:22<28:28, 21.36s/epoch, loss=1.21, accuracy=0.724, val_loss=1.82, val_accuracy=0.52, lr=0.1] 10%|█         | 9/88 [03:42<27:38, 20.99s/epoch, loss=1.21, accuracy=0.727, val_loss=2.8, val_accuracy=0.38, lr=0.0316] 11%|█▏        | 10/88 [04:02<26:58, 20.75s/epoch, loss=1.2, accuracy=0.732, val_loss=2.23, val_accuracy=0.416, lr=0.1]  12%|█▎        | 11/88 [04:23<26:24, 20.57s/epoch, loss=1.2, accuracy=0.735, val_loss=1.68, val_accuracy=0.581, lr=0.1] 14%|█▎        | 12/88 [04:43<25:55, 20.47s/epoch, loss=1.19, accuracy=0.737, val_loss=1.76, val_accuracy=0.569, lr=0.1] 15%|█▍        | 13/88 [05:03<25:30, 20.41s/epoch, loss=1.19, accuracy=0.737, val_loss=1.79, val_accuracy=0.593, lr=0.1] 16%|█▌        | 14/88 [05:23<25:06, 20.35s/epoch, loss=1.19, accuracy=0.737, val_loss=1.83, val_accuracy=0.518, lr=0.0316] 17%|█▋        | 15/88 [05:43<24:38, 20.26s/epoch, loss=1.18, accuracy=0.74, val_loss=2.63, val_accuracy=0.241, lr=0.1]     18%|█▊        | 16/88 [06:03<24:16, 20.24s/epoch, loss=1.18, accuracy=0.74, val_loss=1.84, val_accuracy=0.531, lr=0.1] 19%|█▉        | 17/88 [06:24<23:55, 20.22s/epoch, loss=1.18, accuracy=0.742, val_loss=1.61, val_accuracy=0.605, lr=0.1] 20%|██        | 18/88 [06:44<23:33, 20.19s/epoch, loss=1.17, accuracy=0.742, val_loss=1.98, val_accuracy=0.508, lr=0.1] 22%|██▏       | 19/88 [07:04<23:14, 20.22s/epoch, loss=1.16, accuracy=0.747, val_loss=2.65, val_accuracy=0.432, lr=0.0316] 23%|██▎       | 20/88 [07:24<22:54, 20.21s/epoch, loss=1.17, accuracy=0.746, val_loss=3.33, val_accuracy=0.368, lr=0.1]    24%|██▍       | 21/88 [07:45<22:35, 20.23s/epoch, loss=1.17, accuracy=0.745, val_loss=2.25, val_accuracy=0.497, lr=0.1] 25%|██▌       | 22/88 [08:05<22:16, 20.24s/epoch, loss=1.16, accuracy=0.75, val_loss=1.87, val_accuracy=0.543, lr=0.1]  26%|██▌       | 23/88 [08:25<21:54, 20.23s/epoch, loss=1.16, accuracy=0.747, val_loss=1.56, val_accuracy=0.604, lr=0.1] 27%|██▋       | 24/88 [08:45<21:35, 20.24s/epoch, loss=1.16, accuracy=0.748, val_loss=2.48, val_accuracy=0.459, lr=0.0316] 28%|██▊       | 25/88 [09:05<21:12, 20.21s/epoch, loss=1.16, accuracy=0.749, val_loss=1.69, val_accuracy=0.58, lr=0.1]     30%|██▉       | 26/88 [09:25<20:49, 20.16s/epoch, loss=1.15, accuracy=0.749, val_loss=1.49, val_accuracy=0.636, lr=0.1] 31%|███       | 27/88 [09:45<20:28, 20.13s/epoch, loss=1.15, accuracy=0.749, val_loss=1.99, val_accuracy=0.411, lr=0.1] 32%|███▏      | 28/88 [10:06<20:07, 20.12s/epoch, loss=1.15, accuracy=0.749, val_loss=2.07, val_accuracy=0.552, lr=0.1] 33%|███▎      | 29/88 [10:26<19:45, 20.10s/epoch, loss=1.16, accuracy=0.75, val_loss=2.29, val_accuracy=0.484, lr=0.1]  34%|███▍      | 30/88 [10:46<19:24, 20.09s/epoch, loss=1.15, accuracy=0.751, val_loss=1.79, val_accuracy=0.56, lr=0.1] 35%|███▌      | 31/88 [11:06<19:04, 20.07s/epoch, loss=1.15, accuracy=0.752, val_loss=1.62, val_accuracy=0.582, lr=0.0316] 36%|███▋      | 32/88 [11:26<18:43, 20.06s/epoch, loss=1.15, accuracy=0.753, val_loss=2.23, val_accuracy=0.479, lr=0.1]    38%|███▊      | 33/88 [11:46<18:19, 19.98s/epoch, loss=1.14, accuracy=0.75, val_loss=1.96, val_accuracy=0.544, lr=0.1]  39%|███▊      | 34/88 [12:06<18:02, 20.04s/epoch, loss=1.15, accuracy=0.752, val_loss=2.39, val_accuracy=0.454, lr=0.1] 40%|███▉      | 35/88 [12:26<17:41, 20.03s/epoch, loss=1.14, accuracy=0.751, val_loss=3.19, val_accuracy=0.334, lr=0.1] 41%|████      | 36/88 [12:46<17:25, 20.11s/epoch, loss=1.14, accuracy=0.753, val_loss=1.5, val_accuracy=0.627, lr=0.0316] 42%|████▏     | 37/88 [13:06<17:07, 20.16s/epoch, loss=1.14, accuracy=0.751, val_loss=2.03, val_accuracy=0.495, lr=0.1]   43%|████▎     | 38/88 [13:26<16:45, 20.12s/epoch, loss=1.14, accuracy=0.751, val_loss=1.93, val_accuracy=0.491, lr=0.1] 44%|████▍     | 39/88 [13:46<16:25, 20.10s/epoch, loss=1.14, accuracy=0.755, val_loss=2.09, val_accuracy=0.501, lr=0.1] 45%|████▌     | 40/88 [14:07<16:06, 20.13s/epoch, loss=1.14, accuracy=0.754, val_loss=3.23, val_accuracy=0.291, lr=0.1] 47%|████▋     | 41/88 [14:27<15:45, 20.11s/epoch, loss=1.13, accuracy=0.752, val_loss=2.79, val_accuracy=0.364, lr=0.0316] 48%|████▊     | 42/88 [14:47<15:23, 20.07s/epoch, loss=1.14, accuracy=0.755, val_loss=2.34, val_accuracy=0.44, lr=0.1]     49%|████▉     | 43/88 [15:06<14:58, 19.97s/epoch, loss=1.12, accuracy=0.756, val_loss=1.51, val_accuracy=0.604, lr=0.1] 50%|█████     | 44/88 [15:26<14:36, 19.91s/epoch, loss=1.14, accuracy=0.757, val_loss=2.62, val_accuracy=0.342, lr=0.1] 51%|█████     | 45/88 [15:46<14:12, 19.82s/epoch, loss=1.13, accuracy=0.757, val_loss=1.69, val_accuracy=0.551, lr=0.1] 52%|█████▏    | 46/88 [16:06<13:56, 19.92s/epoch, loss=1.13, accuracy=0.754, val_loss=1.97, val_accuracy=0.507, lr=0.0316] 53%|█████▎    | 47/88 [16:26<13:38, 19.96s/epoch, loss=1.13, accuracy=0.757, val_loss=4.35, val_accuracy=0.169, lr=0.1]    55%|█████▍    | 48/88 [16:46<13:19, 19.98s/epoch, loss=1.13, accuracy=0.758, val_loss=2.2, val_accuracy=0.491, lr=0.1]  56%|█████▌    | 49/88 [17:06<12:59, 19.99s/epoch, loss=1.13, accuracy=0.756, val_loss=1.6, val_accuracy=0.579, lr=0.1] 57%|█████▋    | 50/88 [17:26<12:40, 20.00s/epoch, loss=1.13, accuracy=0.755, val_loss=3.28, val_accuracy=0.36, lr=0.1] 58%|█████▊    | 51/88 [17:46<12:21, 20.05s/epoch, loss=1.13, accuracy=0.756, val_loss=1.66, val_accuracy=0.591, lr=0.0316] 59%|█████▉    | 52/88 [18:06<12:01, 20.04s/epoch, loss=1.12, accuracy=0.756, val_loss=3.43, val_accuracy=0.339, lr=0.1]    60%|██████    | 53/88 [18:26<11:40, 20.03s/epoch, loss=1.12, accuracy=0.755, val_loss=2.3, val_accuracy=0.386, lr=0.1]  61%|██████▏   | 54/88 [18:46<11:20, 20.02s/epoch, loss=1.12, accuracy=0.755, val_loss=1.45, val_accuracy=0.64, lr=0.1] 62%|██████▎   | 55/88 [19:06<11:01, 20.05s/epoch, loss=1.12, accuracy=0.755, val_loss=2.13, val_accuracy=0.487, lr=0.1] 64%|██████▎   | 56/88 [19:26<10:41, 20.03s/epoch, loss=1.13, accuracy=0.755, val_loss=2.13, val_accuracy=0.487, lr=0.1] 65%|██████▍   | 57/88 [19:46<10:22, 20.07s/epoch, loss=1.12, accuracy=0.757, val_loss=1.72, val_accuracy=0.53, lr=0.1]  66%|██████▌   | 58/88 [20:07<10:03, 20.10s/epoch, loss=1.12, accuracy=0.757, val_loss=1.56, val_accuracy=0.613, lr=0.1] 67%|██████▋   | 59/88 [20:27<09:44, 20.14s/epoch, loss=1.12, accuracy=0.758, val_loss=1.47, val_accuracy=0.641, lr=0.0316] 68%|██████▊   | 60/88 [20:47<09:23, 20.12s/epoch, loss=1.12, accuracy=0.757, val_loss=2.18, val_accuracy=0.453, lr=0.1]    69%|██████▉   | 61/88 [21:07<09:03, 20.11s/epoch, loss=1.12, accuracy=0.758, val_loss=1.67, val_accuracy=0.555, lr=0.1] 70%|███████   | 62/88 [21:27<08:42, 20.11s/epoch, loss=1.12, accuracy=0.757, val_loss=3.02, val_accuracy=0.266, lr=0.1] 72%|███████▏  | 63/88 [21:47<08:21, 20.05s/epoch, loss=1.12, accuracy=0.759, val_loss=3.84, val_accuracy=0.34, lr=0.1]  73%|███████▎  | 64/88 [22:07<08:00, 20.04s/epoch, loss=1.12, accuracy=0.758, val_loss=1.87, val_accuracy=0.503, lr=0.0316] 74%|███████▍  | 65/88 [22:27<07:40, 20.03s/epoch, loss=1.12, accuracy=0.76, val_loss=2.25, val_accuracy=0.419, lr=0.1]     75%|███████▌  | 66/88 [22:47<07:22, 20.09s/epoch, loss=1.12, accuracy=0.756, val_loss=1.67, val_accuracy=0.553, lr=0.1] 76%|███████▌  | 67/88 [23:07<07:00, 20.02s/epoch, loss=1.11, accuracy=0.76, val_loss=1.72, val_accuracy=0.512, lr=0.1]  77%|███████▋  | 68/88 [23:28<06:43, 20.18s/epoch, loss=1.12, accuracy=0.755, val_loss=1.76, val_accuracy=0.579, lr=0.1] 78%|███████▊  | 69/88 [23:47<06:20, 20.02s/epoch, loss=1.11, accuracy=0.759, val_loss=2.22, val_accuracy=0.499, lr=0.0316] 80%|███████▉  | 70/88 [24:07<05:59, 19.97s/epoch, loss=1.11, accuracy=0.758, val_loss=3.09, val_accuracy=0.388, lr=0.1]    81%|████████  | 71/88 [24:26<05:35, 19.75s/epoch, loss=1.11, accuracy=0.761, val_loss=1.71, val_accuracy=0.579, lr=0.1] 82%|████████▏ | 72/88 [24:46<05:13, 19.62s/epoch, loss=1.11, accuracy=0.757, val_loss=2.24, val_accuracy=0.448, lr=0.1] 83%|████████▎ | 73/88 [25:05<04:53, 19.53s/epoch, loss=1.11, accuracy=0.758, val_loss=2.03, val_accuracy=0.508, lr=0.1] 84%|████████▍ | 74/88 [25:25<04:35, 19.71s/epoch, loss=1.11, accuracy=0.758, val_loss=2.62, val_accuracy=0.456, lr=0.0316] 85%|████████▌ | 75/88 [25:45<04:16, 19.70s/epoch, loss=1.12, accuracy=0.757, val_loss=4.44, val_accuracy=0.31, lr=0.1]     86%|████████▋ | 76/88 [26:04<03:55, 19.60s/epoch, loss=1.12, accuracy=0.758, val_loss=1.33, val_accuracy=0.686, lr=0.1] 88%|████████▊ | 77/88 [26:24<03:35, 19.58s/epoch, loss=1.11, accuracy=0.756, val_loss=1.72, val_accuracy=0.581, lr=0.1] 89%|████████▊ | 78/88 [26:43<03:15, 19.52s/epoch, loss=1.11, accuracy=0.757, val_loss=2.63, val_accuracy=0.428, lr=0.1] 90%|████████▉ | 79/88 [27:03<02:56, 19.59s/epoch, loss=1.11, accuracy=0.76, val_loss=2.77, val_accuracy=0.384, lr=0.1]  91%|█████████ | 80/88 [27:22<02:35, 19.50s/epoch, loss=1.11, accuracy=0.759, val_loss=1.72, val_accuracy=0.554, lr=0.1] 92%|█████████▏| 81/88 [27:42<02:16, 19.48s/epoch, loss=1.11, accuracy=0.76, val_loss=1.61, val_accuracy=0.59, lr=0.0316] 93%|█████████▎| 82/88 [28:01<01:57, 19.58s/epoch, loss=0.899, accuracy=0.817, val_loss=0.89, val_accuracy=0.806, lr=0.01] 94%|█████████▍| 83/88 [28:21<01:38, 19.61s/epoch, loss=0.724, accuracy=0.848, val_loss=0.837, val_accuracy=0.797, lr=0.01] 95%|█████████▌| 84/88 [28:40<01:18, 19.52s/epoch, loss=0.644, accuracy=0.857, val_loss=0.78, val_accuracy=0.799, lr=0.01]  97%|█████████▋| 85/88 [29:00<00:58, 19.49s/epoch, loss=0.597, accuracy=0.86, val_loss=0.725, val_accuracy=0.812, lr=0.01] 98%|█████████▊| 86/88 [29:20<00:39, 19.73s/epoch, loss=0.58, accuracy=0.862, val_loss=0.719, val_accuracy=0.813, lr=0.01] 99%|█████████▉| 87/88 [29:40<00:19, 19.86s/epoch, loss=0.569, accuracy=0.862, val_loss=0.937, val_accuracy=0.741, lr=0.01]100%|██████████| 88/88 [30:00<00:00, 19.82s/epoch, loss=0.56, accuracy=0.865, val_loss=0.809, val_accuracy=0.786, lr=0.01] 100%|██████████| 88/88 [30:00<00:00, 20.46s/epoch, loss=0.56, accuracy=0.865, val_loss=0.809, val_accuracy=0.786, lr=0.01]
Using real-time data augmentation.
Test score: 0.8086264729499817
Test accuracy: 0.7857000231742859


* * * Run SGD for ID = 17_7. * * *


2024-03-05 12:31:49.763450: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 12:31:52.403704: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 12:31:52.404681: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-05 12:31:52.441274: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-03-05 12:31:52.441321: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 12:31:52.444389: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 12:31:52.444436: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 12:31:52.446784: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 12:31:52.447719: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 12:31:52.450194: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 12:31:52.451550: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 12:31:52.456348: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 12:31:52.461274: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 12:31:52.461365: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 12:31:53.703485: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-05 12:31:53.704142: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 12:31:53.704900: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-03-05 12:31:53.704935: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 12:31:53.704990: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 12:31:53.705011: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 12:31:53.705027: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 12:31:53.705044: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 12:31:53.705060: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 12:31:53.705075: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 12:31:53.705090: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 12:31:53.705518: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 12:31:53.705558: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 12:31:54.371524: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-05 12:31:54.371575: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-05 12:31:54.371584: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-05 12:31:54.372547: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:02:00.0, compute capability: 6.1)
{'id': '17_07', 'seed': 7, 'out_folder': 'results/epoch_budget', 'batch_size': 128, 'epochs': 88, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'bootstrapping': False, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/88 [00:00<?, ?epoch/s]2024-03-05 12:31:55.458162: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-05 12:31:55.470144: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600020000 Hz
2024-03-05 12:31:57.509643: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 12:31:57.782151: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 12:31:58.628884: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-05 12:31:58.689533: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/88 [01:02<1:30:49, 62.64s/epoch, loss=3.15, accuracy=0.298, val_loss=2.2, val_accuracy=0.277, lr=0.1]  2%|▏         | 2/88 [01:23<54:17, 37.88s/epoch, loss=1.59, accuracy=0.521, val_loss=2.25, val_accuracy=0.338, lr=0.1]   3%|▎         | 3/88 [01:43<42:22, 29.91s/epoch, loss=1.35, accuracy=0.638, val_loss=2.64, val_accuracy=0.33, lr=0.1]   5%|▍         | 4/88 [02:04<36:38, 26.18s/epoch, loss=1.28, accuracy=0.682, val_loss=1.86, val_accuracy=0.516, lr=0.1]  6%|▌         | 5/88 [02:24<33:17, 24.07s/epoch, loss=1.27, accuracy=0.698, val_loss=1.91, val_accuracy=0.454, lr=0.1]  7%|▋         | 6/88 [02:45<31:18, 22.90s/epoch, loss=1.25, accuracy=0.707, val_loss=1.76, val_accuracy=0.545, lr=0.1]  8%|▊         | 7/88 [03:05<30:03, 22.26s/epoch, loss=1.24, accuracy=0.715, val_loss=1.73, val_accuracy=0.545, lr=0.1]  9%|▉         | 8/88 [03:26<28:52, 21.66s/epoch, loss=1.23, accuracy=0.72, val_loss=1.9, val_accuracy=0.557, lr=0.1]   10%|█         | 9/88 [03:47<28:06, 21.35s/epoch, loss=1.23, accuracy=0.722, val_loss=2.61, val_accuracy=0.287, lr=0.1] 11%|█▏        | 10/88 [04:07<27:19, 21.02s/epoch, loss=1.23, accuracy=0.724, val_loss=1.95, val_accuracy=0.463, lr=0.1] 12%|█▎        | 11/88 [04:27<26:42, 20.81s/epoch, loss=1.21, accuracy=0.729, val_loss=2.13, val_accuracy=0.458, lr=0.1] 14%|█▎        | 12/88 [04:47<26:10, 20.67s/epoch, loss=1.22, accuracy=0.731, val_loss=1.9, val_accuracy=0.563, lr=0.0316] 15%|█▍        | 13/88 [05:08<25:45, 20.61s/epoch, loss=1.2, accuracy=0.735, val_loss=1.82, val_accuracy=0.582, lr=0.1]    16%|█▌        | 14/88 [05:28<25:19, 20.54s/epoch, loss=1.2, accuracy=0.736, val_loss=2.04, val_accuracy=0.456, lr=0.1] 17%|█▋        | 15/88 [05:49<24:54, 20.47s/epoch, loss=1.2, accuracy=0.736, val_loss=2.75, val_accuracy=0.365, lr=0.1] 18%|█▊        | 16/88 [06:09<24:32, 20.45s/epoch, loss=1.2, accuracy=0.736, val_loss=1.9, val_accuracy=0.482, lr=0.1]  19%|█▉        | 17/88 [06:30<24:15, 20.50s/epoch, loss=1.19, accuracy=0.74, val_loss=2.04, val_accuracy=0.444, lr=0.0316] 20%|██        | 18/88 [06:50<23:51, 20.45s/epoch, loss=1.19, accuracy=0.739, val_loss=2.28, val_accuracy=0.493, lr=0.1]   22%|██▏       | 19/88 [07:10<23:26, 20.38s/epoch, loss=1.2, accuracy=0.738, val_loss=3.19, val_accuracy=0.29, lr=0.1]   23%|██▎       | 20/88 [07:31<23:05, 20.38s/epoch, loss=1.18, accuracy=0.742, val_loss=1.75, val_accuracy=0.59, lr=0.1] 24%|██▍       | 21/88 [07:51<22:46, 20.40s/epoch, loss=1.18, accuracy=0.743, val_loss=3.58, val_accuracy=0.362, lr=0.1] 25%|██▌       | 22/88 [08:11<22:26, 20.40s/epoch, loss=1.18, accuracy=0.741, val_loss=1.69, val_accuracy=0.577, lr=0.1] 26%|██▌       | 23/88 [08:32<22:07, 20.42s/epoch, loss=1.18, accuracy=0.741, val_loss=1.65, val_accuracy=0.598, lr=0.1] 27%|██▋       | 24/88 [08:52<21:49, 20.46s/epoch, loss=1.18, accuracy=0.745, val_loss=2.09, val_accuracy=0.457, lr=0.1] 28%|██▊       | 25/88 [09:13<21:31, 20.50s/epoch, loss=1.18, accuracy=0.744, val_loss=1.94, val_accuracy=0.5, lr=0.1]   30%|██▉       | 26/88 [09:33<21:09, 20.48s/epoch, loss=1.18, accuracy=0.745, val_loss=2.77, val_accuracy=0.414, lr=0.1] 31%|███       | 27/88 [09:54<20:48, 20.46s/epoch, loss=1.18, accuracy=0.745, val_loss=1.77, val_accuracy=0.575, lr=0.1] 32%|███▏      | 28/88 [10:14<20:24, 20.40s/epoch, loss=1.17, accuracy=0.747, val_loss=2.42, val_accuracy=0.407, lr=0.0316] 33%|███▎      | 29/88 [10:35<20:02, 20.38s/epoch, loss=1.18, accuracy=0.745, val_loss=3.78, val_accuracy=0.394, lr=0.1]    34%|███▍      | 30/88 [10:55<19:44, 20.41s/epoch, loss=1.18, accuracy=0.747, val_loss=3.55, val_accuracy=0.352, lr=0.1] 35%|███▌      | 31/88 [11:15<19:25, 20.44s/epoch, loss=1.17, accuracy=0.747, val_loss=2.14, val_accuracy=0.457, lr=0.1] 36%|███▋      | 32/88 [11:36<19:06, 20.47s/epoch, loss=1.17, accuracy=0.747, val_loss=2.07, val_accuracy=0.535, lr=0.1] 38%|███▊      | 33/88 [11:56<18:44, 20.44s/epoch, loss=1.18, accuracy=0.745, val_loss=1.92, val_accuracy=0.505, lr=0.0316] 39%|███▊      | 34/88 [12:17<18:21, 20.40s/epoch, loss=1.17, accuracy=0.747, val_loss=2.59, val_accuracy=0.417, lr=0.1]    40%|███▉      | 35/88 [12:37<18:01, 20.40s/epoch, loss=1.17, accuracy=0.748, val_loss=3.06, val_accuracy=0.408, lr=0.1] 41%|████      | 36/88 [12:57<17:40, 20.39s/epoch, loss=1.16, accuracy=0.75, val_loss=1.64, val_accuracy=0.591, lr=0.1]  42%|████▏     | 37/88 [13:18<17:22, 20.45s/epoch, loss=1.17, accuracy=0.749, val_loss=3.74, val_accuracy=0.331, lr=0.1] 43%|████▎     | 38/88 [13:38<16:59, 20.40s/epoch, loss=1.16, accuracy=0.751, val_loss=2.05, val_accuracy=0.431, lr=0.1] 44%|████▍     | 39/88 [13:58<16:33, 20.28s/epoch, loss=1.15, accuracy=0.75, val_loss=1.93, val_accuracy=0.476, lr=0.1]  45%|████▌     | 40/88 [14:18<16:08, 20.18s/epoch, loss=1.16, accuracy=0.75, val_loss=2.54, val_accuracy=0.369, lr=0.1] 47%|████▋     | 41/88 [14:39<15:51, 20.24s/epoch, loss=1.16, accuracy=0.749, val_loss=2.51, val_accuracy=0.437, lr=0.0316] 48%|████▊     | 42/88 [14:59<15:33, 20.28s/epoch, loss=1.16, accuracy=0.748, val_loss=2.04, val_accuracy=0.501, lr=0.1]    49%|████▉     | 43/88 [15:19<15:04, 20.11s/epoch, loss=1.16, accuracy=0.748, val_loss=1.58, val_accuracy=0.6, lr=0.1]   50%|█████     | 44/88 [15:39<14:50, 20.24s/epoch, loss=1.16, accuracy=0.747, val_loss=1.83, val_accuracy=0.538, lr=0.1] 51%|█████     | 45/88 [16:00<14:33, 20.31s/epoch, loss=1.16, accuracy=0.752, val_loss=1.61, val_accuracy=0.594, lr=0.1] 52%|█████▏    | 46/88 [16:20<14:15, 20.37s/epoch, loss=1.16, accuracy=0.753, val_loss=1.66, val_accuracy=0.586, lr=0.1] 53%|█████▎    | 47/88 [16:41<13:56, 20.40s/epoch, loss=1.17, accuracy=0.75, val_loss=2.04, val_accuracy=0.487, lr=0.1]  55%|█████▍    | 48/88 [17:01<13:38, 20.46s/epoch, loss=1.16, accuracy=0.751, val_loss=1.5, val_accuracy=0.62, lr=0.1]  56%|█████▌    | 49/88 [17:22<13:17, 20.46s/epoch, loss=1.15, accuracy=0.75, val_loss=2.76, val_accuracy=0.373, lr=0.1] 57%|█████▋    | 50/88 [17:42<12:57, 20.47s/epoch, loss=1.16, accuracy=0.752, val_loss=3.5, val_accuracy=0.322, lr=0.1] 58%|█████▊    | 51/88 [18:03<12:36, 20.46s/epoch, loss=1.17, accuracy=0.75, val_loss=2.71, val_accuracy=0.319, lr=0.1] 59%|█████▉    | 52/88 [18:23<12:15, 20.43s/epoch, loss=1.16, accuracy=0.753, val_loss=2.04, val_accuracy=0.506, lr=0.1] 60%|██████    | 53/88 [18:44<11:57, 20.50s/epoch, loss=1.16, accuracy=0.75, val_loss=1.47, val_accuracy=0.641, lr=0.1]  61%|██████▏   | 54/88 [19:04<11:37, 20.50s/epoch, loss=1.15, accuracy=0.753, val_loss=2.34, val_accuracy=0.417, lr=0.1] 62%|██████▎   | 55/88 [19:25<11:15, 20.47s/epoch, loss=1.15, accuracy=0.754, val_loss=2.04, val_accuracy=0.511, lr=0.1] 64%|██████▎   | 56/88 [19:45<10:54, 20.45s/epoch, loss=1.16, accuracy=0.752, val_loss=2.17, val_accuracy=0.511, lr=0.1] 65%|██████▍   | 57/88 [20:05<10:33, 20.44s/epoch, loss=1.16, accuracy=0.752, val_loss=1.94, val_accuracy=0.468, lr=0.1] 66%|██████▌   | 58/88 [20:26<10:12, 20.42s/epoch, loss=1.16, accuracy=0.751, val_loss=2.37, val_accuracy=0.448, lr=0.0316] 67%|██████▋   | 59/88 [20:46<09:50, 20.36s/epoch, loss=1.15, accuracy=0.752, val_loss=2.19, val_accuracy=0.489, lr=0.1]    68%|██████▊   | 60/88 [21:06<09:28, 20.31s/epoch, loss=1.15, accuracy=0.755, val_loss=3.1, val_accuracy=0.369, lr=0.1]  69%|██████▉   | 61/88 [21:27<09:08, 20.30s/epoch, loss=1.15, accuracy=0.753, val_loss=2.28, val_accuracy=0.528, lr=0.1] 70%|███████   | 62/88 [21:47<08:45, 20.22s/epoch, loss=1.15, accuracy=0.751, val_loss=2.24, val_accuracy=0.426, lr=0.1] 72%|███████▏  | 63/88 [22:07<08:25, 20.20s/epoch, loss=1.16, accuracy=0.751, val_loss=1.6, val_accuracy=0.613, lr=0.0316] 73%|███████▎  | 64/88 [22:27<08:05, 20.23s/epoch, loss=1.15, accuracy=0.755, val_loss=1.49, val_accuracy=0.636, lr=0.1]   74%|███████▍  | 65/88 [22:47<07:45, 20.24s/epoch, loss=1.15, accuracy=0.754, val_loss=3.28, val_accuracy=0.379, lr=0.1] 75%|███████▌  | 66/88 [23:07<07:24, 20.22s/epoch, loss=1.16, accuracy=0.752, val_loss=1.82, val_accuracy=0.569, lr=0.1] 76%|███████▌  | 67/88 [23:27<07:00, 20.04s/epoch, loss=1.15, accuracy=0.754, val_loss=2.16, val_accuracy=0.458, lr=0.1] 77%|███████▋  | 68/88 [23:47<06:41, 20.08s/epoch, loss=1.16, accuracy=0.752, val_loss=2.47, val_accuracy=0.325, lr=0.0316] 78%|███████▊  | 69/88 [24:07<06:20, 20.00s/epoch, loss=1.15, accuracy=0.753, val_loss=2.28, val_accuracy=0.395, lr=0.1]    80%|███████▉  | 70/88 [24:27<06:00, 20.05s/epoch, loss=1.15, accuracy=0.754, val_loss=1.82, val_accuracy=0.567, lr=0.1] 81%|████████  | 71/88 [24:47<05:41, 20.06s/epoch, loss=1.14, accuracy=0.753, val_loss=4.79, val_accuracy=0.18, lr=0.1]  82%|████████▏ | 72/88 [25:07<05:20, 20.06s/epoch, loss=1.15, accuracy=0.754, val_loss=2.61, val_accuracy=0.4, lr=0.1]  83%|████████▎ | 73/88 [25:27<05:00, 20.04s/epoch, loss=1.14, accuracy=0.756, val_loss=1.45, val_accuracy=0.655, lr=0.1] 84%|████████▍ | 74/88 [25:48<04:40, 20.07s/epoch, loss=1.14, accuracy=0.756, val_loss=1.86, val_accuracy=0.531, lr=0.1] 85%|████████▌ | 75/88 [26:08<04:21, 20.12s/epoch, loss=1.15, accuracy=0.753, val_loss=1.98, val_accuracy=0.481, lr=0.1] 86%|████████▋ | 76/88 [26:28<04:01, 20.10s/epoch, loss=1.15, accuracy=0.753, val_loss=1.56, val_accuracy=0.61, lr=0.1]  88%|████████▊ | 77/88 [26:48<03:41, 20.11s/epoch, loss=1.15, accuracy=0.753, val_loss=4.83, val_accuracy=0.228, lr=0.1] 89%|████████▊ | 78/88 [27:08<03:21, 20.15s/epoch, loss=1.14, accuracy=0.756, val_loss=2.36, val_accuracy=0.497, lr=0.0316] 90%|████████▉ | 79/88 [27:28<03:01, 20.12s/epoch, loss=1.15, accuracy=0.754, val_loss=2.5, val_accuracy=0.442, lr=0.1]     91%|█████████ | 80/88 [27:49<02:41, 20.17s/epoch, loss=1.15, accuracy=0.756, val_loss=1.75, val_accuracy=0.54, lr=0.1] 92%|█████████▏| 81/88 [28:09<02:21, 20.15s/epoch, loss=1.15, accuracy=0.754, val_loss=1.76, val_accuracy=0.549, lr=0.1] 93%|█████████▎| 82/88 [28:29<02:00, 20.12s/epoch, loss=0.926, accuracy=0.815, val_loss=0.865, val_accuracy=0.822, lr=0.01] 94%|█████████▍| 83/88 [28:49<01:40, 20.10s/epoch, loss=0.747, accuracy=0.845, val_loss=0.763, val_accuracy=0.832, lr=0.01] 95%|█████████▌| 84/88 [29:09<01:20, 20.11s/epoch, loss=0.66, accuracy=0.855, val_loss=0.741, val_accuracy=0.821, lr=0.01]  97%|█████████▋| 85/88 [29:29<01:00, 20.13s/epoch, loss=0.618, accuracy=0.857, val_loss=0.811, val_accuracy=0.795, lr=0.01] 98%|█████████▊| 86/88 [29:49<00:40, 20.14s/epoch, loss=0.593, accuracy=0.859, val_loss=0.839, val_accuracy=0.779, lr=0.01] 99%|█████████▉| 87/88 [30:09<00:20, 20.13s/epoch, loss=0.581, accuracy=0.861, val_loss=0.695, val_accuracy=0.824, lr=0.01]100%|██████████| 88/88 [30:29<00:00, 20.14s/epoch, loss=0.578, accuracy=0.862, val_loss=0.723, val_accuracy=0.816, lr=0.01]100%|██████████| 88/88 [30:29<00:00, 20.80s/epoch, loss=0.578, accuracy=0.862, val_loss=0.723, val_accuracy=0.816, lr=0.01]
Using real-time data augmentation.
Test score: 0.7229592800140381
Test accuracy: 0.8159999847412109


* * * Run SGD for ID = 17_8. * * *


2024-03-05 13:02:28.963598: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 13:02:31.523817: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 13:02:31.524911: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-05 13:02:31.562119: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-03-05 13:02:31.562165: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 13:02:31.565179: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 13:02:31.565220: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 13:02:31.567496: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 13:02:31.568166: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 13:02:31.570666: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 13:02:31.572139: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 13:02:31.576795: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 13:02:31.577390: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 13:02:31.577472: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 13:02:32.818863: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-05 13:02:32.820451: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 13:02:32.821228: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-03-05 13:02:32.821259: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 13:02:32.821314: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 13:02:32.821330: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 13:02:32.821345: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 13:02:32.821361: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 13:02:32.821376: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 13:02:32.821400: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 13:02:32.821415: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 13:02:32.821824: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 13:02:32.821860: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 13:02:33.469988: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-05 13:02:33.470036: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-05 13:02:33.470044: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-05 13:02:33.470964: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:02:00.0, compute capability: 6.1)
{'id': '17_08', 'seed': 8, 'out_folder': 'results/epoch_budget', 'batch_size': 128, 'epochs': 88, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'bootstrapping': False, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/88 [00:00<?, ?epoch/s]2024-03-05 13:02:34.321354: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-05 13:02:34.333128: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600020000 Hz
2024-03-05 13:02:36.322475: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 13:02:36.552849: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 13:02:37.215166: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-05 13:02:37.270419: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/88 [00:57<1:24:04, 57.98s/epoch, loss=2.83, accuracy=0.409, val_loss=2.93, val_accuracy=0.23, lr=0.1]  2%|▏         | 2/88 [01:18<51:15, 35.76s/epoch, loss=1.45, accuracy=0.61, val_loss=1.72, val_accuracy=0.523, lr=0.1]    3%|▎         | 3/88 [01:38<40:39, 28.70s/epoch, loss=1.3, accuracy=0.666, val_loss=2.32, val_accuracy=0.33, lr=0.1]   5%|▍         | 4/88 [01:58<35:11, 25.14s/epoch, loss=1.26, accuracy=0.695, val_loss=2.04, val_accuracy=0.428, lr=0.1]  6%|▌         | 5/88 [02:17<31:58, 23.12s/epoch, loss=1.23, accuracy=0.709, val_loss=2.61, val_accuracy=0.358, lr=0.1]  7%|▋         | 6/88 [02:37<29:54, 21.88s/epoch, loss=1.22, accuracy=0.715, val_loss=1.47, val_accuracy=0.631, lr=0.1]  8%|▊         | 7/88 [02:56<28:34, 21.17s/epoch, loss=1.21, accuracy=0.722, val_loss=2.03, val_accuracy=0.479, lr=0.1]  9%|▉         | 8/88 [03:16<27:27, 20.60s/epoch, loss=1.2, accuracy=0.727, val_loss=1.61, val_accuracy=0.593, lr=0.1]  10%|█         | 9/88 [03:35<26:42, 20.28s/epoch, loss=1.2, accuracy=0.729, val_loss=1.53, val_accuracy=0.606, lr=0.1] 11%|█▏        | 10/88 [03:55<25:59, 20.00s/epoch, loss=1.18, accuracy=0.734, val_loss=2.67, val_accuracy=0.448, lr=0.1] 12%|█▎        | 11/88 [04:15<25:43, 20.05s/epoch, loss=1.17, accuracy=0.737, val_loss=4.04, val_accuracy=0.252, lr=0.0316] 14%|█▎        | 12/88 [04:34<25:13, 19.91s/epoch, loss=1.17, accuracy=0.736, val_loss=1.57, val_accuracy=0.631, lr=0.1]    15%|█▍        | 13/88 [04:54<24:53, 19.92s/epoch, loss=1.18, accuracy=0.737, val_loss=2.1, val_accuracy=0.462, lr=0.1]  16%|█▌        | 14/88 [05:14<24:33, 19.91s/epoch, loss=1.18, accuracy=0.738, val_loss=1.55, val_accuracy=0.603, lr=0.1] 17%|█▋        | 15/88 [05:34<24:09, 19.85s/epoch, loss=1.17, accuracy=0.742, val_loss=1.58, val_accuracy=0.618, lr=0.1] 18%|█▊        | 16/88 [05:55<24:03, 20.05s/epoch, loss=1.17, accuracy=0.743, val_loss=1.49, val_accuracy=0.622, lr=0.0316] 19%|█▉        | 17/88 [06:15<23:53, 20.19s/epoch, loss=1.17, accuracy=0.742, val_loss=1.95, val_accuracy=0.523, lr=0.1]    20%|██        | 18/88 [06:35<23:34, 20.21s/epoch, loss=1.16, accuracy=0.743, val_loss=2.2, val_accuracy=0.474, lr=0.1]  22%|██▏       | 19/88 [06:56<23:15, 20.23s/epoch, loss=1.16, accuracy=0.745, val_loss=2.14, val_accuracy=0.504, lr=0.1] 23%|██▎       | 20/88 [07:16<22:53, 20.20s/epoch, loss=1.16, accuracy=0.747, val_loss=1.78, val_accuracy=0.556, lr=0.1] 24%|██▍       | 21/88 [07:36<22:35, 20.23s/epoch, loss=1.16, accuracy=0.745, val_loss=1.69, val_accuracy=0.57, lr=0.0316] 25%|██▌       | 22/88 [07:56<22:15, 20.23s/epoch, loss=1.16, accuracy=0.747, val_loss=1.43, val_accuracy=0.659, lr=0.1]   26%|██▌       | 23/88 [08:16<21:55, 20.23s/epoch, loss=1.16, accuracy=0.751, val_loss=1.97, val_accuracy=0.513, lr=0.1] 27%|██▋       | 24/88 [08:37<21:44, 20.38s/epoch, loss=1.16, accuracy=0.748, val_loss=1.6, val_accuracy=0.615, lr=0.1]  28%|██▊       | 25/88 [08:58<21:22, 20.35s/epoch, loss=1.15, accuracy=0.748, val_loss=2.14, val_accuracy=0.459, lr=0.1] 30%|██▉       | 26/88 [09:18<21:03, 20.37s/epoch, loss=1.15, accuracy=0.75, val_loss=1.99, val_accuracy=0.491, lr=0.1]  31%|███       | 27/88 [09:38<20:38, 20.30s/epoch, loss=1.15, accuracy=0.75, val_loss=1.5, val_accuracy=0.619, lr=0.0316] 32%|███▏      | 28/88 [09:58<20:18, 20.31s/epoch, loss=1.15, accuracy=0.749, val_loss=1.73, val_accuracy=0.584, lr=0.1]  33%|███▎      | 29/88 [10:19<19:58, 20.31s/epoch, loss=1.15, accuracy=0.751, val_loss=2.37, val_accuracy=0.395, lr=0.1] 34%|███▍      | 30/88 [10:39<19:36, 20.29s/epoch, loss=1.14, accuracy=0.751, val_loss=2.05, val_accuracy=0.511, lr=0.1] 35%|███▌      | 31/88 [10:59<19:13, 20.23s/epoch, loss=1.15, accuracy=0.75, val_loss=2.5, val_accuracy=0.406, lr=0.1]   36%|███▋      | 32/88 [11:19<18:55, 20.27s/epoch, loss=1.14, accuracy=0.752, val_loss=2.53, val_accuracy=0.371, lr=0.0316] 38%|███▊      | 33/88 [11:39<18:31, 20.22s/epoch, loss=1.14, accuracy=0.754, val_loss=1.55, val_accuracy=0.628, lr=0.1]    39%|███▊      | 34/88 [11:59<18:07, 20.14s/epoch, loss=1.14, accuracy=0.754, val_loss=2.13, val_accuracy=0.426, lr=0.1] 40%|███▉      | 35/88 [12:19<17:45, 20.11s/epoch, loss=1.14, accuracy=0.75, val_loss=2.9, val_accuracy=0.447, lr=0.1]   41%|████      | 36/88 [12:40<17:25, 20.10s/epoch, loss=1.15, accuracy=0.751, val_loss=1.93, val_accuracy=0.519, lr=0.1] 42%|████▏     | 37/88 [12:59<17:00, 20.02s/epoch, loss=1.14, accuracy=0.754, val_loss=2.82, val_accuracy=0.378, lr=0.0316] 43%|████▎     | 38/88 [13:19<16:40, 20.00s/epoch, loss=1.13, accuracy=0.754, val_loss=1.7, val_accuracy=0.548, lr=0.1]     44%|████▍     | 39/88 [13:39<16:18, 19.97s/epoch, loss=1.13, accuracy=0.757, val_loss=1.99, val_accuracy=0.497, lr=0.1] 45%|████▌     | 40/88 [13:59<15:56, 19.93s/epoch, loss=1.14, accuracy=0.753, val_loss=2.38, val_accuracy=0.48, lr=0.1]  47%|████▋     | 41/88 [14:19<15:37, 19.94s/epoch, loss=1.13, accuracy=0.756, val_loss=1.75, val_accuracy=0.514, lr=0.1] 48%|████▊     | 42/88 [14:39<15:18, 19.97s/epoch, loss=1.15, accuracy=0.752, val_loss=2.63, val_accuracy=0.396, lr=0.0316] 49%|████▉     | 43/88 [14:59<14:58, 19.97s/epoch, loss=1.14, accuracy=0.752, val_loss=1.52, val_accuracy=0.62, lr=0.1]     50%|█████     | 44/88 [15:19<14:37, 19.95s/epoch, loss=1.14, accuracy=0.755, val_loss=1.51, val_accuracy=0.629, lr=0.1] 51%|█████     | 45/88 [15:39<14:19, 19.99s/epoch, loss=1.13, accuracy=0.755, val_loss=1.82, val_accuracy=0.553, lr=0.1] 52%|█████▏    | 46/88 [15:59<14:03, 20.09s/epoch, loss=1.13, accuracy=0.753, val_loss=1.63, val_accuracy=0.564, lr=0.1] 53%|█████▎    | 47/88 [16:20<13:44, 20.11s/epoch, loss=1.13, accuracy=0.756, val_loss=2.01, val_accuracy=0.522, lr=0.0316] 55%|█████▍    | 48/88 [16:40<13:23, 20.09s/epoch, loss=1.13, accuracy=0.755, val_loss=1.68, val_accuracy=0.579, lr=0.1]    56%|█████▌    | 49/88 [17:00<13:03, 20.09s/epoch, loss=1.12, accuracy=0.758, val_loss=1.71, val_accuracy=0.563, lr=0.1] 57%|█████▋    | 50/88 [17:20<12:44, 20.12s/epoch, loss=1.13, accuracy=0.753, val_loss=2.6, val_accuracy=0.442, lr=0.1]  58%|█████▊    | 51/88 [17:40<12:23, 20.10s/epoch, loss=1.13, accuracy=0.754, val_loss=1.71, val_accuracy=0.577, lr=0.1] 59%|█████▉    | 52/88 [18:00<12:03, 20.08s/epoch, loss=1.13, accuracy=0.755, val_loss=2.08, val_accuracy=0.466, lr=0.0316] 60%|██████    | 53/88 [18:20<11:44, 20.13s/epoch, loss=1.12, accuracy=0.755, val_loss=2.93, val_accuracy=0.425, lr=0.1]    61%|██████▏   | 54/88 [18:40<11:23, 20.10s/epoch, loss=1.13, accuracy=0.756, val_loss=1.5, val_accuracy=0.638, lr=0.1]  62%|██████▎   | 55/88 [19:00<11:02, 20.06s/epoch, loss=1.13, accuracy=0.753, val_loss=2.09, val_accuracy=0.488, lr=0.1] 64%|██████▎   | 56/88 [19:20<10:42, 20.08s/epoch, loss=1.13, accuracy=0.755, val_loss=1.57, val_accuracy=0.604, lr=0.1] 65%|██████▍   | 57/88 [19:40<10:22, 20.09s/epoch, loss=1.13, accuracy=0.751, val_loss=2.06, val_accuracy=0.514, lr=0.0316] 66%|██████▌   | 58/88 [20:01<10:02, 20.09s/epoch, loss=1.13, accuracy=0.755, val_loss=1.43, val_accuracy=0.644, lr=0.1]    67%|██████▋   | 59/88 [20:21<09:43, 20.13s/epoch, loss=1.12, accuracy=0.759, val_loss=2.3, val_accuracy=0.423, lr=0.1]  68%|██████▊   | 60/88 [20:41<09:23, 20.13s/epoch, loss=1.12, accuracy=0.756, val_loss=1.59, val_accuracy=0.634, lr=0.1] 69%|██████▉   | 61/88 [21:01<09:03, 20.14s/epoch, loss=1.12, accuracy=0.756, val_loss=2.94, val_accuracy=0.433, lr=0.1] 70%|███████   | 62/88 [21:21<08:43, 20.14s/epoch, loss=1.12, accuracy=0.757, val_loss=2.53, val_accuracy=0.433, lr=0.0316] 72%|███████▏  | 63/88 [21:41<08:22, 20.10s/epoch, loss=1.12, accuracy=0.753, val_loss=2.11, val_accuracy=0.478, lr=0.1]    73%|███████▎  | 64/88 [22:01<08:00, 20.04s/epoch, loss=1.13, accuracy=0.755, val_loss=1.52, val_accuracy=0.637, lr=0.1] 74%|███████▍  | 65/88 [22:21<07:42, 20.09s/epoch, loss=1.12, accuracy=0.755, val_loss=1.88, val_accuracy=0.505, lr=0.1] 75%|███████▌  | 66/88 [22:41<07:21, 20.09s/epoch, loss=1.12, accuracy=0.756, val_loss=1.5, val_accuracy=0.631, lr=0.1]  76%|███████▌  | 67/88 [23:01<07:01, 20.05s/epoch, loss=1.12, accuracy=0.758, val_loss=2.9, val_accuracy=0.388, lr=0.0316] 77%|███████▋  | 68/88 [23:21<06:40, 20.03s/epoch, loss=1.12, accuracy=0.755, val_loss=1.57, val_accuracy=0.594, lr=0.1]   78%|███████▊  | 69/88 [23:41<06:20, 20.00s/epoch, loss=1.12, accuracy=0.755, val_loss=2.21, val_accuracy=0.457, lr=0.1] 80%|███████▉  | 70/88 [24:01<05:59, 19.96s/epoch, loss=1.11, accuracy=0.756, val_loss=1.77, val_accuracy=0.562, lr=0.1] 81%|████████  | 71/88 [24:21<05:40, 20.01s/epoch, loss=1.12, accuracy=0.757, val_loss=1.67, val_accuracy=0.545, lr=0.1] 82%|████████▏ | 72/88 [24:41<05:20, 20.01s/epoch, loss=1.12, accuracy=0.758, val_loss=2.1, val_accuracy=0.523, lr=0.0316] 83%|████████▎ | 73/88 [25:01<05:00, 20.06s/epoch, loss=1.11, accuracy=0.758, val_loss=3.48, val_accuracy=0.362, lr=0.1]   84%|████████▍ | 74/88 [25:22<04:41, 20.10s/epoch, loss=1.12, accuracy=0.755, val_loss=2.4, val_accuracy=0.382, lr=0.1]  85%|████████▌ | 75/88 [25:42<04:20, 20.08s/epoch, loss=1.11, accuracy=0.757, val_loss=1.56, val_accuracy=0.633, lr=0.1] 86%|████████▋ | 76/88 [26:02<04:01, 20.09s/epoch, loss=1.12, accuracy=0.756, val_loss=1.64, val_accuracy=0.591, lr=0.1] 88%|████████▊ | 77/88 [26:22<03:40, 20.09s/epoch, loss=1.12, accuracy=0.755, val_loss=3.29, val_accuracy=0.218, lr=0.0316] 89%|████████▊ | 78/88 [26:42<03:21, 20.10s/epoch, loss=1.11, accuracy=0.756, val_loss=3.19, val_accuracy=0.434, lr=0.1]    90%|████████▉ | 79/88 [27:02<03:00, 20.02s/epoch, loss=1.11, accuracy=0.758, val_loss=1.69, val_accuracy=0.588, lr=0.1] 91%|█████████ | 80/88 [27:22<02:40, 20.02s/epoch, loss=1.11, accuracy=0.758, val_loss=1.41, val_accuracy=0.66, lr=0.1]  92%|█████████▏| 81/88 [27:42<02:20, 20.02s/epoch, loss=1.12, accuracy=0.756, val_loss=1.52, val_accuracy=0.619, lr=0.1] 93%|█████████▎| 82/88 [28:02<02:00, 20.04s/epoch, loss=0.909, accuracy=0.815, val_loss=0.921, val_accuracy=0.79, lr=0.01] 94%|█████████▍| 83/88 [28:22<01:40, 20.00s/epoch, loss=0.733, accuracy=0.848, val_loss=0.775, val_accuracy=0.824, lr=0.01] 95%|█████████▌| 84/88 [28:42<01:19, 19.99s/epoch, loss=0.649, accuracy=0.856, val_loss=0.801, val_accuracy=0.796, lr=0.01] 97%|█████████▋| 85/88 [29:02<01:00, 20.00s/epoch, loss=0.608, accuracy=0.858, val_loss=0.812, val_accuracy=0.79, lr=0.01]  98%|█████████▊| 86/88 [29:22<00:39, 19.98s/epoch, loss=0.587, accuracy=0.859, val_loss=0.787, val_accuracy=0.794, lr=0.01] 99%|█████████▉| 87/88 [29:42<00:19, 19.91s/epoch, loss=0.574, accuracy=0.861, val_loss=0.694, val_accuracy=0.82, lr=0.01] 100%|██████████| 88/88 [30:01<00:00, 19.91s/epoch, loss=0.569, accuracy=0.861, val_loss=0.98, val_accuracy=0.726, lr=0.01]100%|██████████| 88/88 [30:01<00:00, 20.48s/epoch, loss=0.569, accuracy=0.861, val_loss=0.98, val_accuracy=0.726, lr=0.01]
Using real-time data augmentation.
Test score: 0.9802409410476685
Test accuracy: 0.7257000207901001


* * * Run SGD for ID = 17_9. * * *


2024-03-05 13:32:40.164579: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 13:32:46.046443: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 13:32:46.047599: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-05 13:32:46.084209: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-03-05 13:32:46.084254: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 13:32:46.089799: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 13:32:46.089841: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 13:32:46.093979: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 13:32:46.096621: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 13:32:46.100220: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 13:32:46.103055: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 13:32:46.109238: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 13:32:46.109939: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 13:32:46.110035: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 13:32:47.371164: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-05 13:32:47.371744: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 13:32:47.372232: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-03-05 13:32:47.372263: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 13:32:47.372304: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 13:32:47.372321: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 13:32:47.372336: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 13:32:47.372352: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 13:32:47.372372: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 13:32:47.372387: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 13:32:47.372402: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 13:32:47.372816: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 13:32:47.372848: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 13:32:48.013548: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-05 13:32:48.013594: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-05 13:32:48.013611: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-05 13:32:48.014528: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:02:00.0, compute capability: 6.1)
{'id': '17_09', 'seed': 9, 'out_folder': 'results/epoch_budget', 'batch_size': 128, 'epochs': 88, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'bootstrapping': False, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/88 [00:00<?, ?epoch/s]2024-03-05 13:32:48.877313: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-05 13:32:48.877942: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600020000 Hz
2024-03-05 13:32:50.874311: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 13:32:51.092618: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 13:32:51.867451: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-05 13:32:51.918222: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/88 [01:08<1:39:32, 68.65s/epoch, loss=2.77, accuracy=0.424, val_loss=4.96, val_accuracy=0.21, lr=0.1]  2%|▏         | 2/88 [01:28<57:15, 39.95s/epoch, loss=1.41, accuracy=0.615, val_loss=1.83, val_accuracy=0.498, lr=0.1]   3%|▎         | 3/88 [01:48<43:29, 30.70s/epoch, loss=1.27, accuracy=0.677, val_loss=1.5, val_accuracy=0.59, lr=0.1]    5%|▍         | 4/88 [02:07<36:48, 26.29s/epoch, loss=1.23, accuracy=0.699, val_loss=2.04, val_accuracy=0.471, lr=0.1]  6%|▌         | 5/88 [02:27<32:56, 23.82s/epoch, loss=1.21, accuracy=0.714, val_loss=2.09, val_accuracy=0.466, lr=0.1]  7%|▋         | 6/88 [02:46<30:39, 22.44s/epoch, loss=1.2, accuracy=0.722, val_loss=1.97, val_accuracy=0.454, lr=0.1]   8%|▊         | 7/88 [03:07<29:15, 21.67s/epoch, loss=1.19, accuracy=0.726, val_loss=3.1, val_accuracy=0.353, lr=0.1]  9%|▉         | 8/88 [03:26<27:58, 20.98s/epoch, loss=1.19, accuracy=0.735, val_loss=1.49, val_accuracy=0.63, lr=0.1] 10%|█         | 9/88 [03:46<27:06, 20.59s/epoch, loss=1.18, accuracy=0.736, val_loss=1.58, val_accuracy=0.583, lr=0.1] 11%|█▏        | 10/88 [04:05<26:21, 20.28s/epoch, loss=1.17, accuracy=0.739, val_loss=1.78, val_accuracy=0.532, lr=0.1] 12%|█▎        | 11/88 [04:25<25:51, 20.14s/epoch, loss=1.17, accuracy=0.739, val_loss=1.95, val_accuracy=0.536, lr=0.1] 14%|█▎        | 12/88 [04:45<25:13, 19.91s/epoch, loss=1.17, accuracy=0.742, val_loss=5.95, val_accuracy=0.299, lr=0.1] 15%|█▍        | 13/88 [05:04<24:49, 19.86s/epoch, loss=1.17, accuracy=0.743, val_loss=2.2, val_accuracy=0.481, lr=0.0316] 16%|█▌        | 14/88 [05:24<24:32, 19.90s/epoch, loss=1.16, accuracy=0.745, val_loss=2.1, val_accuracy=0.462, lr=0.1]    17%|█▋        | 15/88 [05:44<24:03, 19.77s/epoch, loss=1.16, accuracy=0.748, val_loss=1.42, val_accuracy=0.657, lr=0.1] 18%|█▊        | 16/88 [06:04<23:45, 19.79s/epoch, loss=1.15, accuracy=0.748, val_loss=2.28, val_accuracy=0.431, lr=0.1] 19%|█▉        | 17/88 [06:24<23:30, 19.87s/epoch, loss=1.15, accuracy=0.749, val_loss=1.77, val_accuracy=0.534, lr=0.1] 20%|██        | 18/88 [06:43<23:06, 19.81s/epoch, loss=1.15, accuracy=0.749, val_loss=1.65, val_accuracy=0.615, lr=0.1] 22%|██▏       | 19/88 [07:03<22:46, 19.81s/epoch, loss=1.15, accuracy=0.751, val_loss=1.38, val_accuracy=0.664, lr=0.1] 23%|██▎       | 20/88 [07:23<22:28, 19.84s/epoch, loss=1.14, accuracy=0.75, val_loss=1.9, val_accuracy=0.513, lr=0.1]   24%|██▍       | 21/88 [07:42<22:01, 19.72s/epoch, loss=1.13, accuracy=0.753, val_loss=1.6, val_accuracy=0.58, lr=0.1] 25%|██▌       | 22/88 [08:02<21:38, 19.68s/epoch, loss=1.13, accuracy=0.753, val_loss=1.76, val_accuracy=0.557, lr=0.1] 26%|██▌       | 23/88 [08:22<21:19, 19.68s/epoch, loss=1.13, accuracy=0.753, val_loss=2.3, val_accuracy=0.404, lr=0.1]  27%|██▋       | 24/88 [08:41<20:57, 19.65s/epoch, loss=1.13, accuracy=0.755, val_loss=1.78, val_accuracy=0.587, lr=0.0316] 28%|██▊       | 25/88 [09:01<20:36, 19.63s/epoch, loss=1.13, accuracy=0.751, val_loss=1.66, val_accuracy=0.557, lr=0.1]    30%|██▉       | 26/88 [09:21<20:18, 19.65s/epoch, loss=1.12, accuracy=0.757, val_loss=3.66, val_accuracy=0.258, lr=0.1] 31%|███       | 27/88 [09:40<19:55, 19.60s/epoch, loss=1.12, accuracy=0.756, val_loss=2.19, val_accuracy=0.477, lr=0.1] 32%|███▏      | 28/88 [10:00<19:34, 19.58s/epoch, loss=1.12, accuracy=0.756, val_loss=1.53, val_accuracy=0.603, lr=0.1] 33%|███▎      | 29/88 [10:19<19:14, 19.57s/epoch, loss=1.11, accuracy=0.758, val_loss=1.8, val_accuracy=0.567, lr=0.0316] 34%|███▍      | 30/88 [10:39<18:55, 19.58s/epoch, loss=1.12, accuracy=0.759, val_loss=2.12, val_accuracy=0.491, lr=0.1]   35%|███▌      | 31/88 [10:58<18:38, 19.63s/epoch, loss=1.13, accuracy=0.756, val_loss=2.04, val_accuracy=0.494, lr=0.1] 36%|███▋      | 32/88 [11:18<18:24, 19.72s/epoch, loss=1.12, accuracy=0.756, val_loss=1.68, val_accuracy=0.595, lr=0.1] 38%|███▊      | 33/88 [11:38<18:03, 19.69s/epoch, loss=1.12, accuracy=0.755, val_loss=1.82, val_accuracy=0.512, lr=0.1] 39%|███▊      | 34/88 [11:58<17:41, 19.66s/epoch, loss=1.12, accuracy=0.757, val_loss=1.66, val_accuracy=0.574, lr=0.0316] 40%|███▉      | 35/88 [12:17<17:24, 19.71s/epoch, loss=1.12, accuracy=0.758, val_loss=1.39, val_accuracy=0.669, lr=0.1]    41%|████      | 36/88 [12:38<17:18, 19.97s/epoch, loss=1.12, accuracy=0.755, val_loss=1.92, val_accuracy=0.555, lr=0.1] 42%|████▏     | 37/88 [12:58<17:05, 20.10s/epoch, loss=1.12, accuracy=0.757, val_loss=1.96, val_accuracy=0.539, lr=0.1] 43%|████▎     | 38/88 [13:19<16:46, 20.12s/epoch, loss=1.11, accuracy=0.758, val_loss=1.61, val_accuracy=0.563, lr=0.1] 44%|████▍     | 39/88 [13:39<16:23, 20.07s/epoch, loss=1.11, accuracy=0.758, val_loss=2.72, val_accuracy=0.312, lr=0.0316] 45%|████▌     | 40/88 [13:59<16:03, 20.08s/epoch, loss=1.11, accuracy=0.76, val_loss=2.03, val_accuracy=0.482, lr=0.1]     47%|████▋     | 41/88 [14:19<15:43, 20.07s/epoch, loss=1.12, accuracy=0.759, val_loss=2.01, val_accuracy=0.516, lr=0.1] 48%|████▊     | 42/88 [14:39<15:22, 20.06s/epoch, loss=1.11, accuracy=0.76, val_loss=1.77, val_accuracy=0.572, lr=0.1]  49%|████▉     | 43/88 [14:59<15:02, 20.06s/epoch, loss=1.12, accuracy=0.76, val_loss=2.5, val_accuracy=0.329, lr=0.1]  50%|█████     | 44/88 [15:19<14:42, 20.05s/epoch, loss=1.11, accuracy=0.762, val_loss=2.54, val_accuracy=0.37, lr=0.0316] 51%|█████     | 45/88 [15:39<14:23, 20.08s/epoch, loss=1.11, accuracy=0.759, val_loss=2.58, val_accuracy=0.45, lr=0.1]    52%|█████▏    | 46/88 [15:59<14:03, 20.08s/epoch, loss=1.11, accuracy=0.759, val_loss=2.02, val_accuracy=0.467, lr=0.1] 53%|█████▎    | 47/88 [16:19<13:42, 20.05s/epoch, loss=1.11, accuracy=0.761, val_loss=2.98, val_accuracy=0.323, lr=0.1] 55%|█████▍    | 48/88 [16:39<13:20, 20.02s/epoch, loss=1.11, accuracy=0.76, val_loss=1.34, val_accuracy=0.669, lr=0.1]  56%|█████▌    | 49/88 [16:59<13:00, 20.00s/epoch, loss=1.11, accuracy=0.76, val_loss=1.92, val_accuracy=0.531, lr=0.1] 57%|█████▋    | 50/88 [17:19<12:41, 20.03s/epoch, loss=1.1, accuracy=0.76, val_loss=1.58, val_accuracy=0.596, lr=0.1]  58%|█████▊    | 51/88 [17:39<12:21, 20.04s/epoch, loss=1.11, accuracy=0.757, val_loss=1.9, val_accuracy=0.528, lr=0.1] 59%|█████▉    | 52/88 [17:59<12:01, 20.03s/epoch, loss=1.11, accuracy=0.761, val_loss=1.97, val_accuracy=0.501, lr=0.1] 60%|██████    | 53/88 [18:19<11:40, 20.01s/epoch, loss=1.11, accuracy=0.76, val_loss=1.92, val_accuracy=0.507, lr=0.0316] 61%|██████▏   | 54/88 [18:39<11:20, 20.03s/epoch, loss=1.11, accuracy=0.761, val_loss=1.72, val_accuracy=0.609, lr=0.1]   62%|██████▎   | 55/88 [18:59<11:02, 20.07s/epoch, loss=1.11, accuracy=0.758, val_loss=2.09, val_accuracy=0.465, lr=0.1] 64%|██████▎   | 56/88 [19:19<10:42, 20.07s/epoch, loss=1.11, accuracy=0.76, val_loss=1.77, val_accuracy=0.566, lr=0.1]  65%|██████▍   | 57/88 [19:40<10:23, 20.12s/epoch, loss=1.11, accuracy=0.759, val_loss=1.56, val_accuracy=0.601, lr=0.1] 66%|██████▌   | 58/88 [20:00<10:03, 20.11s/epoch, loss=1.1, accuracy=0.764, val_loss=2.86, val_accuracy=0.26, lr=0.0316] 67%|██████▋   | 59/88 [20:20<09:42, 20.08s/epoch, loss=1.11, accuracy=0.759, val_loss=3.61, val_accuracy=0.348, lr=0.1]  68%|██████▊   | 60/88 [20:40<09:20, 20.02s/epoch, loss=1.1, accuracy=0.762, val_loss=1.93, val_accuracy=0.462, lr=0.1]  69%|██████▉   | 61/88 [21:00<08:59, 20.00s/epoch, loss=1.11, accuracy=0.762, val_loss=2.3, val_accuracy=0.363, lr=0.1] 70%|███████   | 62/88 [21:20<08:40, 20.04s/epoch, loss=1.1, accuracy=0.761, val_loss=13.5, val_accuracy=0.185, lr=0.1] 72%|███████▏  | 63/88 [21:40<08:20, 20.01s/epoch, loss=1.11, accuracy=0.76, val_loss=2.51, val_accuracy=0.454, lr=0.0316] 73%|███████▎  | 64/88 [22:00<07:59, 19.98s/epoch, loss=1.11, accuracy=0.759, val_loss=2.16, val_accuracy=0.423, lr=0.1]   74%|███████▍  | 65/88 [22:19<07:37, 19.89s/epoch, loss=1.1, accuracy=0.76, val_loss=1.77, val_accuracy=0.513, lr=0.1]   75%|███████▌  | 66/88 [22:39<07:18, 19.94s/epoch, loss=1.11, accuracy=0.763, val_loss=1.81, val_accuracy=0.575, lr=0.1] 76%|███████▌  | 67/88 [22:59<06:57, 19.89s/epoch, loss=1.11, accuracy=0.761, val_loss=1.93, val_accuracy=0.501, lr=0.1] 77%|███████▋  | 68/88 [23:19<06:38, 19.91s/epoch, loss=1.11, accuracy=0.762, val_loss=2.74, val_accuracy=0.404, lr=0.0316] 78%|███████▊  | 69/88 [23:39<06:18, 19.90s/epoch, loss=1.1, accuracy=0.763, val_loss=1.61, val_accuracy=0.566, lr=0.1]     80%|███████▉  | 70/88 [23:59<05:57, 19.84s/epoch, loss=1.1, accuracy=0.763, val_loss=4.38, val_accuracy=0.203, lr=0.1] 81%|████████  | 71/88 [24:18<05:37, 19.83s/epoch, loss=1.11, accuracy=0.761, val_loss=2.42, val_accuracy=0.4, lr=0.1]  82%|████████▏ | 72/88 [24:38<05:15, 19.74s/epoch, loss=1.11, accuracy=0.758, val_loss=2.36, val_accuracy=0.417, lr=0.1] 83%|████████▎ | 73/88 [24:58<04:56, 19.75s/epoch, loss=1.1, accuracy=0.761, val_loss=2.05, val_accuracy=0.45, lr=0.0316] 84%|████████▍ | 74/88 [25:18<04:37, 19.83s/epoch, loss=1.1, accuracy=0.76, val_loss=2.43, val_accuracy=0.46, lr=0.1]     85%|████████▌ | 75/88 [25:38<04:17, 19.83s/epoch, loss=1.11, accuracy=0.76, val_loss=1.85, val_accuracy=0.561, lr=0.1] 86%|████████▋ | 76/88 [25:57<03:58, 19.86s/epoch, loss=1.1, accuracy=0.762, val_loss=1.66, val_accuracy=0.589, lr=0.1] 88%|████████▊ | 77/88 [26:17<03:38, 19.87s/epoch, loss=1.11, accuracy=0.761, val_loss=2.03, val_accuracy=0.506, lr=0.1] 89%|████████▊ | 78/88 [26:37<03:18, 19.90s/epoch, loss=1.11, accuracy=0.76, val_loss=3.9, val_accuracy=0.287, lr=0.0316] 90%|████████▉ | 79/88 [26:57<02:59, 19.94s/epoch, loss=1.1, accuracy=0.762, val_loss=3.55, val_accuracy=0.334, lr=0.1]   91%|█████████ | 80/88 [27:17<02:39, 19.97s/epoch, loss=1.1, accuracy=0.761, val_loss=1.49, val_accuracy=0.618, lr=0.1] 92%|█████████▏| 81/88 [27:37<02:19, 19.97s/epoch, loss=1.11, accuracy=0.761, val_loss=1.6, val_accuracy=0.594, lr=0.1] 93%|█████████▎| 82/88 [27:57<01:59, 19.93s/epoch, loss=0.886, accuracy=0.821, val_loss=0.951, val_accuracy=0.779, lr=0.01] 94%|█████████▍| 83/88 [28:17<01:39, 19.87s/epoch, loss=0.715, accuracy=0.853, val_loss=0.92, val_accuracy=0.769, lr=0.01]  95%|█████████▌| 84/88 [28:37<01:19, 19.94s/epoch, loss=0.638, accuracy=0.859, val_loss=0.777, val_accuracy=0.809, lr=0.01] 97%|█████████▋| 85/88 [28:57<00:59, 19.98s/epoch, loss=0.593, accuracy=0.863, val_loss=0.914, val_accuracy=0.753, lr=0.01] 98%|█████████▊| 86/88 [29:17<00:39, 19.98s/epoch, loss=0.573, accuracy=0.863, val_loss=0.722, val_accuracy=0.816, lr=0.01] 99%|█████████▉| 87/88 [29:37<00:19, 19.94s/epoch, loss=0.567, accuracy=0.864, val_loss=0.754, val_accuracy=0.803, lr=0.01]100%|██████████| 88/88 [29:57<00:00, 19.88s/epoch, loss=0.559, accuracy=0.866, val_loss=0.888, val_accuracy=0.765, lr=0.01]100%|██████████| 88/88 [29:57<00:00, 20.42s/epoch, loss=0.559, accuracy=0.866, val_loss=0.888, val_accuracy=0.765, lr=0.01]
Using real-time data augmentation.
Test score: 0.8881378769874573
Test accuracy: 0.7649000287055969


* * * Run SGD for ID = 17_10. * * *


2024-03-05 14:02:49.581538: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 14:02:52.299707: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 14:02:52.300876: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-05 14:02:52.338172: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-03-05 14:02:52.338215: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 14:02:52.341124: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 14:02:52.341164: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 14:02:52.343465: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 14:02:52.344118: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 14:02:52.346671: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 14:02:52.348032: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 14:02:52.352931: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 14:02:52.353553: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 14:02:52.353646: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 14:02:53.598395: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-05 14:02:53.599456: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 14:02:53.600204: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-03-05 14:02:53.600234: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 14:02:53.600272: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 14:02:53.600288: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 14:02:53.600302: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 14:02:53.600318: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 14:02:53.600342: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 14:02:53.600357: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 14:02:53.600372: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 14:02:53.600797: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 14:02:53.600841: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 14:02:54.272843: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-05 14:02:54.272889: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-05 14:02:54.272898: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-05 14:02:54.274508: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:02:00.0, compute capability: 6.1)
{'id': '17_10', 'seed': 10, 'out_folder': 'results/epoch_budget', 'batch_size': 128, 'epochs': 88, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'bootstrapping': False, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/88 [00:00<?, ?epoch/s]2024-03-05 14:02:55.138006: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-05 14:02:55.138635: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600020000 Hz
2024-03-05 14:02:57.146783: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 14:02:57.386180: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 14:02:58.255453: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-05 14:02:58.328428: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/88 [01:06<1:35:51, 66.11s/epoch, loss=3.2, accuracy=0.316, val_loss=2.39, val_accuracy=0.273, lr=0.1]  2%|▏         | 2/88 [01:27<56:44, 39.59s/epoch, loss=1.56, accuracy=0.532, val_loss=2.62, val_accuracy=0.301, lr=0.1]   3%|▎         | 3/88 [01:47<43:53, 30.98s/epoch, loss=1.33, accuracy=0.643, val_loss=2.69, val_accuracy=0.336, lr=0.1]  5%|▍         | 4/88 [02:08<37:39, 26.90s/epoch, loss=1.27, accuracy=0.687, val_loss=1.58, val_accuracy=0.598, lr=0.1]  6%|▌         | 5/88 [02:29<34:04, 24.63s/epoch, loss=1.25, accuracy=0.703, val_loss=2.16, val_accuracy=0.482, lr=0.1]  7%|▋         | 6/88 [02:49<31:46, 23.25s/epoch, loss=1.23, accuracy=0.715, val_loss=2.93, val_accuracy=0.375, lr=0.1]  8%|▊         | 7/88 [03:10<30:13, 22.39s/epoch, loss=1.21, accuracy=0.72, val_loss=1.69, val_accuracy=0.566, lr=0.1]   9%|▉         | 8/88 [03:30<29:06, 21.83s/epoch, loss=1.21, accuracy=0.724, val_loss=1.49, val_accuracy=0.622, lr=0.1] 10%|█         | 9/88 [03:51<28:14, 21.44s/epoch, loss=1.19, accuracy=0.73, val_loss=1.65, val_accuracy=0.59, lr=0.1]   11%|█▏        | 10/88 [04:12<27:31, 21.17s/epoch, loss=1.19, accuracy=0.729, val_loss=1.93, val_accuracy=0.529, lr=0.1] 12%|█▎        | 11/88 [04:32<26:58, 21.02s/epoch, loss=1.19, accuracy=0.735, val_loss=2.7, val_accuracy=0.327, lr=0.1]  14%|█▎        | 12/88 [04:53<26:30, 20.92s/epoch, loss=1.19, accuracy=0.733, val_loss=1.64, val_accuracy=0.584, lr=0.1] 15%|█▍        | 13/88 [05:14<26:01, 20.83s/epoch, loss=1.19, accuracy=0.738, val_loss=5.14, val_accuracy=0.215, lr=0.0316] 16%|█▌        | 14/88 [05:34<25:32, 20.71s/epoch, loss=1.18, accuracy=0.741, val_loss=1.74, val_accuracy=0.559, lr=0.1]    17%|█▋        | 15/88 [05:55<25:09, 20.68s/epoch, loss=1.17, accuracy=0.742, val_loss=1.66, val_accuracy=0.569, lr=0.1] 18%|█▊        | 16/88 [06:15<24:45, 20.63s/epoch, loss=1.17, accuracy=0.743, val_loss=2.39, val_accuracy=0.434, lr=0.1] 19%|█▉        | 17/88 [06:36<24:25, 20.64s/epoch, loss=1.18, accuracy=0.743, val_loss=1.89, val_accuracy=0.57, lr=0.1]  20%|██        | 18/88 [06:56<24:00, 20.58s/epoch, loss=1.17, accuracy=0.743, val_loss=2.17, val_accuracy=0.468, lr=0.0316] 22%|██▏       | 19/88 [07:17<23:38, 20.55s/epoch, loss=1.16, accuracy=0.747, val_loss=2.56, val_accuracy=0.44, lr=0.1]     23%|██▎       | 20/88 [07:37<23:14, 20.51s/epoch, loss=1.17, accuracy=0.746, val_loss=2.02, val_accuracy=0.459, lr=0.1] 24%|██▍       | 21/88 [07:58<22:53, 20.50s/epoch, loss=1.16, accuracy=0.746, val_loss=2.35, val_accuracy=0.368, lr=0.1] 25%|██▌       | 22/88 [08:18<22:35, 20.53s/epoch, loss=1.17, accuracy=0.747, val_loss=2.16, val_accuracy=0.503, lr=0.1] 26%|██▌       | 23/88 [08:39<22:17, 20.57s/epoch, loss=1.16, accuracy=0.747, val_loss=1.9, val_accuracy=0.469, lr=0.0316] 27%|██▋       | 24/88 [08:59<21:53, 20.52s/epoch, loss=1.16, accuracy=0.748, val_loss=1.88, val_accuracy=0.501, lr=0.1]   28%|██▊       | 25/88 [09:20<21:31, 20.50s/epoch, loss=1.16, accuracy=0.751, val_loss=2.06, val_accuracy=0.447, lr=0.1] 30%|██▉       | 26/88 [09:40<21:06, 20.43s/epoch, loss=1.16, accuracy=0.749, val_loss=1.79, val_accuracy=0.556, lr=0.1] 31%|███       | 27/88 [10:01<20:49, 20.49s/epoch, loss=1.15, accuracy=0.751, val_loss=2.22, val_accuracy=0.438, lr=0.1] 32%|███▏      | 28/88 [10:21<20:32, 20.54s/epoch, loss=1.15, accuracy=0.751, val_loss=1.91, val_accuracy=0.558, lr=0.0316] 33%|███▎      | 29/88 [10:42<20:09, 20.50s/epoch, loss=1.15, accuracy=0.754, val_loss=1.6, val_accuracy=0.628, lr=0.1]     34%|███▍      | 30/88 [11:02<19:47, 20.47s/epoch, loss=1.16, accuracy=0.751, val_loss=2.3, val_accuracy=0.459, lr=0.1] 35%|███▌      | 31/88 [11:23<19:27, 20.48s/epoch, loss=1.15, accuracy=0.751, val_loss=1.94, val_accuracy=0.541, lr=0.1] 36%|███▋      | 32/88 [11:43<19:07, 20.48s/epoch, loss=1.15, accuracy=0.749, val_loss=1.47, val_accuracy=0.655, lr=0.1] 38%|███▊      | 33/88 [12:04<18:45, 20.46s/epoch, loss=1.15, accuracy=0.755, val_loss=1.93, val_accuracy=0.564, lr=0.1] 39%|███▊      | 34/88 [12:24<18:23, 20.43s/epoch, loss=1.15, accuracy=0.752, val_loss=1.57, val_accuracy=0.618, lr=0.1] 40%|███▉      | 35/88 [12:44<18:00, 20.39s/epoch, loss=1.14, accuracy=0.756, val_loss=2.82, val_accuracy=0.367, lr=0.1] 41%|████      | 36/88 [13:05<17:39, 20.37s/epoch, loss=1.14, accuracy=0.756, val_loss=1.99, val_accuracy=0.503, lr=0.1] 42%|████▏     | 37/88 [13:25<17:18, 20.36s/epoch, loss=1.14, accuracy=0.754, val_loss=3.54, val_accuracy=0.245, lr=0.0316] 43%|████▎     | 38/88 [13:45<16:57, 20.35s/epoch, loss=1.14, accuracy=0.755, val_loss=1.82, val_accuracy=0.521, lr=0.1]    44%|████▍     | 39/88 [14:05<16:36, 20.33s/epoch, loss=1.14, accuracy=0.755, val_loss=2.03, val_accuracy=0.438, lr=0.1] 45%|████▌     | 40/88 [14:26<16:17, 20.37s/epoch, loss=1.13, accuracy=0.756, val_loss=1.78, val_accuracy=0.552, lr=0.1] 47%|████▋     | 41/88 [14:46<15:57, 20.37s/epoch, loss=1.14, accuracy=0.753, val_loss=1.57, val_accuracy=0.596, lr=0.1] 48%|████▊     | 42/88 [15:07<15:37, 20.37s/epoch, loss=1.14, accuracy=0.753, val_loss=1.79, val_accuracy=0.579, lr=0.0316] 49%|████▉     | 43/88 [15:27<15:17, 20.39s/epoch, loss=1.14, accuracy=0.755, val_loss=1.69, val_accuracy=0.558, lr=0.1]    50%|█████     | 44/88 [15:47<14:56, 20.37s/epoch, loss=1.13, accuracy=0.758, val_loss=3.31, val_accuracy=0.423, lr=0.1] 51%|█████     | 45/88 [16:08<14:33, 20.32s/epoch, loss=1.13, accuracy=0.758, val_loss=1.71, val_accuracy=0.57, lr=0.1]  52%|█████▏    | 46/88 [16:28<14:12, 20.31s/epoch, loss=1.14, accuracy=0.754, val_loss=1.82, val_accuracy=0.527, lr=0.1] 53%|█████▎    | 47/88 [16:48<13:50, 20.26s/epoch, loss=1.13, accuracy=0.757, val_loss=2.24, val_accuracy=0.401, lr=0.0316] 55%|█████▍    | 48/88 [17:08<13:31, 20.29s/epoch, loss=1.13, accuracy=0.757, val_loss=2.73, val_accuracy=0.403, lr=0.1]    56%|█████▌    | 49/88 [17:29<13:09, 20.26s/epoch, loss=1.13, accuracy=0.759, val_loss=2.21, val_accuracy=0.499, lr=0.1] 57%|█████▋    | 50/88 [17:49<12:50, 20.28s/epoch, loss=1.12, accuracy=0.759, val_loss=1.82, val_accuracy=0.574, lr=0.1] 58%|█████▊    | 51/88 [18:09<12:32, 20.33s/epoch, loss=1.13, accuracy=0.755, val_loss=1.62, val_accuracy=0.571, lr=0.1] 59%|█████▉    | 52/88 [18:30<12:13, 20.38s/epoch, loss=1.13, accuracy=0.756, val_loss=2.39, val_accuracy=0.415, lr=0.0316] 60%|██████    | 53/88 [18:50<11:55, 20.46s/epoch, loss=1.13, accuracy=0.754, val_loss=3.6, val_accuracy=0.331, lr=0.1]     61%|██████▏   | 54/88 [19:11<11:35, 20.45s/epoch, loss=1.13, accuracy=0.757, val_loss=1.91, val_accuracy=0.535, lr=0.1] 62%|██████▎   | 55/88 [19:32<11:16, 20.49s/epoch, loss=1.12, accuracy=0.761, val_loss=1.54, val_accuracy=0.622, lr=0.1] 64%|██████▎   | 56/88 [19:52<10:54, 20.45s/epoch, loss=1.13, accuracy=0.757, val_loss=1.88, val_accuracy=0.529, lr=0.1] 65%|██████▍   | 57/88 [20:12<10:34, 20.45s/epoch, loss=1.12, accuracy=0.757, val_loss=3.84, val_accuracy=0.21, lr=0.0316] 66%|██████▌   | 58/88 [20:33<10:13, 20.45s/epoch, loss=1.12, accuracy=0.757, val_loss=1.58, val_accuracy=0.617, lr=0.1]   67%|██████▋   | 59/88 [20:53<09:53, 20.47s/epoch, loss=1.12, accuracy=0.759, val_loss=2.81, val_accuracy=0.436, lr=0.1] 68%|██████▊   | 60/88 [21:14<09:34, 20.52s/epoch, loss=1.12, accuracy=0.759, val_loss=2.49, val_accuracy=0.402, lr=0.1] 69%|██████▉   | 61/88 [21:34<09:13, 20.50s/epoch, loss=1.12, accuracy=0.759, val_loss=1.9, val_accuracy=0.5, lr=0.1]    70%|███████   | 62/88 [21:55<08:52, 20.48s/epoch, loss=1.12, accuracy=0.758, val_loss=2.05, val_accuracy=0.463, lr=0.0316] 72%|███████▏  | 63/88 [22:15<08:31, 20.44s/epoch, loss=1.13, accuracy=0.757, val_loss=1.51, val_accuracy=0.624, lr=0.1]    73%|███████▎  | 64/88 [22:36<08:11, 20.48s/epoch, loss=1.12, accuracy=0.761, val_loss=2.22, val_accuracy=0.497, lr=0.1] 74%|███████▍  | 65/88 [22:56<07:50, 20.47s/epoch, loss=1.13, accuracy=0.759, val_loss=1.81, val_accuracy=0.543, lr=0.1] 75%|███████▌  | 66/88 [23:17<07:29, 20.45s/epoch, loss=1.13, accuracy=0.756, val_loss=3.65, val_accuracy=0.334, lr=0.1] 76%|███████▌  | 67/88 [23:37<07:09, 20.44s/epoch, loss=1.12, accuracy=0.761, val_loss=3.42, val_accuracy=0.347, lr=0.0316] 77%|███████▋  | 68/88 [23:57<06:48, 20.43s/epoch, loss=1.13, accuracy=0.759, val_loss=2.34, val_accuracy=0.482, lr=0.1]    78%|███████▊  | 69/88 [24:18<06:27, 20.40s/epoch, loss=1.12, accuracy=0.761, val_loss=1.71, val_accuracy=0.553, lr=0.1] 80%|███████▉  | 70/88 [24:38<06:08, 20.47s/epoch, loss=1.11, accuracy=0.758, val_loss=3.03, val_accuracy=0.246, lr=0.1] 81%|████████  | 71/88 [24:59<05:47, 20.44s/epoch, loss=1.12, accuracy=0.76, val_loss=2.42, val_accuracy=0.469, lr=0.1]  82%|████████▏ | 72/88 [25:19<05:27, 20.44s/epoch, loss=1.12, accuracy=0.76, val_loss=2.55, val_accuracy=0.445, lr=0.0316] 83%|████████▎ | 73/88 [25:39<05:05, 20.39s/epoch, loss=1.12, accuracy=0.758, val_loss=5.91, val_accuracy=0.219, lr=0.1]   84%|████████▍ | 74/88 [26:00<04:44, 20.36s/epoch, loss=1.13, accuracy=0.761, val_loss=1.42, val_accuracy=0.656, lr=0.1] 85%|████████▌ | 75/88 [26:20<04:25, 20.44s/epoch, loss=1.13, accuracy=0.757, val_loss=4.76, val_accuracy=0.372, lr=0.1] 86%|████████▋ | 76/88 [26:41<04:04, 20.38s/epoch, loss=1.12, accuracy=0.76, val_loss=1.53, val_accuracy=0.616, lr=0.1]  88%|████████▊ | 77/88 [27:01<03:44, 20.39s/epoch, loss=1.12, accuracy=0.757, val_loss=1.61, val_accuracy=0.615, lr=0.1] 89%|████████▊ | 78/88 [27:21<03:23, 20.40s/epoch, loss=1.13, accuracy=0.758, val_loss=2.97, val_accuracy=0.368, lr=0.1] 90%|████████▉ | 79/88 [27:42<03:03, 20.43s/epoch, loss=1.12, accuracy=0.76, val_loss=2.76, val_accuracy=0.401, lr=0.0316] 91%|█████████ | 80/88 [28:02<02:43, 20.42s/epoch, loss=1.12, accuracy=0.759, val_loss=1.7, val_accuracy=0.584, lr=0.1]    92%|█████████▏| 81/88 [28:23<02:22, 20.42s/epoch, loss=1.12, accuracy=0.759, val_loss=1.54, val_accuracy=0.608, lr=0.1] 93%|█████████▎| 82/88 [28:43<02:02, 20.43s/epoch, loss=0.908, accuracy=0.819, val_loss=0.919, val_accuracy=0.801, lr=0.01] 94%|█████████▍| 83/88 [29:04<01:41, 20.40s/epoch, loss=0.727, accuracy=0.85, val_loss=0.773, val_accuracy=0.824, lr=0.01]  95%|█████████▌| 84/88 [29:24<01:21, 20.38s/epoch, loss=0.646, accuracy=0.857, val_loss=0.696, val_accuracy=0.835, lr=0.01] 97%|█████████▋| 85/88 [29:44<01:01, 20.35s/epoch, loss=0.602, accuracy=0.863, val_loss=0.694, val_accuracy=0.824, lr=0.01] 98%|█████████▊| 86/88 [30:04<00:40, 20.33s/epoch, loss=0.579, accuracy=0.864, val_loss=0.743, val_accuracy=0.811, lr=0.01] 99%|█████████▉| 87/88 [30:25<00:20, 20.35s/epoch, loss=0.568, accuracy=0.863, val_loss=0.723, val_accuracy=0.812, lr=0.01]100%|██████████| 88/88 [30:45<00:00, 20.33s/epoch, loss=0.564, accuracy=0.864, val_loss=0.66, val_accuracy=0.833, lr=0.01] 100%|██████████| 88/88 [30:45<00:00, 20.97s/epoch, loss=0.564, accuracy=0.864, val_loss=0.66, val_accuracy=0.833, lr=0.01]
Using real-time data augmentation.
Test score: 0.6597326993942261
Test accuracy: 0.8331000208854675


* * * Run SGD for ID = 17_11. * * *


2024-03-05 14:33:46.094244: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 14:33:59.489369: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 14:33:59.490486: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-05 14:33:59.530443: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-03-05 14:33:59.530486: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 14:33:59.536750: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 14:33:59.536794: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 14:33:59.543189: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 14:33:59.545751: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 14:33:59.549857: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 14:33:59.552657: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 14:33:59.558909: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 14:33:59.559546: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 14:33:59.559631: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 14:34:00.831035: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-05 14:34:00.831577: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 14:34:00.832059: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-03-05 14:34:00.832092: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 14:34:00.832126: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 14:34:00.832141: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 14:34:00.832156: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 14:34:00.832170: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 14:34:00.832184: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 14:34:00.832198: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 14:34:00.832212: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 14:34:00.832647: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 14:34:00.832686: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 14:34:01.524627: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-05 14:34:01.524689: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-05 14:34:01.524697: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-05 14:34:01.526753: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:02:00.0, compute capability: 6.1)
{'id': '17_11', 'seed': 11, 'out_folder': 'results/epoch_budget', 'batch_size': 128, 'epochs': 88, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'bootstrapping': False, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/88 [00:00<?, ?epoch/s]2024-03-05 14:34:02.400086: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-05 14:34:02.400625: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600020000 Hz
2024-03-05 14:34:04.416248: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 14:34:04.644805: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 14:34:05.429103: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-05 14:34:05.484518: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/88 [01:03<1:31:45, 63.28s/epoch, loss=2.74, accuracy=0.426, val_loss=2.57, val_accuracy=0.3, lr=0.1]  2%|▏         | 2/88 [01:23<54:25, 37.97s/epoch, loss=1.45, accuracy=0.607, val_loss=2.91, val_accuracy=0.433, lr=0.1]  3%|▎         | 3/88 [01:43<42:18, 29.86s/epoch, loss=1.3, accuracy=0.672, val_loss=2.24, val_accuracy=0.428, lr=0.1]   5%|▍         | 4/88 [02:03<36:27, 26.05s/epoch, loss=1.26, accuracy=0.702, val_loss=2.12, val_accuracy=0.44, lr=0.1]  6%|▌         | 5/88 [02:23<32:50, 23.75s/epoch, loss=1.23, accuracy=0.712, val_loss=1.72, val_accuracy=0.539, lr=0.1]  7%|▋         | 6/88 [02:43<30:42, 22.46s/epoch, loss=1.22, accuracy=0.723, val_loss=1.79, val_accuracy=0.52, lr=0.1]   8%|▊         | 7/88 [03:03<29:15, 21.67s/epoch, loss=1.22, accuracy=0.727, val_loss=1.93, val_accuracy=0.501, lr=0.1]  9%|▉         | 8/88 [03:23<28:10, 21.13s/epoch, loss=1.21, accuracy=0.73, val_loss=1.83, val_accuracy=0.513, lr=0.1]  10%|█         | 9/88 [03:43<27:23, 20.80s/epoch, loss=1.21, accuracy=0.735, val_loss=1.88, val_accuracy=0.553, lr=0.1] 11%|█▏        | 10/88 [04:03<26:40, 20.52s/epoch, loss=1.21, accuracy=0.735, val_loss=2.15, val_accuracy=0.476, lr=0.0316] 12%|█▎        | 11/88 [04:23<26:10, 20.39s/epoch, loss=1.2, accuracy=0.738, val_loss=2.38, val_accuracy=0.448, lr=0.1]     14%|█▎        | 12/88 [04:43<25:40, 20.27s/epoch, loss=1.2, accuracy=0.737, val_loss=1.52, val_accuracy=0.621, lr=0.1] 15%|█▍        | 13/88 [05:03<25:11, 20.15s/epoch, loss=1.2, accuracy=0.739, val_loss=2.49, val_accuracy=0.425, lr=0.1] 16%|█▌        | 14/88 [05:23<24:46, 20.09s/epoch, loss=1.19, accuracy=0.742, val_loss=2.07, val_accuracy=0.516, lr=0.1] 17%|█▋        | 15/88 [05:43<24:20, 20.00s/epoch, loss=1.19, accuracy=0.742, val_loss=2.92, val_accuracy=0.278, lr=0.1] 18%|█▊        | 16/88 [06:03<24:00, 20.01s/epoch, loss=1.18, accuracy=0.745, val_loss=1.81, val_accuracy=0.546, lr=0.1] 19%|█▉        | 17/88 [06:23<23:36, 19.95s/epoch, loss=1.17, accuracy=0.747, val_loss=2.69, val_accuracy=0.411, lr=0.0316] 20%|██        | 18/88 [06:43<23:17, 19.97s/epoch, loss=1.18, accuracy=0.746, val_loss=2.07, val_accuracy=0.498, lr=0.1]    22%|██▏       | 19/88 [07:03<22:59, 19.99s/epoch, loss=1.17, accuracy=0.747, val_loss=3.58, val_accuracy=0.29, lr=0.1]  23%|██▎       | 20/88 [07:23<22:39, 19.99s/epoch, loss=1.17, accuracy=0.749, val_loss=1.69, val_accuracy=0.578, lr=0.1] 24%|██▍       | 21/88 [07:43<22:18, 19.98s/epoch, loss=1.17, accuracy=0.747, val_loss=2.43, val_accuracy=0.414, lr=0.1] 25%|██▌       | 22/88 [08:03<22:01, 20.02s/epoch, loss=1.17, accuracy=0.749, val_loss=2.21, val_accuracy=0.439, lr=0.0316] 26%|██▌       | 23/88 [08:23<21:42, 20.03s/epoch, loss=1.17, accuracy=0.748, val_loss=1.82, val_accuracy=0.521, lr=0.1]    27%|██▋       | 24/88 [08:43<21:22, 20.03s/epoch, loss=1.15, accuracy=0.751, val_loss=2.55, val_accuracy=0.463, lr=0.1] 28%|██▊       | 25/88 [09:03<21:07, 20.12s/epoch, loss=1.16, accuracy=0.749, val_loss=2.54, val_accuracy=0.44, lr=0.1]  30%|██▉       | 26/88 [09:23<20:45, 20.09s/epoch, loss=1.16, accuracy=0.752, val_loss=2.08, val_accuracy=0.499, lr=0.1] 31%|███       | 27/88 [09:43<20:24, 20.07s/epoch, loss=1.15, accuracy=0.753, val_loss=1.59, val_accuracy=0.59, lr=0.0316] 32%|███▏      | 28/88 [10:03<20:03, 20.05s/epoch, loss=1.15, accuracy=0.751, val_loss=2.02, val_accuracy=0.452, lr=0.1]   33%|███▎      | 29/88 [10:23<19:37, 19.96s/epoch, loss=1.15, accuracy=0.753, val_loss=1.84, val_accuracy=0.571, lr=0.1] 34%|███▍      | 30/88 [10:43<19:19, 19.99s/epoch, loss=1.15, accuracy=0.749, val_loss=2.33, val_accuracy=0.499, lr=0.1] 35%|███▌      | 31/88 [11:03<18:56, 19.94s/epoch, loss=1.14, accuracy=0.754, val_loss=2.15, val_accuracy=0.44, lr=0.1]  36%|███▋      | 32/88 [11:23<18:38, 19.98s/epoch, loss=1.15, accuracy=0.754, val_loss=1.67, val_accuracy=0.567, lr=0.0316] 38%|███▊      | 33/88 [11:43<18:17, 19.95s/epoch, loss=1.14, accuracy=0.755, val_loss=1.63, val_accuracy=0.602, lr=0.1]    39%|███▊      | 34/88 [12:03<17:56, 19.93s/epoch, loss=1.14, accuracy=0.753, val_loss=1.78, val_accuracy=0.496, lr=0.1] 40%|███▉      | 35/88 [12:23<17:36, 19.93s/epoch, loss=1.13, accuracy=0.756, val_loss=2.16, val_accuracy=0.414, lr=0.1] 41%|████      | 36/88 [12:43<17:16, 19.94s/epoch, loss=1.14, accuracy=0.756, val_loss=2.77, val_accuracy=0.423, lr=0.1] 42%|████▏     | 37/88 [13:03<16:57, 19.95s/epoch, loss=1.13, accuracy=0.756, val_loss=3.41, val_accuracy=0.375, lr=0.0316] 43%|████▎     | 38/88 [13:23<16:39, 19.98s/epoch, loss=1.13, accuracy=0.756, val_loss=4.06, val_accuracy=0.338, lr=0.1]    44%|████▍     | 39/88 [13:43<16:21, 20.03s/epoch, loss=1.14, accuracy=0.754, val_loss=1.77, val_accuracy=0.558, lr=0.1] 45%|████▌     | 40/88 [14:03<16:01, 20.03s/epoch, loss=1.13, accuracy=0.757, val_loss=5.8, val_accuracy=0.353, lr=0.1]  47%|████▋     | 41/88 [14:23<15:39, 20.00s/epoch, loss=1.13, accuracy=0.755, val_loss=1.46, val_accuracy=0.645, lr=0.1] 48%|████▊     | 42/88 [14:43<15:20, 20.02s/epoch, loss=1.12, accuracy=0.757, val_loss=2.45, val_accuracy=0.373, lr=0.1] 49%|████▉     | 43/88 [15:03<14:59, 19.98s/epoch, loss=1.12, accuracy=0.758, val_loss=2.66, val_accuracy=0.374, lr=0.1] 50%|█████     | 44/88 [15:23<14:38, 19.96s/epoch, loss=1.13, accuracy=0.761, val_loss=1.46, val_accuracy=0.636, lr=0.1] 51%|█████     | 45/88 [15:43<14:21, 20.04s/epoch, loss=1.12, accuracy=0.758, val_loss=2.73, val_accuracy=0.324, lr=0.1] 52%|█████▏    | 46/88 [16:03<14:01, 20.03s/epoch, loss=1.12, accuracy=0.759, val_loss=2.11, val_accuracy=0.529, lr=0.1] 53%|█████▎    | 47/88 [16:23<13:41, 20.03s/epoch, loss=1.12, accuracy=0.758, val_loss=2.35, val_accuracy=0.354, lr=0.1] 55%|█████▍    | 48/88 [16:43<13:20, 20.02s/epoch, loss=1.12, accuracy=0.757, val_loss=1.84, val_accuracy=0.548, lr=0.1] 56%|█████▌    | 49/88 [17:03<13:00, 20.02s/epoch, loss=1.12, accuracy=0.756, val_loss=3.31, val_accuracy=0.38, lr=0.0316] 57%|█████▋    | 50/88 [17:23<12:42, 20.05s/epoch, loss=1.12, accuracy=0.758, val_loss=2.17, val_accuracy=0.438, lr=0.1]   58%|█████▊    | 51/88 [17:43<12:21, 20.04s/epoch, loss=1.12, accuracy=0.757, val_loss=1.8, val_accuracy=0.548, lr=0.1]  59%|█████▉    | 52/88 [18:03<12:00, 20.01s/epoch, loss=1.12, accuracy=0.76, val_loss=2.12, val_accuracy=0.506, lr=0.1] 60%|██████    | 53/88 [18:23<11:40, 20.01s/epoch, loss=1.12, accuracy=0.761, val_loss=2.24, val_accuracy=0.465, lr=0.1] 61%|██████▏   | 54/88 [18:43<11:21, 20.05s/epoch, loss=1.12, accuracy=0.758, val_loss=1.84, val_accuracy=0.55, lr=0.0316] 62%|██████▎   | 55/88 [19:03<11:01, 20.04s/epoch, loss=1.12, accuracy=0.757, val_loss=2.58, val_accuracy=0.329, lr=0.1]   64%|██████▎   | 56/88 [19:23<10:39, 19.99s/epoch, loss=1.12, accuracy=0.76, val_loss=1.71, val_accuracy=0.585, lr=0.1]  65%|██████▍   | 57/88 [19:43<10:18, 19.96s/epoch, loss=1.12, accuracy=0.758, val_loss=1.94, val_accuracy=0.468, lr=0.1] 66%|██████▌   | 58/88 [20:03<09:59, 19.98s/epoch, loss=1.12, accuracy=0.759, val_loss=2.53, val_accuracy=0.39, lr=0.1]  67%|██████▋   | 59/88 [20:23<09:38, 19.94s/epoch, loss=1.12, accuracy=0.762, val_loss=2.62, val_accuracy=0.312, lr=0.0316] 68%|██████▊   | 60/88 [20:43<09:18, 19.94s/epoch, loss=1.12, accuracy=0.758, val_loss=1.91, val_accuracy=0.511, lr=0.1]    69%|██████▉   | 61/88 [21:02<08:57, 19.89s/epoch, loss=1.12, accuracy=0.757, val_loss=2.43, val_accuracy=0.427, lr=0.1] 70%|███████   | 62/88 [21:22<08:37, 19.89s/epoch, loss=1.11, accuracy=0.762, val_loss=1.61, val_accuracy=0.587, lr=0.1] 72%|███████▏  | 63/88 [21:42<08:17, 19.90s/epoch, loss=1.12, accuracy=0.758, val_loss=2.22, val_accuracy=0.422, lr=0.1] 73%|███████▎  | 64/88 [22:02<07:56, 19.87s/epoch, loss=1.11, accuracy=0.758, val_loss=2, val_accuracy=0.56, lr=0.0316]  74%|███████▍  | 65/88 [22:22<07:35, 19.82s/epoch, loss=1.11, accuracy=0.761, val_loss=1.66, val_accuracy=0.565, lr=0.1] 75%|███████▌  | 66/88 [22:42<07:16, 19.82s/epoch, loss=1.11, accuracy=0.762, val_loss=2.48, val_accuracy=0.425, lr=0.1] 76%|███████▌  | 67/88 [23:01<06:55, 19.79s/epoch, loss=1.11, accuracy=0.761, val_loss=1.67, val_accuracy=0.577, lr=0.1] 77%|███████▋  | 68/88 [23:21<06:36, 19.81s/epoch, loss=1.12, accuracy=0.758, val_loss=3.31, val_accuracy=0.329, lr=0.1] 78%|███████▊  | 69/88 [23:41<06:15, 19.75s/epoch, loss=1.11, accuracy=0.759, val_loss=10.5, val_accuracy=0.136, lr=0.0316] 80%|███████▉  | 70/88 [24:00<05:55, 19.74s/epoch, loss=1.11, accuracy=0.758, val_loss=2, val_accuracy=0.505, lr=0.1]       81%|████████  | 71/88 [24:20<05:34, 19.69s/epoch, loss=1.11, accuracy=0.761, val_loss=1.54, val_accuracy=0.625, lr=0.1] 82%|████████▏ | 72/88 [24:40<05:14, 19.68s/epoch, loss=1.11, accuracy=0.76, val_loss=1.63, val_accuracy=0.583, lr=0.1]  83%|████████▎ | 73/88 [24:59<04:54, 19.66s/epoch, loss=1.12, accuracy=0.759, val_loss=2.24, val_accuracy=0.403, lr=0.1] 84%|████████▍ | 74/88 [25:19<04:35, 19.66s/epoch, loss=1.11, accuracy=0.759, val_loss=2.5, val_accuracy=0.358, lr=0.0316] 85%|████████▌ | 75/88 [25:39<04:16, 19.74s/epoch, loss=1.11, accuracy=0.76, val_loss=2.55, val_accuracy=0.33, lr=0.1]     86%|████████▋ | 76/88 [25:59<03:56, 19.75s/epoch, loss=1.13, accuracy=0.76, val_loss=1.73, val_accuracy=0.558, lr=0.1] 88%|████████▊ | 77/88 [26:19<03:37, 19.77s/epoch, loss=1.11, accuracy=0.761, val_loss=2.42, val_accuracy=0.367, lr=0.1] 89%|████████▊ | 78/88 [26:38<03:17, 19.78s/epoch, loss=1.11, accuracy=0.759, val_loss=7.99, val_accuracy=0.148, lr=0.1] 90%|████████▉ | 79/88 [26:58<02:58, 19.80s/epoch, loss=1.11, accuracy=0.76, val_loss=3.84, val_accuracy=0.238, lr=0.0316] 91%|█████████ | 80/88 [27:18<02:38, 19.81s/epoch, loss=1.11, accuracy=0.761, val_loss=1.64, val_accuracy=0.585, lr=0.1]   92%|█████████▏| 81/88 [27:38<02:18, 19.79s/epoch, loss=1.11, accuracy=0.761, val_loss=2.51, val_accuracy=0.44, lr=0.1]  93%|█████████▎| 82/88 [27:58<01:58, 19.82s/epoch, loss=0.898, accuracy=0.818, val_loss=0.927, val_accuracy=0.795, lr=0.01] 94%|█████████▍| 83/88 [28:17<01:38, 19.76s/epoch, loss=0.721, accuracy=0.85, val_loss=0.781, val_accuracy=0.819, lr=0.01]  95%|█████████▌| 84/88 [28:37<01:19, 19.79s/epoch, loss=0.64, accuracy=0.859, val_loss=0.886, val_accuracy=0.782, lr=0.01] 97%|█████████▋| 85/88 [28:57<00:59, 19.75s/epoch, loss=0.597, accuracy=0.862, val_loss=0.739, val_accuracy=0.815, lr=0.01] 98%|█████████▊| 86/88 [29:16<00:39, 19.74s/epoch, loss=0.578, accuracy=0.864, val_loss=0.747, val_accuracy=0.803, lr=0.01] 99%|█████████▉| 87/88 [29:36<00:19, 19.78s/epoch, loss=0.566, accuracy=0.864, val_loss=0.722, val_accuracy=0.809, lr=0.01]100%|██████████| 88/88 [29:56<00:00, 19.77s/epoch, loss=0.559, accuracy=0.865, val_loss=0.747, val_accuracy=0.804, lr=0.01]100%|██████████| 88/88 [29:56<00:00, 20.42s/epoch, loss=0.559, accuracy=0.865, val_loss=0.747, val_accuracy=0.804, lr=0.01]
Using real-time data augmentation.
Test score: 0.7469351887702942
Test accuracy: 0.8041999936103821


* * * Run SGD for ID = 17_12. * * *


2024-03-05 15:04:02.749618: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 15:04:05.320063: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 15:04:05.321292: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-05 15:04:05.361615: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-03-05 15:04:05.361658: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 15:04:05.364535: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 15:04:05.364574: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 15:04:05.366811: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 15:04:05.367989: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 15:04:05.370483: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 15:04:05.371865: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 15:04:05.376468: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 15:04:05.379512: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 15:04:05.379608: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 15:04:06.679059: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-05 15:04:06.680140: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 15:04:06.680877: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-03-05 15:04:06.680908: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 15:04:06.680950: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 15:04:06.680998: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 15:04:06.681020: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 15:04:06.681047: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 15:04:06.681062: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 15:04:06.681077: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 15:04:06.681091: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 15:04:06.681519: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 15:04:06.681553: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 15:04:07.370046: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-05 15:04:07.370103: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-05 15:04:07.370119: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-05 15:04:07.371033: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:02:00.0, compute capability: 6.1)
{'id': '17_12', 'seed': 12, 'out_folder': 'results/epoch_budget', 'batch_size': 128, 'epochs': 88, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'bootstrapping': False, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/88 [00:00<?, ?epoch/s]2024-03-05 15:04:08.232279: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-05 15:04:08.244143: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600020000 Hz
2024-03-05 15:04:10.249809: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 15:04:10.467050: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 15:04:11.451073: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-05 15:04:11.512930: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/88 [01:05<1:34:56, 65.47s/epoch, loss=2.79, accuracy=0.427, val_loss=2.78, val_accuracy=0.267, lr=0.1]  2%|▏         | 2/88 [01:26<55:57, 39.04s/epoch, loss=1.43, accuracy=0.613, val_loss=2.3, val_accuracy=0.386, lr=0.1]     3%|▎         | 3/88 [01:46<43:07, 30.44s/epoch, loss=1.28, accuracy=0.677, val_loss=1.88, val_accuracy=0.519, lr=0.1]  5%|▍         | 4/88 [02:06<36:52, 26.34s/epoch, loss=1.24, accuracy=0.702, val_loss=2.09, val_accuracy=0.435, lr=0.1]  6%|▌         | 5/88 [02:26<33:20, 24.10s/epoch, loss=1.23, accuracy=0.712, val_loss=2.09, val_accuracy=0.48, lr=0.1]   7%|▋         | 6/88 [02:46<31:13, 22.84s/epoch, loss=1.21, accuracy=0.718, val_loss=1.7, val_accuracy=0.562, lr=0.1]  8%|▊         | 7/88 [03:07<29:42, 22.01s/epoch, loss=1.2, accuracy=0.724, val_loss=1.55, val_accuracy=0.603, lr=0.1]  9%|▉         | 8/88 [03:27<28:36, 21.46s/epoch, loss=1.19, accuracy=0.729, val_loss=1.99, val_accuracy=0.51, lr=0.1] 10%|█         | 9/88 [03:47<27:40, 21.01s/epoch, loss=1.18, accuracy=0.735, val_loss=1.52, val_accuracy=0.612, lr=0.1] 11%|█▏        | 10/88 [04:07<26:58, 20.75s/epoch, loss=1.18, accuracy=0.735, val_loss=2.1, val_accuracy=0.438, lr=0.1] 12%|█▎        | 11/88 [04:27<26:22, 20.55s/epoch, loss=1.17, accuracy=0.737, val_loss=2.45, val_accuracy=0.461, lr=0.1] 14%|█▎        | 12/88 [04:47<25:48, 20.38s/epoch, loss=1.17, accuracy=0.738, val_loss=1.75, val_accuracy=0.572, lr=0.1] 15%|█▍        | 13/88 [05:07<25:22, 20.30s/epoch, loss=1.16, accuracy=0.74, val_loss=2.1, val_accuracy=0.446, lr=0.1]   16%|█▌        | 14/88 [05:27<24:55, 20.21s/epoch, loss=1.16, accuracy=0.743, val_loss=2.89, val_accuracy=0.403, lr=0.0316] 17%|█▋        | 15/88 [05:47<24:33, 20.18s/epoch, loss=1.15, accuracy=0.745, val_loss=1.58, val_accuracy=0.599, lr=0.1]    18%|█▊        | 16/88 [06:07<24:09, 20.13s/epoch, loss=1.16, accuracy=0.746, val_loss=3.39, val_accuracy=0.292, lr=0.1] 19%|█▉        | 17/88 [06:27<23:47, 20.11s/epoch, loss=1.14, accuracy=0.748, val_loss=1.72, val_accuracy=0.538, lr=0.1] 20%|██        | 18/88 [06:47<23:14, 19.93s/epoch, loss=1.15, accuracy=0.746, val_loss=1.62, val_accuracy=0.586, lr=0.1] 22%|██▏       | 19/88 [07:07<22:56, 19.95s/epoch, loss=1.15, accuracy=0.747, val_loss=2.35, val_accuracy=0.348, lr=0.0316] 23%|██▎       | 20/88 [07:27<22:34, 19.92s/epoch, loss=1.15, accuracy=0.748, val_loss=1.84, val_accuracy=0.539, lr=0.1]    24%|██▍       | 21/88 [07:47<22:14, 19.92s/epoch, loss=1.14, accuracy=0.75, val_loss=3.38, val_accuracy=0.296, lr=0.1]  25%|██▌       | 22/88 [08:07<21:59, 19.99s/epoch, loss=1.14, accuracy=0.746, val_loss=6.64, val_accuracy=0.183, lr=0.1] 26%|██▌       | 23/88 [08:27<21:40, 20.01s/epoch, loss=1.14, accuracy=0.748, val_loss=1.81, val_accuracy=0.593, lr=0.1] 27%|██▋       | 24/88 [08:47<21:19, 19.99s/epoch, loss=1.13, accuracy=0.75, val_loss=1.73, val_accuracy=0.571, lr=0.0316] 28%|██▊       | 25/88 [09:07<20:57, 19.96s/epoch, loss=1.13, accuracy=0.752, val_loss=1.91, val_accuracy=0.531, lr=0.1]   30%|██▉       | 26/88 [09:27<20:39, 19.99s/epoch, loss=1.13, accuracy=0.752, val_loss=1.74, val_accuracy=0.546, lr=0.1] 31%|███       | 27/88 [09:47<20:16, 19.94s/epoch, loss=1.13, accuracy=0.751, val_loss=2.49, val_accuracy=0.439, lr=0.1] 32%|███▏      | 28/88 [10:07<19:59, 20.00s/epoch, loss=1.12, accuracy=0.752, val_loss=2.12, val_accuracy=0.51, lr=0.1]  33%|███▎      | 29/88 [10:27<19:37, 19.95s/epoch, loss=1.12, accuracy=0.753, val_loss=1.41, val_accuracy=0.643, lr=0.1] 34%|███▍      | 30/88 [10:46<19:14, 19.90s/epoch, loss=1.12, accuracy=0.753, val_loss=1.68, val_accuracy=0.557, lr=0.1] 35%|███▌      | 31/88 [11:06<18:52, 19.87s/epoch, loss=1.12, accuracy=0.752, val_loss=1.57, val_accuracy=0.588, lr=0.1] 36%|███▋      | 32/88 [11:26<18:34, 19.90s/epoch, loss=1.12, accuracy=0.756, val_loss=2.12, val_accuracy=0.554, lr=0.1] 38%|███▊      | 33/88 [11:46<18:16, 19.93s/epoch, loss=1.12, accuracy=0.755, val_loss=2.5, val_accuracy=0.369, lr=0.1]  39%|███▊      | 34/88 [12:06<17:55, 19.92s/epoch, loss=1.12, accuracy=0.755, val_loss=1.86, val_accuracy=0.541, lr=0.0316] 40%|███▉      | 35/88 [12:26<17:33, 19.87s/epoch, loss=1.12, accuracy=0.755, val_loss=3.22, val_accuracy=0.3, lr=0.1]      41%|████      | 36/88 [12:46<17:11, 19.83s/epoch, loss=1.12, accuracy=0.754, val_loss=1.52, val_accuracy=0.598, lr=0.1] 42%|████▏     | 37/88 [13:05<16:50, 19.82s/epoch, loss=1.11, accuracy=0.755, val_loss=2.44, val_accuracy=0.413, lr=0.1] 43%|████▎     | 38/88 [13:25<16:29, 19.80s/epoch, loss=1.11, accuracy=0.755, val_loss=1.96, val_accuracy=0.536, lr=0.1] 44%|████▍     | 39/88 [13:45<16:08, 19.76s/epoch, loss=1.12, accuracy=0.754, val_loss=3.2, val_accuracy=0.296, lr=0.0316] 45%|████▌     | 40/88 [14:04<15:45, 19.70s/epoch, loss=1.11, accuracy=0.756, val_loss=2.23, val_accuracy=0.468, lr=0.1]   47%|████▋     | 41/88 [14:24<15:26, 19.71s/epoch, loss=1.11, accuracy=0.758, val_loss=2.42, val_accuracy=0.411, lr=0.1] 48%|████▊     | 42/88 [14:44<15:08, 19.75s/epoch, loss=1.11, accuracy=0.755, val_loss=2.1, val_accuracy=0.513, lr=0.1]  49%|████▉     | 43/88 [15:04<14:48, 19.73s/epoch, loss=1.11, accuracy=0.754, val_loss=2.11, val_accuracy=0.453, lr=0.1] 50%|█████     | 44/88 [15:24<14:30, 19.78s/epoch, loss=1.11, accuracy=0.756, val_loss=2.11, val_accuracy=0.486, lr=0.0316] 51%|█████     | 45/88 [15:43<14:11, 19.81s/epoch, loss=1.1, accuracy=0.759, val_loss=3.82, val_accuracy=0.207, lr=0.1]     52%|█████▏    | 46/88 [16:03<13:54, 19.87s/epoch, loss=1.1, accuracy=0.759, val_loss=2.94, val_accuracy=0.371, lr=0.1] 53%|█████▎    | 47/88 [16:23<13:35, 19.89s/epoch, loss=1.11, accuracy=0.757, val_loss=1.48, val_accuracy=0.647, lr=0.1] 55%|█████▍    | 48/88 [16:43<13:15, 19.89s/epoch, loss=1.11, accuracy=0.756, val_loss=2.32, val_accuracy=0.468, lr=0.1] 56%|█████▌    | 49/88 [17:03<12:53, 19.84s/epoch, loss=1.1, accuracy=0.761, val_loss=1.98, val_accuracy=0.532, lr=0.0316] 57%|█████▋    | 50/88 [17:23<12:33, 19.82s/epoch, loss=1.1, accuracy=0.759, val_loss=2.15, val_accuracy=0.397, lr=0.1]    58%|█████▊    | 51/88 [17:42<12:12, 19.80s/epoch, loss=1.1, accuracy=0.757, val_loss=1.87, val_accuracy=0.524, lr=0.1] 59%|█████▉    | 52/88 [18:02<11:52, 19.78s/epoch, loss=1.1, accuracy=0.759, val_loss=1.88, val_accuracy=0.507, lr=0.1] 60%|██████    | 53/88 [18:22<11:32, 19.80s/epoch, loss=1.1, accuracy=0.758, val_loss=2.14, val_accuracy=0.452, lr=0.1] 61%|██████▏   | 54/88 [18:42<11:14, 19.84s/epoch, loss=1.11, accuracy=0.758, val_loss=1.58, val_accuracy=0.611, lr=0.0316] 62%|██████▎   | 55/88 [19:02<10:55, 19.86s/epoch, loss=1.1, accuracy=0.759, val_loss=2.29, val_accuracy=0.417, lr=0.1]     64%|██████▎   | 56/88 [19:22<10:35, 19.87s/epoch, loss=1.1, accuracy=0.759, val_loss=2.14, val_accuracy=0.489, lr=0.1] 65%|██████▍   | 57/88 [19:42<10:17, 19.93s/epoch, loss=1.1, accuracy=0.761, val_loss=2.21, val_accuracy=0.487, lr=0.1] 66%|██████▌   | 58/88 [20:02<09:58, 19.94s/epoch, loss=1.1, accuracy=0.76, val_loss=6.19, val_accuracy=0.166, lr=0.1]  67%|██████▋   | 59/88 [20:22<09:36, 19.89s/epoch, loss=1.11, accuracy=0.759, val_loss=3.44, val_accuracy=0.314, lr=0.0316] 68%|██████▊   | 60/88 [20:42<09:18, 19.93s/epoch, loss=1.1, accuracy=0.761, val_loss=1.72, val_accuracy=0.571, lr=0.1]     69%|██████▉   | 61/88 [21:01<08:57, 19.90s/epoch, loss=1.1, accuracy=0.76, val_loss=2.41, val_accuracy=0.479, lr=0.1]  70%|███████   | 62/88 [21:21<08:36, 19.86s/epoch, loss=1.11, accuracy=0.76, val_loss=1.97, val_accuracy=0.494, lr=0.1] 72%|███████▏  | 63/88 [21:41<08:16, 19.85s/epoch, loss=1.11, accuracy=0.759, val_loss=1.87, val_accuracy=0.544, lr=0.1] 73%|███████▎  | 64/88 [22:01<07:56, 19.85s/epoch, loss=1.1, accuracy=0.76, val_loss=2.43, val_accuracy=0.365, lr=0.0316] 74%|███████▍  | 65/88 [22:21<07:35, 19.82s/epoch, loss=1.1, accuracy=0.76, val_loss=1.5, val_accuracy=0.648, lr=0.1]     75%|███████▌  | 66/88 [22:41<07:16, 19.83s/epoch, loss=1.09, accuracy=0.763, val_loss=2.39, val_accuracy=0.392, lr=0.1] 76%|███████▌  | 67/88 [23:00<06:56, 19.83s/epoch, loss=1.11, accuracy=0.756, val_loss=1.82, val_accuracy=0.524, lr=0.1] 77%|███████▋  | 68/88 [23:20<06:36, 19.85s/epoch, loss=1.1, accuracy=0.76, val_loss=1.73, val_accuracy=0.584, lr=0.1]   78%|███████▊  | 69/88 [23:40<06:18, 19.90s/epoch, loss=1.1, accuracy=0.757, val_loss=2.01, val_accuracy=0.549, lr=0.0316] 80%|███████▉  | 70/88 [24:00<05:56, 19.79s/epoch, loss=1.1, accuracy=0.759, val_loss=1.65, val_accuracy=0.568, lr=0.1]    81%|████████  | 71/88 [24:19<05:34, 19.65s/epoch, loss=1.1, accuracy=0.758, val_loss=1.74, val_accuracy=0.548, lr=0.1] 82%|████████▏ | 72/88 [24:39<05:14, 19.65s/epoch, loss=1.11, accuracy=0.757, val_loss=2.43, val_accuracy=0.422, lr=0.1] 83%|████████▎ | 73/88 [24:58<04:53, 19.60s/epoch, loss=1.1, accuracy=0.757, val_loss=2.13, val_accuracy=0.504, lr=0.1]  84%|████████▍ | 74/88 [25:18<04:33, 19.55s/epoch, loss=1.11, accuracy=0.757, val_loss=2.19, val_accuracy=0.486, lr=0.0316] 85%|████████▌ | 75/88 [25:37<04:13, 19.51s/epoch, loss=1.1, accuracy=0.759, val_loss=2.02, val_accuracy=0.496, lr=0.1]     86%|████████▋ | 76/88 [25:57<03:54, 19.51s/epoch, loss=1.1, accuracy=0.761, val_loss=2.03, val_accuracy=0.501, lr=0.1] 88%|████████▊ | 77/88 [26:16<03:35, 19.55s/epoch, loss=1.1, accuracy=0.758, val_loss=3.24, val_accuracy=0.433, lr=0.1] 89%|████████▊ | 78/88 [26:35<03:14, 19.44s/epoch, loss=1.1, accuracy=0.758, val_loss=1.99, val_accuracy=0.485, lr=0.1] 90%|████████▉ | 79/88 [26:55<02:54, 19.36s/epoch, loss=1.11, accuracy=0.757, val_loss=1.6, val_accuracy=0.595, lr=0.0316] 91%|█████████ | 80/88 [27:14<02:34, 19.31s/epoch, loss=1.11, accuracy=0.758, val_loss=2.38, val_accuracy=0.449, lr=0.1]   92%|█████████▏| 81/88 [27:33<02:15, 19.29s/epoch, loss=1.1, accuracy=0.758, val_loss=1.59, val_accuracy=0.608, lr=0.1]  93%|█████████▎| 82/88 [27:53<01:56, 19.37s/epoch, loss=0.905, accuracy=0.814, val_loss=0.977, val_accuracy=0.765, lr=0.01] 94%|█████████▍| 83/88 [28:12<01:36, 19.35s/epoch, loss=0.727, accuracy=0.846, val_loss=0.901, val_accuracy=0.77, lr=0.01]  95%|█████████▌| 84/88 [28:31<01:17, 19.25s/epoch, loss=0.647, accuracy=0.855, val_loss=0.983, val_accuracy=0.749, lr=0.01] 97%|█████████▋| 85/88 [28:50<00:57, 19.18s/epoch, loss=0.606, accuracy=0.859, val_loss=0.818, val_accuracy=0.786, lr=0.01] 98%|█████████▊| 86/88 [29:09<00:38, 19.16s/epoch, loss=0.583, accuracy=0.859, val_loss=0.765, val_accuracy=0.797, lr=0.01] 99%|█████████▉| 87/88 [29:28<00:19, 19.18s/epoch, loss=0.576, accuracy=0.859, val_loss=0.862, val_accuracy=0.764, lr=0.01]100%|██████████| 88/88 [29:48<00:00, 19.25s/epoch, loss=0.566, accuracy=0.862, val_loss=0.851, val_accuracy=0.777, lr=0.01]100%|██████████| 88/88 [29:48<00:00, 20.32s/epoch, loss=0.566, accuracy=0.862, val_loss=0.851, val_accuracy=0.777, lr=0.01]
Using real-time data augmentation.
Test score: 0.8505716919898987
Test accuracy: 0.7771999835968018


* * * Run SGD for ID = 17_13. * * *


2024-03-05 15:34:00.084576: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 15:34:02.641837: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 15:34:02.642932: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-05 15:34:02.679650: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-03-05 15:34:02.679693: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 15:34:02.682521: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 15:34:02.682559: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 15:34:02.684580: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 15:34:02.685260: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 15:34:02.687574: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 15:34:02.688913: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 15:34:02.693258: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 15:34:02.693818: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 15:34:02.693920: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 15:34:03.926857: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-05 15:34:03.927429: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 15:34:03.928165: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-03-05 15:34:03.928194: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 15:34:03.928231: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 15:34:03.928247: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 15:34:03.928261: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 15:34:03.928278: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 15:34:03.928292: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 15:34:03.928307: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 15:34:03.928321: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 15:34:03.928742: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 15:34:03.928773: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 15:34:04.570192: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-05 15:34:04.570244: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-05 15:34:04.570253: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-05 15:34:04.571157: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:02:00.0, compute capability: 6.1)
{'id': '17_13', 'seed': 13, 'out_folder': 'results/epoch_budget', 'batch_size': 128, 'epochs': 88, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'bootstrapping': False, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/88 [00:00<?, ?epoch/s]2024-03-05 15:34:05.425054: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-05 15:34:05.437123: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600020000 Hz
2024-03-05 15:34:07.404327: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 15:34:07.613576: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 15:34:08.479342: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-05 15:34:08.538669: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/88 [01:01<1:29:08, 61.48s/epoch, loss=2.82, accuracy=0.418, val_loss=2.71, val_accuracy=0.271, lr=0.1]  2%|▏         | 2/88 [01:21<52:48, 36.84s/epoch, loss=1.43, accuracy=0.616, val_loss=1.92, val_accuracy=0.508, lr=0.1]    3%|▎         | 3/88 [01:40<41:07, 29.03s/epoch, loss=1.29, accuracy=0.678, val_loss=1.52, val_accuracy=0.621, lr=0.1]  5%|▍         | 4/88 [02:00<35:22, 25.27s/epoch, loss=1.25, accuracy=0.702, val_loss=2.73, val_accuracy=0.386, lr=0.1]  6%|▌         | 5/88 [02:19<32:02, 23.16s/epoch, loss=1.23, accuracy=0.711, val_loss=2.07, val_accuracy=0.474, lr=0.1]  7%|▋         | 6/88 [02:39<30:14, 22.13s/epoch, loss=1.22, accuracy=0.721, val_loss=1.52, val_accuracy=0.591, lr=0.1]  8%|▊         | 7/88 [02:59<28:47, 21.32s/epoch, loss=1.21, accuracy=0.728, val_loss=2.64, val_accuracy=0.44, lr=0.1]   9%|▉         | 8/88 [03:18<27:36, 20.71s/epoch, loss=1.2, accuracy=0.733, val_loss=1.8, val_accuracy=0.523, lr=0.1]  10%|█         | 9/88 [03:38<26:51, 20.40s/epoch, loss=1.19, accuracy=0.735, val_loss=1.98, val_accuracy=0.482, lr=0.1] 11%|█▏        | 10/88 [03:58<26:14, 20.19s/epoch, loss=1.19, accuracy=0.737, val_loss=1.95, val_accuracy=0.498, lr=0.1] 12%|█▎        | 11/88 [04:17<25:36, 19.95s/epoch, loss=1.19, accuracy=0.737, val_loss=3.15, val_accuracy=0.412, lr=0.0316] 14%|█▎        | 12/88 [04:37<25:02, 19.76s/epoch, loss=1.18, accuracy=0.739, val_loss=1.56, val_accuracy=0.625, lr=0.1]    15%|█▍        | 13/88 [04:56<24:43, 19.78s/epoch, loss=1.18, accuracy=0.745, val_loss=1.62, val_accuracy=0.606, lr=0.1] 16%|█▌        | 14/88 [05:16<24:29, 19.86s/epoch, loss=1.17, accuracy=0.745, val_loss=1.87, val_accuracy=0.483, lr=0.1] 17%|█▋        | 15/88 [05:36<24:07, 19.83s/epoch, loss=1.17, accuracy=0.745, val_loss=1.85, val_accuracy=0.58, lr=0.1]  18%|█▊        | 16/88 [05:56<23:54, 19.93s/epoch, loss=1.17, accuracy=0.744, val_loss=1.93, val_accuracy=0.478, lr=0.0316] 19%|█▉        | 17/88 [06:16<23:29, 19.85s/epoch, loss=1.16, accuracy=0.747, val_loss=1.92, val_accuracy=0.474, lr=0.1]    20%|██        | 18/88 [06:36<23:09, 19.84s/epoch, loss=1.17, accuracy=0.749, val_loss=1.76, val_accuracy=0.54, lr=0.1]  22%|██▏       | 19/88 [06:56<22:54, 19.92s/epoch, loss=1.16, accuracy=0.748, val_loss=2.05, val_accuracy=0.448, lr=0.1] 23%|██▎       | 20/88 [07:16<22:35, 19.93s/epoch, loss=1.16, accuracy=0.75, val_loss=1.77, val_accuracy=0.58, lr=0.1]   24%|██▍       | 21/88 [07:36<22:18, 19.98s/epoch, loss=1.15, accuracy=0.75, val_loss=2.7, val_accuracy=0.42, lr=0.0316] 25%|██▌       | 22/88 [07:56<21:56, 19.94s/epoch, loss=1.15, accuracy=0.751, val_loss=3.09, val_accuracy=0.371, lr=0.1] 26%|██▌       | 23/88 [08:16<21:46, 20.10s/epoch, loss=1.16, accuracy=0.75, val_loss=3.07, val_accuracy=0.334, lr=0.1]  27%|██▋       | 24/88 [08:37<21:28, 20.14s/epoch, loss=1.14, accuracy=0.754, val_loss=2.09, val_accuracy=0.426, lr=0.1] 28%|██▊       | 25/88 [08:57<21:07, 20.12s/epoch, loss=1.15, accuracy=0.752, val_loss=2.38, val_accuracy=0.502, lr=0.1] 30%|██▉       | 26/88 [09:17<20:45, 20.09s/epoch, loss=1.15, accuracy=0.752, val_loss=2, val_accuracy=0.498, lr=0.0316] 31%|███       | 27/88 [09:37<20:24, 20.07s/epoch, loss=1.14, accuracy=0.753, val_loss=1.71, val_accuracy=0.57, lr=0.1]  32%|███▏      | 28/88 [09:57<20:05, 20.09s/epoch, loss=1.14, accuracy=0.754, val_loss=3.97, val_accuracy=0.271, lr=0.1] 33%|███▎      | 29/88 [10:17<19:41, 20.03s/epoch, loss=1.14, accuracy=0.754, val_loss=2.16, val_accuracy=0.443, lr=0.1] 34%|███▍      | 30/88 [10:37<19:21, 20.03s/epoch, loss=1.14, accuracy=0.753, val_loss=2.93, val_accuracy=0.377, lr=0.1] 35%|███▌      | 31/88 [10:57<19:04, 20.08s/epoch, loss=1.14, accuracy=0.753, val_loss=2.13, val_accuracy=0.482, lr=0.0316] 36%|███▋      | 32/88 [11:17<18:43, 20.07s/epoch, loss=1.14, accuracy=0.752, val_loss=3.79, val_accuracy=0.248, lr=0.1]    38%|███▊      | 33/88 [11:37<18:26, 20.11s/epoch, loss=1.13, accuracy=0.756, val_loss=2.32, val_accuracy=0.502, lr=0.1] 39%|███▊      | 34/88 [11:57<18:02, 20.05s/epoch, loss=1.13, accuracy=0.756, val_loss=1.8, val_accuracy=0.528, lr=0.1]  40%|███▉      | 35/88 [12:17<17:40, 20.01s/epoch, loss=1.13, accuracy=0.757, val_loss=1.9, val_accuracy=0.559, lr=0.1] 41%|████      | 36/88 [12:37<17:20, 20.00s/epoch, loss=1.13, accuracy=0.755, val_loss=1.91, val_accuracy=0.525, lr=0.0316] 42%|████▏     | 37/88 [12:57<16:59, 19.99s/epoch, loss=1.14, accuracy=0.753, val_loss=1.88, val_accuracy=0.563, lr=0.1]    43%|████▎     | 38/88 [13:17<16:41, 20.03s/epoch, loss=1.13, accuracy=0.754, val_loss=2.19, val_accuracy=0.465, lr=0.1] 44%|████▍     | 39/88 [13:37<16:21, 20.02s/epoch, loss=1.13, accuracy=0.757, val_loss=1.44, val_accuracy=0.662, lr=0.1] 45%|████▌     | 40/88 [13:57<16:00, 20.01s/epoch, loss=1.12, accuracy=0.76, val_loss=2.42, val_accuracy=0.326, lr=0.1]  47%|████▋     | 41/88 [14:17<15:38, 19.97s/epoch, loss=1.12, accuracy=0.757, val_loss=1.8, val_accuracy=0.505, lr=0.1] 48%|████▊     | 42/88 [14:37<15:18, 19.96s/epoch, loss=1.13, accuracy=0.756, val_loss=1.85, val_accuracy=0.535, lr=0.1] 49%|████▉     | 43/88 [14:57<14:56, 19.93s/epoch, loss=1.13, accuracy=0.754, val_loss=2.02, val_accuracy=0.556, lr=0.1] 50%|█████     | 44/88 [15:17<14:35, 19.90s/epoch, loss=1.13, accuracy=0.754, val_loss=2.01, val_accuracy=0.547, lr=0.0316] 51%|█████     | 45/88 [15:37<14:18, 19.96s/epoch, loss=1.12, accuracy=0.756, val_loss=2.01, val_accuracy=0.51, lr=0.1]     52%|█████▏    | 46/88 [15:57<13:58, 19.96s/epoch, loss=1.12, accuracy=0.758, val_loss=1.88, val_accuracy=0.475, lr=0.1] 53%|█████▎    | 47/88 [16:17<13:41, 20.04s/epoch, loss=1.12, accuracy=0.759, val_loss=1.79, val_accuracy=0.575, lr=0.1] 55%|█████▍    | 48/88 [16:37<13:21, 20.05s/epoch, loss=1.12, accuracy=0.758, val_loss=1.82, val_accuracy=0.548, lr=0.1] 56%|█████▌    | 49/88 [16:57<13:02, 20.06s/epoch, loss=1.11, accuracy=0.757, val_loss=2.34, val_accuracy=0.339, lr=0.0316] 57%|█████▋    | 50/88 [17:17<12:42, 20.06s/epoch, loss=1.12, accuracy=0.759, val_loss=1.9, val_accuracy=0.508, lr=0.1]     58%|█████▊    | 51/88 [17:37<12:19, 19.99s/epoch, loss=1.12, accuracy=0.759, val_loss=2.15, val_accuracy=0.487, lr=0.1] 59%|█████▉    | 52/88 [17:57<11:58, 19.96s/epoch, loss=1.12, accuracy=0.756, val_loss=3.17, val_accuracy=0.256, lr=0.1] 60%|██████    | 53/88 [18:17<11:38, 19.95s/epoch, loss=1.11, accuracy=0.758, val_loss=2.26, val_accuracy=0.437, lr=0.1] 61%|██████▏   | 54/88 [18:37<11:17, 19.93s/epoch, loss=1.12, accuracy=0.757, val_loss=2.82, val_accuracy=0.263, lr=0.0316] 62%|██████▎   | 55/88 [18:56<10:56, 19.90s/epoch, loss=1.12, accuracy=0.757, val_loss=3.17, val_accuracy=0.356, lr=0.1]    64%|██████▎   | 56/88 [19:16<10:35, 19.86s/epoch, loss=1.12, accuracy=0.758, val_loss=2.76, val_accuracy=0.339, lr=0.1] 65%|██████▍   | 57/88 [19:36<10:15, 19.84s/epoch, loss=1.12, accuracy=0.76, val_loss=2.14, val_accuracy=0.511, lr=0.1]  66%|██████▌   | 58/88 [19:56<09:55, 19.86s/epoch, loss=1.12, accuracy=0.76, val_loss=2.04, val_accuracy=0.493, lr=0.1] 67%|██████▋   | 59/88 [20:16<09:35, 19.84s/epoch, loss=1.11, accuracy=0.759, val_loss=2.83, val_accuracy=0.367, lr=0.0316] 68%|██████▊   | 60/88 [20:36<09:15, 19.83s/epoch, loss=1.12, accuracy=0.759, val_loss=1.81, val_accuracy=0.535, lr=0.1]    69%|██████▉   | 61/88 [20:55<08:54, 19.81s/epoch, loss=1.12, accuracy=0.759, val_loss=2.11, val_accuracy=0.53, lr=0.1]  70%|███████   | 62/88 [21:15<08:37, 19.92s/epoch, loss=1.11, accuracy=0.758, val_loss=1.79, val_accuracy=0.554, lr=0.1] 72%|███████▏  | 63/88 [21:35<08:16, 19.85s/epoch, loss=1.12, accuracy=0.76, val_loss=2.01, val_accuracy=0.503, lr=0.1]  73%|███████▎  | 64/88 [21:55<07:56, 19.84s/epoch, loss=1.12, accuracy=0.758, val_loss=1.58, val_accuracy=0.588, lr=0.0316] 74%|███████▍  | 65/88 [22:15<07:34, 19.77s/epoch, loss=1.12, accuracy=0.759, val_loss=2.67, val_accuracy=0.412, lr=0.1]    75%|███████▌  | 66/88 [22:34<07:14, 19.75s/epoch, loss=1.11, accuracy=0.758, val_loss=1.88, val_accuracy=0.476, lr=0.1] 76%|███████▌  | 67/88 [22:54<06:54, 19.74s/epoch, loss=1.12, accuracy=0.759, val_loss=2.76, val_accuracy=0.474, lr=0.1] 77%|███████▋  | 68/88 [23:14<06:34, 19.72s/epoch, loss=1.12, accuracy=0.758, val_loss=2.52, val_accuracy=0.437, lr=0.1] 78%|███████▊  | 69/88 [23:33<06:14, 19.72s/epoch, loss=1.12, accuracy=0.757, val_loss=2.75, val_accuracy=0.405, lr=0.0316] 80%|███████▉  | 70/88 [23:53<05:56, 19.80s/epoch, loss=1.11, accuracy=0.76, val_loss=2.64, val_accuracy=0.384, lr=0.1]     81%|████████  | 71/88 [24:13<05:37, 19.87s/epoch, loss=1.11, accuracy=0.759, val_loss=2.25, val_accuracy=0.502, lr=0.1] 82%|████████▏ | 72/88 [24:33<05:17, 19.83s/epoch, loss=1.11, accuracy=0.76, val_loss=1.74, val_accuracy=0.545, lr=0.1]  83%|████████▎ | 73/88 [24:53<04:57, 19.85s/epoch, loss=1.11, accuracy=0.759, val_loss=1.79, val_accuracy=0.522, lr=0.1] 84%|████████▍ | 74/88 [25:13<04:37, 19.83s/epoch, loss=1.11, accuracy=0.762, val_loss=2.11, val_accuracy=0.465, lr=0.0316] 85%|████████▌ | 75/88 [25:33<04:18, 19.86s/epoch, loss=1.11, accuracy=0.759, val_loss=3.15, val_accuracy=0.358, lr=0.1]    86%|████████▋ | 76/88 [25:53<03:58, 19.88s/epoch, loss=1.11, accuracy=0.759, val_loss=1.88, val_accuracy=0.538, lr=0.1] 88%|████████▊ | 77/88 [26:13<03:38, 19.89s/epoch, loss=1.11, accuracy=0.759, val_loss=2.19, val_accuracy=0.393, lr=0.1] 89%|████████▊ | 78/88 [26:32<03:18, 19.84s/epoch, loss=1.11, accuracy=0.759, val_loss=2.07, val_accuracy=0.497, lr=0.1] 90%|████████▉ | 79/88 [26:52<02:59, 19.91s/epoch, loss=1.11, accuracy=0.759, val_loss=2.41, val_accuracy=0.397, lr=0.0316] 91%|█████████ | 80/88 [27:12<02:39, 19.92s/epoch, loss=1.11, accuracy=0.761, val_loss=2.03, val_accuracy=0.46, lr=0.1]     92%|█████████▏| 81/88 [27:33<02:20, 20.02s/epoch, loss=1.12, accuracy=0.756, val_loss=3.28, val_accuracy=0.289, lr=0.1] 93%|█████████▎| 82/88 [27:52<01:59, 19.99s/epoch, loss=0.912, accuracy=0.817, val_loss=0.873, val_accuracy=0.811, lr=0.01] 94%|█████████▍| 83/88 [28:12<01:39, 19.98s/epoch, loss=0.728, accuracy=0.85, val_loss=0.796, val_accuracy=0.813, lr=0.01]  95%|█████████▌| 84/88 [28:32<01:19, 19.98s/epoch, loss=0.643, accuracy=0.86, val_loss=0.785, val_accuracy=0.805, lr=0.01] 97%|█████████▋| 85/88 [28:52<00:59, 19.96s/epoch, loss=0.601, accuracy=0.859, val_loss=0.829, val_accuracy=0.781, lr=0.01] 98%|█████████▊| 86/88 [29:12<00:39, 19.94s/epoch, loss=0.576, accuracy=0.866, val_loss=0.737, val_accuracy=0.812, lr=0.01] 99%|█████████▉| 87/88 [29:32<00:19, 19.92s/epoch, loss=0.571, accuracy=0.862, val_loss=0.673, val_accuracy=0.827, lr=0.01]100%|██████████| 88/88 [29:52<00:00, 19.94s/epoch, loss=0.564, accuracy=0.864, val_loss=1.03, val_accuracy=0.724, lr=0.01] 100%|██████████| 88/88 [29:52<00:00, 20.37s/epoch, loss=0.564, accuracy=0.864, val_loss=1.03, val_accuracy=0.724, lr=0.01]
Using real-time data augmentation.
Test score: 1.0266047716140747
Test accuracy: 0.7235000133514404


* * * Run SGD for ID = 17_14. * * *


2024-03-05 16:04:02.542561: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 16:04:12.536493: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 16:04:12.537658: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-05 16:04:12.585352: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-03-05 16:04:12.585398: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 16:04:12.590552: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 16:04:12.590604: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 16:04:12.594754: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 16:04:12.596949: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 16:04:12.600689: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 16:04:12.603382: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 16:04:12.608483: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 16:04:12.609090: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 16:04:12.609175: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 16:04:13.881810: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-05 16:04:13.882320: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 16:04:13.882764: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-03-05 16:04:13.882796: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 16:04:13.882838: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 16:04:13.882854: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 16:04:13.882877: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 16:04:13.882893: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 16:04:13.882908: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 16:04:13.882923: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 16:04:13.882938: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 16:04:13.884385: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 16:04:13.884425: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 16:04:14.588239: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-05 16:04:14.588313: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-05 16:04:14.588322: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-05 16:04:14.590638: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:02:00.0, compute capability: 6.1)
{'id': '17_14', 'seed': 14, 'out_folder': 'results/epoch_budget', 'batch_size': 128, 'epochs': 88, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'bootstrapping': False, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/88 [00:00<?, ?epoch/s]2024-03-05 16:04:15.470563: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-05 16:04:15.483132: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600020000 Hz
2024-03-05 16:04:17.498304: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 16:04:17.748332: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 16:04:18.611062: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-05 16:04:18.668470: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/88 [01:02<1:30:27, 62.38s/epoch, loss=3.21, accuracy=0.279, val_loss=3.2, val_accuracy=0.184, lr=0.1]  2%|▏         | 2/88 [01:22<53:31, 37.35s/epoch, loss=1.59, accuracy=0.514, val_loss=3.4, val_accuracy=0.301, lr=0.1]    3%|▎         | 3/88 [01:42<41:37, 29.39s/epoch, loss=1.36, accuracy=0.636, val_loss=2.1, val_accuracy=0.408, lr=0.1]  5%|▍         | 4/88 [02:02<35:57, 25.69s/epoch, loss=1.29, accuracy=0.68, val_loss=2.48, val_accuracy=0.408, lr=0.1]  6%|▌         | 5/88 [02:21<32:34, 23.55s/epoch, loss=1.25, accuracy=0.701, val_loss=1.62, val_accuracy=0.583, lr=0.1]  7%|▋         | 6/88 [02:42<30:53, 22.60s/epoch, loss=1.24, accuracy=0.708, val_loss=2.1, val_accuracy=0.464, lr=0.1]   8%|▊         | 7/88 [03:02<29:29, 21.85s/epoch, loss=1.23, accuracy=0.714, val_loss=2.07, val_accuracy=0.4, lr=0.1]   9%|▉         | 8/88 [03:23<28:25, 21.32s/epoch, loss=1.22, accuracy=0.721, val_loss=1.67, val_accuracy=0.563, lr=0.1] 10%|█         | 9/88 [03:43<27:33, 20.93s/epoch, loss=1.21, accuracy=0.727, val_loss=2.05, val_accuracy=0.433, lr=0.1] 11%|█▏        | 10/88 [04:03<26:56, 20.73s/epoch, loss=1.2, accuracy=0.73, val_loss=1.58, val_accuracy=0.585, lr=0.1]  12%|█▎        | 11/88 [04:23<26:16, 20.48s/epoch, loss=1.2, accuracy=0.733, val_loss=2.24, val_accuracy=0.521, lr=0.1] 14%|█▎        | 12/88 [04:43<25:42, 20.29s/epoch, loss=1.2, accuracy=0.735, val_loss=1.96, val_accuracy=0.496, lr=0.1] 15%|█▍        | 13/88 [05:03<25:11, 20.15s/epoch, loss=1.2, accuracy=0.736, val_loss=2.19, val_accuracy=0.46, lr=0.1]  16%|█▌        | 14/88 [05:23<24:50, 20.14s/epoch, loss=1.19, accuracy=0.737, val_loss=2.28, val_accuracy=0.447, lr=0.1] 17%|█▋        | 15/88 [05:43<24:32, 20.17s/epoch, loss=1.2, accuracy=0.735, val_loss=1.96, val_accuracy=0.545, lr=0.0316] 18%|█▊        | 16/88 [06:03<24:12, 20.17s/epoch, loss=1.19, accuracy=0.739, val_loss=2.23, val_accuracy=0.41, lr=0.1]    19%|█▉        | 17/88 [06:23<23:50, 20.15s/epoch, loss=1.18, accuracy=0.743, val_loss=1.61, val_accuracy=0.608, lr=0.1] 20%|██        | 18/88 [06:43<23:27, 20.11s/epoch, loss=1.18, accuracy=0.745, val_loss=2.49, val_accuracy=0.439, lr=0.1] 22%|██▏       | 19/88 [07:03<23:06, 20.09s/epoch, loss=1.17, accuracy=0.743, val_loss=1.78, val_accuracy=0.518, lr=0.1] 23%|██▎       | 20/88 [07:23<22:47, 20.10s/epoch, loss=1.17, accuracy=0.744, val_loss=1.84, val_accuracy=0.578, lr=0.0316] 24%|██▍       | 21/88 [07:44<22:31, 20.17s/epoch, loss=1.17, accuracy=0.745, val_loss=1.7, val_accuracy=0.548, lr=0.1]     25%|██▌       | 22/88 [08:04<22:14, 20.22s/epoch, loss=1.17, accuracy=0.745, val_loss=2.94, val_accuracy=0.29, lr=0.1] 26%|██▌       | 23/88 [08:24<21:53, 20.21s/epoch, loss=1.17, accuracy=0.745, val_loss=1.86, val_accuracy=0.537, lr=0.1] 27%|██▋       | 24/88 [08:45<21:34, 20.22s/epoch, loss=1.17, accuracy=0.747, val_loss=1.61, val_accuracy=0.619, lr=0.1] 28%|██▊       | 25/88 [09:05<21:19, 20.32s/epoch, loss=1.17, accuracy=0.744, val_loss=1.45, val_accuracy=0.644, lr=0.1] 30%|██▉       | 26/88 [09:25<21:00, 20.33s/epoch, loss=1.16, accuracy=0.748, val_loss=1.59, val_accuracy=0.604, lr=0.1] 31%|███       | 27/88 [09:46<20:37, 20.28s/epoch, loss=1.17, accuracy=0.747, val_loss=1.67, val_accuracy=0.582, lr=0.1] 32%|███▏      | 28/88 [10:06<20:16, 20.27s/epoch, loss=1.16, accuracy=0.75, val_loss=1.44, val_accuracy=0.649, lr=0.1]  33%|███▎      | 29/88 [10:26<19:56, 20.28s/epoch, loss=1.15, accuracy=0.749, val_loss=2.59, val_accuracy=0.432, lr=0.1] 34%|███▍      | 30/88 [10:47<19:37, 20.31s/epoch, loss=1.15, accuracy=0.75, val_loss=2.6, val_accuracy=0.394, lr=0.1]   35%|███▌      | 31/88 [11:07<19:16, 20.30s/epoch, loss=1.15, accuracy=0.75, val_loss=2.84, val_accuracy=0.421, lr=0.1] 36%|███▋      | 32/88 [11:27<18:52, 20.22s/epoch, loss=1.15, accuracy=0.749, val_loss=2.4, val_accuracy=0.444, lr=0.1] 38%|███▊      | 33/88 [11:47<18:27, 20.14s/epoch, loss=1.16, accuracy=0.749, val_loss=1.66, val_accuracy=0.603, lr=0.0316] 39%|███▊      | 34/88 [12:07<18:04, 20.08s/epoch, loss=1.15, accuracy=0.75, val_loss=1.44, val_accuracy=0.645, lr=0.1]     40%|███▉      | 35/88 [12:27<17:44, 20.09s/epoch, loss=1.16, accuracy=0.751, val_loss=1.57, val_accuracy=0.627, lr=0.1] 41%|████      | 36/88 [12:47<17:24, 20.08s/epoch, loss=1.14, accuracy=0.753, val_loss=1.52, val_accuracy=0.632, lr=0.1] 42%|████▏     | 37/88 [13:07<17:03, 20.07s/epoch, loss=1.15, accuracy=0.751, val_loss=1.57, val_accuracy=0.623, lr=0.1] 43%|████▎     | 38/88 [13:27<16:41, 20.03s/epoch, loss=1.15, accuracy=0.752, val_loss=1.57, val_accuracy=0.604, lr=0.0316] 44%|████▍     | 39/88 [13:47<16:21, 20.03s/epoch, loss=1.15, accuracy=0.748, val_loss=1.42, val_accuracy=0.663, lr=0.1]    45%|████▌     | 40/88 [14:07<16:03, 20.07s/epoch, loss=1.14, accuracy=0.752, val_loss=1.82, val_accuracy=0.564, lr=0.1] 47%|████▋     | 41/88 [14:27<15:43, 20.08s/epoch, loss=1.14, accuracy=0.752, val_loss=2.46, val_accuracy=0.454, lr=0.1] 48%|████▊     | 42/88 [14:47<15:24, 20.10s/epoch, loss=1.14, accuracy=0.752, val_loss=2.11, val_accuracy=0.459, lr=0.1] 49%|████▉     | 43/88 [15:08<15:05, 20.12s/epoch, loss=1.14, accuracy=0.751, val_loss=1.66, val_accuracy=0.57, lr=0.1]  50%|█████     | 44/88 [15:28<14:47, 20.18s/epoch, loss=1.14, accuracy=0.754, val_loss=3.59, val_accuracy=0.371, lr=0.0316] 51%|█████     | 45/88 [15:48<14:27, 20.18s/epoch, loss=1.14, accuracy=0.755, val_loss=1.96, val_accuracy=0.486, lr=0.1]    52%|█████▏    | 46/88 [16:08<14:09, 20.22s/epoch, loss=1.13, accuracy=0.754, val_loss=1.95, val_accuracy=0.54, lr=0.1]  53%|█████▎    | 47/88 [16:29<13:49, 20.23s/epoch, loss=1.15, accuracy=0.753, val_loss=1.63, val_accuracy=0.564, lr=0.1] 55%|█████▍    | 48/88 [16:49<13:28, 20.20s/epoch, loss=1.13, accuracy=0.753, val_loss=2.05, val_accuracy=0.496, lr=0.1] 56%|█████▌    | 49/88 [17:09<13:09, 20.24s/epoch, loss=1.14, accuracy=0.751, val_loss=2.1, val_accuracy=0.438, lr=0.0316] 57%|█████▋    | 50/88 [17:29<12:46, 20.17s/epoch, loss=1.14, accuracy=0.754, val_loss=1.86, val_accuracy=0.548, lr=0.1]   58%|█████▊    | 51/88 [17:49<12:24, 20.11s/epoch, loss=1.14, accuracy=0.756, val_loss=1.47, val_accuracy=0.643, lr=0.1] 59%|█████▉    | 52/88 [18:09<12:03, 20.10s/epoch, loss=1.14, accuracy=0.753, val_loss=1.76, val_accuracy=0.584, lr=0.1] 60%|██████    | 53/88 [18:29<11:45, 20.16s/epoch, loss=1.14, accuracy=0.756, val_loss=2.6, val_accuracy=0.401, lr=0.1]  61%|██████▏   | 54/88 [18:50<11:26, 20.19s/epoch, loss=1.13, accuracy=0.755, val_loss=2.35, val_accuracy=0.353, lr=0.0316] 62%|██████▎   | 55/88 [19:10<11:04, 20.15s/epoch, loss=1.13, accuracy=0.753, val_loss=2.9, val_accuracy=0.415, lr=0.1]     64%|██████▎   | 56/88 [19:30<10:46, 20.22s/epoch, loss=1.13, accuracy=0.754, val_loss=2.58, val_accuracy=0.451, lr=0.1] 65%|██████▍   | 57/88 [19:50<10:27, 20.23s/epoch, loss=1.14, accuracy=0.752, val_loss=2.26, val_accuracy=0.505, lr=0.1] 66%|██████▌   | 58/88 [20:11<10:06, 20.23s/epoch, loss=1.14, accuracy=0.752, val_loss=1.5, val_accuracy=0.636, lr=0.1]  67%|██████▋   | 59/88 [20:31<09:46, 20.21s/epoch, loss=1.13, accuracy=0.753, val_loss=2.27, val_accuracy=0.456, lr=0.0316] 68%|██████▊   | 60/88 [20:51<09:24, 20.15s/epoch, loss=1.13, accuracy=0.755, val_loss=1.57, val_accuracy=0.592, lr=0.1]    69%|██████▉   | 61/88 [21:11<09:03, 20.12s/epoch, loss=1.14, accuracy=0.753, val_loss=1.65, val_accuracy=0.567, lr=0.1] 70%|███████   | 62/88 [21:31<08:41, 20.06s/epoch, loss=1.13, accuracy=0.756, val_loss=2.56, val_accuracy=0.436, lr=0.1] 72%|███████▏  | 63/88 [21:51<08:21, 20.05s/epoch, loss=1.13, accuracy=0.754, val_loss=1.84, val_accuracy=0.489, lr=0.1] 73%|███████▎  | 64/88 [22:11<08:00, 20.00s/epoch, loss=1.13, accuracy=0.758, val_loss=1.56, val_accuracy=0.61, lr=0.0316] 74%|███████▍  | 65/88 [22:31<07:40, 20.01s/epoch, loss=1.13, accuracy=0.756, val_loss=1.4, val_accuracy=0.658, lr=0.1]    75%|███████▌  | 66/88 [22:51<07:19, 19.99s/epoch, loss=1.14, accuracy=0.753, val_loss=2.01, val_accuracy=0.527, lr=0.1] 76%|███████▌  | 67/88 [23:11<06:59, 19.99s/epoch, loss=1.13, accuracy=0.757, val_loss=2.52, val_accuracy=0.43, lr=0.1]  77%|███████▋  | 68/88 [23:31<06:40, 20.04s/epoch, loss=1.13, accuracy=0.752, val_loss=1.85, val_accuracy=0.563, lr=0.1] 78%|███████▊  | 69/88 [23:51<06:20, 20.01s/epoch, loss=1.13, accuracy=0.755, val_loss=2.87, val_accuracy=0.413, lr=0.1] 80%|███████▉  | 70/88 [24:11<06:00, 20.00s/epoch, loss=1.13, accuracy=0.754, val_loss=2.68, val_accuracy=0.394, lr=0.0316] 81%|████████  | 71/88 [24:31<05:39, 19.98s/epoch, loss=1.13, accuracy=0.755, val_loss=1.86, val_accuracy=0.534, lr=0.1]    82%|████████▏ | 72/88 [24:51<05:19, 19.97s/epoch, loss=1.13, accuracy=0.752, val_loss=2.83, val_accuracy=0.36, lr=0.1]  83%|████████▎ | 73/88 [25:11<04:59, 19.97s/epoch, loss=1.12, accuracy=0.758, val_loss=2.13, val_accuracy=0.455, lr=0.1] 84%|████████▍ | 74/88 [25:30<04:39, 19.96s/epoch, loss=1.13, accuracy=0.756, val_loss=2.09, val_accuracy=0.461, lr=0.1] 85%|████████▌ | 75/88 [25:50<04:19, 19.96s/epoch, loss=1.13, accuracy=0.757, val_loss=2.15, val_accuracy=0.431, lr=0.0316] 86%|████████▋ | 76/88 [26:10<03:59, 19.96s/epoch, loss=1.13, accuracy=0.755, val_loss=1.79, val_accuracy=0.559, lr=0.1]    88%|████████▊ | 77/88 [26:31<03:40, 20.08s/epoch, loss=1.13, accuracy=0.757, val_loss=2.36, val_accuracy=0.42, lr=0.1]  89%|████████▊ | 78/88 [26:51<03:21, 20.13s/epoch, loss=1.12, accuracy=0.759, val_loss=1.97, val_accuracy=0.54, lr=0.1] 90%|████████▉ | 79/88 [27:11<03:01, 20.12s/epoch, loss=1.13, accuracy=0.757, val_loss=2, val_accuracy=0.479, lr=0.1]   91%|█████████ | 80/88 [27:31<02:41, 20.14s/epoch, loss=1.13, accuracy=0.756, val_loss=1.68, val_accuracy=0.615, lr=0.0316] 92%|█████████▏| 81/88 [27:51<02:20, 20.09s/epoch, loss=1.13, accuracy=0.754, val_loss=2.25, val_accuracy=0.507, lr=0.1]    93%|█████████▎| 82/88 [28:11<02:00, 20.01s/epoch, loss=0.912, accuracy=0.818, val_loss=0.915, val_accuracy=0.8, lr=0.01] 94%|█████████▍| 83/88 [28:31<01:39, 19.93s/epoch, loss=0.737, accuracy=0.848, val_loss=0.781, val_accuracy=0.824, lr=0.01] 95%|█████████▌| 84/88 [28:50<01:18, 19.75s/epoch, loss=0.654, accuracy=0.857, val_loss=0.734, val_accuracy=0.821, lr=0.01] 97%|█████████▋| 85/88 [29:10<00:59, 19.86s/epoch, loss=0.608, accuracy=0.858, val_loss=0.731, val_accuracy=0.807, lr=0.01] 98%|█████████▊| 86/88 [29:30<00:39, 19.70s/epoch, loss=0.587, accuracy=0.86, val_loss=0.767, val_accuracy=0.798, lr=0.01]  99%|█████████▉| 87/88 [29:49<00:19, 19.59s/epoch, loss=0.579, accuracy=0.861, val_loss=1.01, val_accuracy=0.73, lr=0.01] 100%|██████████| 88/88 [30:08<00:00, 19.53s/epoch, loss=0.57, accuracy=0.863, val_loss=0.828, val_accuracy=0.784, lr=0.01]100%|██████████| 88/88 [30:08<00:00, 20.55s/epoch, loss=0.57, accuracy=0.863, val_loss=0.828, val_accuracy=0.784, lr=0.01]
Using real-time data augmentation.
Test score: 0.8282804489135742
Test accuracy: 0.7840999960899353


* * * Run SGD for ID = 17_15. * * *


2024-03-05 16:34:27.832451: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 16:34:30.501697: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 16:34:30.502904: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-05 16:34:30.540201: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-03-05 16:34:30.540243: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 16:34:30.543064: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 16:34:30.543102: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 16:34:30.545488: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 16:34:30.546172: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 16:34:30.548603: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 16:34:30.549998: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 16:34:30.554636: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 16:34:30.555245: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 16:34:30.555351: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 16:34:31.799106: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-05 16:34:31.799749: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 16:34:31.800531: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-03-05 16:34:31.800563: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 16:34:31.800599: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 16:34:31.800618: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 16:34:31.800634: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 16:34:31.800651: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 16:34:31.800666: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 16:34:31.800682: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 16:34:31.800697: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 16:34:31.801130: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 16:34:31.801162: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 16:34:32.437365: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-05 16:34:32.437409: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-05 16:34:32.437417: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-05 16:34:32.438392: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:02:00.0, compute capability: 6.1)
{'id': '17_15', 'seed': 15, 'out_folder': 'results/epoch_budget', 'batch_size': 128, 'epochs': 88, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'bootstrapping': False, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/88 [00:00<?, ?epoch/s]2024-03-05 16:34:33.288149: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-05 16:34:33.300139: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600020000 Hz
2024-03-05 16:34:35.288388: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 16:34:35.520950: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 16:34:36.279209: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-05 16:34:36.329754: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/88 [00:59<1:26:32, 59.69s/epoch, loss=3.2, accuracy=0.287, val_loss=2.93, val_accuracy=0.208, lr=0.1]  2%|▏         | 2/88 [01:19<51:38, 36.03s/epoch, loss=1.52, accuracy=0.544, val_loss=3.49, val_accuracy=0.268, lr=0.1]   3%|▎         | 3/88 [01:39<40:46, 28.78s/epoch, loss=1.31, accuracy=0.644, val_loss=1.99, val_accuracy=0.477, lr=0.1]  5%|▍         | 4/88 [01:58<35:12, 25.15s/epoch, loss=1.25, accuracy=0.686, val_loss=2.19, val_accuracy=0.438, lr=0.1]  6%|▌         | 5/88 [02:18<31:53, 23.05s/epoch, loss=1.22, accuracy=0.708, val_loss=1.57, val_accuracy=0.578, lr=0.1]  7%|▋         | 6/88 [02:37<29:48, 21.81s/epoch, loss=1.21, accuracy=0.716, val_loss=1.69, val_accuracy=0.541, lr=0.1]  8%|▊         | 7/88 [02:57<28:29, 21.11s/epoch, loss=1.2, accuracy=0.723, val_loss=1.86, val_accuracy=0.505, lr=0.1]   9%|▉         | 8/88 [03:17<27:37, 20.71s/epoch, loss=1.19, accuracy=0.728, val_loss=2.88, val_accuracy=0.403, lr=0.1] 10%|█         | 9/88 [03:36<26:53, 20.42s/epoch, loss=1.18, accuracy=0.734, val_loss=2.68, val_accuracy=0.389, lr=0.1] 11%|█▏        | 10/88 [03:56<26:20, 20.26s/epoch, loss=1.18, accuracy=0.734, val_loss=2.5, val_accuracy=0.415, lr=0.0316] 12%|█▎        | 11/88 [04:16<25:44, 20.06s/epoch, loss=1.17, accuracy=0.737, val_loss=2.01, val_accuracy=0.437, lr=0.1]   14%|█▎        | 12/88 [04:35<25:05, 19.81s/epoch, loss=1.16, accuracy=0.74, val_loss=1.8, val_accuracy=0.508, lr=0.1]   15%|█▍        | 13/88 [04:55<24:36, 19.69s/epoch, loss=1.17, accuracy=0.741, val_loss=1.32, val_accuracy=0.691, lr=0.1] 16%|█▌        | 14/88 [05:14<24:03, 19.51s/epoch, loss=1.16, accuracy=0.741, val_loss=1.97, val_accuracy=0.459, lr=0.1] 17%|█▋        | 15/88 [05:33<23:46, 19.55s/epoch, loss=1.16, accuracy=0.742, val_loss=2.39, val_accuracy=0.404, lr=0.1] 18%|█▊        | 16/88 [05:53<23:25, 19.52s/epoch, loss=1.16, accuracy=0.747, val_loss=1.77, val_accuracy=0.542, lr=0.1] 19%|█▉        | 17/88 [06:12<23:01, 19.46s/epoch, loss=1.15, accuracy=0.746, val_loss=3.07, val_accuracy=0.376, lr=0.1] 20%|██        | 18/88 [06:32<22:42, 19.46s/epoch, loss=1.15, accuracy=0.748, val_loss=1.98, val_accuracy=0.484, lr=0.0316] 22%|██▏       | 19/88 [06:51<22:27, 19.52s/epoch, loss=1.15, accuracy=0.749, val_loss=2.53, val_accuracy=0.407, lr=0.1]    23%|██▎       | 20/88 [07:11<22:07, 19.51s/epoch, loss=1.16, accuracy=0.747, val_loss=1.71, val_accuracy=0.557, lr=0.1] 24%|██▍       | 21/88 [07:30<21:49, 19.54s/epoch, loss=1.15, accuracy=0.749, val_loss=2.07, val_accuracy=0.499, lr=0.1] 25%|██▌       | 22/88 [07:50<21:27, 19.50s/epoch, loss=1.15, accuracy=0.748, val_loss=1.68, val_accuracy=0.562, lr=0.1] 26%|██▌       | 23/88 [08:09<21:04, 19.46s/epoch, loss=1.14, accuracy=0.747, val_loss=1.48, val_accuracy=0.641, lr=0.0316] 27%|██▋       | 24/88 [08:29<20:53, 19.58s/epoch, loss=1.14, accuracy=0.75, val_loss=2.39, val_accuracy=0.445, lr=0.1]     28%|██▊       | 25/88 [08:49<20:35, 19.61s/epoch, loss=1.14, accuracy=0.75, val_loss=2.34, val_accuracy=0.412, lr=0.1] 30%|██▉       | 26/88 [09:09<20:25, 19.77s/epoch, loss=1.13, accuracy=0.75, val_loss=1.59, val_accuracy=0.61, lr=0.1]  31%|███       | 27/88 [09:28<19:58, 19.64s/epoch, loss=1.13, accuracy=0.751, val_loss=1.87, val_accuracy=0.485, lr=0.1] 32%|███▏      | 28/88 [09:48<19:42, 19.71s/epoch, loss=1.13, accuracy=0.754, val_loss=1.98, val_accuracy=0.456, lr=0.0316] 33%|███▎      | 29/88 [10:08<19:21, 19.68s/epoch, loss=1.13, accuracy=0.752, val_loss=3.22, val_accuracy=0.361, lr=0.1]    34%|███▍      | 30/88 [10:27<19:01, 19.69s/epoch, loss=1.13, accuracy=0.752, val_loss=2.29, val_accuracy=0.419, lr=0.1] 35%|███▌      | 31/88 [10:47<18:46, 19.77s/epoch, loss=1.13, accuracy=0.753, val_loss=2.08, val_accuracy=0.514, lr=0.1] 36%|███▋      | 32/88 [11:07<18:22, 19.69s/epoch, loss=1.12, accuracy=0.751, val_loss=1.84, val_accuracy=0.532, lr=0.1] 38%|███▊      | 33/88 [11:26<17:53, 19.52s/epoch, loss=1.12, accuracy=0.752, val_loss=4.3, val_accuracy=0.271, lr=0.0316] 39%|███▊      | 34/88 [11:45<17:30, 19.46s/epoch, loss=1.12, accuracy=0.755, val_loss=2.33, val_accuracy=0.464, lr=0.1]   40%|███▉      | 35/88 [12:05<17:09, 19.42s/epoch, loss=1.12, accuracy=0.753, val_loss=1.74, val_accuracy=0.571, lr=0.1] 41%|████      | 36/88 [12:25<17:05, 19.72s/epoch, loss=1.13, accuracy=0.752, val_loss=1.79, val_accuracy=0.554, lr=0.1] 42%|████▏     | 37/88 [12:44<16:42, 19.65s/epoch, loss=1.11, accuracy=0.756, val_loss=2.75, val_accuracy=0.424, lr=0.1] 43%|████▎     | 38/88 [13:05<16:29, 19.80s/epoch, loss=1.12, accuracy=0.755, val_loss=1.54, val_accuracy=0.605, lr=0.0316] 44%|████▍     | 39/88 [13:24<16:11, 19.82s/epoch, loss=1.11, accuracy=0.756, val_loss=2.7, val_accuracy=0.442, lr=0.1]     45%|████▌     | 40/88 [13:45<15:56, 19.92s/epoch, loss=1.12, accuracy=0.756, val_loss=2.03, val_accuracy=0.466, lr=0.1] 47%|████▋     | 41/88 [14:05<15:35, 19.91s/epoch, loss=1.11, accuracy=0.756, val_loss=2.11, val_accuracy=0.461, lr=0.1] 48%|████▊     | 42/88 [14:24<15:16, 19.92s/epoch, loss=1.1, accuracy=0.756, val_loss=1.92, val_accuracy=0.518, lr=0.1]  49%|████▉     | 43/88 [14:44<14:55, 19.90s/epoch, loss=1.12, accuracy=0.752, val_loss=4.16, val_accuracy=0.336, lr=0.0316] 50%|█████     | 44/88 [15:04<14:36, 19.92s/epoch, loss=1.11, accuracy=0.756, val_loss=2.54, val_accuracy=0.419, lr=0.1]    51%|█████     | 45/88 [15:24<14:17, 19.95s/epoch, loss=1.11, accuracy=0.756, val_loss=1.71, val_accuracy=0.572, lr=0.1] 52%|█████▏    | 46/88 [15:44<13:58, 19.95s/epoch, loss=1.12, accuracy=0.755, val_loss=2.2, val_accuracy=0.476, lr=0.1]  53%|█████▎    | 47/88 [16:04<13:40, 20.02s/epoch, loss=1.11, accuracy=0.756, val_loss=1.4, val_accuracy=0.652, lr=0.1] 55%|█████▍    | 48/88 [16:25<13:21, 20.04s/epoch, loss=1.11, accuracy=0.756, val_loss=2.01, val_accuracy=0.524, lr=0.0316] 56%|█████▌    | 49/88 [16:44<12:59, 19.99s/epoch, loss=1.11, accuracy=0.756, val_loss=2.37, val_accuracy=0.453, lr=0.1]    57%|█████▋    | 50/88 [17:05<12:41, 20.03s/epoch, loss=1.11, accuracy=0.757, val_loss=2.65, val_accuracy=0.308, lr=0.1] 58%|█████▊    | 51/88 [17:24<12:20, 20.00s/epoch, loss=1.11, accuracy=0.757, val_loss=2.21, val_accuracy=0.426, lr=0.1] 59%|█████▉    | 52/88 [17:44<11:58, 19.96s/epoch, loss=1.11, accuracy=0.755, val_loss=2.04, val_accuracy=0.478, lr=0.1] 60%|██████    | 53/88 [18:04<11:37, 19.93s/epoch, loss=1.11, accuracy=0.759, val_loss=2.14, val_accuracy=0.445, lr=0.0316] 61%|██████▏   | 54/88 [18:24<11:18, 19.95s/epoch, loss=1.12, accuracy=0.755, val_loss=2.06, val_accuracy=0.447, lr=0.1]    62%|██████▎   | 55/88 [18:44<10:57, 19.91s/epoch, loss=1.11, accuracy=0.756, val_loss=3.33, val_accuracy=0.325, lr=0.1] 64%|██████▎   | 56/88 [19:04<10:36, 19.90s/epoch, loss=1.1, accuracy=0.759, val_loss=1.66, val_accuracy=0.583, lr=0.1]  65%|██████▍   | 57/88 [19:24<10:17, 19.90s/epoch, loss=1.11, accuracy=0.757, val_loss=1.55, val_accuracy=0.612, lr=0.1] 66%|██████▌   | 58/88 [19:44<09:57, 19.91s/epoch, loss=1.1, accuracy=0.759, val_loss=2.75, val_accuracy=0.258, lr=0.0316] 67%|██████▋   | 59/88 [20:04<09:37, 19.91s/epoch, loss=1.11, accuracy=0.757, val_loss=1.52, val_accuracy=0.612, lr=0.1]   68%|██████▊   | 60/88 [20:23<09:16, 19.89s/epoch, loss=1.11, accuracy=0.757, val_loss=2.72, val_accuracy=0.405, lr=0.1] 69%|██████▉   | 61/88 [20:43<08:56, 19.86s/epoch, loss=1.1, accuracy=0.756, val_loss=1.8, val_accuracy=0.587, lr=0.1]   70%|███████   | 62/88 [21:03<08:37, 19.89s/epoch, loss=1.11, accuracy=0.758, val_loss=4.29, val_accuracy=0.273, lr=0.1] 72%|███████▏  | 63/88 [21:23<08:17, 19.91s/epoch, loss=1.11, accuracy=0.757, val_loss=2.4, val_accuracy=0.449, lr=0.0316] 73%|███████▎  | 64/88 [21:43<07:56, 19.86s/epoch, loss=1.11, accuracy=0.757, val_loss=1.39, val_accuracy=0.659, lr=0.1]   74%|███████▍  | 65/88 [22:03<07:36, 19.84s/epoch, loss=1.1, accuracy=0.757, val_loss=1.95, val_accuracy=0.508, lr=0.1]  75%|███████▌  | 66/88 [22:23<07:16, 19.85s/epoch, loss=1.1, accuracy=0.756, val_loss=1.5, val_accuracy=0.634, lr=0.1]  76%|███████▌  | 67/88 [22:42<06:55, 19.80s/epoch, loss=1.11, accuracy=0.755, val_loss=3.97, val_accuracy=0.313, lr=0.1] 77%|███████▋  | 68/88 [23:02<06:35, 19.78s/epoch, loss=1.1, accuracy=0.756, val_loss=3.47, val_accuracy=0.315, lr=0.0316] 78%|███████▊  | 69/88 [23:22<06:15, 19.76s/epoch, loss=1.1, accuracy=0.759, val_loss=1.86, val_accuracy=0.539, lr=0.1]    80%|███████▉  | 70/88 [23:41<05:55, 19.74s/epoch, loss=1.1, accuracy=0.757, val_loss=4.87, val_accuracy=0.247, lr=0.1] 81%|████████  | 71/88 [24:01<05:35, 19.76s/epoch, loss=1.1, accuracy=0.757, val_loss=3.05, val_accuracy=0.352, lr=0.1] 82%|████████▏ | 72/88 [24:21<05:16, 19.77s/epoch, loss=1.11, accuracy=0.756, val_loss=2.14, val_accuracy=0.465, lr=0.1] 83%|████████▎ | 73/88 [24:41<04:56, 19.78s/epoch, loss=1.11, accuracy=0.756, val_loss=1.8, val_accuracy=0.558, lr=0.0316] 84%|████████▍ | 74/88 [25:01<04:36, 19.75s/epoch, loss=1.1, accuracy=0.759, val_loss=3.55, val_accuracy=0.318, lr=0.1]    85%|████████▌ | 75/88 [25:20<04:17, 19.79s/epoch, loss=1.1, accuracy=0.76, val_loss=2.19, val_accuracy=0.497, lr=0.1]  86%|████████▋ | 76/88 [25:40<03:57, 19.80s/epoch, loss=1.1, accuracy=0.757, val_loss=2.09, val_accuracy=0.492, lr=0.1] 88%|████████▊ | 77/88 [26:00<03:37, 19.77s/epoch, loss=1.1, accuracy=0.758, val_loss=2.12, val_accuracy=0.519, lr=0.1] 89%|████████▊ | 78/88 [26:20<03:17, 19.75s/epoch, loss=1.1, accuracy=0.757, val_loss=2.52, val_accuracy=0.402, lr=0.0316] 90%|████████▉ | 79/88 [26:39<02:57, 19.76s/epoch, loss=1.09, accuracy=0.757, val_loss=2.46, val_accuracy=0.423, lr=0.1]   91%|█████████ | 80/88 [26:59<02:38, 19.78s/epoch, loss=1.1, accuracy=0.758, val_loss=2.14, val_accuracy=0.436, lr=0.1]  92%|█████████▏| 81/88 [27:19<02:18, 19.76s/epoch, loss=1.1, accuracy=0.756, val_loss=2.11, val_accuracy=0.463, lr=0.1] 93%|█████████▎| 82/88 [27:39<01:58, 19.77s/epoch, loss=0.894, accuracy=0.815, val_loss=0.931, val_accuracy=0.788, lr=0.01] 94%|█████████▍| 83/88 [27:58<01:38, 19.76s/epoch, loss=0.724, accuracy=0.845, val_loss=0.765, val_accuracy=0.819, lr=0.01] 95%|█████████▌| 84/88 [28:18<01:19, 19.78s/epoch, loss=0.643, accuracy=0.854, val_loss=0.885, val_accuracy=0.768, lr=0.01] 97%|█████████▋| 85/88 [28:38<00:59, 19.79s/epoch, loss=0.603, accuracy=0.856, val_loss=0.707, val_accuracy=0.822, lr=0.01] 98%|█████████▊| 86/88 [28:58<00:39, 19.77s/epoch, loss=0.583, accuracy=0.858, val_loss=0.844, val_accuracy=0.765, lr=0.01] 99%|█████████▉| 87/88 [29:18<00:19, 19.81s/epoch, loss=0.574, accuracy=0.859, val_loss=0.853, val_accuracy=0.763, lr=0.01]100%|██████████| 88/88 [29:37<00:00, 19.78s/epoch, loss=0.571, accuracy=0.858, val_loss=0.833, val_accuracy=0.779, lr=0.01]100%|██████████| 88/88 [29:37<00:00, 20.20s/epoch, loss=0.571, accuracy=0.858, val_loss=0.833, val_accuracy=0.779, lr=0.01]
Using real-time data augmentation.
Test score: 0.8332647681236267
Test accuracy: 0.7788000106811523


* * * Run SGD for ID = 17_16. * * *


2024-03-05 17:04:14.906069: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 17:04:18.637116: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 17:04:18.638290: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-05 17:04:18.675483: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-03-05 17:04:18.675528: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 17:04:18.678518: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 17:04:18.678557: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 17:04:18.680929: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 17:04:18.681727: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 17:04:18.684198: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 17:04:18.685627: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 17:04:18.690308: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 17:04:18.690940: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 17:04:18.691051: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 17:04:19.934252: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-05 17:04:19.934853: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 17:04:19.935599: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-03-05 17:04:19.935631: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 17:04:19.935668: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 17:04:19.935702: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 17:04:19.935719: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 17:04:19.935736: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 17:04:19.935752: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 17:04:19.935767: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 17:04:19.935783: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 17:04:19.936226: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 17:04:19.936264: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 17:04:20.574038: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-05 17:04:20.574093: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-05 17:04:20.574102: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-05 17:04:20.575030: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:02:00.0, compute capability: 6.1)
{'id': '17_16', 'seed': 16, 'out_folder': 'results/epoch_budget', 'batch_size': 128, 'epochs': 88, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'bootstrapping': False, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/88 [00:00<?, ?epoch/s]2024-03-05 17:04:21.436169: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-05 17:04:21.436735: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600020000 Hz
2024-03-05 17:04:23.459334: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 17:04:23.710033: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 17:04:24.658951: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-05 17:04:24.717932: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/88 [01:05<1:34:36, 65.25s/epoch, loss=3.27, accuracy=0.268, val_loss=2.96, val_accuracy=0.174, lr=0.1]  2%|▏         | 2/88 [01:25<55:43, 38.88s/epoch, loss=1.63, accuracy=0.497, val_loss=1.99, val_accuracy=0.415, lr=0.1]    3%|▎         | 3/88 [01:45<42:40, 30.12s/epoch, loss=1.37, accuracy=0.619, val_loss=2.12, val_accuracy=0.428, lr=0.1]  5%|▍         | 4/88 [02:05<36:49, 26.31s/epoch, loss=1.29, accuracy=0.674, val_loss=2.76, val_accuracy=0.403, lr=0.1]  6%|▌         | 5/88 [02:25<33:16, 24.05s/epoch, loss=1.24, accuracy=0.697, val_loss=1.75, val_accuracy=0.525, lr=0.1]  7%|▋         | 6/88 [02:46<31:03, 22.72s/epoch, loss=1.22, accuracy=0.711, val_loss=4.33, val_accuracy=0.312, lr=0.1]  8%|▊         | 7/88 [03:06<29:29, 21.85s/epoch, loss=1.21, accuracy=0.72, val_loss=2.58, val_accuracy=0.439, lr=0.1]   9%|▉         | 8/88 [03:26<28:24, 21.31s/epoch, loss=1.2, accuracy=0.726, val_loss=2, val_accuracy=0.482, lr=0.1]    10%|█         | 9/88 [03:46<27:34, 20.94s/epoch, loss=1.18, accuracy=0.731, val_loss=2.67, val_accuracy=0.446, lr=0.1] 11%|█▏        | 10/88 [04:06<26:53, 20.68s/epoch, loss=1.18, accuracy=0.734, val_loss=1.43, val_accuracy=0.646, lr=0.1] 12%|█▎        | 11/88 [04:26<26:22, 20.55s/epoch, loss=1.18, accuracy=0.735, val_loss=2.34, val_accuracy=0.455, lr=0.1] 14%|█▎        | 12/88 [04:46<25:53, 20.44s/epoch, loss=1.18, accuracy=0.739, val_loss=2.64, val_accuracy=0.414, lr=0.1] 15%|█▍        | 13/88 [05:07<25:27, 20.37s/epoch, loss=1.17, accuracy=0.739, val_loss=2.64, val_accuracy=0.508, lr=0.1] 16%|█▌        | 14/88 [05:27<25:03, 20.32s/epoch, loss=1.16, accuracy=0.742, val_loss=1.85, val_accuracy=0.542, lr=0.1] 17%|█▋        | 15/88 [05:47<24:40, 20.28s/epoch, loss=1.17, accuracy=0.742, val_loss=1.92, val_accuracy=0.473, lr=0.0316] 18%|█▊        | 16/88 [06:07<24:17, 20.25s/epoch, loss=1.16, accuracy=0.744, val_loss=1.83, val_accuracy=0.53, lr=0.1]     19%|█▉        | 17/88 [06:27<23:52, 20.18s/epoch, loss=1.17, accuracy=0.741, val_loss=2.72, val_accuracy=0.399, lr=0.1] 20%|██        | 18/88 [06:47<23:31, 20.17s/epoch, loss=1.16, accuracy=0.743, val_loss=2.17, val_accuracy=0.488, lr=0.1] 22%|██▏       | 19/88 [07:07<23:09, 20.14s/epoch, loss=1.16, accuracy=0.747, val_loss=1.68, val_accuracy=0.577, lr=0.1] 23%|██▎       | 20/88 [07:27<22:47, 20.11s/epoch, loss=1.15, accuracy=0.747, val_loss=2.9, val_accuracy=0.274, lr=0.0316] 24%|██▍       | 21/88 [07:48<22:28, 20.13s/epoch, loss=1.16, accuracy=0.745, val_loss=1.81, val_accuracy=0.533, lr=0.1]   25%|██▌       | 22/88 [08:08<22:10, 20.16s/epoch, loss=1.15, accuracy=0.747, val_loss=1.64, val_accuracy=0.592, lr=0.1] 26%|██▌       | 23/88 [08:28<21:51, 20.18s/epoch, loss=1.14, accuracy=0.748, val_loss=4.38, val_accuracy=0.261, lr=0.1] 27%|██▋       | 24/88 [08:48<21:31, 20.19s/epoch, loss=1.14, accuracy=0.751, val_loss=2.54, val_accuracy=0.447, lr=0.1] 28%|██▊       | 25/88 [09:08<21:09, 20.14s/epoch, loss=1.14, accuracy=0.75, val_loss=3.09, val_accuracy=0.392, lr=0.0316] 30%|██▉       | 26/88 [09:29<20:54, 20.23s/epoch, loss=1.14, accuracy=0.75, val_loss=2.23, val_accuracy=0.42, lr=0.1]     31%|███       | 27/88 [09:49<20:35, 20.26s/epoch, loss=1.14, accuracy=0.749, val_loss=1.77, val_accuracy=0.521, lr=0.1] 32%|███▏      | 28/88 [10:09<20:16, 20.27s/epoch, loss=1.14, accuracy=0.75, val_loss=2.42, val_accuracy=0.431, lr=0.1]  33%|███▎      | 29/88 [10:29<19:50, 20.18s/epoch, loss=1.14, accuracy=0.748, val_loss=2.14, val_accuracy=0.451, lr=0.1] 34%|███▍      | 30/88 [10:49<19:29, 20.16s/epoch, loss=1.14, accuracy=0.75, val_loss=1.71, val_accuracy=0.622, lr=0.0316] 35%|███▌      | 31/88 [11:10<19:07, 20.13s/epoch, loss=1.15, accuracy=0.749, val_loss=1.84, val_accuracy=0.477, lr=0.1]   36%|███▋      | 32/88 [11:30<18:46, 20.12s/epoch, loss=1.13, accuracy=0.755, val_loss=2.66, val_accuracy=0.323, lr=0.1] 38%|███▊      | 33/88 [11:50<18:25, 20.11s/epoch, loss=1.13, accuracy=0.753, val_loss=1.38, val_accuracy=0.673, lr=0.1] 39%|███▊      | 34/88 [12:10<18:02, 20.05s/epoch, loss=1.14, accuracy=0.753, val_loss=2.79, val_accuracy=0.332, lr=0.1] 40%|███▉      | 35/88 [12:30<17:44, 20.09s/epoch, loss=1.14, accuracy=0.752, val_loss=1.74, val_accuracy=0.554, lr=0.1] 41%|████      | 36/88 [12:50<17:23, 20.07s/epoch, loss=1.13, accuracy=0.754, val_loss=1.94, val_accuracy=0.539, lr=0.1] 42%|████▏     | 37/88 [13:10<17:05, 20.10s/epoch, loss=1.13, accuracy=0.753, val_loss=2.18, val_accuracy=0.514, lr=0.1] 43%|████▎     | 38/88 [13:30<16:46, 20.13s/epoch, loss=1.13, accuracy=0.754, val_loss=2.42, val_accuracy=0.44, lr=0.0316] 44%|████▍     | 39/88 [13:50<16:27, 20.15s/epoch, loss=1.13, accuracy=0.752, val_loss=3.16, val_accuracy=0.377, lr=0.1]   45%|████▌     | 40/88 [14:10<16:03, 20.08s/epoch, loss=1.13, accuracy=0.756, val_loss=2.05, val_accuracy=0.47, lr=0.1]  47%|████▋     | 41/88 [14:30<15:41, 20.02s/epoch, loss=1.13, accuracy=0.756, val_loss=2, val_accuracy=0.488, lr=0.1]   48%|████▊     | 42/88 [14:50<15:14, 19.89s/epoch, loss=1.13, accuracy=0.755, val_loss=2, val_accuracy=0.485, lr=0.1] 49%|████▉     | 43/88 [15:10<14:56, 19.92s/epoch, loss=1.12, accuracy=0.755, val_loss=1.89, val_accuracy=0.539, lr=0.0316] 50%|█████     | 44/88 [15:29<14:31, 19.81s/epoch, loss=1.12, accuracy=0.757, val_loss=1.8, val_accuracy=0.54, lr=0.1]      51%|█████     | 45/88 [15:50<14:16, 19.92s/epoch, loss=1.13, accuracy=0.759, val_loss=1.67, val_accuracy=0.557, lr=0.1] 52%|█████▏    | 46/88 [16:10<14:01, 20.03s/epoch, loss=1.12, accuracy=0.757, val_loss=2.32, val_accuracy=0.478, lr=0.1] 53%|█████▎    | 47/88 [16:30<13:41, 20.04s/epoch, loss=1.12, accuracy=0.756, val_loss=1.82, val_accuracy=0.534, lr=0.1] 55%|█████▍    | 48/88 [16:50<13:21, 20.05s/epoch, loss=1.12, accuracy=0.757, val_loss=2.37, val_accuracy=0.441, lr=0.0316] 56%|█████▌    | 49/88 [17:10<13:03, 20.09s/epoch, loss=1.12, accuracy=0.756, val_loss=2.56, val_accuracy=0.359, lr=0.1]    57%|█████▋    | 50/88 [17:30<12:43, 20.10s/epoch, loss=1.12, accuracy=0.758, val_loss=1.83, val_accuracy=0.52, lr=0.1]  58%|█████▊    | 51/88 [17:50<12:21, 20.04s/epoch, loss=1.12, accuracy=0.756, val_loss=4.25, val_accuracy=0.291, lr=0.1] 59%|█████▉    | 52/88 [18:10<11:59, 19.99s/epoch, loss=1.12, accuracy=0.757, val_loss=2.23, val_accuracy=0.523, lr=0.1] 60%|██████    | 53/88 [18:30<11:39, 19.99s/epoch, loss=1.12, accuracy=0.756, val_loss=1.99, val_accuracy=0.465, lr=0.0316] 61%|██████▏   | 54/88 [18:50<11:20, 20.00s/epoch, loss=1.12, accuracy=0.759, val_loss=4.97, val_accuracy=0.33, lr=0.1]     62%|██████▎   | 55/88 [19:10<11:01, 20.04s/epoch, loss=1.12, accuracy=0.759, val_loss=1.45, val_accuracy=0.635, lr=0.1] 64%|██████▎   | 56/88 [19:30<10:38, 19.95s/epoch, loss=1.12, accuracy=0.758, val_loss=4.17, val_accuracy=0.29, lr=0.1]  65%|██████▍   | 57/88 [19:50<10:18, 19.96s/epoch, loss=1.11, accuracy=0.76, val_loss=4.45, val_accuracy=0.288, lr=0.1] 66%|██████▌   | 58/88 [20:10<09:59, 20.00s/epoch, loss=1.11, accuracy=0.76, val_loss=1.68, val_accuracy=0.601, lr=0.0316] 67%|██████▋   | 59/88 [20:30<09:38, 19.96s/epoch, loss=1.12, accuracy=0.759, val_loss=3.95, val_accuracy=0.269, lr=0.1]   68%|██████▊   | 60/88 [20:50<09:19, 19.98s/epoch, loss=1.12, accuracy=0.756, val_loss=1.71, val_accuracy=0.542, lr=0.1] 69%|██████▉   | 61/88 [21:10<08:59, 19.98s/epoch, loss=1.11, accuracy=0.758, val_loss=2.11, val_accuracy=0.429, lr=0.1] 70%|███████   | 62/88 [21:29<08:36, 19.87s/epoch, loss=1.12, accuracy=0.758, val_loss=2.94, val_accuracy=0.395, lr=0.1] 72%|███████▏  | 63/88 [21:49<08:17, 19.88s/epoch, loss=1.12, accuracy=0.759, val_loss=2.43, val_accuracy=0.402, lr=0.0316] 73%|███████▎  | 64/88 [22:09<07:58, 19.92s/epoch, loss=1.11, accuracy=0.758, val_loss=1.75, val_accuracy=0.539, lr=0.1]    74%|███████▍  | 65/88 [22:29<07:38, 19.93s/epoch, loss=1.11, accuracy=0.76, val_loss=2.04, val_accuracy=0.496, lr=0.1]  75%|███████▌  | 66/88 [22:49<07:15, 19.79s/epoch, loss=1.12, accuracy=0.759, val_loss=3.22, val_accuracy=0.42, lr=0.1] 76%|███████▌  | 67/88 [23:09<06:57, 19.87s/epoch, loss=1.11, accuracy=0.758, val_loss=1.59, val_accuracy=0.591, lr=0.1] 77%|███████▋  | 68/88 [23:29<06:38, 19.91s/epoch, loss=1.11, accuracy=0.758, val_loss=1.88, val_accuracy=0.51, lr=0.0316] 78%|███████▊  | 69/88 [23:49<06:18, 19.91s/epoch, loss=1.11, accuracy=0.761, val_loss=2.13, val_accuracy=0.472, lr=0.1]   80%|███████▉  | 70/88 [24:09<05:58, 19.91s/epoch, loss=1.12, accuracy=0.759, val_loss=2.6, val_accuracy=0.455, lr=0.1]  81%|████████  | 71/88 [24:29<05:38, 19.92s/epoch, loss=1.11, accuracy=0.758, val_loss=1.64, val_accuracy=0.563, lr=0.1] 82%|████████▏ | 72/88 [24:49<05:19, 19.94s/epoch, loss=1.11, accuracy=0.761, val_loss=2.06, val_accuracy=0.488, lr=0.1] 83%|████████▎ | 73/88 [25:08<04:58, 19.92s/epoch, loss=1.11, accuracy=0.762, val_loss=2.34, val_accuracy=0.484, lr=0.0316] 84%|████████▍ | 74/88 [25:29<04:39, 19.99s/epoch, loss=1.11, accuracy=0.759, val_loss=1.64, val_accuracy=0.55, lr=0.1]     85%|████████▌ | 75/88 [25:49<04:20, 20.04s/epoch, loss=1.11, accuracy=0.759, val_loss=2.53, val_accuracy=0.433, lr=0.1] 86%|████████▋ | 76/88 [26:09<03:59, 19.95s/epoch, loss=1.12, accuracy=0.758, val_loss=2.45, val_accuracy=0.401, lr=0.1] 88%|████████▊ | 77/88 [26:29<03:39, 19.96s/epoch, loss=1.1, accuracy=0.761, val_loss=2.59, val_accuracy=0.426, lr=0.1]  89%|████████▊ | 78/88 [26:49<03:20, 20.01s/epoch, loss=1.11, accuracy=0.759, val_loss=1.61, val_accuracy=0.564, lr=0.0316] 90%|████████▉ | 79/88 [27:09<03:00, 20.03s/epoch, loss=1.1, accuracy=0.761, val_loss=1.55, val_accuracy=0.625, lr=0.1]     91%|█████████ | 80/88 [27:29<02:40, 20.07s/epoch, loss=1.11, accuracy=0.758, val_loss=1.76, val_accuracy=0.519, lr=0.1] 92%|█████████▏| 81/88 [27:49<02:20, 20.08s/epoch, loss=1.11, accuracy=0.76, val_loss=2.9, val_accuracy=0.339, lr=0.1]   93%|█████████▎| 82/88 [28:09<02:00, 20.13s/epoch, loss=0.901, accuracy=0.816, val_loss=0.911, val_accuracy=0.795, lr=0.01] 94%|█████████▍| 83/88 [28:29<01:40, 20.11s/epoch, loss=0.723, accuracy=0.848, val_loss=0.816, val_accuracy=0.806, lr=0.01] 95%|█████████▌| 84/88 [28:50<01:20, 20.14s/epoch, loss=0.643, accuracy=0.855, val_loss=0.758, val_accuracy=0.813, lr=0.01] 97%|█████████▋| 85/88 [29:10<01:00, 20.11s/epoch, loss=0.601, accuracy=0.861, val_loss=0.745, val_accuracy=0.813, lr=0.01] 98%|█████████▊| 86/88 [29:30<00:40, 20.08s/epoch, loss=0.578, accuracy=0.86, val_loss=0.745, val_accuracy=0.805, lr=0.01]  99%|█████████▉| 87/88 [29:50<00:20, 20.04s/epoch, loss=0.571, accuracy=0.862, val_loss=0.793, val_accuracy=0.785, lr=0.01]100%|██████████| 88/88 [30:10<00:00, 20.03s/epoch, loss=0.57, accuracy=0.863, val_loss=0.862, val_accuracy=0.763, lr=0.01] 100%|██████████| 88/88 [30:10<00:00, 20.57s/epoch, loss=0.57, accuracy=0.863, val_loss=0.862, val_accuracy=0.763, lr=0.01]
Using real-time data augmentation.
Test score: 0.8618456125259399
Test accuracy: 0.7634000182151794


* * * Run SGD for ID = 17_17. * * *


2024-03-05 17:34:36.177439: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 17:34:48.255906: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 17:34:48.257190: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-05 17:34:48.295509: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-03-05 17:34:48.295553: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 17:34:48.309652: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 17:34:48.309717: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 17:34:48.314275: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 17:34:48.317178: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 17:34:48.321268: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 17:34:48.324014: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 17:34:48.330319: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 17:34:48.330966: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 17:34:48.331068: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 17:34:49.606828: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-05 17:34:49.607378: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 17:34:49.607829: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-03-05 17:34:49.607871: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 17:34:49.607905: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 17:34:49.607922: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 17:34:49.607937: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 17:34:49.607953: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 17:34:49.607997: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 17:34:49.608014: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 17:34:49.608030: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 17:34:49.608459: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 17:34:49.608498: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 17:34:50.290523: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-05 17:34:50.290585: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-05 17:34:50.290594: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-05 17:34:50.291850: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:02:00.0, compute capability: 6.1)
{'id': '17_17', 'seed': 17, 'out_folder': 'results/epoch_budget', 'batch_size': 128, 'epochs': 88, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'bootstrapping': False, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/88 [00:00<?, ?epoch/s]2024-03-05 17:34:51.160266: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-05 17:34:51.172138: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600020000 Hz
2024-03-05 17:34:53.230244: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 17:34:53.498329: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 17:34:55.057051: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-05 17:34:55.104673: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/88 [00:58<1:24:54, 58.55s/epoch, loss=3.21, accuracy=0.298, val_loss=2.31, val_accuracy=0.269, lr=0.1]  2%|▏         | 2/88 [01:20<52:52, 36.89s/epoch, loss=1.63, accuracy=0.497, val_loss=2.15, val_accuracy=0.358, lr=0.1]    3%|▎         | 3/88 [01:41<42:06, 29.72s/epoch, loss=1.41, accuracy=0.611, val_loss=1.9, val_accuracy=0.472, lr=0.1]   5%|▍         | 4/88 [02:02<36:48, 26.30s/epoch, loss=1.32, accuracy=0.663, val_loss=1.63, val_accuracy=0.548, lr=0.1]  6%|▌         | 5/88 [02:23<33:44, 24.39s/epoch, loss=1.27, accuracy=0.691, val_loss=2.33, val_accuracy=0.456, lr=0.1]  7%|▋         | 6/88 [02:44<31:44, 23.23s/epoch, loss=1.25, accuracy=0.704, val_loss=1.96, val_accuracy=0.459, lr=0.1]  8%|▊         | 7/88 [03:05<30:24, 22.52s/epoch, loss=1.25, accuracy=0.708, val_loss=2.1, val_accuracy=0.516, lr=0.1]   9%|▉         | 8/88 [03:26<29:25, 22.07s/epoch, loss=1.23, accuracy=0.716, val_loss=1.67, val_accuracy=0.554, lr=0.1] 10%|█         | 9/88 [03:47<28:38, 21.76s/epoch, loss=1.23, accuracy=0.717, val_loss=2.11, val_accuracy=0.487, lr=0.0316] 11%|█▏        | 10/88 [04:08<28:02, 21.57s/epoch, loss=1.22, accuracy=0.725, val_loss=1.9, val_accuracy=0.529, lr=0.1]    12%|█▎        | 11/88 [04:29<27:27, 21.39s/epoch, loss=1.23, accuracy=0.723, val_loss=2, val_accuracy=0.502, lr=0.1]   14%|█▎        | 12/88 [04:50<26:51, 21.20s/epoch, loss=1.22, accuracy=0.727, val_loss=1.77, val_accuracy=0.536, lr=0.1] 15%|█▍        | 13/88 [05:11<26:23, 21.11s/epoch, loss=1.21, accuracy=0.73, val_loss=2.14, val_accuracy=0.429, lr=0.1]  16%|█▌        | 14/88 [05:32<25:57, 21.05s/epoch, loss=1.2, accuracy=0.732, val_loss=1.98, val_accuracy=0.53, lr=0.0316] 17%|█▋        | 15/88 [05:53<25:39, 21.09s/epoch, loss=1.2, accuracy=0.736, val_loss=1.41, val_accuracy=0.656, lr=0.1]   18%|█▊        | 16/88 [06:14<25:14, 21.04s/epoch, loss=1.2, accuracy=0.738, val_loss=1.53, val_accuracy=0.624, lr=0.1] 19%|█▉        | 17/88 [06:35<24:51, 21.00s/epoch, loss=1.19, accuracy=0.739, val_loss=1.69, val_accuracy=0.606, lr=0.1] 20%|██        | 18/88 [06:56<24:26, 20.95s/epoch, loss=1.19, accuracy=0.737, val_loss=2.26, val_accuracy=0.444, lr=0.1] 22%|██▏       | 19/88 [07:17<24:09, 21.01s/epoch, loss=1.19, accuracy=0.74, val_loss=1.69, val_accuracy=0.553, lr=0.1]  23%|██▎       | 20/88 [07:38<23:45, 20.97s/epoch, loss=1.19, accuracy=0.74, val_loss=1.7, val_accuracy=0.555, lr=0.0316] 24%|██▍       | 21/88 [07:59<23:27, 21.01s/epoch, loss=1.19, accuracy=0.739, val_loss=1.57, val_accuracy=0.591, lr=0.1]  25%|██▌       | 22/88 [08:20<23:05, 20.99s/epoch, loss=1.17, accuracy=0.741, val_loss=1.53, val_accuracy=0.618, lr=0.1] 26%|██▌       | 23/88 [08:41<22:44, 20.99s/epoch, loss=1.18, accuracy=0.74, val_loss=1.64, val_accuracy=0.587, lr=0.1]  27%|██▋       | 24/88 [09:02<22:23, 20.99s/epoch, loss=1.17, accuracy=0.744, val_loss=2.44, val_accuracy=0.507, lr=0.1] 28%|██▊       | 25/88 [09:23<22:01, 20.98s/epoch, loss=1.18, accuracy=0.742, val_loss=1.75, val_accuracy=0.594, lr=0.0316] 30%|██▉       | 26/88 [09:44<21:37, 20.94s/epoch, loss=1.17, accuracy=0.745, val_loss=1.62, val_accuracy=0.57, lr=0.1]     31%|███       | 27/88 [10:04<21:14, 20.90s/epoch, loss=1.17, accuracy=0.745, val_loss=1.66, val_accuracy=0.598, lr=0.1] 32%|███▏      | 28/88 [10:25<20:51, 20.86s/epoch, loss=1.17, accuracy=0.746, val_loss=1.82, val_accuracy=0.533, lr=0.1] 33%|███▎      | 29/88 [10:46<20:27, 20.81s/epoch, loss=1.17, accuracy=0.744, val_loss=4.12, val_accuracy=0.291, lr=0.1] 34%|███▍      | 30/88 [11:07<20:08, 20.83s/epoch, loss=1.16, accuracy=0.746, val_loss=1.86, val_accuracy=0.536, lr=0.0316] 35%|███▌      | 31/88 [11:28<19:46, 20.82s/epoch, loss=1.17, accuracy=0.748, val_loss=1.98, val_accuracy=0.511, lr=0.1]    36%|███▋      | 32/88 [11:48<19:25, 20.81s/epoch, loss=1.17, accuracy=0.749, val_loss=2.87, val_accuracy=0.418, lr=0.1] 38%|███▊      | 33/88 [12:09<19:03, 20.79s/epoch, loss=1.17, accuracy=0.747, val_loss=3.85, val_accuracy=0.315, lr=0.1] 39%|███▊      | 34/88 [12:30<18:42, 20.79s/epoch, loss=1.17, accuracy=0.748, val_loss=1.73, val_accuracy=0.542, lr=0.1] 40%|███▉      | 35/88 [12:51<18:20, 20.77s/epoch, loss=1.16, accuracy=0.748, val_loss=1.6, val_accuracy=0.605, lr=0.0316] 41%|████      | 36/88 [13:11<17:58, 20.75s/epoch, loss=1.16, accuracy=0.746, val_loss=2.67, val_accuracy=0.366, lr=0.1]   42%|████▏     | 37/88 [13:32<17:40, 20.79s/epoch, loss=1.16, accuracy=0.749, val_loss=3.88, val_accuracy=0.241, lr=0.1] 43%|████▎     | 38/88 [13:53<17:18, 20.77s/epoch, loss=1.16, accuracy=0.748, val_loss=4.27, val_accuracy=0.219, lr=0.1] 44%|████▍     | 39/88 [14:14<16:58, 20.78s/epoch, loss=1.16, accuracy=0.751, val_loss=2.68, val_accuracy=0.449, lr=0.1] 45%|████▌     | 40/88 [14:35<16:38, 20.79s/epoch, loss=1.15, accuracy=0.75, val_loss=2.28, val_accuracy=0.352, lr=0.0316] 47%|████▋     | 41/88 [14:55<16:16, 20.78s/epoch, loss=1.16, accuracy=0.747, val_loss=1.81, val_accuracy=0.497, lr=0.1]   48%|████▊     | 42/88 [15:16<15:57, 20.81s/epoch, loss=1.16, accuracy=0.751, val_loss=2.81, val_accuracy=0.4, lr=0.1]   49%|████▉     | 43/88 [15:37<15:37, 20.82s/epoch, loss=1.15, accuracy=0.748, val_loss=1.83, val_accuracy=0.581, lr=0.1] 50%|█████     | 44/88 [15:58<15:16, 20.83s/epoch, loss=1.15, accuracy=0.75, val_loss=1.52, val_accuracy=0.614, lr=0.1]  51%|█████     | 45/88 [16:19<14:56, 20.86s/epoch, loss=1.15, accuracy=0.75, val_loss=2.46, val_accuracy=0.436, lr=0.0316] 52%|█████▏    | 46/88 [16:40<14:37, 20.89s/epoch, loss=1.15, accuracy=0.749, val_loss=1.85, val_accuracy=0.523, lr=0.1]   53%|█████▎    | 47/88 [17:01<14:17, 20.92s/epoch, loss=1.15, accuracy=0.754, val_loss=2.54, val_accuracy=0.437, lr=0.1] 55%|█████▍    | 48/88 [17:22<13:55, 20.88s/epoch, loss=1.15, accuracy=0.752, val_loss=1.65, val_accuracy=0.598, lr=0.1] 56%|█████▌    | 49/88 [17:43<13:35, 20.91s/epoch, loss=1.14, accuracy=0.751, val_loss=1.62, val_accuracy=0.575, lr=0.1] 57%|█████▋    | 50/88 [18:04<13:15, 20.93s/epoch, loss=1.15, accuracy=0.754, val_loss=1.33, val_accuracy=0.691, lr=0.1] 58%|█████▊    | 51/88 [18:24<12:54, 20.94s/epoch, loss=1.14, accuracy=0.751, val_loss=1.85, val_accuracy=0.489, lr=0.1] 59%|█████▉    | 52/88 [18:45<12:33, 20.94s/epoch, loss=1.15, accuracy=0.751, val_loss=1.81, val_accuracy=0.541, lr=0.1] 60%|██████    | 53/88 [19:06<12:14, 20.98s/epoch, loss=1.15, accuracy=0.752, val_loss=1.98, val_accuracy=0.556, lr=0.1] 61%|██████▏   | 54/88 [19:28<11:54, 21.01s/epoch, loss=1.14, accuracy=0.754, val_loss=2.21, val_accuracy=0.477, lr=0.1] 62%|██████▎   | 55/88 [19:49<11:33, 21.00s/epoch, loss=1.15, accuracy=0.753, val_loss=1.48, val_accuracy=0.637, lr=0.0316] 64%|██████▎   | 56/88 [20:10<11:11, 20.99s/epoch, loss=1.14, accuracy=0.754, val_loss=2.25, val_accuracy=0.441, lr=0.1]    65%|██████▍   | 57/88 [20:31<10:52, 21.06s/epoch, loss=1.15, accuracy=0.751, val_loss=1.78, val_accuracy=0.528, lr=0.1] 66%|██████▌   | 58/88 [20:52<10:30, 21.02s/epoch, loss=1.15, accuracy=0.751, val_loss=1.39, val_accuracy=0.654, lr=0.1] 67%|██████▋   | 59/88 [21:13<10:08, 21.00s/epoch, loss=1.15, accuracy=0.756, val_loss=2.67, val_accuracy=0.38, lr=0.1]  68%|██████▊   | 60/88 [21:34<09:48, 21.02s/epoch, loss=1.14, accuracy=0.755, val_loss=2.19, val_accuracy=0.449, lr=0.0316] 69%|██████▉   | 61/88 [21:55<09:27, 21.00s/epoch, loss=1.14, accuracy=0.753, val_loss=1.45, val_accuracy=0.633, lr=0.1]    70%|███████   | 62/88 [22:16<09:05, 21.00s/epoch, loss=1.14, accuracy=0.754, val_loss=1.89, val_accuracy=0.528, lr=0.1] 72%|███████▏  | 63/88 [22:36<08:43, 20.95s/epoch, loss=1.14, accuracy=0.752, val_loss=1.61, val_accuracy=0.591, lr=0.1] 73%|███████▎  | 64/88 [22:58<08:23, 20.99s/epoch, loss=1.14, accuracy=0.754, val_loss=1.86, val_accuracy=0.544, lr=0.1] 74%|███████▍  | 65/88 [23:18<08:02, 20.96s/epoch, loss=1.15, accuracy=0.754, val_loss=2.13, val_accuracy=0.435, lr=0.0316] 75%|███████▌  | 66/88 [23:39<07:40, 20.92s/epoch, loss=1.14, accuracy=0.753, val_loss=1.93, val_accuracy=0.495, lr=0.1]    76%|███████▌  | 67/88 [24:00<07:18, 20.89s/epoch, loss=1.14, accuracy=0.753, val_loss=1.61, val_accuracy=0.573, lr=0.1] 77%|███████▋  | 68/88 [24:21<06:57, 20.88s/epoch, loss=1.14, accuracy=0.752, val_loss=1.52, val_accuracy=0.626, lr=0.1] 78%|███████▊  | 69/88 [24:42<06:36, 20.86s/epoch, loss=1.14, accuracy=0.755, val_loss=2.12, val_accuracy=0.461, lr=0.1] 80%|███████▉  | 70/88 [25:03<06:15, 20.86s/epoch, loss=1.14, accuracy=0.754, val_loss=2.25, val_accuracy=0.404, lr=0.0316] 81%|████████  | 71/88 [25:23<05:54, 20.85s/epoch, loss=1.14, accuracy=0.753, val_loss=1.49, val_accuracy=0.646, lr=0.1]    82%|████████▏ | 72/88 [25:44<05:33, 20.85s/epoch, loss=1.14, accuracy=0.751, val_loss=1.76, val_accuracy=0.57, lr=0.1]  83%|████████▎ | 73/88 [26:05<05:12, 20.82s/epoch, loss=1.13, accuracy=0.753, val_loss=2.65, val_accuracy=0.414, lr=0.1] 84%|████████▍ | 74/88 [26:26<04:51, 20.82s/epoch, loss=1.14, accuracy=0.753, val_loss=1.57, val_accuracy=0.601, lr=0.1] 85%|████████▌ | 75/88 [26:47<04:30, 20.83s/epoch, loss=1.14, accuracy=0.754, val_loss=1.92, val_accuracy=0.526, lr=0.0316] 86%|████████▋ | 76/88 [27:08<04:10, 20.85s/epoch, loss=1.13, accuracy=0.755, val_loss=1.69, val_accuracy=0.588, lr=0.1]    88%|████████▊ | 77/88 [27:28<03:49, 20.85s/epoch, loss=1.14, accuracy=0.754, val_loss=2.38, val_accuracy=0.353, lr=0.1] 89%|████████▊ | 78/88 [27:49<03:28, 20.85s/epoch, loss=1.13, accuracy=0.757, val_loss=1.75, val_accuracy=0.562, lr=0.1] 90%|████████▉ | 79/88 [28:10<03:07, 20.82s/epoch, loss=1.13, accuracy=0.756, val_loss=1.48, val_accuracy=0.633, lr=0.1] 91%|█████████ | 80/88 [28:31<02:47, 20.88s/epoch, loss=1.14, accuracy=0.755, val_loss=1.6, val_accuracy=0.626, lr=0.0316] 92%|█████████▏| 81/88 [28:52<02:25, 20.77s/epoch, loss=1.14, accuracy=0.752, val_loss=1.82, val_accuracy=0.518, lr=0.1]   93%|█████████▎| 82/88 [29:12<02:04, 20.69s/epoch, loss=0.923, accuracy=0.814, val_loss=0.861, val_accuracy=0.821, lr=0.01] 94%|█████████▍| 83/88 [29:33<01:43, 20.67s/epoch, loss=0.742, accuracy=0.847, val_loss=0.793, val_accuracy=0.815, lr=0.01] 95%|█████████▌| 84/88 [29:53<01:22, 20.61s/epoch, loss=0.659, accuracy=0.854, val_loss=0.753, val_accuracy=0.814, lr=0.01] 97%|█████████▋| 85/88 [30:14<01:01, 20.65s/epoch, loss=0.615, accuracy=0.857, val_loss=0.792, val_accuracy=0.799, lr=0.01] 98%|█████████▊| 86/88 [30:35<00:41, 20.65s/epoch, loss=0.596, accuracy=0.858, val_loss=0.744, val_accuracy=0.807, lr=0.01] 99%|█████████▉| 87/88 [30:55<00:20, 20.64s/epoch, loss=0.579, accuracy=0.861, val_loss=0.679, val_accuracy=0.826, lr=0.01]100%|██████████| 88/88 [31:16<00:00, 20.69s/epoch, loss=0.579, accuracy=0.861, val_loss=0.732, val_accuracy=0.812, lr=0.01]100%|██████████| 88/88 [31:16<00:00, 21.32s/epoch, loss=0.579, accuracy=0.861, val_loss=0.732, val_accuracy=0.812, lr=0.01]
Using real-time data augmentation.
Test score: 0.7323535084724426
Test accuracy: 0.8116999864578247
