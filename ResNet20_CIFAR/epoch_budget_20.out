Thu Feb 15 20:17:48 2024       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA TITAN X (Pascal)        Off | 00000000:83:00.0 Off |                  N/A |
| 50%   82C    P0              99W / 250W |      0MiB / 12288MiB |     49%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|  No running processes found                                                           |
+---------------------------------------------------------------------------------------+


* * * Run SGD for cluster size = 20. * * *


Budget: 75


* * * Run SGD for ID = 20_1. * * *


2024-02-15 20:17:49.551422: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 20:17:53.072762: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 20:17:53.073917: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-15 20:17:53.110450: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-15 20:17:53.110483: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 20:17:53.113439: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 20:17:53.113477: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 20:17:53.115894: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 20:17:53.116749: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 20:17:53.119136: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 20:17:53.120618: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 20:17:53.125161: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 20:17:53.125697: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 20:17:53.125765: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 20:17:54.337448: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-15 20:17:54.338715: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 20:17:54.339333: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-15 20:17:54.339364: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 20:17:54.339415: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 20:17:54.339434: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 20:17:54.339452: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 20:17:54.339470: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 20:17:54.339488: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 20:17:54.339505: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 20:17:54.339524: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 20:17:54.339973: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 20:17:54.340004: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 20:17:54.971998: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-15 20:17:54.972064: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-15 20:17:54.972074: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-15 20:17:54.972971: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': 201, 'batch_size': 128, 'epochs': 75, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/75 [00:00<?, ?epoch/s]2024-02-15 20:17:55.749545: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-15 20:17:55.761404: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2599900000 Hz
2024-02-15 20:17:57.623379: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 20:17:57.863989: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 20:17:58.817789: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-15 20:17:58.929843: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|▏         | 1/75 [00:58<1:11:36, 58.06s/epoch, loss=3.39, accuracy=0.261, val_loss=2.33, val_accuracy=0.262, lr=0.1]  3%|▎         | 2/75 [01:20<44:54, 36.91s/epoch, loss=1.64, accuracy=0.49, val_loss=2.21, val_accuracy=0.315, lr=0.1]     4%|▍         | 3/75 [01:41<35:39, 29.72s/epoch, loss=1.38, accuracy=0.621, val_loss=2.31, val_accuracy=0.356, lr=0.1]  5%|▌         | 4/75 [02:03<31:33, 26.67s/epoch, loss=1.29, accuracy=0.676, val_loss=1.84, val_accuracy=0.501, lr=0.1]  7%|▋         | 5/75 [02:25<29:25, 25.23s/epoch, loss=1.26, accuracy=0.696, val_loss=1.55, val_accuracy=0.593, lr=0.1]  8%|▊         | 6/75 [02:48<27:58, 24.33s/epoch, loss=1.24, accuracy=0.708, val_loss=1.56, val_accuracy=0.603, lr=0.1]  9%|▉         | 7/75 [03:11<27:00, 23.84s/epoch, loss=1.22, accuracy=0.718, val_loss=2.19, val_accuracy=0.43, lr=0.1]  11%|█         | 8/75 [03:34<26:10, 23.44s/epoch, loss=1.21, accuracy=0.724, val_loss=2.15, val_accuracy=0.424, lr=0.1] 12%|█▏        | 9/75 [03:56<25:28, 23.16s/epoch, loss=1.21, accuracy=0.723, val_loss=1.66, val_accuracy=0.588, lr=0.1] 13%|█▎        | 10/75 [04:19<24:58, 23.06s/epoch, loss=1.2, accuracy=0.729, val_loss=1.86, val_accuracy=0.492, lr=0.0316] 15%|█▍        | 11/75 [04:41<24:23, 22.86s/epoch, loss=1.19, accuracy=0.733, val_loss=1.85, val_accuracy=0.507, lr=0.1]   16%|█▌        | 12/75 [05:04<24:00, 22.87s/epoch, loss=1.19, accuracy=0.734, val_loss=3.16, val_accuracy=0.345, lr=0.1] 17%|█▋        | 13/75 [05:27<23:41, 22.92s/epoch, loss=1.18, accuracy=0.736, val_loss=1.96, val_accuracy=0.51, lr=0.1]  19%|█▊        | 14/75 [05:50<23:16, 22.89s/epoch, loss=1.18, accuracy=0.741, val_loss=2.14, val_accuracy=0.456, lr=0.1] 20%|██        | 15/75 [06:13<22:54, 22.90s/epoch, loss=1.18, accuracy=0.741, val_loss=4, val_accuracy=0.301, lr=0.0316] 21%|██▏       | 16/75 [06:36<22:29, 22.87s/epoch, loss=1.18, accuracy=0.741, val_loss=2.09, val_accuracy=0.496, lr=0.1] 23%|██▎       | 17/75 [06:59<22:07, 22.90s/epoch, loss=1.17, accuracy=0.741, val_loss=3.27, val_accuracy=0.367, lr=0.1] 24%|██▍       | 18/75 [07:22<21:47, 22.94s/epoch, loss=1.17, accuracy=0.741, val_loss=2.45, val_accuracy=0.385, lr=0.1] 25%|██▌       | 19/75 [07:44<21:12, 22.72s/epoch, loss=1.16, accuracy=0.745, val_loss=1.39, val_accuracy=0.674, lr=0.1] 27%|██▋       | 20/75 [08:07<20:51, 22.75s/epoch, loss=1.16, accuracy=0.742, val_loss=2.28, val_accuracy=0.463, lr=0.1] 28%|██▊       | 21/75 [08:30<20:28, 22.76s/epoch, loss=1.17, accuracy=0.743, val_loss=1.51, val_accuracy=0.639, lr=0.1] 29%|██▉       | 22/75 [08:53<20:09, 22.82s/epoch, loss=1.16, accuracy=0.747, val_loss=1.89, val_accuracy=0.531, lr=0.1] 31%|███       | 23/75 [09:15<19:46, 22.82s/epoch, loss=1.16, accuracy=0.748, val_loss=1.99, val_accuracy=0.508, lr=0.1] 32%|███▏      | 24/75 [09:38<19:26, 22.88s/epoch, loss=1.16, accuracy=0.745, val_loss=2.62, val_accuracy=0.409, lr=0.0316] 33%|███▎      | 25/75 [09:59<18:32, 22.26s/epoch, loss=1.15, accuracy=0.75, val_loss=1.74, val_accuracy=0.563, lr=0.1]     35%|███▍      | 26/75 [10:22<18:23, 22.52s/epoch, loss=1.15, accuracy=0.748, val_loss=2.43, val_accuracy=0.317, lr=0.1] 36%|███▌      | 27/75 [10:45<18:06, 22.64s/epoch, loss=1.16, accuracy=0.749, val_loss=1.69, val_accuracy=0.59, lr=0.1]  37%|███▋      | 28/75 [11:08<17:43, 22.64s/epoch, loss=1.15, accuracy=0.751, val_loss=1.77, val_accuracy=0.554, lr=0.1] 39%|███▊      | 29/75 [11:31<17:22, 22.67s/epoch, loss=1.15, accuracy=0.751, val_loss=1.6, val_accuracy=0.59, lr=0.0316] 40%|████      | 30/75 [11:53<17:01, 22.70s/epoch, loss=1.15, accuracy=0.752, val_loss=2.88, val_accuracy=0.311, lr=0.1]  41%|████▏     | 31/75 [12:16<16:32, 22.55s/epoch, loss=1.14, accuracy=0.753, val_loss=2.07, val_accuracy=0.455, lr=0.1] 43%|████▎     | 32/75 [12:39<16:15, 22.68s/epoch, loss=1.15, accuracy=0.749, val_loss=2.1, val_accuracy=0.467, lr=0.1]  44%|████▍     | 33/75 [13:02<15:56, 22.77s/epoch, loss=1.15, accuracy=0.751, val_loss=2.2, val_accuracy=0.354, lr=0.1] 45%|████▌     | 34/75 [13:24<15:34, 22.80s/epoch, loss=1.15, accuracy=0.748, val_loss=3.13, val_accuracy=0.224, lr=0.0316] 47%|████▋     | 35/75 [13:47<15:09, 22.73s/epoch, loss=1.14, accuracy=0.755, val_loss=1.83, val_accuracy=0.515, lr=0.1]    48%|████▊     | 36/75 [14:10<14:46, 22.72s/epoch, loss=1.14, accuracy=0.751, val_loss=2.47, val_accuracy=0.447, lr=0.1] 49%|████▉     | 37/75 [14:32<14:21, 22.68s/epoch, loss=1.14, accuracy=0.751, val_loss=2.12, val_accuracy=0.513, lr=0.1] 51%|█████     | 38/75 [14:55<14:00, 22.72s/epoch, loss=1.14, accuracy=0.752, val_loss=1.93, val_accuracy=0.541, lr=0.1] 52%|█████▏    | 39/75 [15:18<13:39, 22.77s/epoch, loss=1.14, accuracy=0.753, val_loss=1.69, val_accuracy=0.545, lr=0.0316] 53%|█████▎    | 40/75 [15:41<13:16, 22.75s/epoch, loss=1.14, accuracy=0.754, val_loss=2.66, val_accuracy=0.375, lr=0.1]    55%|█████▍    | 41/75 [16:03<12:53, 22.76s/epoch, loss=1.15, accuracy=0.752, val_loss=2.25, val_accuracy=0.415, lr=0.1] 56%|█████▌    | 42/75 [16:26<12:32, 22.79s/epoch, loss=1.14, accuracy=0.752, val_loss=1.5, val_accuracy=0.637, lr=0.1]  57%|█████▋    | 43/75 [16:49<12:09, 22.79s/epoch, loss=1.15, accuracy=0.752, val_loss=2.42, val_accuracy=0.436, lr=0.1] 59%|█████▊    | 44/75 [17:12<11:47, 22.83s/epoch, loss=1.14, accuracy=0.753, val_loss=1.92, val_accuracy=0.525, lr=0.0316] 60%|██████    | 45/75 [17:35<11:25, 22.83s/epoch, loss=1.13, accuracy=0.757, val_loss=1.61, val_accuracy=0.593, lr=0.1]    61%|██████▏   | 46/75 [17:58<11:01, 22.81s/epoch, loss=1.14, accuracy=0.753, val_loss=2.07, val_accuracy=0.496, lr=0.1] 63%|██████▎   | 47/75 [18:20<10:36, 22.74s/epoch, loss=1.13, accuracy=0.755, val_loss=1.75, val_accuracy=0.544, lr=0.1] 64%|██████▍   | 48/75 [18:43<10:15, 22.80s/epoch, loss=1.14, accuracy=0.752, val_loss=1.92, val_accuracy=0.518, lr=0.1] 65%|██████▌   | 49/75 [19:06<09:54, 22.86s/epoch, loss=1.15, accuracy=0.751, val_loss=2.43, val_accuracy=0.323, lr=0.0316] 67%|██████▋   | 50/75 [19:29<09:31, 22.86s/epoch, loss=1.13, accuracy=0.754, val_loss=2.77, val_accuracy=0.376, lr=0.1]    68%|██████▊   | 51/75 [19:52<09:08, 22.85s/epoch, loss=1.14, accuracy=0.755, val_loss=3.01, val_accuracy=0.293, lr=0.1] 69%|██████▉   | 52/75 [20:15<08:46, 22.91s/epoch, loss=1.13, accuracy=0.755, val_loss=1.95, val_accuracy=0.531, lr=0.1] 71%|███████   | 53/75 [20:37<08:20, 22.77s/epoch, loss=1.13, accuracy=0.755, val_loss=2.63, val_accuracy=0.396, lr=0.1] 72%|███████▏  | 54/75 [21:00<07:59, 22.81s/epoch, loss=1.14, accuracy=0.755, val_loss=1.56, val_accuracy=0.599, lr=0.0316] 73%|███████▎  | 55/75 [21:23<07:36, 22.83s/epoch, loss=1.13, accuracy=0.756, val_loss=2.31, val_accuracy=0.386, lr=0.1]    75%|███████▍  | 56/75 [21:46<07:13, 22.84s/epoch, loss=1.14, accuracy=0.755, val_loss=2.77, val_accuracy=0.352, lr=0.1] 76%|███████▌  | 57/75 [22:09<06:52, 22.91s/epoch, loss=1.14, accuracy=0.752, val_loss=2.18, val_accuracy=0.467, lr=0.1] 77%|███████▋  | 58/75 [22:32<06:29, 22.93s/epoch, loss=1.14, accuracy=0.754, val_loss=2.23, val_accuracy=0.489, lr=0.1] 79%|███████▊  | 59/75 [22:55<06:05, 22.82s/epoch, loss=1.13, accuracy=0.758, val_loss=3.12, val_accuracy=0.272, lr=0.0316] 80%|████████  | 60/75 [23:17<05:42, 22.84s/epoch, loss=1.14, accuracy=0.752, val_loss=2.04, val_accuracy=0.534, lr=0.1]    81%|████████▏ | 61/75 [23:40<05:20, 22.86s/epoch, loss=1.14, accuracy=0.755, val_loss=1.58, val_accuracy=0.61, lr=0.1]  83%|████████▎ | 62/75 [24:03<04:57, 22.85s/epoch, loss=1.14, accuracy=0.753, val_loss=1.84, val_accuracy=0.508, lr=0.1] 84%|████████▍ | 63/75 [24:26<04:34, 22.87s/epoch, loss=1.13, accuracy=0.758, val_loss=1.67, val_accuracy=0.556, lr=0.1] 85%|████████▌ | 64/75 [24:49<04:11, 22.90s/epoch, loss=1.14, accuracy=0.752, val_loss=1.95, val_accuracy=0.487, lr=0.0316] 87%|████████▋ | 65/75 [25:12<03:49, 22.94s/epoch, loss=1.13, accuracy=0.756, val_loss=2.49, val_accuracy=0.439, lr=0.1]    88%|████████▊ | 66/75 [25:35<03:25, 22.86s/epoch, loss=1.13, accuracy=0.756, val_loss=1.48, val_accuracy=0.629, lr=0.1] 89%|████████▉ | 67/75 [25:58<03:03, 22.92s/epoch, loss=1.13, accuracy=0.755, val_loss=3.07, val_accuracy=0.349, lr=0.1] 91%|█████████ | 68/75 [26:21<02:40, 22.87s/epoch, loss=1.13, accuracy=0.756, val_loss=4.81, val_accuracy=0.183, lr=0.1] 92%|█████████▏| 69/75 [26:44<02:17, 22.94s/epoch, loss=1.13, accuracy=0.758, val_loss=1.99, val_accuracy=0.485, lr=0.0316] 93%|█████████▎| 70/75 [27:07<01:54, 22.98s/epoch, loss=1.14, accuracy=0.753, val_loss=1.97, val_accuracy=0.431, lr=0.1]    95%|█████████▍| 71/75 [27:30<01:31, 22.97s/epoch, loss=1.13, accuracy=0.755, val_loss=1.73, val_accuracy=0.571, lr=0.1] 96%|█████████▌| 72/75 [27:53<01:08, 22.98s/epoch, loss=1.12, accuracy=0.754, val_loss=1.96, val_accuracy=0.507, lr=0.1] 97%|█████████▋| 73/75 [28:14<00:44, 22.50s/epoch, loss=1.13, accuracy=0.759, val_loss=1.8, val_accuracy=0.548, lr=0.1]  99%|█████████▊| 74/75 [28:36<00:22, 22.44s/epoch, loss=1.13, accuracy=0.755, val_loss=1.58, val_accuracy=0.577, lr=0.0316]100%|██████████| 75/75 [28:59<00:00, 22.47s/epoch, loss=1.14, accuracy=0.754, val_loss=1.9, val_accuracy=0.506, lr=0.1]    100%|██████████| 75/75 [28:59<00:00, 23.19s/epoch, loss=1.14, accuracy=0.754, val_loss=1.9, val_accuracy=0.506, lr=0.1]
Using real-time data augmentation.
Test loss: 1.9029581546783447
Test accuracy: 0.5060999989509583


* * * Run SGD for ID = 20_2. * * *


2024-02-15 20:46:57.868048: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 20:47:00.520083: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 20:47:00.521246: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-15 20:47:00.557139: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-15 20:47:00.557170: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 20:47:00.559952: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 20:47:00.559990: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 20:47:00.562190: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 20:47:00.562851: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 20:47:00.565141: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 20:47:00.566571: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 20:47:00.571086: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 20:47:00.571618: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 20:47:00.571700: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 20:47:01.754713: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-15 20:47:01.755822: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 20:47:01.756477: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-15 20:47:01.756508: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 20:47:01.756559: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 20:47:01.756596: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 20:47:01.756631: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 20:47:01.756649: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 20:47:01.756666: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 20:47:01.756683: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 20:47:01.756700: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 20:47:01.757099: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 20:47:01.757131: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 20:47:02.363649: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-15 20:47:02.363728: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-15 20:47:02.363738: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-15 20:47:02.364671: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': 202, 'batch_size': 128, 'epochs': 75, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/75 [00:00<?, ?epoch/s]2024-02-15 20:47:03.127297: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-15 20:47:03.139396: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2599900000 Hz
2024-02-15 20:47:04.947518: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 20:47:05.148184: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 20:47:06.203419: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-15 20:47:06.241521: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|▏         | 1/75 [00:49<1:00:48, 49.31s/epoch, loss=3.25, accuracy=0.253, val_loss=2.21, val_accuracy=0.27, lr=0.1]  3%|▎         | 2/75 [01:09<39:22, 32.36s/epoch, loss=1.65, accuracy=0.476, val_loss=2.37, val_accuracy=0.318, lr=0.1]   4%|▍         | 3/75 [01:31<32:43, 27.27s/epoch, loss=1.4, accuracy=0.6, val_loss=2.05, val_accuracy=0.437, lr=0.1]     5%|▌         | 4/75 [01:53<30:01, 25.37s/epoch, loss=1.29, accuracy=0.667, val_loss=2.87, val_accuracy=0.444, lr=0.1]  7%|▋         | 5/75 [02:13<27:31, 23.60s/epoch, loss=1.25, accuracy=0.693, val_loss=1.97, val_accuracy=0.469, lr=0.1]  8%|▊         | 6/75 [02:36<26:46, 23.29s/epoch, loss=1.23, accuracy=0.707, val_loss=1.69, val_accuracy=0.537, lr=0.1]  9%|▉         | 7/75 [02:59<26:09, 23.08s/epoch, loss=1.22, accuracy=0.713, val_loss=1.6, val_accuracy=0.565, lr=0.1]  11%|█         | 8/75 [03:21<25:30, 22.84s/epoch, loss=1.2, accuracy=0.72, val_loss=2, val_accuracy=0.496, lr=0.1]     12%|█▏        | 9/75 [03:43<24:57, 22.69s/epoch, loss=1.2, accuracy=0.726, val_loss=1.89, val_accuracy=0.506, lr=0.1] 13%|█▎        | 10/75 [04:06<24:32, 22.66s/epoch, loss=1.19, accuracy=0.729, val_loss=2.25, val_accuracy=0.439, lr=0.1] 15%|█▍        | 11/75 [04:28<24:03, 22.55s/epoch, loss=1.19, accuracy=0.73, val_loss=2.65, val_accuracy=0.439, lr=0.1]  16%|█▌        | 12/75 [04:51<23:40, 22.55s/epoch, loss=1.19, accuracy=0.734, val_loss=2.46, val_accuracy=0.462, lr=0.0316] 17%|█▋        | 13/75 [05:13<23:14, 22.49s/epoch, loss=1.19, accuracy=0.735, val_loss=2.26, val_accuracy=0.488, lr=0.1]    19%|█▊        | 14/75 [05:36<22:53, 22.51s/epoch, loss=1.18, accuracy=0.741, val_loss=2.08, val_accuracy=0.464, lr=0.1] 20%|██        | 15/75 [05:59<22:36, 22.61s/epoch, loss=1.18, accuracy=0.742, val_loss=1.59, val_accuracy=0.595, lr=0.1] 21%|██▏       | 16/75 [06:21<22:01, 22.41s/epoch, loss=1.17, accuracy=0.743, val_loss=1.78, val_accuracy=0.539, lr=0.1] 23%|██▎       | 17/75 [06:43<21:41, 22.45s/epoch, loss=1.18, accuracy=0.741, val_loss=1.64, val_accuracy=0.618, lr=0.1] 24%|██▍       | 18/75 [07:06<21:24, 22.53s/epoch, loss=1.18, accuracy=0.743, val_loss=1.59, val_accuracy=0.605, lr=0.1] 25%|██▌       | 19/75 [07:29<21:04, 22.58s/epoch, loss=1.17, accuracy=0.743, val_loss=2.24, val_accuracy=0.422, lr=0.1] 27%|██▋       | 20/75 [07:51<20:45, 22.65s/epoch, loss=1.18, accuracy=0.742, val_loss=1.51, val_accuracy=0.629, lr=0.1] 28%|██▊       | 21/75 [08:14<20:15, 22.50s/epoch, loss=1.18, accuracy=0.742, val_loss=2.07, val_accuracy=0.517, lr=0.1] 29%|██▉       | 22/75 [08:36<19:53, 22.53s/epoch, loss=1.18, accuracy=0.743, val_loss=1.58, val_accuracy=0.623, lr=0.1] 31%|███       | 23/75 [08:58<19:26, 22.43s/epoch, loss=1.18, accuracy=0.743, val_loss=1.89, val_accuracy=0.535, lr=0.1] 32%|███▏      | 24/75 [09:21<19:05, 22.47s/epoch, loss=1.17, accuracy=0.746, val_loss=1.72, val_accuracy=0.559, lr=0.1] 33%|███▎      | 25/75 [09:43<18:42, 22.45s/epoch, loss=1.17, accuracy=0.746, val_loss=1.64, val_accuracy=0.605, lr=0.0316] 35%|███▍      | 26/75 [10:06<18:21, 22.48s/epoch, loss=1.17, accuracy=0.745, val_loss=2.89, val_accuracy=0.411, lr=0.1]    36%|███▌      | 27/75 [10:28<17:51, 22.33s/epoch, loss=1.16, accuracy=0.749, val_loss=1.76, val_accuracy=0.536, lr=0.1] 37%|███▋      | 28/75 [10:50<17:20, 22.14s/epoch, loss=1.15, accuracy=0.751, val_loss=1.88, val_accuracy=0.495, lr=0.1] 39%|███▊      | 29/75 [11:12<16:59, 22.16s/epoch, loss=1.16, accuracy=0.749, val_loss=1.85, val_accuracy=0.538, lr=0.1] 40%|████      | 30/75 [11:34<16:34, 22.09s/epoch, loss=1.16, accuracy=0.749, val_loss=2.24, val_accuracy=0.441, lr=0.0316] 41%|████▏     | 31/75 [11:55<15:58, 21.78s/epoch, loss=1.16, accuracy=0.749, val_loss=2.39, val_accuracy=0.477, lr=0.1]    43%|████▎     | 32/75 [12:17<15:37, 21.80s/epoch, loss=1.16, accuracy=0.749, val_loss=3.12, val_accuracy=0.288, lr=0.1] 44%|████▍     | 33/75 [12:39<15:21, 21.93s/epoch, loss=1.16, accuracy=0.749, val_loss=3.9, val_accuracy=0.294, lr=0.1]  45%|████▌     | 34/75 [13:00<14:56, 21.85s/epoch, loss=1.15, accuracy=0.748, val_loss=2.58, val_accuracy=0.402, lr=0.1] 47%|████▋     | 35/75 [13:23<14:38, 21.97s/epoch, loss=1.16, accuracy=0.753, val_loss=1.8, val_accuracy=0.544, lr=0.0316] 48%|████▊     | 36/75 [13:45<14:20, 22.08s/epoch, loss=1.15, accuracy=0.748, val_loss=3.84, val_accuracy=0.353, lr=0.1]   49%|████▉     | 37/75 [14:07<13:52, 21.91s/epoch, loss=1.15, accuracy=0.749, val_loss=1.78, val_accuracy=0.584, lr=0.1] 51%|█████     | 38/75 [14:28<13:30, 21.91s/epoch, loss=1.15, accuracy=0.748, val_loss=2.32, val_accuracy=0.426, lr=0.1] 52%|█████▏    | 39/75 [14:50<13:07, 21.88s/epoch, loss=1.15, accuracy=0.749, val_loss=1.65, val_accuracy=0.61, lr=0.1]  53%|█████▎    | 40/75 [15:13<12:51, 22.03s/epoch, loss=1.15, accuracy=0.751, val_loss=2.23, val_accuracy=0.479, lr=0.0316] 55%|█████▍    | 41/75 [15:35<12:31, 22.11s/epoch, loss=1.15, accuracy=0.75, val_loss=2, val_accuracy=0.479, lr=0.1]        56%|█████▌    | 42/75 [15:57<12:09, 22.10s/epoch, loss=1.15, accuracy=0.75, val_loss=2.16, val_accuracy=0.498, lr=0.1] 57%|█████▋    | 43/75 [16:19<11:48, 22.15s/epoch, loss=1.14, accuracy=0.753, val_loss=2.46, val_accuracy=0.493, lr=0.1] 59%|█████▊    | 44/75 [16:42<11:29, 22.25s/epoch, loss=1.14, accuracy=0.756, val_loss=1.61, val_accuracy=0.596, lr=0.1] 60%|██████    | 45/75 [17:04<11:04, 22.15s/epoch, loss=1.14, accuracy=0.753, val_loss=1.74, val_accuracy=0.598, lr=0.0316] 61%|██████▏   | 46/75 [17:26<10:42, 22.17s/epoch, loss=1.14, accuracy=0.754, val_loss=2.57, val_accuracy=0.427, lr=0.1]    63%|██████▎   | 47/75 [17:48<10:22, 22.24s/epoch, loss=1.14, accuracy=0.754, val_loss=2.44, val_accuracy=0.437, lr=0.1] 64%|██████▍   | 48/75 [18:10<09:58, 22.16s/epoch, loss=1.14, accuracy=0.752, val_loss=2.48, val_accuracy=0.4, lr=0.1]   65%|██████▌   | 49/75 [18:33<09:36, 22.18s/epoch, loss=1.14, accuracy=0.753, val_loss=1.6, val_accuracy=0.604, lr=0.1] 67%|██████▋   | 50/75 [18:55<09:15, 22.23s/epoch, loss=1.14, accuracy=0.752, val_loss=2.19, val_accuracy=0.456, lr=0.0316] 68%|██████▊   | 51/75 [19:17<08:50, 22.10s/epoch, loss=1.14, accuracy=0.753, val_loss=4.1, val_accuracy=0.238, lr=0.1]     69%|██████▉   | 52/75 [19:39<08:31, 22.22s/epoch, loss=1.14, accuracy=0.755, val_loss=2.18, val_accuracy=0.501, lr=0.1] 71%|███████   | 53/75 [20:02<08:10, 22.30s/epoch, loss=1.14, accuracy=0.755, val_loss=2.51, val_accuracy=0.435, lr=0.1] 72%|███████▏  | 54/75 [20:24<07:48, 22.33s/epoch, loss=1.13, accuracy=0.754, val_loss=2.24, val_accuracy=0.456, lr=0.1] 73%|███████▎  | 55/75 [20:46<07:23, 22.19s/epoch, loss=1.14, accuracy=0.756, val_loss=2.31, val_accuracy=0.422, lr=0.0316] 75%|███████▍  | 56/75 [21:08<07:00, 22.16s/epoch, loss=1.13, accuracy=0.756, val_loss=2.54, val_accuracy=0.353, lr=0.1]    76%|███████▌  | 57/75 [21:30<06:36, 22.03s/epoch, loss=1.13, accuracy=0.757, val_loss=1.61, val_accuracy=0.587, lr=0.1] 77%|███████▋  | 58/75 [21:52<06:14, 22.01s/epoch, loss=1.14, accuracy=0.754, val_loss=3.15, val_accuracy=0.305, lr=0.1] 79%|███████▊  | 59/75 [22:14<05:54, 22.13s/epoch, loss=1.13, accuracy=0.755, val_loss=2.4, val_accuracy=0.45, lr=0.1]   80%|████████  | 60/75 [22:36<05:31, 22.12s/epoch, loss=1.13, accuracy=0.756, val_loss=2.43, val_accuracy=0.449, lr=0.0316] 81%|████████▏ | 61/75 [22:59<05:10, 22.19s/epoch, loss=1.13, accuracy=0.756, val_loss=3.8, val_accuracy=0.253, lr=0.1]     83%|████████▎ | 62/75 [23:21<04:48, 22.17s/epoch, loss=1.13, accuracy=0.757, val_loss=3.21, val_accuracy=0.285, lr=0.1] 84%|████████▍ | 63/75 [23:42<04:24, 22.07s/epoch, loss=1.13, accuracy=0.755, val_loss=2.11, val_accuracy=0.506, lr=0.1] 85%|████████▌ | 64/75 [24:05<04:03, 22.14s/epoch, loss=1.14, accuracy=0.755, val_loss=2.22, val_accuracy=0.549, lr=0.1] 87%|████████▋ | 65/75 [24:27<03:41, 22.19s/epoch, loss=1.13, accuracy=0.755, val_loss=2.43, val_accuracy=0.387, lr=0.0316] 88%|████████▊ | 66/75 [24:49<03:18, 22.02s/epoch, loss=1.13, accuracy=0.753, val_loss=1.6, val_accuracy=0.574, lr=0.1]     89%|████████▉ | 67/75 [25:09<02:52, 21.58s/epoch, loss=1.13, accuracy=0.757, val_loss=2.91, val_accuracy=0.368, lr=0.1] 91%|█████████ | 68/75 [25:31<02:31, 21.69s/epoch, loss=1.13, accuracy=0.755, val_loss=1.92, val_accuracy=0.538, lr=0.1] 92%|█████████▏| 69/75 [25:53<02:10, 21.72s/epoch, loss=1.13, accuracy=0.756, val_loss=1.62, val_accuracy=0.601, lr=0.1] 93%|█████████▎| 70/75 [26:15<01:48, 21.68s/epoch, loss=1.13, accuracy=0.754, val_loss=1.54, val_accuracy=0.615, lr=0.0316] 95%|█████████▍| 71/75 [26:36<01:26, 21.54s/epoch, loss=1.13, accuracy=0.753, val_loss=1.48, val_accuracy=0.635, lr=0.1]    96%|█████████▌| 72/75 [26:58<01:04, 21.61s/epoch, loss=1.13, accuracy=0.755, val_loss=2.04, val_accuracy=0.507, lr=0.1] 97%|█████████▋| 73/75 [27:19<00:43, 21.61s/epoch, loss=1.13, accuracy=0.755, val_loss=2.07, val_accuracy=0.514, lr=0.1] 99%|█████████▊| 74/75 [27:41<00:21, 21.75s/epoch, loss=1.13, accuracy=0.754, val_loss=1.99, val_accuracy=0.48, lr=0.1] 100%|██████████| 75/75 [28:04<00:00, 21.93s/epoch, loss=1.13, accuracy=0.754, val_loss=1.84, val_accuracy=0.533, lr=0.1]100%|██████████| 75/75 [28:04<00:00, 22.45s/epoch, loss=1.13, accuracy=0.754, val_loss=1.84, val_accuracy=0.533, lr=0.1]
Using real-time data augmentation.
Test loss: 1.839492917060852
Test accuracy: 0.5331000089645386


* * * Run SGD for ID = 20_3. * * *


2024-02-15 21:15:10.269446: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 21:15:20.781237: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 21:15:20.782375: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-15 21:15:20.820732: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-15 21:15:20.820759: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 21:15:20.825119: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 21:15:20.825158: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 21:15:20.861410: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 21:15:20.862640: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 21:15:20.865970: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 21:15:20.867948: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 21:15:20.873733: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 21:15:20.875407: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 21:15:20.875489: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 21:15:22.080844: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-15 21:15:22.081953: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 21:15:22.082565: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-15 21:15:22.082610: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 21:15:22.082662: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 21:15:22.082681: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 21:15:22.082699: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 21:15:22.082717: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 21:15:22.082734: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 21:15:22.082752: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 21:15:22.082770: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 21:15:22.083243: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 21:15:22.083306: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 21:15:22.724626: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-15 21:15:22.724682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-15 21:15:22.724691: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-15 21:15:22.725641: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': 203, 'batch_size': 128, 'epochs': 75, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/75 [00:00<?, ?epoch/s]2024-02-15 21:15:23.482096: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-15 21:15:23.494387: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2599900000 Hz
2024-02-15 21:15:25.304109: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 21:15:25.504444: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 21:15:29.077732: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-15 21:15:29.110269: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|▏         | 1/75 [00:52<1:04:30, 52.30s/epoch, loss=3.25, accuracy=0.255, val_loss=2.92, val_accuracy=0.132, lr=0.1]  3%|▎         | 2/75 [01:14<42:09, 34.65s/epoch, loss=1.61, accuracy=0.501, val_loss=3.86, val_accuracy=0.27, lr=0.1]     4%|▍         | 3/75 [01:37<34:55, 29.10s/epoch, loss=1.33, accuracy=0.648, val_loss=5.34, val_accuracy=0.255, lr=0.1]  5%|▌         | 4/75 [01:59<31:23, 26.53s/epoch, loss=1.27, accuracy=0.686, val_loss=2.48, val_accuracy=0.457, lr=0.1]  7%|▋         | 5/75 [02:22<29:21, 25.17s/epoch, loss=1.24, accuracy=0.698, val_loss=2.41, val_accuracy=0.428, lr=0.1]  8%|▊         | 6/75 [02:44<27:47, 24.17s/epoch, loss=1.23, accuracy=0.71, val_loss=1.88, val_accuracy=0.473, lr=0.1]   9%|▉         | 7/75 [03:07<26:46, 23.63s/epoch, loss=1.22, accuracy=0.718, val_loss=1.81, val_accuracy=0.522, lr=0.1] 11%|█         | 8/75 [03:29<26:00, 23.29s/epoch, loss=1.21, accuracy=0.722, val_loss=1.66, val_accuracy=0.58, lr=0.1]  12%|█▏        | 9/75 [03:52<25:17, 22.99s/epoch, loss=1.2, accuracy=0.725, val_loss=1.65, val_accuracy=0.595, lr=0.1] 13%|█▎        | 10/75 [04:14<24:44, 22.84s/epoch, loss=1.19, accuracy=0.732, val_loss=2.66, val_accuracy=0.391, lr=0.1] 15%|█▍        | 11/75 [04:36<24:12, 22.69s/epoch, loss=1.19, accuracy=0.733, val_loss=1.39, val_accuracy=0.663, lr=0.1] 16%|█▌        | 12/75 [04:59<23:43, 22.59s/epoch, loss=1.18, accuracy=0.735, val_loss=1.89, val_accuracy=0.486, lr=0.1] 17%|█▋        | 13/75 [05:20<22:51, 22.12s/epoch, loss=1.18, accuracy=0.738, val_loss=1.9, val_accuracy=0.518, lr=0.1]  19%|█▊        | 14/75 [05:42<22:31, 22.15s/epoch, loss=1.18, accuracy=0.737, val_loss=2.01, val_accuracy=0.496, lr=0.1] 20%|██        | 15/75 [06:04<22:11, 22.20s/epoch, loss=1.16, accuracy=0.74, val_loss=3.12, val_accuracy=0.408, lr=0.1]  21%|██▏       | 16/75 [06:27<21:58, 22.35s/epoch, loss=1.16, accuracy=0.744, val_loss=1.99, val_accuracy=0.507, lr=0.0316] 23%|██▎       | 17/75 [06:49<21:33, 22.30s/epoch, loss=1.17, accuracy=0.74, val_loss=1.59, val_accuracy=0.596, lr=0.1]     24%|██▍       | 18/75 [07:11<21:07, 22.24s/epoch, loss=1.18, accuracy=0.741, val_loss=5.9, val_accuracy=0.169, lr=0.1] 25%|██▌       | 19/75 [07:34<20:49, 22.32s/epoch, loss=1.16, accuracy=0.741, val_loss=1.85, val_accuracy=0.542, lr=0.1] 27%|██▋       | 20/75 [07:56<20:22, 22.23s/epoch, loss=1.16, accuracy=0.745, val_loss=2.1, val_accuracy=0.476, lr=0.1]  28%|██▊       | 21/75 [08:18<19:53, 22.11s/epoch, loss=1.16, accuracy=0.744, val_loss=2.12, val_accuracy=0.483, lr=0.0316] 29%|██▉       | 22/75 [08:40<19:40, 22.27s/epoch, loss=1.16, accuracy=0.743, val_loss=1.32, val_accuracy=0.694, lr=0.1]    31%|███       | 23/75 [09:03<19:17, 22.27s/epoch, loss=1.15, accuracy=0.747, val_loss=2.21, val_accuracy=0.491, lr=0.1] 32%|███▏      | 24/75 [09:23<18:29, 21.76s/epoch, loss=1.16, accuracy=0.745, val_loss=1.46, val_accuracy=0.643, lr=0.1] 33%|███▎      | 25/75 [09:46<18:16, 21.94s/epoch, loss=1.15, accuracy=0.745, val_loss=2.46, val_accuracy=0.396, lr=0.1] 35%|███▍      | 26/75 [10:07<17:50, 21.86s/epoch, loss=1.15, accuracy=0.747, val_loss=1.64, val_accuracy=0.593, lr=0.1] 36%|███▌      | 27/75 [10:30<17:37, 22.02s/epoch, loss=1.14, accuracy=0.751, val_loss=1.86, val_accuracy=0.496, lr=0.0316] 37%|███▋      | 28/75 [10:52<17:23, 22.21s/epoch, loss=1.15, accuracy=0.747, val_loss=1.69, val_accuracy=0.572, lr=0.1]    39%|███▊      | 29/75 [11:15<17:07, 22.34s/epoch, loss=1.15, accuracy=0.747, val_loss=2.21, val_accuracy=0.549, lr=0.1] 40%|████      | 30/75 [11:38<16:49, 22.42s/epoch, loss=1.14, accuracy=0.748, val_loss=1.93, val_accuracy=0.553, lr=0.1] 41%|████▏     | 31/75 [12:00<16:28, 22.46s/epoch, loss=1.15, accuracy=0.748, val_loss=1.5, val_accuracy=0.625, lr=0.1]  43%|████▎     | 32/75 [12:22<16:04, 22.44s/epoch, loss=1.14, accuracy=0.751, val_loss=4.28, val_accuracy=0.212, lr=0.0316] 44%|████▍     | 33/75 [12:44<15:35, 22.28s/epoch, loss=1.14, accuracy=0.75, val_loss=2.44, val_accuracy=0.46, lr=0.1]      45%|████▌     | 34/75 [13:07<15:12, 22.26s/epoch, loss=1.15, accuracy=0.747, val_loss=1.66, val_accuracy=0.572, lr=0.1] 47%|████▋     | 35/75 [13:29<14:47, 22.19s/epoch, loss=1.14, accuracy=0.749, val_loss=2.99, val_accuracy=0.415, lr=0.1] 48%|████▊     | 36/75 [13:51<14:28, 22.28s/epoch, loss=1.14, accuracy=0.751, val_loss=1.85, val_accuracy=0.542, lr=0.1] 49%|████▉     | 37/75 [14:14<14:09, 22.36s/epoch, loss=1.14, accuracy=0.751, val_loss=2.7, val_accuracy=0.252, lr=0.0316] 51%|█████     | 38/75 [14:35<13:41, 22.21s/epoch, loss=1.14, accuracy=0.749, val_loss=2.27, val_accuracy=0.479, lr=0.1]   52%|█████▏    | 39/75 [14:58<13:21, 22.26s/epoch, loss=1.14, accuracy=0.752, val_loss=3.07, val_accuracy=0.25, lr=0.1]  53%|█████▎    | 40/75 [15:20<13:00, 22.31s/epoch, loss=1.14, accuracy=0.751, val_loss=1.84, val_accuracy=0.518, lr=0.1] 55%|█████▍    | 41/75 [15:42<12:34, 22.18s/epoch, loss=1.14, accuracy=0.75, val_loss=2.32, val_accuracy=0.438, lr=0.1]  56%|█████▌    | 42/75 [16:04<12:13, 22.22s/epoch, loss=1.13, accuracy=0.753, val_loss=1.66, val_accuracy=0.567, lr=0.0316] 57%|█████▋    | 43/75 [16:27<11:54, 22.32s/epoch, loss=1.14, accuracy=0.753, val_loss=3.07, val_accuracy=0.301, lr=0.1]    59%|█████▊    | 44/75 [16:49<11:29, 22.26s/epoch, loss=1.13, accuracy=0.754, val_loss=1.36, val_accuracy=0.679, lr=0.1] 60%|██████    | 45/75 [17:11<11:08, 22.27s/epoch, loss=1.14, accuracy=0.753, val_loss=2.14, val_accuracy=0.434, lr=0.1] 61%|██████▏   | 46/75 [17:33<10:37, 21.99s/epoch, loss=1.14, accuracy=0.752, val_loss=2, val_accuracy=0.531, lr=0.1]    63%|██████▎   | 47/75 [17:55<10:16, 22.03s/epoch, loss=1.14, accuracy=0.752, val_loss=1.63, val_accuracy=0.576, lr=0.0316] 64%|██████▍   | 48/75 [18:16<09:45, 21.68s/epoch, loss=1.14, accuracy=0.751, val_loss=1.64, val_accuracy=0.58, lr=0.1]     65%|██████▌   | 49/75 [18:38<09:25, 21.76s/epoch, loss=1.13, accuracy=0.753, val_loss=2.2, val_accuracy=0.472, lr=0.1] 67%|██████▋   | 50/75 [19:00<09:06, 21.86s/epoch, loss=1.13, accuracy=0.754, val_loss=17.4, val_accuracy=0.112, lr=0.1] 68%|██████▊   | 51/75 [19:22<08:48, 22.02s/epoch, loss=1.14, accuracy=0.753, val_loss=2.16, val_accuracy=0.485, lr=0.1] 69%|██████▉   | 52/75 [19:45<08:29, 22.13s/epoch, loss=1.13, accuracy=0.751, val_loss=2.27, val_accuracy=0.386, lr=0.0316] 71%|███████   | 53/75 [20:07<08:07, 22.17s/epoch, loss=1.13, accuracy=0.756, val_loss=2.23, val_accuracy=0.512, lr=0.1]    72%|███████▏  | 54/75 [20:29<07:45, 22.16s/epoch, loss=1.14, accuracy=0.751, val_loss=1.52, val_accuracy=0.623, lr=0.1] 73%|███████▎  | 55/75 [20:52<07:25, 22.29s/epoch, loss=1.13, accuracy=0.754, val_loss=2.42, val_accuracy=0.459, lr=0.1] 75%|███████▍  | 56/75 [21:14<07:04, 22.35s/epoch, loss=1.13, accuracy=0.753, val_loss=3.73, val_accuracy=0.283, lr=0.1] 76%|███████▌  | 57/75 [21:36<06:38, 22.16s/epoch, loss=1.14, accuracy=0.752, val_loss=1.82, val_accuracy=0.536, lr=0.0316] 77%|███████▋  | 58/75 [21:58<06:16, 22.17s/epoch, loss=1.13, accuracy=0.755, val_loss=1.85, val_accuracy=0.548, lr=0.1]    79%|███████▊  | 59/75 [22:20<05:56, 22.26s/epoch, loss=1.13, accuracy=0.753, val_loss=2.42, val_accuracy=0.426, lr=0.1] 80%|████████  | 60/75 [22:43<05:35, 22.38s/epoch, loss=1.13, accuracy=0.754, val_loss=1.83, val_accuracy=0.555, lr=0.1] 81%|████████▏ | 61/75 [23:06<05:14, 22.44s/epoch, loss=1.13, accuracy=0.756, val_loss=1.65, val_accuracy=0.574, lr=0.1] 83%|████████▎ | 62/75 [23:28<04:50, 22.38s/epoch, loss=1.13, accuracy=0.753, val_loss=1.88, val_accuracy=0.538, lr=0.0316] 84%|████████▍ | 63/75 [23:49<04:25, 22.09s/epoch, loss=1.13, accuracy=0.753, val_loss=1.62, val_accuracy=0.602, lr=0.1]    85%|████████▌ | 64/75 [24:12<04:03, 22.16s/epoch, loss=1.13, accuracy=0.754, val_loss=2.54, val_accuracy=0.438, lr=0.1] 87%|████████▋ | 65/75 [24:34<03:42, 22.24s/epoch, loss=1.13, accuracy=0.756, val_loss=1.6, val_accuracy=0.605, lr=0.1]  88%|████████▊ | 66/75 [24:57<03:21, 22.37s/epoch, loss=1.13, accuracy=0.753, val_loss=1.57, val_accuracy=0.615, lr=0.1] 89%|████████▉ | 67/75 [25:19<02:58, 22.36s/epoch, loss=1.13, accuracy=0.754, val_loss=2.27, val_accuracy=0.478, lr=0.0316] 91%|█████████ | 68/75 [25:41<02:36, 22.31s/epoch, loss=1.13, accuracy=0.755, val_loss=4.11, val_accuracy=0.18, lr=0.1]     92%|█████████▏| 69/75 [26:04<02:14, 22.37s/epoch, loss=1.13, accuracy=0.753, val_loss=2.35, val_accuracy=0.364, lr=0.1] 93%|█████████▎| 70/75 [26:26<01:52, 22.40s/epoch, loss=1.13, accuracy=0.754, val_loss=1.84, val_accuracy=0.533, lr=0.1] 95%|█████████▍| 71/75 [26:49<01:29, 22.44s/epoch, loss=1.13, accuracy=0.753, val_loss=2.37, val_accuracy=0.44, lr=0.1]  96%|█████████▌| 72/75 [27:11<01:07, 22.45s/epoch, loss=1.13, accuracy=0.752, val_loss=4.19, val_accuracy=0.243, lr=0.0316] 97%|█████████▋| 73/75 [27:34<00:44, 22.45s/epoch, loss=1.12, accuracy=0.756, val_loss=2.17, val_accuracy=0.444, lr=0.1]    99%|█████████▊| 74/75 [27:56<00:22, 22.49s/epoch, loss=1.13, accuracy=0.753, val_loss=2.24, val_accuracy=0.422, lr=0.1]100%|██████████| 75/75 [28:19<00:00, 22.54s/epoch, loss=1.12, accuracy=0.754, val_loss=1.63, val_accuracy=0.58, lr=0.1] 100%|██████████| 75/75 [28:19<00:00, 22.66s/epoch, loss=1.12, accuracy=0.754, val_loss=1.63, val_accuracy=0.58, lr=0.1]
Using real-time data augmentation.
Test loss: 1.6285243034362793
Test accuracy: 0.5795000195503235


* * * Run SGD for ID = 20_4. * * *


2024-02-15 21:43:46.045395: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 21:43:48.611980: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 21:43:48.613152: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-15 21:43:48.649405: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-15 21:43:48.649434: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 21:43:48.652895: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 21:43:48.652934: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 21:43:48.655241: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 21:43:48.655981: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 21:43:48.658190: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 21:43:48.659623: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 21:43:48.664064: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 21:43:48.664551: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 21:43:48.664641: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 21:43:49.844066: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-15 21:43:49.845127: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 21:43:49.845800: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-15 21:43:49.845837: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 21:43:49.845889: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 21:43:49.845908: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 21:43:49.845925: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 21:43:49.845943: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 21:43:49.845960: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 21:43:49.845978: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 21:43:49.845996: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 21:43:49.846423: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 21:43:49.846460: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 21:43:50.458814: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-15 21:43:50.458874: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-15 21:43:50.458883: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-15 21:43:50.459814: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': 204, 'batch_size': 128, 'epochs': 75, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/75 [00:00<?, ?epoch/s]2024-02-15 21:43:51.226959: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-15 21:43:51.239395: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2599900000 Hz
2024-02-15 21:43:53.059501: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 21:43:53.283307: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 21:43:54.100639: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-15 21:43:54.192425: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|▏         | 1/75 [00:54<1:06:51, 54.21s/epoch, loss=3.19, accuracy=0.303, val_loss=2.24, val_accuracy=0.274, lr=0.1]  3%|▎         | 2/75 [01:15<42:40, 35.08s/epoch, loss=1.64, accuracy=0.489, val_loss=3.98, val_accuracy=0.237, lr=0.1]    4%|▍         | 3/75 [01:38<35:03, 29.22s/epoch, loss=1.45, accuracy=0.593, val_loss=3.33, val_accuracy=0.252, lr=0.1]  5%|▌         | 4/75 [01:59<30:55, 26.13s/epoch, loss=1.32, accuracy=0.664, val_loss=2.45, val_accuracy=0.366, lr=0.1]  7%|▋         | 5/75 [02:22<29:19, 25.14s/epoch, loss=1.27, accuracy=0.696, val_loss=2.1, val_accuracy=0.502, lr=0.1]   8%|▊         | 6/75 [02:45<28:01, 24.36s/epoch, loss=1.25, accuracy=0.707, val_loss=1.91, val_accuracy=0.536, lr=0.1]  9%|▉         | 7/75 [03:09<27:18, 24.09s/epoch, loss=1.23, accuracy=0.718, val_loss=2.27, val_accuracy=0.459, lr=0.1] 11%|█         | 8/75 [03:32<26:37, 23.84s/epoch, loss=1.22, accuracy=0.726, val_loss=2.2, val_accuracy=0.493, lr=0.1]  12%|█▏        | 9/75 [03:56<26:09, 23.78s/epoch, loss=1.22, accuracy=0.728, val_loss=2.16, val_accuracy=0.492, lr=0.1] 13%|█▎        | 10/75 [04:19<25:29, 23.54s/epoch, loss=1.2, accuracy=0.733, val_loss=2.38, val_accuracy=0.436, lr=0.1] 15%|█▍        | 11/75 [04:42<25:01, 23.47s/epoch, loss=1.21, accuracy=0.732, val_loss=5.99, val_accuracy=0.254, lr=0.0316] 16%|█▌        | 12/75 [05:05<24:31, 23.36s/epoch, loss=1.21, accuracy=0.735, val_loss=2.16, val_accuracy=0.495, lr=0.1]    17%|█▋        | 13/75 [05:29<24:07, 23.35s/epoch, loss=1.2, accuracy=0.738, val_loss=2.03, val_accuracy=0.529, lr=0.1]  19%|█▊        | 14/75 [05:52<23:46, 23.38s/epoch, loss=1.19, accuracy=0.739, val_loss=1.72, val_accuracy=0.586, lr=0.1] 20%|██        | 15/75 [06:16<23:26, 23.45s/epoch, loss=1.19, accuracy=0.74, val_loss=1.9, val_accuracy=0.561, lr=0.1]   21%|██▏       | 16/75 [06:40<23:15, 23.65s/epoch, loss=1.18, accuracy=0.742, val_loss=2.87, val_accuracy=0.413, lr=0.1] 23%|██▎       | 17/75 [07:03<22:43, 23.50s/epoch, loss=1.19, accuracy=0.74, val_loss=3.49, val_accuracy=0.303, lr=0.1]  24%|██▍       | 18/75 [07:26<22:12, 23.38s/epoch, loss=1.19, accuracy=0.742, val_loss=1.92, val_accuracy=0.553, lr=0.1] 25%|██▌       | 19/75 [07:49<21:37, 23.17s/epoch, loss=1.18, accuracy=0.747, val_loss=1.78, val_accuracy=0.527, lr=0.0316] 27%|██▋       | 20/75 [08:11<20:58, 22.88s/epoch, loss=1.18, accuracy=0.746, val_loss=2.07, val_accuracy=0.516, lr=0.1]    28%|██▊       | 21/75 [08:34<20:33, 22.84s/epoch, loss=1.18, accuracy=0.747, val_loss=3.28, val_accuracy=0.405, lr=0.1] 29%|██▉       | 22/75 [08:56<20:05, 22.75s/epoch, loss=1.18, accuracy=0.745, val_loss=2.81, val_accuracy=0.386, lr=0.1] 31%|███       | 23/75 [09:18<19:28, 22.48s/epoch, loss=1.17, accuracy=0.748, val_loss=2.66, val_accuracy=0.335, lr=0.1] 32%|███▏      | 24/75 [09:40<19:05, 22.46s/epoch, loss=1.17, accuracy=0.747, val_loss=2.25, val_accuracy=0.404, lr=0.0316] 33%|███▎      | 25/75 [10:03<18:44, 22.49s/epoch, loss=1.16, accuracy=0.752, val_loss=2.54, val_accuracy=0.402, lr=0.1]    35%|███▍      | 26/75 [10:26<18:32, 22.70s/epoch, loss=1.16, accuracy=0.75, val_loss=1.81, val_accuracy=0.533, lr=0.1]  36%|███▌      | 27/75 [10:48<18:05, 22.61s/epoch, loss=1.16, accuracy=0.751, val_loss=1.98, val_accuracy=0.495, lr=0.1] 37%|███▋      | 28/75 [11:12<17:48, 22.73s/epoch, loss=1.16, accuracy=0.752, val_loss=1.79, val_accuracy=0.541, lr=0.1] 39%|███▊      | 29/75 [11:34<17:22, 22.66s/epoch, loss=1.15, accuracy=0.749, val_loss=2.05, val_accuracy=0.454, lr=0.0316] 40%|████      | 30/75 [11:57<16:58, 22.63s/epoch, loss=1.15, accuracy=0.753, val_loss=2.31, val_accuracy=0.469, lr=0.1]    41%|████▏     | 31/75 [12:18<16:17, 22.22s/epoch, loss=1.15, accuracy=0.753, val_loss=2, val_accuracy=0.488, lr=0.1]    43%|████▎     | 32/75 [12:41<16:03, 22.42s/epoch, loss=1.15, accuracy=0.754, val_loss=4.08, val_accuracy=0.317, lr=0.1] 44%|████▍     | 33/75 [13:03<15:33, 22.23s/epoch, loss=1.15, accuracy=0.754, val_loss=1.98, val_accuracy=0.514, lr=0.1] 45%|████▌     | 34/75 [13:25<15:17, 22.39s/epoch, loss=1.15, accuracy=0.754, val_loss=2.64, val_accuracy=0.313, lr=0.0316] 47%|████▋     | 35/75 [13:48<14:58, 22.45s/epoch, loss=1.14, accuracy=0.755, val_loss=1.94, val_accuracy=0.482, lr=0.1]    48%|████▊     | 36/75 [14:11<14:39, 22.54s/epoch, loss=1.14, accuracy=0.754, val_loss=2.17, val_accuracy=0.441, lr=0.1] 49%|████▉     | 37/75 [14:33<14:19, 22.62s/epoch, loss=1.14, accuracy=0.755, val_loss=2.8, val_accuracy=0.408, lr=0.1]  51%|█████     | 38/75 [14:56<13:53, 22.52s/epoch, loss=1.14, accuracy=0.753, val_loss=2.05, val_accuracy=0.467, lr=0.1] 52%|█████▏    | 39/75 [15:19<13:34, 22.63s/epoch, loss=1.15, accuracy=0.754, val_loss=2.11, val_accuracy=0.46, lr=0.0316] 53%|█████▎    | 40/75 [15:41<13:12, 22.65s/epoch, loss=1.14, accuracy=0.754, val_loss=1.88, val_accuracy=0.555, lr=0.1]   55%|█████▍    | 41/75 [16:04<12:49, 22.64s/epoch, loss=1.14, accuracy=0.758, val_loss=1.62, val_accuracy=0.599, lr=0.1] 56%|█████▌    | 42/75 [16:26<12:24, 22.56s/epoch, loss=1.13, accuracy=0.754, val_loss=1.72, val_accuracy=0.576, lr=0.1] 57%|█████▋    | 43/75 [16:48<11:51, 22.24s/epoch, loss=1.14, accuracy=0.756, val_loss=2.68, val_accuracy=0.411, lr=0.1] 59%|█████▊    | 44/75 [17:10<11:32, 22.33s/epoch, loss=1.14, accuracy=0.756, val_loss=1.65, val_accuracy=0.573, lr=0.1] 60%|██████    | 45/75 [17:33<11:14, 22.49s/epoch, loss=1.14, accuracy=0.757, val_loss=1.79, val_accuracy=0.582, lr=0.1] 61%|██████▏   | 46/75 [17:55<10:43, 22.17s/epoch, loss=1.13, accuracy=0.756, val_loss=1.74, val_accuracy=0.559, lr=0.0316] 63%|██████▎   | 47/75 [18:17<10:21, 22.21s/epoch, loss=1.13, accuracy=0.756, val_loss=2.34, val_accuracy=0.383, lr=0.1]    64%|██████▍   | 48/75 [18:39<10:00, 22.24s/epoch, loss=1.14, accuracy=0.758, val_loss=1.91, val_accuracy=0.484, lr=0.1] 65%|██████▌   | 49/75 [19:01<09:31, 21.97s/epoch, loss=1.13, accuracy=0.758, val_loss=1.91, val_accuracy=0.508, lr=0.1] 67%|██████▋   | 50/75 [19:23<09:12, 22.11s/epoch, loss=1.13, accuracy=0.756, val_loss=1.4, val_accuracy=0.667, lr=0.1]  68%|██████▊   | 51/75 [19:46<08:54, 22.28s/epoch, loss=1.13, accuracy=0.756, val_loss=1.66, val_accuracy=0.59, lr=0.1] 69%|██████▉   | 52/75 [20:08<08:32, 22.29s/epoch, loss=1.13, accuracy=0.756, val_loss=3.03, val_accuracy=0.422, lr=0.1] 71%|███████   | 53/75 [20:30<08:11, 22.33s/epoch, loss=1.14, accuracy=0.757, val_loss=2.19, val_accuracy=0.411, lr=0.1] 72%|███████▏  | 54/75 [20:53<07:50, 22.38s/epoch, loss=1.13, accuracy=0.757, val_loss=1.61, val_accuracy=0.61, lr=0.1]  73%|███████▎  | 55/75 [21:16<07:30, 22.52s/epoch, loss=1.13, accuracy=0.756, val_loss=2.42, val_accuracy=0.473, lr=0.0316] 75%|███████▍  | 56/75 [21:38<07:08, 22.57s/epoch, loss=1.14, accuracy=0.756, val_loss=1.72, val_accuracy=0.6, lr=0.1]      76%|███████▌  | 57/75 [22:01<06:46, 22.60s/epoch, loss=1.13, accuracy=0.759, val_loss=1.51, val_accuracy=0.628, lr=0.1] 77%|███████▋  | 58/75 [22:24<06:25, 22.70s/epoch, loss=1.12, accuracy=0.758, val_loss=2.13, val_accuracy=0.464, lr=0.1] 79%|███████▊  | 59/75 [22:47<06:03, 22.69s/epoch, loss=1.12, accuracy=0.758, val_loss=1.66, val_accuracy=0.578, lr=0.1] 80%|████████  | 60/75 [23:09<05:39, 22.63s/epoch, loss=1.14, accuracy=0.754, val_loss=1.77, val_accuracy=0.552, lr=0.0316] 81%|████████▏ | 61/75 [23:31<05:14, 22.47s/epoch, loss=1.13, accuracy=0.76, val_loss=2.38, val_accuracy=0.432, lr=0.1]     83%|████████▎ | 62/75 [23:54<04:52, 22.52s/epoch, loss=1.13, accuracy=0.758, val_loss=2.27, val_accuracy=0.358, lr=0.1] 84%|████████▍ | 63/75 [24:16<04:28, 22.36s/epoch, loss=1.13, accuracy=0.758, val_loss=1.97, val_accuracy=0.443, lr=0.1] 85%|████████▌ | 64/75 [24:38<04:05, 22.35s/epoch, loss=1.12, accuracy=0.763, val_loss=1.77, val_accuracy=0.6, lr=0.1]   87%|████████▋ | 65/75 [25:01<03:43, 22.39s/epoch, loss=1.12, accuracy=0.757, val_loss=3.02, val_accuracy=0.313, lr=0.0316] 88%|████████▊ | 66/75 [25:23<03:22, 22.50s/epoch, loss=1.12, accuracy=0.758, val_loss=2.66, val_accuracy=0.313, lr=0.1]    89%|████████▉ | 67/75 [25:45<02:58, 22.27s/epoch, loss=1.12, accuracy=0.76, val_loss=2.01, val_accuracy=0.524, lr=0.1]  91%|█████████ | 68/75 [26:07<02:35, 22.23s/epoch, loss=1.12, accuracy=0.763, val_loss=1.51, val_accuracy=0.6, lr=0.1]  92%|█████████▏| 69/75 [26:30<02:13, 22.33s/epoch, loss=1.13, accuracy=0.757, val_loss=1.99, val_accuracy=0.507, lr=0.1] 93%|█████████▎| 70/75 [26:52<01:51, 22.32s/epoch, loss=1.12, accuracy=0.76, val_loss=5.06, val_accuracy=0.28, lr=0.0316] 95%|█████████▍| 71/75 [27:14<01:29, 22.26s/epoch, loss=1.12, accuracy=0.761, val_loss=1.57, val_accuracy=0.605, lr=0.1]  96%|█████████▌| 72/75 [27:36<01:06, 22.01s/epoch, loss=1.12, accuracy=0.761, val_loss=2.61, val_accuracy=0.41, lr=0.1]  97%|█████████▋| 73/75 [27:58<00:44, 22.12s/epoch, loss=1.12, accuracy=0.759, val_loss=2.15, val_accuracy=0.492, lr=0.1] 99%|█████████▊| 74/75 [28:20<00:22, 22.17s/epoch, loss=1.13, accuracy=0.759, val_loss=1.79, val_accuracy=0.582, lr=0.1]100%|██████████| 75/75 [28:42<00:00, 22.11s/epoch, loss=1.13, accuracy=0.756, val_loss=1.77, val_accuracy=0.561, lr=0.0316]100%|██████████| 75/75 [28:42<00:00, 22.97s/epoch, loss=1.13, accuracy=0.756, val_loss=1.77, val_accuracy=0.561, lr=0.0316]
Using real-time data augmentation.
Test loss: 1.7659251689910889
Test accuracy: 0.5605000257492065


* * * Run SGD for ID = 20_5. * * *


2024-02-15 22:12:36.661004: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 22:12:39.232220: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 22:12:39.233367: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-15 22:12:39.268999: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-15 22:12:39.269031: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 22:12:39.271736: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 22:12:39.271778: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 22:12:39.273912: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 22:12:39.274546: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 22:12:39.276766: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 22:12:39.278079: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 22:12:39.282854: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 22:12:39.283361: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 22:12:39.283450: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 22:12:40.486569: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-15 22:12:40.487158: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 22:12:40.487775: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-15 22:12:40.487804: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 22:12:40.487850: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 22:12:40.487869: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 22:12:40.487887: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 22:12:40.487904: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 22:12:40.487921: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 22:12:40.487938: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 22:12:40.487955: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 22:12:40.488375: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 22:12:40.488405: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 22:12:41.076533: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-15 22:12:41.076610: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-15 22:12:41.076619: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-15 22:12:41.077509: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': 205, 'batch_size': 128, 'epochs': 75, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/75 [00:00<?, ?epoch/s]2024-02-15 22:12:41.813759: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-15 22:12:41.825402: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2599900000 Hz
2024-02-15 22:12:43.562945: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 22:12:43.724081: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 22:12:44.939968: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-15 22:12:45.041416: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|▏         | 1/75 [00:54<1:06:54, 54.25s/epoch, loss=3.42, accuracy=0.309, val_loss=2.41, val_accuracy=0.245, lr=0.1]  3%|▎         | 2/75 [01:16<43:10, 35.48s/epoch, loss=1.54, accuracy=0.55, val_loss=1.61, val_accuracy=0.523, lr=0.1]     4%|▍         | 3/75 [01:38<35:14, 29.36s/epoch, loss=1.32, accuracy=0.648, val_loss=1.7, val_accuracy=0.532, lr=0.1]  5%|▌         | 4/75 [02:00<31:08, 26.32s/epoch, loss=1.26, accuracy=0.683, val_loss=1.47, val_accuracy=0.604, lr=0.1]  7%|▋         | 5/75 [02:21<28:42, 24.60s/epoch, loss=1.24, accuracy=0.7, val_loss=1.43, val_accuracy=0.63, lr=0.1]     8%|▊         | 6/75 [02:44<27:21, 23.79s/epoch, loss=1.22, accuracy=0.714, val_loss=1.64, val_accuracy=0.588, lr=0.1]  9%|▉         | 7/75 [03:06<26:25, 23.31s/epoch, loss=1.21, accuracy=0.719, val_loss=1.52, val_accuracy=0.593, lr=0.1] 11%|█         | 8/75 [03:27<25:19, 22.68s/epoch, loss=1.2, accuracy=0.726, val_loss=2.13, val_accuracy=0.421, lr=0.1]  12%|█▏        | 9/75 [03:48<24:25, 22.21s/epoch, loss=1.2, accuracy=0.726, val_loss=1.78, val_accuracy=0.539, lr=0.1] 13%|█▎        | 10/75 [04:10<23:58, 22.13s/epoch, loss=1.19, accuracy=0.733, val_loss=1.77, val_accuracy=0.52, lr=0.0316] 15%|█▍        | 11/75 [04:33<23:41, 22.21s/epoch, loss=1.19, accuracy=0.734, val_loss=1.72, val_accuracy=0.536, lr=0.1]   16%|█▌        | 12/75 [04:55<23:21, 22.25s/epoch, loss=1.19, accuracy=0.735, val_loss=2.48, val_accuracy=0.379, lr=0.1] 17%|█▋        | 13/75 [05:16<22:43, 21.99s/epoch, loss=1.18, accuracy=0.737, val_loss=1.74, val_accuracy=0.547, lr=0.1] 19%|█▊        | 14/75 [05:39<22:27, 22.09s/epoch, loss=1.17, accuracy=0.74, val_loss=1.86, val_accuracy=0.503, lr=0.1]  20%|██        | 15/75 [06:01<22:08, 22.14s/epoch, loss=1.18, accuracy=0.739, val_loss=2.38, val_accuracy=0.421, lr=0.0316] 21%|██▏       | 16/75 [06:23<21:45, 22.13s/epoch, loss=1.17, accuracy=0.744, val_loss=3.16, val_accuracy=0.31, lr=0.1]     23%|██▎       | 17/75 [06:46<21:27, 22.20s/epoch, loss=1.18, accuracy=0.742, val_loss=6.82, val_accuracy=0.217, lr=0.1] 24%|██▍       | 18/75 [07:08<21:06, 22.21s/epoch, loss=1.17, accuracy=0.741, val_loss=2.43, val_accuracy=0.445, lr=0.1] 25%|██▌       | 19/75 [07:30<20:41, 22.17s/epoch, loss=1.17, accuracy=0.744, val_loss=2.4, val_accuracy=0.386, lr=0.1]  27%|██▋       | 20/75 [07:52<20:17, 22.13s/epoch, loss=1.16, accuracy=0.747, val_loss=1.7, val_accuracy=0.579, lr=0.0316] 28%|██▊       | 21/75 [08:13<19:42, 21.91s/epoch, loss=1.16, accuracy=0.743, val_loss=2.09, val_accuracy=0.498, lr=0.1]   29%|██▉       | 22/75 [08:36<19:26, 22.01s/epoch, loss=1.16, accuracy=0.747, val_loss=2.15, val_accuracy=0.493, lr=0.1] 31%|███       | 23/75 [08:57<18:59, 21.91s/epoch, loss=1.16, accuracy=0.748, val_loss=1.98, val_accuracy=0.559, lr=0.1] 32%|███▏      | 24/75 [09:19<18:42, 22.00s/epoch, loss=1.16, accuracy=0.747, val_loss=2.56, val_accuracy=0.386, lr=0.1] 33%|███▎      | 25/75 [09:42<18:23, 22.06s/epoch, loss=1.15, accuracy=0.75, val_loss=1.51, val_accuracy=0.615, lr=0.0316] 35%|███▍      | 26/75 [10:04<18:05, 22.15s/epoch, loss=1.15, accuracy=0.747, val_loss=1.65, val_accuracy=0.607, lr=0.1]   36%|███▌      | 27/75 [10:26<17:48, 22.26s/epoch, loss=1.14, accuracy=0.752, val_loss=1.96, val_accuracy=0.507, lr=0.1] 37%|███▋      | 28/75 [10:48<17:21, 22.17s/epoch, loss=1.15, accuracy=0.748, val_loss=1.81, val_accuracy=0.589, lr=0.1] 39%|███▊      | 29/75 [11:11<17:03, 22.24s/epoch, loss=1.15, accuracy=0.751, val_loss=1.54, val_accuracy=0.613, lr=0.1] 40%|████      | 30/75 [11:33<16:39, 22.20s/epoch, loss=1.14, accuracy=0.75, val_loss=2.69, val_accuracy=0.306, lr=0.0316] 41%|████▏     | 31/75 [11:55<16:12, 22.10s/epoch, loss=1.14, accuracy=0.751, val_loss=3.75, val_accuracy=0.374, lr=0.1]   43%|████▎     | 32/75 [12:17<15:46, 22.01s/epoch, loss=1.14, accuracy=0.753, val_loss=1.6, val_accuracy=0.629, lr=0.1]  44%|████▍     | 33/75 [12:38<15:18, 21.87s/epoch, loss=1.15, accuracy=0.748, val_loss=4.41, val_accuracy=0.281, lr=0.1]