Thu Feb 15 20:17:48 2024       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA TITAN X (Pascal)        Off | 00000000:83:00.0 Off |                  N/A |
| 50%   82C    P0              99W / 250W |      0MiB / 12288MiB |     49%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|  No running processes found                                                           |
+---------------------------------------------------------------------------------------+


* * * Run SGD for cluster size = 20. * * *


Budget: 75


* * * Run SGD for ID = 20_1. * * *


2024-02-15 20:17:49.551422: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 20:17:53.072762: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 20:17:53.073917: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-15 20:17:53.110450: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-15 20:17:53.110483: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 20:17:53.113439: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 20:17:53.113477: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 20:17:53.115894: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 20:17:53.116749: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 20:17:53.119136: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 20:17:53.120618: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 20:17:53.125161: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 20:17:53.125697: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 20:17:53.125765: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 20:17:54.337448: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-15 20:17:54.338715: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 20:17:54.339333: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-15 20:17:54.339364: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 20:17:54.339415: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 20:17:54.339434: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 20:17:54.339452: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 20:17:54.339470: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 20:17:54.339488: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 20:17:54.339505: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 20:17:54.339524: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 20:17:54.339973: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 20:17:54.340004: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 20:17:54.971998: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-15 20:17:54.972064: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-15 20:17:54.972074: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-15 20:17:54.972971: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': 201, 'batch_size': 128, 'epochs': 75, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/75 [00:00<?, ?epoch/s]2024-02-15 20:17:55.749545: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-15 20:17:55.761404: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2599900000 Hz
2024-02-15 20:17:57.623379: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 20:17:57.863989: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 20:17:58.817789: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-15 20:17:58.929843: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|▏         | 1/75 [00:58<1:11:36, 58.06s/epoch, loss=3.39, accuracy=0.261, val_loss=2.33, val_accuracy=0.262, lr=0.1]  3%|▎         | 2/75 [01:20<44:54, 36.91s/epoch, loss=1.64, accuracy=0.49, val_loss=2.21, val_accuracy=0.315, lr=0.1]     4%|▍         | 3/75 [01:41<35:39, 29.72s/epoch, loss=1.38, accuracy=0.621, val_loss=2.31, val_accuracy=0.356, lr=0.1]  5%|▌         | 4/75 [02:03<31:33, 26.67s/epoch, loss=1.29, accuracy=0.676, val_loss=1.84, val_accuracy=0.501, lr=0.1]  7%|▋         | 5/75 [02:25<29:25, 25.23s/epoch, loss=1.26, accuracy=0.696, val_loss=1.55, val_accuracy=0.593, lr=0.1]  8%|▊         | 6/75 [02:48<27:58, 24.33s/epoch, loss=1.24, accuracy=0.708, val_loss=1.56, val_accuracy=0.603, lr=0.1]  9%|▉         | 7/75 [03:11<27:00, 23.84s/epoch, loss=1.22, accuracy=0.718, val_loss=2.19, val_accuracy=0.43, lr=0.1]  11%|█         | 8/75 [03:34<26:10, 23.44s/epoch, loss=1.21, accuracy=0.724, val_loss=2.15, val_accuracy=0.424, lr=0.1] 12%|█▏        | 9/75 [03:56<25:28, 23.16s/epoch, loss=1.21, accuracy=0.723, val_loss=1.66, val_accuracy=0.588, lr=0.1] 13%|█▎        | 10/75 [04:19<24:58, 23.06s/epoch, loss=1.2, accuracy=0.729, val_loss=1.86, val_accuracy=0.492, lr=0.0316] 15%|█▍        | 11/75 [04:41<24:23, 22.86s/epoch, loss=1.19, accuracy=0.733, val_loss=1.85, val_accuracy=0.507, lr=0.1]   16%|█▌        | 12/75 [05:04<24:00, 22.87s/epoch, loss=1.19, accuracy=0.734, val_loss=3.16, val_accuracy=0.345, lr=0.1] 17%|█▋        | 13/75 [05:27<23:41, 22.92s/epoch, loss=1.18, accuracy=0.736, val_loss=1.96, val_accuracy=0.51, lr=0.1]  19%|█▊        | 14/75 [05:50<23:16, 22.89s/epoch, loss=1.18, accuracy=0.741, val_loss=2.14, val_accuracy=0.456, lr=0.1] 20%|██        | 15/75 [06:13<22:54, 22.90s/epoch, loss=1.18, accuracy=0.741, val_loss=4, val_accuracy=0.301, lr=0.0316] 21%|██▏       | 16/75 [06:36<22:29, 22.87s/epoch, loss=1.18, accuracy=0.741, val_loss=2.09, val_accuracy=0.496, lr=0.1] 23%|██▎       | 17/75 [06:59<22:07, 22.90s/epoch, loss=1.17, accuracy=0.741, val_loss=3.27, val_accuracy=0.367, lr=0.1] 24%|██▍       | 18/75 [07:22<21:47, 22.94s/epoch, loss=1.17, accuracy=0.741, val_loss=2.45, val_accuracy=0.385, lr=0.1] 25%|██▌       | 19/75 [07:44<21:12, 22.72s/epoch, loss=1.16, accuracy=0.745, val_loss=1.39, val_accuracy=0.674, lr=0.1] 27%|██▋       | 20/75 [08:07<20:51, 22.75s/epoch, loss=1.16, accuracy=0.742, val_loss=2.28, val_accuracy=0.463, lr=0.1] 28%|██▊       | 21/75 [08:30<20:28, 22.76s/epoch, loss=1.17, accuracy=0.743, val_loss=1.51, val_accuracy=0.639, lr=0.1] 29%|██▉       | 22/75 [08:53<20:09, 22.82s/epoch, loss=1.16, accuracy=0.747, val_loss=1.89, val_accuracy=0.531, lr=0.1] 31%|███       | 23/75 [09:15<19:46, 22.82s/epoch, loss=1.16, accuracy=0.748, val_loss=1.99, val_accuracy=0.508, lr=0.1] 32%|███▏      | 24/75 [09:38<19:26, 22.88s/epoch, loss=1.16, accuracy=0.745, val_loss=2.62, val_accuracy=0.409, lr=0.0316] 33%|███▎      | 25/75 [09:59<18:32, 22.26s/epoch, loss=1.15, accuracy=0.75, val_loss=1.74, val_accuracy=0.563, lr=0.1]     35%|███▍      | 26/75 [10:22<18:23, 22.52s/epoch, loss=1.15, accuracy=0.748, val_loss=2.43, val_accuracy=0.317, lr=0.1] 36%|███▌      | 27/75 [10:45<18:06, 22.64s/epoch, loss=1.16, accuracy=0.749, val_loss=1.69, val_accuracy=0.59, lr=0.1]  37%|███▋      | 28/75 [11:08<17:43, 22.64s/epoch, loss=1.15, accuracy=0.751, val_loss=1.77, val_accuracy=0.554, lr=0.1] 39%|███▊      | 29/75 [11:31<17:22, 22.67s/epoch, loss=1.15, accuracy=0.751, val_loss=1.6, val_accuracy=0.59, lr=0.0316] 40%|████      | 30/75 [11:53<17:01, 22.70s/epoch, loss=1.15, accuracy=0.752, val_loss=2.88, val_accuracy=0.311, lr=0.1]  41%|████▏     | 31/75 [12:16<16:32, 22.55s/epoch, loss=1.14, accuracy=0.753, val_loss=2.07, val_accuracy=0.455, lr=0.1] 43%|████▎     | 32/75 [12:39<16:15, 22.68s/epoch, loss=1.15, accuracy=0.749, val_loss=2.1, val_accuracy=0.467, lr=0.1]  44%|████▍     | 33/75 [13:02<15:56, 22.77s/epoch, loss=1.15, accuracy=0.751, val_loss=2.2, val_accuracy=0.354, lr=0.1] 45%|████▌     | 34/75 [13:24<15:34, 22.80s/epoch, loss=1.15, accuracy=0.748, val_loss=3.13, val_accuracy=0.224, lr=0.0316] 47%|████▋     | 35/75 [13:47<15:09, 22.73s/epoch, loss=1.14, accuracy=0.755, val_loss=1.83, val_accuracy=0.515, lr=0.1]    48%|████▊     | 36/75 [14:10<14:46, 22.72s/epoch, loss=1.14, accuracy=0.751, val_loss=2.47, val_accuracy=0.447, lr=0.1] 49%|████▉     | 37/75 [14:32<14:21, 22.68s/epoch, loss=1.14, accuracy=0.751, val_loss=2.12, val_accuracy=0.513, lr=0.1] 51%|█████     | 38/75 [14:55<14:00, 22.72s/epoch, loss=1.14, accuracy=0.752, val_loss=1.93, val_accuracy=0.541, lr=0.1] 52%|█████▏    | 39/75 [15:18<13:39, 22.77s/epoch, loss=1.14, accuracy=0.753, val_loss=1.69, val_accuracy=0.545, lr=0.0316] 53%|█████▎    | 40/75 [15:41<13:16, 22.75s/epoch, loss=1.14, accuracy=0.754, val_loss=2.66, val_accuracy=0.375, lr=0.1]    55%|█████▍    | 41/75 [16:03<12:53, 22.76s/epoch, loss=1.15, accuracy=0.752, val_loss=2.25, val_accuracy=0.415, lr=0.1] 56%|█████▌    | 42/75 [16:26<12:32, 22.79s/epoch, loss=1.14, accuracy=0.752, val_loss=1.5, val_accuracy=0.637, lr=0.1]  57%|█████▋    | 43/75 [16:49<12:09, 22.79s/epoch, loss=1.15, accuracy=0.752, val_loss=2.42, val_accuracy=0.436, lr=0.1] 59%|█████▊    | 44/75 [17:12<11:47, 22.83s/epoch, loss=1.14, accuracy=0.753, val_loss=1.92, val_accuracy=0.525, lr=0.0316] 60%|██████    | 45/75 [17:35<11:25, 22.83s/epoch, loss=1.13, accuracy=0.757, val_loss=1.61, val_accuracy=0.593, lr=0.1]    61%|██████▏   | 46/75 [17:58<11:01, 22.81s/epoch, loss=1.14, accuracy=0.753, val_loss=2.07, val_accuracy=0.496, lr=0.1] 63%|██████▎   | 47/75 [18:20<10:36, 22.74s/epoch, loss=1.13, accuracy=0.755, val_loss=1.75, val_accuracy=0.544, lr=0.1] 64%|██████▍   | 48/75 [18:43<10:15, 22.80s/epoch, loss=1.14, accuracy=0.752, val_loss=1.92, val_accuracy=0.518, lr=0.1] 65%|██████▌   | 49/75 [19:06<09:54, 22.86s/epoch, loss=1.15, accuracy=0.751, val_loss=2.43, val_accuracy=0.323, lr=0.0316] 67%|██████▋   | 50/75 [19:29<09:31, 22.86s/epoch, loss=1.13, accuracy=0.754, val_loss=2.77, val_accuracy=0.376, lr=0.1]    68%|██████▊   | 51/75 [19:52<09:08, 22.85s/epoch, loss=1.14, accuracy=0.755, val_loss=3.01, val_accuracy=0.293, lr=0.1] 69%|██████▉   | 52/75 [20:15<08:46, 22.91s/epoch, loss=1.13, accuracy=0.755, val_loss=1.95, val_accuracy=0.531, lr=0.1] 71%|███████   | 53/75 [20:37<08:20, 22.77s/epoch, loss=1.13, accuracy=0.755, val_loss=2.63, val_accuracy=0.396, lr=0.1] 72%|███████▏  | 54/75 [21:00<07:59, 22.81s/epoch, loss=1.14, accuracy=0.755, val_loss=1.56, val_accuracy=0.599, lr=0.0316] 73%|███████▎  | 55/75 [21:23<07:36, 22.83s/epoch, loss=1.13, accuracy=0.756, val_loss=2.31, val_accuracy=0.386, lr=0.1]    75%|███████▍  | 56/75 [21:46<07:13, 22.84s/epoch, loss=1.14, accuracy=0.755, val_loss=2.77, val_accuracy=0.352, lr=0.1] 76%|███████▌  | 57/75 [22:09<06:52, 22.91s/epoch, loss=1.14, accuracy=0.752, val_loss=2.18, val_accuracy=0.467, lr=0.1] 77%|███████▋  | 58/75 [22:32<06:29, 22.93s/epoch, loss=1.14, accuracy=0.754, val_loss=2.23, val_accuracy=0.489, lr=0.1] 79%|███████▊  | 59/75 [22:55<06:05, 22.82s/epoch, loss=1.13, accuracy=0.758, val_loss=3.12, val_accuracy=0.272, lr=0.0316] 80%|████████  | 60/75 [23:17<05:42, 22.84s/epoch, loss=1.14, accuracy=0.752, val_loss=2.04, val_accuracy=0.534, lr=0.1]    81%|████████▏ | 61/75 [23:40<05:20, 22.86s/epoch, loss=1.14, accuracy=0.755, val_loss=1.58, val_accuracy=0.61, lr=0.1]  83%|████████▎ | 62/75 [24:03<04:57, 22.85s/epoch, loss=1.14, accuracy=0.753, val_loss=1.84, val_accuracy=0.508, lr=0.1] 84%|████████▍ | 63/75 [24:26<04:34, 22.87s/epoch, loss=1.13, accuracy=0.758, val_loss=1.67, val_accuracy=0.556, lr=0.1] 85%|████████▌ | 64/75 [24:49<04:11, 22.90s/epoch, loss=1.14, accuracy=0.752, val_loss=1.95, val_accuracy=0.487, lr=0.0316] 87%|████████▋ | 65/75 [25:12<03:49, 22.94s/epoch, loss=1.13, accuracy=0.756, val_loss=2.49, val_accuracy=0.439, lr=0.1]    88%|████████▊ | 66/75 [25:35<03:25, 22.86s/epoch, loss=1.13, accuracy=0.756, val_loss=1.48, val_accuracy=0.629, lr=0.1] 89%|████████▉ | 67/75 [25:58<03:03, 22.92s/epoch, loss=1.13, accuracy=0.755, val_loss=3.07, val_accuracy=0.349, lr=0.1] 91%|█████████ | 68/75 [26:21<02:40, 22.87s/epoch, loss=1.13, accuracy=0.756, val_loss=4.81, val_accuracy=0.183, lr=0.1] 92%|█████████▏| 69/75 [26:44<02:17, 22.94s/epoch, loss=1.13, accuracy=0.758, val_loss=1.99, val_accuracy=0.485, lr=0.0316] 93%|█████████▎| 70/75 [27:07<01:54, 22.98s/epoch, loss=1.14, accuracy=0.753, val_loss=1.97, val_accuracy=0.431, lr=0.1]    95%|█████████▍| 71/75 [27:30<01:31, 22.97s/epoch, loss=1.13, accuracy=0.755, val_loss=1.73, val_accuracy=0.571, lr=0.1] 96%|█████████▌| 72/75 [27:53<01:08, 22.98s/epoch, loss=1.12, accuracy=0.754, val_loss=1.96, val_accuracy=0.507, lr=0.1] 97%|█████████▋| 73/75 [28:14<00:44, 22.50s/epoch, loss=1.13, accuracy=0.759, val_loss=1.8, val_accuracy=0.548, lr=0.1]  99%|█████████▊| 74/75 [28:36<00:22, 22.44s/epoch, loss=1.13, accuracy=0.755, val_loss=1.58, val_accuracy=0.577, lr=0.0316]100%|██████████| 75/75 [28:59<00:00, 22.47s/epoch, loss=1.14, accuracy=0.754, val_loss=1.9, val_accuracy=0.506, lr=0.1]    100%|██████████| 75/75 [28:59<00:00, 23.19s/epoch, loss=1.14, accuracy=0.754, val_loss=1.9, val_accuracy=0.506, lr=0.1]
Using real-time data augmentation.
Test loss: 1.9029581546783447
Test accuracy: 0.5060999989509583


* * * Run SGD for ID = 20_2. * * *


2024-02-15 20:46:57.868048: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 20:47:00.520083: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 20:47:00.521246: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-15 20:47:00.557139: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-15 20:47:00.557170: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 20:47:00.559952: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 20:47:00.559990: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 20:47:00.562190: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 20:47:00.562851: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 20:47:00.565141: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 20:47:00.566571: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 20:47:00.571086: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 20:47:00.571618: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 20:47:00.571700: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 20:47:01.754713: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-15 20:47:01.755822: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 20:47:01.756477: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-15 20:47:01.756508: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 20:47:01.756559: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 20:47:01.756596: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 20:47:01.756631: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 20:47:01.756649: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 20:47:01.756666: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 20:47:01.756683: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 20:47:01.756700: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 20:47:01.757099: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 20:47:01.757131: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 20:47:02.363649: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-15 20:47:02.363728: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-15 20:47:02.363738: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-15 20:47:02.364671: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': 202, 'batch_size': 128, 'epochs': 75, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/75 [00:00<?, ?epoch/s]2024-02-15 20:47:03.127297: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-15 20:47:03.139396: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2599900000 Hz
2024-02-15 20:47:04.947518: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 20:47:05.148184: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 20:47:06.203419: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-15 20:47:06.241521: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|▏         | 1/75 [00:49<1:00:48, 49.31s/epoch, loss=3.25, accuracy=0.253, val_loss=2.21, val_accuracy=0.27, lr=0.1]  3%|▎         | 2/75 [01:09<39:22, 32.36s/epoch, loss=1.65, accuracy=0.476, val_loss=2.37, val_accuracy=0.318, lr=0.1]   4%|▍         | 3/75 [01:31<32:43, 27.27s/epoch, loss=1.4, accuracy=0.6, val_loss=2.05, val_accuracy=0.437, lr=0.1]     5%|▌         | 4/75 [01:53<30:01, 25.37s/epoch, loss=1.29, accuracy=0.667, val_loss=2.87, val_accuracy=0.444, lr=0.1]  7%|▋         | 5/75 [02:13<27:31, 23.60s/epoch, loss=1.25, accuracy=0.693, val_loss=1.97, val_accuracy=0.469, lr=0.1]  8%|▊         | 6/75 [02:36<26:46, 23.29s/epoch, loss=1.23, accuracy=0.707, val_loss=1.69, val_accuracy=0.537, lr=0.1]  9%|▉         | 7/75 [02:59<26:09, 23.08s/epoch, loss=1.22, accuracy=0.713, val_loss=1.6, val_accuracy=0.565, lr=0.1]  11%|█         | 8/75 [03:21<25:30, 22.84s/epoch, loss=1.2, accuracy=0.72, val_loss=2, val_accuracy=0.496, lr=0.1]     12%|█▏        | 9/75 [03:43<24:57, 22.69s/epoch, loss=1.2, accuracy=0.726, val_loss=1.89, val_accuracy=0.506, lr=0.1] 13%|█▎        | 10/75 [04:06<24:32, 22.66s/epoch, loss=1.19, accuracy=0.729, val_loss=2.25, val_accuracy=0.439, lr=0.1] 15%|█▍        | 11/75 [04:28<24:03, 22.55s/epoch, loss=1.19, accuracy=0.73, val_loss=2.65, val_accuracy=0.439, lr=0.1]  16%|█▌        | 12/75 [04:51<23:40, 22.55s/epoch, loss=1.19, accuracy=0.734, val_loss=2.46, val_accuracy=0.462, lr=0.0316] 17%|█▋        | 13/75 [05:13<23:14, 22.49s/epoch, loss=1.19, accuracy=0.735, val_loss=2.26, val_accuracy=0.488, lr=0.1]    19%|█▊        | 14/75 [05:36<22:53, 22.51s/epoch, loss=1.18, accuracy=0.741, val_loss=2.08, val_accuracy=0.464, lr=0.1] 20%|██        | 15/75 [05:59<22:36, 22.61s/epoch, loss=1.18, accuracy=0.742, val_loss=1.59, val_accuracy=0.595, lr=0.1] 21%|██▏       | 16/75 [06:21<22:01, 22.41s/epoch, loss=1.17, accuracy=0.743, val_loss=1.78, val_accuracy=0.539, lr=0.1] 23%|██▎       | 17/75 [06:43<21:41, 22.45s/epoch, loss=1.18, accuracy=0.741, val_loss=1.64, val_accuracy=0.618, lr=0.1] 24%|██▍       | 18/75 [07:06<21:24, 22.53s/epoch, loss=1.18, accuracy=0.743, val_loss=1.59, val_accuracy=0.605, lr=0.1] 25%|██▌       | 19/75 [07:29<21:04, 22.58s/epoch, loss=1.17, accuracy=0.743, val_loss=2.24, val_accuracy=0.422, lr=0.1] 27%|██▋       | 20/75 [07:51<20:45, 22.65s/epoch, loss=1.18, accuracy=0.742, val_loss=1.51, val_accuracy=0.629, lr=0.1] 28%|██▊       | 21/75 [08:14<20:15, 22.50s/epoch, loss=1.18, accuracy=0.742, val_loss=2.07, val_accuracy=0.517, lr=0.1] 29%|██▉       | 22/75 [08:36<19:53, 22.53s/epoch, loss=1.18, accuracy=0.743, val_loss=1.58, val_accuracy=0.623, lr=0.1] 31%|███       | 23/75 [08:58<19:26, 22.43s/epoch, loss=1.18, accuracy=0.743, val_loss=1.89, val_accuracy=0.535, lr=0.1] 32%|███▏      | 24/75 [09:21<19:05, 22.47s/epoch, loss=1.17, accuracy=0.746, val_loss=1.72, val_accuracy=0.559, lr=0.1] 33%|███▎      | 25/75 [09:43<18:42, 22.45s/epoch, loss=1.17, accuracy=0.746, val_loss=1.64, val_accuracy=0.605, lr=0.0316] 35%|███▍      | 26/75 [10:06<18:21, 22.48s/epoch, loss=1.17, accuracy=0.745, val_loss=2.89, val_accuracy=0.411, lr=0.1]    36%|███▌      | 27/75 [10:28<17:51, 22.33s/epoch, loss=1.16, accuracy=0.749, val_loss=1.76, val_accuracy=0.536, lr=0.1] 37%|███▋      | 28/75 [10:50<17:20, 22.14s/epoch, loss=1.15, accuracy=0.751, val_loss=1.88, val_accuracy=0.495, lr=0.1] 39%|███▊      | 29/75 [11:12<16:59, 22.16s/epoch, loss=1.16, accuracy=0.749, val_loss=1.85, val_accuracy=0.538, lr=0.1] 40%|████      | 30/75 [11:34<16:34, 22.09s/epoch, loss=1.16, accuracy=0.749, val_loss=2.24, val_accuracy=0.441, lr=0.0316] 41%|████▏     | 31/75 [11:55<15:58, 21.78s/epoch, loss=1.16, accuracy=0.749, val_loss=2.39, val_accuracy=0.477, lr=0.1]    43%|████▎     | 32/75 [12:17<15:37, 21.80s/epoch, loss=1.16, accuracy=0.749, val_loss=3.12, val_accuracy=0.288, lr=0.1] 44%|████▍     | 33/75 [12:39<15:21, 21.93s/epoch, loss=1.16, accuracy=0.749, val_loss=3.9, val_accuracy=0.294, lr=0.1]  45%|████▌     | 34/75 [13:00<14:56, 21.85s/epoch, loss=1.15, accuracy=0.748, val_loss=2.58, val_accuracy=0.402, lr=0.1] 47%|████▋     | 35/75 [13:23<14:38, 21.97s/epoch, loss=1.16, accuracy=0.753, val_loss=1.8, val_accuracy=0.544, lr=0.0316] 48%|████▊     | 36/75 [13:45<14:20, 22.08s/epoch, loss=1.15, accuracy=0.748, val_loss=3.84, val_accuracy=0.353, lr=0.1]   49%|████▉     | 37/75 [14:07<13:52, 21.91s/epoch, loss=1.15, accuracy=0.749, val_loss=1.78, val_accuracy=0.584, lr=0.1] 51%|█████     | 38/75 [14:28<13:30, 21.91s/epoch, loss=1.15, accuracy=0.748, val_loss=2.32, val_accuracy=0.426, lr=0.1] 52%|█████▏    | 39/75 [14:50<13:07, 21.88s/epoch, loss=1.15, accuracy=0.749, val_loss=1.65, val_accuracy=0.61, lr=0.1]  53%|█████▎    | 40/75 [15:13<12:51, 22.03s/epoch, loss=1.15, accuracy=0.751, val_loss=2.23, val_accuracy=0.479, lr=0.0316] 55%|█████▍    | 41/75 [15:35<12:31, 22.11s/epoch, loss=1.15, accuracy=0.75, val_loss=2, val_accuracy=0.479, lr=0.1]        56%|█████▌    | 42/75 [15:57<12:09, 22.10s/epoch, loss=1.15, accuracy=0.75, val_loss=2.16, val_accuracy=0.498, lr=0.1] 57%|█████▋    | 43/75 [16:19<11:48, 22.15s/epoch, loss=1.14, accuracy=0.753, val_loss=2.46, val_accuracy=0.493, lr=0.1] 59%|█████▊    | 44/75 [16:42<11:29, 22.25s/epoch, loss=1.14, accuracy=0.756, val_loss=1.61, val_accuracy=0.596, lr=0.1] 60%|██████    | 45/75 [17:04<11:04, 22.15s/epoch, loss=1.14, accuracy=0.753, val_loss=1.74, val_accuracy=0.598, lr=0.0316] 61%|██████▏   | 46/75 [17:26<10:42, 22.17s/epoch, loss=1.14, accuracy=0.754, val_loss=2.57, val_accuracy=0.427, lr=0.1]    63%|██████▎   | 47/75 [17:48<10:22, 22.24s/epoch, loss=1.14, accuracy=0.754, val_loss=2.44, val_accuracy=0.437, lr=0.1] 64%|██████▍   | 48/75 [18:10<09:58, 22.16s/epoch, loss=1.14, accuracy=0.752, val_loss=2.48, val_accuracy=0.4, lr=0.1]   65%|██████▌   | 49/75 [18:33<09:36, 22.18s/epoch, loss=1.14, accuracy=0.753, val_loss=1.6, val_accuracy=0.604, lr=0.1] 67%|██████▋   | 50/75 [18:55<09:15, 22.23s/epoch, loss=1.14, accuracy=0.752, val_loss=2.19, val_accuracy=0.456, lr=0.0316] 68%|██████▊   | 51/75 [19:17<08:50, 22.10s/epoch, loss=1.14, accuracy=0.753, val_loss=4.1, val_accuracy=0.238, lr=0.1]     69%|██████▉   | 52/75 [19:39<08:31, 22.22s/epoch, loss=1.14, accuracy=0.755, val_loss=2.18, val_accuracy=0.501, lr=0.1] 71%|███████   | 53/75 [20:02<08:10, 22.30s/epoch, loss=1.14, accuracy=0.755, val_loss=2.51, val_accuracy=0.435, lr=0.1] 72%|███████▏  | 54/75 [20:24<07:48, 22.33s/epoch, loss=1.13, accuracy=0.754, val_loss=2.24, val_accuracy=0.456, lr=0.1] 73%|███████▎  | 55/75 [20:46<07:23, 22.19s/epoch, loss=1.14, accuracy=0.756, val_loss=2.31, val_accuracy=0.422, lr=0.0316] 75%|███████▍  | 56/75 [21:08<07:00, 22.16s/epoch, loss=1.13, accuracy=0.756, val_loss=2.54, val_accuracy=0.353, lr=0.1]    76%|███████▌  | 57/75 [21:30<06:36, 22.03s/epoch, loss=1.13, accuracy=0.757, val_loss=1.61, val_accuracy=0.587, lr=0.1] 77%|███████▋  | 58/75 [21:52<06:14, 22.01s/epoch, loss=1.14, accuracy=0.754, val_loss=3.15, val_accuracy=0.305, lr=0.1] 79%|███████▊  | 59/75 [22:14<05:54, 22.13s/epoch, loss=1.13, accuracy=0.755, val_loss=2.4, val_accuracy=0.45, lr=0.1]   80%|████████  | 60/75 [22:36<05:31, 22.12s/epoch, loss=1.13, accuracy=0.756, val_loss=2.43, val_accuracy=0.449, lr=0.0316] 81%|████████▏ | 61/75 [22:59<05:10, 22.19s/epoch, loss=1.13, accuracy=0.756, val_loss=3.8, val_accuracy=0.253, lr=0.1]     83%|████████▎ | 62/75 [23:21<04:48, 22.17s/epoch, loss=1.13, accuracy=0.757, val_loss=3.21, val_accuracy=0.285, lr=0.1] 84%|████████▍ | 63/75 [23:42<04:24, 22.07s/epoch, loss=1.13, accuracy=0.755, val_loss=2.11, val_accuracy=0.506, lr=0.1] 85%|████████▌ | 64/75 [24:05<04:03, 22.14s/epoch, loss=1.14, accuracy=0.755, val_loss=2.22, val_accuracy=0.549, lr=0.1] 87%|████████▋ | 65/75 [24:27<03:41, 22.19s/epoch, loss=1.13, accuracy=0.755, val_loss=2.43, val_accuracy=0.387, lr=0.0316] 88%|████████▊ | 66/75 [24:49<03:18, 22.02s/epoch, loss=1.13, accuracy=0.753, val_loss=1.6, val_accuracy=0.574, lr=0.1]     89%|████████▉ | 67/75 [25:09<02:52, 21.58s/epoch, loss=1.13, accuracy=0.757, val_loss=2.91, val_accuracy=0.368, lr=0.1] 91%|█████████ | 68/75 [25:31<02:31, 21.69s/epoch, loss=1.13, accuracy=0.755, val_loss=1.92, val_accuracy=0.538, lr=0.1] 92%|█████████▏| 69/75 [25:53<02:10, 21.72s/epoch, loss=1.13, accuracy=0.756, val_loss=1.62, val_accuracy=0.601, lr=0.1] 93%|█████████▎| 70/75 [26:15<01:48, 21.68s/epoch, loss=1.13, accuracy=0.754, val_loss=1.54, val_accuracy=0.615, lr=0.0316] 95%|█████████▍| 71/75 [26:36<01:26, 21.54s/epoch, loss=1.13, accuracy=0.753, val_loss=1.48, val_accuracy=0.635, lr=0.1]    96%|█████████▌| 72/75 [26:58<01:04, 21.61s/epoch, loss=1.13, accuracy=0.755, val_loss=2.04, val_accuracy=0.507, lr=0.1] 97%|█████████▋| 73/75 [27:19<00:43, 21.61s/epoch, loss=1.13, accuracy=0.755, val_loss=2.07, val_accuracy=0.514, lr=0.1] 99%|█████████▊| 74/75 [27:41<00:21, 21.75s/epoch, loss=1.13, accuracy=0.754, val_loss=1.99, val_accuracy=0.48, lr=0.1] 100%|██████████| 75/75 [28:04<00:00, 21.93s/epoch, loss=1.13, accuracy=0.754, val_loss=1.84, val_accuracy=0.533, lr=0.1]100%|██████████| 75/75 [28:04<00:00, 22.45s/epoch, loss=1.13, accuracy=0.754, val_loss=1.84, val_accuracy=0.533, lr=0.1]
Using real-time data augmentation.
Test loss: 1.839492917060852
Test accuracy: 0.5331000089645386


* * * Run SGD for ID = 20_3. * * *


2024-02-15 21:15:10.269446: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 21:15:20.781237: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 21:15:20.782375: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-15 21:15:20.820732: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-15 21:15:20.820759: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 21:15:20.825119: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 21:15:20.825158: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 21:15:20.861410: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 21:15:20.862640: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 21:15:20.865970: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 21:15:20.867948: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 21:15:20.873733: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 21:15:20.875407: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 21:15:20.875489: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 21:15:22.080844: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-15 21:15:22.081953: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 21:15:22.082565: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-15 21:15:22.082610: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 21:15:22.082662: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 21:15:22.082681: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 21:15:22.082699: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 21:15:22.082717: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 21:15:22.082734: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 21:15:22.082752: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 21:15:22.082770: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 21:15:22.083243: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 21:15:22.083306: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 21:15:22.724626: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-15 21:15:22.724682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-15 21:15:22.724691: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-15 21:15:22.725641: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': 203, 'batch_size': 128, 'epochs': 75, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/75 [00:00<?, ?epoch/s]2024-02-15 21:15:23.482096: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-15 21:15:23.494387: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2599900000 Hz
2024-02-15 21:15:25.304109: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 21:15:25.504444: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 21:15:29.077732: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-15 21:15:29.110269: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|▏         | 1/75 [00:52<1:04:30, 52.30s/epoch, loss=3.25, accuracy=0.255, val_loss=2.92, val_accuracy=0.132, lr=0.1]  3%|▎         | 2/75 [01:14<42:09, 34.65s/epoch, loss=1.61, accuracy=0.501, val_loss=3.86, val_accuracy=0.27, lr=0.1]     4%|▍         | 3/75 [01:37<34:55, 29.10s/epoch, loss=1.33, accuracy=0.648, val_loss=5.34, val_accuracy=0.255, lr=0.1]  5%|▌         | 4/75 [01:59<31:23, 26.53s/epoch, loss=1.27, accuracy=0.686, val_loss=2.48, val_accuracy=0.457, lr=0.1]  7%|▋         | 5/75 [02:22<29:21, 25.17s/epoch, loss=1.24, accuracy=0.698, val_loss=2.41, val_accuracy=0.428, lr=0.1]  8%|▊         | 6/75 [02:44<27:47, 24.17s/epoch, loss=1.23, accuracy=0.71, val_loss=1.88, val_accuracy=0.473, lr=0.1]   9%|▉         | 7/75 [03:07<26:46, 23.63s/epoch, loss=1.22, accuracy=0.718, val_loss=1.81, val_accuracy=0.522, lr=0.1] 11%|█         | 8/75 [03:29<26:00, 23.29s/epoch, loss=1.21, accuracy=0.722, val_loss=1.66, val_accuracy=0.58, lr=0.1]  12%|█▏        | 9/75 [03:52<25:17, 22.99s/epoch, loss=1.2, accuracy=0.725, val_loss=1.65, val_accuracy=0.595, lr=0.1] 13%|█▎        | 10/75 [04:14<24:44, 22.84s/epoch, loss=1.19, accuracy=0.732, val_loss=2.66, val_accuracy=0.391, lr=0.1] 15%|█▍        | 11/75 [04:36<24:12, 22.69s/epoch, loss=1.19, accuracy=0.733, val_loss=1.39, val_accuracy=0.663, lr=0.1] 16%|█▌        | 12/75 [04:59<23:43, 22.59s/epoch, loss=1.18, accuracy=0.735, val_loss=1.89, val_accuracy=0.486, lr=0.1] 17%|█▋        | 13/75 [05:20<22:51, 22.12s/epoch, loss=1.18, accuracy=0.738, val_loss=1.9, val_accuracy=0.518, lr=0.1]  19%|█▊        | 14/75 [05:42<22:31, 22.15s/epoch, loss=1.18, accuracy=0.737, val_loss=2.01, val_accuracy=0.496, lr=0.1] 20%|██        | 15/75 [06:04<22:11, 22.20s/epoch, loss=1.16, accuracy=0.74, val_loss=3.12, val_accuracy=0.408, lr=0.1]  21%|██▏       | 16/75 [06:27<21:58, 22.35s/epoch, loss=1.16, accuracy=0.744, val_loss=1.99, val_accuracy=0.507, lr=0.0316] 23%|██▎       | 17/75 [06:49<21:33, 22.30s/epoch, loss=1.17, accuracy=0.74, val_loss=1.59, val_accuracy=0.596, lr=0.1]     24%|██▍       | 18/75 [07:11<21:07, 22.24s/epoch, loss=1.18, accuracy=0.741, val_loss=5.9, val_accuracy=0.169, lr=0.1] 25%|██▌       | 19/75 [07:34<20:49, 22.32s/epoch, loss=1.16, accuracy=0.741, val_loss=1.85, val_accuracy=0.542, lr=0.1] 27%|██▋       | 20/75 [07:56<20:22, 22.23s/epoch, loss=1.16, accuracy=0.745, val_loss=2.1, val_accuracy=0.476, lr=0.1]  28%|██▊       | 21/75 [08:18<19:53, 22.11s/epoch, loss=1.16, accuracy=0.744, val_loss=2.12, val_accuracy=0.483, lr=0.0316] 29%|██▉       | 22/75 [08:40<19:40, 22.27s/epoch, loss=1.16, accuracy=0.743, val_loss=1.32, val_accuracy=0.694, lr=0.1]    31%|███       | 23/75 [09:03<19:17, 22.27s/epoch, loss=1.15, accuracy=0.747, val_loss=2.21, val_accuracy=0.491, lr=0.1] 32%|███▏      | 24/75 [09:23<18:29, 21.76s/epoch, loss=1.16, accuracy=0.745, val_loss=1.46, val_accuracy=0.643, lr=0.1] 33%|███▎      | 25/75 [09:46<18:16, 21.94s/epoch, loss=1.15, accuracy=0.745, val_loss=2.46, val_accuracy=0.396, lr=0.1] 35%|███▍      | 26/75 [10:07<17:50, 21.86s/epoch, loss=1.15, accuracy=0.747, val_loss=1.64, val_accuracy=0.593, lr=0.1] 36%|███▌      | 27/75 [10:30<17:37, 22.02s/epoch, loss=1.14, accuracy=0.751, val_loss=1.86, val_accuracy=0.496, lr=0.0316] 37%|███▋      | 28/75 [10:52<17:23, 22.21s/epoch, loss=1.15, accuracy=0.747, val_loss=1.69, val_accuracy=0.572, lr=0.1]    39%|███▊      | 29/75 [11:15<17:07, 22.34s/epoch, loss=1.15, accuracy=0.747, val_loss=2.21, val_accuracy=0.549, lr=0.1] 40%|████      | 30/75 [11:38<16:49, 22.42s/epoch, loss=1.14, accuracy=0.748, val_loss=1.93, val_accuracy=0.553, lr=0.1] 41%|████▏     | 31/75 [12:00<16:28, 22.46s/epoch, loss=1.15, accuracy=0.748, val_loss=1.5, val_accuracy=0.625, lr=0.1]  43%|████▎     | 32/75 [12:22<16:04, 22.44s/epoch, loss=1.14, accuracy=0.751, val_loss=4.28, val_accuracy=0.212, lr=0.0316] 44%|████▍     | 33/75 [12:44<15:35, 22.28s/epoch, loss=1.14, accuracy=0.75, val_loss=2.44, val_accuracy=0.46, lr=0.1]      45%|████▌     | 34/75 [13:07<15:12, 22.26s/epoch, loss=1.15, accuracy=0.747, val_loss=1.66, val_accuracy=0.572, lr=0.1] 47%|████▋     | 35/75 [13:29<14:47, 22.19s/epoch, loss=1.14, accuracy=0.749, val_loss=2.99, val_accuracy=0.415, lr=0.1] 48%|████▊     | 36/75 [13:51<14:28, 22.28s/epoch, loss=1.14, accuracy=0.751, val_loss=1.85, val_accuracy=0.542, lr=0.1] 49%|████▉     | 37/75 [14:14<14:09, 22.36s/epoch, loss=1.14, accuracy=0.751, val_loss=2.7, val_accuracy=0.252, lr=0.0316] 51%|█████     | 38/75 [14:35<13:41, 22.21s/epoch, loss=1.14, accuracy=0.749, val_loss=2.27, val_accuracy=0.479, lr=0.1]   52%|█████▏    | 39/75 [14:58<13:21, 22.26s/epoch, loss=1.14, accuracy=0.752, val_loss=3.07, val_accuracy=0.25, lr=0.1]  53%|█████▎    | 40/75 [15:20<13:00, 22.31s/epoch, loss=1.14, accuracy=0.751, val_loss=1.84, val_accuracy=0.518, lr=0.1] 55%|█████▍    | 41/75 [15:42<12:34, 22.18s/epoch, loss=1.14, accuracy=0.75, val_loss=2.32, val_accuracy=0.438, lr=0.1]  56%|█████▌    | 42/75 [16:04<12:13, 22.22s/epoch, loss=1.13, accuracy=0.753, val_loss=1.66, val_accuracy=0.567, lr=0.0316] 57%|█████▋    | 43/75 [16:27<11:54, 22.32s/epoch, loss=1.14, accuracy=0.753, val_loss=3.07, val_accuracy=0.301, lr=0.1]    59%|█████▊    | 44/75 [16:49<11:29, 22.26s/epoch, loss=1.13, accuracy=0.754, val_loss=1.36, val_accuracy=0.679, lr=0.1] 60%|██████    | 45/75 [17:11<11:08, 22.27s/epoch, loss=1.14, accuracy=0.753, val_loss=2.14, val_accuracy=0.434, lr=0.1] 61%|██████▏   | 46/75 [17:33<10:37, 21.99s/epoch, loss=1.14, accuracy=0.752, val_loss=2, val_accuracy=0.531, lr=0.1]    63%|██████▎   | 47/75 [17:55<10:16, 22.03s/epoch, loss=1.14, accuracy=0.752, val_loss=1.63, val_accuracy=0.576, lr=0.0316] 64%|██████▍   | 48/75 [18:16<09:45, 21.68s/epoch, loss=1.14, accuracy=0.751, val_loss=1.64, val_accuracy=0.58, lr=0.1]     65%|██████▌   | 49/75 [18:38<09:25, 21.76s/epoch, loss=1.13, accuracy=0.753, val_loss=2.2, val_accuracy=0.472, lr=0.1] 67%|██████▋   | 50/75 [19:00<09:06, 21.86s/epoch, loss=1.13, accuracy=0.754, val_loss=17.4, val_accuracy=0.112, lr=0.1] 68%|██████▊   | 51/75 [19:22<08:48, 22.02s/epoch, loss=1.14, accuracy=0.753, val_loss=2.16, val_accuracy=0.485, lr=0.1] 69%|██████▉   | 52/75 [19:45<08:29, 22.13s/epoch, loss=1.13, accuracy=0.751, val_loss=2.27, val_accuracy=0.386, lr=0.0316] 71%|███████   | 53/75 [20:07<08:07, 22.17s/epoch, loss=1.13, accuracy=0.756, val_loss=2.23, val_accuracy=0.512, lr=0.1]    72%|███████▏  | 54/75 [20:29<07:45, 22.16s/epoch, loss=1.14, accuracy=0.751, val_loss=1.52, val_accuracy=0.623, lr=0.1] 73%|███████▎  | 55/75 [20:52<07:25, 22.29s/epoch, loss=1.13, accuracy=0.754, val_loss=2.42, val_accuracy=0.459, lr=0.1] 75%|███████▍  | 56/75 [21:14<07:04, 22.35s/epoch, loss=1.13, accuracy=0.753, val_loss=3.73, val_accuracy=0.283, lr=0.1] 76%|███████▌  | 57/75 [21:36<06:38, 22.16s/epoch, loss=1.14, accuracy=0.752, val_loss=1.82, val_accuracy=0.536, lr=0.0316] 77%|███████▋  | 58/75 [21:58<06:16, 22.17s/epoch, loss=1.13, accuracy=0.755, val_loss=1.85, val_accuracy=0.548, lr=0.1]    79%|███████▊  | 59/75 [22:20<05:56, 22.26s/epoch, loss=1.13, accuracy=0.753, val_loss=2.42, val_accuracy=0.426, lr=0.1] 80%|████████  | 60/75 [22:43<05:35, 22.38s/epoch, loss=1.13, accuracy=0.754, val_loss=1.83, val_accuracy=0.555, lr=0.1] 81%|████████▏ | 61/75 [23:06<05:14, 22.44s/epoch, loss=1.13, accuracy=0.756, val_loss=1.65, val_accuracy=0.574, lr=0.1] 83%|████████▎ | 62/75 [23:28<04:50, 22.38s/epoch, loss=1.13, accuracy=0.753, val_loss=1.88, val_accuracy=0.538, lr=0.0316] 84%|████████▍ | 63/75 [23:49<04:25, 22.09s/epoch, loss=1.13, accuracy=0.753, val_loss=1.62, val_accuracy=0.602, lr=0.1]    85%|████████▌ | 64/75 [24:12<04:03, 22.16s/epoch, loss=1.13, accuracy=0.754, val_loss=2.54, val_accuracy=0.438, lr=0.1] 87%|████████▋ | 65/75 [24:34<03:42, 22.24s/epoch, loss=1.13, accuracy=0.756, val_loss=1.6, val_accuracy=0.605, lr=0.1]  88%|████████▊ | 66/75 [24:57<03:21, 22.37s/epoch, loss=1.13, accuracy=0.753, val_loss=1.57, val_accuracy=0.615, lr=0.1] 89%|████████▉ | 67/75 [25:19<02:58, 22.36s/epoch, loss=1.13, accuracy=0.754, val_loss=2.27, val_accuracy=0.478, lr=0.0316] 91%|█████████ | 68/75 [25:41<02:36, 22.31s/epoch, loss=1.13, accuracy=0.755, val_loss=4.11, val_accuracy=0.18, lr=0.1]     92%|█████████▏| 69/75 [26:04<02:14, 22.37s/epoch, loss=1.13, accuracy=0.753, val_loss=2.35, val_accuracy=0.364, lr=0.1] 93%|█████████▎| 70/75 [26:26<01:52, 22.40s/epoch, loss=1.13, accuracy=0.754, val_loss=1.84, val_accuracy=0.533, lr=0.1] 95%|█████████▍| 71/75 [26:49<01:29, 22.44s/epoch, loss=1.13, accuracy=0.753, val_loss=2.37, val_accuracy=0.44, lr=0.1]  96%|█████████▌| 72/75 [27:11<01:07, 22.45s/epoch, loss=1.13, accuracy=0.752, val_loss=4.19, val_accuracy=0.243, lr=0.0316] 97%|█████████▋| 73/75 [27:34<00:44, 22.45s/epoch, loss=1.12, accuracy=0.756, val_loss=2.17, val_accuracy=0.444, lr=0.1]    99%|█████████▊| 74/75 [27:56<00:22, 22.49s/epoch, loss=1.13, accuracy=0.753, val_loss=2.24, val_accuracy=0.422, lr=0.1]100%|██████████| 75/75 [28:19<00:00, 22.54s/epoch, loss=1.12, accuracy=0.754, val_loss=1.63, val_accuracy=0.58, lr=0.1] 100%|██████████| 75/75 [28:19<00:00, 22.66s/epoch, loss=1.12, accuracy=0.754, val_loss=1.63, val_accuracy=0.58, lr=0.1]
Using real-time data augmentation.
Test loss: 1.6285243034362793
Test accuracy: 0.5795000195503235


* * * Run SGD for ID = 20_4. * * *


2024-02-15 21:43:46.045395: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 21:43:48.611980: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 21:43:48.613152: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-15 21:43:48.649405: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-15 21:43:48.649434: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 21:43:48.652895: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 21:43:48.652934: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 21:43:48.655241: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 21:43:48.655981: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 21:43:48.658190: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 21:43:48.659623: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 21:43:48.664064: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 21:43:48.664551: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 21:43:48.664641: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 21:43:49.844066: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-15 21:43:49.845127: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 21:43:49.845800: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-15 21:43:49.845837: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 21:43:49.845889: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 21:43:49.845908: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 21:43:49.845925: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 21:43:49.845943: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 21:43:49.845960: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 21:43:49.845978: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 21:43:49.845996: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 21:43:49.846423: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 21:43:49.846460: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 21:43:50.458814: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-15 21:43:50.458874: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-15 21:43:50.458883: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-15 21:43:50.459814: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': 204, 'batch_size': 128, 'epochs': 75, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/75 [00:00<?, ?epoch/s]2024-02-15 21:43:51.226959: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-15 21:43:51.239395: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2599900000 Hz
2024-02-15 21:43:53.059501: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 21:43:53.283307: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 21:43:54.100639: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-15 21:43:54.192425: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|▏         | 1/75 [00:54<1:06:51, 54.21s/epoch, loss=3.19, accuracy=0.303, val_loss=2.24, val_accuracy=0.274, lr=0.1]  3%|▎         | 2/75 [01:15<42:40, 35.08s/epoch, loss=1.64, accuracy=0.489, val_loss=3.98, val_accuracy=0.237, lr=0.1]    4%|▍         | 3/75 [01:38<35:03, 29.22s/epoch, loss=1.45, accuracy=0.593, val_loss=3.33, val_accuracy=0.252, lr=0.1]  5%|▌         | 4/75 [01:59<30:55, 26.13s/epoch, loss=1.32, accuracy=0.664, val_loss=2.45, val_accuracy=0.366, lr=0.1]  7%|▋         | 5/75 [02:22<29:19, 25.14s/epoch, loss=1.27, accuracy=0.696, val_loss=2.1, val_accuracy=0.502, lr=0.1]   8%|▊         | 6/75 [02:45<28:01, 24.36s/epoch, loss=1.25, accuracy=0.707, val_loss=1.91, val_accuracy=0.536, lr=0.1]  9%|▉         | 7/75 [03:09<27:18, 24.09s/epoch, loss=1.23, accuracy=0.718, val_loss=2.27, val_accuracy=0.459, lr=0.1] 11%|█         | 8/75 [03:32<26:37, 23.84s/epoch, loss=1.22, accuracy=0.726, val_loss=2.2, val_accuracy=0.493, lr=0.1]  12%|█▏        | 9/75 [03:56<26:09, 23.78s/epoch, loss=1.22, accuracy=0.728, val_loss=2.16, val_accuracy=0.492, lr=0.1] 13%|█▎        | 10/75 [04:19<25:29, 23.54s/epoch, loss=1.2, accuracy=0.733, val_loss=2.38, val_accuracy=0.436, lr=0.1] 15%|█▍        | 11/75 [04:42<25:01, 23.47s/epoch, loss=1.21, accuracy=0.732, val_loss=5.99, val_accuracy=0.254, lr=0.0316] 16%|█▌        | 12/75 [05:05<24:31, 23.36s/epoch, loss=1.21, accuracy=0.735, val_loss=2.16, val_accuracy=0.495, lr=0.1]    17%|█▋        | 13/75 [05:29<24:07, 23.35s/epoch, loss=1.2, accuracy=0.738, val_loss=2.03, val_accuracy=0.529, lr=0.1]  19%|█▊        | 14/75 [05:52<23:46, 23.38s/epoch, loss=1.19, accuracy=0.739, val_loss=1.72, val_accuracy=0.586, lr=0.1] 20%|██        | 15/75 [06:16<23:26, 23.45s/epoch, loss=1.19, accuracy=0.74, val_loss=1.9, val_accuracy=0.561, lr=0.1]   21%|██▏       | 16/75 [06:40<23:15, 23.65s/epoch, loss=1.18, accuracy=0.742, val_loss=2.87, val_accuracy=0.413, lr=0.1] 23%|██▎       | 17/75 [07:03<22:43, 23.50s/epoch, loss=1.19, accuracy=0.74, val_loss=3.49, val_accuracy=0.303, lr=0.1]  24%|██▍       | 18/75 [07:26<22:12, 23.38s/epoch, loss=1.19, accuracy=0.742, val_loss=1.92, val_accuracy=0.553, lr=0.1] 25%|██▌       | 19/75 [07:49<21:37, 23.17s/epoch, loss=1.18, accuracy=0.747, val_loss=1.78, val_accuracy=0.527, lr=0.0316] 27%|██▋       | 20/75 [08:11<20:58, 22.88s/epoch, loss=1.18, accuracy=0.746, val_loss=2.07, val_accuracy=0.516, lr=0.1]    28%|██▊       | 21/75 [08:34<20:33, 22.84s/epoch, loss=1.18, accuracy=0.747, val_loss=3.28, val_accuracy=0.405, lr=0.1] 29%|██▉       | 22/75 [08:56<20:05, 22.75s/epoch, loss=1.18, accuracy=0.745, val_loss=2.81, val_accuracy=0.386, lr=0.1] 31%|███       | 23/75 [09:18<19:28, 22.48s/epoch, loss=1.17, accuracy=0.748, val_loss=2.66, val_accuracy=0.335, lr=0.1] 32%|███▏      | 24/75 [09:40<19:05, 22.46s/epoch, loss=1.17, accuracy=0.747, val_loss=2.25, val_accuracy=0.404, lr=0.0316] 33%|███▎      | 25/75 [10:03<18:44, 22.49s/epoch, loss=1.16, accuracy=0.752, val_loss=2.54, val_accuracy=0.402, lr=0.1]    35%|███▍      | 26/75 [10:26<18:32, 22.70s/epoch, loss=1.16, accuracy=0.75, val_loss=1.81, val_accuracy=0.533, lr=0.1]  36%|███▌      | 27/75 [10:48<18:05, 22.61s/epoch, loss=1.16, accuracy=0.751, val_loss=1.98, val_accuracy=0.495, lr=0.1] 37%|███▋      | 28/75 [11:12<17:48, 22.73s/epoch, loss=1.16, accuracy=0.752, val_loss=1.79, val_accuracy=0.541, lr=0.1] 39%|███▊      | 29/75 [11:34<17:22, 22.66s/epoch, loss=1.15, accuracy=0.749, val_loss=2.05, val_accuracy=0.454, lr=0.0316] 40%|████      | 30/75 [11:57<16:58, 22.63s/epoch, loss=1.15, accuracy=0.753, val_loss=2.31, val_accuracy=0.469, lr=0.1]    41%|████▏     | 31/75 [12:18<16:17, 22.22s/epoch, loss=1.15, accuracy=0.753, val_loss=2, val_accuracy=0.488, lr=0.1]    43%|████▎     | 32/75 [12:41<16:03, 22.42s/epoch, loss=1.15, accuracy=0.754, val_loss=4.08, val_accuracy=0.317, lr=0.1] 44%|████▍     | 33/75 [13:03<15:33, 22.23s/epoch, loss=1.15, accuracy=0.754, val_loss=1.98, val_accuracy=0.514, lr=0.1] 45%|████▌     | 34/75 [13:25<15:17, 22.39s/epoch, loss=1.15, accuracy=0.754, val_loss=2.64, val_accuracy=0.313, lr=0.0316] 47%|████▋     | 35/75 [13:48<14:58, 22.45s/epoch, loss=1.14, accuracy=0.755, val_loss=1.94, val_accuracy=0.482, lr=0.1]    48%|████▊     | 36/75 [14:11<14:39, 22.54s/epoch, loss=1.14, accuracy=0.754, val_loss=2.17, val_accuracy=0.441, lr=0.1] 49%|████▉     | 37/75 [14:33<14:19, 22.62s/epoch, loss=1.14, accuracy=0.755, val_loss=2.8, val_accuracy=0.408, lr=0.1]  51%|█████     | 38/75 [14:56<13:53, 22.52s/epoch, loss=1.14, accuracy=0.753, val_loss=2.05, val_accuracy=0.467, lr=0.1] 52%|█████▏    | 39/75 [15:19<13:34, 22.63s/epoch, loss=1.15, accuracy=0.754, val_loss=2.11, val_accuracy=0.46, lr=0.0316] 53%|█████▎    | 40/75 [15:41<13:12, 22.65s/epoch, loss=1.14, accuracy=0.754, val_loss=1.88, val_accuracy=0.555, lr=0.1]   55%|█████▍    | 41/75 [16:04<12:49, 22.64s/epoch, loss=1.14, accuracy=0.758, val_loss=1.62, val_accuracy=0.599, lr=0.1] 56%|█████▌    | 42/75 [16:26<12:24, 22.56s/epoch, loss=1.13, accuracy=0.754, val_loss=1.72, val_accuracy=0.576, lr=0.1] 57%|█████▋    | 43/75 [16:48<11:51, 22.24s/epoch, loss=1.14, accuracy=0.756, val_loss=2.68, val_accuracy=0.411, lr=0.1] 59%|█████▊    | 44/75 [17:10<11:32, 22.33s/epoch, loss=1.14, accuracy=0.756, val_loss=1.65, val_accuracy=0.573, lr=0.1] 60%|██████    | 45/75 [17:33<11:14, 22.49s/epoch, loss=1.14, accuracy=0.757, val_loss=1.79, val_accuracy=0.582, lr=0.1] 61%|██████▏   | 46/75 [17:55<10:43, 22.17s/epoch, loss=1.13, accuracy=0.756, val_loss=1.74, val_accuracy=0.559, lr=0.0316] 63%|██████▎   | 47/75 [18:17<10:21, 22.21s/epoch, loss=1.13, accuracy=0.756, val_loss=2.34, val_accuracy=0.383, lr=0.1]    64%|██████▍   | 48/75 [18:39<10:00, 22.24s/epoch, loss=1.14, accuracy=0.758, val_loss=1.91, val_accuracy=0.484, lr=0.1] 65%|██████▌   | 49/75 [19:01<09:31, 21.97s/epoch, loss=1.13, accuracy=0.758, val_loss=1.91, val_accuracy=0.508, lr=0.1] 67%|██████▋   | 50/75 [19:23<09:12, 22.11s/epoch, loss=1.13, accuracy=0.756, val_loss=1.4, val_accuracy=0.667, lr=0.1]  68%|██████▊   | 51/75 [19:46<08:54, 22.28s/epoch, loss=1.13, accuracy=0.756, val_loss=1.66, val_accuracy=0.59, lr=0.1] 69%|██████▉   | 52/75 [20:08<08:32, 22.29s/epoch, loss=1.13, accuracy=0.756, val_loss=3.03, val_accuracy=0.422, lr=0.1] 71%|███████   | 53/75 [20:30<08:11, 22.33s/epoch, loss=1.14, accuracy=0.757, val_loss=2.19, val_accuracy=0.411, lr=0.1] 72%|███████▏  | 54/75 [20:53<07:50, 22.38s/epoch, loss=1.13, accuracy=0.757, val_loss=1.61, val_accuracy=0.61, lr=0.1]  73%|███████▎  | 55/75 [21:16<07:30, 22.52s/epoch, loss=1.13, accuracy=0.756, val_loss=2.42, val_accuracy=0.473, lr=0.0316] 75%|███████▍  | 56/75 [21:38<07:08, 22.57s/epoch, loss=1.14, accuracy=0.756, val_loss=1.72, val_accuracy=0.6, lr=0.1]      76%|███████▌  | 57/75 [22:01<06:46, 22.60s/epoch, loss=1.13, accuracy=0.759, val_loss=1.51, val_accuracy=0.628, lr=0.1] 77%|███████▋  | 58/75 [22:24<06:25, 22.70s/epoch, loss=1.12, accuracy=0.758, val_loss=2.13, val_accuracy=0.464, lr=0.1] 79%|███████▊  | 59/75 [22:47<06:03, 22.69s/epoch, loss=1.12, accuracy=0.758, val_loss=1.66, val_accuracy=0.578, lr=0.1] 80%|████████  | 60/75 [23:09<05:39, 22.63s/epoch, loss=1.14, accuracy=0.754, val_loss=1.77, val_accuracy=0.552, lr=0.0316] 81%|████████▏ | 61/75 [23:31<05:14, 22.47s/epoch, loss=1.13, accuracy=0.76, val_loss=2.38, val_accuracy=0.432, lr=0.1]     83%|████████▎ | 62/75 [23:54<04:52, 22.52s/epoch, loss=1.13, accuracy=0.758, val_loss=2.27, val_accuracy=0.358, lr=0.1] 84%|████████▍ | 63/75 [24:16<04:28, 22.36s/epoch, loss=1.13, accuracy=0.758, val_loss=1.97, val_accuracy=0.443, lr=0.1] 85%|████████▌ | 64/75 [24:38<04:05, 22.35s/epoch, loss=1.12, accuracy=0.763, val_loss=1.77, val_accuracy=0.6, lr=0.1]   87%|████████▋ | 65/75 [25:01<03:43, 22.39s/epoch, loss=1.12, accuracy=0.757, val_loss=3.02, val_accuracy=0.313, lr=0.0316] 88%|████████▊ | 66/75 [25:23<03:22, 22.50s/epoch, loss=1.12, accuracy=0.758, val_loss=2.66, val_accuracy=0.313, lr=0.1]    89%|████████▉ | 67/75 [25:45<02:58, 22.27s/epoch, loss=1.12, accuracy=0.76, val_loss=2.01, val_accuracy=0.524, lr=0.1]  91%|█████████ | 68/75 [26:07<02:35, 22.23s/epoch, loss=1.12, accuracy=0.763, val_loss=1.51, val_accuracy=0.6, lr=0.1]  92%|█████████▏| 69/75 [26:30<02:13, 22.33s/epoch, loss=1.13, accuracy=0.757, val_loss=1.99, val_accuracy=0.507, lr=0.1] 93%|█████████▎| 70/75 [26:52<01:51, 22.32s/epoch, loss=1.12, accuracy=0.76, val_loss=5.06, val_accuracy=0.28, lr=0.0316] 95%|█████████▍| 71/75 [27:14<01:29, 22.26s/epoch, loss=1.12, accuracy=0.761, val_loss=1.57, val_accuracy=0.605, lr=0.1]  96%|█████████▌| 72/75 [27:36<01:06, 22.01s/epoch, loss=1.12, accuracy=0.761, val_loss=2.61, val_accuracy=0.41, lr=0.1]  97%|█████████▋| 73/75 [27:58<00:44, 22.12s/epoch, loss=1.12, accuracy=0.759, val_loss=2.15, val_accuracy=0.492, lr=0.1] 99%|█████████▊| 74/75 [28:20<00:22, 22.17s/epoch, loss=1.13, accuracy=0.759, val_loss=1.79, val_accuracy=0.582, lr=0.1]100%|██████████| 75/75 [28:42<00:00, 22.11s/epoch, loss=1.13, accuracy=0.756, val_loss=1.77, val_accuracy=0.561, lr=0.0316]100%|██████████| 75/75 [28:42<00:00, 22.97s/epoch, loss=1.13, accuracy=0.756, val_loss=1.77, val_accuracy=0.561, lr=0.0316]
Using real-time data augmentation.
Test loss: 1.7659251689910889
Test accuracy: 0.5605000257492065


* * * Run SGD for ID = 20_5. * * *


2024-02-15 22:12:36.661004: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 22:12:39.232220: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 22:12:39.233367: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-15 22:12:39.268999: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-15 22:12:39.269031: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 22:12:39.271736: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 22:12:39.271778: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 22:12:39.273912: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 22:12:39.274546: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 22:12:39.276766: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 22:12:39.278079: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 22:12:39.282854: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 22:12:39.283361: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 22:12:39.283450: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 22:12:40.486569: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-15 22:12:40.487158: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 22:12:40.487775: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-15 22:12:40.487804: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 22:12:40.487850: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 22:12:40.487869: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 22:12:40.487887: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 22:12:40.487904: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 22:12:40.487921: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 22:12:40.487938: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 22:12:40.487955: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 22:12:40.488375: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 22:12:40.488405: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 22:12:41.076533: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-15 22:12:41.076610: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-15 22:12:41.076619: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-15 22:12:41.077509: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': 205, 'batch_size': 128, 'epochs': 75, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/75 [00:00<?, ?epoch/s]2024-02-15 22:12:41.813759: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-15 22:12:41.825402: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2599900000 Hz
2024-02-15 22:12:43.562945: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 22:12:43.724081: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 22:12:44.939968: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-15 22:12:45.041416: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|▏         | 1/75 [00:54<1:06:54, 54.25s/epoch, loss=3.42, accuracy=0.309, val_loss=2.41, val_accuracy=0.245, lr=0.1]  3%|▎         | 2/75 [01:16<43:10, 35.48s/epoch, loss=1.54, accuracy=0.55, val_loss=1.61, val_accuracy=0.523, lr=0.1]     4%|▍         | 3/75 [01:38<35:14, 29.36s/epoch, loss=1.32, accuracy=0.648, val_loss=1.7, val_accuracy=0.532, lr=0.1]  5%|▌         | 4/75 [02:00<31:08, 26.32s/epoch, loss=1.26, accuracy=0.683, val_loss=1.47, val_accuracy=0.604, lr=0.1]  7%|▋         | 5/75 [02:21<28:42, 24.60s/epoch, loss=1.24, accuracy=0.7, val_loss=1.43, val_accuracy=0.63, lr=0.1]     8%|▊         | 6/75 [02:44<27:21, 23.79s/epoch, loss=1.22, accuracy=0.714, val_loss=1.64, val_accuracy=0.588, lr=0.1]  9%|▉         | 7/75 [03:06<26:25, 23.31s/epoch, loss=1.21, accuracy=0.719, val_loss=1.52, val_accuracy=0.593, lr=0.1] 11%|█         | 8/75 [03:27<25:19, 22.68s/epoch, loss=1.2, accuracy=0.726, val_loss=2.13, val_accuracy=0.421, lr=0.1]  12%|█▏        | 9/75 [03:48<24:25, 22.21s/epoch, loss=1.2, accuracy=0.726, val_loss=1.78, val_accuracy=0.539, lr=0.1] 13%|█▎        | 10/75 [04:10<23:58, 22.13s/epoch, loss=1.19, accuracy=0.733, val_loss=1.77, val_accuracy=0.52, lr=0.0316] 15%|█▍        | 11/75 [04:33<23:41, 22.21s/epoch, loss=1.19, accuracy=0.734, val_loss=1.72, val_accuracy=0.536, lr=0.1]   16%|█▌        | 12/75 [04:55<23:21, 22.25s/epoch, loss=1.19, accuracy=0.735, val_loss=2.48, val_accuracy=0.379, lr=0.1] 17%|█▋        | 13/75 [05:16<22:43, 21.99s/epoch, loss=1.18, accuracy=0.737, val_loss=1.74, val_accuracy=0.547, lr=0.1] 19%|█▊        | 14/75 [05:39<22:27, 22.09s/epoch, loss=1.17, accuracy=0.74, val_loss=1.86, val_accuracy=0.503, lr=0.1]  20%|██        | 15/75 [06:01<22:08, 22.14s/epoch, loss=1.18, accuracy=0.739, val_loss=2.38, val_accuracy=0.421, lr=0.0316] 21%|██▏       | 16/75 [06:23<21:45, 22.13s/epoch, loss=1.17, accuracy=0.744, val_loss=3.16, val_accuracy=0.31, lr=0.1]     23%|██▎       | 17/75 [06:46<21:27, 22.20s/epoch, loss=1.18, accuracy=0.742, val_loss=6.82, val_accuracy=0.217, lr=0.1] 24%|██▍       | 18/75 [07:08<21:06, 22.21s/epoch, loss=1.17, accuracy=0.741, val_loss=2.43, val_accuracy=0.445, lr=0.1] 25%|██▌       | 19/75 [07:30<20:41, 22.17s/epoch, loss=1.17, accuracy=0.744, val_loss=2.4, val_accuracy=0.386, lr=0.1]  27%|██▋       | 20/75 [07:52<20:17, 22.13s/epoch, loss=1.16, accuracy=0.747, val_loss=1.7, val_accuracy=0.579, lr=0.0316] 28%|██▊       | 21/75 [08:13<19:42, 21.91s/epoch, loss=1.16, accuracy=0.743, val_loss=2.09, val_accuracy=0.498, lr=0.1]   29%|██▉       | 22/75 [08:36<19:26, 22.01s/epoch, loss=1.16, accuracy=0.747, val_loss=2.15, val_accuracy=0.493, lr=0.1] 31%|███       | 23/75 [08:57<18:59, 21.91s/epoch, loss=1.16, accuracy=0.748, val_loss=1.98, val_accuracy=0.559, lr=0.1] 32%|███▏      | 24/75 [09:19<18:42, 22.00s/epoch, loss=1.16, accuracy=0.747, val_loss=2.56, val_accuracy=0.386, lr=0.1] 33%|███▎      | 25/75 [09:42<18:23, 22.06s/epoch, loss=1.15, accuracy=0.75, val_loss=1.51, val_accuracy=0.615, lr=0.0316] 35%|███▍      | 26/75 [10:04<18:05, 22.15s/epoch, loss=1.15, accuracy=0.747, val_loss=1.65, val_accuracy=0.607, lr=0.1]   36%|███▌      | 27/75 [10:26<17:48, 22.26s/epoch, loss=1.14, accuracy=0.752, val_loss=1.96, val_accuracy=0.507, lr=0.1] 37%|███▋      | 28/75 [10:48<17:21, 22.17s/epoch, loss=1.15, accuracy=0.748, val_loss=1.81, val_accuracy=0.589, lr=0.1] 39%|███▊      | 29/75 [11:11<17:03, 22.24s/epoch, loss=1.15, accuracy=0.751, val_loss=1.54, val_accuracy=0.613, lr=0.1] 40%|████      | 30/75 [11:33<16:39, 22.20s/epoch, loss=1.14, accuracy=0.75, val_loss=2.69, val_accuracy=0.306, lr=0.0316] 41%|████▏     | 31/75 [11:55<16:12, 22.10s/epoch, loss=1.14, accuracy=0.751, val_loss=3.75, val_accuracy=0.374, lr=0.1]   43%|████▎     | 32/75 [12:17<15:46, 22.01s/epoch, loss=1.14, accuracy=0.753, val_loss=1.6, val_accuracy=0.629, lr=0.1]  44%|████▍     | 33/75 [12:38<15:18, 21.87s/epoch, loss=1.15, accuracy=0.748, val_loss=4.41, val_accuracy=0.281, lr=0.1] 45%|████▌     | 34/75 [13:00<14:50, 21.73s/epoch, loss=1.13, accuracy=0.753, val_loss=2.14, val_accuracy=0.412, lr=0.1] 47%|████▋     | 35/75 [13:21<14:31, 21.78s/epoch, loss=1.14, accuracy=0.753, val_loss=2.3, val_accuracy=0.4, lr=0.0316] 48%|████▊     | 36/75 [13:43<14:12, 21.85s/epoch, loss=1.13, accuracy=0.756, val_loss=3.34, val_accuracy=0.376, lr=0.1] 49%|████▉     | 37/75 [14:05<13:48, 21.80s/epoch, loss=1.13, accuracy=0.753, val_loss=2.01, val_accuracy=0.503, lr=0.1] 51%|█████     | 38/75 [14:27<13:24, 21.73s/epoch, loss=1.13, accuracy=0.752, val_loss=4.27, val_accuracy=0.243, lr=0.1] 52%|█████▏    | 39/75 [14:49<13:02, 21.74s/epoch, loss=1.13, accuracy=0.754, val_loss=2.78, val_accuracy=0.401, lr=0.1] 53%|█████▎    | 40/75 [15:10<12:41, 21.76s/epoch, loss=1.13, accuracy=0.755, val_loss=2.35, val_accuracy=0.473, lr=0.0316] 55%|█████▍    | 41/75 [15:32<12:22, 21.82s/epoch, loss=1.13, accuracy=0.753, val_loss=6.22, val_accuracy=0.248, lr=0.1]    56%|█████▌    | 42/75 [15:55<12:04, 21.96s/epoch, loss=1.13, accuracy=0.754, val_loss=1.44, val_accuracy=0.664, lr=0.1] 57%|█████▋    | 43/75 [16:16<11:41, 21.92s/epoch, loss=1.13, accuracy=0.756, val_loss=3.01, val_accuracy=0.357, lr=0.1] 59%|█████▊    | 44/75 [16:39<11:21, 21.99s/epoch, loss=1.12, accuracy=0.756, val_loss=1.63, val_accuracy=0.585, lr=0.1] 60%|██████    | 45/75 [17:00<10:58, 21.96s/epoch, loss=1.13, accuracy=0.755, val_loss=2.23, val_accuracy=0.449, lr=0.0316] 61%|██████▏   | 46/75 [17:23<10:39, 22.05s/epoch, loss=1.13, accuracy=0.752, val_loss=1.5, val_accuracy=0.615, lr=0.1]     63%|██████▎   | 47/75 [17:45<10:19, 22.11s/epoch, loss=1.13, accuracy=0.754, val_loss=1.69, val_accuracy=0.566, lr=0.1] 64%|██████▍   | 48/75 [18:06<09:45, 21.68s/epoch, loss=1.13, accuracy=0.755, val_loss=2.22, val_accuracy=0.462, lr=0.1] 65%|██████▌   | 49/75 [18:27<09:23, 21.66s/epoch, loss=1.12, accuracy=0.755, val_loss=3.38, val_accuracy=0.382, lr=0.1] 67%|██████▋   | 50/75 [18:49<09:00, 21.63s/epoch, loss=1.13, accuracy=0.756, val_loss=3.44, val_accuracy=0.376, lr=0.0316] 68%|██████▊   | 51/75 [19:10<08:38, 21.62s/epoch, loss=1.13, accuracy=0.754, val_loss=2.84, val_accuracy=0.299, lr=0.1]    69%|██████▉   | 52/75 [19:33<08:20, 21.77s/epoch, loss=1.12, accuracy=0.754, val_loss=1.96, val_accuracy=0.5, lr=0.1]   71%|███████   | 53/75 [19:54<07:56, 21.66s/epoch, loss=1.12, accuracy=0.755, val_loss=1.66, val_accuracy=0.567, lr=0.1] 72%|███████▏  | 54/75 [20:15<07:32, 21.54s/epoch, loss=1.12, accuracy=0.755, val_loss=1.7, val_accuracy=0.576, lr=0.1]  73%|███████▎  | 55/75 [20:37<07:13, 21.69s/epoch, loss=1.12, accuracy=0.756, val_loss=2.67, val_accuracy=0.418, lr=0.0316] 75%|███████▍  | 56/75 [20:59<06:52, 21.73s/epoch, loss=1.12, accuracy=0.758, val_loss=2, val_accuracy=0.457, lr=0.1]       76%|███████▌  | 57/75 [21:21<06:33, 21.84s/epoch, loss=1.12, accuracy=0.758, val_loss=2.37, val_accuracy=0.391, lr=0.1] 77%|███████▋  | 58/75 [21:44<06:14, 22.03s/epoch, loss=1.12, accuracy=0.756, val_loss=2.26, val_accuracy=0.463, lr=0.1] 79%|███████▊  | 59/75 [22:06<05:52, 22.05s/epoch, loss=1.12, accuracy=0.757, val_loss=1.75, val_accuracy=0.57, lr=0.1]  80%|████████  | 60/75 [22:28<05:30, 22.06s/epoch, loss=1.12, accuracy=0.755, val_loss=2.13, val_accuracy=0.456, lr=0.0316] 81%|████████▏ | 61/75 [22:49<05:06, 21.86s/epoch, loss=1.11, accuracy=0.758, val_loss=1.87, val_accuracy=0.539, lr=0.1]    83%|████████▎ | 62/75 [23:11<04:46, 22.01s/epoch, loss=1.12, accuracy=0.758, val_loss=2.78, val_accuracy=0.284, lr=0.1] 84%|████████▍ | 63/75 [23:34<04:24, 22.02s/epoch, loss=1.12, accuracy=0.759, val_loss=4.48, val_accuracy=0.272, lr=0.1] 85%|████████▌ | 64/75 [23:56<04:03, 22.10s/epoch, loss=1.12, accuracy=0.757, val_loss=5.41, val_accuracy=0.213, lr=0.1] 87%|████████▋ | 65/75 [24:18<03:41, 22.11s/epoch, loss=1.12, accuracy=0.755, val_loss=1.8, val_accuracy=0.539, lr=0.0316] 88%|████████▊ | 66/75 [24:40<03:19, 22.11s/epoch, loss=1.12, accuracy=0.756, val_loss=1.93, val_accuracy=0.483, lr=0.1]   89%|████████▉ | 67/75 [25:02<02:55, 21.94s/epoch, loss=1.12, accuracy=0.756, val_loss=2.82, val_accuracy=0.391, lr=0.1] 91%|█████████ | 68/75 [25:24<02:33, 21.97s/epoch, loss=1.12, accuracy=0.755, val_loss=1.92, val_accuracy=0.54, lr=0.1]  92%|█████████▏| 69/75 [25:46<02:11, 21.96s/epoch, loss=1.12, accuracy=0.757, val_loss=2.77, val_accuracy=0.443, lr=0.1] 93%|█████████▎| 70/75 [26:07<01:49, 21.89s/epoch, loss=1.12, accuracy=0.755, val_loss=1.99, val_accuracy=0.461, lr=0.0316] 95%|█████████▍| 71/75 [26:29<01:27, 21.87s/epoch, loss=1.11, accuracy=0.757, val_loss=2.21, val_accuracy=0.469, lr=0.1]    96%|█████████▌| 72/75 [26:51<01:05, 21.95s/epoch, loss=1.12, accuracy=0.758, val_loss=1.71, val_accuracy=0.588, lr=0.1] 97%|█████████▋| 73/75 [27:13<00:43, 21.96s/epoch, loss=1.11, accuracy=0.758, val_loss=2.9, val_accuracy=0.398, lr=0.1]  99%|█████████▊| 74/75 [27:36<00:22, 22.05s/epoch, loss=1.11, accuracy=0.76, val_loss=3.76, val_accuracy=0.355, lr=0.1]100%|██████████| 75/75 [27:58<00:00, 22.21s/epoch, loss=1.12, accuracy=0.757, val_loss=1.57, val_accuracy=0.576, lr=0.0316]100%|██████████| 75/75 [27:58<00:00, 22.38s/epoch, loss=1.12, accuracy=0.757, val_loss=1.57, val_accuracy=0.576, lr=0.0316]
Using real-time data augmentation.
Test loss: 1.566838264465332
Test accuracy: 0.5764999985694885


* * * Run SGD for ID = 20_6. * * *


2024-02-15 22:40:43.785662: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 22:40:50.994628: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 22:40:51.003541: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-15 22:40:51.040824: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-15 22:40:51.040862: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 22:40:51.064514: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 22:40:51.064550: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 22:40:51.077478: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 22:40:51.096477: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 22:40:51.112738: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 22:40:51.127522: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 22:40:51.143775: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 22:40:51.144299: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 22:40:51.144388: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 22:40:52.409745: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-15 22:40:52.410798: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 22:40:52.411236: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-15 22:40:52.411266: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 22:40:52.411312: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 22:40:52.411333: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 22:40:52.411349: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 22:40:52.411364: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 22:40:52.411380: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 22:40:52.411397: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 22:40:52.411413: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 22:40:52.411846: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 22:40:52.411878: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 22:40:53.335943: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-15 22:40:53.336012: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-15 22:40:53.336021: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-15 22:40:53.337182: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': 206, 'batch_size': 128, 'epochs': 75, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/75 [00:00<?, ?epoch/s]2024-02-15 22:40:54.072632: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-15 22:40:54.073013: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2599900000 Hz
2024-02-15 22:40:55.758468: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 22:40:56.068446: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 22:40:57.722989: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-15 22:40:57.756996: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|▏         | 1/75 [00:44<54:37, 44.29s/epoch, loss=3.31, accuracy=0.306, val_loss=2.34, val_accuracy=0.234, lr=0.1]  3%|▎         | 2/75 [01:02<35:31, 29.20s/epoch, loss=1.58, accuracy=0.521, val_loss=2.06, val_accuracy=0.407, lr=0.1]  4%|▍         | 3/75 [01:24<30:39, 25.55s/epoch, loss=1.34, accuracy=0.628, val_loss=2.21, val_accuracy=0.403, lr=0.1]  5%|▌         | 4/75 [01:43<27:08, 22.94s/epoch, loss=1.26, accuracy=0.683, val_loss=1.67, val_accuracy=0.549, lr=0.1]  7%|▋         | 5/75 [02:02<25:07, 21.53s/epoch, loss=1.24, accuracy=0.701, val_loss=1.91, val_accuracy=0.497, lr=0.1]  8%|▊         | 6/75 [02:21<23:50, 20.73s/epoch, loss=1.22, accuracy=0.715, val_loss=1.52, val_accuracy=0.599, lr=0.1]  9%|▉         | 7/75 [02:40<23:04, 20.36s/epoch, loss=1.21, accuracy=0.72, val_loss=1.86, val_accuracy=0.541, lr=0.1]  11%|█         | 8/75 [02:59<22:14, 19.92s/epoch, loss=1.21, accuracy=0.727, val_loss=1.48, val_accuracy=0.644, lr=0.1] 12%|█▏        | 9/75 [03:19<21:46, 19.79s/epoch, loss=1.19, accuracy=0.731, val_loss=1.65, val_accuracy=0.549, lr=0.1] 13%|█▎        | 10/75 [03:39<21:42, 20.03s/epoch, loss=1.19, accuracy=0.732, val_loss=1.77, val_accuracy=0.56, lr=0.1] 15%|█▍        | 11/75 [03:59<21:16, 19.95s/epoch, loss=1.18, accuracy=0.734, val_loss=3.09, val_accuracy=0.373, lr=0.1] 16%|█▌        | 12/75 [04:19<21:01, 20.02s/epoch, loss=1.18, accuracy=0.74, val_loss=8.42, val_accuracy=0.28, lr=0.1]   17%|█▋        | 13/75 [04:40<20:45, 20.09s/epoch, loss=1.17, accuracy=0.739, val_loss=2.5, val_accuracy=0.404, lr=0.0316] 19%|█▊        | 14/75 [05:00<20:21, 20.03s/epoch, loss=1.17, accuracy=0.742, val_loss=1.75, val_accuracy=0.55, lr=0.1]    20%|██        | 15/75 [05:19<19:43, 19.72s/epoch, loss=1.17, accuracy=0.745, val_loss=1.72, val_accuracy=0.544, lr=0.1] 21%|██▏       | 16/75 [05:38<19:11, 19.52s/epoch, loss=1.17, accuracy=0.744, val_loss=1.72, val_accuracy=0.582, lr=0.1] 23%|██▎       | 17/75 [05:57<18:51, 19.51s/epoch, loss=1.17, accuracy=0.743, val_loss=2.58, val_accuracy=0.427, lr=0.1] 24%|██▍       | 18/75 [06:18<18:58, 19.97s/epoch, loss=1.17, accuracy=0.745, val_loss=1.76, val_accuracy=0.542, lr=0.0316] 25%|██▌       | 19/75 [06:37<18:21, 19.68s/epoch, loss=1.17, accuracy=0.742, val_loss=1.68, val_accuracy=0.557, lr=0.1]    27%|██▋       | 20/75 [06:57<18:06, 19.75s/epoch, loss=1.16, accuracy=0.744, val_loss=2.44, val_accuracy=0.331, lr=0.1] 28%|██▊       | 21/75 [07:17<17:53, 19.88s/epoch, loss=1.16, accuracy=0.746, val_loss=2, val_accuracy=0.469, lr=0.1]    29%|██▉       | 22/75 [07:37<17:35, 19.92s/epoch, loss=1.16, accuracy=0.749, val_loss=2.83, val_accuracy=0.231, lr=0.1] 31%|███       | 23/75 [07:56<17:00, 19.62s/epoch, loss=1.15, accuracy=0.749, val_loss=2.1, val_accuracy=0.517, lr=0.0316] 32%|███▏      | 24/75 [08:16<16:45, 19.72s/epoch, loss=1.15, accuracy=0.75, val_loss=1.68, val_accuracy=0.586, lr=0.1]    33%|███▎      | 25/75 [08:35<16:14, 19.50s/epoch, loss=1.15, accuracy=0.75, val_loss=3.16, val_accuracy=0.381, lr=0.1] 35%|███▍      | 26/75 [08:54<15:53, 19.45s/epoch, loss=1.15, accuracy=0.749, val_loss=2.9, val_accuracy=0.34, lr=0.1]  36%|███▌      | 27/75 [09:14<15:29, 19.36s/epoch, loss=1.15, accuracy=0.749, val_loss=1.48, val_accuracy=0.645, lr=0.1] 37%|███▋      | 28/75 [09:33<15:13, 19.43s/epoch, loss=1.14, accuracy=0.75, val_loss=1.98, val_accuracy=0.499, lr=0.1]  39%|███▊      | 29/75 [09:54<15:15, 19.90s/epoch, loss=1.14, accuracy=0.752, val_loss=2.21, val_accuracy=0.396, lr=0.1] 40%|████      | 30/75 [10:15<15:09, 20.21s/epoch, loss=1.15, accuracy=0.751, val_loss=2.11, val_accuracy=0.455, lr=0.1] 41%|████▏     | 31/75 [10:36<15:04, 20.55s/epoch, loss=1.15, accuracy=0.752, val_loss=2.02, val_accuracy=0.557, lr=0.1] 43%|████▎     | 32/75 [10:56<14:34, 20.33s/epoch, loss=1.15, accuracy=0.751, val_loss=2.61, val_accuracy=0.413, lr=0.0316] 44%|████▍     | 33/75 [11:16<14:02, 20.05s/epoch, loss=1.15, accuracy=0.752, val_loss=2.38, val_accuracy=0.412, lr=0.1]    45%|████▌     | 34/75 [11:36<13:48, 20.20s/epoch, loss=1.15, accuracy=0.753, val_loss=1.85, val_accuracy=0.517, lr=0.1] 47%|████▋     | 35/75 [11:57<13:37, 20.43s/epoch, loss=1.14, accuracy=0.751, val_loss=2.24, val_accuracy=0.469, lr=0.1] 48%|████▊     | 36/75 [12:17<13:10, 20.27s/epoch, loss=1.14, accuracy=0.752, val_loss=1.51, val_accuracy=0.613, lr=0.1] 49%|████▉     | 37/75 [12:38<12:53, 20.35s/epoch, loss=1.14, accuracy=0.756, val_loss=1.8, val_accuracy=0.554, lr=0.0316] 51%|█████     | 38/75 [12:59<12:48, 20.78s/epoch, loss=1.13, accuracy=0.753, val_loss=2.9, val_accuracy=0.31, lr=0.1]     52%|█████▏    | 39/75 [13:20<12:24, 20.68s/epoch, loss=1.14, accuracy=0.754, val_loss=2.4, val_accuracy=0.38, lr=0.1] 53%|█████▎    | 40/75 [13:42<12:16, 21.04s/epoch, loss=1.14, accuracy=0.756, val_loss=2.38, val_accuracy=0.438, lr=0.1] 55%|█████▍    | 41/75 [14:04<12:04, 21.32s/epoch, loss=1.14, accuracy=0.753, val_loss=2.1, val_accuracy=0.459, lr=0.1]  56%|█████▌    | 42/75 [14:25<11:46, 21.42s/epoch, loss=1.14, accuracy=0.754, val_loss=1.75, val_accuracy=0.592, lr=0.0316] 57%|█████▋    | 43/75 [14:46<11:18, 21.21s/epoch, loss=1.14, accuracy=0.756, val_loss=2.39, val_accuracy=0.457, lr=0.1]    59%|█████▊    | 44/75 [15:08<11:05, 21.47s/epoch, loss=1.13, accuracy=0.755, val_loss=2.07, val_accuracy=0.494, lr=0.1] 60%|██████    | 45/75 [15:30<10:46, 21.56s/epoch, loss=1.13, accuracy=0.757, val_loss=2.1, val_accuracy=0.46, lr=0.1]   61%|██████▏   | 46/75 [15:52<10:29, 21.71s/epoch, loss=1.13, accuracy=0.755, val_loss=1.93, val_accuracy=0.512, lr=0.1] 63%|██████▎   | 47/75 [16:14<10:08, 21.74s/epoch, loss=1.13, accuracy=0.753, val_loss=1.45, val_accuracy=0.633, lr=0.1] 64%|██████▍   | 48/75 [16:35<09:46, 21.73s/epoch, loss=1.14, accuracy=0.757, val_loss=4.01, val_accuracy=0.312, lr=0.1] 65%|██████▌   | 49/75 [16:56<09:18, 21.48s/epoch, loss=1.13, accuracy=0.755, val_loss=2.94, val_accuracy=0.433, lr=0.1] 67%|██████▋   | 50/75 [17:18<08:58, 21.53s/epoch, loss=1.13, accuracy=0.755, val_loss=2.72, val_accuracy=0.336, lr=0.1] 68%|██████▊   | 51/75 [17:40<08:40, 21.69s/epoch, loss=1.13, accuracy=0.757, val_loss=2.97, val_accuracy=0.254, lr=0.1] 69%|██████▉   | 52/75 [18:02<08:22, 21.83s/epoch, loss=1.12, accuracy=0.757, val_loss=2.48, val_accuracy=0.487, lr=0.0316] 71%|███████   | 53/75 [18:23<07:55, 21.61s/epoch, loss=1.13, accuracy=0.756, val_loss=4.93, val_accuracy=0.241, lr=0.1]    72%|███████▏  | 54/75 [18:45<07:36, 21.76s/epoch, loss=1.14, accuracy=0.753, val_loss=4.12, val_accuracy=0.359, lr=0.1] 73%|███████▎  | 55/75 [19:08<07:17, 21.89s/epoch, loss=1.13, accuracy=0.756, val_loss=1.71, val_accuracy=0.545, lr=0.1] 75%|███████▍  | 56/75 [19:29<06:54, 21.83s/epoch, loss=1.12, accuracy=0.76, val_loss=1.71, val_accuracy=0.543, lr=0.1]  76%|███████▌  | 57/75 [19:51<06:31, 21.73s/epoch, loss=1.13, accuracy=0.754, val_loss=3.06, val_accuracy=0.267, lr=0.0316] 77%|███████▋  | 58/75 [20:12<06:04, 21.44s/epoch, loss=1.12, accuracy=0.758, val_loss=1.88, val_accuracy=0.489, lr=0.1]    79%|███████▊  | 59/75 [20:33<05:41, 21.32s/epoch, loss=1.12, accuracy=0.758, val_loss=1.78, val_accuracy=0.612, lr=0.1] 80%|████████  | 60/75 [20:53<05:17, 21.18s/epoch, loss=1.13, accuracy=0.757, val_loss=2.09, val_accuracy=0.533, lr=0.1] 81%|████████▏ | 61/75 [21:13<04:50, 20.74s/epoch, loss=1.12, accuracy=0.756, val_loss=1.67, val_accuracy=0.558, lr=0.1] 83%|████████▎ | 62/75 [21:34<04:30, 20.78s/epoch, loss=1.12, accuracy=0.759, val_loss=3.97, val_accuracy=0.332, lr=0.0316] 84%|████████▍ | 63/75 [21:54<04:05, 20.47s/epoch, loss=1.12, accuracy=0.757, val_loss=1.82, val_accuracy=0.565, lr=0.1]    85%|████████▌ | 64/75 [22:14<03:43, 20.35s/epoch, loss=1.13, accuracy=0.756, val_loss=2.08, val_accuracy=0.506, lr=0.1] 87%|████████▋ | 65/75 [22:34<03:24, 20.42s/epoch, loss=1.12, accuracy=0.757, val_loss=1.54, val_accuracy=0.599, lr=0.1] 88%|████████▊ | 66/75 [22:55<03:03, 20.35s/epoch, loss=1.13, accuracy=0.757, val_loss=2.37, val_accuracy=0.431, lr=0.1] 89%|████████▉ | 67/75 [23:16<02:44, 20.53s/epoch, loss=1.12, accuracy=0.758, val_loss=2.08, val_accuracy=0.457, lr=0.0316] 91%|█████████ | 68/75 [23:36<02:22, 20.38s/epoch, loss=1.12, accuracy=0.758, val_loss=1.99, val_accuracy=0.525, lr=0.1]    92%|█████████▏| 69/75 [23:56<02:03, 20.52s/epoch, loss=1.12, accuracy=0.758, val_loss=1.87, val_accuracy=0.566, lr=0.1] 93%|█████████▎| 70/75 [24:17<01:43, 20.63s/epoch, loss=1.12, accuracy=0.758, val_loss=1.64, val_accuracy=0.613, lr=0.1] 95%|█████████▍| 71/75 [24:38<01:22, 20.71s/epoch, loss=1.12, accuracy=0.755, val_loss=4.5, val_accuracy=0.301, lr=0.1]  96%|█████████▌| 72/75 [24:58<01:01, 20.57s/epoch, loss=1.12, accuracy=0.756, val_loss=1.96, val_accuracy=0.466, lr=0.0316] 97%|█████████▋| 73/75 [25:20<00:41, 20.89s/epoch, loss=1.12, accuracy=0.758, val_loss=1.61, val_accuracy=0.564, lr=0.1]    99%|█████████▊| 74/75 [25:42<00:21, 21.12s/epoch, loss=1.12, accuracy=0.756, val_loss=2.01, val_accuracy=0.49, lr=0.1] 100%|██████████| 75/75 [26:04<00:00, 21.33s/epoch, loss=1.11, accuracy=0.761, val_loss=1.59, val_accuracy=0.609, lr=0.1]100%|██████████| 75/75 [26:04<00:00, 20.85s/epoch, loss=1.11, accuracy=0.761, val_loss=1.59, val_accuracy=0.609, lr=0.1]
Using real-time data augmentation.
Test loss: 1.593013882637024
Test accuracy: 0.6093999743461609


* * * Run SGD for ID = 20_7. * * *


2024-02-15 23:07:00.482746: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 23:07:02.973503: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 23:07:02.974668: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-15 23:07:03.010051: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-15 23:07:03.010088: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 23:07:03.012809: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 23:07:03.012847: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 23:07:03.014898: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 23:07:03.015577: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 23:07:03.017895: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 23:07:03.019206: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 23:07:03.023606: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 23:07:03.024711: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 23:07:03.024786: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 23:07:04.198584: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-15 23:07:04.200097: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 23:07:04.200679: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-15 23:07:04.200709: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 23:07:04.200756: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 23:07:04.200777: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 23:07:04.200801: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 23:07:04.200820: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 23:07:04.200839: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 23:07:04.200858: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 23:07:04.200877: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 23:07:04.201294: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 23:07:04.201329: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 23:07:04.851958: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-15 23:07:04.852026: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-15 23:07:04.852035: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-15 23:07:04.852886: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': 207, 'batch_size': 128, 'epochs': 75, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/75 [00:00<?, ?epoch/s]2024-02-15 23:07:05.591924: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-15 23:07:05.604400: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2599900000 Hz
2024-02-15 23:07:07.408254: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 23:07:07.614616: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 23:07:08.417276: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-15 23:07:08.463052: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|▏         | 1/75 [00:52<1:04:16, 52.11s/epoch, loss=3.02, accuracy=0.334, val_loss=3.04, val_accuracy=0.217, lr=0.1]  3%|▎         | 2/75 [01:12<40:39, 33.42s/epoch, loss=1.52, accuracy=0.556, val_loss=2.06, val_accuracy=0.443, lr=0.1]    4%|▍         | 3/75 [01:32<32:37, 27.19s/epoch, loss=1.33, accuracy=0.654, val_loss=1.64, val_accuracy=0.546, lr=0.1]  5%|▌         | 4/75 [01:52<28:51, 24.38s/epoch, loss=1.28, accuracy=0.686, val_loss=2.34, val_accuracy=0.432, lr=0.1]  7%|▋         | 5/75 [02:12<26:31, 22.74s/epoch, loss=1.25, accuracy=0.702, val_loss=1.59, val_accuracy=0.576, lr=0.1]  8%|▊         | 6/75 [02:34<25:57, 22.57s/epoch, loss=1.23, accuracy=0.713, val_loss=1.7, val_accuracy=0.56, lr=0.1]    9%|▉         | 7/75 [02:56<25:20, 22.36s/epoch, loss=1.22, accuracy=0.716, val_loss=1.73, val_accuracy=0.564, lr=0.1] 11%|█         | 8/75 [03:17<24:31, 21.97s/epoch, loss=1.21, accuracy=0.723, val_loss=3, val_accuracy=0.401, lr=0.1]    12%|█▏        | 9/75 [03:39<24:11, 21.99s/epoch, loss=1.2, accuracy=0.728, val_loss=1.41, val_accuracy=0.647, lr=0.1] 13%|█▎        | 10/75 [04:01<23:44, 21.92s/epoch, loss=1.2, accuracy=0.73, val_loss=2.95, val_accuracy=0.339, lr=0.1] 15%|█▍        | 11/75 [04:22<23:14, 21.78s/epoch, loss=1.2, accuracy=0.733, val_loss=1.96, val_accuracy=0.544, lr=0.1] 16%|█▌        | 12/75 [04:42<22:17, 21.24s/epoch, loss=1.19, accuracy=0.733, val_loss=2.08, val_accuracy=0.513, lr=0.1] 17%|█▋        | 13/75 [05:03<21:42, 21.01s/epoch, loss=1.19, accuracy=0.737, val_loss=2.07, val_accuracy=0.43, lr=0.1]  19%|█▊        | 14/75 [05:24<21:30, 21.15s/epoch, loss=1.19, accuracy=0.737, val_loss=1.86, val_accuracy=0.507, lr=0.0316] 20%|██        | 15/75 [05:46<21:18, 21.30s/epoch, loss=1.19, accuracy=0.739, val_loss=1.37, val_accuracy=0.687, lr=0.1]    21%|██▏       | 16/75 [06:06<20:41, 21.05s/epoch, loss=1.19, accuracy=0.74, val_loss=2.72, val_accuracy=0.381, lr=0.1]  23%|██▎       | 17/75 [06:27<20:19, 21.02s/epoch, loss=1.18, accuracy=0.738, val_loss=5.05, val_accuracy=0.306, lr=0.1] 24%|██▍       | 18/75 [06:49<20:10, 21.24s/epoch, loss=1.17, accuracy=0.74, val_loss=4.5, val_accuracy=0.216, lr=0.1]   25%|██▌       | 19/75 [07:11<20:00, 21.44s/epoch, loss=1.18, accuracy=0.74, val_loss=2.42, val_accuracy=0.433, lr=0.1] 27%|██▋       | 20/75 [07:33<19:52, 21.68s/epoch, loss=1.17, accuracy=0.741, val_loss=3.18, val_accuracy=0.387, lr=0.0316] 28%|██▊       | 21/75 [07:55<19:31, 21.69s/epoch, loss=1.17, accuracy=0.743, val_loss=2.23, val_accuracy=0.457, lr=0.1]    29%|██▉       | 22/75 [08:16<18:58, 21.47s/epoch, loss=1.17, accuracy=0.744, val_loss=1.91, val_accuracy=0.52, lr=0.1]  31%|███       | 23/75 [08:37<18:34, 21.43s/epoch, loss=1.16, accuracy=0.744, val_loss=1.96, val_accuracy=0.496, lr=0.1] 32%|███▏      | 24/75 [08:58<18:08, 21.34s/epoch, loss=1.15, accuracy=0.747, val_loss=1.63, val_accuracy=0.578, lr=0.1] 33%|███▎      | 25/75 [09:19<17:43, 21.28s/epoch, loss=1.16, accuracy=0.744, val_loss=1.99, val_accuracy=0.515, lr=0.0316] 35%|███▍      | 26/75 [09:42<17:38, 21.60s/epoch, loss=1.15, accuracy=0.746, val_loss=3.98, val_accuracy=0.19, lr=0.1]     36%|███▌      | 27/75 [10:03<17:18, 21.63s/epoch, loss=1.15, accuracy=0.746, val_loss=2.02, val_accuracy=0.505, lr=0.1] 37%|███▋      | 28/75 [10:24<16:46, 21.41s/epoch, loss=1.16, accuracy=0.748, val_loss=1.85, val_accuracy=0.552, lr=0.1] 39%|███▊      | 29/75 [10:45<16:14, 21.18s/epoch, loss=1.16, accuracy=0.747, val_loss=3.7, val_accuracy=0.364, lr=0.1]  40%|████      | 30/75 [11:07<16:05, 21.45s/epoch, loss=1.15, accuracy=0.748, val_loss=2.37, val_accuracy=0.35, lr=0.0316] 41%|████▏     | 31/75 [11:28<15:43, 21.45s/epoch, loss=1.15, accuracy=0.748, val_loss=2.17, val_accuracy=0.417, lr=0.1]   43%|████▎     | 32/75 [11:50<15:27, 21.58s/epoch, loss=1.15, accuracy=0.748, val_loss=2.23, val_accuracy=0.455, lr=0.1] 44%|████▍     | 33/75 [12:12<15:10, 21.68s/epoch, loss=1.14, accuracy=0.75, val_loss=2.36, val_accuracy=0.466, lr=0.1]  45%|████▌     | 34/75 [12:34<14:46, 21.63s/epoch, loss=1.14, accuracy=0.752, val_loss=1.57, val_accuracy=0.616, lr=0.1] 47%|████▋     | 35/75 [12:54<14:09, 21.24s/epoch, loss=1.14, accuracy=0.748, val_loss=1.82, val_accuracy=0.496, lr=0.0316] 48%|████▊     | 36/75 [13:15<13:46, 21.19s/epoch, loss=1.14, accuracy=0.751, val_loss=2.07, val_accuracy=0.461, lr=0.1]    49%|████▉     | 37/75 [13:37<13:30, 21.32s/epoch, loss=1.14, accuracy=0.75, val_loss=1.64, val_accuracy=0.615, lr=0.1]  51%|█████     | 38/75 [13:58<13:07, 21.27s/epoch, loss=1.14, accuracy=0.75, val_loss=2.64, val_accuracy=0.315, lr=0.1] 52%|█████▏    | 39/75 [14:20<12:54, 21.53s/epoch, loss=1.13, accuracy=0.752, val_loss=2.56, val_accuracy=0.439, lr=0.1] 53%|█████▎    | 40/75 [14:42<12:39, 21.71s/epoch, loss=1.13, accuracy=0.75, val_loss=1.56, val_accuracy=0.61, lr=0.0316] 55%|█████▍    | 41/75 [15:05<12:26, 21.95s/epoch, loss=1.13, accuracy=0.752, val_loss=3, val_accuracy=0.395, lr=0.1]     56%|█████▌    | 42/75 [15:27<12:07, 22.05s/epoch, loss=1.13, accuracy=0.753, val_loss=2.01, val_accuracy=0.486, lr=0.1] 57%|█████▋    | 43/75 [15:49<11:45, 22.05s/epoch, loss=1.13, accuracy=0.753, val_loss=1.88, val_accuracy=0.549, lr=0.1] 59%|█████▊    | 44/75 [16:11<11:18, 21.87s/epoch, loss=1.12, accuracy=0.755, val_loss=1.57, val_accuracy=0.605, lr=0.1] 60%|██████    | 45/75 [16:33<10:58, 21.94s/epoch, loss=1.12, accuracy=0.756, val_loss=1.7, val_accuracy=0.574, lr=0.0316] 61%|██████▏   | 46/75 [16:54<10:29, 21.70s/epoch, loss=1.13, accuracy=0.753, val_loss=2.07, val_accuracy=0.513, lr=0.1]   63%|██████▎   | 47/75 [17:15<10:04, 21.59s/epoch, loss=1.12, accuracy=0.757, val_loss=1.78, val_accuracy=0.561, lr=0.1] 64%|██████▍   | 48/75 [17:36<09:39, 21.45s/epoch, loss=1.13, accuracy=0.752, val_loss=2.08, val_accuracy=0.516, lr=0.1] 65%|██████▌   | 49/75 [17:58<09:16, 21.42s/epoch, loss=1.13, accuracy=0.754, val_loss=2.75, val_accuracy=0.409, lr=0.1] 67%|██████▋   | 50/75 [18:19<08:54, 21.37s/epoch, loss=1.12, accuracy=0.755, val_loss=1.93, val_accuracy=0.483, lr=0.0316] 68%|██████▊   | 51/75 [18:40<08:31, 21.32s/epoch, loss=1.13, accuracy=0.752, val_loss=2.46, val_accuracy=0.394, lr=0.1]    69%|██████▉   | 52/75 [19:02<08:15, 21.55s/epoch, loss=1.12, accuracy=0.753, val_loss=2.68, val_accuracy=0.362, lr=0.1] 71%|███████   | 53/75 [19:25<08:01, 21.88s/epoch, loss=1.12, accuracy=0.759, val_loss=3.16, val_accuracy=0.366, lr=0.1] 72%|███████▏  | 54/75 [19:47<07:40, 21.91s/epoch, loss=1.12, accuracy=0.756, val_loss=2.43, val_accuracy=0.468, lr=0.1] 73%|███████▎  | 55/75 [20:09<07:18, 21.92s/epoch, loss=1.12, accuracy=0.752, val_loss=1.75, val_accuracy=0.613, lr=0.0316] 75%|███████▍  | 56/75 [20:30<06:55, 21.86s/epoch, loss=1.12, accuracy=0.753, val_loss=1.93, val_accuracy=0.544, lr=0.1]    76%|███████▌  | 57/75 [20:53<06:35, 21.96s/epoch, loss=1.12, accuracy=0.756, val_loss=1.81, val_accuracy=0.556, lr=0.1] 77%|███████▋  | 58/75 [21:15<06:14, 22.02s/epoch, loss=1.12, accuracy=0.758, val_loss=2.56, val_accuracy=0.35, lr=0.1]  79%|███████▊  | 59/75 [21:36<05:50, 21.89s/epoch, loss=1.13, accuracy=0.754, val_loss=2.83, val_accuracy=0.442, lr=0.1] 80%|████████  | 60/75 [21:57<05:21, 21.41s/epoch, loss=1.12, accuracy=0.757, val_loss=1.76, val_accuracy=0.545, lr=0.0316] 81%|████████▏ | 61/75 [22:18<05:01, 21.51s/epoch, loss=1.12, accuracy=0.755, val_loss=8.76, val_accuracy=0.196, lr=0.1]    83%|████████▎ | 62/75 [22:39<04:36, 21.30s/epoch, loss=1.11, accuracy=0.757, val_loss=1.64, val_accuracy=0.61, lr=0.1]  84%|████████▍ | 63/75 [23:01<04:17, 21.45s/epoch, loss=1.12, accuracy=0.755, val_loss=1.79, val_accuracy=0.566, lr=0.1] 85%|████████▌ | 64/75 [23:23<03:57, 21.58s/epoch, loss=1.11, accuracy=0.758, val_loss=1.78, val_accuracy=0.54, lr=0.1]  87%|████████▋ | 65/75 [23:45<03:36, 21.67s/epoch, loss=1.12, accuracy=0.754, val_loss=1.96, val_accuracy=0.56, lr=0.0316] 88%|████████▊ | 66/75 [24:05<03:10, 21.13s/epoch, loss=1.12, accuracy=0.755, val_loss=2.71, val_accuracy=0.377, lr=0.1]   89%|████████▉ | 67/75 [24:27<02:50, 21.37s/epoch, loss=1.12, accuracy=0.752, val_loss=4.27, val_accuracy=0.265, lr=0.1] 91%|█████████ | 68/75 [24:49<02:31, 21.59s/epoch, loss=1.11, accuracy=0.756, val_loss=2.05, val_accuracy=0.514, lr=0.1] 92%|█████████▏| 69/75 [25:10<02:09, 21.65s/epoch, loss=1.12, accuracy=0.756, val_loss=4.2, val_accuracy=0.351, lr=0.1]  93%|█████████▎| 70/75 [25:33<01:49, 21.86s/epoch, loss=1.12, accuracy=0.753, val_loss=1.81, val_accuracy=0.543, lr=0.0316] 95%|█████████▍| 71/75 [25:55<01:27, 21.96s/epoch, loss=1.11, accuracy=0.756, val_loss=2, val_accuracy=0.451, lr=0.1]       96%|█████████▌| 72/75 [26:17<01:05, 21.84s/epoch, loss=1.11, accuracy=0.758, val_loss=3.6, val_accuracy=0.282, lr=0.1] 97%|█████████▋| 73/75 [26:38<00:43, 21.67s/epoch, loss=1.12, accuracy=0.755, val_loss=5.38, val_accuracy=0.25, lr=0.1] 99%|█████████▊| 74/75 [26:59<00:21, 21.37s/epoch, loss=1.11, accuracy=0.756, val_loss=3.01, val_accuracy=0.333, lr=0.1]100%|██████████| 75/75 [27:21<00:00, 21.62s/epoch, loss=1.11, accuracy=0.758, val_loss=1.84, val_accuracy=0.552, lr=0.0316]100%|██████████| 75/75 [27:21<00:00, 21.88s/epoch, loss=1.11, accuracy=0.758, val_loss=1.84, val_accuracy=0.552, lr=0.0316]
Using real-time data augmentation.
Test loss: 1.838977336883545
Test accuracy: 0.5523999929428101


* * * Run SGD for ID = 20_8. * * *


2024-02-15 23:34:29.389674: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 23:34:31.888873: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 23:34:31.890066: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-15 23:34:31.926641: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-15 23:34:31.926678: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 23:34:31.929441: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 23:34:31.929479: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 23:34:31.931510: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 23:34:31.932131: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 23:34:31.934347: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 23:34:31.935639: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 23:34:31.939945: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 23:34:31.942010: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 23:34:31.942090: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 23:34:33.167746: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-15 23:34:33.168799: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 23:34:33.169399: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-15 23:34:33.169429: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 23:34:33.169476: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 23:34:33.169495: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 23:34:33.169514: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 23:34:33.169532: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 23:34:33.169550: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 23:34:33.169567: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 23:34:33.169585: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 23:34:33.171011: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 23:34:33.171063: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 23:34:33.792854: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-15 23:34:33.792908: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-15 23:34:33.792916: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-15 23:34:33.793799: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': 208, 'batch_size': 128, 'epochs': 75, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/75 [00:00<?, ?epoch/s]2024-02-15 23:34:34.542853: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-15 23:34:34.554404: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2599900000 Hz
2024-02-15 23:34:36.359722: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 23:34:36.577055: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 23:34:37.292326: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-15 23:34:37.331736: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|▏         | 1/75 [00:51<1:04:06, 51.98s/epoch, loss=3.86, accuracy=0.284, val_loss=2.62, val_accuracy=0.151, lr=0.1]  3%|▎         | 2/75 [01:12<40:29, 33.28s/epoch, loss=1.72, accuracy=0.456, val_loss=2.61, val_accuracy=0.277, lr=0.1]    4%|▍         | 3/75 [01:32<32:46, 27.31s/epoch, loss=1.53, accuracy=0.543, val_loss=1.83, val_accuracy=0.459, lr=0.1]  5%|▌         | 4/75 [01:52<28:58, 24.48s/epoch, loss=1.44, accuracy=0.6, val_loss=2.09, val_accuracy=0.388, lr=0.1]    7%|▋         | 5/75 [02:12<26:41, 22.88s/epoch, loss=1.4, accuracy=0.63, val_loss=1.7, val_accuracy=0.541, lr=0.1]   8%|▊         | 6/75 [02:33<25:27, 22.13s/epoch, loss=1.35, accuracy=0.66, val_loss=2.51, val_accuracy=0.38, lr=0.1]  9%|▉         | 7/75 [02:53<24:22, 21.50s/epoch, loss=1.31, accuracy=0.684, val_loss=1.68, val_accuracy=0.558, lr=0.1] 11%|█         | 8/75 [03:13<23:33, 21.09s/epoch, loss=1.27, accuracy=0.702, val_loss=2.29, val_accuracy=0.425, lr=0.1] 12%|█▏        | 9/75 [03:33<22:45, 20.70s/epoch, loss=1.26, accuracy=0.705, val_loss=1.59, val_accuracy=0.6, lr=0.1]   13%|█▎        | 10/75 [03:53<22:19, 20.60s/epoch, loss=1.26, accuracy=0.712, val_loss=2.93, val_accuracy=0.392, lr=0.1] 15%|█▍        | 11/75 [04:13<21:46, 20.41s/epoch, loss=1.25, accuracy=0.719, val_loss=1.43, val_accuracy=0.646, lr=0.1] 16%|█▌        | 12/75 [04:35<21:56, 20.90s/epoch, loss=1.24, accuracy=0.72, val_loss=1.55, val_accuracy=0.612, lr=0.1]  17%|█▋        | 13/75 [04:57<21:41, 20.98s/epoch, loss=1.24, accuracy=0.724, val_loss=1.73, val_accuracy=0.595, lr=0.1] 19%|█▊        | 14/75 [05:18<21:26, 21.09s/epoch, loss=1.24, accuracy=0.726, val_loss=1.8, val_accuracy=0.536, lr=0.1]  20%|██        | 15/75 [05:40<21:17, 21.29s/epoch, loss=1.23, accuracy=0.725, val_loss=1.89, val_accuracy=0.558, lr=0.1] 21%|██▏       | 16/75 [06:01<21:04, 21.42s/epoch, loss=1.23, accuracy=0.728, val_loss=2.22, val_accuracy=0.407, lr=0.0316] 23%|██▎       | 17/75 [06:23<20:46, 21.50s/epoch, loss=1.22, accuracy=0.731, val_loss=1.66, val_accuracy=0.574, lr=0.1]    24%|██▍       | 18/75 [06:45<20:26, 21.52s/epoch, loss=1.22, accuracy=0.729, val_loss=1.65, val_accuracy=0.591, lr=0.1] 25%|██▌       | 19/75 [07:06<20:09, 21.60s/epoch, loss=1.21, accuracy=0.734, val_loss=1.76, val_accuracy=0.585, lr=0.1] 27%|██▋       | 20/75 [07:28<19:54, 21.72s/epoch, loss=1.22, accuracy=0.734, val_loss=1.8, val_accuracy=0.588, lr=0.1]  28%|██▊       | 21/75 [07:50<19:23, 21.56s/epoch, loss=1.21, accuracy=0.735, val_loss=1.64, val_accuracy=0.588, lr=0.0316] 29%|██▉       | 22/75 [08:11<18:56, 21.45s/epoch, loss=1.21, accuracy=0.733, val_loss=1.93, val_accuracy=0.515, lr=0.1]    31%|███       | 23/75 [08:32<18:33, 21.41s/epoch, loss=1.2, accuracy=0.738, val_loss=2.61, val_accuracy=0.477, lr=0.1]  32%|███▏      | 24/75 [08:53<18:07, 21.33s/epoch, loss=1.2, accuracy=0.736, val_loss=1.74, val_accuracy=0.565, lr=0.1] 33%|███▎      | 25/75 [09:14<17:33, 21.06s/epoch, loss=1.2, accuracy=0.737, val_loss=1.66, val_accuracy=0.594, lr=0.1] 35%|███▍      | 26/75 [09:35<17:10, 21.03s/epoch, loss=1.2, accuracy=0.735, val_loss=1.96, val_accuracy=0.509, lr=0.0316] 36%|███▌      | 27/75 [09:57<17:01, 21.28s/epoch, loss=1.2, accuracy=0.738, val_loss=2.31, val_accuracy=0.427, lr=0.1]    37%|███▋      | 28/75 [10:18<16:46, 21.43s/epoch, loss=1.19, accuracy=0.739, val_loss=2.48, val_accuracy=0.438, lr=0.1] 39%|███▊      | 29/75 [10:38<16:07, 21.03s/epoch, loss=1.19, accuracy=0.74, val_loss=1.72, val_accuracy=0.575, lr=0.1]  40%|████      | 30/75 [10:59<15:34, 20.78s/epoch, loss=1.19, accuracy=0.74, val_loss=2.04, val_accuracy=0.515, lr=0.1] 41%|████▏     | 31/75 [11:19<15:03, 20.54s/epoch, loss=1.19, accuracy=0.742, val_loss=1.68, val_accuracy=0.585, lr=0.0316] 43%|████▎     | 32/75 [11:39<14:35, 20.37s/epoch, loss=1.19, accuracy=0.741, val_loss=1.68, val_accuracy=0.57, lr=0.1]     44%|████▍     | 33/75 [11:59<14:12, 20.30s/epoch, loss=1.19, accuracy=0.742, val_loss=1.96, val_accuracy=0.516, lr=0.1] 45%|████▌     | 34/75 [12:20<13:58, 20.46s/epoch, loss=1.18, accuracy=0.743, val_loss=1.48, val_accuracy=0.643, lr=0.1] 47%|████▋     | 35/75 [12:40<13:34, 20.36s/epoch, loss=1.18, accuracy=0.744, val_loss=1.48, val_accuracy=0.635, lr=0.1] 48%|████▊     | 36/75 [13:00<13:15, 20.40s/epoch, loss=1.18, accuracy=0.744, val_loss=1.66, val_accuracy=0.59, lr=0.0316] 49%|████▉     | 37/75 [13:20<12:54, 20.38s/epoch, loss=1.18, accuracy=0.744, val_loss=1.67, val_accuracy=0.58, lr=0.1]    51%|█████     | 38/75 [13:43<12:54, 20.92s/epoch, loss=1.18, accuracy=0.742, val_loss=1.54, val_accuracy=0.619, lr=0.1] 52%|█████▏    | 39/75 [14:04<12:35, 20.98s/epoch, loss=1.18, accuracy=0.743, val_loss=2.55, val_accuracy=0.355, lr=0.1] 53%|█████▎    | 40/75 [14:25<12:21, 21.18s/epoch, loss=1.17, accuracy=0.746, val_loss=1.87, val_accuracy=0.564, lr=0.1] 55%|█████▍    | 41/75 [14:47<12:08, 21.43s/epoch, loss=1.17, accuracy=0.744, val_loss=1.82, val_accuracy=0.533, lr=0.0316] 56%|█████▌    | 42/75 [15:10<11:53, 21.63s/epoch, loss=1.17, accuracy=0.746, val_loss=2.68, val_accuracy=0.404, lr=0.1]    57%|█████▋    | 43/75 [15:32<11:37, 21.81s/epoch, loss=1.16, accuracy=0.745, val_loss=2.53, val_accuracy=0.413, lr=0.1] 59%|█████▊    | 44/75 [15:53<11:11, 21.67s/epoch, loss=1.16, accuracy=0.746, val_loss=1.64, val_accuracy=0.568, lr=0.1] 60%|██████    | 45/75 [16:16<10:58, 21.96s/epoch, loss=1.16, accuracy=0.747, val_loss=1.75, val_accuracy=0.576, lr=0.1] 61%|██████▏   | 46/75 [16:38<10:43, 22.20s/epoch, loss=1.16, accuracy=0.746, val_loss=1.97, val_accuracy=0.509, lr=0.0316] 63%|██████▎   | 47/75 [17:01<10:20, 22.15s/epoch, loss=1.16, accuracy=0.748, val_loss=2.45, val_accuracy=0.346, lr=0.1]    64%|██████▍   | 48/75 [17:23<10:00, 22.23s/epoch, loss=1.16, accuracy=0.747, val_loss=2.12, val_accuracy=0.504, lr=0.1] 65%|██████▌   | 49/75 [17:46<09:41, 22.38s/epoch, loss=1.16, accuracy=0.748, val_loss=1.48, val_accuracy=0.616, lr=0.1] 67%|██████▋   | 50/75 [18:08<09:18, 22.35s/epoch, loss=1.15, accuracy=0.751, val_loss=1.76, val_accuracy=0.554, lr=0.1] 68%|██████▊   | 51/75 [18:31<08:59, 22.46s/epoch, loss=1.16, accuracy=0.748, val_loss=1.89, val_accuracy=0.495, lr=0.0316] 69%|██████▉   | 52/75 [18:53<08:38, 22.55s/epoch, loss=1.16, accuracy=0.748, val_loss=1.92, val_accuracy=0.527, lr=0.1]    71%|███████   | 53/75 [19:16<08:15, 22.53s/epoch, loss=1.16, accuracy=0.748, val_loss=1.81, val_accuracy=0.575, lr=0.1] 72%|███████▏  | 54/75 [19:38<07:51, 22.47s/epoch, loss=1.16, accuracy=0.748, val_loss=2.22, val_accuracy=0.465, lr=0.1] 73%|███████▎  | 55/75 [20:00<07:28, 22.40s/epoch, loss=1.17, accuracy=0.746, val_loss=2.01, val_accuracy=0.554, lr=0.1] 75%|███████▍  | 56/75 [20:24<07:09, 22.59s/epoch, loss=1.15, accuracy=0.749, val_loss=1.66, val_accuracy=0.574, lr=0.0316] 76%|███████▌  | 57/75 [20:46<06:48, 22.67s/epoch, loss=1.15, accuracy=0.748, val_loss=1.99, val_accuracy=0.541, lr=0.1]    77%|███████▋  | 58/75 [21:09<06:26, 22.73s/epoch, loss=1.15, accuracy=0.748, val_loss=2.21, val_accuracy=0.515, lr=0.1] 79%|███████▊  | 59/75 [21:32<06:04, 22.77s/epoch, loss=1.15, accuracy=0.749, val_loss=2.47, val_accuracy=0.431, lr=0.1] 80%|████████  | 60/75 [21:54<05:39, 22.66s/epoch, loss=1.16, accuracy=0.747, val_loss=1.39, val_accuracy=0.659, lr=0.1] 81%|████████▏ | 61/75 [22:17<05:17, 22.65s/epoch, loss=1.15, accuracy=0.749, val_loss=1.99, val_accuracy=0.519, lr=0.1] 83%|████████▎ | 62/75 [22:40<04:54, 22.62s/epoch, loss=1.15, accuracy=0.751, val_loss=2, val_accuracy=0.555, lr=0.1]    84%|████████▍ | 63/75 [23:02<04:31, 22.63s/epoch, loss=1.16, accuracy=0.749, val_loss=1.66, val_accuracy=0.564, lr=0.1] 85%|████████▌ | 64/75 [23:25<04:09, 22.64s/epoch, loss=1.15, accuracy=0.749, val_loss=1.87, val_accuracy=0.55, lr=0.1]  87%|████████▋ | 65/75 [23:48<03:46, 22.61s/epoch, loss=1.14, accuracy=0.752, val_loss=2.03, val_accuracy=0.48, lr=0.0316] 88%|████████▊ | 66/75 [24:09<03:20, 22.28s/epoch, loss=1.15, accuracy=0.748, val_loss=1.94, val_accuracy=0.503, lr=0.1]   89%|████████▉ | 67/75 [24:31<02:58, 22.31s/epoch, loss=1.15, accuracy=0.749, val_loss=1.78, val_accuracy=0.561, lr=0.1] 91%|█████████ | 68/75 [24:54<02:36, 22.39s/epoch, loss=1.14, accuracy=0.749, val_loss=1.65, val_accuracy=0.592, lr=0.1] 92%|█████████▏| 69/75 [25:16<02:14, 22.37s/epoch, loss=1.15, accuracy=0.751, val_loss=1.67, val_accuracy=0.585, lr=0.1] 93%|█████████▎| 70/75 [25:39<01:51, 22.32s/epoch, loss=1.15, accuracy=0.752, val_loss=2.14, val_accuracy=0.474, lr=0.0316] 95%|█████████▍| 71/75 [26:01<01:29, 22.39s/epoch, loss=1.14, accuracy=0.754, val_loss=1.78, val_accuracy=0.584, lr=0.1]    96%|█████████▌| 72/75 [26:23<01:07, 22.40s/epoch, loss=1.16, accuracy=0.748, val_loss=1.38, val_accuracy=0.677, lr=0.1] 97%|█████████▋| 73/75 [26:46<00:44, 22.33s/epoch, loss=1.15, accuracy=0.75, val_loss=1.86, val_accuracy=0.561, lr=0.1]  99%|█████████▊| 74/75 [27:08<00:22, 22.37s/epoch, loss=1.16, accuracy=0.75, val_loss=2.58, val_accuracy=0.366, lr=0.1]100%|██████████| 75/75 [27:31<00:00, 22.54s/epoch, loss=1.15, accuracy=0.753, val_loss=1.98, val_accuracy=0.505, lr=0.1]100%|██████████| 75/75 [27:31<00:00, 22.02s/epoch, loss=1.15, accuracy=0.753, val_loss=1.98, val_accuracy=0.505, lr=0.1]
Using real-time data augmentation.
Test loss: 1.9809998273849487
Test accuracy: 0.5054000020027161


* * * Run SGD for ID = 20_9. * * *


2024-02-16 00:02:08.317051: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-16 00:02:11.007718: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-16 00:02:11.008864: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-16 00:02:11.053916: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-16 00:02:11.053948: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-16 00:02:11.056782: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-16 00:02:11.056820: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-16 00:02:11.059044: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-16 00:02:11.059737: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-16 00:02:11.061948: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-16 00:02:11.063324: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-16 00:02:11.067804: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-16 00:02:11.068264: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-16 00:02:11.068364: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-16 00:02:12.245527: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-16 00:02:12.246705: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-16 00:02:12.247272: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-16 00:02:12.247327: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-16 00:02:12.247375: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-16 00:02:12.247394: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-16 00:02:12.247412: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-16 00:02:12.247429: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-16 00:02:12.247447: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-16 00:02:12.247465: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-16 00:02:12.247492: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-16 00:02:12.247929: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-16 00:02:12.247959: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-16 00:02:12.868150: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-16 00:02:12.868211: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-16 00:02:12.868221: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-16 00:02:12.869114: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': 209, 'batch_size': 128, 'epochs': 75, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/75 [00:00<?, ?epoch/s]2024-02-16 00:02:13.628094: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-16 00:02:13.640405: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2599900000 Hz
2024-02-16 00:02:15.435038: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-16 00:02:15.714631: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-16 00:02:16.406106: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-16 00:02:16.459289: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|▏         | 1/75 [00:58<1:12:21, 58.67s/epoch, loss=3.31, accuracy=0.29, val_loss=2.35, val_accuracy=0.205, lr=0.1]  3%|▎         | 2/75 [01:20<44:51, 36.86s/epoch, loss=1.59, accuracy=0.512, val_loss=1.93, val_accuracy=0.411, lr=0.1]   4%|▍         | 3/75 [01:42<36:27, 30.38s/epoch, loss=1.36, accuracy=0.629, val_loss=2.84, val_accuracy=0.343, lr=0.1]  5%|▌         | 4/75 [02:05<32:15, 27.26s/epoch, loss=1.28, accuracy=0.678, val_loss=1.92, val_accuracy=0.474, lr=0.1]  7%|▋         | 5/75 [02:28<29:54, 25.64s/epoch, loss=1.25, accuracy=0.7, val_loss=1.83, val_accuracy=0.532, lr=0.1]    8%|▊         | 6/75 [02:51<28:23, 24.69s/epoch, loss=1.23, accuracy=0.714, val_loss=2.63, val_accuracy=0.393, lr=0.1]  9%|▉         | 7/75 [03:13<27:09, 23.97s/epoch, loss=1.22, accuracy=0.719, val_loss=3.52, val_accuracy=0.287, lr=0.1] 11%|█         | 8/75 [03:35<26:04, 23.36s/epoch, loss=1.22, accuracy=0.723, val_loss=2.41, val_accuracy=0.446, lr=0.1] 12%|█▏        | 9/75 [03:58<25:31, 23.20s/epoch, loss=1.21, accuracy=0.729, val_loss=2.46, val_accuracy=0.433, lr=0.1] 13%|█▎        | 10/75 [04:20<24:54, 22.99s/epoch, loss=1.2, accuracy=0.732, val_loss=2.93, val_accuracy=0.346, lr=0.0316] 15%|█▍        | 11/75 [04:43<24:16, 22.75s/epoch, loss=1.19, accuracy=0.735, val_loss=2.14, val_accuracy=0.484, lr=0.1]   16%|█▌        | 12/75 [05:05<23:48, 22.68s/epoch, loss=1.19, accuracy=0.737, val_loss=3.14, val_accuracy=0.312, lr=0.1] 17%|█▋        | 13/75 [05:28<23:21, 22.61s/epoch, loss=1.2, accuracy=0.735, val_loss=1.62, val_accuracy=0.597, lr=0.1]  19%|█▊        | 14/75 [05:50<22:59, 22.62s/epoch, loss=1.18, accuracy=0.74, val_loss=2.53, val_accuracy=0.411, lr=0.1] 20%|██        | 15/75 [06:13<22:41, 22.69s/epoch, loss=1.19, accuracy=0.74, val_loss=1.87, val_accuracy=0.54, lr=0.1]  21%|██▏       | 16/75 [06:36<22:21, 22.74s/epoch, loss=1.17, accuracy=0.742, val_loss=3.22, val_accuracy=0.265, lr=0.1] 23%|██▎       | 17/75 [06:59<21:58, 22.73s/epoch, loss=1.17, accuracy=0.744, val_loss=2.29, val_accuracy=0.466, lr=0.1] 24%|██▍       | 18/75 [07:21<21:35, 22.72s/epoch, loss=1.17, accuracy=0.745, val_loss=1.64, val_accuracy=0.584, lr=0.0316] 25%|██▌       | 19/75 [07:44<21:06, 22.61s/epoch, loss=1.16, accuracy=0.747, val_loss=3.27, val_accuracy=0.383, lr=0.1]    27%|██▋       | 20/75 [08:06<20:38, 22.52s/epoch, loss=1.16, accuracy=0.746, val_loss=1.64, val_accuracy=0.6, lr=0.1]   28%|██▊       | 21/75 [08:29<20:19, 22.58s/epoch, loss=1.17, accuracy=0.744, val_loss=2.92, val_accuracy=0.385, lr=0.1] 29%|██▉       | 22/75 [08:51<19:55, 22.56s/epoch, loss=1.17, accuracy=0.747, val_loss=2.31, val_accuracy=0.451, lr=0.1] 31%|███       | 23/75 [09:14<19:33, 22.57s/epoch, loss=1.16, accuracy=0.748, val_loss=1.87, val_accuracy=0.554, lr=0.0316] 32%|███▏      | 24/75 [09:36<19:12, 22.60s/epoch, loss=1.15, accuracy=0.751, val_loss=1.72, val_accuracy=0.574, lr=0.1]    33%|███▎      | 25/75 [09:59<18:49, 22.60s/epoch, loss=1.16, accuracy=0.747, val_loss=1.81, val_accuracy=0.554, lr=0.1] 35%|███▍      | 26/75 [10:21<18:24, 22.54s/epoch, loss=1.16, accuracy=0.747, val_loss=2.85, val_accuracy=0.44, lr=0.1]  36%|███▌      | 27/75 [10:44<18:02, 22.55s/epoch, loss=1.15, accuracy=0.751, val_loss=1.67, val_accuracy=0.593, lr=0.1] 37%|███▋      | 28/75 [11:07<17:42, 22.61s/epoch, loss=1.15, accuracy=0.752, val_loss=2.43, val_accuracy=0.423, lr=0.0316] 39%|███▊      | 29/75 [11:29<17:19, 22.61s/epoch, loss=1.16, accuracy=0.75, val_loss=1.95, val_accuracy=0.502, lr=0.1]     40%|████      | 30/75 [11:52<16:57, 22.61s/epoch, loss=1.15, accuracy=0.751, val_loss=1.72, val_accuracy=0.572, lr=0.1] 41%|████▏     | 31/75 [12:15<16:37, 22.66s/epoch, loss=1.15, accuracy=0.752, val_loss=3.45, val_accuracy=0.302, lr=0.1] 43%|████▎     | 32/75 [12:37<16:14, 22.67s/epoch, loss=1.15, accuracy=0.751, val_loss=2.26, val_accuracy=0.416, lr=0.1] 44%|████▍     | 33/75 [13:00<15:50, 22.63s/epoch, loss=1.14, accuracy=0.754, val_loss=1.78, val_accuracy=0.567, lr=0.0316] 45%|████▌     | 34/75 [13:23<15:27, 22.61s/epoch, loss=1.15, accuracy=0.752, val_loss=2.24, val_accuracy=0.396, lr=0.1]    47%|████▋     | 35/75 [13:45<15:07, 22.69s/epoch, loss=1.13, accuracy=0.756, val_loss=1.58, val_accuracy=0.595, lr=0.1] 48%|████▊     | 36/75 [14:08<14:37, 22.51s/epoch, loss=1.13, accuracy=0.756, val_loss=1.56, val_accuracy=0.606, lr=0.1] 49%|████▉     | 37/75 [14:29<14:05, 22.26s/epoch, loss=1.13, accuracy=0.756, val_loss=2.22, val_accuracy=0.468, lr=0.1] 51%|█████     | 38/75 [14:51<13:39, 22.15s/epoch, loss=1.14, accuracy=0.756, val_loss=1.9, val_accuracy=0.499, lr=0.1]  52%|█████▏    | 39/75 [15:14<13:20, 22.23s/epoch, loss=1.13, accuracy=0.756, val_loss=1.85, val_accuracy=0.55, lr=0.1] 53%|█████▎    | 40/75 [15:35<12:50, 22.02s/epoch, loss=1.14, accuracy=0.755, val_loss=3.11, val_accuracy=0.318, lr=0.1] 55%|█████▍    | 41/75 [15:56<12:14, 21.59s/epoch, loss=1.14, accuracy=0.754, val_loss=2.42, val_accuracy=0.492, lr=0.0316] 56%|█████▌    | 42/75 [16:19<12:04, 21.97s/epoch, loss=1.12, accuracy=0.757, val_loss=1.54, val_accuracy=0.62, lr=0.1]     57%|█████▋    | 43/75 [16:41<11:47, 22.11s/epoch, loss=1.14, accuracy=0.754, val_loss=2.04, val_accuracy=0.525, lr=0.1] 59%|█████▊    | 44/75 [17:02<11:16, 21.83s/epoch, loss=1.13, accuracy=0.755, val_loss=1.93, val_accuracy=0.485, lr=0.1] 60%|██████    | 45/75 [17:24<10:54, 21.83s/epoch, loss=1.13, accuracy=0.753, val_loss=2.13, val_accuracy=0.447, lr=0.1] 61%|██████▏   | 46/75 [17:46<10:31, 21.79s/epoch, loss=1.13, accuracy=0.755, val_loss=3.24, val_accuracy=0.359, lr=0.1] 63%|██████▎   | 47/75 [18:08<10:15, 21.98s/epoch, loss=1.12, accuracy=0.755, val_loss=2.45, val_accuracy=0.439, lr=0.0316] 64%|██████▍   | 48/75 [18:30<09:55, 22.07s/epoch, loss=1.13, accuracy=0.755, val_loss=3.82, val_accuracy=0.277, lr=0.1]    65%|██████▌   | 49/75 [18:52<09:31, 21.99s/epoch, loss=1.13, accuracy=0.755, val_loss=1.93, val_accuracy=0.51, lr=0.1]  67%|██████▋   | 50/75 [19:14<09:09, 21.98s/epoch, loss=1.13, accuracy=0.757, val_loss=1.75, val_accuracy=0.578, lr=0.1] 68%|██████▊   | 51/75 [19:37<08:53, 22.22s/epoch, loss=1.13, accuracy=0.757, val_loss=2.12, val_accuracy=0.478, lr=0.1] 69%|██████▉   | 52/75 [20:00<08:34, 22.36s/epoch, loss=1.13, accuracy=0.756, val_loss=1.83, val_accuracy=0.507, lr=0.0316] 71%|███████   | 53/75 [20:21<08:04, 22.03s/epoch, loss=1.11, accuracy=0.759, val_loss=1.86, val_accuracy=0.483, lr=0.1]    72%|███████▏  | 54/75 [20:43<07:45, 22.19s/epoch, loss=1.12, accuracy=0.758, val_loss=1.62, val_accuracy=0.621, lr=0.1] 73%|███████▎  | 55/75 [21:06<07:27, 22.37s/epoch, loss=1.11, accuracy=0.759, val_loss=2.21, val_accuracy=0.442, lr=0.1] 75%|███████▍  | 56/75 [21:29<07:08, 22.54s/epoch, loss=1.12, accuracy=0.757, val_loss=2.68, val_accuracy=0.35, lr=0.1]  76%|███████▌  | 57/75 [21:52<06:45, 22.51s/epoch, loss=1.12, accuracy=0.759, val_loss=1.8, val_accuracy=0.556, lr=0.0316] 77%|███████▋  | 58/75 [22:14<06:22, 22.48s/epoch, loss=1.12, accuracy=0.758, val_loss=1.86, val_accuracy=0.509, lr=0.1]   79%|███████▊  | 59/75 [22:36<05:59, 22.48s/epoch, loss=1.12, accuracy=0.756, val_loss=1.78, val_accuracy=0.524, lr=0.1] 80%|████████  | 60/75 [22:59<05:37, 22.48s/epoch, loss=1.11, accuracy=0.759, val_loss=2.21, val_accuracy=0.452, lr=0.1] 81%|████████▏ | 61/75 [23:21<05:12, 22.32s/epoch, loss=1.13, accuracy=0.755, val_loss=2.53, val_accuracy=0.364, lr=0.1] 83%|████████▎ | 62/75 [23:43<04:50, 22.34s/epoch, loss=1.12, accuracy=0.756, val_loss=2.71, val_accuracy=0.42, lr=0.0316] 84%|████████▍ | 63/75 [24:06<04:29, 22.45s/epoch, loss=1.12, accuracy=0.757, val_loss=1.9, val_accuracy=0.522, lr=0.1]    85%|████████▌ | 64/75 [24:28<04:06, 22.40s/epoch, loss=1.12, accuracy=0.758, val_loss=1.62, val_accuracy=0.582, lr=0.1] 87%|████████▋ | 65/75 [24:51<03:44, 22.41s/epoch, loss=1.12, accuracy=0.756, val_loss=2.66, val_accuracy=0.375, lr=0.1] 88%|████████▊ | 66/75 [25:13<03:21, 22.34s/epoch, loss=1.12, accuracy=0.759, val_loss=2.6, val_accuracy=0.411, lr=0.1]  89%|████████▉ | 67/75 [25:35<02:59, 22.42s/epoch, loss=1.11, accuracy=0.759, val_loss=3.02, val_accuracy=0.433, lr=0.0316] 91%|█████████ | 68/75 [25:57<02:36, 22.30s/epoch, loss=1.1, accuracy=0.763, val_loss=4.62, val_accuracy=0.332, lr=0.1]     92%|█████████▏| 69/75 [26:20<02:14, 22.43s/epoch, loss=1.12, accuracy=0.76, val_loss=4.68, val_accuracy=0.251, lr=0.1] 93%|█████████▎| 70/75 [26:43<01:52, 22.51s/epoch, loss=1.11, accuracy=0.757, val_loss=1.88, val_accuracy=0.527, lr=0.1] 95%|█████████▍| 71/75 [27:05<01:29, 22.46s/epoch, loss=1.11, accuracy=0.76, val_loss=2.81, val_accuracy=0.413, lr=0.1]  96%|█████████▌| 72/75 [27:28<01:07, 22.49s/epoch, loss=1.11, accuracy=0.758, val_loss=1.9, val_accuracy=0.552, lr=0.0316] 97%|█████████▋| 73/75 [27:50<00:44, 22.49s/epoch, loss=1.12, accuracy=0.76, val_loss=1.82, val_accuracy=0.528, lr=0.1]    99%|█████████▊| 74/75 [28:13<00:22, 22.55s/epoch, loss=1.12, accuracy=0.759, val_loss=2.26, val_accuracy=0.473, lr=0.1]100%|██████████| 75/75 [28:35<00:00, 22.42s/epoch, loss=1.11, accuracy=0.758, val_loss=1.77, val_accuracy=0.576, lr=0.1]100%|██████████| 75/75 [28:35<00:00, 22.88s/epoch, loss=1.11, accuracy=0.758, val_loss=1.77, val_accuracy=0.576, lr=0.1]
Using real-time data augmentation.
Test loss: 1.7743840217590332
Test accuracy: 0.5764999985694885


* * * Run SGD for ID = 20_10. * * *


2024-02-16 00:30:52.321390: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-16 00:30:54.907809: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-16 00:30:54.908943: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-16 00:30:54.945715: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-16 00:30:54.945743: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-16 00:30:54.948540: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-16 00:30:54.948578: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-16 00:30:54.950815: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-16 00:30:54.951461: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-16 00:30:54.953688: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-16 00:30:54.955151: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-16 00:30:54.959810: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-16 00:30:54.960266: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-16 00:30:54.960374: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-16 00:30:56.236161: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-16 00:30:56.236733: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-16 00:30:56.237368: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-16 00:30:56.237399: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-16 00:30:56.237447: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-16 00:30:56.237468: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-16 00:30:56.237488: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-16 00:30:56.237507: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-16 00:30:56.237535: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-16 00:30:56.237554: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-16 00:30:56.237572: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-16 00:30:56.238010: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-16 00:30:56.238046: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-16 00:30:56.847328: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-16 00:30:56.847389: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-16 00:30:56.847400: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-16 00:30:56.848292: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': 2010, 'batch_size': 128, 'epochs': 75, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/75 [00:00<?, ?epoch/s]2024-02-16 00:30:57.604704: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-16 00:30:57.616397: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2599900000 Hz
2024-02-16 00:30:59.429450: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-16 00:30:59.703610: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-16 00:31:00.477034: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-16 00:31:00.520476: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|▏         | 1/75 [00:52<1:04:34, 52.35s/epoch, loss=3.06, accuracy=0.324, val_loss=2.26, val_accuracy=0.301, lr=0.1]  3%|▎         | 2/75 [01:13<41:05, 33.78s/epoch, loss=1.57, accuracy=0.526, val_loss=4.3, val_accuracy=0.221, lr=0.1]     4%|▍         | 3/75 [01:35<34:04, 28.39s/epoch, loss=1.32, accuracy=0.642, val_loss=2.61, val_accuracy=0.374, lr=0.1]  5%|▌         | 4/75 [01:57<30:47, 26.03s/epoch, loss=1.25, accuracy=0.686, val_loss=2.96, val_accuracy=0.26, lr=0.1]   7%|▋         | 5/75 [02:19<28:35, 24.51s/epoch, loss=1.23, accuracy=0.699, val_loss=2.23, val_accuracy=0.353, lr=0.1]  8%|▊         | 6/75 [02:41<27:14, 23.68s/epoch, loss=1.2, accuracy=0.716, val_loss=1.61, val_accuracy=0.585, lr=0.1]   9%|▉         | 7/75 [03:01<25:41, 22.67s/epoch, loss=1.2, accuracy=0.719, val_loss=2.56, val_accuracy=0.378, lr=0.1] 11%|█         | 8/75 [03:24<25:12, 22.57s/epoch, loss=1.19, accuracy=0.727, val_loss=2.75, val_accuracy=0.435, lr=0.1] 12%|█▏        | 9/75 [03:46<24:38, 22.40s/epoch, loss=1.19, accuracy=0.729, val_loss=1.9, val_accuracy=0.489, lr=0.1]  13%|█▎        | 10/75 [04:08<24:15, 22.40s/epoch, loss=1.18, accuracy=0.733, val_loss=3.3, val_accuracy=0.291, lr=0.1] 15%|█▍        | 11/75 [04:30<23:49, 22.33s/epoch, loss=1.18, accuracy=0.738, val_loss=2.13, val_accuracy=0.453, lr=0.0316] 16%|█▌        | 12/75 [04:53<23:24, 22.29s/epoch, loss=1.18, accuracy=0.735, val_loss=2.09, val_accuracy=0.454, lr=0.1]    17%|█▋        | 13/75 [05:15<23:04, 22.34s/epoch, loss=1.17, accuracy=0.739, val_loss=1.55, val_accuracy=0.588, lr=0.1] 19%|█▊        | 14/75 [05:37<22:41, 22.33s/epoch, loss=1.16, accuracy=0.742, val_loss=2.01, val_accuracy=0.541, lr=0.1] 20%|██        | 15/75 [05:58<21:46, 21.78s/epoch, loss=1.17, accuracy=0.742, val_loss=2.13, val_accuracy=0.451, lr=0.1] 21%|██▏       | 16/75 [06:20<21:35, 21.96s/epoch, loss=1.16, accuracy=0.742, val_loss=3.95, val_accuracy=0.326, lr=0.1] 23%|██▎       | 17/75 [06:43<21:21, 22.10s/epoch, loss=1.15, accuracy=0.744, val_loss=5.83, val_accuracy=0.204, lr=0.1] 24%|██▍       | 18/75 [07:05<21:02, 22.14s/epoch, loss=1.15, accuracy=0.744, val_loss=1.76, val_accuracy=0.562, lr=0.0316] 25%|██▌       | 19/75 [07:27<20:45, 22.25s/epoch, loss=1.14, accuracy=0.748, val_loss=1.63, val_accuracy=0.626, lr=0.1]    27%|██▋       | 20/75 [07:50<20:20, 22.19s/epoch, loss=1.14, accuracy=0.748, val_loss=5.05, val_accuracy=0.253, lr=0.1] 28%|██▊       | 21/75 [08:11<19:52, 22.08s/epoch, loss=1.14, accuracy=0.748, val_loss=2.57, val_accuracy=0.438, lr=0.1] 29%|██▉       | 22/75 [08:34<19:38, 22.24s/epoch, loss=1.14, accuracy=0.748, val_loss=1.51, val_accuracy=0.63, lr=0.1]  31%|███       | 23/75 [08:56<19:19, 22.30s/epoch, loss=1.14, accuracy=0.749, val_loss=1.56, val_accuracy=0.606, lr=0.1] 32%|███▏      | 24/75 [09:19<18:58, 22.32s/epoch, loss=1.14, accuracy=0.75, val_loss=1.7, val_accuracy=0.57, lr=0.1]    33%|███▎      | 25/75 [09:41<18:34, 22.28s/epoch, loss=1.13, accuracy=0.752, val_loss=1.55, val_accuracy=0.626, lr=0.1] 35%|███▍      | 26/75 [10:03<18:06, 22.18s/epoch, loss=1.13, accuracy=0.751, val_loss=2, val_accuracy=0.519, lr=0.1]    36%|███▌      | 27/75 [10:25<17:50, 22.29s/epoch, loss=1.12, accuracy=0.754, val_loss=2.63, val_accuracy=0.427, lr=0.0316] 37%|███▋      | 28/75 [10:48<17:33, 22.42s/epoch, loss=1.12, accuracy=0.755, val_loss=2.31, val_accuracy=0.416, lr=0.1]    39%|███▊      | 29/75 [11:11<17:13, 22.47s/epoch, loss=1.12, accuracy=0.755, val_loss=1.85, val_accuracy=0.57, lr=0.1]  40%|████      | 30/75 [11:33<16:50, 22.46s/epoch, loss=1.12, accuracy=0.752, val_loss=3.05, val_accuracy=0.412, lr=0.1] 41%|████▏     | 31/75 [11:56<16:28, 22.46s/epoch, loss=1.12, accuracy=0.755, val_loss=2.52, val_accuracy=0.452, lr=0.1] 43%|████▎     | 32/75 [12:18<16:05, 22.46s/epoch, loss=1.12, accuracy=0.757, val_loss=2.21, val_accuracy=0.432, lr=0.0316] 44%|████▍     | 33/75 [12:40<15:40, 22.39s/epoch, loss=1.12, accuracy=0.756, val_loss=1.64, val_accuracy=0.612, lr=0.1]    45%|████▌     | 34/75 [13:02<15:07, 22.14s/epoch, loss=1.12, accuracy=0.757, val_loss=3.26, val_accuracy=0.389, lr=0.1] 47%|████▋     | 35/75 [13:24<14:42, 22.05s/epoch, loss=1.12, accuracy=0.756, val_loss=2.21, val_accuracy=0.504, lr=0.1] 48%|████▊     | 36/75 [13:46<14:21, 22.10s/epoch, loss=1.12, accuracy=0.755, val_loss=2.05, val_accuracy=0.473, lr=0.1] 49%|████▉     | 37/75 [14:08<14:02, 22.16s/epoch, loss=1.11, accuracy=0.756, val_loss=4.27, val_accuracy=0.35, lr=0.0316] 51%|█████     | 38/75 [14:31<13:44, 22.27s/epoch, loss=1.12, accuracy=0.754, val_loss=2.42, val_accuracy=0.377, lr=0.1]   52%|█████▏    | 39/75 [14:53<13:20, 22.23s/epoch, loss=1.12, accuracy=0.756, val_loss=2.46, val_accuracy=0.434, lr=0.1] 53%|█████▎    | 40/75 [15:15<12:57, 22.21s/epoch, loss=1.12, accuracy=0.756, val_loss=2.17, val_accuracy=0.451, lr=0.1] 55%|█████▍    | 41/75 [15:37<12:34, 22.19s/epoch, loss=1.11, accuracy=0.758, val_loss=2.69, val_accuracy=0.512, lr=0.1] 56%|█████▌    | 42/75 [16:00<12:14, 22.26s/epoch, loss=1.11, accuracy=0.756, val_loss=2.51, val_accuracy=0.399, lr=0.0316] 57%|█████▋    | 43/75 [16:22<11:53, 22.29s/epoch, loss=1.11, accuracy=0.756, val_loss=1.78, val_accuracy=0.535, lr=0.1]    59%|█████▊    | 44/75 [16:44<11:30, 22.27s/epoch, loss=1.12, accuracy=0.758, val_loss=1.62, val_accuracy=0.623, lr=0.1] 60%|██████    | 45/75 [17:06<11:06, 22.22s/epoch, loss=1.11, accuracy=0.759, val_loss=1.49, val_accuracy=0.629, lr=0.1] 61%|██████▏   | 46/75 [17:29<10:45, 22.25s/epoch, loss=1.11, accuracy=0.759, val_loss=1.96, val_accuracy=0.546, lr=0.1] 63%|██████▎   | 47/75 [17:51<10:24, 22.30s/epoch, loss=1.12, accuracy=0.758, val_loss=3.27, val_accuracy=0.361, lr=0.1] 64%|██████▍   | 48/75 [18:12<09:52, 21.94s/epoch, loss=1.11, accuracy=0.759, val_loss=1.42, val_accuracy=0.656, lr=0.1] 65%|██████▌   | 49/75 [18:34<09:32, 22.03s/epoch, loss=1.12, accuracy=0.758, val_loss=1.83, val_accuracy=0.566, lr=0.1] 67%|██████▋   | 50/75 [18:57<09:13, 22.14s/epoch, loss=1.11, accuracy=0.759, val_loss=1.59, val_accuracy=0.582, lr=0.1] 68%|██████▊   | 51/75 [19:19<08:53, 22.22s/epoch, loss=1.11, accuracy=0.757, val_loss=4.82, val_accuracy=0.288, lr=0.1] 69%|██████▉   | 52/75 [19:41<08:31, 22.23s/epoch, loss=1.11, accuracy=0.758, val_loss=3.01, val_accuracy=0.336, lr=0.1] 71%|███████   | 53/75 [20:04<08:08, 22.18s/epoch, loss=1.11, accuracy=0.758, val_loss=2.69, val_accuracy=0.421, lr=0.0316] 72%|███████▏  | 54/75 [20:26<07:48, 22.32s/epoch, loss=1.11, accuracy=0.76, val_loss=1.94, val_accuracy=0.528, lr=0.1]     73%|███████▎  | 55/75 [20:49<07:27, 22.40s/epoch, loss=1.11, accuracy=0.76, val_loss=3.83, val_accuracy=0.347, lr=0.1] 75%|███████▍  | 56/75 [21:11<07:05, 22.38s/epoch, loss=1.12, accuracy=0.758, val_loss=3.27, val_accuracy=0.284, lr=0.1] 76%|███████▌  | 57/75 [21:33<06:41, 22.32s/epoch, loss=1.11, accuracy=0.757, val_loss=3.88, val_accuracy=0.353, lr=0.1] 77%|███████▋  | 58/75 [21:55<06:15, 22.08s/epoch, loss=1.11, accuracy=0.759, val_loss=2.57, val_accuracy=0.444, lr=0.0316] 79%|███████▊  | 59/75 [22:17<05:54, 22.18s/epoch, loss=1.11, accuracy=0.759, val_loss=3.91, val_accuracy=0.306, lr=0.1]    80%|████████  | 60/75 [22:38<05:27, 21.81s/epoch, loss=1.11, accuracy=0.76, val_loss=2.46, val_accuracy=0.433, lr=0.1]  81%|████████▏ | 61/75 [23:00<05:07, 21.93s/epoch, loss=1.11, accuracy=0.759, val_loss=2.23, val_accuracy=0.419, lr=0.1] 83%|████████▎ | 62/75 [23:23<04:46, 22.06s/epoch, loss=1.11, accuracy=0.761, val_loss=1.7, val_accuracy=0.578, lr=0.1]  84%|████████▍ | 63/75 [23:45<04:25, 22.12s/epoch, loss=1.11, accuracy=0.759, val_loss=1.87, val_accuracy=0.55, lr=0.0316] 85%|████████▌ | 64/75 [24:07<04:04, 22.21s/epoch, loss=1.11, accuracy=0.761, val_loss=1.95, val_accuracy=0.46, lr=0.1]    87%|████████▋ | 65/75 [24:30<03:41, 22.19s/epoch, loss=1.11, accuracy=0.758, val_loss=1.68, val_accuracy=0.575, lr=0.1] 88%|████████▊ | 66/75 [24:52<03:20, 22.24s/epoch, loss=1.11, accuracy=0.758, val_loss=2.88, val_accuracy=0.351, lr=0.1] 89%|████████▉ | 67/75 [25:14<02:58, 22.29s/epoch, loss=1.11, accuracy=0.76, val_loss=2.98, val_accuracy=0.367, lr=0.1]  91%|█████████ | 68/75 [25:37<02:35, 22.27s/epoch, loss=1.1, accuracy=0.76, val_loss=1.78, val_accuracy=0.545, lr=0.0316] 92%|█████████▏| 69/75 [25:58<02:13, 22.17s/epoch, loss=1.12, accuracy=0.76, val_loss=1.83, val_accuracy=0.531, lr=0.1]   93%|█████████▎| 70/75 [26:20<01:50, 22.12s/epoch, loss=1.11, accuracy=0.759, val_loss=1.46, val_accuracy=0.649, lr=0.1] 95%|█████████▍| 71/75 [26:42<01:28, 22.08s/epoch, loss=1.11, accuracy=0.757, val_loss=2.31, val_accuracy=0.47, lr=0.1]  96%|█████████▌| 72/75 [27:05<01:06, 22.08s/epoch, loss=1.11, accuracy=0.757, val_loss=1.94, val_accuracy=0.545, lr=0.1] 97%|█████████▋| 73/75 [27:27<00:44, 22.08s/epoch, loss=1.11, accuracy=0.759, val_loss=1.9, val_accuracy=0.503, lr=0.0316] 99%|█████████▊| 74/75 [27:49<00:22, 22.14s/epoch, loss=1.11, accuracy=0.759, val_loss=1.41, val_accuracy=0.656, lr=0.1]  100%|██████████| 75/75 [28:11<00:00, 22.12s/epoch, loss=1.11, accuracy=0.757, val_loss=2.43, val_accuracy=0.482, lr=0.1]100%|██████████| 75/75 [28:11<00:00, 22.55s/epoch, loss=1.11, accuracy=0.757, val_loss=2.43, val_accuracy=0.482, lr=0.1]
Using real-time data augmentation.
Test loss: 2.431919813156128
Test accuracy: 0.48249998688697815


* * * Run SGD for ID = 20_11. * * *


2024-02-16 00:59:12.921365: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-16 00:59:18.440174: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-16 00:59:18.441230: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-16 00:59:18.476684: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-16 00:59:18.476714: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-16 00:59:18.479284: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-16 00:59:18.479340: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-16 00:59:18.481558: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-16 00:59:18.482198: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-16 00:59:18.484417: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-16 00:59:18.485785: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-16 00:59:18.490380: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-16 00:59:18.490853: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-16 00:59:18.490923: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-16 00:59:19.664654: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-16 00:59:19.665184: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-16 00:59:19.665819: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-16 00:59:19.665850: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-16 00:59:19.665897: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-16 00:59:19.665926: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-16 00:59:19.665946: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-16 00:59:19.665964: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-16 00:59:19.665981: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-16 00:59:19.665999: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-16 00:59:19.666017: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-16 00:59:19.666434: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-16 00:59:19.666465: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-16 00:59:20.283913: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-16 00:59:20.283971: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-16 00:59:20.283988: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-16 00:59:20.284918: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': 2011, 'batch_size': 128, 'epochs': 75, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/75 [00:00<?, ?epoch/s]2024-02-16 00:59:21.060990: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-16 00:59:21.073398: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2599900000 Hz
2024-02-16 00:59:22.882507: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-16 00:59:23.093942: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-16 00:59:23.824460: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-16 00:59:23.867272: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|▏         | 1/75 [00:55<1:08:01, 55.15s/epoch, loss=3.36, accuracy=0.24, val_loss=3.66, val_accuracy=0.147, lr=0.1]  3%|▎         | 2/75 [01:17<43:19, 35.61s/epoch, loss=1.63, accuracy=0.495, val_loss=3.01, val_accuracy=0.244, lr=0.1]   4%|▍         | 3/75 [01:39<35:34, 29.65s/epoch, loss=1.35, accuracy=0.627, val_loss=2.1, val_accuracy=0.388, lr=0.1]   5%|▌         | 4/75 [02:02<31:49, 26.89s/epoch, loss=1.28, accuracy=0.673, val_loss=2.06, val_accuracy=0.454, lr=0.1]  7%|▋         | 5/75 [02:24<29:27, 25.25s/epoch, loss=1.25, accuracy=0.694, val_loss=1.89, val_accuracy=0.487, lr=0.1]  8%|▊         | 6/75 [02:47<27:57, 24.31s/epoch, loss=1.24, accuracy=0.704, val_loss=1.69, val_accuracy=0.552, lr=0.1]  9%|▉         | 7/75 [03:09<26:51, 23.70s/epoch, loss=1.22, accuracy=0.712, val_loss=1.86, val_accuracy=0.519, lr=0.1] 11%|█         | 8/75 [03:32<26:06, 23.38s/epoch, loss=1.21, accuracy=0.722, val_loss=3.48, val_accuracy=0.305, lr=0.1] 12%|█▏        | 9/75 [03:54<25:22, 23.07s/epoch, loss=1.21, accuracy=0.721, val_loss=2.68, val_accuracy=0.402, lr=0.1] 13%|█▎        | 10/75 [04:17<24:52, 22.96s/epoch, loss=1.21, accuracy=0.724, val_loss=1.79, val_accuracy=0.541, lr=0.1] 15%|█▍        | 11/75 [04:39<24:20, 22.82s/epoch, loss=1.2, accuracy=0.728, val_loss=1.57, val_accuracy=0.582, lr=0.1]  16%|█▌        | 12/75 [05:02<23:49, 22.69s/epoch, loss=1.19, accuracy=0.731, val_loss=1.95, val_accuracy=0.541, lr=0.1] 17%|█▋        | 13/75 [05:24<23:13, 22.47s/epoch, loss=1.19, accuracy=0.734, val_loss=1.71, val_accuracy=0.572, lr=0.1] 19%|█▊        | 14/75 [05:46<22:53, 22.51s/epoch, loss=1.18, accuracy=0.735, val_loss=4.2, val_accuracy=0.384, lr=0.1]  20%|██        | 15/75 [06:09<22:37, 22.62s/epoch, loss=1.18, accuracy=0.737, val_loss=2.14, val_accuracy=0.5, lr=0.1]  21%|██▏       | 16/75 [06:32<22:18, 22.68s/epoch, loss=1.18, accuracy=0.738, val_loss=1.91, val_accuracy=0.523, lr=0.0316] 23%|██▎       | 17/75 [06:55<21:56, 22.70s/epoch, loss=1.18, accuracy=0.738, val_loss=1.49, val_accuracy=0.628, lr=0.1]    24%|██▍       | 18/75 [07:17<21:27, 22.58s/epoch, loss=1.18, accuracy=0.739, val_loss=1.9, val_accuracy=0.505, lr=0.1]  25%|██▌       | 19/75 [07:40<21:02, 22.55s/epoch, loss=1.18, accuracy=0.737, val_loss=1.93, val_accuracy=0.554, lr=0.1] 27%|██▋       | 20/75 [08:02<20:39, 22.53s/epoch, loss=1.18, accuracy=0.741, val_loss=2, val_accuracy=0.466, lr=0.1]    28%|██▊       | 21/75 [08:24<20:13, 22.47s/epoch, loss=1.17, accuracy=0.743, val_loss=5.66, val_accuracy=0.241, lr=0.1] 29%|██▉       | 22/75 [08:47<19:51, 22.47s/epoch, loss=1.17, accuracy=0.744, val_loss=1.86, val_accuracy=0.539, lr=0.0316] 31%|███       | 23/75 [09:09<19:29, 22.48s/epoch, loss=1.17, accuracy=0.741, val_loss=3.41, val_accuracy=0.329, lr=0.1]    32%|███▏      | 24/75 [09:32<19:03, 22.43s/epoch, loss=1.17, accuracy=0.743, val_loss=4.33, val_accuracy=0.294, lr=0.1] 33%|███▎      | 25/75 [09:54<18:43, 22.48s/epoch, loss=1.17, accuracy=0.745, val_loss=1.77, val_accuracy=0.551, lr=0.1] 35%|███▍      | 26/75 [10:17<18:21, 22.47s/epoch, loss=1.16, accuracy=0.744, val_loss=2.12, val_accuracy=0.461, lr=0.1] 36%|███▌      | 27/75 [10:39<18:00, 22.51s/epoch, loss=1.16, accuracy=0.744, val_loss=1.55, val_accuracy=0.622, lr=0.0316] 37%|███▋      | 28/75 [11:01<17:32, 22.39s/epoch, loss=1.17, accuracy=0.744, val_loss=1.88, val_accuracy=0.571, lr=0.1]    39%|███▊      | 29/75 [11:24<17:14, 22.49s/epoch, loss=1.17, accuracy=0.745, val_loss=3.29, val_accuracy=0.308, lr=0.1] 40%|████      | 30/75 [11:47<16:54, 22.54s/epoch, loss=1.16, accuracy=0.748, val_loss=1.54, val_accuracy=0.624, lr=0.1] 41%|████▏     | 31/75 [12:09<16:28, 22.47s/epoch, loss=1.16, accuracy=0.744, val_loss=1.88, val_accuracy=0.539, lr=0.1] 43%|████▎     | 32/75 [12:31<15:57, 22.27s/epoch, loss=1.17, accuracy=0.745, val_loss=2.45, val_accuracy=0.432, lr=0.0316] 44%|████▍     | 33/75 [12:53<15:35, 22.28s/epoch, loss=1.16, accuracy=0.751, val_loss=1.47, val_accuracy=0.637, lr=0.1]    45%|████▌     | 34/75 [13:16<15:19, 22.42s/epoch, loss=1.15, accuracy=0.747, val_loss=2.11, val_accuracy=0.51, lr=0.1]  47%|████▋     | 35/75 [13:39<14:59, 22.50s/epoch, loss=1.16, accuracy=0.748, val_loss=1.91, val_accuracy=0.543, lr=0.1] 48%|████▊     | 36/75 [14:01<14:39, 22.55s/epoch, loss=1.16, accuracy=0.746, val_loss=1.48, val_accuracy=0.639, lr=0.1] 49%|████▉     | 37/75 [14:24<14:18, 22.59s/epoch, loss=1.14, accuracy=0.748, val_loss=1.89, val_accuracy=0.551, lr=0.1] 51%|█████     | 38/75 [14:46<13:54, 22.55s/epoch, loss=1.16, accuracy=0.747, val_loss=2.27, val_accuracy=0.506, lr=0.0316] 52%|█████▏    | 39/75 [15:09<13:30, 22.51s/epoch, loss=1.15, accuracy=0.748, val_loss=1.92, val_accuracy=0.465, lr=0.1]    53%|█████▎    | 40/75 [15:31<13:08, 22.54s/epoch, loss=1.15, accuracy=0.75, val_loss=3.09, val_accuracy=0.387, lr=0.1]  55%|█████▍    | 41/75 [15:54<12:48, 22.59s/epoch, loss=1.15, accuracy=0.748, val_loss=1.77, val_accuracy=0.562, lr=0.1] 56%|█████▌    | 42/75 [16:17<12:23, 22.53s/epoch, loss=1.14, accuracy=0.751, val_loss=1.65, val_accuracy=0.592, lr=0.1] 57%|█████▋    | 43/75 [16:39<12:01, 22.56s/epoch, loss=1.15, accuracy=0.75, val_loss=1.62, val_accuracy=0.57, lr=0.0316] 59%|█████▊    | 44/75 [17:02<11:39, 22.56s/epoch, loss=1.15, accuracy=0.75, val_loss=2.67, val_accuracy=0.464, lr=0.1]   60%|██████    | 45/75 [17:24<11:18, 22.60s/epoch, loss=1.15, accuracy=0.75, val_loss=1.76, val_accuracy=0.538, lr=0.1] 61%|██████▏   | 46/75 [17:46<10:50, 22.42s/epoch, loss=1.14, accuracy=0.75, val_loss=3.16, val_accuracy=0.391, lr=0.1] 63%|██████▎   | 47/75 [18:08<10:23, 22.25s/epoch, loss=1.14, accuracy=0.751, val_loss=1.86, val_accuracy=0.494, lr=0.1] 64%|██████▍   | 48/75 [18:31<10:02, 22.30s/epoch, loss=1.15, accuracy=0.751, val_loss=3.78, val_accuracy=0.339, lr=0.0316] 65%|██████▌   | 49/75 [18:53<09:42, 22.42s/epoch, loss=1.14, accuracy=0.751, val_loss=1.57, val_accuracy=0.637, lr=0.1]    67%|██████▋   | 50/75 [19:16<09:18, 22.36s/epoch, loss=1.14, accuracy=0.752, val_loss=1.71, val_accuracy=0.572, lr=0.1] 68%|██████▊   | 51/75 [19:38<08:54, 22.28s/epoch, loss=1.14, accuracy=0.75, val_loss=1.65, val_accuracy=0.577, lr=0.1]  69%|██████▉   | 52/75 [20:00<08:35, 22.42s/epoch, loss=1.15, accuracy=0.749, val_loss=1.97, val_accuracy=0.501, lr=0.1] 71%|███████   | 53/75 [20:23<08:15, 22.52s/epoch, loss=1.14, accuracy=0.751, val_loss=2.74, val_accuracy=0.404, lr=0.0316] 72%|███████▏  | 54/75 [20:46<07:53, 22.55s/epoch, loss=1.14, accuracy=0.751, val_loss=2.09, val_accuracy=0.525, lr=0.1]    73%|███████▎  | 55/75 [21:09<07:32, 22.60s/epoch, loss=1.14, accuracy=0.75, val_loss=2.07, val_accuracy=0.438, lr=0.1]  75%|███████▍  | 56/75 [21:31<07:06, 22.47s/epoch, loss=1.14, accuracy=0.752, val_loss=1.63, val_accuracy=0.579, lr=0.1] 76%|███████▌  | 57/75 [21:53<06:45, 22.51s/epoch, loss=1.13, accuracy=0.751, val_loss=1.78, val_accuracy=0.552, lr=0.1] 77%|███████▋  | 58/75 [22:16<06:24, 22.59s/epoch, loss=1.14, accuracy=0.751, val_loss=1.71, val_accuracy=0.559, lr=0.0316] 79%|███████▊  | 59/75 [22:38<05:59, 22.48s/epoch, loss=1.14, accuracy=0.751, val_loss=2.2, val_accuracy=0.375, lr=0.1]     80%|████████  | 60/75 [23:00<05:35, 22.35s/epoch, loss=1.14, accuracy=0.753, val_loss=2.94, val_accuracy=0.359, lr=0.1] 81%|████████▏ | 61/75 [23:23<05:13, 22.42s/epoch, loss=1.14, accuracy=0.749, val_loss=1.66, val_accuracy=0.604, lr=0.1] 83%|████████▎ | 62/75 [23:45<04:51, 22.44s/epoch, loss=1.13, accuracy=0.753, val_loss=4.72, val_accuracy=0.338, lr=0.1] 84%|████████▍ | 63/75 [24:08<04:30, 22.54s/epoch, loss=1.14, accuracy=0.75, val_loss=2.58, val_accuracy=0.421, lr=0.0316] 85%|████████▌ | 64/75 [24:31<04:08, 22.62s/epoch, loss=1.14, accuracy=0.751, val_loss=2.79, val_accuracy=0.421, lr=0.1]   87%|████████▋ | 65/75 [24:54<03:46, 22.62s/epoch, loss=1.14, accuracy=0.752, val_loss=2.25, val_accuracy=0.441, lr=0.1] 88%|████████▊ | 66/75 [25:16<03:22, 22.50s/epoch, loss=1.13, accuracy=0.753, val_loss=6.01, val_accuracy=0.182, lr=0.1] 89%|████████▉ | 67/75 [25:38<03:00, 22.51s/epoch, loss=1.15, accuracy=0.75, val_loss=3.65, val_accuracy=0.327, lr=0.1]  91%|█████████ | 68/75 [26:01<02:37, 22.53s/epoch, loss=1.15, accuracy=0.75, val_loss=2.12, val_accuracy=0.498, lr=0.0316] 92%|█████████▏| 69/75 [26:23<02:15, 22.51s/epoch, loss=1.14, accuracy=0.752, val_loss=3.26, val_accuracy=0.292, lr=0.1]   93%|█████████▎| 70/75 [26:46<01:52, 22.45s/epoch, loss=1.14, accuracy=0.751, val_loss=2.97, val_accuracy=0.373, lr=0.1] 95%|█████████▍| 71/75 [27:08<01:29, 22.38s/epoch, loss=1.14, accuracy=0.752, val_loss=2.46, val_accuracy=0.402, lr=0.1] 96%|█████████▌| 72/75 [27:30<01:06, 22.32s/epoch, loss=1.13, accuracy=0.753, val_loss=1.45, val_accuracy=0.638, lr=0.1] 97%|█████████▋| 73/75 [27:52<00:44, 22.30s/epoch, loss=1.14, accuracy=0.751, val_loss=3.04, val_accuracy=0.398, lr=0.1] 99%|█████████▊| 74/75 [28:15<00:22, 22.26s/epoch, loss=1.14, accuracy=0.752, val_loss=1.69, val_accuracy=0.568, lr=0.1]100%|██████████| 75/75 [28:37<00:00, 22.24s/epoch, loss=1.14, accuracy=0.752, val_loss=2.97, val_accuracy=0.318, lr=0.1]100%|██████████| 75/75 [28:37<00:00, 22.90s/epoch, loss=1.14, accuracy=0.752, val_loss=2.97, val_accuracy=0.318, lr=0.1]
Using real-time data augmentation.
Test loss: 2.974602699279785
Test accuracy: 0.31769999861717224


* * * Run SGD for ID = 20_12. * * *


2024-02-16 01:28:01.094432: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-16 01:28:03.455496: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-16 01:28:03.456565: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-16 01:28:03.491350: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-16 01:28:03.491386: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-16 01:28:03.494105: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-16 01:28:03.494143: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-16 01:28:03.496156: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-16 01:28:03.496753: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-16 01:28:03.498974: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-16 01:28:03.500354: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-16 01:28:03.504739: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-16 01:28:03.505210: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-16 01:28:03.505306: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-16 01:28:04.718364: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-16 01:28:04.719300: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-16 01:28:04.719922: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-16 01:28:04.719960: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-16 01:28:04.720007: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-16 01:28:04.720027: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-16 01:28:04.720045: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-16 01:28:04.720063: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-16 01:28:04.720082: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-16 01:28:04.720100: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-16 01:28:04.720118: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-16 01:28:04.720556: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-16 01:28:04.720588: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-16 01:28:05.365684: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-16 01:28:05.365735: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-16 01:28:05.365744: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-16 01:28:05.366590: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': 2012, 'batch_size': 128, 'epochs': 75, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/75 [00:00<?, ?epoch/s]2024-02-16 01:28:06.118079: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-16 01:28:06.130405: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2599900000 Hz
2024-02-16 01:28:07.954143: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-16 01:28:08.147018: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-16 01:28:08.842089: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-16 01:28:08.879337: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|▏         | 1/75 [00:54<1:07:46, 54.95s/epoch, loss=3.16, accuracy=0.303, val_loss=2.19, val_accuracy=0.277, lr=0.1]  3%|▎         | 2/75 [01:16<43:11, 35.50s/epoch, loss=1.68, accuracy=0.471, val_loss=2.3, val_accuracy=0.343, lr=0.1]     4%|▍         | 3/75 [01:39<35:26, 29.54s/epoch, loss=1.46, accuracy=0.575, val_loss=2.62, val_accuracy=0.361, lr=0.1]  5%|▌         | 4/75 [02:02<31:46, 26.86s/epoch, loss=1.31, accuracy=0.655, val_loss=1.88, val_accuracy=0.489, lr=0.1]  7%|▋         | 5/75 [02:23<29:15, 25.08s/epoch, loss=1.27, accuracy=0.689, val_loss=1.89, val_accuracy=0.52, lr=0.1]   8%|▊         | 6/75 [02:46<27:42, 24.10s/epoch, loss=1.25, accuracy=0.702, val_loss=2.14, val_accuracy=0.489, lr=0.1]  9%|▉         | 7/75 [03:08<26:35, 23.46s/epoch, loss=1.24, accuracy=0.711, val_loss=1.73, val_accuracy=0.553, lr=0.1] 11%|█         | 8/75 [03:31<25:57, 23.24s/epoch, loss=1.22, accuracy=0.72, val_loss=2.35, val_accuracy=0.383, lr=0.1]  12%|█▏        | 9/75 [03:53<25:21, 23.05s/epoch, loss=1.22, accuracy=0.722, val_loss=1.89, val_accuracy=0.526, lr=0.1] 13%|█▎        | 10/75 [04:15<24:41, 22.80s/epoch, loss=1.22, accuracy=0.727, val_loss=1.59, val_accuracy=0.623, lr=0.1] 15%|█▍        | 11/75 [04:38<24:15, 22.74s/epoch, loss=1.22, accuracy=0.728, val_loss=2.08, val_accuracy=0.503, lr=0.1] 16%|█▌        | 12/75 [05:01<23:50, 22.71s/epoch, loss=1.21, accuracy=0.732, val_loss=2.38, val_accuracy=0.414, lr=0.1] 17%|█▋        | 13/75 [05:23<23:22, 22.62s/epoch, loss=1.2, accuracy=0.734, val_loss=1.96, val_accuracy=0.486, lr=0.1]  19%|█▊        | 14/75 [05:45<22:42, 22.33s/epoch, loss=1.2, accuracy=0.736, val_loss=2.17, val_accuracy=0.39, lr=0.1]  20%|██        | 15/75 [06:07<22:19, 22.33s/epoch, loss=1.19, accuracy=0.737, val_loss=1.53, val_accuracy=0.616, lr=0.1] 21%|██▏       | 16/75 [06:29<21:41, 22.06s/epoch, loss=1.19, accuracy=0.741, val_loss=2.12, val_accuracy=0.472, lr=0.1] 23%|██▎       | 17/75 [06:51<21:29, 22.24s/epoch, loss=1.19, accuracy=0.74, val_loss=1.62, val_accuracy=0.607, lr=0.1]  24%|██▍       | 18/75 [07:12<20:38, 21.73s/epoch, loss=1.18, accuracy=0.746, val_loss=1.53, val_accuracy=0.613, lr=0.1] 25%|██▌       | 19/75 [07:34<20:30, 21.97s/epoch, loss=1.19, accuracy=0.744, val_loss=2.13, val_accuracy=0.49, lr=0.1]  27%|██▋       | 20/75 [07:57<20:21, 22.21s/epoch, loss=1.18, accuracy=0.742, val_loss=2.87, val_accuracy=0.254, lr=0.1] 28%|██▊       | 21/75 [08:19<20:00, 22.22s/epoch, loss=1.18, accuracy=0.747, val_loss=2.17, val_accuracy=0.476, lr=0.1] 29%|██▉       | 22/75 [08:42<19:45, 22.37s/epoch, loss=1.18, accuracy=0.748, val_loss=2.83, val_accuracy=0.376, lr=0.1] 31%|███       | 23/75 [09:05<19:28, 22.48s/epoch, loss=1.17, accuracy=0.748, val_loss=2.73, val_accuracy=0.334, lr=0.0316] 32%|███▏      | 24/75 [09:27<19:10, 22.56s/epoch, loss=1.17, accuracy=0.746, val_loss=2.39, val_accuracy=0.421, lr=0.1]    33%|███▎      | 25/75 [09:50<18:52, 22.65s/epoch, loss=1.18, accuracy=0.748, val_loss=1.88, val_accuracy=0.547, lr=0.1] 35%|███▍      | 26/75 [10:13<18:30, 22.67s/epoch, loss=1.17, accuracy=0.751, val_loss=2.22, val_accuracy=0.49, lr=0.1]  36%|███▌      | 27/75 [10:34<17:43, 22.15s/epoch, loss=1.16, accuracy=0.75, val_loss=2.11, val_accuracy=0.515, lr=0.1] 37%|███▋      | 28/75 [10:56<17:26, 22.26s/epoch, loss=1.17, accuracy=0.749, val_loss=1.68, val_accuracy=0.569, lr=0.0316] 39%|███▊      | 29/75 [11:19<17:06, 22.32s/epoch, loss=1.16, accuracy=0.749, val_loss=2.55, val_accuracy=0.453, lr=0.1]    40%|████      | 30/75 [11:40<16:30, 22.01s/epoch, loss=1.16, accuracy=0.753, val_loss=2.87, val_accuracy=0.288, lr=0.1] 41%|████▏     | 31/75 [12:03<16:13, 22.12s/epoch, loss=1.17, accuracy=0.749, val_loss=1.83, val_accuracy=0.509, lr=0.1] 43%|████▎     | 32/75 [12:24<15:35, 21.76s/epoch, loss=1.15, accuracy=0.752, val_loss=3.07, val_accuracy=0.333, lr=0.1] 44%|████▍     | 33/75 [12:46<15:21, 21.95s/epoch, loss=1.16, accuracy=0.752, val_loss=1.56, val_accuracy=0.614, lr=0.0316] 45%|████▌     | 34/75 [13:09<15:07, 22.14s/epoch, loss=1.15, accuracy=0.751, val_loss=2.18, val_accuracy=0.437, lr=0.1]    47%|████▋     | 35/75 [13:31<14:50, 22.27s/epoch, loss=1.15, accuracy=0.752, val_loss=1.63, val_accuracy=0.622, lr=0.1] 48%|████▊     | 36/75 [13:53<14:28, 22.28s/epoch, loss=1.15, accuracy=0.752, val_loss=2.25, val_accuracy=0.492, lr=0.1] 49%|████▉     | 37/75 [14:16<14:09, 22.37s/epoch, loss=1.15, accuracy=0.751, val_loss=4.03, val_accuracy=0.201, lr=0.1] 51%|█████     | 38/75 [14:38<13:43, 22.26s/epoch, loss=1.15, accuracy=0.751, val_loss=1.99, val_accuracy=0.484, lr=0.0316] 52%|█████▏    | 39/75 [15:01<13:26, 22.39s/epoch, loss=1.16, accuracy=0.751, val_loss=2.54, val_accuracy=0.351, lr=0.1]    53%|█████▎    | 40/75 [15:23<13:05, 22.44s/epoch, loss=1.14, accuracy=0.754, val_loss=1.78, val_accuracy=0.566, lr=0.1] 55%|█████▍    | 41/75 [15:44<12:26, 21.97s/epoch, loss=1.15, accuracy=0.752, val_loss=2, val_accuracy=0.497, lr=0.1]    56%|█████▌    | 42/75 [16:06<12:02, 21.91s/epoch, loss=1.15, accuracy=0.753, val_loss=1.66, val_accuracy=0.556, lr=0.1] 57%|█████▋    | 43/75 [16:28<11:46, 22.06s/epoch, loss=1.14, accuracy=0.754, val_loss=1.61, val_accuracy=0.589, lr=0.0316] 59%|█████▊    | 44/75 [16:51<11:25, 22.12s/epoch, loss=1.14, accuracy=0.753, val_loss=2.75, val_accuracy=0.394, lr=0.1]    60%|██████    | 45/75 [17:13<11:07, 22.26s/epoch, loss=1.14, accuracy=0.753, val_loss=2.36, val_accuracy=0.378, lr=0.1] 61%|██████▏   | 46/75 [17:36<10:49, 22.41s/epoch, loss=1.13, accuracy=0.756, val_loss=1.86, val_accuracy=0.508, lr=0.1] 63%|██████▎   | 47/75 [17:58<10:28, 22.45s/epoch, loss=1.14, accuracy=0.753, val_loss=3.16, val_accuracy=0.362, lr=0.1] 64%|██████▍   | 48/75 [18:19<09:53, 22.00s/epoch, loss=1.14, accuracy=0.754, val_loss=1.59, val_accuracy=0.609, lr=0.0316] 65%|██████▌   | 49/75 [18:41<09:31, 21.97s/epoch, loss=1.13, accuracy=0.755, val_loss=3.02, val_accuracy=0.387, lr=0.1]    67%|██████▋   | 50/75 [19:04<09:15, 22.22s/epoch, loss=1.14, accuracy=0.755, val_loss=1.44, val_accuracy=0.644, lr=0.1] 68%|██████▊   | 51/75 [19:27<08:55, 22.30s/epoch, loss=1.14, accuracy=0.755, val_loss=2.95, val_accuracy=0.193, lr=0.1] 69%|██████▉   | 52/75 [19:49<08:32, 22.29s/epoch, loss=1.13, accuracy=0.755, val_loss=1.88, val_accuracy=0.544, lr=0.1] 71%|███████   | 53/75 [20:11<08:11, 22.32s/epoch, loss=1.13, accuracy=0.754, val_loss=1.84, val_accuracy=0.557, lr=0.1] 72%|███████▏  | 54/75 [20:34<07:52, 22.49s/epoch, loss=1.14, accuracy=0.755, val_loss=2.99, val_accuracy=0.367, lr=0.1] 73%|███████▎  | 55/75 [20:57<07:30, 22.54s/epoch, loss=1.13, accuracy=0.757, val_loss=1.42, val_accuracy=0.666, lr=0.1] 75%|███████▍  | 56/75 [21:20<07:09, 22.60s/epoch, loss=1.14, accuracy=0.755, val_loss=1.94, val_accuracy=0.466, lr=0.1] 76%|███████▌  | 57/75 [21:42<06:46, 22.56s/epoch, loss=1.13, accuracy=0.755, val_loss=2.5, val_accuracy=0.474, lr=0.1]  77%|███████▋  | 58/75 [22:05<06:23, 22.58s/epoch, loss=1.13, accuracy=0.756, val_loss=2.06, val_accuracy=0.503, lr=0.1] 79%|███████▊  | 59/75 [22:26<05:55, 22.25s/epoch, loss=1.12, accuracy=0.759, val_loss=1.67, val_accuracy=0.578, lr=0.1] 80%|████████  | 60/75 [22:49<05:36, 22.40s/epoch, loss=1.14, accuracy=0.756, val_loss=1.74, val_accuracy=0.55, lr=0.0316] 81%|████████▏ | 61/75 [23:12<05:14, 22.48s/epoch, loss=1.13, accuracy=0.758, val_loss=1.97, val_accuracy=0.527, lr=0.1]   83%|████████▎ | 62/75 [23:34<04:51, 22.41s/epoch, loss=1.13, accuracy=0.757, val_loss=1.48, val_accuracy=0.646, lr=0.1] 84%|████████▍ | 63/75 [23:56<04:30, 22.50s/epoch, loss=1.12, accuracy=0.758, val_loss=2.36, val_accuracy=0.426, lr=0.1] 85%|████████▌ | 64/75 [24:19<04:08, 22.59s/epoch, loss=1.14, accuracy=0.755, val_loss=1.62, val_accuracy=0.58, lr=0.1]  87%|████████▋ | 65/75 [24:42<03:46, 22.63s/epoch, loss=1.13, accuracy=0.754, val_loss=2.15, val_accuracy=0.431, lr=0.0316] 88%|████████▊ | 66/75 [25:05<03:23, 22.64s/epoch, loss=1.13, accuracy=0.756, val_loss=1.99, val_accuracy=0.481, lr=0.1]    89%|████████▉ | 67/75 [25:27<03:01, 22.63s/epoch, loss=1.13, accuracy=0.755, val_loss=2.29, val_accuracy=0.385, lr=0.1] 91%|█████████ | 68/75 [25:50<02:37, 22.54s/epoch, loss=1.12, accuracy=0.758, val_loss=4.76, val_accuracy=0.235, lr=0.1] 92%|█████████▏| 69/75 [26:12<02:14, 22.39s/epoch, loss=1.12, accuracy=0.756, val_loss=1.62, val_accuracy=0.59, lr=0.1]  93%|█████████▎| 70/75 [26:34<01:52, 22.43s/epoch, loss=1.13, accuracy=0.755, val_loss=1.55, val_accuracy=0.609, lr=0.0316] 95%|█████████▍| 71/75 [26:57<01:30, 22.51s/epoch, loss=1.13, accuracy=0.754, val_loss=2.11, val_accuracy=0.462, lr=0.1]    96%|█████████▌| 72/75 [27:19<01:07, 22.46s/epoch, loss=1.12, accuracy=0.759, val_loss=1.99, val_accuracy=0.554, lr=0.1] 97%|█████████▋| 73/75 [27:41<00:44, 22.37s/epoch, loss=1.12, accuracy=0.757, val_loss=1.62, val_accuracy=0.601, lr=0.1] 99%|█████████▊| 74/75 [28:04<00:22, 22.46s/epoch, loss=1.12, accuracy=0.758, val_loss=2.81, val_accuracy=0.412, lr=0.1]100%|██████████| 75/75 [28:27<00:00, 22.56s/epoch, loss=1.12, accuracy=0.758, val_loss=1.89, val_accuracy=0.592, lr=0.0316]100%|██████████| 75/75 [28:27<00:00, 22.76s/epoch, loss=1.12, accuracy=0.758, val_loss=1.89, val_accuracy=0.592, lr=0.0316]
Using real-time data augmentation.
Test loss: 1.88608980178833
Test accuracy: 0.592199981212616


* * * Run SGD for ID = 20_13. * * *


2024-02-16 01:56:35.750174: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-16 01:56:39.430018: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-16 01:56:39.431119: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-16 01:56:39.467457: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-16 01:56:39.467491: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-16 01:56:39.470274: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-16 01:56:39.470335: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-16 01:56:39.472570: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-16 01:56:39.473741: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-16 01:56:39.477220: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-16 01:56:39.478696: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-16 01:56:39.483488: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-16 01:56:39.483994: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-16 01:56:39.484069: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-16 01:56:40.682230: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-16 01:56:40.683330: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-16 01:56:40.684003: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-16 01:56:40.684034: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-16 01:56:40.684082: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-16 01:56:40.684103: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-16 01:56:40.684121: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-16 01:56:40.684140: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-16 01:56:40.684175: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-16 01:56:40.684194: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-16 01:56:40.684212: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-16 01:56:40.684684: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-16 01:56:40.684722: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-16 01:56:41.284686: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-16 01:56:41.284747: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-16 01:56:41.284757: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-16 01:56:41.285642: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': 2013, 'batch_size': 128, 'epochs': 75, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/75 [00:00<?, ?epoch/s]2024-02-16 01:56:42.047105: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-16 01:56:42.059406: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2599900000 Hz
2024-02-16 01:56:43.894572: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-16 01:56:44.072591: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-16 01:56:44.851306: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-16 01:56:44.907236: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|▏         | 1/75 [00:58<1:12:06, 58.47s/epoch, loss=3.15, accuracy=0.28, val_loss=3.73, val_accuracy=0.123, lr=0.1]  3%|▎         | 2/75 [01:20<45:12, 37.16s/epoch, loss=1.54, accuracy=0.546, val_loss=2.67, val_accuracy=0.324, lr=0.1]   4%|▍         | 3/75 [01:43<36:27, 30.38s/epoch, loss=1.34, accuracy=0.643, val_loss=2.58, val_accuracy=0.388, lr=0.1]  5%|▌         | 4/75 [02:05<32:05, 27.12s/epoch, loss=1.29, accuracy=0.68, val_loss=4.72, val_accuracy=0.219, lr=0.1]   7%|▋         | 5/75 [02:27<29:44, 25.50s/epoch, loss=1.26, accuracy=0.695, val_loss=1.97, val_accuracy=0.489, lr=0.1]  8%|▊         | 6/75 [02:49<27:44, 24.12s/epoch, loss=1.24, accuracy=0.707, val_loss=1.73, val_accuracy=0.543, lr=0.1]  9%|▉         | 7/75 [03:11<26:40, 23.54s/epoch, loss=1.23, accuracy=0.711, val_loss=5.62, val_accuracy=0.244, lr=0.1] 11%|█         | 8/75 [03:34<26:00, 23.29s/epoch, loss=1.22, accuracy=0.717, val_loss=2.24, val_accuracy=0.434, lr=0.1] 12%|█▏        | 9/75 [03:55<24:53, 22.62s/epoch, loss=1.21, accuracy=0.721, val_loss=2.52, val_accuracy=0.479, lr=0.1] 13%|█▎        | 10/75 [04:18<24:29, 22.60s/epoch, loss=1.2, accuracy=0.729, val_loss=2.05, val_accuracy=0.504, lr=0.1] 15%|█▍        | 11/75 [04:40<24:04, 22.57s/epoch, loss=1.2, accuracy=0.727, val_loss=1.87, val_accuracy=0.524, lr=0.0316] 16%|█▌        | 12/75 [05:02<23:22, 22.27s/epoch, loss=1.19, accuracy=0.731, val_loss=1.93, val_accuracy=0.471, lr=0.1]   17%|█▋        | 13/75 [05:24<23:01, 22.28s/epoch, loss=1.19, accuracy=0.735, val_loss=2.36, val_accuracy=0.429, lr=0.1] 19%|█▊        | 14/75 [05:46<22:41, 22.32s/epoch, loss=1.18, accuracy=0.734, val_loss=2.17, val_accuracy=0.486, lr=0.1] 20%|██        | 15/75 [06:07<21:55, 21.93s/epoch, loss=1.18, accuracy=0.738, val_loss=1.86, val_accuracy=0.551, lr=0.1] 21%|██▏       | 16/75 [06:28<21:12, 21.56s/epoch, loss=1.18, accuracy=0.738, val_loss=1.52, val_accuracy=0.623, lr=0.1] 23%|██▎       | 17/75 [06:50<20:50, 21.56s/epoch, loss=1.18, accuracy=0.74, val_loss=2.49, val_accuracy=0.452, lr=0.1]  24%|██▍       | 18/75 [07:12<20:47, 21.89s/epoch, loss=1.17, accuracy=0.741, val_loss=1.73, val_accuracy=0.542, lr=0.1] 25%|██▌       | 19/75 [07:35<20:39, 22.13s/epoch, loss=1.17, accuracy=0.743, val_loss=4.41, val_accuracy=0.224, lr=0.1] 27%|██▋       | 20/75 [07:57<20:23, 22.24s/epoch, loss=1.17, accuracy=0.743, val_loss=3.16, val_accuracy=0.364, lr=0.1] 28%|██▊       | 21/75 [08:20<19:59, 22.20s/epoch, loss=1.17, accuracy=0.742, val_loss=2.55, val_accuracy=0.38, lr=0.0316] 29%|██▉       | 22/75 [08:42<19:45, 22.38s/epoch, loss=1.16, accuracy=0.747, val_loss=1.91, val_accuracy=0.516, lr=0.1]   31%|███       | 23/75 [09:05<19:20, 22.33s/epoch, loss=1.16, accuracy=0.747, val_loss=2.66, val_accuracy=0.432, lr=0.1] 32%|███▏      | 24/75 [09:27<19:03, 22.42s/epoch, loss=1.17, accuracy=0.746, val_loss=1.77, val_accuracy=0.593, lr=0.1] 33%|███▎      | 25/75 [09:50<18:45, 22.52s/epoch, loss=1.16, accuracy=0.748, val_loss=2.14, val_accuracy=0.454, lr=0.1] 35%|███▍      | 26/75 [10:12<18:22, 22.51s/epoch, loss=1.15, accuracy=0.747, val_loss=1.68, val_accuracy=0.577, lr=0.0316] 36%|███▌      | 27/75 [10:35<18:02, 22.56s/epoch, loss=1.16, accuracy=0.75, val_loss=1.6, val_accuracy=0.601, lr=0.1]      37%|███▋      | 28/75 [10:58<17:42, 22.60s/epoch, loss=1.15, accuracy=0.75, val_loss=1.9, val_accuracy=0.486, lr=0.1] 39%|███▊      | 29/75 [11:20<17:07, 22.35s/epoch, loss=1.15, accuracy=0.751, val_loss=1.57, val_accuracy=0.623, lr=0.1] 40%|████      | 30/75 [11:42<16:43, 22.29s/epoch, loss=1.15, accuracy=0.749, val_loss=1.8, val_accuracy=0.54, lr=0.1]   41%|████▏     | 31/75 [12:04<16:21, 22.30s/epoch, loss=1.15, accuracy=0.751, val_loss=1.57, val_accuracy=0.599, lr=0.0316] 43%|████▎     | 32/75 [12:27<16:02, 22.39s/epoch, loss=1.15, accuracy=0.751, val_loss=1.66, val_accuracy=0.567, lr=0.1]    44%|████▍     | 33/75 [12:49<15:40, 22.38s/epoch, loss=1.14, accuracy=0.751, val_loss=1.79, val_accuracy=0.589, lr=0.1] 45%|████▌     | 34/75 [13:12<15:19, 22.44s/epoch, loss=1.14, accuracy=0.753, val_loss=2.35, val_accuracy=0.49, lr=0.1]  47%|████▋     | 35/75 [13:33<14:50, 22.27s/epoch, loss=1.14, accuracy=0.752, val_loss=1.71, val_accuracy=0.606, lr=0.1] 48%|████▊     | 36/75 [13:56<14:32, 22.36s/epoch, loss=1.14, accuracy=0.752, val_loss=1.97, val_accuracy=0.558, lr=0.0316] 49%|████▉     | 37/75 [14:17<13:58, 22.06s/epoch, loss=1.13, accuracy=0.753, val_loss=3.51, val_accuracy=0.278, lr=0.1]    51%|█████     | 38/75 [14:40<13:42, 22.22s/epoch, loss=1.14, accuracy=0.755, val_loss=2.66, val_accuracy=0.322, lr=0.1] 52%|█████▏    | 39/75 [15:02<13:22, 22.29s/epoch, loss=1.14, accuracy=0.751, val_loss=2.34, val_accuracy=0.466, lr=0.1] 53%|█████▎    | 40/75 [15:25<13:04, 22.41s/epoch, loss=1.14, accuracy=0.755, val_loss=2.31, val_accuracy=0.536, lr=0.1] 55%|█████▍    | 41/75 [15:47<12:36, 22.25s/epoch, loss=1.14, accuracy=0.753, val_loss=2.12, val_accuracy=0.528, lr=0.0316] 56%|█████▌    | 42/75 [16:09<12:15, 22.29s/epoch, loss=1.13, accuracy=0.755, val_loss=2.14, val_accuracy=0.478, lr=0.1]    57%|█████▋    | 43/75 [16:30<11:38, 21.82s/epoch, loss=1.13, accuracy=0.754, val_loss=2.22, val_accuracy=0.461, lr=0.1] 59%|█████▊    | 44/75 [16:53<11:22, 22.00s/epoch, loss=1.13, accuracy=0.756, val_loss=1.93, val_accuracy=0.525, lr=0.1] 60%|██████    | 45/75 [17:15<11:03, 22.12s/epoch, loss=1.12, accuracy=0.756, val_loss=1.71, val_accuracy=0.584, lr=0.1] 61%|██████▏   | 46/75 [17:37<10:45, 22.24s/epoch, loss=1.12, accuracy=0.756, val_loss=3.53, val_accuracy=0.386, lr=0.0316] 63%|██████▎   | 47/75 [18:00<10:25, 22.32s/epoch, loss=1.13, accuracy=0.758, val_loss=1.75, val_accuracy=0.551, lr=0.1]    64%|██████▍   | 48/75 [18:23<10:04, 22.40s/epoch, loss=1.13, accuracy=0.755, val_loss=1.85, val_accuracy=0.542, lr=0.1] 65%|██████▌   | 49/75 [18:45<09:43, 22.44s/epoch, loss=1.12, accuracy=0.756, val_loss=2.05, val_accuracy=0.47, lr=0.1]  67%|██████▋   | 50/75 [19:08<09:21, 22.44s/epoch, loss=1.12, accuracy=0.758, val_loss=2.07, val_accuracy=0.501, lr=0.1] 68%|██████▊   | 51/75 [19:30<09:00, 22.52s/epoch, loss=1.12, accuracy=0.757, val_loss=1.95, val_accuracy=0.58, lr=0.0316] 69%|██████▉   | 52/75 [19:53<08:39, 22.57s/epoch, loss=1.13, accuracy=0.755, val_loss=1.79, val_accuracy=0.554, lr=0.1]   71%|███████   | 53/75 [20:15<08:15, 22.52s/epoch, loss=1.12, accuracy=0.759, val_loss=2.58, val_accuracy=0.438, lr=0.1] 72%|███████▏  | 54/75 [20:38<07:53, 22.56s/epoch, loss=1.13, accuracy=0.755, val_loss=3.53, val_accuracy=0.329, lr=0.1] 73%|███████▎  | 55/75 [21:01<07:31, 22.55s/epoch, loss=1.13, accuracy=0.756, val_loss=2.05, val_accuracy=0.5, lr=0.1]   75%|███████▍  | 56/75 [21:23<07:06, 22.46s/epoch, loss=1.13, accuracy=0.757, val_loss=2.91, val_accuracy=0.426, lr=0.0316] 76%|███████▌  | 57/75 [21:45<06:41, 22.29s/epoch, loss=1.12, accuracy=0.755, val_loss=3.17, val_accuracy=0.379, lr=0.1]    77%|███████▋  | 58/75 [22:07<06:19, 22.31s/epoch, loss=1.12, accuracy=0.759, val_loss=1.75, val_accuracy=0.535, lr=0.1] 79%|███████▊  | 59/75 [22:29<05:56, 22.27s/epoch, loss=1.13, accuracy=0.755, val_loss=2.49, val_accuracy=0.312, lr=0.1] 80%|████████  | 60/75 [22:50<05:26, 21.78s/epoch, loss=1.12, accuracy=0.757, val_loss=1.91, val_accuracy=0.542, lr=0.1] 81%|████████▏ | 61/75 [23:12<05:07, 21.93s/epoch, loss=1.12, accuracy=0.759, val_loss=1.66, val_accuracy=0.563, lr=0.0316] 83%|████████▎ | 62/75 [23:34<04:43, 21.81s/epoch, loss=1.13, accuracy=0.751, val_loss=1.74, val_accuracy=0.563, lr=0.1]    84%|████████▍ | 63/75 [23:56<04:22, 21.87s/epoch, loss=1.12, accuracy=0.757, val_loss=1.83, val_accuracy=0.568, lr=0.1] 85%|████████▌ | 64/75 [24:18<04:00, 21.91s/epoch, loss=1.12, accuracy=0.758, val_loss=1.8, val_accuracy=0.577, lr=0.1]  87%|████████▋ | 65/75 [24:40<03:40, 22.00s/epoch, loss=1.12, accuracy=0.758, val_loss=1.9, val_accuracy=0.459, lr=0.1] 88%|████████▊ | 66/75 [25:03<03:19, 22.19s/epoch, loss=1.11, accuracy=0.758, val_loss=1.58, val_accuracy=0.597, lr=0.0316] 89%|████████▉ | 67/75 [25:25<02:57, 22.17s/epoch, loss=1.12, accuracy=0.758, val_loss=2.25, val_accuracy=0.439, lr=0.1]    91%|█████████ | 68/75 [25:47<02:35, 22.19s/epoch, loss=1.12, accuracy=0.757, val_loss=2.32, val_accuracy=0.493, lr=0.1] 92%|█████████▏| 69/75 [26:09<02:13, 22.20s/epoch, loss=1.12, accuracy=0.756, val_loss=1.9, val_accuracy=0.543, lr=0.1]  93%|█████████▎| 70/75 [26:32<01:51, 22.29s/epoch, loss=1.11, accuracy=0.759, val_loss=2.78, val_accuracy=0.417, lr=0.1] 95%|█████████▍| 71/75 [26:54<01:29, 22.36s/epoch, loss=1.11, accuracy=0.757, val_loss=1.65, val_accuracy=0.586, lr=0.0316] 96%|█████████▌| 72/75 [27:16<01:06, 22.32s/epoch, loss=1.12, accuracy=0.756, val_loss=2.01, val_accuracy=0.55, lr=0.1]     97%|█████████▋| 73/75 [27:38<00:44, 22.17s/epoch, loss=1.11, accuracy=0.756, val_loss=1.52, val_accuracy=0.62, lr=0.1] 99%|█████████▊| 74/75 [28:01<00:22, 22.24s/epoch, loss=1.11, accuracy=0.758, val_loss=2.31, val_accuracy=0.468, lr=0.1]100%|██████████| 75/75 [28:23<00:00, 22.16s/epoch, loss=1.11, accuracy=0.759, val_loss=1.77, val_accuracy=0.532, lr=0.1]100%|██████████| 75/75 [28:23<00:00, 22.71s/epoch, loss=1.11, accuracy=0.759, val_loss=1.77, val_accuracy=0.532, lr=0.1]
Using real-time data augmentation.
Test loss: 1.7702988386154175
Test accuracy: 0.5321000218391418


* * * Run SGD for ID = 20_14. * * *


2024-02-16 02:25:07.381759: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-16 02:25:09.964186: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-16 02:25:09.965384: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-16 02:25:10.002658: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-16 02:25:10.002690: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-16 02:25:10.005504: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-16 02:25:10.005544: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-16 02:25:10.007750: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-16 02:25:10.008407: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-16 02:25:10.010714: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-16 02:25:10.012142: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-16 02:25:10.016690: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-16 02:25:10.017183: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-16 02:25:10.017259: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-16 02:25:11.196856: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-16 02:25:11.197442: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-16 02:25:11.198149: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-16 02:25:11.198179: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-16 02:25:11.198227: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-16 02:25:11.198247: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-16 02:25:11.198265: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-16 02:25:11.198295: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-16 02:25:11.198317: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-16 02:25:11.198335: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-16 02:25:11.198353: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-16 02:25:11.198748: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-16 02:25:11.198779: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-16 02:25:11.821428: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-16 02:25:11.821491: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-16 02:25:11.821500: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-16 02:25:11.822375: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': 2014, 'batch_size': 128, 'epochs': 75, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/75 [00:00<?, ?epoch/s]2024-02-16 02:25:12.587406: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-16 02:25:12.599397: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2599900000 Hz
2024-02-16 02:25:14.392276: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-16 02:25:14.578453: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-16 02:25:15.380248: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-16 02:25:15.431360: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|▏         | 1/75 [00:53<1:05:30, 53.11s/epoch, loss=3.28, accuracy=0.323, val_loss=2.53, val_accuracy=0.233, lr=0.1]  3%|▎         | 2/75 [01:14<41:34, 34.18s/epoch, loss=1.61, accuracy=0.509, val_loss=3.1, val_accuracy=0.364, lr=0.1]     4%|▍         | 3/75 [01:35<33:52, 28.22s/epoch, loss=1.37, accuracy=0.633, val_loss=1.98, val_accuracy=0.508, lr=0.1]  5%|▌         | 4/75 [01:56<30:21, 25.65s/epoch, loss=1.3, accuracy=0.678, val_loss=1.94, val_accuracy=0.52, lr=0.1]    7%|▋         | 5/75 [02:19<28:45, 24.65s/epoch, loss=1.26, accuracy=0.701, val_loss=1.67, val_accuracy=0.549, lr=0.1]  8%|▊         | 6/75 [02:42<27:31, 23.93s/epoch, loss=1.24, accuracy=0.711, val_loss=1.42, val_accuracy=0.652, lr=0.1]  9%|▉         | 7/75 [03:05<26:44, 23.59s/epoch, loss=1.23, accuracy=0.716, val_loss=1.67, val_accuracy=0.573, lr=0.1] 11%|█         | 8/75 [03:28<26:05, 23.36s/epoch, loss=1.22, accuracy=0.724, val_loss=1.99, val_accuracy=0.507, lr=0.1] 12%|█▏        | 9/75 [03:50<25:25, 23.11s/epoch, loss=1.21, accuracy=0.727, val_loss=1.64, val_accuracy=0.604, lr=0.1] 13%|█▎        | 10/75 [04:13<24:56, 23.02s/epoch, loss=1.21, accuracy=0.73, val_loss=1.68, val_accuracy=0.568, lr=0.1] 15%|█▍        | 11/75 [04:36<24:27, 22.92s/epoch, loss=1.21, accuracy=0.731, val_loss=2.99, val_accuracy=0.392, lr=0.0316] 16%|█▌        | 12/75 [04:59<24:06, 22.96s/epoch, loss=1.2, accuracy=0.733, val_loss=2.05, val_accuracy=0.466, lr=0.1]     17%|█▋        | 13/75 [05:21<23:32, 22.78s/epoch, loss=1.21, accuracy=0.734, val_loss=1.76, val_accuracy=0.52, lr=0.1] 19%|█▊        | 14/75 [05:44<23:09, 22.78s/epoch, loss=1.2, accuracy=0.735, val_loss=5.02, val_accuracy=0.224, lr=0.1] 20%|██        | 15/75 [06:07<22:50, 22.85s/epoch, loss=1.2, accuracy=0.735, val_loss=1.48, val_accuracy=0.645, lr=0.1] 21%|██▏       | 16/75 [06:30<22:30, 22.89s/epoch, loss=1.19, accuracy=0.739, val_loss=1.54, val_accuracy=0.625, lr=0.0316] 23%|██▎       | 17/75 [06:52<22:01, 22.79s/epoch, loss=1.19, accuracy=0.739, val_loss=1.75, val_accuracy=0.527, lr=0.1]    24%|██▍       | 18/75 [07:15<21:40, 22.81s/epoch, loss=1.18, accuracy=0.745, val_loss=1.58, val_accuracy=0.599, lr=0.1] 25%|██▌       | 19/75 [07:37<20:53, 22.39s/epoch, loss=1.19, accuracy=0.742, val_loss=1.48, val_accuracy=0.646, lr=0.1] 27%|██▋       | 20/75 [07:59<20:28, 22.34s/epoch, loss=1.19, accuracy=0.741, val_loss=3.57, val_accuracy=0.297, lr=0.1] 28%|██▊       | 21/75 [08:22<20:11, 22.43s/epoch, loss=1.18, accuracy=0.746, val_loss=3.38, val_accuracy=0.382, lr=0.0316] 29%|██▉       | 22/75 [08:44<19:53, 22.51s/epoch, loss=1.17, accuracy=0.746, val_loss=2.12, val_accuracy=0.5, lr=0.1]      31%|███       | 23/75 [09:07<19:31, 22.53s/epoch, loss=1.17, accuracy=0.746, val_loss=2.33, val_accuracy=0.461, lr=0.1] 32%|███▏      | 24/75 [09:29<19:08, 22.52s/epoch, loss=1.17, accuracy=0.745, val_loss=1.98, val_accuracy=0.501, lr=0.1] 33%|███▎      | 25/75 [09:52<18:51, 22.62s/epoch, loss=1.17, accuracy=0.744, val_loss=2.74, val_accuracy=0.373, lr=0.1] 35%|███▍      | 26/75 [10:15<18:31, 22.69s/epoch, loss=1.17, accuracy=0.746, val_loss=1.82, val_accuracy=0.539, lr=0.0316] 36%|███▌      | 27/75 [10:38<18:12, 22.75s/epoch, loss=1.17, accuracy=0.747, val_loss=3.68, val_accuracy=0.312, lr=0.1]    37%|███▋      | 28/75 [11:01<17:52, 22.81s/epoch, loss=1.17, accuracy=0.748, val_loss=1.77, val_accuracy=0.59, lr=0.1]  39%|███▊      | 29/75 [11:24<17:29, 22.81s/epoch, loss=1.16, accuracy=0.751, val_loss=1.62, val_accuracy=0.597, lr=0.1] 40%|████      | 30/75 [11:46<17:00, 22.67s/epoch, loss=1.17, accuracy=0.747, val_loss=2.25, val_accuracy=0.416, lr=0.1] 41%|████▏     | 31/75 [12:09<16:40, 22.74s/epoch, loss=1.16, accuracy=0.751, val_loss=1.73, val_accuracy=0.555, lr=0.0316] 43%|████▎     | 32/75 [12:31<16:13, 22.65s/epoch, loss=1.17, accuracy=0.749, val_loss=1.78, val_accuracy=0.527, lr=0.1]    44%|████▍     | 33/75 [12:54<15:54, 22.73s/epoch, loss=1.16, accuracy=0.752, val_loss=1.72, val_accuracy=0.544, lr=0.1] 45%|████▌     | 34/75 [13:17<15:37, 22.86s/epoch, loss=1.16, accuracy=0.75, val_loss=2.12, val_accuracy=0.49, lr=0.1]   47%|████▋     | 35/75 [13:39<14:57, 22.44s/epoch, loss=1.16, accuracy=0.75, val_loss=1.52, val_accuracy=0.613, lr=0.1] 48%|████▊     | 36/75 [14:02<14:38, 22.53s/epoch, loss=1.16, accuracy=0.751, val_loss=1.97, val_accuracy=0.508, lr=0.0316] 49%|████▉     | 37/75 [14:24<14:16, 22.53s/epoch, loss=1.15, accuracy=0.75, val_loss=2.36, val_accuracy=0.431, lr=0.1]     51%|█████     | 38/75 [14:46<13:41, 22.21s/epoch, loss=1.15, accuracy=0.754, val_loss=1.74, val_accuracy=0.563, lr=0.1] 52%|█████▏    | 39/75 [15:08<13:17, 22.15s/epoch, loss=1.15, accuracy=0.751, val_loss=1.41, val_accuracy=0.659, lr=0.1] 53%|█████▎    | 40/75 [15:30<13:02, 22.36s/epoch, loss=1.15, accuracy=0.754, val_loss=1.75, val_accuracy=0.547, lr=0.1] 55%|█████▍    | 41/75 [15:53<12:42, 22.42s/epoch, loss=1.16, accuracy=0.749, val_loss=3.23, val_accuracy=0.373, lr=0.1] 56%|█████▌    | 42/75 [16:16<12:22, 22.51s/epoch, loss=1.15, accuracy=0.752, val_loss=2.39, val_accuracy=0.436, lr=0.1] 57%|█████▋    | 43/75 [16:38<12:00, 22.51s/epoch, loss=1.15, accuracy=0.752, val_loss=2.11, val_accuracy=0.504, lr=0.1] 59%|█████▊    | 44/75 [17:01<11:40, 22.60s/epoch, loss=1.14, accuracy=0.754, val_loss=2.94, val_accuracy=0.323, lr=0.0316] 60%|██████    | 45/75 [17:24<11:17, 22.58s/epoch, loss=1.15, accuracy=0.754, val_loss=1.74, val_accuracy=0.592, lr=0.1]    61%|██████▏   | 46/75 [17:46<10:56, 22.64s/epoch, loss=1.15, accuracy=0.754, val_loss=1.52, val_accuracy=0.635, lr=0.1] 63%|██████▎   | 47/75 [18:09<10:33, 22.62s/epoch, loss=1.15, accuracy=0.752, val_loss=1.77, val_accuracy=0.562, lr=0.1] 64%|██████▍   | 48/75 [18:32<10:10, 22.61s/epoch, loss=1.15, accuracy=0.753, val_loss=3.96, val_accuracy=0.341, lr=0.1] 65%|██████▌   | 49/75 [18:54<09:47, 22.58s/epoch, loss=1.15, accuracy=0.754, val_loss=2.49, val_accuracy=0.451, lr=0.0316] 67%|██████▋   | 50/75 [19:17<09:24, 22.57s/epoch, loss=1.15, accuracy=0.754, val_loss=2.14, val_accuracy=0.448, lr=0.1]    68%|██████▊   | 51/75 [19:39<09:01, 22.56s/epoch, loss=1.14, accuracy=0.755, val_loss=2.49, val_accuracy=0.445, lr=0.1] 69%|██████▉   | 52/75 [20:02<08:40, 22.61s/epoch, loss=1.14, accuracy=0.754, val_loss=2.11, val_accuracy=0.442, lr=0.1] 71%|███████   | 53/75 [20:24<08:12, 22.39s/epoch, loss=1.14, accuracy=0.755, val_loss=2.66, val_accuracy=0.373, lr=0.1] 72%|███████▏  | 54/75 [20:46<07:51, 22.45s/epoch, loss=1.14, accuracy=0.753, val_loss=1.86, val_accuracy=0.49, lr=0.0316] 73%|███████▎  | 55/75 [21:09<07:30, 22.53s/epoch, loss=1.13, accuracy=0.757, val_loss=1.6, val_accuracy=0.589, lr=0.1]    75%|███████▍  | 56/75 [21:31<07:03, 22.29s/epoch, loss=1.14, accuracy=0.755, val_loss=2.54, val_accuracy=0.396, lr=0.1] 76%|███████▌  | 57/75 [21:53<06:43, 22.40s/epoch, loss=1.14, accuracy=0.755, val_loss=2.83, val_accuracy=0.264, lr=0.1] 77%|███████▋  | 58/75 [22:16<06:23, 22.54s/epoch, loss=1.14, accuracy=0.755, val_loss=1.54, val_accuracy=0.636, lr=0.1] 79%|███████▊  | 59/75 [22:39<06:01, 22.57s/epoch, loss=1.14, accuracy=0.755, val_loss=3.58, val_accuracy=0.35, lr=0.0316] 80%|████████  | 60/75 [23:02<05:40, 22.69s/epoch, loss=1.14, accuracy=0.756, val_loss=2.38, val_accuracy=0.489, lr=0.1]   81%|████████▏ | 61/75 [23:25<05:18, 22.75s/epoch, loss=1.14, accuracy=0.756, val_loss=2.16, val_accuracy=0.46, lr=0.1]  83%|████████▎ | 62/75 [23:48<04:55, 22.74s/epoch, loss=1.14, accuracy=0.751, val_loss=2.02, val_accuracy=0.493, lr=0.1] 84%|████████▍ | 63/75 [24:10<04:32, 22.72s/epoch, loss=1.13, accuracy=0.757, val_loss=1.68, val_accuracy=0.615, lr=0.1] 85%|████████▌ | 64/75 [24:33<04:10, 22.76s/epoch, loss=1.13, accuracy=0.757, val_loss=1.89, val_accuracy=0.527, lr=0.0316] 87%|████████▋ | 65/75 [24:56<03:46, 22.67s/epoch, loss=1.13, accuracy=0.755, val_loss=1.86, val_accuracy=0.486, lr=0.1]    88%|████████▊ | 66/75 [25:18<03:23, 22.64s/epoch, loss=1.14, accuracy=0.752, val_loss=1.88, val_accuracy=0.563, lr=0.1] 89%|████████▉ | 67/75 [25:41<03:01, 22.73s/epoch, loss=1.14, accuracy=0.755, val_loss=1.91, val_accuracy=0.519, lr=0.1] 91%|█████████ | 68/75 [26:04<02:39, 22.77s/epoch, loss=1.13, accuracy=0.755, val_loss=1.51, val_accuracy=0.611, lr=0.1] 92%|█████████▏| 69/75 [26:27<02:16, 22.78s/epoch, loss=1.13, accuracy=0.757, val_loss=1.76, val_accuracy=0.566, lr=0.0316] 93%|█████████▎| 70/75 [26:49<01:53, 22.77s/epoch, loss=1.13, accuracy=0.755, val_loss=2.02, val_accuracy=0.522, lr=0.1]    95%|█████████▍| 71/75 [27:12<01:30, 22.72s/epoch, loss=1.13, accuracy=0.756, val_loss=1.52, val_accuracy=0.619, lr=0.1] 96%|█████████▌| 72/75 [27:34<01:07, 22.62s/epoch, loss=1.13, accuracy=0.755, val_loss=2.42, val_accuracy=0.402, lr=0.1] 97%|█████████▋| 73/75 [27:57<00:45, 22.62s/epoch, loss=1.13, accuracy=0.756, val_loss=1.6, val_accuracy=0.61, lr=0.1]   99%|█████████▊| 74/75 [28:20<00:22, 22.67s/epoch, loss=1.13, accuracy=0.754, val_loss=1.84, val_accuracy=0.539, lr=0.0316]100%|██████████| 75/75 [28:42<00:00, 22.66s/epoch, loss=1.13, accuracy=0.756, val_loss=2.38, val_accuracy=0.424, lr=0.1]   100%|██████████| 75/75 [28:42<00:00, 22.97s/epoch, loss=1.13, accuracy=0.756, val_loss=2.38, val_accuracy=0.424, lr=0.1]
Using real-time data augmentation.
Test loss: 2.381155014038086
Test accuracy: 0.4235999882221222


* * * Run SGD for ID = 20_15. * * *


2024-02-16 02:53:58.350970: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-16 02:54:00.875444: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-16 02:54:00.876651: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-16 02:54:00.912894: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-16 02:54:00.912933: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-16 02:54:00.915810: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-16 02:54:00.915846: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-16 02:54:00.918055: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-16 02:54:00.919136: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-16 02:54:00.921253: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-16 02:54:00.922675: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-16 02:54:00.927132: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-16 02:54:00.927674: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-16 02:54:00.927760: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-16 02:54:02.128263: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-16 02:54:02.128835: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-16 02:54:02.129495: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-16 02:54:02.129526: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-16 02:54:02.129598: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-16 02:54:02.129617: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-16 02:54:02.129635: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-16 02:54:02.129653: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-16 02:54:02.129670: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-16 02:54:02.129688: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-16 02:54:02.129706: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-16 02:54:02.130104: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-16 02:54:02.130134: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-16 02:54:02.745318: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-16 02:54:02.745379: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-16 02:54:02.745389: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-16 02:54:02.746246: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': 2015, 'batch_size': 128, 'epochs': 75, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/75 [00:00<?, ?epoch/s]2024-02-16 02:54:03.511919: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-16 02:54:03.524408: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2599900000 Hz
2024-02-16 02:54:05.322562: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-16 02:54:05.559271: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-16 02:54:06.406801: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-16 02:54:06.450409: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|▏         | 1/75 [00:57<1:10:30, 57.16s/epoch, loss=3.21, accuracy=0.243, val_loss=2.63, val_accuracy=0.194, lr=0.1]  3%|▎         | 2/75 [01:19<44:37, 36.68s/epoch, loss=1.6, accuracy=0.51, val_loss=3.03, val_accuracy=0.23, lr=0.1]       4%|▍         | 3/75 [01:42<36:25, 30.35s/epoch, loss=1.36, accuracy=0.629, val_loss=2.98, val_accuracy=0.35, lr=0.1]  5%|▌         | 4/75 [02:04<32:06, 27.14s/epoch, loss=1.28, accuracy=0.676, val_loss=1.95, val_accuracy=0.459, lr=0.1]  7%|▋         | 5/75 [02:27<29:43, 25.48s/epoch, loss=1.26, accuracy=0.695, val_loss=1.69, val_accuracy=0.555, lr=0.1]  8%|▊         | 6/75 [02:50<28:20, 24.64s/epoch, loss=1.24, accuracy=0.707, val_loss=2.08, val_accuracy=0.511, lr=0.1]  9%|▉         | 7/75 [03:12<27:16, 24.07s/epoch, loss=1.23, accuracy=0.714, val_loss=1.49, val_accuracy=0.644, lr=0.1] 11%|█         | 8/75 [03:35<26:29, 23.73s/epoch, loss=1.22, accuracy=0.719, val_loss=2.39, val_accuracy=0.368, lr=0.1] 12%|█▏        | 9/75 [03:58<25:44, 23.41s/epoch, loss=1.22, accuracy=0.722, val_loss=2, val_accuracy=0.5, lr=0.1]      13%|█▎        | 10/75 [04:20<24:54, 22.98s/epoch, loss=1.21, accuracy=0.724, val_loss=2, val_accuracy=0.451, lr=0.1] 15%|█▍        | 11/75 [04:42<24:09, 22.65s/epoch, loss=1.21, accuracy=0.727, val_loss=2.67, val_accuracy=0.393, lr=0.1] 16%|█▌        | 12/75 [05:05<23:48, 22.67s/epoch, loss=1.2, accuracy=0.73, val_loss=1.7, val_accuracy=0.528, lr=0.0316] 17%|█▋        | 13/75 [05:28<23:27, 22.70s/epoch, loss=1.2, accuracy=0.731, val_loss=2.08, val_accuracy=0.5, lr=0.1]    19%|█▊        | 14/75 [05:50<23:03, 22.69s/epoch, loss=1.18, accuracy=0.735, val_loss=1.62, val_accuracy=0.564, lr=0.1] 20%|██        | 15/75 [06:13<22:38, 22.64s/epoch, loss=1.18, accuracy=0.736, val_loss=1.94, val_accuracy=0.499, lr=0.1] 21%|██▏       | 16/75 [06:36<22:21, 22.74s/epoch, loss=1.18, accuracy=0.738, val_loss=3.02, val_accuracy=0.392, lr=0.1] 23%|██▎       | 17/75 [06:58<21:55, 22.68s/epoch, loss=1.18, accuracy=0.736, val_loss=3.86, val_accuracy=0.356, lr=0.0316] 24%|██▍       | 18/75 [07:21<21:26, 22.57s/epoch, loss=1.17, accuracy=0.738, val_loss=1.58, val_accuracy=0.596, lr=0.1]    25%|██▌       | 19/75 [07:43<21:07, 22.64s/epoch, loss=1.17, accuracy=0.74, val_loss=1.71, val_accuracy=0.57, lr=0.1]   27%|██▋       | 20/75 [08:06<20:45, 22.65s/epoch, loss=1.17, accuracy=0.74, val_loss=1.81, val_accuracy=0.542, lr=0.1] 28%|██▊       | 21/75 [08:29<20:26, 22.71s/epoch, loss=1.17, accuracy=0.738, val_loss=1.76, val_accuracy=0.58, lr=0.1] 29%|██▉       | 22/75 [08:51<19:46, 22.39s/epoch, loss=1.17, accuracy=0.743, val_loss=1.77, val_accuracy=0.551, lr=0.0316] 31%|███       | 23/75 [09:13<19:25, 22.41s/epoch, loss=1.17, accuracy=0.743, val_loss=1.71, val_accuracy=0.585, lr=0.1]    32%|███▏      | 24/75 [09:35<19:02, 22.40s/epoch, loss=1.17, accuracy=0.743, val_loss=1.65, val_accuracy=0.602, lr=0.1] 33%|███▎      | 25/75 [09:57<18:29, 22.18s/epoch, loss=1.16, accuracy=0.747, val_loss=1.76, val_accuracy=0.564, lr=0.1] 35%|███▍      | 26/75 [10:20<18:16, 22.38s/epoch, loss=1.17, accuracy=0.742, val_loss=1.84, val_accuracy=0.516, lr=0.1] 36%|███▌      | 27/75 [10:42<17:45, 22.19s/epoch, loss=1.17, accuracy=0.744, val_loss=1.53, val_accuracy=0.619, lr=0.0316] 37%|███▋      | 28/75 [11:04<17:31, 22.38s/epoch, loss=1.16, accuracy=0.744, val_loss=2.22, val_accuracy=0.397, lr=0.1]    39%|███▊      | 29/75 [11:27<17:08, 22.35s/epoch, loss=1.16, accuracy=0.746, val_loss=1.97, val_accuracy=0.536, lr=0.1] 40%|████      | 30/75 [11:49<16:47, 22.39s/epoch, loss=1.16, accuracy=0.746, val_loss=1.78, val_accuracy=0.546, lr=0.1] 41%|████▏     | 31/75 [12:12<16:31, 22.53s/epoch, loss=1.15, accuracy=0.749, val_loss=2.55, val_accuracy=0.446, lr=0.1] 43%|████▎     | 32/75 [12:35<16:12, 22.61s/epoch, loss=1.15, accuracy=0.749, val_loss=1.56, val_accuracy=0.62, lr=0.0316] 44%|████▍     | 33/75 [12:58<15:50, 22.64s/epoch, loss=1.16, accuracy=0.747, val_loss=1.74, val_accuracy=0.592, lr=0.1]   45%|████▌     | 34/75 [13:20<15:30, 22.69s/epoch, loss=1.15, accuracy=0.747, val_loss=1.62, val_accuracy=0.621, lr=0.1] 47%|████▋     | 35/75 [13:43<15:02, 22.57s/epoch, loss=1.15, accuracy=0.746, val_loss=3.23, val_accuracy=0.283, lr=0.1] 48%|████▊     | 36/75 [14:05<14:36, 22.46s/epoch, loss=1.15, accuracy=0.747, val_loss=1.93, val_accuracy=0.51, lr=0.1]  49%|████▉     | 37/75 [14:27<14:13, 22.45s/epoch, loss=1.15, accuracy=0.747, val_loss=1.77, val_accuracy=0.554, lr=0.0316] 51%|█████     | 38/75 [14:50<13:53, 22.54s/epoch, loss=1.14, accuracy=0.749, val_loss=1.71, val_accuracy=0.555, lr=0.1]    52%|█████▏    | 39/75 [15:13<13:34, 22.62s/epoch, loss=1.14, accuracy=0.75, val_loss=1.78, val_accuracy=0.606, lr=0.1]  53%|█████▎    | 40/75 [15:36<13:12, 22.65s/epoch, loss=1.14, accuracy=0.75, val_loss=1.64, val_accuracy=0.573, lr=0.1] 55%|█████▍    | 41/75 [15:59<12:52, 22.73s/epoch, loss=1.15, accuracy=0.748, val_loss=2.01, val_accuracy=0.479, lr=0.1] 56%|█████▌    | 42/75 [16:21<12:30, 22.75s/epoch, loss=1.14, accuracy=0.748, val_loss=3.02, val_accuracy=0.395, lr=0.0316] 57%|█████▋    | 43/75 [16:44<12:04, 22.64s/epoch, loss=1.14, accuracy=0.752, val_loss=2.76, val_accuracy=0.435, lr=0.1]    59%|█████▊    | 44/75 [17:06<11:34, 22.40s/epoch, loss=1.14, accuracy=0.752, val_loss=1.59, val_accuracy=0.58, lr=0.1]  60%|██████    | 45/75 [17:28<11:09, 22.33s/epoch, loss=1.15, accuracy=0.75, val_loss=2.66, val_accuracy=0.428, lr=0.1] 61%|██████▏   | 46/75 [17:50<10:46, 22.28s/epoch, loss=1.14, accuracy=0.752, val_loss=2.52, val_accuracy=0.4, lr=0.1]  63%|██████▎   | 47/75 [18:12<10:25, 22.33s/epoch, loss=1.14, accuracy=0.749, val_loss=5.52, val_accuracy=0.177, lr=0.0316] 64%|██████▍   | 48/75 [18:34<10:01, 22.26s/epoch, loss=1.14, accuracy=0.749, val_loss=1.85, val_accuracy=0.524, lr=0.1]    65%|██████▌   | 49/75 [18:57<09:39, 22.28s/epoch, loss=1.14, accuracy=0.751, val_loss=1.71, val_accuracy=0.573, lr=0.1] 67%|██████▋   | 50/75 [19:19<09:14, 22.18s/epoch, loss=1.13, accuracy=0.752, val_loss=3, val_accuracy=0.318, lr=0.1]    68%|██████▊   | 51/75 [19:41<08:52, 22.18s/epoch, loss=1.14, accuracy=0.749, val_loss=1.81, val_accuracy=0.516, lr=0.1] 69%|██████▉   | 52/75 [20:03<08:30, 22.21s/epoch, loss=1.13, accuracy=0.751, val_loss=1.7, val_accuracy=0.59, lr=0.0316] 71%|███████   | 53/75 [20:24<07:58, 21.75s/epoch, loss=1.14, accuracy=0.752, val_loss=3.03, val_accuracy=0.304, lr=0.1]  72%|███████▏  | 54/75 [20:45<07:35, 21.67s/epoch, loss=1.14, accuracy=0.753, val_loss=4.13, val_accuracy=0.283, lr=0.1] 73%|███████▎  | 55/75 [21:07<07:10, 21.52s/epoch, loss=1.14, accuracy=0.751, val_loss=2.65, val_accuracy=0.411, lr=0.1] 75%|███████▍  | 56/75 [21:29<06:53, 21.78s/epoch, loss=1.13, accuracy=0.751, val_loss=1.59, val_accuracy=0.596, lr=0.1] 76%|███████▌  | 57/75 [21:51<06:32, 21.81s/epoch, loss=1.13, accuracy=0.751, val_loss=2.02, val_accuracy=0.466, lr=0.0316] 77%|███████▋  | 58/75 [22:13<06:11, 21.88s/epoch, loss=1.12, accuracy=0.752, val_loss=1.77, val_accuracy=0.544, lr=0.1]    79%|███████▊  | 59/75 [22:35<05:50, 21.93s/epoch, loss=1.13, accuracy=0.751, val_loss=4.29, val_accuracy=0.29, lr=0.1]  80%|████████  | 60/75 [22:56<05:27, 21.82s/epoch, loss=1.13, accuracy=0.751, val_loss=1.59, val_accuracy=0.57, lr=0.1] 81%|████████▏ | 61/75 [23:19<05:06, 21.93s/epoch, loss=1.12, accuracy=0.755, val_loss=1.97, val_accuracy=0.474, lr=0.1] 83%|████████▎ | 62/75 [23:40<04:44, 21.90s/epoch, loss=1.13, accuracy=0.751, val_loss=2.27, val_accuracy=0.49, lr=0.0316] 84%|████████▍ | 63/75 [24:03<04:23, 21.99s/epoch, loss=1.13, accuracy=0.755, val_loss=2.16, val_accuracy=0.443, lr=0.1]   85%|████████▌ | 64/75 [24:24<03:59, 21.75s/epoch, loss=1.14, accuracy=0.753, val_loss=2.23, val_accuracy=0.471, lr=0.1] 87%|████████▋ | 65/75 [24:46<03:37, 21.74s/epoch, loss=1.13, accuracy=0.753, val_loss=1.69, val_accuracy=0.538, lr=0.1] 88%|████████▊ | 66/75 [25:08<03:17, 21.89s/epoch, loss=1.13, accuracy=0.752, val_loss=2.06, val_accuracy=0.511, lr=0.1] 89%|████████▉ | 67/75 [25:30<02:55, 22.00s/epoch, loss=1.13, accuracy=0.751, val_loss=1.86, val_accuracy=0.497, lr=0.0316] 91%|█████████ | 68/75 [25:52<02:34, 22.07s/epoch, loss=1.13, accuracy=0.751, val_loss=3.27, val_accuracy=0.346, lr=0.1]    92%|█████████▏| 69/75 [26:12<02:07, 21.25s/epoch, loss=1.12, accuracy=0.753, val_loss=2.82, val_accuracy=0.338, lr=0.1] 93%|█████████▎| 70/75 [26:30<01:42, 20.54s/epoch, loss=1.13, accuracy=0.755, val_loss=1.71, val_accuracy=0.568, lr=0.1] 95%|█████████▍| 71/75 [26:51<01:22, 20.50s/epoch, loss=1.12, accuracy=0.756, val_loss=1.79, val_accuracy=0.541, lr=0.1] 96%|█████████▌| 72/75 [27:11<01:01, 20.48s/epoch, loss=1.13, accuracy=0.753, val_loss=1.59, val_accuracy=0.593, lr=0.0316] 97%|█████████▋| 73/75 [27:31<00:40, 20.21s/epoch, loss=1.12, accuracy=0.754, val_loss=1.51, val_accuracy=0.62, lr=0.1]     99%|█████████▊| 74/75 [27:51<00:20, 20.06s/epoch, loss=1.12, accuracy=0.756, val_loss=3.05, val_accuracy=0.383, lr=0.1]100%|██████████| 75/75 [28:11<00:00, 20.16s/epoch, loss=1.12, accuracy=0.752, val_loss=6.08, val_accuracy=0.242, lr=0.1]100%|██████████| 75/75 [28:11<00:00, 22.55s/epoch, loss=1.12, accuracy=0.752, val_loss=6.08, val_accuracy=0.242, lr=0.1]
Using real-time data augmentation.
Test loss: 6.082986831665039
Test accuracy: 0.2418999969959259


* * * Run SGD for ID = 20_16. * * *


2024-02-16 03:22:17.573505: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-16 03:22:20.291553: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-16 03:22:20.292612: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-16 03:22:20.327385: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-16 03:22:20.327412: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-16 03:22:20.330123: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-16 03:22:20.330159: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-16 03:22:20.332248: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-16 03:22:20.333014: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-16 03:22:20.335144: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-16 03:22:20.336537: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-16 03:22:20.341192: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-16 03:22:20.357993: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-16 03:22:20.358077: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-16 03:22:21.463079: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-16 03:22:21.464140: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-16 03:22:21.464728: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-16 03:22:21.464757: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-16 03:22:21.464805: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-16 03:22:21.464825: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-16 03:22:21.464844: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-16 03:22:21.464862: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-16 03:22:21.464881: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-16 03:22:21.464899: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-16 03:22:21.464918: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-16 03:22:21.465343: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-16 03:22:21.465379: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-16 03:22:22.033853: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-16 03:22:22.033916: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-16 03:22:22.033926: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-16 03:22:22.034799: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': 2016, 'batch_size': 128, 'epochs': 75, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/75 [00:00<?, ?epoch/s]2024-02-16 03:22:22.762355: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-16 03:22:22.774400: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2599900000 Hz
2024-02-16 03:22:24.480567: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-16 03:22:24.688341: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-16 03:22:25.415999: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-16 03:22:25.449422: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|▏         | 1/75 [00:44<54:48, 44.43s/epoch, loss=3.26, accuracy=0.318, val_loss=2.33, val_accuracy=0.279, lr=0.1]  3%|▎         | 2/75 [01:04<36:45, 30.21s/epoch, loss=1.62, accuracy=0.508, val_loss=2.72, val_accuracy=0.434, lr=0.1]  4%|▍         | 3/75 [01:24<30:26, 25.36s/epoch, loss=1.37, accuracy=0.618, val_loss=2.41, val_accuracy=0.393, lr=0.1]  5%|▌         | 4/75 [01:44<27:29, 23.23s/epoch, loss=1.28, accuracy=0.676, val_loss=1.93, val_accuracy=0.49, lr=0.1]   7%|▋         | 5/75 [02:03<25:22, 21.75s/epoch, loss=1.24, accuracy=0.699, val_loss=1.87, val_accuracy=0.502, lr=0.1]  8%|▊         | 6/75 [02:24<24:38, 21.43s/epoch, loss=1.23, accuracy=0.708, val_loss=1.67, val_accuracy=0.566, lr=0.1]  9%|▉         | 7/75 [02:43<23:28, 20.71s/epoch, loss=1.21, accuracy=0.716, val_loss=2.62, val_accuracy=0.356, lr=0.1] 11%|█         | 8/75 [03:04<23:17, 20.86s/epoch, loss=1.22, accuracy=0.721, val_loss=2.83, val_accuracy=0.382, lr=0.1] 12%|█▏        | 9/75 [03:25<23:02, 20.95s/epoch, loss=1.21, accuracy=0.724, val_loss=5.1, val_accuracy=0.214, lr=0.1]  13%|█▎        | 10/75 [03:45<22:09, 20.46s/epoch, loss=1.2, accuracy=0.727, val_loss=2.27, val_accuracy=0.499, lr=0.1] 15%|█▍        | 11/75 [04:05<21:52, 20.50s/epoch, loss=1.19, accuracy=0.732, val_loss=2.01, val_accuracy=0.5, lr=0.0316] 16%|█▌        | 12/75 [04:24<21:04, 20.06s/epoch, loss=1.19, accuracy=0.735, val_loss=2.13, val_accuracy=0.452, lr=0.1]  17%|█▋        | 13/75 [04:44<20:33, 19.90s/epoch, loss=1.19, accuracy=0.736, val_loss=1.53, val_accuracy=0.632, lr=0.1] 19%|█▊        | 14/75 [05:03<20:03, 19.72s/epoch, loss=1.18, accuracy=0.738, val_loss=2.22, val_accuracy=0.444, lr=0.1] 20%|██        | 15/75 [05:22<19:31, 19.52s/epoch, loss=1.17, accuracy=0.739, val_loss=3.29, val_accuracy=0.424, lr=0.1] 21%|██▏       | 16/75 [05:41<19:06, 19.44s/epoch, loss=1.18, accuracy=0.737, val_loss=1.66, val_accuracy=0.562, lr=0.1] 23%|██▎       | 17/75 [06:01<18:55, 19.58s/epoch, loss=1.17, accuracy=0.737, val_loss=2.43, val_accuracy=0.354, lr=0.1] 24%|██▍       | 18/75 [06:20<18:29, 19.46s/epoch, loss=1.17, accuracy=0.739, val_loss=3.22, val_accuracy=0.287, lr=0.0316] 25%|██▌       | 19/75 [06:41<18:22, 19.69s/epoch, loss=1.17, accuracy=0.741, val_loss=2.34, val_accuracy=0.422, lr=0.1]    27%|██▋       | 20/75 [07:01<18:07, 19.77s/epoch, loss=1.16, accuracy=0.742, val_loss=2.11, val_accuracy=0.496, lr=0.1] 28%|██▊       | 21/75 [07:22<18:08, 20.15s/epoch, loss=1.16, accuracy=0.743, val_loss=1.65, val_accuracy=0.596, lr=0.1] 29%|██▉       | 22/75 [07:42<17:43, 20.06s/epoch, loss=1.16, accuracy=0.742, val_loss=5.66, val_accuracy=0.155, lr=0.1] 31%|███       | 23/75 [08:03<17:42, 20.43s/epoch, loss=1.15, accuracy=0.745, val_loss=1.94, val_accuracy=0.541, lr=0.0316] 32%|███▏      | 24/75 [08:23<17:22, 20.44s/epoch, loss=1.16, accuracy=0.748, val_loss=1.57, val_accuracy=0.631, lr=0.1]    33%|███▎      | 25/75 [08:43<16:56, 20.33s/epoch, loss=1.15, accuracy=0.748, val_loss=2.18, val_accuracy=0.419, lr=0.1] 35%|███▍      | 26/75 [09:05<16:49, 20.60s/epoch, loss=1.15, accuracy=0.746, val_loss=2.52, val_accuracy=0.408, lr=0.1] 36%|███▌      | 27/75 [09:26<16:40, 20.84s/epoch, loss=1.15, accuracy=0.748, val_loss=1.86, val_accuracy=0.483, lr=0.1] 37%|███▋      | 28/75 [09:45<15:54, 20.30s/epoch, loss=1.15, accuracy=0.747, val_loss=2.53, val_accuracy=0.354, lr=0.0316] 39%|███▊      | 29/75 [10:05<15:23, 20.07s/epoch, loss=1.15, accuracy=0.748, val_loss=3.01, val_accuracy=0.306, lr=0.1]    40%|████      | 30/75 [10:26<15:17, 20.39s/epoch, loss=1.14, accuracy=0.748, val_loss=1.67, val_accuracy=0.608, lr=0.1] 41%|████▏     | 31/75 [10:47<15:06, 20.61s/epoch, loss=1.14, accuracy=0.751, val_loss=1.69, val_accuracy=0.547, lr=0.1] 43%|████▎     | 32/75 [11:06<14:24, 20.12s/epoch, loss=1.14, accuracy=0.75, val_loss=2.68, val_accuracy=0.395, lr=0.1]  44%|████▍     | 33/75 [11:26<14:02, 20.07s/epoch, loss=1.14, accuracy=0.751, val_loss=1.87, val_accuracy=0.506, lr=0.0316] 45%|████▌     | 34/75 [11:45<13:37, 19.95s/epoch, loss=1.13, accuracy=0.751, val_loss=1.32, val_accuracy=0.688, lr=0.1]    47%|████▋     | 35/75 [12:05<13:16, 19.90s/epoch, loss=1.13, accuracy=0.752, val_loss=1.96, val_accuracy=0.511, lr=0.1] 48%|████▊     | 36/75 [12:26<13:04, 20.12s/epoch, loss=1.13, accuracy=0.752, val_loss=2.14, val_accuracy=0.432, lr=0.1] 49%|████▉     | 37/75 [12:46<12:43, 20.10s/epoch, loss=1.13, accuracy=0.753, val_loss=2.06, val_accuracy=0.531, lr=0.1] 51%|█████     | 38/75 [13:05<12:15, 19.87s/epoch, loss=1.13, accuracy=0.751, val_loss=1.39, val_accuracy=0.666, lr=0.1] 52%|█████▏    | 39/75 [13:26<12:01, 20.05s/epoch, loss=1.12, accuracy=0.753, val_loss=2.02, val_accuracy=0.451, lr=0.0316] 53%|█████▎    | 40/75 [13:45<11:29, 19.69s/epoch, loss=1.12, accuracy=0.752, val_loss=1.81, val_accuracy=0.546, lr=0.1]    55%|█████▍    | 41/75 [14:04<11:07, 19.64s/epoch, loss=1.12, accuracy=0.754, val_loss=2.33, val_accuracy=0.416, lr=0.1] 56%|█████▌    | 42/75 [14:25<10:59, 19.98s/epoch, loss=1.12, accuracy=0.752, val_loss=3.99, val_accuracy=0.312, lr=0.1] 57%|█████▋    | 43/75 [14:44<10:28, 19.64s/epoch, loss=1.12, accuracy=0.754, val_loss=1.87, val_accuracy=0.529, lr=0.1] 59%|█████▊    | 44/75 [15:05<10:20, 20.03s/epoch, loss=1.12, accuracy=0.755, val_loss=1.96, val_accuracy=0.529, lr=0.0316] 60%|██████    | 45/75 [15:25<10:05, 20.19s/epoch, loss=1.12, accuracy=0.754, val_loss=3.92, val_accuracy=0.323, lr=0.1]    61%|██████▏   | 46/75 [15:44<09:35, 19.85s/epoch, loss=1.12, accuracy=0.755, val_loss=1.64, val_accuracy=0.583, lr=0.1] 63%|██████▎   | 47/75 [16:03<09:07, 19.55s/epoch, loss=1.12, accuracy=0.756, val_loss=2.3, val_accuracy=0.469, lr=0.1]  64%|██████▍   | 48/75 [16:23<08:52, 19.72s/epoch, loss=1.11, accuracy=0.755, val_loss=3.79, val_accuracy=0.318, lr=0.1] 65%|██████▌   | 49/75 [16:42<08:27, 19.50s/epoch, loss=1.11, accuracy=0.757, val_loss=2.12, val_accuracy=0.442, lr=0.0316] 67%|██████▋   | 50/75 [17:02<08:10, 19.62s/epoch, loss=1.11, accuracy=0.754, val_loss=2.29, val_accuracy=0.467, lr=0.1]    68%|██████▊   | 51/75 [17:22<07:54, 19.76s/epoch, loss=1.12, accuracy=0.754, val_loss=1.92, val_accuracy=0.512, lr=0.1] 69%|██████▉   | 52/75 [17:43<07:44, 20.18s/epoch, loss=1.1, accuracy=0.757, val_loss=2.05, val_accuracy=0.538, lr=0.1]  71%|███████   | 53/75 [18:02<07:15, 19.78s/epoch, loss=1.1, accuracy=0.756, val_loss=2.58, val_accuracy=0.346, lr=0.1] 72%|███████▏  | 54/75 [18:23<07:03, 20.18s/epoch, loss=1.11, accuracy=0.755, val_loss=2.39, val_accuracy=0.462, lr=0.0316] 73%|███████▎  | 55/75 [18:42<06:36, 19.84s/epoch, loss=1.11, accuracy=0.755, val_loss=1.5, val_accuracy=0.608, lr=0.1]     75%|███████▍  | 56/75 [19:03<06:19, 19.95s/epoch, loss=1.11, accuracy=0.757, val_loss=1.97, val_accuracy=0.481, lr=0.1] 76%|███████▌  | 57/75 [19:22<05:57, 19.86s/epoch, loss=1.11, accuracy=0.755, val_loss=2.01, val_accuracy=0.514, lr=0.1] 77%|███████▋  | 58/75 [19:42<05:39, 19.94s/epoch, loss=1.11, accuracy=0.758, val_loss=1.53, val_accuracy=0.582, lr=0.1] 79%|███████▊  | 59/75 [20:02<05:19, 19.97s/epoch, loss=1.11, accuracy=0.756, val_loss=2.58, val_accuracy=0.341, lr=0.0316] 80%|████████  | 60/75 [20:23<05:00, 20.02s/epoch, loss=1.11, accuracy=0.755, val_loss=3.06, val_accuracy=0.247, lr=0.1]    81%|████████▏ | 61/75 [20:43<04:40, 20.06s/epoch, loss=1.1, accuracy=0.756, val_loss=2.09, val_accuracy=0.463, lr=0.1]  83%|████████▎ | 62/75 [21:02<04:17, 19.80s/epoch, loss=1.11, accuracy=0.755, val_loss=2.42, val_accuracy=0.533, lr=0.1] 84%|████████▍ | 63/75 [21:23<04:02, 20.21s/epoch, loss=1.11, accuracy=0.756, val_loss=1.89, val_accuracy=0.524, lr=0.1] 85%|████████▌ | 64/75 [21:43<03:39, 19.97s/epoch, loss=1.1, accuracy=0.756, val_loss=1.56, val_accuracy=0.634, lr=0.0316] 87%|████████▋ | 65/75 [22:02<03:17, 19.77s/epoch, loss=1.11, accuracy=0.758, val_loss=1.65, val_accuracy=0.585, lr=0.1]   88%|████████▊ | 66/75 [22:21<02:55, 19.48s/epoch, loss=1.1, accuracy=0.759, val_loss=2.22, val_accuracy=0.508, lr=0.1]  89%|████████▉ | 67/75 [22:40<02:35, 19.46s/epoch, loss=1.11, accuracy=0.757, val_loss=1.68, val_accuracy=0.567, lr=0.1] 91%|█████████ | 68/75 [23:00<02:17, 19.66s/epoch, loss=1.1, accuracy=0.757, val_loss=2.66, val_accuracy=0.422, lr=0.1]  92%|█████████▏| 69/75 [23:21<01:59, 19.94s/epoch, loss=1.11, accuracy=0.756, val_loss=1.72, val_accuracy=0.58, lr=0.0316] 93%|█████████▎| 70/75 [23:42<01:41, 20.33s/epoch, loss=1.1, accuracy=0.76, val_loss=10.7, val_accuracy=0.143, lr=0.1]     95%|█████████▍| 71/75 [24:02<01:20, 20.13s/epoch, loss=1.1, accuracy=0.756, val_loss=1.73, val_accuracy=0.539, lr=0.1] 96%|█████████▌| 72/75 [24:21<00:59, 19.80s/epoch, loss=1.11, accuracy=0.755, val_loss=1.3, val_accuracy=0.68, lr=0.1]  97%|█████████▋| 73/75 [24:39<00:38, 19.49s/epoch, loss=1.1, accuracy=0.759, val_loss=1.64, val_accuracy=0.578, lr=0.1] 99%|█████████▊| 74/75 [24:59<00:19, 19.48s/epoch, loss=1.1, accuracy=0.758, val_loss=3.32, val_accuracy=0.308, lr=0.1]100%|██████████| 75/75 [25:18<00:00, 19.30s/epoch, loss=1.1, accuracy=0.758, val_loss=2.71, val_accuracy=0.431, lr=0.1]100%|██████████| 75/75 [25:18<00:00, 20.24s/epoch, loss=1.1, accuracy=0.758, val_loss=2.71, val_accuracy=0.431, lr=0.1]
Using real-time data augmentation.
Test loss: 2.712961435317993
Test accuracy: 0.4309999942779541


* * * Run SGD for ID = 20_17. * * *


2024-02-16 03:47:43.566532: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-16 03:47:46.988211: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-16 03:47:46.989358: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-16 03:47:47.024639: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-16 03:47:47.024667: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-16 03:47:47.027728: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-16 03:47:47.027765: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-16 03:47:47.031065: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-16 03:47:47.032034: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-16 03:47:47.034650: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-16 03:47:47.036443: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-16 03:47:47.052057: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-16 03:47:47.052532: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-16 03:47:47.052614: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-16 03:47:48.176609: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-16 03:47:48.177119: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-16 03:47:48.177731: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-16 03:47:48.177761: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-16 03:47:48.177809: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-16 03:47:48.177847: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-16 03:47:48.177874: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-16 03:47:48.177899: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-16 03:47:48.177919: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-16 03:47:48.177943: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-16 03:47:48.177969: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-16 03:47:48.178402: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-16 03:47:48.178437: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-16 03:47:48.749783: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-16 03:47:48.749849: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-16 03:47:48.749858: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-16 03:47:48.750779: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': 2017, 'batch_size': 128, 'epochs': 75, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/75 [00:00<?, ?epoch/s]2024-02-16 03:47:49.473914: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-16 03:47:49.486514: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2599900000 Hz
2024-02-16 03:47:51.186881: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-16 03:47:51.462735: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-16 03:47:52.242827: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-16 03:47:52.274322: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|▏         | 1/75 [00:43<53:15, 43.18s/epoch, loss=3.27, accuracy=0.28, val_loss=2.36, val_accuracy=0.268, lr=0.1]  3%|▎         | 2/75 [01:02<35:37, 29.28s/epoch, loss=1.61, accuracy=0.51, val_loss=1.98, val_accuracy=0.414, lr=0.1]  4%|▍         | 3/75 [01:22<30:01, 25.02s/epoch, loss=1.43, accuracy=0.61, val_loss=2.11, val_accuracy=0.465, lr=0.1]  5%|▌         | 4/75 [01:42<27:08, 22.93s/epoch, loss=1.34, accuracy=0.662, val_loss=1.67, val_accuracy=0.564, lr=0.1]  7%|▋         | 5/75 [02:01<25:03, 21.48s/epoch, loss=1.29, accuracy=0.69, val_loss=3.78, val_accuracy=0.29, lr=0.1]    8%|▊         | 6/75 [02:21<24:12, 21.06s/epoch, loss=1.27, accuracy=0.705, val_loss=3.08, val_accuracy=0.359, lr=0.1]  9%|▉         | 7/75 [02:40<23:11, 20.46s/epoch, loss=1.25, accuracy=0.711, val_loss=2.54, val_accuracy=0.416, lr=0.1] 11%|█         | 8/75 [02:59<22:15, 19.93s/epoch, loss=1.24, accuracy=0.717, val_loss=1.79, val_accuracy=0.546, lr=0.1] 12%|█▏        | 9/75 [03:19<21:53, 19.89s/epoch, loss=1.23, accuracy=0.723, val_loss=1.77, val_accuracy=0.555, lr=0.0316] 13%|█▎        | 10/75 [03:38<21:14, 19.60s/epoch, loss=1.23, accuracy=0.724, val_loss=1.72, val_accuracy=0.587, lr=0.1]   15%|█▍        | 11/75 [03:58<21:09, 19.84s/epoch, loss=1.22, accuracy=0.727, val_loss=1.78, val_accuracy=0.572, lr=0.1] 16%|█▌        | 12/75 [04:19<21:11, 20.19s/epoch, loss=1.22, accuracy=0.73, val_loss=2.13, val_accuracy=0.515, lr=0.1]  17%|█▋        | 13/75 [04:39<20:47, 20.11s/epoch, loss=1.21, accuracy=0.732, val_loss=1.86, val_accuracy=0.518, lr=0.1] 19%|█▊        | 14/75 [04:58<20:04, 19.75s/epoch, loss=1.2, accuracy=0.735, val_loss=2.96, val_accuracy=0.265, lr=0.0316] 20%|██        | 15/75 [05:17<19:29, 19.49s/epoch, loss=1.2, accuracy=0.738, val_loss=1.52, val_accuracy=0.629, lr=0.1]    21%|██▏       | 16/75 [05:36<18:59, 19.32s/epoch, loss=1.2, accuracy=0.739, val_loss=2.06, val_accuracy=0.539, lr=0.1] 23%|██▎       | 17/75 [05:55<18:31, 19.17s/epoch, loss=1.2, accuracy=0.737, val_loss=1.55, val_accuracy=0.615, lr=0.1] 24%|██▍       | 18/75 [06:16<18:41, 19.67s/epoch, loss=1.2, accuracy=0.739, val_loss=3, val_accuracy=0.35, lr=0.1]     25%|██▌       | 19/75 [06:35<18:20, 19.65s/epoch, loss=1.2, accuracy=0.739, val_loss=2.72, val_accuracy=0.467, lr=0.1] 27%|██▋       | 20/75 [06:54<17:49, 19.45s/epoch, loss=1.2, accuracy=0.738, val_loss=3.1, val_accuracy=0.377, lr=0.0316] 28%|██▊       | 21/75 [07:13<17:24, 19.33s/epoch, loss=1.2, accuracy=0.738, val_loss=2.9, val_accuracy=0.42, lr=0.1]     29%|██▉       | 22/75 [07:33<17:09, 19.43s/epoch, loss=1.19, accuracy=0.741, val_loss=1.42, val_accuracy=0.655, lr=0.1] 31%|███       | 23/75 [07:53<16:58, 19.59s/epoch, loss=1.19, accuracy=0.744, val_loss=1.96, val_accuracy=0.527, lr=0.1] 32%|███▏      | 24/75 [08:13<16:47, 19.75s/epoch, loss=1.19, accuracy=0.745, val_loss=1.8, val_accuracy=0.549, lr=0.1]  33%|███▎      | 25/75 [08:32<16:17, 19.54s/epoch, loss=1.19, accuracy=0.742, val_loss=2.23, val_accuracy=0.474, lr=0.1] 35%|███▍      | 26/75 [08:52<15:59, 19.58s/epoch, loss=1.19, accuracy=0.742, val_loss=2.39, val_accuracy=0.468, lr=0.1] 36%|███▌      | 27/75 [09:11<15:38, 19.55s/epoch, loss=1.19, accuracy=0.743, val_loss=2.55, val_accuracy=0.38, lr=0.0316] 37%|███▋      | 28/75 [09:31<15:19, 19.56s/epoch, loss=1.18, accuracy=0.742, val_loss=2.81, val_accuracy=0.369, lr=0.1]   39%|███▊      | 29/75 [09:51<15:16, 19.92s/epoch, loss=1.18, accuracy=0.745, val_loss=2.14, val_accuracy=0.456, lr=0.1] 40%|████      | 30/75 [10:12<15:03, 20.07s/epoch, loss=1.18, accuracy=0.745, val_loss=2.69, val_accuracy=0.433, lr=0.1] 41%|████▏     | 31/75 [10:32<14:43, 20.07s/epoch, loss=1.18, accuracy=0.744, val_loss=1.43, val_accuracy=0.662, lr=0.1] 43%|████▎     | 32/75 [10:52<14:22, 20.06s/epoch, loss=1.19, accuracy=0.741, val_loss=1.71, val_accuracy=0.587, lr=0.0316] 44%|████▍     | 33/75 [11:12<14:02, 20.07s/epoch, loss=1.18, accuracy=0.744, val_loss=1.68, val_accuracy=0.609, lr=0.1]    45%|████▌     | 34/75 [11:31<13:26, 19.67s/epoch, loss=1.17, accuracy=0.744, val_loss=1.9, val_accuracy=0.535, lr=0.1]  47%|████▋     | 35/75 [11:51<13:09, 19.73s/epoch, loss=1.17, accuracy=0.746, val_loss=1.69, val_accuracy=0.614, lr=0.1] 48%|████▊     | 36/75 [12:11<12:52, 19.80s/epoch, loss=1.18, accuracy=0.745, val_loss=1.43, val_accuracy=0.669, lr=0.1] 49%|████▉     | 37/75 [12:30<12:27, 19.68s/epoch, loss=1.18, accuracy=0.745, val_loss=1.45, val_accuracy=0.67, lr=0.0316] 51%|█████     | 38/75 [12:49<11:57, 19.40s/epoch, loss=1.18, accuracy=0.746, val_loss=2.11, val_accuracy=0.45, lr=0.1]    52%|█████▏    | 39/75 [13:08<11:37, 19.36s/epoch, loss=1.17, accuracy=0.746, val_loss=2.52, val_accuracy=0.405, lr=0.1] 53%|█████▎    | 40/75 [13:27<11:17, 19.37s/epoch, loss=1.17, accuracy=0.747, val_loss=1.43, val_accuracy=0.644, lr=0.1] 55%|█████▍    | 41/75 [13:47<10:55, 19.29s/epoch, loss=1.17, accuracy=0.747, val_loss=2.14, val_accuracy=0.513, lr=0.1] 56%|█████▌    | 42/75 [14:06<10:38, 19.35s/epoch, loss=1.16, accuracy=0.751, val_loss=1.95, val_accuracy=0.503, lr=0.0316] 57%|█████▋    | 43/75 [14:25<10:15, 19.24s/epoch, loss=1.16, accuracy=0.747, val_loss=3.26, val_accuracy=0.424, lr=0.1]    59%|█████▊    | 44/75 [14:44<09:51, 19.09s/epoch, loss=1.16, accuracy=0.748, val_loss=1.61, val_accuracy=0.584, lr=0.1] 60%|██████    | 45/75 [15:04<09:44, 19.49s/epoch, loss=1.16, accuracy=0.749, val_loss=2.12, val_accuracy=0.52, lr=0.1]  61%|██████▏   | 46/75 [15:23<09:21, 19.35s/epoch, loss=1.17, accuracy=0.747, val_loss=1.69, val_accuracy=0.565, lr=0.1] 63%|██████▎   | 47/75 [15:42<08:58, 19.22s/epoch, loss=1.16, accuracy=0.748, val_loss=2.18, val_accuracy=0.417, lr=0.0316] 64%|██████▍   | 48/75 [16:01<08:36, 19.15s/epoch, loss=1.16, accuracy=0.75, val_loss=2.16, val_accuracy=0.472, lr=0.1]     65%|██████▌   | 49/75 [16:22<08:33, 19.75s/epoch, loss=1.16, accuracy=0.749, val_loss=3.59, val_accuracy=0.379, lr=0.1] 67%|██████▋   | 50/75 [16:41<08:06, 19.47s/epoch, loss=1.16, accuracy=0.749, val_loss=1.49, val_accuracy=0.629, lr=0.1] 68%|██████▊   | 51/75 [17:01<07:47, 19.47s/epoch, loss=1.15, accuracy=0.751, val_loss=1.68, val_accuracy=0.579, lr=0.1] 69%|██████▉   | 52/75 [17:20<07:26, 19.42s/epoch, loss=1.16, accuracy=0.748, val_loss=1.92, val_accuracy=0.509, lr=0.0316] 71%|███████   | 53/75 [17:41<07:18, 19.94s/epoch, loss=1.15, accuracy=0.752, val_loss=1.8, val_accuracy=0.549, lr=0.1]     72%|███████▏  | 54/75 [18:00<06:53, 19.67s/epoch, loss=1.16, accuracy=0.749, val_loss=3.04, val_accuracy=0.347, lr=0.1] 73%|███████▎  | 55/75 [18:20<06:37, 19.88s/epoch, loss=1.16, accuracy=0.75, val_loss=3.11, val_accuracy=0.306, lr=0.1]  75%|███████▍  | 56/75 [18:41<06:18, 19.94s/epoch, loss=1.15, accuracy=0.75, val_loss=1.69, val_accuracy=0.562, lr=0.1] 76%|███████▌  | 57/75 [19:02<06:05, 20.30s/epoch, loss=1.15, accuracy=0.753, val_loss=3.23, val_accuracy=0.308, lr=0.0316] 77%|███████▋  | 58/75 [19:21<05:41, 20.07s/epoch, loss=1.15, accuracy=0.75, val_loss=2.19, val_accuracy=0.481, lr=0.1]     79%|███████▊  | 59/75 [19:42<05:24, 20.31s/epoch, loss=1.15, accuracy=0.753, val_loss=2.31, val_accuracy=0.368, lr=0.1] 80%|████████  | 60/75 [20:01<04:58, 19.90s/epoch, loss=1.15, accuracy=0.75, val_loss=2.95, val_accuracy=0.371, lr=0.1]  81%|████████▏ | 61/75 [20:22<04:43, 20.23s/epoch, loss=1.16, accuracy=0.751, val_loss=1.84, val_accuracy=0.564, lr=0.1] 83%|████████▎ | 62/75 [20:42<04:22, 20.16s/epoch, loss=1.16, accuracy=0.749, val_loss=2.75, val_accuracy=0.46, lr=0.0316] 84%|████████▍ | 63/75 [21:02<04:00, 20.01s/epoch, loss=1.16, accuracy=0.749, val_loss=2.6, val_accuracy=0.465, lr=0.1]    85%|████████▌ | 64/75 [21:23<03:42, 20.27s/epoch, loss=1.15, accuracy=0.751, val_loss=1.72, val_accuracy=0.568, lr=0.1] 87%|████████▋ | 65/75 [21:41<03:18, 19.81s/epoch, loss=1.15, accuracy=0.753, val_loss=1.59, val_accuracy=0.592, lr=0.1] 88%|████████▊ | 66/75 [22:00<02:55, 19.50s/epoch, loss=1.15, accuracy=0.751, val_loss=1.6, val_accuracy=0.62, lr=0.1]   89%|████████▉ | 67/75 [22:19<02:35, 19.44s/epoch, loss=1.15, accuracy=0.753, val_loss=1.96, val_accuracy=0.531, lr=0.0316] 91%|█████████ | 68/75 [22:40<02:17, 19.70s/epoch, loss=1.15, accuracy=0.751, val_loss=2.82, val_accuracy=0.376, lr=0.1]    92%|█████████▏| 69/75 [22:59<01:58, 19.72s/epoch, loss=1.15, accuracy=0.751, val_loss=1.92, val_accuracy=0.537, lr=0.1] 93%|█████████▎| 70/75 [23:20<01:40, 20.11s/epoch, loss=1.15, accuracy=0.753, val_loss=4.11, val_accuracy=0.273, lr=0.1] 95%|█████████▍| 71/75 [23:39<01:19, 19.76s/epoch, loss=1.14, accuracy=0.753, val_loss=3.73, val_accuracy=0.329, lr=0.1] 96%|█████████▌| 72/75 [23:59<00:58, 19.59s/epoch, loss=1.14, accuracy=0.755, val_loss=2.59, val_accuracy=0.461, lr=0.0316] 97%|█████████▋| 73/75 [24:20<00:39, 20.00s/epoch, loss=1.15, accuracy=0.751, val_loss=1.84, val_accuracy=0.566, lr=0.1]    99%|█████████▊| 74/75 [24:40<00:20, 20.15s/epoch, loss=1.14, accuracy=0.755, val_loss=2.84, val_accuracy=0.288, lr=0.1]100%|██████████| 75/75 [24:59<00:00, 19.79s/epoch, loss=1.15, accuracy=0.752, val_loss=2.5, val_accuracy=0.364, lr=0.1] 100%|██████████| 75/75 [24:59<00:00, 19.99s/epoch, loss=1.15, accuracy=0.752, val_loss=2.5, val_accuracy=0.364, lr=0.1]
Using real-time data augmentation.
Test loss: 2.496321678161621
Test accuracy: 0.36419999599456787


* * * Run SGD for ID = 20_18. * * *


2024-02-16 04:12:51.560537: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-16 04:13:02.026073: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-16 04:13:02.027437: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-16 04:13:02.065644: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-16 04:13:02.065678: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-16 04:13:02.070431: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-16 04:13:02.070479: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-16 04:13:02.072947: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-16 04:13:02.074223: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-16 04:13:02.077178: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-16 04:13:02.079212: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-16 04:13:02.084218: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-16 04:13:02.084824: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-16 04:13:02.084911: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-16 04:13:03.204939: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-16 04:13:03.205928: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-16 04:13:03.206415: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-16 04:13:03.206444: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-16 04:13:03.206478: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-16 04:13:03.206495: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-16 04:13:03.206510: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-16 04:13:03.206526: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-16 04:13:03.206556: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-16 04:13:03.206571: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-16 04:13:03.206586: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-16 04:13:03.207009: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-16 04:13:03.207043: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-16 04:13:03.800787: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-16 04:13:03.800855: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-16 04:13:03.800864: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-16 04:13:03.802061: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': 2018, 'batch_size': 128, 'epochs': 75, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/75 [00:00<?, ?epoch/s]2024-02-16 04:13:04.517375: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-16 04:13:04.517798: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2599900000 Hz
2024-02-16 04:13:06.216244: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-16 04:13:06.493157: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-16 04:13:07.224095: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-16 04:13:07.257227: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|▏         | 1/75 [00:45<55:31, 45.02s/epoch, loss=3.15, accuracy=0.305, val_loss=2.64, val_accuracy=0.224, lr=0.1]  3%|▎         | 2/75 [01:04<36:22, 29.89s/epoch, loss=1.61, accuracy=0.511, val_loss=2.33, val_accuracy=0.389, lr=0.1]  4%|▍         | 3/75 [01:22<29:38, 24.70s/epoch, loss=1.41, accuracy=0.612, val_loss=2.53, val_accuracy=0.316, lr=0.1]  5%|▌         | 4/75 [01:42<26:46, 22.63s/epoch, loss=1.31, accuracy=0.672, val_loss=2.4, val_accuracy=0.355, lr=0.1]   7%|▋         | 5/75 [02:01<25:06, 21.52s/epoch, loss=1.27, accuracy=0.692, val_loss=1.76, val_accuracy=0.527, lr=0.1]  8%|▊         | 6/75 [02:22<24:28, 21.29s/epoch, loss=1.25, accuracy=0.708, val_loss=2.82, val_accuracy=0.335, lr=0.1]  9%|▉         | 7/75 [02:42<23:29, 20.73s/epoch, loss=1.23, accuracy=0.718, val_loss=2.13, val_accuracy=0.391, lr=0.1] 11%|█         | 8/75 [03:03<23:17, 20.86s/epoch, loss=1.22, accuracy=0.72, val_loss=2.13, val_accuracy=0.432, lr=0.1]  12%|█▏        | 9/75 [03:23<22:45, 20.70s/epoch, loss=1.22, accuracy=0.727, val_loss=2.54, val_accuracy=0.446, lr=0.1] 13%|█▎        | 10/75 [03:44<22:27, 20.74s/epoch, loss=1.21, accuracy=0.731, val_loss=1.69, val_accuracy=0.567, lr=0.1] 15%|█▍        | 11/75 [04:04<21:55, 20.55s/epoch, loss=1.21, accuracy=0.732, val_loss=3.75, val_accuracy=0.36, lr=0.1]  16%|█▌        | 12/75 [04:23<21:06, 20.10s/epoch, loss=1.2, accuracy=0.735, val_loss=1.5, val_accuracy=0.632, lr=0.1]  17%|█▋        | 13/75 [04:42<20:18, 19.65s/epoch, loss=1.2, accuracy=0.736, val_loss=2.02, val_accuracy=0.525, lr=0.1] 19%|█▊        | 14/75 [05:01<19:42, 19.38s/epoch, loss=1.2, accuracy=0.736, val_loss=3.1, val_accuracy=0.405, lr=0.1]  20%|██        | 15/75 [05:21<19:32, 19.54s/epoch, loss=1.2, accuracy=0.736, val_loss=2.78, val_accuracy=0.383, lr=0.1] 21%|██▏       | 16/75 [05:39<18:57, 19.29s/epoch, loss=1.19, accuracy=0.74, val_loss=1.88, val_accuracy=0.525, lr=0.1] 23%|██▎       | 17/75 [06:00<19:03, 19.72s/epoch, loss=1.19, accuracy=0.742, val_loss=2.23, val_accuracy=0.465, lr=0.0316] 24%|██▍       | 18/75 [06:20<18:56, 19.94s/epoch, loss=1.19, accuracy=0.742, val_loss=1.47, val_accuracy=0.649, lr=0.1]    25%|██▌       | 19/75 [06:40<18:33, 19.88s/epoch, loss=1.19, accuracy=0.743, val_loss=1.73, val_accuracy=0.595, lr=0.1] 27%|██▋       | 20/75 [07:00<18:09, 19.81s/epoch, loss=1.19, accuracy=0.741, val_loss=2.61, val_accuracy=0.431, lr=0.1] 28%|██▊       | 21/75 [07:19<17:41, 19.66s/epoch, loss=1.18, accuracy=0.745, val_loss=2.17, val_accuracy=0.53, lr=0.1]  29%|██▉       | 22/75 [07:38<17:08, 19.40s/epoch, loss=1.18, accuracy=0.744, val_loss=1.71, val_accuracy=0.584, lr=0.1] 31%|███       | 23/75 [07:57<16:48, 19.39s/epoch, loss=1.17, accuracy=0.748, val_loss=1.81, val_accuracy=0.55, lr=0.0316] 32%|███▏      | 24/75 [08:16<16:23, 19.29s/epoch, loss=1.18, accuracy=0.746, val_loss=2.63, val_accuracy=0.398, lr=0.1]   33%|███▎      | 25/75 [08:36<16:06, 19.33s/epoch, loss=1.17, accuracy=0.747, val_loss=1.92, val_accuracy=0.513, lr=0.1] 35%|███▍      | 26/75 [08:56<15:54, 19.48s/epoch, loss=1.18, accuracy=0.746, val_loss=3.81, val_accuracy=0.181, lr=0.1] 36%|███▌      | 27/75 [09:15<15:27, 19.32s/epoch, loss=1.18, accuracy=0.747, val_loss=1.77, val_accuracy=0.566, lr=0.1] 37%|███▋      | 28/75 [09:34<15:08, 19.34s/epoch, loss=1.17, accuracy=0.749, val_loss=1.73, val_accuracy=0.568, lr=0.0316] 39%|███▊      | 29/75 [09:53<14:44, 19.22s/epoch, loss=1.18, accuracy=0.748, val_loss=2.3, val_accuracy=0.411, lr=0.1]     40%|████      | 30/75 [10:13<14:32, 19.38s/epoch, loss=1.17, accuracy=0.747, val_loss=1.68, val_accuracy=0.556, lr=0.1] 41%|████▏     | 31/75 [10:34<14:32, 19.84s/epoch, loss=1.16, accuracy=0.75, val_loss=2.68, val_accuracy=0.405, lr=0.1]  43%|████▎     | 32/75 [10:54<14:26, 20.16s/epoch, loss=1.17, accuracy=0.751, val_loss=1.83, val_accuracy=0.528, lr=0.1] 44%|████▍     | 33/75 [11:14<13:53, 19.85s/epoch, loss=1.17, accuracy=0.749, val_loss=1.41, val_accuracy=0.675, lr=0.1] 45%|████▌     | 34/75 [11:33<13:28, 19.71s/epoch, loss=1.16, accuracy=0.75, val_loss=1.94, val_accuracy=0.526, lr=0.1]  47%|████▋     | 35/75 [11:52<12:55, 19.39s/epoch, loss=1.15, accuracy=0.753, val_loss=2, val_accuracy=0.478, lr=0.1]   48%|████▊     | 36/75 [12:11<12:36, 19.41s/epoch, loss=1.16, accuracy=0.753, val_loss=1.57, val_accuracy=0.617, lr=0.1] 49%|████▉     | 37/75 [12:32<12:33, 19.83s/epoch, loss=1.16, accuracy=0.752, val_loss=2.12, val_accuracy=0.446, lr=0.1] 51%|█████     | 38/75 [12:51<12:01, 19.51s/epoch, loss=1.16, accuracy=0.753, val_loss=1.82, val_accuracy=0.531, lr=0.0316] 52%|█████▏    | 39/75 [13:11<11:48, 19.67s/epoch, loss=1.16, accuracy=0.749, val_loss=1.85, val_accuracy=0.569, lr=0.1]    53%|█████▎    | 40/75 [13:30<11:28, 19.68s/epoch, loss=1.16, accuracy=0.75, val_loss=1.72, val_accuracy=0.566, lr=0.1]  55%|█████▍    | 41/75 [13:49<11:00, 19.42s/epoch, loss=1.15, accuracy=0.753, val_loss=2.68, val_accuracy=0.373, lr=0.1] 56%|█████▌    | 42/75 [14:08<10:38, 19.35s/epoch, loss=1.16, accuracy=0.75, val_loss=1.98, val_accuracy=0.582, lr=0.1]  57%|█████▋    | 43/75 [14:28<10:22, 19.46s/epoch, loss=1.15, accuracy=0.754, val_loss=2.54, val_accuracy=0.438, lr=0.0316] 59%|█████▊    | 44/75 [14:49<10:13, 19.80s/epoch, loss=1.16, accuracy=0.751, val_loss=1.52, val_accuracy=0.632, lr=0.1]    60%|██████    | 45/75 [15:08<09:47, 19.58s/epoch, loss=1.16, accuracy=0.753, val_loss=1.78, val_accuracy=0.609, lr=0.1] 61%|██████▏   | 46/75 [15:28<09:30, 19.67s/epoch, loss=1.15, accuracy=0.754, val_loss=1.96, val_accuracy=0.527, lr=0.1] 63%|██████▎   | 47/75 [15:46<09:00, 19.29s/epoch, loss=1.15, accuracy=0.75, val_loss=1.53, val_accuracy=0.627, lr=0.1]  64%|██████▍   | 48/75 [16:06<08:49, 19.61s/epoch, loss=1.15, accuracy=0.754, val_loss=1.9, val_accuracy=0.575, lr=0.0316] 65%|██████▌   | 49/75 [16:26<08:33, 19.76s/epoch, loss=1.15, accuracy=0.753, val_loss=1.67, val_accuracy=0.557, lr=0.1]   67%|██████▋   | 50/75 [16:47<08:21, 20.05s/epoch, loss=1.14, accuracy=0.754, val_loss=1.69, val_accuracy=0.61, lr=0.1]  68%|██████▊   | 51/75 [17:07<07:57, 19.89s/epoch, loss=1.15, accuracy=0.754, val_loss=1.6, val_accuracy=0.604, lr=0.1] 69%|██████▉   | 52/75 [17:26<07:31, 19.65s/epoch, loss=1.15, accuracy=0.754, val_loss=2.83, val_accuracy=0.379, lr=0.1] 71%|███████   | 53/75 [17:45<07:06, 19.38s/epoch, loss=1.14, accuracy=0.755, val_loss=1.96, val_accuracy=0.495, lr=0.0316] 72%|███████▏  | 54/75 [18:04<06:47, 19.43s/epoch, loss=1.14, accuracy=0.751, val_loss=1.55, val_accuracy=0.61, lr=0.1]     73%|███████▎  | 55/75 [18:23<06:24, 19.22s/epoch, loss=1.15, accuracy=0.755, val_loss=2.11, val_accuracy=0.474, lr=0.1] 75%|███████▍  | 56/75 [18:42<06:04, 19.17s/epoch, loss=1.15, accuracy=0.754, val_loss=2.26, val_accuracy=0.5, lr=0.1]   76%|███████▌  | 57/75 [19:00<05:40, 18.94s/epoch, loss=1.15, accuracy=0.753, val_loss=2.34, val_accuracy=0.434, lr=0.1] 77%|███████▋  | 58/75 [19:19<05:22, 18.99s/epoch, loss=1.15, accuracy=0.754, val_loss=1.99, val_accuracy=0.462, lr=0.0316] 79%|███████▊  | 59/75 [19:39<05:07, 19.23s/epoch, loss=1.15, accuracy=0.753, val_loss=1.8, val_accuracy=0.534, lr=0.1]     80%|████████  | 60/75 [20:00<04:53, 19.59s/epoch, loss=1.14, accuracy=0.754, val_loss=6.91, val_accuracy=0.265, lr=0.1] 81%|████████▏ | 61/75 [20:19<04:33, 19.55s/epoch, loss=1.14, accuracy=0.753, val_loss=2.5, val_accuracy=0.413, lr=0.1]  83%|████████▎ | 62/75 [20:38<04:13, 19.50s/epoch, loss=1.14, accuracy=0.755, val_loss=3.39, val_accuracy=0.206, lr=0.1] 84%|████████▍ | 63/75 [20:57<03:51, 19.27s/epoch, loss=1.14, accuracy=0.757, val_loss=2.37, val_accuracy=0.326, lr=0.0316] 85%|████████▌ | 64/75 [21:18<03:35, 19.62s/epoch, loss=1.15, accuracy=0.754, val_loss=1.98, val_accuracy=0.503, lr=0.1]    87%|████████▋ | 65/75 [21:37<03:15, 19.50s/epoch, loss=1.14, accuracy=0.757, val_loss=2.49, val_accuracy=0.408, lr=0.1] 88%|████████▊ | 66/75 [21:57<02:56, 19.66s/epoch, loss=1.14, accuracy=0.756, val_loss=1.95, val_accuracy=0.543, lr=0.1] 89%|████████▉ | 67/75 [22:17<02:38, 19.78s/epoch, loss=1.14, accuracy=0.756, val_loss=1.79, val_accuracy=0.536, lr=0.1] 91%|█████████ | 68/75 [22:38<02:20, 20.08s/epoch, loss=1.14, accuracy=0.755, val_loss=1.67, val_accuracy=0.575, lr=0.0316] 92%|█████████▏| 69/75 [22:57<01:58, 19.76s/epoch, loss=1.14, accuracy=0.752, val_loss=1.86, val_accuracy=0.529, lr=0.1]    93%|█████████▎| 70/75 [23:16<01:38, 19.66s/epoch, loss=1.14, accuracy=0.753, val_loss=1.53, val_accuracy=0.625, lr=0.1] 95%|█████████▍| 71/75 [23:35<01:17, 19.34s/epoch, loss=1.14, accuracy=0.754, val_loss=1.6, val_accuracy=0.61, lr=0.1]   96%|█████████▌| 72/75 [23:53<00:57, 19.11s/epoch, loss=1.13, accuracy=0.755, val_loss=1.38, val_accuracy=0.676, lr=0.1] 97%|█████████▋| 73/75 [24:12<00:37, 18.97s/epoch, loss=1.13, accuracy=0.755, val_loss=2.27, val_accuracy=0.434, lr=0.1] 99%|█████████▊| 74/75 [24:33<00:19, 19.63s/epoch, loss=1.14, accuracy=0.755, val_loss=1.64, val_accuracy=0.594, lr=0.1]100%|██████████| 75/75 [24:52<00:00, 19.33s/epoch, loss=1.13, accuracy=0.756, val_loss=1.99, val_accuracy=0.533, lr=0.1]100%|██████████| 75/75 [24:52<00:00, 19.90s/epoch, loss=1.13, accuracy=0.756, val_loss=1.99, val_accuracy=0.533, lr=0.1]
Using real-time data augmentation.
Test loss: 1.9855289459228516
Test accuracy: 0.5328999757766724


* * * Run SGD for ID = 20_19. * * *


2024-02-16 04:37:59.257903: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-16 04:38:01.751149: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-16 04:38:01.752311: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-16 04:38:01.787362: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-16 04:38:01.787399: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-16 04:38:01.790020: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-16 04:38:01.790055: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-16 04:38:01.792036: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-16 04:38:01.793093: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-16 04:38:01.795222: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-16 04:38:01.796550: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-16 04:38:01.800930: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-16 04:38:01.801417: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-16 04:38:01.801504: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-16 04:38:02.912308: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-16 04:38:02.913032: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-16 04:38:02.913603: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-16 04:38:02.913633: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-16 04:38:02.913680: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-16 04:38:02.913699: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-16 04:38:02.913717: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-16 04:38:02.913734: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-16 04:38:02.913751: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-16 04:38:02.913768: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-16 04:38:02.913785: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-16 04:38:02.914196: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-16 04:38:02.914229: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-16 04:38:03.471415: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-16 04:38:03.471472: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-16 04:38:03.471480: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-16 04:38:03.472319: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': 2019, 'batch_size': 128, 'epochs': 75, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/75 [00:00<?, ?epoch/s]2024-02-16 04:38:04.174044: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-16 04:38:04.174451: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2599900000 Hz
2024-02-16 04:38:05.838195: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-16 04:38:06.046663: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-16 04:38:06.751960: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-16 04:38:06.784912: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|▏         | 1/75 [00:40<49:56, 40.50s/epoch, loss=3.13, accuracy=0.313, val_loss=2.64, val_accuracy=0.235, lr=0.1]  3%|▎         | 2/75 [01:00<34:24, 28.29s/epoch, loss=1.54, accuracy=0.537, val_loss=2.26, val_accuracy=0.37, lr=0.1]   4%|▍         | 3/75 [01:21<30:03, 25.05s/epoch, loss=1.32, accuracy=0.65, val_loss=2.14, val_accuracy=0.419, lr=0.1]  5%|▌         | 4/75 [01:41<27:13, 23.00s/epoch, loss=1.26, accuracy=0.684, val_loss=2.01, val_accuracy=0.507, lr=0.1]  7%|▋         | 5/75 [02:00<25:19, 21.71s/epoch, loss=1.24, accuracy=0.7, val_loss=3.11, val_accuracy=0.325, lr=0.1]    8%|▊         | 6/75 [02:19<23:59, 20.86s/epoch, loss=1.22, accuracy=0.709, val_loss=2.94, val_accuracy=0.348, lr=0.1]  9%|▉         | 7/75 [02:40<23:34, 20.80s/epoch, loss=1.21, accuracy=0.715, val_loss=1.53, val_accuracy=0.612, lr=0.1] 11%|█         | 8/75 [03:00<22:52, 20.48s/epoch, loss=1.21, accuracy=0.721, val_loss=2.26, val_accuracy=0.431, lr=0.1] 12%|█▏        | 9/75 [03:19<22:13, 20.20s/epoch, loss=1.2, accuracy=0.728, val_loss=2.08, val_accuracy=0.496, lr=0.1]  13%|█▎        | 10/75 [03:41<22:18, 20.59s/epoch, loss=1.2, accuracy=0.729, val_loss=2.19, val_accuracy=0.435, lr=0.1] 15%|█▍        | 11/75 [04:01<21:40, 20.32s/epoch, loss=1.19, accuracy=0.733, val_loss=2.16, val_accuracy=0.47, lr=0.1] 16%|█▌        | 12/75 [04:20<21:10, 20.17s/epoch, loss=1.19, accuracy=0.733, val_loss=1.57, val_accuracy=0.587, lr=0.0316] 17%|█▋        | 13/75 [04:40<20:41, 20.03s/epoch, loss=1.19, accuracy=0.734, val_loss=2.94, val_accuracy=0.433, lr=0.1]    19%|█▊        | 14/75 [05:00<20:14, 19.91s/epoch, loss=1.18, accuracy=0.737, val_loss=1.75, val_accuracy=0.558, lr=0.1] 20%|██        | 15/75 [05:19<19:49, 19.83s/epoch, loss=1.18, accuracy=0.739, val_loss=2.92, val_accuracy=0.369, lr=0.1] 21%|██▏       | 16/75 [05:39<19:29, 19.83s/epoch, loss=1.18, accuracy=0.74, val_loss=2.99, val_accuracy=0.373, lr=0.1]  23%|██▎       | 17/75 [05:59<19:14, 19.91s/epoch, loss=1.17, accuracy=0.739, val_loss=3.07, val_accuracy=0.399, lr=0.0316] 24%|██▍       | 18/75 [06:19<18:58, 19.97s/epoch, loss=1.18, accuracy=0.739, val_loss=1.55, val_accuracy=0.606, lr=0.1]    25%|██▌       | 19/75 [06:40<18:39, 19.99s/epoch, loss=1.16, accuracy=0.743, val_loss=1.75, val_accuracy=0.581, lr=0.1] 27%|██▋       | 20/75 [06:59<18:08, 19.80s/epoch, loss=1.17, accuracy=0.742, val_loss=1.55, val_accuracy=0.601, lr=0.1] 28%|██▊       | 21/75 [07:20<18:08, 20.16s/epoch, loss=1.17, accuracy=0.744, val_loss=2.67, val_accuracy=0.393, lr=0.1] 29%|██▉       | 22/75 [07:40<17:47, 20.14s/epoch, loss=1.17, accuracy=0.746, val_loss=2.96, val_accuracy=0.31, lr=0.0316] 31%|███       | 23/75 [07:59<17:07, 19.75s/epoch, loss=1.16, accuracy=0.745, val_loss=2.74, val_accuracy=0.396, lr=0.1]   32%|███▏      | 24/75 [08:18<16:40, 19.62s/epoch, loss=1.16, accuracy=0.747, val_loss=2.16, val_accuracy=0.446, lr=0.1] 33%|███▎      | 25/75 [08:38<16:19, 19.60s/epoch, loss=1.16, accuracy=0.748, val_loss=1.82, val_accuracy=0.531, lr=0.1] 35%|███▍      | 26/75 [08:58<16:06, 19.72s/epoch, loss=1.16, accuracy=0.748, val_loss=5.53, val_accuracy=0.297, lr=0.1] 36%|███▌      | 27/75 [09:16<15:32, 19.43s/epoch, loss=1.15, accuracy=0.747, val_loss=2.16, val_accuracy=0.449, lr=0.0316] 37%|███▋      | 28/75 [09:37<15:23, 19.65s/epoch, loss=1.15, accuracy=0.749, val_loss=2.69, val_accuracy=0.325, lr=0.1]    39%|███▊      | 29/75 [09:56<14:54, 19.45s/epoch, loss=1.15, accuracy=0.748, val_loss=3.97, val_accuracy=0.326, lr=0.1] 40%|████      | 30/75 [10:15<14:34, 19.43s/epoch, loss=1.15, accuracy=0.749, val_loss=2.12, val_accuracy=0.516, lr=0.1] 41%|████▏     | 31/75 [10:34<14:13, 19.41s/epoch, loss=1.15, accuracy=0.75, val_loss=2.3, val_accuracy=0.393, lr=0.1]   43%|████▎     | 32/75 [10:54<14:02, 19.60s/epoch, loss=1.15, accuracy=0.75, val_loss=1.85, val_accuracy=0.574, lr=0.0316] 44%|████▍     | 33/75 [11:13<13:35, 19.42s/epoch, loss=1.15, accuracy=0.749, val_loss=1.95, val_accuracy=0.495, lr=0.1]   45%|████▌     | 34/75 [11:32<13:09, 19.26s/epoch, loss=1.14, accuracy=0.751, val_loss=2.64, val_accuracy=0.43, lr=0.1]  47%|████▋     | 35/75 [11:51<12:46, 19.16s/epoch, loss=1.14, accuracy=0.751, val_loss=1.44, val_accuracy=0.642, lr=0.1] 48%|████▊     | 36/75 [12:11<12:31, 19.26s/epoch, loss=1.14, accuracy=0.751, val_loss=3.02, val_accuracy=0.212, lr=0.1] 49%|████▉     | 37/75 [12:30<12:10, 19.23s/epoch, loss=1.13, accuracy=0.755, val_loss=2.21, val_accuracy=0.519, lr=0.1] 51%|█████     | 38/75 [12:49<11:49, 19.18s/epoch, loss=1.14, accuracy=0.753, val_loss=2.45, val_accuracy=0.332, lr=0.1] 52%|█████▏    | 39/75 [13:08<11:33, 19.26s/epoch, loss=1.13, accuracy=0.753, val_loss=1.71, val_accuracy=0.573, lr=0.1] 53%|█████▎    | 40/75 [13:27<11:12, 19.21s/epoch, loss=1.13, accuracy=0.753, val_loss=2.14, val_accuracy=0.5, lr=0.0316] 55%|█████▍    | 41/75 [13:47<10:55, 19.28s/epoch, loss=1.14, accuracy=0.753, val_loss=3.43, val_accuracy=0.35, lr=0.1]   56%|█████▌    | 42/75 [14:06<10:36, 19.28s/epoch, loss=1.13, accuracy=0.756, val_loss=2.19, val_accuracy=0.509, lr=0.1] 57%|█████▋    | 43/75 [14:27<10:31, 19.73s/epoch, loss=1.14, accuracy=0.754, val_loss=2.25, val_accuracy=0.345, lr=0.1] 59%|█████▊    | 44/75 [14:47<10:10, 19.69s/epoch, loss=1.14, accuracy=0.753, val_loss=1.73, val_accuracy=0.606, lr=0.1] 60%|██████    | 45/75 [15:06<09:44, 19.49s/epoch, loss=1.13, accuracy=0.753, val_loss=3.4, val_accuracy=0.357, lr=0.0316] 61%|██████▏   | 46/75 [15:25<09:27, 19.57s/epoch, loss=1.14, accuracy=0.752, val_loss=3.89, val_accuracy=0.244, lr=0.1]   63%|██████▎   | 47/75 [15:47<09:24, 20.15s/epoch, loss=1.13, accuracy=0.754, val_loss=1.53, val_accuracy=0.626, lr=0.1] 64%|██████▍   | 48/75 [16:08<09:09, 20.36s/epoch, loss=1.13, accuracy=0.755, val_loss=1.78, val_accuracy=0.526, lr=0.1] 65%|██████▌   | 49/75 [16:29<08:55, 20.61s/epoch, loss=1.12, accuracy=0.755, val_loss=2.28, val_accuracy=0.472, lr=0.1] 67%|██████▋   | 50/75 [16:48<08:27, 20.31s/epoch, loss=1.13, accuracy=0.754, val_loss=3.48, val_accuracy=0.255, lr=0.0316] 68%|██████▊   | 51/75 [17:10<08:12, 20.53s/epoch, loss=1.13, accuracy=0.753, val_loss=1.56, val_accuracy=0.614, lr=0.1]    69%|██████▉   | 52/75 [17:30<07:50, 20.44s/epoch, loss=1.13, accuracy=0.756, val_loss=2.38, val_accuracy=0.392, lr=0.1] 71%|███████   | 53/75 [17:50<07:26, 20.31s/epoch, loss=1.13, accuracy=0.755, val_loss=3.91, val_accuracy=0.296, lr=0.1] 72%|███████▏  | 54/75 [18:10<07:04, 20.23s/epoch, loss=1.13, accuracy=0.754, val_loss=1.98, val_accuracy=0.486, lr=0.1] 73%|███████▎  | 55/75 [18:29<06:37, 19.85s/epoch, loss=1.12, accuracy=0.756, val_loss=1.9, val_accuracy=0.531, lr=0.0316] 75%|███████▍  | 56/75 [18:49<06:17, 19.89s/epoch, loss=1.13, accuracy=0.755, val_loss=2.15, val_accuracy=0.459, lr=0.1]   76%|███████▌  | 57/75 [19:09<05:59, 19.96s/epoch, loss=1.12, accuracy=0.755, val_loss=1.99, val_accuracy=0.502, lr=0.1] 77%|███████▋  | 58/75 [19:30<05:43, 20.21s/epoch, loss=1.13, accuracy=0.752, val_loss=3.26, val_accuracy=0.3, lr=0.1]   79%|███████▊  | 59/75 [19:49<05:19, 19.94s/epoch, loss=1.12, accuracy=0.757, val_loss=2, val_accuracy=0.51, lr=0.1]   80%|████████  | 60/75 [20:09<04:57, 19.81s/epoch, loss=1.12, accuracy=0.756, val_loss=2.37, val_accuracy=0.491, lr=0.0316] 81%|████████▏ | 61/75 [20:27<04:31, 19.42s/epoch, loss=1.12, accuracy=0.757, val_loss=2.26, val_accuracy=0.48, lr=0.1]     83%|████████▎ | 62/75 [20:46<04:10, 19.30s/epoch, loss=1.12, accuracy=0.756, val_loss=4.36, val_accuracy=0.329, lr=0.1] 84%|████████▍ | 63/75 [21:06<03:52, 19.39s/epoch, loss=1.12, accuracy=0.756, val_loss=2.51, val_accuracy=0.375, lr=0.1] 85%|████████▌ | 64/75 [21:25<03:33, 19.38s/epoch, loss=1.12, accuracy=0.757, val_loss=1.94, val_accuracy=0.499, lr=0.1] 87%|████████▋ | 65/75 [21:44<03:13, 19.33s/epoch, loss=1.13, accuracy=0.753, val_loss=1.63, val_accuracy=0.601, lr=0.0316] 88%|████████▊ | 66/75 [22:03<02:53, 19.28s/epoch, loss=1.12, accuracy=0.755, val_loss=3.9, val_accuracy=0.326, lr=0.1]     89%|████████▉ | 67/75 [22:22<02:33, 19.20s/epoch, loss=1.12, accuracy=0.757, val_loss=2.71, val_accuracy=0.453, lr=0.1] 91%|█████████ | 68/75 [22:41<02:13, 19.08s/epoch, loss=1.12, accuracy=0.757, val_loss=1.76, val_accuracy=0.559, lr=0.1] 92%|█████████▏| 69/75 [23:00<01:53, 18.99s/epoch, loss=1.11, accuracy=0.759, val_loss=3.75, val_accuracy=0.221, lr=0.1] 93%|█████████▎| 70/75 [23:20<01:36, 19.35s/epoch, loss=1.12, accuracy=0.756, val_loss=3.09, val_accuracy=0.353, lr=0.0316] 95%|█████████▍| 71/75 [23:39<01:16, 19.20s/epoch, loss=1.11, accuracy=0.762, val_loss=2.4, val_accuracy=0.408, lr=0.1]     96%|█████████▌| 72/75 [23:59<00:58, 19.52s/epoch, loss=1.12, accuracy=0.757, val_loss=2.61, val_accuracy=0.295, lr=0.1] 97%|█████████▋| 73/75 [24:20<00:39, 19.88s/epoch, loss=1.12, accuracy=0.757, val_loss=2.28, val_accuracy=0.44, lr=0.1]  99%|█████████▊| 74/75 [24:39<00:19, 19.64s/epoch, loss=1.12, accuracy=0.756, val_loss=4.37, val_accuracy=0.313, lr=0.1]100%|██████████| 75/75 [24:59<00:00, 19.59s/epoch, loss=1.11, accuracy=0.757, val_loss=1.8, val_accuracy=0.555, lr=0.0316]100%|██████████| 75/75 [24:59<00:00, 19.99s/epoch, loss=1.11, accuracy=0.757, val_loss=1.8, val_accuracy=0.555, lr=0.0316]
Using real-time data augmentation.
Test loss: 1.799136757850647
Test accuracy: 0.5547999739646912


* * * Run SGD for ID = 20_20. * * *


2024-02-16 05:03:05.432853: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-16 05:03:08.299396: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-16 05:03:08.300474: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-16 05:03:08.335703: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-16 05:03:08.335731: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-16 05:03:08.338851: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-16 05:03:08.338889: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-16 05:03:08.341104: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-16 05:03:08.341798: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-16 05:03:08.344164: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-16 05:03:08.345735: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-16 05:03:08.350374: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-16 05:03:08.350885: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-16 05:03:08.350963: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-16 05:03:09.475353: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-16 05:03:09.475819: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-16 05:03:09.476426: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-16 05:03:09.476456: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-16 05:03:09.476506: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-16 05:03:09.476526: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-16 05:03:09.476545: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-16 05:03:09.476564: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-16 05:03:09.476582: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-16 05:03:09.476600: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-16 05:03:09.476618: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-16 05:03:09.477038: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-16 05:03:09.477069: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-16 05:03:10.052574: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-16 05:03:10.052649: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-16 05:03:10.052660: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-16 05:03:10.053571: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': 2020, 'batch_size': 128, 'epochs': 75, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/75 [00:00<?, ?epoch/s]2024-02-16 05:03:10.771714: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-16 05:03:10.783473: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2599900000 Hz
2024-02-16 05:03:12.481133: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-16 05:03:12.736675: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-16 05:03:13.450677: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-16 05:03:13.481227: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|▏         | 1/75 [00:43<53:48, 43.62s/epoch, loss=3.26, accuracy=0.265, val_loss=2.16, val_accuracy=0.279, lr=0.1]  3%|▎         | 2/75 [01:02<35:38, 29.30s/epoch, loss=1.64, accuracy=0.486, val_loss=3.02, val_accuracy=0.28, lr=0.1]   4%|▍         | 3/75 [01:21<29:21, 24.47s/epoch, loss=1.42, accuracy=0.603, val_loss=2.18, val_accuracy=0.489, lr=0.1]  5%|▌         | 4/75 [01:40<26:12, 22.15s/epoch, loss=1.31, accuracy=0.664, val_loss=1.75, val_accuracy=0.54, lr=0.1]   7%|▋         | 5/75 [01:59<24:31, 21.03s/epoch, loss=1.26, accuracy=0.691, val_loss=2.14, val_accuracy=0.467, lr=0.1]  8%|▊         | 6/75 [02:18<23:18, 20.27s/epoch, loss=1.25, accuracy=0.705, val_loss=1.55, val_accuracy=0.594, lr=0.1]  9%|▉         | 7/75 [02:36<22:24, 19.77s/epoch, loss=1.23, accuracy=0.712, val_loss=1.6, val_accuracy=0.602, lr=0.1]  11%|█         | 8/75 [02:55<21:42, 19.44s/epoch, loss=1.21, accuracy=0.722, val_loss=1.49, val_accuracy=0.629, lr=0.1] 12%|█▏        | 9/75 [03:14<21:19, 19.39s/epoch, loss=1.21, accuracy=0.723, val_loss=1.43, val_accuracy=0.645, lr=0.1] 13%|█▎        | 10/75 [03:33<20:48, 19.21s/epoch, loss=1.2, accuracy=0.729, val_loss=2.38, val_accuracy=0.445, lr=0.1] 15%|█▍        | 11/75 [03:52<20:18, 19.03s/epoch, loss=1.19, accuracy=0.731, val_loss=2.17, val_accuracy=0.432, lr=0.1] 16%|█▌        | 12/75 [04:11<19:56, 18.99s/epoch, loss=1.19, accuracy=0.736, val_loss=3.63, val_accuracy=0.363, lr=0.1] 17%|█▋        | 13/75 [04:32<20:20, 19.69s/epoch, loss=1.18, accuracy=0.739, val_loss=1.59, val_accuracy=0.568, lr=0.1] 19%|█▊        | 14/75 [04:51<19:44, 19.42s/epoch, loss=1.18, accuracy=0.738, val_loss=2.73, val_accuracy=0.374, lr=0.0316] 20%|██        | 15/75 [05:11<19:40, 19.67s/epoch, loss=1.18, accuracy=0.74, val_loss=1.53, val_accuracy=0.626, lr=0.1]     21%|██▏       | 16/75 [05:31<19:26, 19.77s/epoch, loss=1.18, accuracy=0.74, val_loss=2.22, val_accuracy=0.439, lr=0.1] 23%|██▎       | 17/75 [05:50<18:55, 19.58s/epoch, loss=1.17, accuracy=0.742, val_loss=2.24, val_accuracy=0.503, lr=0.1] 24%|██▍       | 18/75 [06:10<18:33, 19.54s/epoch, loss=1.16, accuracy=0.744, val_loss=1.41, val_accuracy=0.659, lr=0.1] 25%|██▌       | 19/75 [06:29<18:11, 19.49s/epoch, loss=1.16, accuracy=0.746, val_loss=2.28, val_accuracy=0.499, lr=0.1] 27%|██▋       | 20/75 [06:49<18:01, 19.66s/epoch, loss=1.15, accuracy=0.745, val_loss=1.99, val_accuracy=0.489, lr=0.1] 28%|██▊       | 21/75 [07:08<17:37, 19.59s/epoch, loss=1.16, accuracy=0.745, val_loss=1.68, val_accuracy=0.6, lr=0.1]   29%|██▉       | 22/75 [07:27<17:05, 19.35s/epoch, loss=1.15, accuracy=0.749, val_loss=2.1, val_accuracy=0.469, lr=0.1] 31%|███       | 23/75 [07:46<16:37, 19.18s/epoch, loss=1.15, accuracy=0.749, val_loss=2.23, val_accuracy=0.46, lr=0.0316] 32%|███▏      | 24/75 [08:05<16:15, 19.13s/epoch, loss=1.14, accuracy=0.75, val_loss=1.61, val_accuracy=0.624, lr=0.1]    33%|███▎      | 25/75 [08:25<16:03, 19.26s/epoch, loss=1.14, accuracy=0.751, val_loss=2.23, val_accuracy=0.499, lr=0.1] 35%|███▍      | 26/75 [08:44<15:41, 19.21s/epoch, loss=1.14, accuracy=0.753, val_loss=2.21, val_accuracy=0.429, lr=0.1] 36%|███▌      | 27/75 [09:03<15:30, 19.40s/epoch, loss=1.14, accuracy=0.752, val_loss=3.42, val_accuracy=0.248, lr=0.1] 37%|███▋      | 28/75 [09:23<15:08, 19.34s/epoch, loss=1.14, accuracy=0.75, val_loss=4.35, val_accuracy=0.314, lr=0.0316] 39%|███▊      | 29/75 [09:42<14:46, 19.28s/epoch, loss=1.13, accuracy=0.753, val_loss=2.4, val_accuracy=0.431, lr=0.1]    40%|████      | 30/75 [10:02<14:40, 19.57s/epoch, loss=1.14, accuracy=0.751, val_loss=2.09, val_accuracy=0.476, lr=0.1] 41%|████▏     | 31/75 [10:23<14:39, 19.99s/epoch, loss=1.13, accuracy=0.754, val_loss=2.89, val_accuracy=0.389, lr=0.1] 43%|████▎     | 32/75 [10:44<14:26, 20.14s/epoch, loss=1.13, accuracy=0.754, val_loss=1.88, val_accuracy=0.522, lr=0.1] 44%|████▍     | 33/75 [11:03<13:58, 19.95s/epoch, loss=1.13, accuracy=0.753, val_loss=1.73, val_accuracy=0.549, lr=0.0316] 45%|████▌     | 34/75 [11:22<13:29, 19.74s/epoch, loss=1.13, accuracy=0.754, val_loss=1.49, val_accuracy=0.632, lr=0.1]    47%|████▋     | 35/75 [11:42<13:13, 19.85s/epoch, loss=1.13, accuracy=0.752, val_loss=2.28, val_accuracy=0.487, lr=0.1] 48%|████▊     | 36/75 [12:02<12:49, 19.72s/epoch, loss=1.12, accuracy=0.752, val_loss=2.85, val_accuracy=0.396, lr=0.1] 49%|████▉     | 37/75 [12:21<12:19, 19.47s/epoch, loss=1.13, accuracy=0.752, val_loss=1.88, val_accuracy=0.5, lr=0.1]   51%|█████     | 38/75 [12:41<12:05, 19.61s/epoch, loss=1.13, accuracy=0.755, val_loss=3.15, val_accuracy=0.301, lr=0.0316] 52%|█████▏    | 39/75 [13:02<12:00, 20.01s/epoch, loss=1.13, accuracy=0.752, val_loss=2.73, val_accuracy=0.417, lr=0.1]    53%|█████▎    | 40/75 [13:21<11:30, 19.72s/epoch, loss=1.13, accuracy=0.754, val_loss=1.79, val_accuracy=0.522, lr=0.1] 55%|█████▍    | 41/75 [13:40<11:04, 19.55s/epoch, loss=1.12, accuracy=0.754, val_loss=1.94, val_accuracy=0.443, lr=0.1] 56%|█████▌    | 42/75 [14:00<10:47, 19.63s/epoch, loss=1.12, accuracy=0.755, val_loss=1.78, val_accuracy=0.585, lr=0.1] 57%|█████▋    | 43/75 [14:19<10:21, 19.43s/epoch, loss=1.12, accuracy=0.756, val_loss=1.69, val_accuracy=0.562, lr=0.0316] 59%|█████▊    | 44/75 [14:40<10:20, 20.01s/epoch, loss=1.12, accuracy=0.754, val_loss=2.72, val_accuracy=0.483, lr=0.1]    60%|██████    | 45/75 [14:59<09:49, 19.65s/epoch, loss=1.12, accuracy=0.757, val_loss=1.67, val_accuracy=0.549, lr=0.1] 61%|██████▏   | 46/75 [15:20<09:45, 20.19s/epoch, loss=1.12, accuracy=0.755, val_loss=2.89, val_accuracy=0.357, lr=0.1] 63%|██████▎   | 47/75 [15:39<09:17, 19.92s/epoch, loss=1.12, accuracy=0.757, val_loss=2.47, val_accuracy=0.373, lr=0.1] 64%|██████▍   | 48/75 [15:59<08:54, 19.79s/epoch, loss=1.12, accuracy=0.754, val_loss=5.1, val_accuracy=0.266, lr=0.0316] 65%|██████▌   | 49/75 [16:19<08:40, 20.01s/epoch, loss=1.12, accuracy=0.757, val_loss=4.27, val_accuracy=0.161, lr=0.1]   67%|██████▋   | 50/75 [16:38<08:11, 19.68s/epoch, loss=1.13, accuracy=0.754, val_loss=3.76, val_accuracy=0.243, lr=0.1] 68%|██████▊   | 51/75 [16:59<07:56, 19.87s/epoch, loss=1.12, accuracy=0.757, val_loss=4.56, val_accuracy=0.271, lr=0.1] 69%|██████▉   | 52/75 [17:18<07:36, 19.83s/epoch, loss=1.12, accuracy=0.756, val_loss=3.93, val_accuracy=0.237, lr=0.1] 71%|███████   | 53/75 [17:38<07:16, 19.83s/epoch, loss=1.12, accuracy=0.757, val_loss=2.86, val_accuracy=0.328, lr=0.0316] 72%|███████▏  | 54/75 [17:58<06:56, 19.83s/epoch, loss=1.11, accuracy=0.757, val_loss=1.94, val_accuracy=0.495, lr=0.1]    73%|███████▎  | 55/75 [18:18<06:36, 19.83s/epoch, loss=1.11, accuracy=0.758, val_loss=1.55, val_accuracy=0.598, lr=0.1] 75%|███████▍  | 56/75 [18:39<06:23, 20.16s/epoch, loss=1.11, accuracy=0.754, val_loss=3.23, val_accuracy=0.376, lr=0.1] 76%|███████▌  | 57/75 [18:58<05:56, 19.79s/epoch, loss=1.11, accuracy=0.756, val_loss=2.37, val_accuracy=0.432, lr=0.1] 77%|███████▋  | 58/75 [19:18<05:40, 20.03s/epoch, loss=1.12, accuracy=0.755, val_loss=1.55, val_accuracy=0.61, lr=0.0316] 79%|███████▊  | 59/75 [19:37<05:14, 19.66s/epoch, loss=1.11, accuracy=0.756, val_loss=1.91, val_accuracy=0.556, lr=0.1]   80%|████████  | 60/75 [19:56<04:51, 19.44s/epoch, loss=1.11, accuracy=0.758, val_loss=1.76, val_accuracy=0.565, lr=0.1] 81%|████████▏ | 61/75 [20:16<04:35, 19.67s/epoch, loss=1.11, accuracy=0.758, val_loss=1.93, val_accuracy=0.465, lr=0.1] 83%|████████▎ | 62/75 [20:35<04:11, 19.38s/epoch, loss=1.11, accuracy=0.759, val_loss=1.65, val_accuracy=0.619, lr=0.1] 84%|████████▍ | 63/75 [20:55<03:56, 19.67s/epoch, loss=1.11, accuracy=0.756, val_loss=1.92, val_accuracy=0.568, lr=0.0316] 85%|████████▌ | 64/75 [21:14<03:34, 19.50s/epoch, loss=1.11, accuracy=0.755, val_loss=2.14, val_accuracy=0.5, lr=0.1]      87%|████████▋ | 65/75 [21:34<03:15, 19.51s/epoch, loss=1.11, accuracy=0.757, val_loss=1.5, val_accuracy=0.641, lr=0.1] 88%|████████▊ | 66/75 [21:53<02:54, 19.34s/epoch, loss=1.11, accuracy=0.756, val_loss=1.61, val_accuracy=0.59, lr=0.1] 89%|████████▉ | 67/75 [22:12<02:33, 19.15s/epoch, loss=1.11, accuracy=0.758, val_loss=1.68, val_accuracy=0.62, lr=0.1] 91%|█████████ | 68/75 [22:32<02:17, 19.64s/epoch, loss=1.12, accuracy=0.755, val_loss=3.64, val_accuracy=0.356, lr=0.0316] 92%|█████████▏| 69/75 [22:52<01:57, 19.55s/epoch, loss=1.11, accuracy=0.756, val_loss=2.07, val_accuracy=0.528, lr=0.1]    93%|█████████▎| 70/75 [23:11<01:36, 19.38s/epoch, loss=1.11, accuracy=0.755, val_loss=2.08, val_accuracy=0.498, lr=0.1] 95%|█████████▍| 71/75 [23:31<01:18, 19.54s/epoch, loss=1.11, accuracy=0.756, val_loss=2.63, val_accuracy=0.395, lr=0.1] 96%|█████████▌| 72/75 [23:50<00:58, 19.34s/epoch, loss=1.12, accuracy=0.756, val_loss=1.82, val_accuracy=0.532, lr=0.1] 97%|█████████▋| 73/75 [24:10<00:39, 19.64s/epoch, loss=1.11, accuracy=0.755, val_loss=2.07, val_accuracy=0.444, lr=0.0316] 99%|█████████▊| 74/75 [24:29<00:19, 19.39s/epoch, loss=1.12, accuracy=0.756, val_loss=1.67, val_accuracy=0.555, lr=0.1]   100%|██████████| 75/75 [24:48<00:00, 19.23s/epoch, loss=1.1, accuracy=0.758, val_loss=1.91, val_accuracy=0.58, lr=0.1]  100%|██████████| 75/75 [24:48<00:00, 19.84s/epoch, loss=1.1, accuracy=0.758, val_loss=1.91, val_accuracy=0.58, lr=0.1]
Using real-time data augmentation.
Test loss: 1.9126722812652588
Test accuracy: 0.5799999833106995
