Tue Mar  5 13:25:57 2024       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 545.23.08              Driver Version: 545.23.08    CUDA Version: 12.3     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA TITAN Xp                Off | 00000000:02:00.0 Off |                  N/A |
| 46%   70C    P0              87W / 250W |      0MiB / 12288MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|  No running processes found                                                           |
+---------------------------------------------------------------------------------------+


* * * Run SGD for cluster size = 20. * * *


Budget: 75


* * * Run SGD for ID = 20_1. * * *


2024-03-05 13:25:58.093811: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 13:26:07.206345: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 13:26:07.208275: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-05 13:26:07.251522: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-05 13:26:07.251554: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 13:26:07.289198: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 13:26:07.289248: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 13:26:07.323768: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 13:26:07.358983: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 13:26:07.401411: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 13:26:07.436476: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 13:26:07.463059: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 13:26:07.463896: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 13:26:07.463979: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 13:26:08.712684: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-05 13:26:08.714013: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 13:26:08.714522: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-05 13:26:08.714554: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 13:26:08.714585: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 13:26:08.714602: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 13:26:08.714618: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 13:26:08.714633: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 13:26:08.714649: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 13:26:08.714665: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 13:26:08.714681: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 13:26:08.715158: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 13:26:08.715193: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 13:26:09.690387: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-05 13:26:09.690459: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-05 13:26:09.690470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-05 13:26:09.691785: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:02:00.0, compute capability: 6.1)
{'id': '20_01', 'seed': 1, 'out_folder': 'results/epoch_budget', 'batch_size': 128, 'epochs': 75, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'bootstrapping': False, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/75 [00:00<?, ?epoch/s]2024-03-05 13:26:10.525354: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-05 13:26:10.537167: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199825000 Hz
2024-03-05 13:26:12.507628: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 13:26:12.756863: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 13:26:13.461649: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-05 13:26:13.494435: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|▏         | 1/75 [00:50<1:02:37, 50.78s/epoch, loss=3.25, accuracy=0.298, val_loss=2.89, val_accuracy=0.221, lr=0.1]  3%|▎         | 2/75 [01:14<42:38, 35.05s/epoch, loss=1.67, accuracy=0.468, val_loss=1.7, val_accuracy=0.457, lr=0.1]     4%|▍         | 3/75 [01:38<35:54, 29.93s/epoch, loss=1.43, accuracy=0.593, val_loss=1.96, val_accuracy=0.431, lr=0.1]  5%|▌         | 4/75 [02:02<32:31, 27.49s/epoch, loss=1.3, accuracy=0.665, val_loss=2.04, val_accuracy=0.484, lr=0.1]   7%|▋         | 5/75 [02:26<30:26, 26.10s/epoch, loss=1.27, accuracy=0.694, val_loss=1.82, val_accuracy=0.51, lr=0.1]  8%|▊         | 6/75 [02:49<29:00, 25.22s/epoch, loss=1.25, accuracy=0.71, val_loss=2.7, val_accuracy=0.383, lr=0.1]   9%|▉         | 7/75 [03:13<27:55, 24.64s/epoch, loss=1.23, accuracy=0.72, val_loss=2.35, val_accuracy=0.433, lr=0.0316] 11%|█         | 8/75 [03:35<26:46, 23.98s/epoch, loss=1.22, accuracy=0.725, val_loss=2.75, val_accuracy=0.391, lr=0.1]   12%|█▏        | 9/75 [03:58<26:10, 23.80s/epoch, loss=1.22, accuracy=0.726, val_loss=2.9, val_accuracy=0.347, lr=0.1]  13%|█▎        | 10/75 [04:22<25:44, 23.75s/epoch, loss=1.21, accuracy=0.732, val_loss=2.47, val_accuracy=0.331, lr=0.1] 15%|█▍        | 11/75 [04:46<25:19, 23.74s/epoch, loss=1.2, accuracy=0.732, val_loss=2.15, val_accuracy=0.462, lr=0.1]  16%|█▌        | 12/75 [05:09<24:44, 23.56s/epoch, loss=1.2, accuracy=0.737, val_loss=3.2, val_accuracy=0.366, lr=0.0316] 17%|█▋        | 13/75 [05:32<24:14, 23.46s/epoch, loss=1.19, accuracy=0.737, val_loss=4.06, val_accuracy=0.251, lr=0.1]  19%|█▊        | 14/75 [05:54<23:29, 23.10s/epoch, loss=1.2, accuracy=0.737, val_loss=2.24, val_accuracy=0.525, lr=0.1]  20%|██        | 15/75 [06:17<22:47, 22.79s/epoch, loss=1.19, accuracy=0.737, val_loss=2.55, val_accuracy=0.345, lr=0.1] 21%|██▏       | 16/75 [06:39<22:12, 22.58s/epoch, loss=1.19, accuracy=0.741, val_loss=2.42, val_accuracy=0.44, lr=0.1]  23%|██▎       | 17/75 [07:02<22:06, 22.88s/epoch, loss=1.19, accuracy=0.741, val_loss=2.39, val_accuracy=0.443, lr=0.0316] 24%|██▍       | 18/75 [07:24<21:32, 22.67s/epoch, loss=1.18, accuracy=0.742, val_loss=2.44, val_accuracy=0.461, lr=0.1]    25%|██▌       | 19/75 [07:46<20:58, 22.48s/epoch, loss=1.19, accuracy=0.742, val_loss=1.46, val_accuracy=0.657, lr=0.1] 27%|██▋       | 20/75 [08:08<20:29, 22.35s/epoch, loss=1.17, accuracy=0.747, val_loss=1.92, val_accuracy=0.52, lr=0.1]  28%|██▊       | 21/75 [08:32<20:22, 22.65s/epoch, loss=1.18, accuracy=0.743, val_loss=2, val_accuracy=0.48, lr=0.1]    29%|██▉       | 22/75 [08:55<20:16, 22.95s/epoch, loss=1.17, accuracy=0.745, val_loss=2.31, val_accuracy=0.437, lr=0.1] 31%|███       | 23/75 [09:18<19:41, 22.72s/epoch, loss=1.17, accuracy=0.747, val_loss=2.04, val_accuracy=0.491, lr=0.1] 32%|███▏      | 24/75 [09:41<19:32, 23.00s/epoch, loss=1.17, accuracy=0.746, val_loss=2.77, val_accuracy=0.371, lr=0.0316] 33%|███▎      | 25/75 [10:05<19:20, 23.21s/epoch, loss=1.17, accuracy=0.746, val_loss=2.06, val_accuracy=0.537, lr=0.1]    35%|███▍      | 26/75 [10:29<19:04, 23.35s/epoch, loss=1.17, accuracy=0.746, val_loss=1.92, val_accuracy=0.54, lr=0.1]  36%|███▌      | 27/75 [10:51<18:21, 22.95s/epoch, loss=1.17, accuracy=0.747, val_loss=1.95, val_accuracy=0.48, lr=0.1] 37%|███▋      | 28/75 [11:14<18:06, 23.11s/epoch, loss=1.17, accuracy=0.745, val_loss=2.18, val_accuracy=0.513, lr=0.1] 39%|███▊      | 29/75 [11:38<17:51, 23.29s/epoch, loss=1.16, accuracy=0.75, val_loss=1.74, val_accuracy=0.525, lr=0.0316] 40%|████      | 30/75 [12:00<17:12, 22.93s/epoch, loss=1.16, accuracy=0.748, val_loss=1.75, val_accuracy=0.562, lr=0.1]   41%|████▏     | 31/75 [12:22<16:39, 22.71s/epoch, loss=1.15, accuracy=0.749, val_loss=1.46, val_accuracy=0.631, lr=0.1] 43%|████▎     | 32/75 [12:44<16:08, 22.53s/epoch, loss=1.16, accuracy=0.747, val_loss=1.53, val_accuracy=0.632, lr=0.1] 44%|████▍     | 33/75 [13:08<15:57, 22.79s/epoch, loss=1.16, accuracy=0.75, val_loss=2.3, val_accuracy=0.406, lr=0.1]   45%|████▌     | 34/75 [13:31<15:43, 23.02s/epoch, loss=1.16, accuracy=0.751, val_loss=1.87, val_accuracy=0.47, lr=0.1] 47%|████▋     | 35/75 [13:55<15:24, 23.12s/epoch, loss=1.15, accuracy=0.752, val_loss=1.85, val_accuracy=0.532, lr=0.1] 48%|████▊     | 36/75 [14:18<15:04, 23.18s/epoch, loss=1.16, accuracy=0.751, val_loss=2.12, val_accuracy=0.512, lr=0.0316] 49%|████▉     | 37/75 [14:41<14:45, 23.31s/epoch, loss=1.15, accuracy=0.752, val_loss=2.41, val_accuracy=0.459, lr=0.1]    51%|█████     | 38/75 [15:06<14:31, 23.55s/epoch, loss=1.16, accuracy=0.753, val_loss=1.66, val_accuracy=0.598, lr=0.1] 52%|█████▏    | 39/75 [15:29<14:08, 23.58s/epoch, loss=1.16, accuracy=0.75, val_loss=1.81, val_accuracy=0.553, lr=0.1]  53%|█████▎    | 40/75 [15:53<13:42, 23.50s/epoch, loss=1.15, accuracy=0.753, val_loss=1.53, val_accuracy=0.621, lr=0.1] 55%|█████▍    | 41/75 [16:15<13:08, 23.18s/epoch, loss=1.15, accuracy=0.753, val_loss=4.43, val_accuracy=0.289, lr=0.0316] 56%|█████▌    | 42/75 [16:38<12:38, 23.00s/epoch, loss=1.14, accuracy=0.755, val_loss=1.84, val_accuracy=0.498, lr=0.1]    57%|█████▋    | 43/75 [17:02<12:29, 23.43s/epoch, loss=1.14, accuracy=0.755, val_loss=2.12, val_accuracy=0.485, lr=0.1] 59%|█████▊    | 44/75 [17:26<12:07, 23.47s/epoch, loss=1.15, accuracy=0.752, val_loss=2.74, val_accuracy=0.274, lr=0.1] 60%|██████    | 45/75 [17:49<11:44, 23.49s/epoch, loss=1.15, accuracy=0.753, val_loss=2.04, val_accuracy=0.448, lr=0.1] 61%|██████▏   | 46/75 [18:11<11:10, 23.12s/epoch, loss=1.14, accuracy=0.755, val_loss=1.96, val_accuracy=0.529, lr=0.0316] 63%|██████▎   | 47/75 [18:34<10:44, 23.02s/epoch, loss=1.14, accuracy=0.754, val_loss=2.55, val_accuracy=0.36, lr=0.1]     64%|██████▍   | 48/75 [18:58<10:26, 23.19s/epoch, loss=1.14, accuracy=0.753, val_loss=2.31, val_accuracy=0.469, lr=0.1] 65%|██████▌   | 49/75 [19:20<09:55, 22.90s/epoch, loss=1.14, accuracy=0.755, val_loss=1.78, val_accuracy=0.547, lr=0.1] 67%|██████▋   | 50/75 [19:43<09:32, 22.91s/epoch, loss=1.14, accuracy=0.754, val_loss=1.72, val_accuracy=0.601, lr=0.1] 68%|██████▊   | 51/75 [20:06<09:07, 22.82s/epoch, loss=1.14, accuracy=0.752, val_loss=2.25, val_accuracy=0.456, lr=0.0316] 69%|██████▉   | 52/75 [20:28<08:40, 22.62s/epoch, loss=1.14, accuracy=0.753, val_loss=2.24, val_accuracy=0.465, lr=0.1]    71%|███████   | 53/75 [20:50<08:14, 22.49s/epoch, loss=1.14, accuracy=0.757, val_loss=1.7, val_accuracy=0.573, lr=0.1]  72%|███████▏  | 54/75 [21:12<07:52, 22.51s/epoch, loss=1.13, accuracy=0.754, val_loss=1.55, val_accuracy=0.597, lr=0.1] 73%|███████▎  | 55/75 [21:35<07:30, 22.51s/epoch, loss=1.13, accuracy=0.755, val_loss=1.89, val_accuracy=0.533, lr=0.1] 75%|███████▍  | 56/75 [21:57<07:05, 22.40s/epoch, loss=1.14, accuracy=0.752, val_loss=1.51, val_accuracy=0.647, lr=0.0316] 76%|███████▌  | 57/75 [22:19<06:42, 22.35s/epoch, loss=1.13, accuracy=0.757, val_loss=4.21, val_accuracy=0.25, lr=0.1]     77%|███████▋  | 58/75 [22:43<06:24, 22.61s/epoch, loss=1.13, accuracy=0.754, val_loss=1.67, val_accuracy=0.579, lr=0.1] 79%|███████▊  | 59/75 [23:06<06:04, 22.80s/epoch, loss=1.12, accuracy=0.756, val_loss=3.76, val_accuracy=0.268, lr=0.1] 80%|████████  | 60/75 [23:28<05:41, 22.75s/epoch, loss=1.14, accuracy=0.755, val_loss=2.35, val_accuracy=0.464, lr=0.1] 81%|████████▏ | 61/75 [23:51<05:16, 22.58s/epoch, loss=1.13, accuracy=0.754, val_loss=1.79, val_accuracy=0.553, lr=0.0316] 83%|████████▎ | 62/75 [24:12<04:50, 22.38s/epoch, loss=1.12, accuracy=0.757, val_loss=1.55, val_accuracy=0.592, lr=0.1]    84%|████████▍ | 63/75 [24:34<04:26, 22.20s/epoch, loss=1.13, accuracy=0.755, val_loss=1.85, val_accuracy=0.524, lr=0.1] 85%|████████▌ | 64/75 [24:57<04:07, 22.47s/epoch, loss=1.13, accuracy=0.757, val_loss=1.39, val_accuracy=0.673, lr=0.1] 87%|████████▋ | 65/75 [25:21<03:47, 22.77s/epoch, loss=1.14, accuracy=0.757, val_loss=1.69, val_accuracy=0.564, lr=0.1] 88%|████████▊ | 66/75 [25:45<03:27, 23.04s/epoch, loss=1.12, accuracy=0.758, val_loss=1.55, val_accuracy=0.602, lr=0.1] 89%|████████▉ | 67/75 [26:08<03:04, 23.03s/epoch, loss=1.12, accuracy=0.758, val_loss=2.14, val_accuracy=0.483, lr=0.1] 91%|█████████ | 68/75 [26:30<02:40, 22.88s/epoch, loss=1.13, accuracy=0.756, val_loss=2.05, val_accuracy=0.483, lr=0.1] 92%|█████████▏| 69/75 [26:54<02:19, 23.19s/epoch, loss=1.12, accuracy=0.757, val_loss=2.27, val_accuracy=0.502, lr=0.0316] 93%|█████████▎| 70/75 [27:17<01:55, 23.11s/epoch, loss=1.12, accuracy=0.76, val_loss=3.1, val_accuracy=0.328, lr=0.1]      95%|█████████▍| 71/75 [27:39<01:31, 22.80s/epoch, loss=1.12, accuracy=0.758, val_loss=2.1, val_accuracy=0.508, lr=0.1] 96%|█████████▌| 72/75 [28:01<01:07, 22.61s/epoch, loss=1.13, accuracy=0.757, val_loss=3.54, val_accuracy=0.327, lr=0.1] 97%|█████████▋| 73/75 [28:24<00:45, 22.59s/epoch, loss=1.12, accuracy=0.76, val_loss=2.02, val_accuracy=0.479, lr=0.1]  99%|█████████▊| 74/75 [28:45<00:22, 22.33s/epoch, loss=1.12, accuracy=0.759, val_loss=1.27, val_accuracy=0.7, lr=0.1] 100%|██████████| 75/75 [29:07<00:00, 22.17s/epoch, loss=1.12, accuracy=0.758, val_loss=2.01, val_accuracy=0.481, lr=0.1]100%|██████████| 75/75 [29:07<00:00, 23.30s/epoch, loss=1.12, accuracy=0.758, val_loss=2.01, val_accuracy=0.481, lr=0.1]
Using real-time data augmentation.
Test score: 2.006197929382324
Test accuracy: 0.4814999997615814


* * * Run SGD for ID = 20_2. * * *


2024-03-05 13:55:21.871241: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 13:55:24.690276: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 13:55:24.691325: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-05 13:55:24.744014: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-05 13:55:24.744083: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 13:55:24.747150: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 13:55:24.747194: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 13:55:24.749476: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 13:55:24.750658: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 13:55:24.753091: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 13:55:24.754691: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 13:55:24.759706: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 13:55:24.760330: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 13:55:24.760439: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 13:55:26.113921: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-05 13:55:26.114546: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 13:55:26.115205: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-05 13:55:26.115240: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 13:55:26.115277: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 13:55:26.115296: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 13:55:26.115314: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 13:55:26.115332: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 13:55:26.115349: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 13:55:26.115366: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 13:55:26.115384: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 13:55:26.115865: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 13:55:26.115900: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 13:55:26.844854: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-05 13:55:26.844906: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-05 13:55:26.844916: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-05 13:55:26.845912: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:02:00.0, compute capability: 6.1)
{'id': '20_02', 'seed': 2, 'out_folder': 'results/epoch_budget', 'batch_size': 128, 'epochs': 75, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'bootstrapping': False, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/75 [00:00<?, ?epoch/s]2024-03-05 13:55:27.763181: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-05 13:55:27.775200: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199825000 Hz
2024-03-05 13:55:30.009799: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 13:55:30.263102: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 13:55:31.093888: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-05 13:55:31.149739: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|▏         | 1/75 [00:57<1:11:22, 57.87s/epoch, loss=2.77, accuracy=0.432, val_loss=2.97, val_accuracy=0.225, lr=0.1]  3%|▎         | 2/75 [01:20<44:59, 36.98s/epoch, loss=1.43, accuracy=0.618, val_loss=2.15, val_accuracy=0.49, lr=0.1]     4%|▍         | 3/75 [01:42<36:15, 30.21s/epoch, loss=1.3, accuracy=0.67, val_loss=1.48, val_accuracy=0.602, lr=0.1]   5%|▌         | 4/75 [02:05<32:14, 27.24s/epoch, loss=1.26, accuracy=0.696, val_loss=1.65, val_accuracy=0.553, lr=0.1]  7%|▋         | 5/75 [02:28<30:07, 25.81s/epoch, loss=1.25, accuracy=0.704, val_loss=2.98, val_accuracy=0.292, lr=0.1]  8%|▊         | 6/75 [02:52<28:52, 25.10s/epoch, loss=1.22, accuracy=0.714, val_loss=3.31, val_accuracy=0.315, lr=0.1]  9%|▉         | 7/75 [03:15<27:57, 24.67s/epoch, loss=1.22, accuracy=0.721, val_loss=2.07, val_accuracy=0.503, lr=0.1] 11%|█         | 8/75 [03:40<27:31, 24.65s/epoch, loss=1.21, accuracy=0.725, val_loss=1.56, val_accuracy=0.624, lr=0.0316] 12%|█▏        | 9/75 [04:04<27:03, 24.59s/epoch, loss=1.19, accuracy=0.73, val_loss=1.93, val_accuracy=0.513, lr=0.1]     13%|█▎        | 10/75 [04:29<26:29, 24.46s/epoch, loss=1.18, accuracy=0.733, val_loss=1.48, val_accuracy=0.611, lr=0.1] 15%|█▍        | 11/75 [04:52<25:45, 24.16s/epoch, loss=1.18, accuracy=0.736, val_loss=1.51, val_accuracy=0.604, lr=0.1] 16%|█▌        | 12/75 [05:17<25:29, 24.28s/epoch, loss=1.17, accuracy=0.739, val_loss=1.95, val_accuracy=0.537, lr=0.1] 17%|█▋        | 13/75 [05:41<25:10, 24.36s/epoch, loss=1.17, accuracy=0.742, val_loss=2.47, val_accuracy=0.407, lr=0.1] 19%|█▊        | 14/75 [06:05<24:38, 24.23s/epoch, loss=1.17, accuracy=0.741, val_loss=2.09, val_accuracy=0.416, lr=0.1] 20%|██        | 15/75 [06:28<23:45, 23.76s/epoch, loss=1.16, accuracy=0.742, val_loss=2.22, val_accuracy=0.457, lr=0.0316] 21%|██▏       | 16/75 [06:51<23:06, 23.50s/epoch, loss=1.16, accuracy=0.741, val_loss=1.57, val_accuracy=0.597, lr=0.1]    23%|██▎       | 17/75 [07:13<22:28, 23.25s/epoch, loss=1.15, accuracy=0.745, val_loss=2, val_accuracy=0.481, lr=0.1]    24%|██▍       | 18/75 [07:36<21:51, 23.02s/epoch, loss=1.15, accuracy=0.745, val_loss=1.93, val_accuracy=0.49, lr=0.1] 25%|██▌       | 19/75 [07:59<21:23, 22.93s/epoch, loss=1.15, accuracy=0.745, val_loss=1.85, val_accuracy=0.526, lr=0.1] 27%|██▋       | 20/75 [08:22<21:04, 22.98s/epoch, loss=1.15, accuracy=0.748, val_loss=4.47, val_accuracy=0.311, lr=0.0316] 28%|██▊       | 21/75 [08:46<21:04, 23.42s/epoch, loss=1.16, accuracy=0.749, val_loss=2.06, val_accuracy=0.491, lr=0.1]    29%|██▉       | 22/75 [09:10<20:45, 23.50s/epoch, loss=1.14, accuracy=0.752, val_loss=1.89, val_accuracy=0.58, lr=0.1]  31%|███       | 23/75 [09:34<20:36, 23.77s/epoch, loss=1.15, accuracy=0.751, val_loss=1.49, val_accuracy=0.629, lr=0.1] 32%|███▏      | 24/75 [09:58<20:13, 23.80s/epoch, loss=1.15, accuracy=0.748, val_loss=1.88, val_accuracy=0.551, lr=0.1] 33%|███▎      | 25/75 [10:23<20:03, 24.07s/epoch, loss=1.14, accuracy=0.753, val_loss=1.72, val_accuracy=0.59, lr=0.0316] 35%|███▍      | 26/75 [10:46<19:33, 23.94s/epoch, loss=1.14, accuracy=0.753, val_loss=2.14, val_accuracy=0.481, lr=0.1]   36%|███▌      | 27/75 [11:11<19:14, 24.06s/epoch, loss=1.15, accuracy=0.753, val_loss=1.41, val_accuracy=0.651, lr=0.1] 37%|███▋      | 28/75 [11:33<18:28, 23.59s/epoch, loss=1.14, accuracy=0.753, val_loss=2.13, val_accuracy=0.481, lr=0.1] 39%|███▊      | 29/75 [11:57<18:09, 23.68s/epoch, loss=1.14, accuracy=0.752, val_loss=1.93, val_accuracy=0.488, lr=0.1] 40%|████      | 30/75 [12:19<17:27, 23.29s/epoch, loss=1.14, accuracy=0.753, val_loss=1.88, val_accuracy=0.507, lr=0.1] 41%|████▏     | 31/75 [12:43<17:05, 23.31s/epoch, loss=1.14, accuracy=0.751, val_loss=1.82, val_accuracy=0.519, lr=0.1] 43%|████▎     | 32/75 [13:06<16:34, 23.14s/epoch, loss=1.14, accuracy=0.754, val_loss=1.39, val_accuracy=0.648, lr=0.1] 44%|████▍     | 33/75 [13:28<16:05, 22.98s/epoch, loss=1.14, accuracy=0.754, val_loss=2.06, val_accuracy=0.5, lr=0.1]   45%|████▌     | 34/75 [13:52<15:57, 23.35s/epoch, loss=1.14, accuracy=0.753, val_loss=2.44, val_accuracy=0.454, lr=0.1] 47%|████▋     | 35/75 [14:15<15:23, 23.09s/epoch, loss=1.13, accuracy=0.756, val_loss=2.09, val_accuracy=0.548, lr=0.1] 48%|████▊     | 36/75 [14:37<14:49, 22.81s/epoch, loss=1.12, accuracy=0.756, val_loss=1.77, val_accuracy=0.533, lr=0.1] 49%|████▉     | 37/75 [14:59<14:18, 22.59s/epoch, loss=1.13, accuracy=0.753, val_loss=2.73, val_accuracy=0.377, lr=0.0316] 51%|█████     | 38/75 [15:23<14:11, 23.02s/epoch, loss=1.14, accuracy=0.753, val_loss=3.16, val_accuracy=0.34, lr=0.1]     52%|█████▏    | 39/75 [15:46<13:48, 23.02s/epoch, loss=1.13, accuracy=0.756, val_loss=1.83, val_accuracy=0.541, lr=0.1] 53%|█████▎    | 40/75 [16:09<13:24, 22.97s/epoch, loss=1.13, accuracy=0.757, val_loss=1.83, val_accuracy=0.583, lr=0.1] 55%|█████▍    | 41/75 [16:32<12:58, 22.90s/epoch, loss=1.13, accuracy=0.754, val_loss=3.01, val_accuracy=0.24, lr=0.1]  56%|█████▌    | 42/75 [16:55<12:35, 22.89s/epoch, loss=1.13, accuracy=0.755, val_loss=2.33, val_accuracy=0.377, lr=0.0316] 57%|█████▋    | 43/75 [17:17<12:08, 22.76s/epoch, loss=1.13, accuracy=0.754, val_loss=2.13, val_accuracy=0.537, lr=0.1]    59%|█████▊    | 44/75 [17:40<11:44, 22.72s/epoch, loss=1.12, accuracy=0.756, val_loss=1.72, val_accuracy=0.585, lr=0.1] 60%|██████    | 45/75 [18:02<11:17, 22.59s/epoch, loss=1.12, accuracy=0.76, val_loss=1.93, val_accuracy=0.5, lr=0.1]    61%|██████▏   | 46/75 [18:24<10:53, 22.52s/epoch, loss=1.12, accuracy=0.758, val_loss=3.09, val_accuracy=0.342, lr=0.1] 63%|██████▎   | 47/75 [18:49<10:45, 23.06s/epoch, loss=1.13, accuracy=0.756, val_loss=2.74, val_accuracy=0.394, lr=0.0316] 64%|██████▍   | 48/75 [19:13<10:32, 23.42s/epoch, loss=1.12, accuracy=0.757, val_loss=1.99, val_accuracy=0.512, lr=0.1]    65%|██████▌   | 49/75 [19:36<10:07, 23.37s/epoch, loss=1.13, accuracy=0.758, val_loss=2.93, val_accuracy=0.445, lr=0.1] 67%|██████▋   | 50/75 [20:00<09:47, 23.49s/epoch, loss=1.12, accuracy=0.758, val_loss=2.45, val_accuracy=0.479, lr=0.1] 68%|██████▊   | 51/75 [20:23<09:23, 23.46s/epoch, loss=1.12, accuracy=0.756, val_loss=2.41, val_accuracy=0.495, lr=0.1] 69%|██████▉   | 52/75 [20:46<08:52, 23.15s/epoch, loss=1.12, accuracy=0.757, val_loss=2.02, val_accuracy=0.484, lr=0.0316] 71%|███████   | 53/75 [21:10<08:34, 23.37s/epoch, loss=1.13, accuracy=0.756, val_loss=2.74, val_accuracy=0.319, lr=0.1]    72%|███████▏  | 54/75 [21:34<08:16, 23.66s/epoch, loss=1.13, accuracy=0.757, val_loss=2.77, val_accuracy=0.41, lr=0.1]  73%|███████▎  | 55/75 [21:57<07:46, 23.33s/epoch, loss=1.12, accuracy=0.756, val_loss=1.94, val_accuracy=0.51, lr=0.1] 75%|███████▍  | 56/75 [22:19<07:17, 23.04s/epoch, loss=1.12, accuracy=0.759, val_loss=3.26, val_accuracy=0.344, lr=0.1] 76%|███████▌  | 57/75 [22:41<06:51, 22.86s/epoch, loss=1.12, accuracy=0.758, val_loss=1.59, val_accuracy=0.578, lr=0.0316] 77%|███████▋  | 58/75 [23:04<06:29, 22.92s/epoch, loss=1.12, accuracy=0.76, val_loss=3.75, val_accuracy=0.319, lr=0.1]     79%|███████▊  | 59/75 [23:27<06:06, 22.92s/epoch, loss=1.13, accuracy=0.753, val_loss=1.7, val_accuracy=0.57, lr=0.1]  80%|████████  | 60/75 [23:50<05:44, 22.99s/epoch, loss=1.12, accuracy=0.758, val_loss=4.77, val_accuracy=0.339, lr=0.1] 81%|████████▏ | 61/75 [24:13<05:18, 22.74s/epoch, loss=1.12, accuracy=0.755, val_loss=2.02, val_accuracy=0.504, lr=0.1] 83%|████████▎ | 62/75 [24:35<04:54, 22.64s/epoch, loss=1.12, accuracy=0.758, val_loss=2.55, val_accuracy=0.433, lr=0.0316] 84%|████████▍ | 63/75 [24:59<04:35, 22.93s/epoch, loss=1.11, accuracy=0.758, val_loss=1.96, val_accuracy=0.547, lr=0.1]    85%|████████▌ | 64/75 [25:21<04:10, 22.73s/epoch, loss=1.12, accuracy=0.761, val_loss=5.43, val_accuracy=0.176, lr=0.1] 87%|████████▋ | 65/75 [25:44<03:47, 22.76s/epoch, loss=1.12, accuracy=0.759, val_loss=4.3, val_accuracy=0.356, lr=0.1]  88%|████████▊ | 66/75 [26:06<03:23, 22.58s/epoch, loss=1.11, accuracy=0.756, val_loss=2.19, val_accuracy=0.568, lr=0.1] 89%|████████▉ | 67/75 [26:28<02:58, 22.37s/epoch, loss=1.12, accuracy=0.757, val_loss=1.42, val_accuracy=0.656, lr=0.0316] 91%|█████████ | 68/75 [26:50<02:36, 22.38s/epoch, loss=1.12, accuracy=0.758, val_loss=2.04, val_accuracy=0.484, lr=0.1]    92%|█████████▏| 69/75 [27:13<02:14, 22.39s/epoch, loss=1.13, accuracy=0.756, val_loss=3.1, val_accuracy=0.424, lr=0.1]  93%|█████████▎| 70/75 [27:35<01:51, 22.28s/epoch, loss=1.11, accuracy=0.76, val_loss=1.71, val_accuracy=0.543, lr=0.1] 95%|█████████▍| 71/75 [27:57<01:28, 22.21s/epoch, loss=1.12, accuracy=0.759, val_loss=2.58, val_accuracy=0.369, lr=0.1] 96%|█████████▌| 72/75 [28:19<01:06, 22.24s/epoch, loss=1.11, accuracy=0.759, val_loss=2.48, val_accuracy=0.473, lr=0.0316] 97%|█████████▋| 73/75 [28:41<00:44, 22.20s/epoch, loss=1.11, accuracy=0.758, val_loss=1.61, val_accuracy=0.642, lr=0.1]    99%|█████████▊| 74/75 [29:03<00:22, 22.22s/epoch, loss=1.13, accuracy=0.757, val_loss=1.63, val_accuracy=0.574, lr=0.1]100%|██████████| 75/75 [29:26<00:00, 22.24s/epoch, loss=1.12, accuracy=0.758, val_loss=1.88, val_accuracy=0.504, lr=0.1]100%|██████████| 75/75 [29:26<00:00, 23.55s/epoch, loss=1.12, accuracy=0.758, val_loss=1.88, val_accuracy=0.504, lr=0.1]
Using real-time data augmentation.
Test score: 1.8824306726455688
Test accuracy: 0.503600001335144


* * * Run SGD for ID = 20_3. * * *


2024-03-05 14:24:58.150779: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 14:25:03.060452: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 14:25:03.061643: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-05 14:25:03.103647: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-05 14:25:03.103678: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 14:25:03.146272: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 14:25:03.146319: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 14:25:03.150316: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 14:25:03.152386: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 14:25:03.172791: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 14:25:03.188887: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 14:25:03.213399: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 14:25:03.213925: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 14:25:03.214016: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 14:25:04.674905: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-05 14:25:04.675468: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 14:25:04.675946: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-05 14:25:04.675974: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 14:25:04.676006: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 14:25:04.676024: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 14:25:04.676040: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 14:25:04.676102: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 14:25:04.676123: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 14:25:04.676141: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 14:25:04.676160: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 14:25:04.676660: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 14:25:04.676697: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 14:25:05.544119: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-05 14:25:05.544276: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-05 14:25:05.544285: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-05 14:25:05.545324: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:02:00.0, compute capability: 6.1)
{'id': '20_03', 'seed': 3, 'out_folder': 'results/epoch_budget', 'batch_size': 128, 'epochs': 75, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'bootstrapping': False, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/75 [00:00<?, ?epoch/s]2024-03-05 14:25:06.381847: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-05 14:25:06.394240: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199825000 Hz
2024-03-05 14:25:08.384166: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 14:25:08.654326: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 14:25:09.942568: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-05 14:25:10.041032: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|▏         | 1/75 [00:46<57:06, 46.30s/epoch, loss=2.88, accuracy=0.385, val_loss=4.89, val_accuracy=0.16, lr=0.1]  3%|▎         | 2/75 [01:08<38:46, 31.87s/epoch, loss=1.45, accuracy=0.593, val_loss=2.03, val_accuracy=0.496, lr=0.1]  4%|▍         | 3/75 [01:29<32:32, 27.12s/epoch, loss=1.3, accuracy=0.669, val_loss=2.02, val_accuracy=0.444, lr=0.1]   5%|▌         | 4/75 [01:51<29:40, 25.08s/epoch, loss=1.25, accuracy=0.698, val_loss=2.99, val_accuracy=0.353, lr=0.1]  7%|▋         | 5/75 [02:13<27:49, 23.84s/epoch, loss=1.22, accuracy=0.714, val_loss=1.76, val_accuracy=0.555, lr=0.1]  8%|▊         | 6/75 [02:34<26:28, 23.02s/epoch, loss=1.21, accuracy=0.721, val_loss=2.1, val_accuracy=0.527, lr=0.1]   9%|▉         | 7/75 [02:56<25:37, 22.61s/epoch, loss=1.21, accuracy=0.726, val_loss=2.24, val_accuracy=0.462, lr=0.1] 11%|█         | 8/75 [03:18<24:55, 22.32s/epoch, loss=1.21, accuracy=0.729, val_loss=1.51, val_accuracy=0.63, lr=0.1]  12%|█▏        | 9/75 [03:39<24:20, 22.13s/epoch, loss=1.2, accuracy=0.733, val_loss=1.5, val_accuracy=0.643, lr=0.1]  13%|█▎        | 10/75 [04:01<23:45, 21.93s/epoch, loss=1.2, accuracy=0.733, val_loss=2.47, val_accuracy=0.395, lr=0.1] 15%|█▍        | 11/75 [04:23<23:23, 21.94s/epoch, loss=1.18, accuracy=0.738, val_loss=1.72, val_accuracy=0.535, lr=0.1] 16%|█▌        | 12/75 [04:44<22:53, 21.79s/epoch, loss=1.18, accuracy=0.74, val_loss=2.82, val_accuracy=0.334, lr=0.1]  17%|█▋        | 13/75 [05:06<22:28, 21.75s/epoch, loss=1.18, accuracy=0.738, val_loss=1.7, val_accuracy=0.548, lr=0.1] 19%|█▊        | 14/75 [05:28<22:20, 21.97s/epoch, loss=1.18, accuracy=0.743, val_loss=2.16, val_accuracy=0.389, lr=0.0316] 20%|██        | 15/75 [05:50<21:49, 21.82s/epoch, loss=1.17, accuracy=0.743, val_loss=1.87, val_accuracy=0.493, lr=0.1]    21%|██▏       | 16/75 [06:11<21:20, 21.71s/epoch, loss=1.16, accuracy=0.745, val_loss=1.84, val_accuracy=0.502, lr=0.1] 23%|██▎       | 17/75 [06:33<20:59, 21.71s/epoch, loss=1.17, accuracy=0.745, val_loss=1.77, val_accuracy=0.549, lr=0.1] 24%|██▍       | 18/75 [06:54<20:32, 21.63s/epoch, loss=1.17, accuracy=0.745, val_loss=3.11, val_accuracy=0.306, lr=0.1] 25%|██▌       | 19/75 [07:16<20:09, 21.59s/epoch, loss=1.17, accuracy=0.745, val_loss=3.37, val_accuracy=0.318, lr=0.0316] 27%|██▋       | 20/75 [07:38<19:48, 21.61s/epoch, loss=1.16, accuracy=0.747, val_loss=2.19, val_accuracy=0.49, lr=0.1]     28%|██▊       | 21/75 [07:59<19:28, 21.63s/epoch, loss=1.17, accuracy=0.748, val_loss=2.25, val_accuracy=0.512, lr=0.1] 29%|██▉       | 22/75 [08:21<19:09, 21.69s/epoch, loss=1.15, accuracy=0.747, val_loss=2.15, val_accuracy=0.445, lr=0.1] 31%|███       | 23/75 [08:43<18:50, 21.73s/epoch, loss=1.15, accuracy=0.749, val_loss=1.53, val_accuracy=0.621, lr=0.1] 32%|███▏      | 24/75 [09:05<18:30, 21.78s/epoch, loss=1.15, accuracy=0.751, val_loss=1.72, val_accuracy=0.586, lr=0.0316] 33%|███▎      | 25/75 [09:26<18:05, 21.71s/epoch, loss=1.15, accuracy=0.748, val_loss=3.26, val_accuracy=0.344, lr=0.1]    35%|███▍      | 26/75 [09:49<17:56, 21.97s/epoch, loss=1.15, accuracy=0.75, val_loss=1.8, val_accuracy=0.522, lr=0.1]   36%|███▌      | 27/75 [10:11<17:30, 21.88s/epoch, loss=1.14, accuracy=0.752, val_loss=2.79, val_accuracy=0.362, lr=0.1] 37%|███▋      | 28/75 [10:33<17:09, 21.91s/epoch, loss=1.15, accuracy=0.75, val_loss=1.63, val_accuracy=0.571, lr=0.1]  39%|███▊      | 29/75 [10:54<16:43, 21.83s/epoch, loss=1.14, accuracy=0.755, val_loss=3.12, val_accuracy=0.376, lr=0.0316] 40%|████      | 30/75 [11:16<16:21, 21.81s/epoch, loss=1.13, accuracy=0.752, val_loss=5.04, val_accuracy=0.293, lr=0.1]    41%|████▏     | 31/75 [11:38<15:57, 21.76s/epoch, loss=1.14, accuracy=0.755, val_loss=1.94, val_accuracy=0.505, lr=0.1] 43%|████▎     | 32/75 [12:00<15:38, 21.83s/epoch, loss=1.14, accuracy=0.753, val_loss=2.29, val_accuracy=0.443, lr=0.1] 44%|████▍     | 33/75 [12:21<15:14, 21.77s/epoch, loss=1.13, accuracy=0.755, val_loss=1.56, val_accuracy=0.608, lr=0.1] 45%|████▌     | 34/75 [12:43<14:49, 21.70s/epoch, loss=1.14, accuracy=0.752, val_loss=1.52, val_accuracy=0.618, lr=0.0316] 47%|████▋     | 35/75 [13:04<14:27, 21.68s/epoch, loss=1.13, accuracy=0.756, val_loss=1.77, val_accuracy=0.547, lr=0.1]    48%|████▊     | 36/75 [13:26<14:06, 21.70s/epoch, loss=1.13, accuracy=0.756, val_loss=2.66, val_accuracy=0.404, lr=0.1] 49%|████▉     | 37/75 [13:48<13:44, 21.69s/epoch, loss=1.13, accuracy=0.754, val_loss=1.78, val_accuracy=0.553, lr=0.1] 51%|█████     | 38/75 [14:10<13:23, 21.72s/epoch, loss=1.13, accuracy=0.754, val_loss=7.39, val_accuracy=0.15, lr=0.1]  52%|█████▏    | 39/75 [14:31<13:03, 21.78s/epoch, loss=1.13, accuracy=0.754, val_loss=1.85, val_accuracy=0.553, lr=0.0316] 53%|█████▎    | 40/75 [14:53<12:41, 21.74s/epoch, loss=1.13, accuracy=0.756, val_loss=1.97, val_accuracy=0.458, lr=0.1]    55%|█████▍    | 41/75 [15:15<12:18, 21.71s/epoch, loss=1.13, accuracy=0.753, val_loss=1.54, val_accuracy=0.589, lr=0.1] 56%|█████▌    | 42/75 [15:37<11:56, 21.73s/epoch, loss=1.13, accuracy=0.754, val_loss=1.61, val_accuracy=0.587, lr=0.1] 57%|█████▋    | 43/75 [15:58<11:33, 21.68s/epoch, loss=1.12, accuracy=0.755, val_loss=4.25, val_accuracy=0.298, lr=0.1] 59%|█████▊    | 44/75 [16:20<11:10, 21.63s/epoch, loss=1.12, accuracy=0.755, val_loss=2.88, val_accuracy=0.423, lr=0.0316] 60%|██████    | 45/75 [16:41<10:47, 21.60s/epoch, loss=1.12, accuracy=0.756, val_loss=2.25, val_accuracy=0.419, lr=0.1]    61%|██████▏   | 46/75 [17:03<10:26, 21.61s/epoch, loss=1.11, accuracy=0.759, val_loss=1.73, val_accuracy=0.531, lr=0.1] 63%|██████▎   | 47/75 [17:24<10:04, 21.60s/epoch, loss=1.12, accuracy=0.757, val_loss=1.69, val_accuracy=0.572, lr=0.1] 64%|██████▍   | 48/75 [17:47<09:50, 21.88s/epoch, loss=1.12, accuracy=0.757, val_loss=2.36, val_accuracy=0.419, lr=0.1] 65%|██████▌   | 49/75 [18:08<09:26, 21.79s/epoch, loss=1.13, accuracy=0.755, val_loss=2.79, val_accuracy=0.331, lr=0.0316] 67%|██████▋   | 50/75 [18:30<09:03, 21.72s/epoch, loss=1.12, accuracy=0.759, val_loss=2.03, val_accuracy=0.464, lr=0.1]    68%|██████▊   | 51/75 [18:52<08:40, 21.67s/epoch, loss=1.12, accuracy=0.757, val_loss=2.86, val_accuracy=0.283, lr=0.1] 69%|██████▉   | 52/75 [19:13<08:17, 21.61s/epoch, loss=1.12, accuracy=0.759, val_loss=1.81, val_accuracy=0.519, lr=0.1] 71%|███████   | 53/75 [19:35<07:55, 21.60s/epoch, loss=1.11, accuracy=0.759, val_loss=1.87, val_accuracy=0.536, lr=0.1] 72%|███████▏  | 54/75 [19:56<07:34, 21.62s/epoch, loss=1.11, accuracy=0.757, val_loss=2.17, val_accuracy=0.433, lr=0.0316] 73%|███████▎  | 55/75 [20:18<07:15, 21.76s/epoch, loss=1.11, accuracy=0.759, val_loss=1.93, val_accuracy=0.516, lr=0.1]    75%|███████▍  | 56/75 [20:40<06:51, 21.68s/epoch, loss=1.12, accuracy=0.757, val_loss=2.57, val_accuracy=0.344, lr=0.1] 76%|███████▌  | 57/75 [21:02<06:30, 21.70s/epoch, loss=1.12, accuracy=0.757, val_loss=3.7, val_accuracy=0.308, lr=0.1]  77%|███████▋  | 58/75 [21:23<06:08, 21.69s/epoch, loss=1.12, accuracy=0.755, val_loss=2.58, val_accuracy=0.318, lr=0.1] 79%|███████▊  | 59/75 [21:45<05:48, 21.79s/epoch, loss=1.11, accuracy=0.757, val_loss=3.68, val_accuracy=0.341, lr=0.0316] 80%|████████  | 60/75 [22:07<05:26, 21.77s/epoch, loss=1.11, accuracy=0.755, val_loss=2.98, val_accuracy=0.285, lr=0.1]    81%|████████▏ | 61/75 [22:29<05:06, 21.90s/epoch, loss=1.11, accuracy=0.757, val_loss=2.01, val_accuracy=0.441, lr=0.1] 83%|████████▎ | 62/75 [22:51<04:43, 21.79s/epoch, loss=1.11, accuracy=0.758, val_loss=2.39, val_accuracy=0.441, lr=0.1] 84%|████████▍ | 63/75 [23:12<04:20, 21.75s/epoch, loss=1.11, accuracy=0.758, val_loss=3.31, val_accuracy=0.341, lr=0.1] 85%|████████▌ | 64/75 [23:34<03:58, 21.70s/epoch, loss=1.11, accuracy=0.759, val_loss=3.29, val_accuracy=0.407, lr=0.0316] 87%|████████▋ | 65/75 [23:56<03:36, 21.66s/epoch, loss=1.11, accuracy=0.761, val_loss=1.58, val_accuracy=0.588, lr=0.1]    88%|████████▊ | 66/75 [24:17<03:15, 21.68s/epoch, loss=1.12, accuracy=0.756, val_loss=2.39, val_accuracy=0.464, lr=0.1] 89%|████████▉ | 67/75 [24:39<02:53, 21.65s/epoch, loss=1.11, accuracy=0.758, val_loss=2.96, val_accuracy=0.4, lr=0.1]   91%|█████████ | 68/75 [25:00<02:31, 21.63s/epoch, loss=1.11, accuracy=0.757, val_loss=1.41, val_accuracy=0.638, lr=0.1] 92%|█████████▏| 69/75 [25:22<02:10, 21.70s/epoch, loss=1.11, accuracy=0.759, val_loss=1.75, val_accuracy=0.566, lr=0.1] 93%|█████████▎| 70/75 [25:44<01:48, 21.71s/epoch, loss=1.11, accuracy=0.759, val_loss=2.27, val_accuracy=0.438, lr=0.1] 95%|█████████▍| 71/75 [26:06<01:26, 21.68s/epoch, loss=1.12, accuracy=0.757, val_loss=3.5, val_accuracy=0.314, lr=0.1]  96%|█████████▌| 72/75 [26:27<01:05, 21.67s/epoch, loss=1.11, accuracy=0.757, val_loss=2.01, val_accuracy=0.49, lr=0.1] 97%|█████████▋| 73/75 [26:49<00:43, 21.64s/epoch, loss=1.11, accuracy=0.757, val_loss=1.99, val_accuracy=0.535, lr=0.0316] 99%|█████████▊| 74/75 [27:11<00:21, 21.75s/epoch, loss=1.11, accuracy=0.757, val_loss=1.79, val_accuracy=0.548, lr=0.1]   100%|██████████| 75/75 [27:33<00:00, 21.75s/epoch, loss=1.11, accuracy=0.758, val_loss=2.09, val_accuracy=0.457, lr=0.1]100%|██████████| 75/75 [27:33<00:00, 22.04s/epoch, loss=1.11, accuracy=0.758, val_loss=2.09, val_accuracy=0.457, lr=0.1]
Using real-time data augmentation.
Test score: 2.0922341346740723
Test accuracy: 0.45719999074935913


* * * Run SGD for ID = 20_4. * * *


2024-03-05 14:52:43.473938: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 14:52:50.759848: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 14:52:50.760957: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-05 14:52:50.799742: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-05 14:52:50.799771: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 14:52:50.802805: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 14:52:50.802846: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 14:52:50.805088: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 14:52:50.806205: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 14:52:50.809248: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 14:52:50.810719: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 14:52:50.815285: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 14:52:50.815808: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 14:52:50.815895: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 14:52:52.089922: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-05 14:52:52.090425: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 14:52:52.090873: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-05 14:52:52.090903: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 14:52:52.090934: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 14:52:52.090951: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 14:52:52.090966: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 14:52:52.090982: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 14:52:52.090997: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 14:52:52.091012: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 14:52:52.091028: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 14:52:52.091490: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 14:52:52.091523: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 14:52:52.779965: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-05 14:52:52.780032: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-05 14:52:52.780041: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-05 14:52:52.781449: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:02:00.0, compute capability: 6.1)
{'id': '20_04', 'seed': 4, 'out_folder': 'results/epoch_budget', 'batch_size': 128, 'epochs': 75, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'bootstrapping': False, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/75 [00:00<?, ?epoch/s]2024-03-05 14:52:53.639848: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-05 14:52:53.652224: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199825000 Hz
2024-03-05 14:52:55.742224: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 14:52:56.031623: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 14:52:56.749462: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-05 14:52:56.802975: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|▏         | 1/75 [00:50<1:02:22, 50.57s/epoch, loss=2.85, accuracy=0.392, val_loss=2.5, val_accuracy=0.229, lr=0.1]  3%|▎         | 2/75 [01:12<41:05, 33.77s/epoch, loss=1.5, accuracy=0.575, val_loss=2.33, val_accuracy=0.351, lr=0.1]    4%|▍         | 3/75 [01:34<33:58, 28.31s/epoch, loss=1.32, accuracy=0.661, val_loss=1.97, val_accuracy=0.493, lr=0.1]  5%|▌         | 4/75 [01:56<30:27, 25.74s/epoch, loss=1.26, accuracy=0.693, val_loss=1.82, val_accuracy=0.52, lr=0.1]   7%|▋         | 5/75 [02:18<28:28, 24.41s/epoch, loss=1.24, accuracy=0.703, val_loss=2.9, val_accuracy=0.407, lr=0.1]  8%|▊         | 6/75 [02:39<27:01, 23.50s/epoch, loss=1.23, accuracy=0.715, val_loss=2.75, val_accuracy=0.38, lr=0.1]  9%|▉         | 7/75 [03:01<26:00, 22.94s/epoch, loss=1.22, accuracy=0.72, val_loss=1.71, val_accuracy=0.587, lr=0.1] 11%|█         | 8/75 [03:23<25:11, 22.56s/epoch, loss=1.2, accuracy=0.725, val_loss=2.35, val_accuracy=0.458, lr=0.1] 12%|█▏        | 9/75 [03:45<24:30, 22.28s/epoch, loss=1.2, accuracy=0.73, val_loss=8.17, val_accuracy=0.162, lr=0.1]  13%|█▎        | 10/75 [04:06<23:56, 22.10s/epoch, loss=1.19, accuracy=0.733, val_loss=2.26, val_accuracy=0.504, lr=0.1] 15%|█▍        | 11/75 [04:28<23:29, 22.02s/epoch, loss=1.18, accuracy=0.734, val_loss=2.18, val_accuracy=0.476, lr=0.1] 16%|█▌        | 12/75 [04:50<22:59, 21.89s/epoch, loss=1.17, accuracy=0.737, val_loss=1.69, val_accuracy=0.587, lr=0.1] 17%|█▋        | 13/75 [05:12<22:34, 21.85s/epoch, loss=1.17, accuracy=0.739, val_loss=2.06, val_accuracy=0.455, lr=0.1] 19%|█▊        | 14/75 [05:33<22:13, 21.87s/epoch, loss=1.17, accuracy=0.741, val_loss=1.58, val_accuracy=0.591, lr=0.1] 20%|██        | 15/75 [05:55<21:49, 21.83s/epoch, loss=1.17, accuracy=0.742, val_loss=1.72, val_accuracy=0.581, lr=0.1] 21%|██▏       | 16/75 [06:17<21:29, 21.85s/epoch, loss=1.17, accuracy=0.74, val_loss=2.51, val_accuracy=0.381, lr=0.1]  23%|██▎       | 17/75 [06:39<21:09, 21.88s/epoch, loss=1.16, accuracy=0.744, val_loss=2.14, val_accuracy=0.485, lr=0.1] 24%|██▍       | 18/75 [07:01<20:56, 22.04s/epoch, loss=1.16, accuracy=0.744, val_loss=2.07, val_accuracy=0.499, lr=0.1] 25%|██▌       | 19/75 [07:24<20:37, 22.10s/epoch, loss=1.17, accuracy=0.743, val_loss=2.41, val_accuracy=0.389, lr=0.0316] 27%|██▋       | 20/75 [07:46<20:11, 22.03s/epoch, loss=1.16, accuracy=0.746, val_loss=1.82, val_accuracy=0.568, lr=0.1]    28%|██▊       | 21/75 [08:08<19:52, 22.07s/epoch, loss=1.15, accuracy=0.746, val_loss=2.75, val_accuracy=0.372, lr=0.1] 29%|██▉       | 22/75 [08:30<19:30, 22.08s/epoch, loss=1.16, accuracy=0.745, val_loss=2.3, val_accuracy=0.454, lr=0.1]  31%|███       | 23/75 [08:53<19:24, 22.39s/epoch, loss=1.16, accuracy=0.747, val_loss=1.72, val_accuracy=0.581, lr=0.1] 32%|███▏      | 24/75 [09:15<18:57, 22.30s/epoch, loss=1.15, accuracy=0.748, val_loss=2.99, val_accuracy=0.366, lr=0.0316] 33%|███▎      | 25/75 [09:37<18:28, 22.18s/epoch, loss=1.15, accuracy=0.746, val_loss=2.36, val_accuracy=0.498, lr=0.1]    35%|███▍      | 26/75 [09:59<18:02, 22.09s/epoch, loss=1.15, accuracy=0.75, val_loss=1.87, val_accuracy=0.523, lr=0.1]  36%|███▌      | 27/75 [10:21<17:39, 22.07s/epoch, loss=1.15, accuracy=0.748, val_loss=2.15, val_accuracy=0.426, lr=0.1] 37%|███▋      | 28/75 [10:43<17:20, 22.14s/epoch, loss=1.15, accuracy=0.749, val_loss=14.3, val_accuracy=0.141, lr=0.1] 39%|███▊      | 29/75 [11:05<16:55, 22.08s/epoch, loss=1.15, accuracy=0.749, val_loss=2.12, val_accuracy=0.537, lr=0.0316] 40%|████      | 30/75 [11:27<16:28, 21.96s/epoch, loss=1.15, accuracy=0.752, val_loss=2.69, val_accuracy=0.438, lr=0.1]    41%|████▏     | 31/75 [11:48<16:02, 21.87s/epoch, loss=1.14, accuracy=0.75, val_loss=1.52, val_accuracy=0.636, lr=0.1]  43%|████▎     | 32/75 [12:10<15:39, 21.85s/epoch, loss=1.15, accuracy=0.752, val_loss=3.33, val_accuracy=0.35, lr=0.1] 44%|████▍     | 33/75 [12:33<15:31, 22.19s/epoch, loss=1.15, accuracy=0.75, val_loss=2.15, val_accuracy=0.484, lr=0.1] 45%|████▌     | 34/75 [12:55<15:06, 22.11s/epoch, loss=1.14, accuracy=0.752, val_loss=2.05, val_accuracy=0.544, lr=0.1] 47%|████▋     | 35/75 [13:17<14:44, 22.11s/epoch, loss=1.14, accuracy=0.751, val_loss=1.8, val_accuracy=0.546, lr=0.1]  48%|████▊     | 36/75 [13:39<14:16, 21.97s/epoch, loss=1.14, accuracy=0.75, val_loss=1.91, val_accuracy=0.544, lr=0.0316] 49%|████▉     | 37/75 [14:01<13:54, 21.97s/epoch, loss=1.15, accuracy=0.748, val_loss=1.84, val_accuracy=0.544, lr=0.1]   51%|█████     | 38/75 [14:24<13:42, 22.24s/epoch, loss=1.14, accuracy=0.752, val_loss=1.85, val_accuracy=0.551, lr=0.1] 52%|█████▏    | 39/75 [14:48<13:40, 22.78s/epoch, loss=1.14, accuracy=0.753, val_loss=2.08, val_accuracy=0.479, lr=0.1] 53%|█████▎    | 40/75 [15:10<13:11, 22.60s/epoch, loss=1.14, accuracy=0.752, val_loss=1.51, val_accuracy=0.625, lr=0.1] 55%|█████▍    | 41/75 [15:32<12:41, 22.41s/epoch, loss=1.14, accuracy=0.752, val_loss=3.5, val_accuracy=0.28, lr=0.1]   56%|█████▌    | 42/75 [15:54<12:18, 22.39s/epoch, loss=1.14, accuracy=0.753, val_loss=2.7, val_accuracy=0.426, lr=0.1] 57%|█████▋    | 43/75 [16:16<11:51, 22.23s/epoch, loss=1.14, accuracy=0.752, val_loss=2.78, val_accuracy=0.391, lr=0.1] 59%|█████▊    | 44/75 [16:39<11:33, 22.38s/epoch, loss=1.15, accuracy=0.752, val_loss=1.89, val_accuracy=0.527, lr=0.1] 60%|██████    | 45/75 [17:01<11:08, 22.29s/epoch, loss=1.14, accuracy=0.752, val_loss=2.09, val_accuracy=0.502, lr=0.0316] 61%|██████▏   | 46/75 [17:25<11:01, 22.80s/epoch, loss=1.14, accuracy=0.751, val_loss=2.23, val_accuracy=0.487, lr=0.1]    63%|██████▎   | 47/75 [17:48<10:38, 22.79s/epoch, loss=1.14, accuracy=0.756, val_loss=1.8, val_accuracy=0.549, lr=0.1]  64%|██████▍   | 48/75 [18:10<10:09, 22.57s/epoch, loss=1.14, accuracy=0.754, val_loss=2.14, val_accuracy=0.496, lr=0.1] 65%|██████▌   | 49/75 [18:31<09:40, 22.31s/epoch, loss=1.14, accuracy=0.754, val_loss=2.17, val_accuracy=0.496, lr=0.1] 67%|██████▋   | 50/75 [18:53<09:15, 22.20s/epoch, loss=1.13, accuracy=0.754, val_loss=1.9, val_accuracy=0.528, lr=0.0316] 68%|██████▊   | 51/75 [19:15<08:49, 22.08s/epoch, loss=1.13, accuracy=0.755, val_loss=1.83, val_accuracy=0.54, lr=0.1]    69%|██████▉   | 52/75 [19:37<08:26, 22.03s/epoch, loss=1.13, accuracy=0.752, val_loss=2.5, val_accuracy=0.368, lr=0.1] 71%|███████   | 53/75 [19:59<08:01, 21.90s/epoch, loss=1.13, accuracy=0.756, val_loss=3.47, val_accuracy=0.335, lr=0.1] 72%|███████▏  | 54/75 [20:21<07:42, 22.02s/epoch, loss=1.14, accuracy=0.754, val_loss=1.84, val_accuracy=0.538, lr=0.1] 73%|███████▎  | 55/75 [20:43<07:19, 21.99s/epoch, loss=1.13, accuracy=0.757, val_loss=2, val_accuracy=0.495, lr=0.0316] 75%|███████▍  | 56/75 [21:05<06:56, 21.95s/epoch, loss=1.13, accuracy=0.758, val_loss=1.77, val_accuracy=0.572, lr=0.1] 76%|███████▌  | 57/75 [21:26<06:33, 21.85s/epoch, loss=1.13, accuracy=0.756, val_loss=3.23, val_accuracy=0.245, lr=0.1] 77%|███████▋  | 58/75 [21:49<06:12, 21.93s/epoch, loss=1.13, accuracy=0.755, val_loss=2.44, val_accuracy=0.439, lr=0.1] 79%|███████▊  | 59/75 [22:11<05:51, 21.99s/epoch, loss=1.13, accuracy=0.756, val_loss=2, val_accuracy=0.443, lr=0.1]    80%|████████  | 60/75 [22:34<05:36, 22.42s/epoch, loss=1.13, accuracy=0.758, val_loss=2.18, val_accuracy=0.495, lr=0.0316] 81%|████████▏ | 61/75 [22:57<05:15, 22.52s/epoch, loss=1.13, accuracy=0.757, val_loss=3.77, val_accuracy=0.266, lr=0.1]    83%|████████▎ | 62/75 [23:19<04:50, 22.33s/epoch, loss=1.13, accuracy=0.757, val_loss=1.86, val_accuracy=0.532, lr=0.1] 84%|████████▍ | 63/75 [23:41<04:26, 22.17s/epoch, loss=1.13, accuracy=0.758, val_loss=1.81, val_accuracy=0.576, lr=0.1] 85%|████████▌ | 64/75 [24:02<04:02, 22.07s/epoch, loss=1.13, accuracy=0.756, val_loss=3.78, val_accuracy=0.292, lr=0.1] 87%|████████▋ | 65/75 [24:24<03:39, 21.95s/epoch, loss=1.13, accuracy=0.754, val_loss=1.96, val_accuracy=0.471, lr=0.0316] 88%|████████▊ | 66/75 [24:46<03:16, 21.88s/epoch, loss=1.13, accuracy=0.758, val_loss=1.58, val_accuracy=0.622, lr=0.1]    89%|████████▉ | 67/75 [25:08<02:56, 22.04s/epoch, loss=1.13, accuracy=0.755, val_loss=2.59, val_accuracy=0.452, lr=0.1] 91%|█████████ | 68/75 [25:30<02:34, 22.07s/epoch, loss=1.13, accuracy=0.755, val_loss=2.04, val_accuracy=0.522, lr=0.1] 92%|█████████▏| 69/75 [25:54<02:14, 22.49s/epoch, loss=1.13, accuracy=0.753, val_loss=3.67, val_accuracy=0.293, lr=0.1] 93%|█████████▎| 70/75 [26:17<01:53, 22.75s/epoch, loss=1.13, accuracy=0.756, val_loss=2.03, val_accuracy=0.522, lr=0.0316] 95%|█████████▍| 71/75 [26:39<01:29, 22.48s/epoch, loss=1.13, accuracy=0.756, val_loss=1.39, val_accuracy=0.664, lr=0.1]    96%|█████████▌| 72/75 [27:01<01:06, 22.23s/epoch, loss=1.13, accuracy=0.757, val_loss=2.68, val_accuracy=0.409, lr=0.1] 97%|█████████▋| 73/75 [27:24<00:45, 22.65s/epoch, loss=1.14, accuracy=0.753, val_loss=4.67, val_accuracy=0.288, lr=0.1] 99%|█████████▊| 74/75 [27:48<00:22, 22.96s/epoch, loss=1.12, accuracy=0.759, val_loss=1.9, val_accuracy=0.503, lr=0.1] 100%|██████████| 75/75 [28:10<00:00, 22.72s/epoch, loss=1.14, accuracy=0.755, val_loss=3.25, val_accuracy=0.36, lr=0.1]100%|██████████| 75/75 [28:10<00:00, 22.54s/epoch, loss=1.14, accuracy=0.755, val_loss=3.25, val_accuracy=0.36, lr=0.1]
Using real-time data augmentation.
Test score: 3.247732639312744
Test accuracy: 0.3603000044822693


* * * Run SGD for ID = 20_5. * * *


2024-03-05 15:21:07.792578: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 15:21:10.606100: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 15:21:10.607037: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-05 15:21:10.645797: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-05 15:21:10.645827: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 15:21:10.649103: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 15:21:10.649148: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 15:21:10.651504: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 15:21:10.652670: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 15:21:10.655274: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 15:21:10.656750: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 15:21:10.661564: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 15:21:10.662133: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 15:21:10.662231: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 15:21:11.874969: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-05 15:21:11.875939: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 15:21:11.876750: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-05 15:21:11.876790: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 15:21:11.876826: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 15:21:11.876843: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 15:21:11.876860: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 15:21:11.876877: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 15:21:11.876893: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 15:21:11.876908: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 15:21:11.876924: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 15:21:11.877446: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 15:21:11.877480: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 15:21:12.533109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-05 15:21:12.533165: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-05 15:21:12.533175: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-05 15:21:12.534118: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:02:00.0, compute capability: 6.1)
{'id': '20_05', 'seed': 5, 'out_folder': 'results/epoch_budget', 'batch_size': 128, 'epochs': 75, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'bootstrapping': False, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/75 [00:00<?, ?epoch/s]2024-03-05 15:21:13.388967: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-05 15:21:13.389692: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199825000 Hz
2024-03-05 15:21:15.448035: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 15:21:15.679132: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 15:21:16.497624: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-05 15:21:16.552727: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|▏         | 1/75 [00:53<1:06:12, 53.69s/epoch, loss=3.24, accuracy=0.315, val_loss=2.27, val_accuracy=0.292, lr=0.1]  3%|▎         | 2/75 [01:15<42:37, 35.03s/epoch, loss=1.6, accuracy=0.521, val_loss=1.96, val_accuracy=0.42, lr=0.1]      4%|▍         | 3/75 [01:37<34:48, 29.00s/epoch, loss=1.39, accuracy=0.62, val_loss=2.18, val_accuracy=0.423, lr=0.1]  5%|▌         | 4/75 [01:59<30:55, 26.13s/epoch, loss=1.3, accuracy=0.676, val_loss=2.53, val_accuracy=0.436, lr=0.1]  7%|▋         | 5/75 [02:20<28:38, 24.55s/epoch, loss=1.27, accuracy=0.698, val_loss=2.14, val_accuracy=0.403, lr=0.1]  8%|▊         | 6/75 [02:42<27:11, 23.65s/epoch, loss=1.25, accuracy=0.706, val_loss=1.9, val_accuracy=0.509, lr=0.1]   9%|▉         | 7/75 [03:04<26:06, 23.03s/epoch, loss=1.23, accuracy=0.716, val_loss=1.78, val_accuracy=0.537, lr=0.1] 11%|█         | 8/75 [03:26<25:24, 22.75s/epoch, loss=1.22, accuracy=0.722, val_loss=1.7, val_accuracy=0.578, lr=0.1]  12%|█▏        | 9/75 [03:48<24:42, 22.46s/epoch, loss=1.21, accuracy=0.724, val_loss=2.18, val_accuracy=0.394, lr=0.1] 13%|█▎        | 10/75 [04:10<24:13, 22.36s/epoch, loss=1.21, accuracy=0.727, val_loss=2.31, val_accuracy=0.423, lr=0.1] 15%|█▍        | 11/75 [04:32<23:43, 22.24s/epoch, loss=1.2, accuracy=0.726, val_loss=2.14, val_accuracy=0.484, lr=0.1]  16%|█▌        | 12/75 [04:55<23:24, 22.30s/epoch, loss=1.19, accuracy=0.735, val_loss=1.83, val_accuracy=0.568, lr=0.1] 17%|█▋        | 13/75 [05:16<22:52, 22.15s/epoch, loss=1.19, accuracy=0.734, val_loss=1.75, val_accuracy=0.547, lr=0.0316] 19%|█▊        | 14/75 [05:38<22:24, 22.05s/epoch, loss=1.18, accuracy=0.739, val_loss=3.33, val_accuracy=0.386, lr=0.1]    20%|██        | 15/75 [06:00<21:57, 21.96s/epoch, loss=1.17, accuracy=0.738, val_loss=1.9, val_accuracy=0.549, lr=0.1]  21%|██▏       | 16/75 [06:22<21:32, 21.90s/epoch, loss=1.18, accuracy=0.741, val_loss=2.31, val_accuracy=0.474, lr=0.1] 23%|██▎       | 17/75 [06:44<21:08, 21.87s/epoch, loss=1.17, accuracy=0.742, val_loss=1.85, val_accuracy=0.523, lr=0.1] 24%|██▍       | 18/75 [07:05<20:47, 21.88s/epoch, loss=1.17, accuracy=0.743, val_loss=1.89, val_accuracy=0.579, lr=0.0316] 25%|██▌       | 19/75 [07:27<20:24, 21.86s/epoch, loss=1.17, accuracy=0.743, val_loss=1.93, val_accuracy=0.508, lr=0.1]    27%|██▋       | 20/75 [07:49<20:01, 21.85s/epoch, loss=1.16, accuracy=0.745, val_loss=1.56, val_accuracy=0.613, lr=0.1] 28%|██▊       | 21/75 [08:12<19:48, 22.01s/epoch, loss=1.16, accuracy=0.746, val_loss=2.89, val_accuracy=0.339, lr=0.1] 29%|██▉       | 22/75 [08:33<19:22, 21.94s/epoch, loss=1.16, accuracy=0.747, val_loss=1.58, val_accuracy=0.619, lr=0.1] 31%|███       | 23/75 [08:56<19:05, 22.02s/epoch, loss=1.16, accuracy=0.747, val_loss=1.76, val_accuracy=0.603, lr=0.1] 32%|███▏      | 24/75 [09:18<18:44, 22.06s/epoch, loss=1.15, accuracy=0.748, val_loss=1.99, val_accuracy=0.482, lr=0.1] 33%|███▎      | 25/75 [09:40<18:22, 22.06s/epoch, loss=1.15, accuracy=0.75, val_loss=1.77, val_accuracy=0.57, lr=0.0316] 35%|███▍      | 26/75 [10:02<17:58, 22.01s/epoch, loss=1.15, accuracy=0.75, val_loss=2.34, val_accuracy=0.462, lr=0.1]   36%|███▌      | 27/75 [10:24<17:40, 22.09s/epoch, loss=1.15, accuracy=0.749, val_loss=2.23, val_accuracy=0.465, lr=0.1] 37%|███▋      | 28/75 [10:46<17:22, 22.19s/epoch, loss=1.16, accuracy=0.747, val_loss=1.6, val_accuracy=0.609, lr=0.1]  39%|███▊      | 29/75 [11:08<16:56, 22.09s/epoch, loss=1.15, accuracy=0.754, val_loss=2.67, val_accuracy=0.388, lr=0.1] 40%|████      | 30/75 [11:30<16:29, 21.98s/epoch, loss=1.15, accuracy=0.751, val_loss=2.74, val_accuracy=0.369, lr=0.0316] 41%|████▏     | 31/75 [11:51<16:01, 21.85s/epoch, loss=1.14, accuracy=0.751, val_loss=2.21, val_accuracy=0.451, lr=0.1]    43%|████▎     | 32/75 [12:13<15:37, 21.81s/epoch, loss=1.14, accuracy=0.753, val_loss=5.24, val_accuracy=0.33, lr=0.1]  44%|████▍     | 33/75 [12:35<15:18, 21.86s/epoch, loss=1.15, accuracy=0.752, val_loss=1.91, val_accuracy=0.521, lr=0.1] 45%|████▌     | 34/75 [12:58<15:04, 22.07s/epoch, loss=1.14, accuracy=0.751, val_loss=3.1, val_accuracy=0.344, lr=0.1]  47%|████▋     | 35/75 [13:19<14:38, 21.96s/epoch, loss=1.14, accuracy=0.751, val_loss=2.67, val_accuracy=0.357, lr=0.0316] 48%|████▊     | 36/75 [13:41<14:17, 21.99s/epoch, loss=1.13, accuracy=0.754, val_loss=1.86, val_accuracy=0.515, lr=0.1]    49%|████▉     | 37/75 [14:03<13:55, 21.99s/epoch, loss=1.14, accuracy=0.753, val_loss=2.18, val_accuracy=0.479, lr=0.1] 51%|█████     | 38/75 [14:25<13:33, 21.99s/epoch, loss=1.13, accuracy=0.754, val_loss=2.03, val_accuracy=0.462, lr=0.1] 52%|█████▏    | 39/75 [14:47<13:08, 21.91s/epoch, loss=1.14, accuracy=0.754, val_loss=1.62, val_accuracy=0.588, lr=0.1] 53%|█████▎    | 40/75 [15:09<12:46, 21.89s/epoch, loss=1.13, accuracy=0.753, val_loss=2.08, val_accuracy=0.487, lr=0.0316] 55%|█████▍    | 41/75 [15:31<12:23, 21.86s/epoch, loss=1.14, accuracy=0.755, val_loss=2.31, val_accuracy=0.467, lr=0.1]    56%|█████▌    | 42/75 [15:53<12:00, 21.83s/epoch, loss=1.13, accuracy=0.757, val_loss=1.5, val_accuracy=0.627, lr=0.1]  57%|█████▋    | 43/75 [16:14<11:38, 21.82s/epoch, loss=1.13, accuracy=0.755, val_loss=1.84, val_accuracy=0.559, lr=0.1] 59%|█████▊    | 44/75 [16:37<11:19, 21.93s/epoch, loss=1.13, accuracy=0.754, val_loss=1.59, val_accuracy=0.605, lr=0.1] 60%|██████    | 45/75 [16:59<10:59, 21.98s/epoch, loss=1.14, accuracy=0.754, val_loss=2.1, val_accuracy=0.427, lr=0.1]  61%|██████▏   | 46/75 [17:21<10:37, 21.99s/epoch, loss=1.13, accuracy=0.754, val_loss=3.3, val_accuracy=0.341, lr=0.1] 63%|██████▎   | 47/75 [17:43<10:20, 22.16s/epoch, loss=1.13, accuracy=0.756, val_loss=1.76, val_accuracy=0.538, lr=0.0316] 64%|██████▍   | 48/75 [18:05<09:58, 22.18s/epoch, loss=1.13, accuracy=0.753, val_loss=4.14, val_accuracy=0.302, lr=0.1]    65%|██████▌   | 49/75 [18:28<09:37, 22.22s/epoch, loss=1.13, accuracy=0.755, val_loss=2.08, val_accuracy=0.491, lr=0.1] 67%|██████▋   | 50/75 [18:50<09:15, 22.21s/epoch, loss=1.12, accuracy=0.756, val_loss=2.94, val_accuracy=0.317, lr=0.1] 68%|██████▊   | 51/75 [19:12<08:50, 22.10s/epoch, loss=1.13, accuracy=0.755, val_loss=2.53, val_accuracy=0.437, lr=0.1] 69%|██████▉   | 52/75 [19:34<08:25, 21.99s/epoch, loss=1.13, accuracy=0.756, val_loss=1.87, val_accuracy=0.52, lr=0.0316] 71%|███████   | 53/75 [19:56<08:03, 21.99s/epoch, loss=1.13, accuracy=0.757, val_loss=2.1, val_accuracy=0.405, lr=0.1]    72%|███████▏  | 54/75 [20:18<07:42, 22.04s/epoch, loss=1.13, accuracy=0.757, val_loss=2.16, val_accuracy=0.425, lr=0.1] 73%|███████▎  | 55/75 [20:40<07:21, 22.10s/epoch, loss=1.12, accuracy=0.757, val_loss=3.05, val_accuracy=0.369, lr=0.1] 75%|███████▍  | 56/75 [21:02<06:59, 22.09s/epoch, loss=1.13, accuracy=0.755, val_loss=1.82, val_accuracy=0.529, lr=0.1] 76%|███████▌  | 57/75 [21:24<06:36, 22.06s/epoch, loss=1.13, accuracy=0.757, val_loss=1.83, val_accuracy=0.565, lr=0.0316] 77%|███████▋  | 58/75 [21:47<06:19, 22.32s/epoch, loss=1.13, accuracy=0.753, val_loss=1.87, val_accuracy=0.575, lr=0.1]    79%|███████▊  | 59/75 [22:09<05:55, 22.21s/epoch, loss=1.12, accuracy=0.758, val_loss=1.74, val_accuracy=0.573, lr=0.1] 80%|████████  | 60/75 [22:31<05:32, 22.17s/epoch, loss=1.13, accuracy=0.753, val_loss=1.52, val_accuracy=0.614, lr=0.1] 81%|████████▏ | 61/75 [22:53<05:09, 22.09s/epoch, loss=1.12, accuracy=0.757, val_loss=1.96, val_accuracy=0.542, lr=0.1] 83%|████████▎ | 62/75 [23:15<04:47, 22.11s/epoch, loss=1.13, accuracy=0.756, val_loss=2.27, val_accuracy=0.445, lr=0.0316] 84%|████████▍ | 63/75 [23:37<04:24, 22.07s/epoch, loss=1.13, accuracy=0.755, val_loss=1.92, val_accuracy=0.545, lr=0.1]    85%|████████▌ | 64/75 [23:59<04:02, 22.02s/epoch, loss=1.12, accuracy=0.756, val_loss=3.26, val_accuracy=0.331, lr=0.1] 87%|████████▋ | 65/75 [24:21<03:39, 21.93s/epoch, loss=1.11, accuracy=0.761, val_loss=1.89, val_accuracy=0.53, lr=0.1]  88%|████████▊ | 66/75 [24:42<03:17, 21.90s/epoch, loss=1.12, accuracy=0.757, val_loss=1.72, val_accuracy=0.568, lr=0.1] 89%|████████▉ | 67/75 [25:04<02:55, 21.91s/epoch, loss=1.12, accuracy=0.756, val_loss=2.07, val_accuracy=0.535, lr=0.0316] 91%|█████████ | 68/75 [25:26<02:33, 21.96s/epoch, loss=1.12, accuracy=0.756, val_loss=1.71, val_accuracy=0.567, lr=0.1]    92%|█████████▏| 69/75 [25:48<02:11, 21.89s/epoch, loss=1.13, accuracy=0.754, val_loss=2.26, val_accuracy=0.479, lr=0.1] 93%|█████████▎| 70/75 [26:11<01:50, 22.05s/epoch, loss=1.13, accuracy=0.757, val_loss=3.79, val_accuracy=0.18, lr=0.1]  95%|█████████▍| 71/75 [26:33<01:28, 22.13s/epoch, loss=1.12, accuracy=0.759, val_loss=2.4, val_accuracy=0.416, lr=0.1] 96%|█████████▌| 72/75 [26:55<01:06, 22.05s/epoch, loss=1.14, accuracy=0.756, val_loss=2.22, val_accuracy=0.534, lr=0.0316] 97%|█████████▋| 73/75 [27:17<00:43, 21.98s/epoch, loss=1.11, accuracy=0.759, val_loss=1.57, val_accuracy=0.597, lr=0.1]    99%|█████████▊| 74/75 [27:38<00:21, 21.96s/epoch, loss=1.12, accuracy=0.757, val_loss=1.42, val_accuracy=0.672, lr=0.1]100%|██████████| 75/75 [28:00<00:00, 21.88s/epoch, loss=1.12, accuracy=0.756, val_loss=2.83, val_accuracy=0.398, lr=0.1]100%|██████████| 75/75 [28:00<00:00, 22.41s/epoch, loss=1.12, accuracy=0.756, val_loss=2.83, val_accuracy=0.398, lr=0.1]
Using real-time data augmentation.
Test score: 2.8255815505981445
Test accuracy: 0.3978999853134155


* * * Run SGD for ID = 20_6. * * *


2024-03-05 15:49:18.020747: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 15:49:20.975523: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 15:49:20.976473: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-05 15:49:21.021854: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-05 15:49:21.021893: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 15:49:21.024841: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 15:49:21.024881: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 15:49:21.027488: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 15:49:21.028180: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 15:49:21.030802: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 15:49:21.032293: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 15:49:21.036873: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 15:49:21.040154: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 15:49:21.040251: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 15:49:22.299088: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-05 15:49:22.299607: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 15:49:22.300451: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-05 15:49:22.300482: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 15:49:22.300518: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 15:49:22.300535: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 15:49:22.300552: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 15:49:22.300570: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 15:49:22.300586: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 15:49:22.300602: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 15:49:22.300617: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 15:49:22.301102: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 15:49:22.301138: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 15:49:22.958326: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-05 15:49:22.958396: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-05 15:49:22.958413: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-05 15:49:22.961035: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:02:00.0, compute capability: 6.1)
{'id': '20_06', 'seed': 6, 'out_folder': 'results/epoch_budget', 'batch_size': 128, 'epochs': 75, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'bootstrapping': False, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/75 [00:00<?, ?epoch/s]2024-03-05 15:49:23.814245: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-05 15:49:23.814808: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199825000 Hz
2024-03-05 15:49:25.896323: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 15:49:26.178737: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 15:49:27.051271: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-05 15:49:27.137588: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|▏         | 1/75 [00:53<1:05:54, 53.43s/epoch, loss=3.08, accuracy=0.33, val_loss=2.4, val_accuracy=0.233, lr=0.1]  3%|▎         | 2/75 [01:15<42:23, 34.84s/epoch, loss=1.57, accuracy=0.534, val_loss=2.51, val_accuracy=0.342, lr=0.1]  4%|▍         | 3/75 [01:37<35:08, 29.28s/epoch, loss=1.4, accuracy=0.613, val_loss=2.9, val_accuracy=0.328, lr=0.1]    5%|▌         | 4/75 [01:59<31:06, 26.29s/epoch, loss=1.31, accuracy=0.667, val_loss=1.72, val_accuracy=0.537, lr=0.1]  7%|▋         | 5/75 [02:21<28:40, 24.58s/epoch, loss=1.26, accuracy=0.693, val_loss=3.09, val_accuracy=0.352, lr=0.1]  8%|▊         | 6/75 [02:42<27:06, 23.57s/epoch, loss=1.24, accuracy=0.705, val_loss=1.9, val_accuracy=0.494, lr=0.1]   9%|▉         | 7/75 [03:04<25:58, 22.92s/epoch, loss=1.23, accuracy=0.712, val_loss=2.57, val_accuracy=0.45, lr=0.1] 11%|█         | 8/75 [03:25<25:07, 22.50s/epoch, loss=1.22, accuracy=0.722, val_loss=2.7, val_accuracy=0.401, lr=0.1] 12%|█▏        | 9/75 [03:47<24:26, 22.22s/epoch, loss=1.21, accuracy=0.722, val_loss=2.18, val_accuracy=0.45, lr=0.0316] 13%|█▎        | 10/75 [04:09<23:50, 22.01s/epoch, loss=1.21, accuracy=0.727, val_loss=1.93, val_accuracy=0.466, lr=0.1]  15%|█▍        | 11/75 [04:30<23:18, 21.86s/epoch, loss=1.2, accuracy=0.729, val_loss=1.8, val_accuracy=0.561, lr=0.1]   16%|█▌        | 12/75 [04:52<22:54, 21.81s/epoch, loss=1.19, accuracy=0.734, val_loss=1.6, val_accuracy=0.608, lr=0.1] 17%|█▋        | 13/75 [05:13<22:27, 21.73s/epoch, loss=1.19, accuracy=0.734, val_loss=2.1, val_accuracy=0.523, lr=0.1] 19%|█▊        | 14/75 [05:35<22:03, 21.70s/epoch, loss=1.18, accuracy=0.738, val_loss=3.18, val_accuracy=0.289, lr=0.1] 20%|██        | 15/75 [05:57<21:45, 21.76s/epoch, loss=1.19, accuracy=0.736, val_loss=1.66, val_accuracy=0.559, lr=0.1] 21%|██▏       | 16/75 [06:18<21:19, 21.69s/epoch, loss=1.18, accuracy=0.741, val_loss=1.73, val_accuracy=0.598, lr=0.1] 23%|██▎       | 17/75 [06:40<20:52, 21.60s/epoch, loss=1.17, accuracy=0.743, val_loss=2.5, val_accuracy=0.398, lr=0.0316] 24%|██▍       | 18/75 [07:01<20:31, 21.61s/epoch, loss=1.17, accuracy=0.742, val_loss=1.68, val_accuracy=0.554, lr=0.1]   25%|██▌       | 19/75 [07:23<20:06, 21.55s/epoch, loss=1.17, accuracy=0.741, val_loss=1.52, val_accuracy=0.608, lr=0.1] 27%|██▋       | 20/75 [07:45<19:46, 21.58s/epoch, loss=1.16, accuracy=0.746, val_loss=1.67, val_accuracy=0.597, lr=0.1] 28%|██▊       | 21/75 [08:06<19:29, 21.65s/epoch, loss=1.17, accuracy=0.744, val_loss=2.79, val_accuracy=0.341, lr=0.1] 29%|██▉       | 22/75 [08:28<19:10, 21.70s/epoch, loss=1.17, accuracy=0.744, val_loss=2.25, val_accuracy=0.432, lr=0.1] 31%|███       | 23/75 [08:50<18:47, 21.69s/epoch, loss=1.17, accuracy=0.745, val_loss=1.68, val_accuracy=0.569, lr=0.1] 32%|███▏      | 24/75 [09:12<18:27, 21.72s/epoch, loss=1.16, accuracy=0.744, val_loss=2.43, val_accuracy=0.494, lr=0.0316] 33%|███▎      | 25/75 [09:35<18:31, 22.23s/epoch, loss=1.16, accuracy=0.744, val_loss=2.19, val_accuracy=0.477, lr=0.1]    35%|███▍      | 26/75 [09:57<18:05, 22.15s/epoch, loss=1.16, accuracy=0.748, val_loss=2.35, val_accuracy=0.434, lr=0.1] 36%|███▌      | 27/75 [10:19<17:43, 22.15s/epoch, loss=1.16, accuracy=0.745, val_loss=1.61, val_accuracy=0.598, lr=0.1] 37%|███▋      | 28/75 [10:41<17:13, 21.98s/epoch, loss=1.16, accuracy=0.746, val_loss=2.51, val_accuracy=0.423, lr=0.1] 39%|███▊      | 29/75 [11:02<16:47, 21.89s/epoch, loss=1.16, accuracy=0.747, val_loss=1.77, val_accuracy=0.559, lr=0.0316] 40%|████      | 30/75 [11:24<16:21, 21.81s/epoch, loss=1.15, accuracy=0.75, val_loss=1.79, val_accuracy=0.528, lr=0.1]     41%|████▏     | 31/75 [11:45<15:54, 21.70s/epoch, loss=1.16, accuracy=0.75, val_loss=1.8, val_accuracy=0.566, lr=0.1]  43%|████▎     | 32/75 [12:07<15:31, 21.66s/epoch, loss=1.16, accuracy=0.748, val_loss=2.49, val_accuracy=0.41, lr=0.1] 44%|████▍     | 33/75 [12:29<15:13, 21.74s/epoch, loss=1.15, accuracy=0.752, val_loss=2.6, val_accuracy=0.416, lr=0.1] 45%|████▌     | 34/75 [12:51<14:49, 21.70s/epoch, loss=1.16, accuracy=0.749, val_loss=1.56, val_accuracy=0.621, lr=0.0316] 47%|████▋     | 35/75 [13:12<14:27, 21.68s/epoch, loss=1.14, accuracy=0.752, val_loss=2.83, val_accuracy=0.33, lr=0.1]     48%|████▊     | 36/75 [13:34<14:03, 21.62s/epoch, loss=1.13, accuracy=0.752, val_loss=2.56, val_accuracy=0.412, lr=0.1] 49%|████▉     | 37/75 [13:55<13:40, 21.58s/epoch, loss=1.15, accuracy=0.749, val_loss=2.48, val_accuracy=0.397, lr=0.1] 51%|█████     | 38/75 [14:17<13:22, 21.69s/epoch, loss=1.14, accuracy=0.751, val_loss=1.83, val_accuracy=0.505, lr=0.1] 52%|█████▏    | 39/75 [14:39<13:01, 21.71s/epoch, loss=1.14, accuracy=0.753, val_loss=1.78, val_accuracy=0.539, lr=0.0316] 53%|█████▎    | 40/75 [15:00<12:35, 21.60s/epoch, loss=1.14, accuracy=0.751, val_loss=1.85, val_accuracy=0.533, lr=0.1]    55%|█████▍    | 41/75 [15:22<12:14, 21.60s/epoch, loss=1.14, accuracy=0.751, val_loss=2.32, val_accuracy=0.476, lr=0.1] 56%|█████▌    | 42/75 [15:43<11:52, 21.60s/epoch, loss=1.14, accuracy=0.753, val_loss=2.22, val_accuracy=0.488, lr=0.1] 57%|█████▋    | 43/75 [16:05<11:31, 21.61s/epoch, loss=1.15, accuracy=0.752, val_loss=1.92, val_accuracy=0.531, lr=0.1] 59%|█████▊    | 44/75 [16:27<11:11, 21.66s/epoch, loss=1.15, accuracy=0.751, val_loss=1.98, val_accuracy=0.548, lr=0.0316] 60%|██████    | 45/75 [16:48<10:49, 21.64s/epoch, loss=1.14, accuracy=0.754, val_loss=4.49, val_accuracy=0.263, lr=0.1]    61%|██████▏   | 46/75 [17:10<10:27, 21.65s/epoch, loss=1.14, accuracy=0.753, val_loss=4.11, val_accuracy=0.32, lr=0.1]  63%|██████▎   | 47/75 [17:32<10:11, 21.84s/epoch, loss=1.14, accuracy=0.756, val_loss=1.61, val_accuracy=0.589, lr=0.1] 64%|██████▍   | 48/75 [17:54<09:47, 21.75s/epoch, loss=1.14, accuracy=0.753, val_loss=2.84, val_accuracy=0.393, lr=0.1] 65%|██████▌   | 49/75 [18:15<09:23, 21.69s/epoch, loss=1.14, accuracy=0.751, val_loss=1.75, val_accuracy=0.558, lr=0.0316] 67%|██████▋   | 50/75 [18:37<09:00, 21.63s/epoch, loss=1.14, accuracy=0.752, val_loss=1.84, val_accuracy=0.546, lr=0.1]    68%|██████▊   | 51/75 [18:58<08:38, 21.61s/epoch, loss=1.14, accuracy=0.753, val_loss=1.73, val_accuracy=0.578, lr=0.1] 69%|██████▉   | 52/75 [19:20<08:16, 21.60s/epoch, loss=1.14, accuracy=0.751, val_loss=3.26, val_accuracy=0.394, lr=0.1] 71%|███████   | 53/75 [19:42<07:56, 21.65s/epoch, loss=1.14, accuracy=0.752, val_loss=1.67, val_accuracy=0.589, lr=0.1] 72%|███████▏  | 54/75 [20:04<07:36, 21.73s/epoch, loss=1.14, accuracy=0.753, val_loss=1.83, val_accuracy=0.579, lr=0.0316] 73%|███████▎  | 55/75 [20:25<07:14, 21.72s/epoch, loss=1.14, accuracy=0.754, val_loss=1.91, val_accuracy=0.487, lr=0.1]    75%|███████▍  | 56/75 [20:47<06:52, 21.70s/epoch, loss=1.14, accuracy=0.755, val_loss=1.61, val_accuracy=0.588, lr=0.1] 76%|███████▌  | 57/75 [21:10<06:34, 21.92s/epoch, loss=1.14, accuracy=0.755, val_loss=2.06, val_accuracy=0.49, lr=0.1]  77%|███████▋  | 58/75 [21:31<06:10, 21.82s/epoch, loss=1.14, accuracy=0.756, val_loss=4.06, val_accuracy=0.377, lr=0.1] 79%|███████▊  | 59/75 [21:53<05:47, 21.72s/epoch, loss=1.14, accuracy=0.753, val_loss=2.17, val_accuracy=0.498, lr=0.0316] 80%|████████  | 60/75 [22:14<05:26, 21.75s/epoch, loss=1.14, accuracy=0.755, val_loss=3.13, val_accuracy=0.392, lr=0.1]    81%|████████▏ | 61/75 [22:37<05:06, 21.88s/epoch, loss=1.12, accuracy=0.758, val_loss=1.87, val_accuracy=0.553, lr=0.1] 83%|████████▎ | 62/75 [22:58<04:44, 21.86s/epoch, loss=1.15, accuracy=0.75, val_loss=1.62, val_accuracy=0.601, lr=0.1]  84%|████████▍ | 63/75 [23:20<04:22, 21.91s/epoch, loss=1.13, accuracy=0.756, val_loss=3.27, val_accuracy=0.338, lr=0.1] 85%|████████▌ | 64/75 [23:43<04:02, 22.07s/epoch, loss=1.13, accuracy=0.754, val_loss=2.63, val_accuracy=0.373, lr=0.0316] 87%|████████▋ | 65/75 [24:05<03:39, 21.95s/epoch, loss=1.14, accuracy=0.752, val_loss=2.11, val_accuracy=0.48, lr=0.1]     88%|████████▊ | 66/75 [24:27<03:17, 21.96s/epoch, loss=1.13, accuracy=0.757, val_loss=1.75, val_accuracy=0.571, lr=0.1] 89%|████████▉ | 67/75 [24:48<02:54, 21.87s/epoch, loss=1.13, accuracy=0.755, val_loss=1.96, val_accuracy=0.531, lr=0.1] 91%|█████████ | 68/75 [25:10<02:32, 21.77s/epoch, loss=1.13, accuracy=0.754, val_loss=2.42, val_accuracy=0.427, lr=0.1] 92%|█████████▏| 69/75 [25:32<02:10, 21.83s/epoch, loss=1.13, accuracy=0.757, val_loss=1.78, val_accuracy=0.54, lr=0.0316] 93%|█████████▎| 70/75 [25:53<01:48, 21.74s/epoch, loss=1.13, accuracy=0.755, val_loss=5.26, val_accuracy=0.251, lr=0.1]   95%|█████████▍| 71/75 [26:15<01:26, 21.65s/epoch, loss=1.13, accuracy=0.754, val_loss=3.53, val_accuracy=0.368, lr=0.1] 96%|█████████▌| 72/75 [26:36<01:04, 21.65s/epoch, loss=1.13, accuracy=0.755, val_loss=2.51, val_accuracy=0.453, lr=0.1] 97%|█████████▋| 73/75 [26:58<00:43, 21.56s/epoch, loss=1.14, accuracy=0.754, val_loss=2.8, val_accuracy=0.318, lr=0.1]  99%|█████████▊| 74/75 [27:20<00:21, 21.76s/epoch, loss=1.14, accuracy=0.756, val_loss=1.65, val_accuracy=0.581, lr=0.0316]100%|██████████| 75/75 [27:43<00:00, 22.07s/epoch, loss=1.14, accuracy=0.752, val_loss=2.77, val_accuracy=0.398, lr=0.1]   100%|██████████| 75/75 [27:43<00:00, 22.18s/epoch, loss=1.14, accuracy=0.752, val_loss=2.77, val_accuracy=0.398, lr=0.1]
Using real-time data augmentation.
Test score: 2.7692065238952637
Test accuracy: 0.39820000529289246


* * * Run SGD for ID = 20_7. * * *


2024-03-05 16:17:11.057965: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 16:17:16.829411: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 16:17:16.830424: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-05 16:17:16.872585: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-05 16:17:16.872616: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 16:17:16.878108: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 16:17:16.878151: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 16:17:16.881796: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 16:17:16.883760: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 16:17:16.887162: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 16:17:16.889682: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 16:17:16.895772: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 16:17:16.896359: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 16:17:16.896455: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 16:17:18.190737: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-05 16:17:18.191774: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 16:17:18.192256: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-05 16:17:18.192287: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 16:17:18.192320: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 16:17:18.192354: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 16:17:18.192370: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 16:17:18.192387: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 16:17:18.192403: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 16:17:18.192420: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 16:17:18.192452: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 16:17:18.192901: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 16:17:18.192934: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 16:17:18.874949: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-05 16:17:18.875009: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-05 16:17:18.875019: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-05 16:17:18.876339: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:02:00.0, compute capability: 6.1)
{'id': '20_07', 'seed': 7, 'out_folder': 'results/epoch_budget', 'batch_size': 128, 'epochs': 75, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'bootstrapping': False, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/75 [00:00<?, ?epoch/s]2024-03-05 16:17:19.748508: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-05 16:17:19.749156: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199825000 Hz
2024-03-05 16:17:21.935761: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 16:17:22.183282: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 16:17:23.180203: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-05 16:17:23.221128: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|▏         | 1/75 [00:54<1:07:20, 54.60s/epoch, loss=3.26, accuracy=0.286, val_loss=2.16, val_accuracy=0.295, lr=0.1]  3%|▎         | 2/75 [01:17<43:27, 35.73s/epoch, loss=1.6, accuracy=0.518, val_loss=1.68, val_accuracy=0.486, lr=0.1]     4%|▍         | 3/75 [01:39<35:21, 29.46s/epoch, loss=1.38, accuracy=0.625, val_loss=2.3, val_accuracy=0.413, lr=0.1]  5%|▌         | 4/75 [02:01<31:28, 26.60s/epoch, loss=1.29, accuracy=0.679, val_loss=1.89, val_accuracy=0.503, lr=0.1]  7%|▋         | 5/75 [02:24<29:39, 25.42s/epoch, loss=1.26, accuracy=0.694, val_loss=1.43, val_accuracy=0.637, lr=0.1]  8%|▊         | 6/75 [02:46<27:58, 24.33s/epoch, loss=1.24, accuracy=0.709, val_loss=3.45, val_accuracy=0.298, lr=0.1]  9%|▉         | 7/75 [03:09<26:48, 23.65s/epoch, loss=1.23, accuracy=0.716, val_loss=1.74, val_accuracy=0.547, lr=0.1] 11%|█         | 8/75 [03:30<25:46, 23.07s/epoch, loss=1.21, accuracy=0.721, val_loss=2.36, val_accuracy=0.386, lr=0.1] 12%|█▏        | 9/75 [03:53<25:14, 22.95s/epoch, loss=1.21, accuracy=0.725, val_loss=1.54, val_accuracy=0.595, lr=0.1] 13%|█▎        | 10/75 [04:16<24:58, 23.05s/epoch, loss=1.2, accuracy=0.73, val_loss=1.84, val_accuracy=0.584, lr=0.0316] 15%|█▍        | 11/75 [04:39<24:24, 22.89s/epoch, loss=1.2, accuracy=0.73, val_loss=1.64, val_accuracy=0.596, lr=0.1]    16%|█▌        | 12/75 [05:02<24:05, 22.94s/epoch, loss=1.19, accuracy=0.732, val_loss=1.85, val_accuracy=0.488, lr=0.1] 17%|█▋        | 13/75 [05:24<23:29, 22.73s/epoch, loss=1.19, accuracy=0.732, val_loss=1.8, val_accuracy=0.494, lr=0.1]  19%|█▊        | 14/75 [05:46<22:52, 22.50s/epoch, loss=1.18, accuracy=0.736, val_loss=1.48, val_accuracy=0.627, lr=0.1] 20%|██        | 15/75 [06:08<22:23, 22.39s/epoch, loss=1.17, accuracy=0.738, val_loss=1.75, val_accuracy=0.533, lr=0.0316] 21%|██▏       | 16/75 [06:31<22:03, 22.43s/epoch, loss=1.17, accuracy=0.737, val_loss=1.65, val_accuracy=0.561, lr=0.1]    23%|██▎       | 17/75 [06:53<21:35, 22.33s/epoch, loss=1.18, accuracy=0.737, val_loss=1.91, val_accuracy=0.56, lr=0.1]  24%|██▍       | 18/75 [07:15<20:59, 22.10s/epoch, loss=1.17, accuracy=0.741, val_loss=1.5, val_accuracy=0.63, lr=0.1]  25%|██▌       | 19/75 [07:36<20:30, 21.97s/epoch, loss=1.17, accuracy=0.742, val_loss=2.15, val_accuracy=0.5, lr=0.1] 27%|██▋       | 20/75 [07:58<20:00, 21.82s/epoch, loss=1.16, accuracy=0.745, val_loss=2.19, val_accuracy=0.511, lr=0.0316] 28%|██▊       | 21/75 [08:20<19:45, 21.95s/epoch, loss=1.16, accuracy=0.747, val_loss=1.86, val_accuracy=0.549, lr=0.1]    29%|██▉       | 22/75 [08:42<19:21, 21.92s/epoch, loss=1.16, accuracy=0.743, val_loss=1.7, val_accuracy=0.6, lr=0.1]    31%|███       | 23/75 [09:04<18:57, 21.88s/epoch, loss=1.16, accuracy=0.743, val_loss=1.98, val_accuracy=0.523, lr=0.1] 32%|███▏      | 24/75 [09:26<18:37, 21.92s/epoch, loss=1.16, accuracy=0.747, val_loss=1.98, val_accuracy=0.483, lr=0.1] 33%|███▎      | 25/75 [09:48<18:19, 21.98s/epoch, loss=1.15, accuracy=0.749, val_loss=2.88, val_accuracy=0.369, lr=0.0316] 35%|███▍      | 26/75 [10:10<17:58, 22.00s/epoch, loss=1.15, accuracy=0.747, val_loss=1.75, val_accuracy=0.549, lr=0.1]    36%|███▌      | 27/75 [10:32<17:42, 22.14s/epoch, loss=1.15, accuracy=0.745, val_loss=2.25, val_accuracy=0.371, lr=0.1] 37%|███▋      | 28/75 [10:55<17:32, 22.40s/epoch, loss=1.15, accuracy=0.75, val_loss=1.73, val_accuracy=0.545, lr=0.1]  39%|███▊      | 29/75 [11:17<17:02, 22.23s/epoch, loss=1.15, accuracy=0.747, val_loss=1.96, val_accuracy=0.5, lr=0.1]  40%|████      | 30/75 [11:40<16:47, 22.38s/epoch, loss=1.14, accuracy=0.748, val_loss=2.07, val_accuracy=0.433, lr=0.0316] 41%|████▏     | 31/75 [12:02<16:21, 22.31s/epoch, loss=1.14, accuracy=0.749, val_loss=1.66, val_accuracy=0.577, lr=0.1]    43%|████▎     | 32/75 [12:24<15:55, 22.21s/epoch, loss=1.15, accuracy=0.748, val_loss=2.25, val_accuracy=0.458, lr=0.1] 44%|████▍     | 33/75 [12:46<15:29, 22.14s/epoch, loss=1.14, accuracy=0.752, val_loss=3.1, val_accuracy=0.31, lr=0.1]   45%|████▌     | 34/75 [13:09<15:21, 22.48s/epoch, loss=1.14, accuracy=0.75, val_loss=2.62, val_accuracy=0.423, lr=0.1] 47%|████▋     | 35/75 [13:33<15:14, 22.86s/epoch, loss=1.14, accuracy=0.75, val_loss=2.01, val_accuracy=0.517, lr=0.0316] 48%|████▊     | 36/75 [13:56<14:55, 22.96s/epoch, loss=1.14, accuracy=0.751, val_loss=1.76, val_accuracy=0.554, lr=0.1]   49%|████▉     | 37/75 [14:18<14:25, 22.77s/epoch, loss=1.13, accuracy=0.749, val_loss=2.58, val_accuracy=0.491, lr=0.1] 51%|█████     | 38/75 [14:41<13:56, 22.62s/epoch, loss=1.13, accuracy=0.754, val_loss=1.93, val_accuracy=0.538, lr=0.1] 52%|█████▏    | 39/75 [15:03<13:26, 22.41s/epoch, loss=1.14, accuracy=0.749, val_loss=1.68, val_accuracy=0.577, lr=0.1] 53%|█████▎    | 40/75 [15:26<13:10, 22.58s/epoch, loss=1.13, accuracy=0.752, val_loss=1.69, val_accuracy=0.57, lr=0.0316] 55%|█████▍    | 41/75 [15:49<12:53, 22.75s/epoch, loss=1.13, accuracy=0.753, val_loss=1.79, val_accuracy=0.517, lr=0.1]   56%|█████▌    | 42/75 [16:11<12:22, 22.49s/epoch, loss=1.13, accuracy=0.753, val_loss=1.84, val_accuracy=0.529, lr=0.1] 57%|█████▋    | 43/75 [16:33<11:54, 22.32s/epoch, loss=1.13, accuracy=0.752, val_loss=1.51, val_accuracy=0.616, lr=0.1] 59%|█████▊    | 44/75 [16:55<11:29, 22.23s/epoch, loss=1.12, accuracy=0.755, val_loss=2.77, val_accuracy=0.331, lr=0.1] 60%|██████    | 45/75 [17:17<11:07, 22.26s/epoch, loss=1.12, accuracy=0.754, val_loss=4.79, val_accuracy=0.296, lr=0.0316] 61%|██████▏   | 46/75 [17:39<10:43, 22.18s/epoch, loss=1.13, accuracy=0.754, val_loss=2.22, val_accuracy=0.42, lr=0.1]     63%|██████▎   | 47/75 [18:01<10:21, 22.19s/epoch, loss=1.13, accuracy=0.752, val_loss=4.66, val_accuracy=0.34, lr=0.1] 64%|██████▍   | 48/75 [18:24<10:01, 22.28s/epoch, loss=1.13, accuracy=0.752, val_loss=3.26, val_accuracy=0.314, lr=0.1] 65%|██████▌   | 49/75 [18:46<09:37, 22.22s/epoch, loss=1.13, accuracy=0.755, val_loss=2.32, val_accuracy=0.473, lr=0.1] 67%|██████▋   | 50/75 [19:08<09:18, 22.32s/epoch, loss=1.12, accuracy=0.754, val_loss=2.46, val_accuracy=0.472, lr=0.0316] 68%|██████▊   | 51/75 [19:30<08:54, 22.25s/epoch, loss=1.13, accuracy=0.756, val_loss=1.65, val_accuracy=0.559, lr=0.1]    69%|██████▉   | 52/75 [19:52<08:31, 22.22s/epoch, loss=1.13, accuracy=0.755, val_loss=2.02, val_accuracy=0.468, lr=0.1] 71%|███████   | 53/75 [20:14<08:06, 22.13s/epoch, loss=1.12, accuracy=0.756, val_loss=1.9, val_accuracy=0.508, lr=0.1]  72%|███████▏  | 54/75 [20:37<07:47, 22.29s/epoch, loss=1.12, accuracy=0.755, val_loss=2.27, val_accuracy=0.446, lr=0.1] 73%|███████▎  | 55/75 [20:59<07:24, 22.22s/epoch, loss=1.12, accuracy=0.753, val_loss=3.95, val_accuracy=0.207, lr=0.0316] 75%|███████▍  | 56/75 [21:21<07:01, 22.17s/epoch, loss=1.12, accuracy=0.756, val_loss=1.52, val_accuracy=0.635, lr=0.1]    76%|███████▌  | 57/75 [21:43<06:37, 22.11s/epoch, loss=1.13, accuracy=0.754, val_loss=1.55, val_accuracy=0.622, lr=0.1] 77%|███████▋  | 58/75 [22:05<06:17, 22.18s/epoch, loss=1.12, accuracy=0.754, val_loss=4.18, val_accuracy=0.33, lr=0.1]  79%|███████▊  | 59/75 [22:28<05:54, 22.15s/epoch, loss=1.12, accuracy=0.754, val_loss=2.42, val_accuracy=0.399, lr=0.1] 80%|████████  | 60/75 [22:50<05:31, 22.10s/epoch, loss=1.12, accuracy=0.756, val_loss=1.93, val_accuracy=0.503, lr=0.0316] 81%|████████▏ | 61/75 [23:12<05:10, 22.17s/epoch, loss=1.12, accuracy=0.756, val_loss=2.41, val_accuracy=0.39, lr=0.1]     83%|████████▎ | 62/75 [23:35<04:52, 22.52s/epoch, loss=1.11, accuracy=0.756, val_loss=2.63, val_accuracy=0.386, lr=0.1] 84%|████████▍ | 63/75 [23:57<04:28, 22.41s/epoch, loss=1.12, accuracy=0.755, val_loss=1.49, val_accuracy=0.629, lr=0.1] 85%|████████▌ | 64/75 [24:20<04:06, 22.39s/epoch, loss=1.12, accuracy=0.758, val_loss=5.57, val_accuracy=0.283, lr=0.1] 87%|████████▋ | 65/75 [24:42<03:43, 22.35s/epoch, loss=1.11, accuracy=0.758, val_loss=1.97, val_accuracy=0.529, lr=0.0316] 88%|████████▊ | 66/75 [25:04<03:20, 22.25s/epoch, loss=1.12, accuracy=0.756, val_loss=7.81, val_accuracy=0.186, lr=0.1]    89%|████████▉ | 67/75 [25:26<02:56, 22.11s/epoch, loss=1.12, accuracy=0.754, val_loss=2.74, val_accuracy=0.415, lr=0.1] 91%|█████████ | 68/75 [25:48<02:34, 22.04s/epoch, loss=1.12, accuracy=0.756, val_loss=2.73, val_accuracy=0.396, lr=0.1] 92%|█████████▏| 69/75 [26:10<02:12, 22.04s/epoch, loss=1.11, accuracy=0.757, val_loss=1.9, val_accuracy=0.538, lr=0.1]  93%|█████████▎| 70/75 [26:32<01:50, 22.01s/epoch, loss=1.13, accuracy=0.752, val_loss=2.05, val_accuracy=0.55, lr=0.0316] 95%|█████████▍| 71/75 [26:54<01:28, 22.10s/epoch, loss=1.11, accuracy=0.758, val_loss=2.87, val_accuracy=0.411, lr=0.1]   96%|█████████▌| 72/75 [27:16<01:06, 22.08s/epoch, loss=1.11, accuracy=0.76, val_loss=2.32, val_accuracy=0.463, lr=0.1]  97%|█████████▋| 73/75 [27:38<00:44, 22.17s/epoch, loss=1.11, accuracy=0.759, val_loss=1.79, val_accuracy=0.547, lr=0.1] 99%|█████████▊| 74/75 [28:00<00:22, 22.13s/epoch, loss=1.12, accuracy=0.757, val_loss=5.47, val_accuracy=0.122, lr=0.1]100%|██████████| 75/75 [28:22<00:00, 22.12s/epoch, loss=1.12, accuracy=0.758, val_loss=2.35, val_accuracy=0.466, lr=0.0316]100%|██████████| 75/75 [28:22<00:00, 22.71s/epoch, loss=1.12, accuracy=0.758, val_loss=2.35, val_accuracy=0.466, lr=0.0316]
Using real-time data augmentation.
Test score: 2.354732036590576
Test accuracy: 0.4661000072956085


* * * Run SGD for ID = 20_8. * * *


2024-03-05 16:45:46.471314: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 16:45:50.198799: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 16:45:50.200000: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-05 16:45:50.243116: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-05 16:45:50.243146: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 16:45:50.247443: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 16:45:50.247484: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 16:45:50.250083: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 16:45:50.251152: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 16:45:50.253693: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 16:45:50.255699: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 16:45:50.260693: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 16:45:50.261250: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 16:45:50.261345: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 16:45:51.587411: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-05 16:45:51.587965: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 16:45:51.588797: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-05 16:45:51.588829: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 16:45:51.588866: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 16:45:51.588883: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 16:45:51.588900: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 16:45:51.588917: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 16:45:51.588933: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 16:45:51.588948: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 16:45:51.588970: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 16:45:51.589544: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 16:45:51.589581: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 16:45:52.328607: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-05 16:45:52.328664: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-05 16:45:52.328673: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-05 16:45:52.329641: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:02:00.0, compute capability: 6.1)
{'id': '20_08', 'seed': 8, 'out_folder': 'results/epoch_budget', 'batch_size': 128, 'epochs': 75, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'bootstrapping': False, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/75 [00:00<?, ?epoch/s]2024-03-05 16:45:53.216545: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-05 16:45:53.217121: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199825000 Hz
2024-03-05 16:45:55.308724: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 16:45:55.523821: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 16:45:56.393596: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-05 16:45:56.448617: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|▏         | 1/75 [00:58<1:12:37, 58.88s/epoch, loss=2.75, accuracy=0.428, val_loss=2.5, val_accuracy=0.328, lr=0.1]  3%|▎         | 2/75 [01:21<45:51, 37.70s/epoch, loss=1.39, accuracy=0.625, val_loss=1.67, val_accuracy=0.547, lr=0.1]   4%|▍         | 3/75 [01:44<37:02, 30.87s/epoch, loss=1.27, accuracy=0.68, val_loss=2.66, val_accuracy=0.292, lr=0.1]   5%|▌         | 4/75 [02:06<32:33, 27.52s/epoch, loss=1.23, accuracy=0.703, val_loss=1.85, val_accuracy=0.496, lr=0.1]  7%|▋         | 5/75 [02:29<30:00, 25.72s/epoch, loss=1.22, accuracy=0.714, val_loss=3.86, val_accuracy=0.253, lr=0.1]  8%|▊         | 6/75 [02:52<28:43, 24.98s/epoch, loss=1.19, accuracy=0.723, val_loss=2.44, val_accuracy=0.419, lr=0.1]  9%|▉         | 7/75 [03:15<27:29, 24.26s/epoch, loss=1.19, accuracy=0.725, val_loss=2.09, val_accuracy=0.456, lr=0.0316] 11%|█         | 8/75 [03:39<26:51, 24.05s/epoch, loss=1.17, accuracy=0.735, val_loss=1.75, val_accuracy=0.525, lr=0.1]    12%|█▏        | 9/75 [04:02<26:08, 23.77s/epoch, loss=1.17, accuracy=0.737, val_loss=2.23, val_accuracy=0.435, lr=0.1] 13%|█▎        | 10/75 [04:24<25:17, 23.34s/epoch, loss=1.18, accuracy=0.735, val_loss=3.26, val_accuracy=0.298, lr=0.1] 15%|█▍        | 11/75 [04:47<24:31, 22.99s/epoch, loss=1.16, accuracy=0.745, val_loss=1.8, val_accuracy=0.579, lr=0.1]  16%|█▌        | 12/75 [05:09<23:57, 22.82s/epoch, loss=1.17, accuracy=0.743, val_loss=3.92, val_accuracy=0.388, lr=0.0316] 17%|█▋        | 13/75 [05:31<23:26, 22.69s/epoch, loss=1.17, accuracy=0.743, val_loss=2.06, val_accuracy=0.477, lr=0.1]    19%|█▊        | 14/75 [05:54<22:59, 22.62s/epoch, loss=1.16, accuracy=0.745, val_loss=1.69, val_accuracy=0.616, lr=0.1] 20%|██        | 15/75 [06:16<22:31, 22.52s/epoch, loss=1.15, accuracy=0.745, val_loss=2.5, val_accuracy=0.308, lr=0.1]  21%|██▏       | 16/75 [06:39<22:21, 22.73s/epoch, loss=1.15, accuracy=0.749, val_loss=1.68, val_accuracy=0.571, lr=0.1] 23%|██▎       | 17/75 [07:02<21:59, 22.75s/epoch, loss=1.15, accuracy=0.749, val_loss=2.38, val_accuracy=0.444, lr=0.0316] 24%|██▍       | 18/75 [07:25<21:30, 22.65s/epoch, loss=1.14, accuracy=0.75, val_loss=2.27, val_accuracy=0.496, lr=0.1]     25%|██▌       | 19/75 [07:47<21:01, 22.53s/epoch, loss=1.15, accuracy=0.749, val_loss=1.71, val_accuracy=0.566, lr=0.1] 27%|██▋       | 20/75 [08:09<20:39, 22.53s/epoch, loss=1.15, accuracy=0.75, val_loss=2.54, val_accuracy=0.382, lr=0.1]  28%|██▊       | 21/75 [08:32<20:16, 22.54s/epoch, loss=1.14, accuracy=0.752, val_loss=2.04, val_accuracy=0.505, lr=0.1] 29%|██▉       | 22/75 [08:55<19:58, 22.61s/epoch, loss=1.14, accuracy=0.752, val_loss=3.54, val_accuracy=0.314, lr=0.0316] 31%|███       | 23/75 [09:17<19:33, 22.57s/epoch, loss=1.13, accuracy=0.754, val_loss=2.51, val_accuracy=0.412, lr=0.1]    32%|███▏      | 24/75 [09:40<19:14, 22.64s/epoch, loss=1.14, accuracy=0.751, val_loss=3.15, val_accuracy=0.309, lr=0.1] 33%|███▎      | 25/75 [10:03<18:56, 22.73s/epoch, loss=1.14, accuracy=0.753, val_loss=1.63, val_accuracy=0.586, lr=0.1] 35%|███▍      | 26/75 [10:25<18:31, 22.68s/epoch, loss=1.13, accuracy=0.755, val_loss=2.03, val_accuracy=0.457, lr=0.1] 36%|███▌      | 27/75 [10:48<18:09, 22.71s/epoch, loss=1.13, accuracy=0.753, val_loss=2.38, val_accuracy=0.461, lr=0.1] 37%|███▋      | 28/75 [11:11<17:54, 22.86s/epoch, loss=1.13, accuracy=0.753, val_loss=1.51, val_accuracy=0.634, lr=0.1] 39%|███▊      | 29/75 [11:34<17:29, 22.81s/epoch, loss=1.14, accuracy=0.756, val_loss=3.44, val_accuracy=0.392, lr=0.1] 40%|████      | 30/75 [11:58<17:16, 23.03s/epoch, loss=1.13, accuracy=0.756, val_loss=1.4, val_accuracy=0.653, lr=0.1]  41%|████▏     | 31/75 [12:20<16:45, 22.85s/epoch, loss=1.12, accuracy=0.756, val_loss=2.12, val_accuracy=0.512, lr=0.1] 43%|████▎     | 32/75 [12:42<16:16, 22.71s/epoch, loss=1.13, accuracy=0.754, val_loss=2.16, val_accuracy=0.424, lr=0.1] 44%|████▍     | 33/75 [13:05<15:52, 22.67s/epoch, loss=1.13, accuracy=0.754, val_loss=1.59, val_accuracy=0.584, lr=0.1] 45%|████▌     | 34/75 [13:28<15:26, 22.61s/epoch, loss=1.13, accuracy=0.754, val_loss=1.55, val_accuracy=0.625, lr=0.1] 47%|████▋     | 35/75 [13:50<15:01, 22.53s/epoch, loss=1.13, accuracy=0.758, val_loss=1.79, val_accuracy=0.521, lr=0.0316] 48%|████▊     | 36/75 [14:12<14:39, 22.54s/epoch, loss=1.13, accuracy=0.756, val_loss=2.86, val_accuracy=0.447, lr=0.1]    49%|████▉     | 37/75 [14:35<14:15, 22.52s/epoch, loss=1.12, accuracy=0.757, val_loss=2.31, val_accuracy=0.407, lr=0.1] 51%|█████     | 38/75 [14:57<13:51, 22.48s/epoch, loss=1.13, accuracy=0.756, val_loss=3.32, val_accuracy=0.352, lr=0.1] 52%|█████▏    | 39/75 [15:20<13:29, 22.50s/epoch, loss=1.13, accuracy=0.755, val_loss=3.49, val_accuracy=0.308, lr=0.1] 53%|█████▎    | 40/75 [15:43<13:12, 22.65s/epoch, loss=1.12, accuracy=0.757, val_loss=1.98, val_accuracy=0.457, lr=0.0316] 55%|█████▍    | 41/75 [16:05<12:48, 22.60s/epoch, loss=1.12, accuracy=0.759, val_loss=2.12, val_accuracy=0.515, lr=0.1]    56%|█████▌    | 42/75 [16:28<12:28, 22.68s/epoch, loss=1.13, accuracy=0.755, val_loss=4.74, val_accuracy=0.15, lr=0.1]  57%|█████▋    | 43/75 [16:50<12:02, 22.57s/epoch, loss=1.12, accuracy=0.76, val_loss=3.47, val_accuracy=0.326, lr=0.1] 59%|█████▊    | 44/75 [17:13<11:36, 22.47s/epoch, loss=1.12, accuracy=0.759, val_loss=2.7, val_accuracy=0.417, lr=0.1] 60%|██████    | 45/75 [17:35<11:16, 22.54s/epoch, loss=1.12, accuracy=0.759, val_loss=1.76, val_accuracy=0.592, lr=0.0316] 61%|██████▏   | 46/75 [17:58<10:53, 22.54s/epoch, loss=1.11, accuracy=0.757, val_loss=1.41, val_accuracy=0.666, lr=0.1]    63%|██████▎   | 47/75 [18:20<10:30, 22.53s/epoch, loss=1.11, accuracy=0.76, val_loss=2.07, val_accuracy=0.457, lr=0.1]  64%|██████▍   | 48/75 [18:43<10:11, 22.64s/epoch, loss=1.12, accuracy=0.757, val_loss=2.38, val_accuracy=0.446, lr=0.1] 65%|██████▌   | 49/75 [19:06<09:49, 22.68s/epoch, loss=1.12, accuracy=0.757, val_loss=2.28, val_accuracy=0.477, lr=0.1] 67%|██████▋   | 50/75 [19:29<09:25, 22.62s/epoch, loss=1.12, accuracy=0.756, val_loss=2.8, val_accuracy=0.272, lr=0.0316] 68%|██████▊   | 51/75 [19:51<09:03, 22.65s/epoch, loss=1.11, accuracy=0.761, val_loss=1.92, val_accuracy=0.494, lr=0.1]   69%|██████▉   | 52/75 [20:14<08:38, 22.54s/epoch, loss=1.12, accuracy=0.759, val_loss=1.96, val_accuracy=0.491, lr=0.1] 71%|███████   | 53/75 [20:36<08:16, 22.55s/epoch, loss=1.11, accuracy=0.763, val_loss=1.58, val_accuracy=0.624, lr=0.1] 72%|███████▏  | 54/75 [21:00<07:59, 22.81s/epoch, loss=1.11, accuracy=0.759, val_loss=2.42, val_accuracy=0.435, lr=0.1] 73%|███████▎  | 55/75 [21:23<07:37, 22.88s/epoch, loss=1.11, accuracy=0.759, val_loss=2.34, val_accuracy=0.429, lr=0.0316] 75%|███████▍  | 56/75 [21:45<07:14, 22.86s/epoch, loss=1.11, accuracy=0.758, val_loss=1.65, val_accuracy=0.578, lr=0.1]    76%|███████▌  | 57/75 [22:09<06:52, 22.94s/epoch, loss=1.12, accuracy=0.759, val_loss=2.82, val_accuracy=0.333, lr=0.1] 77%|███████▋  | 58/75 [22:32<06:31, 23.00s/epoch, loss=1.11, accuracy=0.759, val_loss=1.71, val_accuracy=0.56, lr=0.1]  79%|███████▊  | 59/75 [22:55<06:07, 22.94s/epoch, loss=1.11, accuracy=0.76, val_loss=2.44, val_accuracy=0.473, lr=0.1] 80%|████████  | 60/75 [23:17<05:43, 22.91s/epoch, loss=1.11, accuracy=0.757, val_loss=2.07, val_accuracy=0.467, lr=0.0316] 81%|████████▏ | 61/75 [23:40<05:19, 22.82s/epoch, loss=1.12, accuracy=0.758, val_loss=1.86, val_accuracy=0.538, lr=0.1]    83%|████████▎ | 62/75 [24:02<04:54, 22.65s/epoch, loss=1.11, accuracy=0.758, val_loss=3, val_accuracy=0.344, lr=0.1]    84%|████████▍ | 63/75 [24:25<04:33, 22.79s/epoch, loss=1.11, accuracy=0.761, val_loss=1.77, val_accuracy=0.571, lr=0.1] 85%|████████▌ | 64/75 [24:48<04:11, 22.86s/epoch, loss=1.11, accuracy=0.759, val_loss=3.59, val_accuracy=0.309, lr=0.1] 87%|████████▋ | 65/75 [25:11<03:47, 22.77s/epoch, loss=1.11, accuracy=0.76, val_loss=2.89, val_accuracy=0.382, lr=0.0316] 88%|████████▊ | 66/75 [25:33<03:23, 22.63s/epoch, loss=1.11, accuracy=0.76, val_loss=3.27, val_accuracy=0.35, lr=0.1]     89%|████████▉ | 67/75 [25:57<03:03, 22.93s/epoch, loss=1.11, accuracy=0.759, val_loss=2.24, val_accuracy=0.452, lr=0.1] 91%|█████████ | 68/75 [26:20<02:40, 22.89s/epoch, loss=1.12, accuracy=0.756, val_loss=1.85, val_accuracy=0.555, lr=0.1] 92%|█████████▏| 69/75 [26:42<02:16, 22.68s/epoch, loss=1.11, accuracy=0.757, val_loss=2.49, val_accuracy=0.433, lr=0.1] 93%|█████████▎| 70/75 [27:06<01:54, 22.97s/epoch, loss=1.11, accuracy=0.759, val_loss=5.06, val_accuracy=0.271, lr=0.0316] 95%|█████████▍| 71/75 [27:28<01:31, 22.87s/epoch, loss=1.11, accuracy=0.757, val_loss=3.58, val_accuracy=0.155, lr=0.1]    96%|█████████▌| 72/75 [27:51<01:08, 22.93s/epoch, loss=1.11, accuracy=0.76, val_loss=1.71, val_accuracy=0.535, lr=0.1]  97%|█████████▋| 73/75 [28:14<00:45, 22.90s/epoch, loss=1.11, accuracy=0.759, val_loss=2.94, val_accuracy=0.241, lr=0.1] 99%|█████████▊| 74/75 [28:37<00:22, 22.81s/epoch, loss=1.11, accuracy=0.759, val_loss=1.78, val_accuracy=0.537, lr=0.1]100%|██████████| 75/75 [29:00<00:00, 23.01s/epoch, loss=1.1, accuracy=0.762, val_loss=2.81, val_accuracy=0.28, lr=0.0316]100%|██████████| 75/75 [29:00<00:00, 23.21s/epoch, loss=1.1, accuracy=0.762, val_loss=2.81, val_accuracy=0.28, lr=0.0316]
Using real-time data augmentation.
Test score: 2.809866189956665
Test accuracy: 0.27959999442100525


* * * Run SGD for ID = 20_9. * * *


2024-03-05 17:14:58.948956: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 17:15:05.941498: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 17:15:05.942714: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-05 17:15:05.982815: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-05 17:15:05.982862: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 17:15:05.987899: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 17:15:05.987947: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 17:15:05.990982: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 17:15:05.993788: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 17:15:05.997779: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 17:15:05.999562: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 17:15:06.004741: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 17:15:06.005432: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 17:15:06.005528: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 17:15:07.453804: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-05 17:15:07.454417: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 17:15:07.455169: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-05 17:15:07.455201: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 17:15:07.455236: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 17:15:07.455253: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 17:15:07.455269: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 17:15:07.455294: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 17:15:07.455310: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 17:15:07.455326: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 17:15:07.455357: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 17:15:07.455827: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 17:15:07.455860: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 17:15:08.266170: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-05 17:15:08.266234: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-05 17:15:08.266248: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-05 17:15:08.267694: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:02:00.0, compute capability: 6.1)
{'id': '20_09', 'seed': 9, 'out_folder': 'results/epoch_budget', 'batch_size': 128, 'epochs': 75, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'bootstrapping': False, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/75 [00:00<?, ?epoch/s]2024-03-05 17:15:09.180995: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-05 17:15:09.181663: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199825000 Hz
2024-03-05 17:15:11.356289: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 17:15:11.611820: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 17:15:15.134975: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-05 17:15:15.183718: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|▏         | 1/75 [00:59<1:12:48, 59.03s/epoch, loss=2.83, accuracy=0.409, val_loss=1.99, val_accuracy=0.411, lr=0.1]  3%|▎         | 2/75 [01:21<45:31, 37.42s/epoch, loss=1.45, accuracy=0.591, val_loss=2.7, val_accuracy=0.367, lr=0.1]     4%|▍         | 3/75 [01:43<36:25, 30.36s/epoch, loss=1.28, accuracy=0.665, val_loss=2.34, val_accuracy=0.426, lr=0.1]  5%|▌         | 4/75 [02:05<32:14, 27.25s/epoch, loss=1.24, accuracy=0.692, val_loss=1.91, val_accuracy=0.505, lr=0.1]  7%|▋         | 5/75 [02:28<29:57, 25.68s/epoch, loss=1.23, accuracy=0.708, val_loss=1.81, val_accuracy=0.509, lr=0.1]  8%|▊         | 6/75 [02:50<28:08, 24.48s/epoch, loss=1.22, accuracy=0.719, val_loss=1.72, val_accuracy=0.528, lr=0.1]  9%|▉         | 7/75 [03:12<26:47, 23.64s/epoch, loss=1.21, accuracy=0.725, val_loss=2.3, val_accuracy=0.432, lr=0.1]  11%|█         | 8/75 [03:34<25:50, 23.14s/epoch, loss=1.2, accuracy=0.728, val_loss=2.68, val_accuracy=0.426, lr=0.1] 12%|█▏        | 9/75 [03:56<25:01, 22.75s/epoch, loss=1.19, accuracy=0.731, val_loss=4.61, val_accuracy=0.144, lr=0.1] 13%|█▎        | 10/75 [04:18<24:25, 22.54s/epoch, loss=1.18, accuracy=0.735, val_loss=2.36, val_accuracy=0.476, lr=0.1] 15%|█▍        | 11/75 [04:42<24:20, 22.82s/epoch, loss=1.19, accuracy=0.739, val_loss=2.14, val_accuracy=0.418, lr=0.0316] 16%|█▌        | 12/75 [05:04<23:55, 22.78s/epoch, loss=1.18, accuracy=0.739, val_loss=1.68, val_accuracy=0.57, lr=0.1]     17%|█▋        | 13/75 [05:27<23:24, 22.66s/epoch, loss=1.17, accuracy=0.74, val_loss=1.81, val_accuracy=0.518, lr=0.1] 19%|█▊        | 14/75 [05:49<22:47, 22.41s/epoch, loss=1.18, accuracy=0.74, val_loss=1.59, val_accuracy=0.615, lr=0.1] 20%|██        | 15/75 [06:10<22:11, 22.18s/epoch, loss=1.18, accuracy=0.743, val_loss=2.39, val_accuracy=0.433, lr=0.1] 21%|██▏       | 16/75 [06:33<21:55, 22.29s/epoch, loss=1.16, accuracy=0.743, val_loss=3.34, val_accuracy=0.354, lr=0.1] 23%|██▎       | 17/75 [06:55<21:26, 22.19s/epoch, loss=1.17, accuracy=0.746, val_loss=1.61, val_accuracy=0.624, lr=0.1] 24%|██▍       | 18/75 [07:17<21:02, 22.14s/epoch, loss=1.17, accuracy=0.743, val_loss=3.26, val_accuracy=0.274, lr=0.1] 25%|██▌       | 19/75 [07:39<20:36, 22.07s/epoch, loss=1.17, accuracy=0.742, val_loss=2.49, val_accuracy=0.46, lr=0.0316] 27%|██▋       | 20/75 [08:03<20:43, 22.61s/epoch, loss=1.16, accuracy=0.746, val_loss=3.53, val_accuracy=0.305, lr=0.1]   28%|██▊       | 21/75 [08:25<20:21, 22.62s/epoch, loss=1.16, accuracy=0.745, val_loss=2.05, val_accuracy=0.488, lr=0.1] 29%|██▉       | 22/75 [08:48<20:05, 22.74s/epoch, loss=1.16, accuracy=0.747, val_loss=2.64, val_accuracy=0.427, lr=0.1] 31%|███       | 23/75 [09:11<19:46, 22.82s/epoch, loss=1.15, accuracy=0.751, val_loss=2.62, val_accuracy=0.492, lr=0.1] 32%|███▏      | 24/75 [09:34<19:22, 22.79s/epoch, loss=1.15, accuracy=0.75, val_loss=1.96, val_accuracy=0.519, lr=0.0316] 33%|███▎      | 25/75 [09:56<18:46, 22.53s/epoch, loss=1.16, accuracy=0.748, val_loss=2.12, val_accuracy=0.417, lr=0.1]   35%|███▍      | 26/75 [10:18<18:21, 22.48s/epoch, loss=1.16, accuracy=0.75, val_loss=1.56, val_accuracy=0.641, lr=0.1]  36%|███▌      | 27/75 [10:41<17:57, 22.45s/epoch, loss=1.15, accuracy=0.752, val_loss=2.68, val_accuracy=0.38, lr=0.1] 37%|███▋      | 28/75 [11:03<17:30, 22.35s/epoch, loss=1.15, accuracy=0.749, val_loss=3.45, val_accuracy=0.243, lr=0.1] 39%|███▊      | 29/75 [11:25<17:02, 22.22s/epoch, loss=1.14, accuracy=0.752, val_loss=2.04, val_accuracy=0.48, lr=0.1]  40%|████      | 30/75 [11:47<16:39, 22.21s/epoch, loss=1.14, accuracy=0.751, val_loss=2.39, val_accuracy=0.454, lr=0.1] 41%|████▏     | 31/75 [12:09<16:20, 22.29s/epoch, loss=1.14, accuracy=0.752, val_loss=2.56, val_accuracy=0.333, lr=0.0316] 43%|████▎     | 32/75 [12:31<15:52, 22.15s/epoch, loss=1.14, accuracy=0.75, val_loss=2.5, val_accuracy=0.394, lr=0.1]      44%|████▍     | 33/75 [12:53<15:31, 22.18s/epoch, loss=1.14, accuracy=0.753, val_loss=1.44, val_accuracy=0.632, lr=0.1] 45%|████▌     | 34/75 [13:16<15:12, 22.26s/epoch, loss=1.14, accuracy=0.755, val_loss=1.91, val_accuracy=0.576, lr=0.1] 47%|████▋     | 35/75 [13:38<14:49, 22.23s/epoch, loss=1.14, accuracy=0.754, val_loss=1.8, val_accuracy=0.561, lr=0.1]  48%|████▊     | 36/75 [14:00<14:25, 22.20s/epoch, loss=1.14, accuracy=0.754, val_loss=1.8, val_accuracy=0.514, lr=0.1] 49%|████▉     | 37/75 [14:23<14:09, 22.36s/epoch, loss=1.14, accuracy=0.756, val_loss=1.95, val_accuracy=0.476, lr=0.1] 51%|█████     | 38/75 [14:45<13:44, 22.28s/epoch, loss=1.14, accuracy=0.756, val_loss=8.57, val_accuracy=0.194, lr=0.0316] 52%|█████▏    | 39/75 [15:07<13:23, 22.31s/epoch, loss=1.14, accuracy=0.755, val_loss=2.25, val_accuracy=0.465, lr=0.1]    53%|█████▎    | 40/75 [15:29<12:56, 22.18s/epoch, loss=1.13, accuracy=0.756, val_loss=2.15, val_accuracy=0.396, lr=0.1] 55%|█████▍    | 41/75 [15:51<12:30, 22.06s/epoch, loss=1.12, accuracy=0.757, val_loss=1.85, val_accuracy=0.565, lr=0.1] 56%|█████▌    | 42/75 [16:13<12:04, 21.96s/epoch, loss=1.13, accuracy=0.755, val_loss=1.66, val_accuracy=0.583, lr=0.1] 57%|█████▋    | 43/75 [16:34<11:39, 21.87s/epoch, loss=1.13, accuracy=0.756, val_loss=1.66, val_accuracy=0.573, lr=0.0316] 59%|█████▊    | 44/75 [16:58<11:37, 22.48s/epoch, loss=1.13, accuracy=0.756, val_loss=2.1, val_accuracy=0.427, lr=0.1]     60%|██████    | 45/75 [17:20<11:09, 22.33s/epoch, loss=1.13, accuracy=0.756, val_loss=1.6, val_accuracy=0.603, lr=0.1] 61%|██████▏   | 46/75 [17:42<10:44, 22.22s/epoch, loss=1.13, accuracy=0.757, val_loss=2.78, val_accuracy=0.311, lr=0.1] 63%|██████▎   | 47/75 [18:04<10:20, 22.15s/epoch, loss=1.13, accuracy=0.756, val_loss=1.83, val_accuracy=0.536, lr=0.1] 64%|██████▍   | 48/75 [18:27<10:01, 22.28s/epoch, loss=1.14, accuracy=0.757, val_loss=1.55, val_accuracy=0.621, lr=0.0316] 65%|██████▌   | 49/75 [18:49<09:36, 22.16s/epoch, loss=1.13, accuracy=0.755, val_loss=2.43, val_accuracy=0.279, lr=0.1]    67%|██████▋   | 50/75 [19:11<09:14, 22.19s/epoch, loss=1.13, accuracy=0.757, val_loss=2.07, val_accuracy=0.502, lr=0.1] 68%|██████▊   | 51/75 [19:33<08:54, 22.27s/epoch, loss=1.13, accuracy=0.757, val_loss=4.62, val_accuracy=0.257, lr=0.1] 69%|██████▉   | 52/75 [19:55<08:29, 22.17s/epoch, loss=1.13, accuracy=0.755, val_loss=2.33, val_accuracy=0.319, lr=0.1] 71%|███████   | 53/75 [20:18<08:08, 22.20s/epoch, loss=1.13, accuracy=0.757, val_loss=2.99, val_accuracy=0.278, lr=0.0316] 72%|███████▏  | 54/75 [20:40<07:50, 22.39s/epoch, loss=1.14, accuracy=0.758, val_loss=2.54, val_accuracy=0.371, lr=0.1]    73%|███████▎  | 55/75 [21:02<07:25, 22.26s/epoch, loss=1.12, accuracy=0.758, val_loss=2.48, val_accuracy=0.468, lr=0.1] 75%|███████▍  | 56/75 [21:25<07:04, 22.34s/epoch, loss=1.13, accuracy=0.76, val_loss=3.49, val_accuracy=0.17, lr=0.1]   76%|███████▌  | 57/75 [21:48<06:45, 22.55s/epoch, loss=1.12, accuracy=0.758, val_loss=1.62, val_accuracy=0.589, lr=0.1] 77%|███████▋  | 58/75 [22:10<06:21, 22.43s/epoch, loss=1.12, accuracy=0.758, val_loss=1.74, val_accuracy=0.566, lr=0.0316] 79%|███████▊  | 59/75 [22:33<05:58, 22.43s/epoch, loss=1.12, accuracy=0.758, val_loss=2.14, val_accuracy=0.425, lr=0.1]    80%|████████  | 60/75 [22:55<05:38, 22.58s/epoch, loss=1.13, accuracy=0.757, val_loss=1.63, val_accuracy=0.597, lr=0.1] 81%|████████▏ | 61/75 [23:17<05:13, 22.36s/epoch, loss=1.12, accuracy=0.757, val_loss=1.88, val_accuracy=0.503, lr=0.1] 83%|████████▎ | 62/75 [23:39<04:49, 22.25s/epoch, loss=1.12, accuracy=0.759, val_loss=1.98, val_accuracy=0.52, lr=0.1]  84%|████████▍ | 63/75 [24:01<04:26, 22.21s/epoch, loss=1.11, accuracy=0.758, val_loss=1.9, val_accuracy=0.561, lr=0.0316] 85%|████████▌ | 64/75 [24:24<04:06, 22.45s/epoch, loss=1.12, accuracy=0.758, val_loss=1.86, val_accuracy=0.534, lr=0.1]   87%|████████▋ | 65/75 [24:47<03:45, 22.53s/epoch, loss=1.11, accuracy=0.759, val_loss=2.1, val_accuracy=0.457, lr=0.1]  88%|████████▊ | 66/75 [25:11<03:25, 22.79s/epoch, loss=1.12, accuracy=0.758, val_loss=2.67, val_accuracy=0.311, lr=0.1] 89%|████████▉ | 67/75 [25:32<03:00, 22.52s/epoch, loss=1.12, accuracy=0.758, val_loss=2.92, val_accuracy=0.374, lr=0.1] 91%|█████████ | 68/75 [25:56<02:38, 22.71s/epoch, loss=1.12, accuracy=0.756, val_loss=1.69, val_accuracy=0.555, lr=0.0316] 92%|█████████▏| 69/75 [26:19<02:17, 22.84s/epoch, loss=1.12, accuracy=0.758, val_loss=5.05, val_accuracy=0.336, lr=0.1]    93%|█████████▎| 70/75 [26:41<01:53, 22.69s/epoch, loss=1.12, accuracy=0.757, val_loss=1.88, val_accuracy=0.5, lr=0.1]   95%|█████████▍| 71/75 [27:03<01:29, 22.46s/epoch, loss=1.12, accuracy=0.756, val_loss=1.86, val_accuracy=0.586, lr=0.1] 96%|█████████▌| 72/75 [27:25<01:07, 22.37s/epoch, loss=1.11, accuracy=0.758, val_loss=2.39, val_accuracy=0.449, lr=0.1] 97%|█████████▋| 73/75 [27:47<00:44, 22.23s/epoch, loss=1.12, accuracy=0.756, val_loss=2.05, val_accuracy=0.465, lr=0.0316] 99%|█████████▊| 74/75 [28:09<00:22, 22.20s/epoch, loss=1.11, accuracy=0.759, val_loss=2.87, val_accuracy=0.403, lr=0.1]   100%|██████████| 75/75 [28:32<00:00, 22.22s/epoch, loss=1.11, accuracy=0.757, val_loss=2.69, val_accuracy=0.326, lr=0.1]100%|██████████| 75/75 [28:32<00:00, 22.83s/epoch, loss=1.11, accuracy=0.757, val_loss=2.69, val_accuracy=0.326, lr=0.1]
Using real-time data augmentation.
Test score: 2.6944897174835205
Test accuracy: 0.3262999951839447


* * * Run SGD for ID = 20_10. * * *


2024-03-05 17:44:00.004104: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 17:44:29.174837: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 17:44:29.175914: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-05 17:44:29.224457: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-05 17:44:29.224486: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 17:44:29.239035: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 17:44:29.239120: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 17:44:29.242637: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 17:44:29.244724: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 17:44:29.248150: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 17:44:29.250931: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 17:44:29.257420: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 17:44:29.257932: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 17:44:29.258026: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 17:44:30.627092: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-05 17:44:30.627588: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 17:44:30.628058: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-05 17:44:30.628105: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 17:44:30.628138: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 17:44:30.628163: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 17:44:30.628181: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 17:44:30.628197: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 17:44:30.628214: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 17:44:30.628231: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 17:44:30.628248: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 17:44:30.628735: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 17:44:30.628774: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 17:44:31.377306: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-05 17:44:31.377382: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-05 17:44:31.377391: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-05 17:44:31.378775: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:02:00.0, compute capability: 6.1)
{'id': '20_10', 'seed': 10, 'out_folder': 'results/epoch_budget', 'batch_size': 128, 'epochs': 75, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'bootstrapping': False, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/75 [00:00<?, ?epoch/s]2024-03-05 17:44:32.281841: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-05 17:44:32.295189: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199825000 Hz
2024-03-05 17:44:34.434752: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 17:44:34.853974: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 17:44:35.700873: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-05 17:44:35.742867: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|▏         | 1/75 [00:56<1:09:27, 56.32s/epoch, loss=2.81, accuracy=0.406, val_loss=2.85, val_accuracy=0.233, lr=0.1]  3%|▎         | 2/75 [01:19<44:31, 36.60s/epoch, loss=1.43, accuracy=0.601, val_loss=1.86, val_accuracy=0.496, lr=0.1]    4%|▍         | 3/75 [01:42<36:34, 30.47s/epoch, loss=1.29, accuracy=0.673, val_loss=1.67, val_accuracy=0.538, lr=0.1]  5%|▌         | 4/75 [02:05<32:36, 27.56s/epoch, loss=1.25, accuracy=0.698, val_loss=2.13, val_accuracy=0.411, lr=0.1]  7%|▋         | 5/75 [02:28<30:05, 25.79s/epoch, loss=1.22, accuracy=0.71, val_loss=2.42, val_accuracy=0.35, lr=0.1]    8%|▊         | 6/75 [02:50<28:23, 24.69s/epoch, loss=1.21, accuracy=0.721, val_loss=1.57, val_accuracy=0.59, lr=0.1]  9%|▉         | 7/75 [03:13<27:16, 24.06s/epoch, loss=1.2, accuracy=0.726, val_loss=1.97, val_accuracy=0.429, lr=0.1] 11%|█         | 8/75 [03:35<26:21, 23.60s/epoch, loss=1.2, accuracy=0.728, val_loss=2.68, val_accuracy=0.293, lr=0.1] 12%|█▏        | 9/75 [03:59<25:51, 23.50s/epoch, loss=1.19, accuracy=0.736, val_loss=1.8, val_accuracy=0.549, lr=0.1] 13%|█▎        | 10/75 [04:22<25:20, 23.39s/epoch, loss=1.19, accuracy=0.734, val_loss=1.35, val_accuracy=0.676, lr=0.1] 15%|█▍        | 11/75 [04:45<24:48, 23.26s/epoch, loss=1.18, accuracy=0.739, val_loss=1.8, val_accuracy=0.559, lr=0.1]  16%|█▌        | 12/75 [05:08<24:30, 23.35s/epoch, loss=1.17, accuracy=0.74, val_loss=2.2, val_accuracy=0.448, lr=0.1]  17%|█▋        | 13/75 [05:31<23:53, 23.12s/epoch, loss=1.17, accuracy=0.739, val_loss=2.01, val_accuracy=0.466, lr=0.1] 19%|█▊        | 14/75 [05:54<23:30, 23.12s/epoch, loss=1.16, accuracy=0.744, val_loss=1.52, val_accuracy=0.614, lr=0.1] 20%|██        | 15/75 [06:17<23:04, 23.08s/epoch, loss=1.15, accuracy=0.746, val_loss=1.52, val_accuracy=0.624, lr=0.0316] 21%|██▏       | 16/75 [06:40<22:40, 23.05s/epoch, loss=1.15, accuracy=0.746, val_loss=1.91, val_accuracy=0.444, lr=0.1]    23%|██▎       | 17/75 [07:03<22:08, 22.91s/epoch, loss=1.15, accuracy=0.747, val_loss=1.63, val_accuracy=0.598, lr=0.1] 24%|██▍       | 18/75 [07:26<21:59, 23.15s/epoch, loss=1.15, accuracy=0.747, val_loss=2.43, val_accuracy=0.434, lr=0.1] 25%|██▌       | 19/75 [07:50<21:45, 23.31s/epoch, loss=1.14, accuracy=0.75, val_loss=2.85, val_accuracy=0.449, lr=0.1]  27%|██▋       | 20/75 [08:13<21:23, 23.33s/epoch, loss=1.14, accuracy=0.75, val_loss=2.28, val_accuracy=0.454, lr=0.0316] 28%|██▊       | 21/75 [08:36<20:53, 23.21s/epoch, loss=1.14, accuracy=0.752, val_loss=1.6, val_accuracy=0.607, lr=0.1]    29%|██▉       | 22/75 [09:00<20:30, 23.22s/epoch, loss=1.14, accuracy=0.751, val_loss=2.15, val_accuracy=0.514, lr=0.1] 31%|███       | 23/75 [09:23<20:09, 23.26s/epoch, loss=1.13, accuracy=0.751, val_loss=1.8, val_accuracy=0.597, lr=0.1]  32%|███▏      | 24/75 [09:48<20:12, 23.78s/epoch, loss=1.13, accuracy=0.753, val_loss=2.98, val_accuracy=0.242, lr=0.1] 33%|███▎      | 25/75 [10:11<19:40, 23.61s/epoch, loss=1.12, accuracy=0.753, val_loss=5.83, val_accuracy=0.244, lr=0.0316] 35%|███▍      | 26/75 [10:34<19:06, 23.39s/epoch, loss=1.12, accuracy=0.753, val_loss=1.93, val_accuracy=0.474, lr=0.1]    36%|███▌      | 27/75 [10:57<18:35, 23.24s/epoch, loss=1.12, accuracy=0.752, val_loss=1.62, val_accuracy=0.602, lr=0.1] 37%|███▋      | 28/75 [11:20<18:13, 23.26s/epoch, loss=1.12, accuracy=0.754, val_loss=2.17, val_accuracy=0.488, lr=0.1] 39%|███▊      | 29/75 [11:43<17:45, 23.16s/epoch, loss=1.12, accuracy=0.756, val_loss=1.72, val_accuracy=0.567, lr=0.1] 40%|████      | 30/75 [12:06<17:22, 23.17s/epoch, loss=1.11, accuracy=0.757, val_loss=2.74, val_accuracy=0.363, lr=0.0316] 41%|████▏     | 31/75 [12:31<17:16, 23.55s/epoch, loss=1.12, accuracy=0.755, val_loss=1.99, val_accuracy=0.469, lr=0.1]    43%|████▎     | 32/75 [12:55<16:55, 23.63s/epoch, loss=1.12, accuracy=0.756, val_loss=1.84, val_accuracy=0.525, lr=0.1] 44%|████▍     | 33/75 [13:18<16:30, 23.57s/epoch, loss=1.12, accuracy=0.756, val_loss=2.06, val_accuracy=0.495, lr=0.1] 45%|████▌     | 34/75 [13:42<16:13, 23.75s/epoch, loss=1.12, accuracy=0.76, val_loss=1.73, val_accuracy=0.582, lr=0.1]  47%|████▋     | 35/75 [14:05<15:42, 23.56s/epoch, loss=1.11, accuracy=0.757, val_loss=1.63, val_accuracy=0.58, lr=0.0316] 48%|████▊     | 36/75 [14:29<15:16, 23.50s/epoch, loss=1.12, accuracy=0.757, val_loss=1.63, val_accuracy=0.594, lr=0.1]   49%|████▉     | 37/75 [14:52<14:45, 23.29s/epoch, loss=1.12, accuracy=0.757, val_loss=1.89, val_accuracy=0.469, lr=0.1] 51%|█████     | 38/75 [15:14<14:16, 23.14s/epoch, loss=1.11, accuracy=0.759, val_loss=1.36, val_accuracy=0.665, lr=0.1] 52%|█████▏    | 39/75 [15:37<13:46, 22.97s/epoch, loss=1.12, accuracy=0.756, val_loss=1.91, val_accuracy=0.56, lr=0.1]  53%|█████▎    | 40/75 [16:00<13:21, 22.91s/epoch, loss=1.11, accuracy=0.758, val_loss=1.52, val_accuracy=0.636, lr=0.0316] 55%|█████▍    | 41/75 [16:22<12:58, 22.88s/epoch, loss=1.11, accuracy=0.758, val_loss=1.56, val_accuracy=0.604, lr=0.1]    56%|█████▌    | 42/75 [16:45<12:34, 22.85s/epoch, loss=1.11, accuracy=0.755, val_loss=1.82, val_accuracy=0.536, lr=0.1] 57%|█████▋    | 43/75 [17:08<12:09, 22.81s/epoch, loss=1.11, accuracy=0.759, val_loss=2.28, val_accuracy=0.364, lr=0.1] 59%|█████▊    | 44/75 [17:31<11:47, 22.81s/epoch, loss=1.11, accuracy=0.759, val_loss=1.98, val_accuracy=0.477, lr=0.1] 60%|██████    | 45/75 [17:54<11:27, 22.93s/epoch, loss=1.1, accuracy=0.76, val_loss=2.52, val_accuracy=0.437, lr=0.0316] 61%|██████▏   | 46/75 [18:17<11:05, 22.96s/epoch, loss=1.11, accuracy=0.758, val_loss=3.12, val_accuracy=0.352, lr=0.1]  63%|██████▎   | 47/75 [18:40<10:44, 23.02s/epoch, loss=1.11, accuracy=0.758, val_loss=1.74, val_accuracy=0.562, lr=0.1] 64%|██████▍   | 48/75 [19:03<10:20, 22.99s/epoch, loss=1.11, accuracy=0.76, val_loss=2.12, val_accuracy=0.507, lr=0.1]  65%|██████▌   | 49/75 [19:26<10:00, 23.08s/epoch, loss=1.11, accuracy=0.758, val_loss=3.27, val_accuracy=0.401, lr=0.1] 67%|██████▋   | 50/75 [19:49<09:34, 22.99s/epoch, loss=1.1, accuracy=0.759, val_loss=2.03, val_accuracy=0.438, lr=0.0316] 68%|██████▊   | 51/75 [20:13<09:20, 23.36s/epoch, loss=1.11, accuracy=0.758, val_loss=2.82, val_accuracy=0.408, lr=0.1]   69%|██████▉   | 52/75 [20:37<08:57, 23.36s/epoch, loss=1.11, accuracy=0.759, val_loss=2, val_accuracy=0.483, lr=0.1]    71%|███████   | 53/75 [21:00<08:32, 23.27s/epoch, loss=1.11, accuracy=0.76, val_loss=1.84, val_accuracy=0.482, lr=0.1] 72%|███████▏  | 54/75 [21:23<08:06, 23.17s/epoch, loss=1.11, accuracy=0.761, val_loss=2.65, val_accuracy=0.368, lr=0.1] 73%|███████▎  | 55/75 [21:46<07:43, 23.16s/epoch, loss=1.11, accuracy=0.757, val_loss=3.26, val_accuracy=0.389, lr=0.0316] 75%|███████▍  | 56/75 [22:09<07:20, 23.17s/epoch, loss=1.11, accuracy=0.761, val_loss=2.5, val_accuracy=0.374, lr=0.1]     76%|███████▌  | 57/75 [22:32<06:56, 23.13s/epoch, loss=1.11, accuracy=0.761, val_loss=3.43, val_accuracy=0.361, lr=0.1] 77%|███████▋  | 58/75 [22:56<06:36, 23.30s/epoch, loss=1.11, accuracy=0.76, val_loss=3.99, val_accuracy=0.32, lr=0.1]   79%|███████▊  | 59/75 [23:19<06:11, 23.19s/epoch, loss=1.1, accuracy=0.758, val_loss=3.28, val_accuracy=0.354, lr=0.1] 80%|████████  | 60/75 [23:42<05:46, 23.10s/epoch, loss=1.11, accuracy=0.761, val_loss=3.08, val_accuracy=0.322, lr=0.0316] 81%|████████▏ | 61/75 [24:05<05:24, 23.17s/epoch, loss=1.11, accuracy=0.759, val_loss=2.41, val_accuracy=0.331, lr=0.1]    83%|████████▎ | 62/75 [24:28<04:59, 23.05s/epoch, loss=1.11, accuracy=0.759, val_loss=1.72, val_accuracy=0.563, lr=0.1] 84%|████████▍ | 63/75 [24:51<04:36, 23.05s/epoch, loss=1.1, accuracy=0.759, val_loss=1.67, val_accuracy=0.571, lr=0.1]  85%|████████▌ | 64/75 [25:14<04:12, 22.97s/epoch, loss=1.1, accuracy=0.761, val_loss=2.45, val_accuracy=0.387, lr=0.1] 87%|████████▋ | 65/75 [25:37<03:49, 22.97s/epoch, loss=1.11, accuracy=0.757, val_loss=2.21, val_accuracy=0.501, lr=0.0316] 88%|████████▊ | 66/75 [26:00<03:27, 23.06s/epoch, loss=1.1, accuracy=0.762, val_loss=1.49, val_accuracy=0.665, lr=0.1]     89%|████████▉ | 67/75 [26:23<03:03, 22.96s/epoch, loss=1.1, accuracy=0.76, val_loss=2.37, val_accuracy=0.388, lr=0.1]  91%|█████████ | 68/75 [26:45<02:40, 22.91s/epoch, loss=1.1, accuracy=0.76, val_loss=2.66, val_accuracy=0.288, lr=0.1] 92%|█████████▏| 69/75 [27:09<02:18, 23.06s/epoch, loss=1.11, accuracy=0.759, val_loss=1.85, val_accuracy=0.54, lr=0.1] 93%|█████████▎| 70/75 [27:32<01:55, 23.11s/epoch, loss=1.1, accuracy=0.759, val_loss=2.56, val_accuracy=0.317, lr=0.0316] 95%|█████████▍| 71/75 [27:56<01:33, 23.30s/epoch, loss=1.1, accuracy=0.758, val_loss=2.42, val_accuracy=0.399, lr=0.1]    96%|█████████▌| 72/75 [28:20<01:10, 23.48s/epoch, loss=1.12, accuracy=0.759, val_loss=2.55, val_accuracy=0.312, lr=0.1] 97%|█████████▋| 73/75 [28:43<00:46, 23.37s/epoch, loss=1.11, accuracy=0.761, val_loss=2.13, val_accuracy=0.43, lr=0.1]  99%|█████████▊| 74/75 [29:06<00:23, 23.34s/epoch, loss=1.11, accuracy=0.759, val_loss=7.83, val_accuracy=0.15, lr=0.1]100%|██████████| 75/75 [29:29<00:00, 23.18s/epoch, loss=1.1, accuracy=0.76, val_loss=1.91, val_accuracy=0.507, lr=0.0316]100%|██████████| 75/75 [29:29<00:00, 23.59s/epoch, loss=1.1, accuracy=0.76, val_loss=1.91, val_accuracy=0.507, lr=0.0316]
Using real-time data augmentation.
Test score: 1.9050021171569824
Test accuracy: 0.5072000026702881


* * * Run SGD for ID = 20_11. * * *


2024-03-05 18:14:06.391263: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 18:14:12.229782: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 18:14:12.230859: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-05 18:14:12.271126: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-05 18:14:12.271159: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 18:14:12.274991: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 18:14:12.275035: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 18:14:12.277425: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 18:14:12.278225: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 18:14:12.280723: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 18:14:12.282290: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 18:14:12.288007: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 18:14:12.288619: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 18:14:12.288707: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 18:14:13.546951: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-05 18:14:13.547995: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 18:14:13.548496: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-05 18:14:13.548533: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 18:14:13.548564: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 18:14:13.548580: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 18:14:13.548595: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 18:14:13.548610: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 18:14:13.548625: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 18:14:13.548640: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 18:14:13.548655: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 18:14:13.549114: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 18:14:13.549152: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 18:14:14.292736: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-05 18:14:14.292808: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-05 18:14:14.292818: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-05 18:14:14.307651: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:02:00.0, compute capability: 6.1)
{'id': '20_11', 'seed': 11, 'out_folder': 'results/epoch_budget', 'batch_size': 128, 'epochs': 75, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'bootstrapping': False, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/75 [00:00<?, ?epoch/s]2024-03-05 18:14:15.200080: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-05 18:14:15.212185: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199825000 Hz
2024-03-05 18:14:17.376092: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 18:14:17.689496: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 18:14:18.479787: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-05 18:14:18.525180: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|▏         | 1/75 [01:03<1:18:17, 63.48s/epoch, loss=2.67, accuracy=0.469, val_loss=3.18, val_accuracy=0.291, lr=0.1]  3%|▎         | 2/75 [01:25<47:45, 39.25s/epoch, loss=1.41, accuracy=0.635, val_loss=2.49, val_accuracy=0.411, lr=0.1]    4%|▍         | 3/75 [01:48<37:47, 31.50s/epoch, loss=1.29, accuracy=0.681, val_loss=2.41, val_accuracy=0.41, lr=0.1]   5%|▌         | 4/75 [02:10<33:04, 27.96s/epoch, loss=1.26, accuracy=0.699, val_loss=1.62, val_accuracy=0.604, lr=0.1]  7%|▋         | 5/75 [02:32<30:09, 25.85s/epoch, loss=1.25, accuracy=0.707, val_loss=1.54, val_accuracy=0.61, lr=0.1]   8%|▊         | 6/75 [02:55<28:25, 24.71s/epoch, loss=1.23, accuracy=0.717, val_loss=1.97, val_accuracy=0.525, lr=0.1]  9%|▉         | 7/75 [03:17<27:15, 24.05s/epoch, loss=1.22, accuracy=0.724, val_loss=2.98, val_accuracy=0.449, lr=0.1] 11%|█         | 8/75 [03:39<26:08, 23.42s/epoch, loss=1.21, accuracy=0.726, val_loss=2.52, val_accuracy=0.456, lr=0.1] 12%|█▏        | 9/75 [04:02<25:18, 23.01s/epoch, loss=1.2, accuracy=0.732, val_loss=1.79, val_accuracy=0.547, lr=0.1]  13%|█▎        | 10/75 [04:25<24:55, 23.00s/epoch, loss=1.2, accuracy=0.733, val_loss=1.65, val_accuracy=0.572, lr=0.0316] 15%|█▍        | 11/75 [04:47<24:26, 22.91s/epoch, loss=1.19, accuracy=0.736, val_loss=2.03, val_accuracy=0.492, lr=0.1]   16%|█▌        | 12/75 [05:09<23:48, 22.68s/epoch, loss=1.19, accuracy=0.737, val_loss=1.75, val_accuracy=0.586, lr=0.1] 17%|█▋        | 13/75 [05:32<23:30, 22.75s/epoch, loss=1.19, accuracy=0.741, val_loss=1.39, val_accuracy=0.68, lr=0.1]  19%|█▊        | 14/75 [05:55<23:13, 22.84s/epoch, loss=1.19, accuracy=0.739, val_loss=1.79, val_accuracy=0.59, lr=0.1] 20%|██        | 15/75 [06:19<23:03, 23.06s/epoch, loss=1.19, accuracy=0.74, val_loss=1.56, val_accuracy=0.635, lr=0.1] 21%|██▏       | 16/75 [06:41<22:23, 22.77s/epoch, loss=1.18, accuracy=0.742, val_loss=1.97, val_accuracy=0.533, lr=0.1] 23%|██▎       | 17/75 [07:04<21:56, 22.69s/epoch, loss=1.18, accuracy=0.743, val_loss=1.81, val_accuracy=0.553, lr=0.1] 24%|██▍       | 18/75 [07:26<21:23, 22.53s/epoch, loss=1.17, accuracy=0.746, val_loss=2.23, val_accuracy=0.45, lr=0.0316] 25%|██▌       | 19/75 [07:48<20:56, 22.44s/epoch, loss=1.17, accuracy=0.744, val_loss=2.34, val_accuracy=0.445, lr=0.1]   27%|██▋       | 20/75 [08:10<20:30, 22.38s/epoch, loss=1.17, accuracy=0.748, val_loss=2.43, val_accuracy=0.462, lr=0.1] 28%|██▊       | 21/75 [08:33<20:12, 22.45s/epoch, loss=1.16, accuracy=0.747, val_loss=1.99, val_accuracy=0.552, lr=0.1] 29%|██▉       | 22/75 [08:55<19:46, 22.39s/epoch, loss=1.17, accuracy=0.745, val_loss=1.85, val_accuracy=0.525, lr=0.1] 31%|███       | 23/75 [09:17<19:25, 22.42s/epoch, loss=1.16, accuracy=0.747, val_loss=2.02, val_accuracy=0.513, lr=0.0316] 32%|███▏      | 24/75 [09:40<19:02, 22.39s/epoch, loss=1.16, accuracy=0.75, val_loss=1.88, val_accuracy=0.542, lr=0.1]     33%|███▎      | 25/75 [10:02<18:38, 22.37s/epoch, loss=1.16, accuracy=0.75, val_loss=1.68, val_accuracy=0.553, lr=0.1] 35%|███▍      | 26/75 [10:24<18:14, 22.33s/epoch, loss=1.16, accuracy=0.748, val_loss=3.12, val_accuracy=0.409, lr=0.1] 36%|███▌      | 27/75 [10:47<17:57, 22.45s/epoch, loss=1.16, accuracy=0.75, val_loss=1.72, val_accuracy=0.562, lr=0.1]  37%|███▋      | 28/75 [11:09<17:33, 22.41s/epoch, loss=1.15, accuracy=0.75, val_loss=1.56, val_accuracy=0.609, lr=0.0316] 39%|███▊      | 29/75 [11:32<17:19, 22.60s/epoch, loss=1.15, accuracy=0.753, val_loss=3.05, val_accuracy=0.39, lr=0.1]    40%|████      | 30/75 [11:55<16:50, 22.45s/epoch, loss=1.15, accuracy=0.752, val_loss=1.61, val_accuracy=0.594, lr=0.1] 41%|████▏     | 31/75 [12:17<16:29, 22.48s/epoch, loss=1.14, accuracy=0.753, val_loss=4.43, val_accuracy=0.282, lr=0.1] 43%|████▎     | 32/75 [12:40<16:08, 22.53s/epoch, loss=1.14, accuracy=0.752, val_loss=1.93, val_accuracy=0.548, lr=0.1] 44%|████▍     | 33/75 [13:01<15:36, 22.30s/epoch, loss=1.14, accuracy=0.753, val_loss=1.91, val_accuracy=0.53, lr=0.0316] 45%|████▌     | 34/75 [13:23<15:08, 22.15s/epoch, loss=1.15, accuracy=0.751, val_loss=1.98, val_accuracy=0.517, lr=0.1]   47%|████▋     | 35/75 [13:45<14:39, 22.00s/epoch, loss=1.14, accuracy=0.754, val_loss=1.8, val_accuracy=0.555, lr=0.1]  48%|████▊     | 36/75 [14:07<14:17, 21.98s/epoch, loss=1.14, accuracy=0.753, val_loss=1.67, val_accuracy=0.565, lr=0.1] 49%|████▉     | 37/75 [14:29<13:51, 21.88s/epoch, loss=1.13, accuracy=0.758, val_loss=2.67, val_accuracy=0.39, lr=0.1]  51%|█████     | 38/75 [14:50<13:25, 21.76s/epoch, loss=1.13, accuracy=0.756, val_loss=1.45, val_accuracy=0.628, lr=0.0316] 52%|█████▏    | 39/75 [15:11<12:59, 21.64s/epoch, loss=1.14, accuracy=0.753, val_loss=1.75, val_accuracy=0.553, lr=0.1]    53%|█████▎    | 40/75 [15:33<12:41, 21.74s/epoch, loss=1.13, accuracy=0.754, val_loss=2.09, val_accuracy=0.522, lr=0.1] 55%|█████▍    | 41/75 [15:55<12:19, 21.75s/epoch, loss=1.13, accuracy=0.756, val_loss=2.35, val_accuracy=0.44, lr=0.1]  56%|█████▌    | 42/75 [16:17<11:54, 21.66s/epoch, loss=1.13, accuracy=0.755, val_loss=1.86, val_accuracy=0.561, lr=0.1] 57%|█████▋    | 43/75 [16:38<11:32, 21.65s/epoch, loss=1.13, accuracy=0.755, val_loss=2.39, val_accuracy=0.466, lr=0.0316] 59%|█████▊    | 44/75 [17:00<11:09, 21.58s/epoch, loss=1.13, accuracy=0.756, val_loss=1.7, val_accuracy=0.584, lr=0.1]     60%|██████    | 45/75 [17:22<10:50, 21.69s/epoch, loss=1.13, accuracy=0.755, val_loss=4.2, val_accuracy=0.22, lr=0.1]  61%|██████▏   | 46/75 [17:43<10:27, 21.64s/epoch, loss=1.13, accuracy=0.757, val_loss=3.97, val_accuracy=0.219, lr=0.1] 63%|██████▎   | 47/75 [18:05<10:09, 21.78s/epoch, loss=1.12, accuracy=0.756, val_loss=3.01, val_accuracy=0.443, lr=0.1] 64%|██████▍   | 48/75 [18:27<09:48, 21.78s/epoch, loss=1.13, accuracy=0.757, val_loss=2.9, val_accuracy=0.282, lr=0.0316] 65%|██████▌   | 49/75 [18:49<09:25, 21.76s/epoch, loss=1.13, accuracy=0.756, val_loss=1.75, val_accuracy=0.547, lr=0.1]   67%|██████▋   | 50/75 [19:10<09:04, 21.77s/epoch, loss=1.12, accuracy=0.755, val_loss=1.73, val_accuracy=0.621, lr=0.1] 68%|██████▊   | 51/75 [19:32<08:42, 21.76s/epoch, loss=1.12, accuracy=0.754, val_loss=1.67, val_accuracy=0.606, lr=0.1] 69%|██████▉   | 52/75 [19:54<08:19, 21.71s/epoch, loss=1.12, accuracy=0.758, val_loss=2.04, val_accuracy=0.519, lr=0.1] 71%|███████   | 53/75 [20:16<07:59, 21.79s/epoch, loss=1.12, accuracy=0.757, val_loss=1.91, val_accuracy=0.495, lr=0.0316] 72%|███████▏  | 54/75 [20:38<07:37, 21.77s/epoch, loss=1.12, accuracy=0.76, val_loss=2.72, val_accuracy=0.373, lr=0.1]     73%|███████▎  | 55/75 [20:59<07:15, 21.77s/epoch, loss=1.12, accuracy=0.761, val_loss=1.5, val_accuracy=0.637, lr=0.1] 75%|███████▍  | 56/75 [21:21<06:55, 21.88s/epoch, loss=1.12, accuracy=0.758, val_loss=1.64, val_accuracy=0.616, lr=0.1] 76%|███████▌  | 57/75 [21:43<06:33, 21.88s/epoch, loss=1.12, accuracy=0.755, val_loss=2.63, val_accuracy=0.432, lr=0.1] 77%|███████▋  | 58/75 [22:05<06:12, 21.90s/epoch, loss=1.12, accuracy=0.758, val_loss=2.25, val_accuracy=0.46, lr=0.0316] 79%|███████▊  | 59/75 [22:27<05:48, 21.80s/epoch, loss=1.12, accuracy=0.758, val_loss=1.4, val_accuracy=0.648, lr=0.1]    80%|████████  | 60/75 [22:49<05:27, 21.83s/epoch, loss=1.12, accuracy=0.757, val_loss=2.19, val_accuracy=0.465, lr=0.1] 81%|████████▏ | 61/75 [23:11<05:05, 21.83s/epoch, loss=1.12, accuracy=0.759, val_loss=1.57, val_accuracy=0.622, lr=0.1] 83%|████████▎ | 62/75 [23:32<04:43, 21.79s/epoch, loss=1.11, accuracy=0.758, val_loss=1.58, val_accuracy=0.622, lr=0.1] 84%|████████▍ | 63/75 [23:54<04:22, 21.87s/epoch, loss=1.12, accuracy=0.758, val_loss=1.4, val_accuracy=0.65, lr=0.0316] 85%|████████▌ | 64/75 [24:16<03:59, 21.81s/epoch, loss=1.12, accuracy=0.756, val_loss=1.72, val_accuracy=0.542, lr=0.1]  87%|████████▋ | 65/75 [24:38<03:38, 21.80s/epoch, loss=1.12, accuracy=0.759, val_loss=1.86, val_accuracy=0.557, lr=0.1] 88%|████████▊ | 66/75 [25:00<03:16, 21.82s/epoch, loss=1.11, accuracy=0.76, val_loss=2.86, val_accuracy=0.377, lr=0.1]  89%|████████▉ | 67/75 [25:21<02:54, 21.81s/epoch, loss=1.11, accuracy=0.759, val_loss=2.28, val_accuracy=0.44, lr=0.1] 91%|█████████ | 68/75 [25:43<02:33, 21.88s/epoch, loss=1.11, accuracy=0.757, val_loss=1.97, val_accuracy=0.538, lr=0.0316] 92%|█████████▏| 69/75 [26:05<02:11, 21.86s/epoch, loss=1.12, accuracy=0.758, val_loss=3.21, val_accuracy=0.271, lr=0.1]    93%|█████████▎| 70/75 [26:27<01:49, 21.81s/epoch, loss=1.12, accuracy=0.757, val_loss=2.29, val_accuracy=0.422, lr=0.1] 95%|█████████▍| 71/75 [26:49<01:27, 21.80s/epoch, loss=1.11, accuracy=0.758, val_loss=2.29, val_accuracy=0.412, lr=0.1] 96%|█████████▌| 72/75 [27:11<01:05, 21.79s/epoch, loss=1.11, accuracy=0.76, val_loss=1.85, val_accuracy=0.505, lr=0.1]  97%|█████████▋| 73/75 [27:32<00:43, 21.79s/epoch, loss=1.12, accuracy=0.759, val_loss=6.07, val_accuracy=0.226, lr=0.0316] 99%|█████████▊| 74/75 [27:54<00:21, 21.73s/epoch, loss=1.11, accuracy=0.759, val_loss=1.55, val_accuracy=0.596, lr=0.1]   100%|██████████| 75/75 [28:16<00:00, 21.76s/epoch, loss=1.11, accuracy=0.759, val_loss=1.96, val_accuracy=0.479, lr=0.1]100%|██████████| 75/75 [28:16<00:00, 22.62s/epoch, loss=1.11, accuracy=0.759, val_loss=1.96, val_accuracy=0.479, lr=0.1]
Using real-time data augmentation.
Test score: 1.959665060043335
Test accuracy: 0.47929999232292175


* * * Run SGD for ID = 20_12. * * *


2024-03-05 18:42:35.021076: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 18:42:38.179106: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 18:42:38.180165: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-05 18:42:38.228182: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-05 18:42:38.228214: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 18:42:38.232258: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 18:42:38.232303: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 18:42:38.236148: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 18:42:38.237896: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 18:42:38.241126: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 18:42:38.243597: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 18:42:38.248472: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 18:42:38.253424: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 18:42:38.253516: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 18:42:39.495952: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-05 18:42:39.496993: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 18:42:39.497466: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-05 18:42:39.497497: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 18:42:39.497530: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 18:42:39.497549: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 18:42:39.497567: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 18:42:39.497584: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 18:42:39.497602: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 18:42:39.497619: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 18:42:39.497637: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 18:42:39.498136: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 18:42:39.498171: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 18:42:40.217283: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-05 18:42:40.217353: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-05 18:42:40.217363: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-05 18:42:40.218377: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:02:00.0, compute capability: 6.1)
{'id': '20_12', 'seed': 12, 'out_folder': 'results/epoch_budget', 'batch_size': 128, 'epochs': 75, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'bootstrapping': False, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/75 [00:00<?, ?epoch/s]2024-03-05 18:42:41.075013: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-05 18:42:41.087194: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199825000 Hz
2024-03-05 18:42:43.086440: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 18:42:43.308765: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 18:42:44.123580: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-05 18:42:44.174351: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|▏         | 1/75 [00:53<1:05:38, 53.23s/epoch, loss=2.84, accuracy=0.395, val_loss=4.09, val_accuracy=0.174, lr=0.1]  3%|▎         | 2/75 [01:15<42:15, 34.73s/epoch, loss=1.44, accuracy=0.596, val_loss=2.33, val_accuracy=0.442, lr=0.1]    4%|▍         | 3/75 [01:36<34:32, 28.79s/epoch, loss=1.28, accuracy=0.673, val_loss=1.67, val_accuracy=0.539, lr=0.1]  5%|▌         | 4/75 [01:58<30:42, 25.95s/epoch, loss=1.23, accuracy=0.698, val_loss=1.83, val_accuracy=0.539, lr=0.1]  7%|▋         | 5/75 [02:19<28:26, 24.37s/epoch, loss=1.22, accuracy=0.71, val_loss=2.02, val_accuracy=0.483, lr=0.1]   8%|▊         | 6/75 [02:41<26:56, 23.42s/epoch, loss=1.2, accuracy=0.717, val_loss=1.73, val_accuracy=0.589, lr=0.1]  9%|▉         | 7/75 [03:03<25:56, 22.90s/epoch, loss=1.2, accuracy=0.727, val_loss=2.16, val_accuracy=0.388, lr=0.1] 11%|█         | 8/75 [03:24<25:07, 22.49s/epoch, loss=1.2, accuracy=0.727, val_loss=1.8, val_accuracy=0.504, lr=0.0316] 12%|█▏        | 9/75 [03:46<24:24, 22.19s/epoch, loss=1.18, accuracy=0.734, val_loss=2.36, val_accuracy=0.488, lr=0.1]  13%|█▎        | 10/75 [04:08<23:51, 22.02s/epoch, loss=1.18, accuracy=0.737, val_loss=1.61, val_accuracy=0.571, lr=0.1] 15%|█▍        | 11/75 [04:29<23:19, 21.87s/epoch, loss=1.18, accuracy=0.737, val_loss=2.11, val_accuracy=0.437, lr=0.1] 16%|█▌        | 12/75 [04:51<22:53, 21.80s/epoch, loss=1.17, accuracy=0.74, val_loss=3.87, val_accuracy=0.374, lr=0.1]  17%|█▋        | 13/75 [05:13<22:33, 21.84s/epoch, loss=1.17, accuracy=0.74, val_loss=1.76, val_accuracy=0.588, lr=0.1] 19%|█▊        | 14/75 [05:34<22:05, 21.73s/epoch, loss=1.17, accuracy=0.742, val_loss=1.89, val_accuracy=0.541, lr=0.1] 20%|██        | 15/75 [05:56<21:42, 21.71s/epoch, loss=1.16, accuracy=0.746, val_loss=1.59, val_accuracy=0.612, lr=0.1] 21%|██▏       | 16/75 [06:17<21:19, 21.69s/epoch, loss=1.16, accuracy=0.744, val_loss=2.48, val_accuracy=0.409, lr=0.1] 23%|██▎       | 17/75 [06:39<20:57, 21.68s/epoch, loss=1.16, accuracy=0.747, val_loss=3.68, val_accuracy=0.332, lr=0.1] 24%|██▍       | 18/75 [07:01<20:35, 21.68s/epoch, loss=1.15, accuracy=0.747, val_loss=1.61, val_accuracy=0.608, lr=0.1] 25%|██▌       | 19/75 [07:22<20:13, 21.68s/epoch, loss=1.16, accuracy=0.746, val_loss=3, val_accuracy=0.318, lr=0.1]    27%|██▋       | 20/75 [07:44<19:52, 21.69s/epoch, loss=1.15, accuracy=0.747, val_loss=1.69, val_accuracy=0.563, lr=0.0316] 28%|██▊       | 21/75 [08:06<19:33, 21.73s/epoch, loss=1.15, accuracy=0.748, val_loss=1.73, val_accuracy=0.562, lr=0.1]    29%|██▉       | 22/75 [08:28<19:11, 21.73s/epoch, loss=1.15, accuracy=0.748, val_loss=1.72, val_accuracy=0.548, lr=0.1] 31%|███       | 23/75 [08:50<18:51, 21.76s/epoch, loss=1.15, accuracy=0.75, val_loss=2.43, val_accuracy=0.44, lr=0.1]   32%|███▏      | 24/75 [09:11<18:30, 21.78s/epoch, loss=1.14, accuracy=0.752, val_loss=1.58, val_accuracy=0.6, lr=0.1] 33%|███▎      | 25/75 [09:33<18:08, 21.77s/epoch, loss=1.14, accuracy=0.753, val_loss=6.2, val_accuracy=0.244, lr=0.1] 35%|███▍      | 26/75 [09:55<17:47, 21.78s/epoch, loss=1.14, accuracy=0.751, val_loss=2.19, val_accuracy=0.554, lr=0.1] 36%|███▌      | 27/75 [10:17<17:25, 21.79s/epoch, loss=1.14, accuracy=0.75, val_loss=3.84, val_accuracy=0.204, lr=0.1]  37%|███▋      | 28/75 [10:38<17:02, 21.76s/epoch, loss=1.14, accuracy=0.753, val_loss=2.07, val_accuracy=0.49, lr=0.1] 39%|███▊      | 29/75 [11:00<16:40, 21.74s/epoch, loss=1.14, accuracy=0.751, val_loss=1.78, val_accuracy=0.522, lr=0.0316] 40%|████      | 30/75 [11:22<16:22, 21.83s/epoch, loss=1.14, accuracy=0.753, val_loss=2.74, val_accuracy=0.425, lr=0.1]    41%|████▏     | 31/75 [11:44<15:59, 21.81s/epoch, loss=1.13, accuracy=0.756, val_loss=2.11, val_accuracy=0.496, lr=0.1] 43%|████▎     | 32/75 [12:06<15:43, 21.94s/epoch, loss=1.13, accuracy=0.754, val_loss=1.45, val_accuracy=0.647, lr=0.1] 44%|████▍     | 33/75 [12:28<15:21, 21.95s/epoch, loss=1.14, accuracy=0.754, val_loss=2.28, val_accuracy=0.499, lr=0.1] 45%|████▌     | 34/75 [12:50<14:59, 21.93s/epoch, loss=1.13, accuracy=0.755, val_loss=2.23, val_accuracy=0.477, lr=0.1] 47%|████▋     | 35/75 [13:12<14:39, 22.00s/epoch, loss=1.13, accuracy=0.755, val_loss=1.59, val_accuracy=0.595, lr=0.1] 48%|████▊     | 36/75 [13:35<14:21, 22.09s/epoch, loss=1.13, accuracy=0.757, val_loss=1.9, val_accuracy=0.502, lr=0.1]  49%|████▉     | 37/75 [13:56<13:57, 22.03s/epoch, loss=1.12, accuracy=0.756, val_loss=1.72, val_accuracy=0.556, lr=0.0316] 51%|█████     | 38/75 [14:18<13:33, 21.97s/epoch, loss=1.13, accuracy=0.756, val_loss=4.48, val_accuracy=0.271, lr=0.1]    52%|█████▏    | 39/75 [14:41<13:15, 22.09s/epoch, loss=1.13, accuracy=0.755, val_loss=1.85, val_accuracy=0.557, lr=0.1] 53%|█████▎    | 40/75 [15:04<13:03, 22.38s/epoch, loss=1.13, accuracy=0.755, val_loss=1.73, val_accuracy=0.558, lr=0.1] 55%|█████▍    | 41/75 [15:26<12:37, 22.29s/epoch, loss=1.12, accuracy=0.757, val_loss=2.7, val_accuracy=0.381, lr=0.1]  56%|█████▌    | 42/75 [15:48<12:19, 22.41s/epoch, loss=1.13, accuracy=0.757, val_loss=6.25, val_accuracy=0.218, lr=0.0316] 57%|█████▋    | 43/75 [16:11<11:58, 22.44s/epoch, loss=1.12, accuracy=0.758, val_loss=2.62, val_accuracy=0.381, lr=0.1]    59%|█████▊    | 44/75 [16:33<11:34, 22.41s/epoch, loss=1.12, accuracy=0.761, val_loss=1.64, val_accuracy=0.569, lr=0.1] 60%|██████    | 45/75 [16:55<11:09, 22.31s/epoch, loss=1.12, accuracy=0.759, val_loss=5.77, val_accuracy=0.348, lr=0.1] 61%|██████▏   | 46/75 [17:17<10:43, 22.17s/epoch, loss=1.12, accuracy=0.76, val_loss=2.9, val_accuracy=0.423, lr=0.1]   63%|██████▎   | 47/75 [17:39<10:20, 22.15s/epoch, loss=1.13, accuracy=0.756, val_loss=3.38, val_accuracy=0.353, lr=0.0316] 64%|██████▍   | 48/75 [18:01<09:57, 22.15s/epoch, loss=1.13, accuracy=0.758, val_loss=1.47, val_accuracy=0.636, lr=0.1]    65%|██████▌   | 49/75 [18:24<09:35, 22.13s/epoch, loss=1.12, accuracy=0.755, val_loss=2, val_accuracy=0.496, lr=0.1]    67%|██████▋   | 50/75 [18:46<09:14, 22.16s/epoch, loss=1.13, accuracy=0.758, val_loss=1.98, val_accuracy=0.495, lr=0.1] 68%|██████▊   | 51/75 [19:08<08:49, 22.07s/epoch, loss=1.12, accuracy=0.758, val_loss=1.69, val_accuracy=0.565, lr=0.1] 69%|██████▉   | 52/75 [19:30<08:28, 22.11s/epoch, loss=1.13, accuracy=0.755, val_loss=1.67, val_accuracy=0.571, lr=0.0316] 71%|███████   | 53/75 [19:52<08:06, 22.13s/epoch, loss=1.12, accuracy=0.758, val_loss=1.93, val_accuracy=0.526, lr=0.1]    72%|███████▏  | 54/75 [20:14<07:44, 22.11s/epoch, loss=1.11, accuracy=0.758, val_loss=2.78, val_accuracy=0.396, lr=0.1] 73%|███████▎  | 55/75 [20:36<07:21, 22.09s/epoch, loss=1.12, accuracy=0.757, val_loss=5.03, val_accuracy=0.203, lr=0.1] 75%|███████▍  | 56/75 [20:58<06:58, 22.05s/epoch, loss=1.12, accuracy=0.76, val_loss=2.37, val_accuracy=0.426, lr=0.1]  76%|███████▌  | 57/75 [21:20<06:38, 22.12s/epoch, loss=1.12, accuracy=0.759, val_loss=2.33, val_accuracy=0.43, lr=0.0316] 77%|███████▋  | 58/75 [21:42<06:14, 22.02s/epoch, loss=1.11, accuracy=0.759, val_loss=2.65, val_accuracy=0.445, lr=0.1]   79%|███████▊  | 59/75 [22:04<05:52, 22.01s/epoch, loss=1.11, accuracy=0.761, val_loss=2.59, val_accuracy=0.255, lr=0.1] 80%|████████  | 60/75 [22:26<05:29, 21.95s/epoch, loss=1.12, accuracy=0.756, val_loss=2.64, val_accuracy=0.431, lr=0.1] 81%|████████▏ | 61/75 [22:47<05:05, 21.81s/epoch, loss=1.11, accuracy=0.758, val_loss=2.18, val_accuracy=0.487, lr=0.1] 83%|████████▎ | 62/75 [23:09<04:43, 21.83s/epoch, loss=1.11, accuracy=0.759, val_loss=1.69, val_accuracy=0.557, lr=0.0316] 84%|████████▍ | 63/75 [23:31<04:21, 21.76s/epoch, loss=1.11, accuracy=0.759, val_loss=1.59, val_accuracy=0.621, lr=0.1]    85%|████████▌ | 64/75 [23:53<03:59, 21.75s/epoch, loss=1.11, accuracy=0.76, val_loss=2.22, val_accuracy=0.441, lr=0.1]  87%|████████▋ | 65/75 [24:15<03:38, 21.83s/epoch, loss=1.11, accuracy=0.757, val_loss=3.33, val_accuracy=0.371, lr=0.1] 88%|████████▊ | 66/75 [24:36<03:16, 21.79s/epoch, loss=1.11, accuracy=0.759, val_loss=4.01, val_accuracy=0.286, lr=0.1] 89%|████████▉ | 67/75 [24:58<02:54, 21.76s/epoch, loss=1.12, accuracy=0.757, val_loss=1.85, val_accuracy=0.567, lr=0.0316] 91%|█████████ | 68/75 [25:20<02:32, 21.74s/epoch, loss=1.12, accuracy=0.758, val_loss=1.63, val_accuracy=0.583, lr=0.1]    92%|█████████▏| 69/75 [25:42<02:10, 21.75s/epoch, loss=1.11, accuracy=0.758, val_loss=2.89, val_accuracy=0.387, lr=0.1] 93%|█████████▎| 70/75 [26:03<01:48, 21.68s/epoch, loss=1.11, accuracy=0.759, val_loss=2.21, val_accuracy=0.461, lr=0.1] 95%|█████████▍| 71/75 [26:25<01:26, 21.68s/epoch, loss=1.11, accuracy=0.759, val_loss=2.96, val_accuracy=0.431, lr=0.1] 96%|█████████▌| 72/75 [26:46<01:05, 21.71s/epoch, loss=1.11, accuracy=0.76, val_loss=11.2, val_accuracy=0.169, lr=0.0316] 97%|█████████▋| 73/75 [27:09<00:43, 21.82s/epoch, loss=1.11, accuracy=0.757, val_loss=2.12, val_accuracy=0.456, lr=0.1]   99%|█████████▊| 74/75 [27:31<00:22, 22.06s/epoch, loss=1.11, accuracy=0.757, val_loss=4.26, val_accuracy=0.284, lr=0.1]100%|██████████| 75/75 [27:53<00:00, 21.95s/epoch, loss=1.11, accuracy=0.759, val_loss=2.01, val_accuracy=0.488, lr=0.1]100%|██████████| 75/75 [27:53<00:00, 22.31s/epoch, loss=1.11, accuracy=0.759, val_loss=2.01, val_accuracy=0.488, lr=0.1]
Using real-time data augmentation.
Test score: 2.0075113773345947
Test accuracy: 0.48809999227523804


* * * Run SGD for ID = 20_13. * * *


2024-03-05 19:10:37.985087: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 19:10:41.209576: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 19:10:41.210633: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-05 19:10:41.259044: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-05 19:10:41.259100: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 19:10:41.262010: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 19:10:41.262058: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 19:10:41.264401: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 19:10:41.265569: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 19:10:41.268147: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 19:10:41.269737: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 19:10:41.274552: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 19:10:41.275749: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 19:10:41.275842: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 19:10:42.482558: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-05 19:10:42.483093: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 19:10:42.483588: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-05 19:10:42.483617: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 19:10:42.483649: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 19:10:42.483666: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 19:10:42.483681: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 19:10:42.483697: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 19:10:42.483713: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 19:10:42.483729: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 19:10:42.483745: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 19:10:42.484256: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 19:10:42.484293: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 19:10:43.145967: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-05 19:10:43.146027: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-05 19:10:43.146037: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-05 19:10:43.147008: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:02:00.0, compute capability: 6.1)
{'id': '20_13', 'seed': 13, 'out_folder': 'results/epoch_budget', 'batch_size': 128, 'epochs': 75, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'bootstrapping': False, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/75 [00:00<?, ?epoch/s]2024-03-05 19:10:43.999671: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-05 19:10:44.012187: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199825000 Hz
2024-03-05 19:10:46.171589: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 19:10:46.420903: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 19:10:47.138019: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-05 19:10:47.175748: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|▏         | 1/75 [00:54<1:06:59, 54.32s/epoch, loss=2.79, accuracy=0.42, val_loss=2.18, val_accuracy=0.363, lr=0.1]  3%|▎         | 2/75 [01:16<42:50, 35.22s/epoch, loss=1.41, accuracy=0.619, val_loss=3.69, val_accuracy=0.252, lr=0.1]   4%|▍         | 3/75 [01:37<34:48, 29.00s/epoch, loss=1.27, accuracy=0.68, val_loss=2.1, val_accuracy=0.417, lr=0.1]    5%|▌         | 4/75 [01:59<30:51, 26.08s/epoch, loss=1.23, accuracy=0.703, val_loss=2.1, val_accuracy=0.412, lr=0.1]  7%|▋         | 5/75 [02:20<28:29, 24.43s/epoch, loss=1.21, accuracy=0.714, val_loss=13, val_accuracy=0.137, lr=0.1]   8%|▊         | 6/75 [02:42<27:04, 23.54s/epoch, loss=1.21, accuracy=0.723, val_loss=2.17, val_accuracy=0.434, lr=0.1]  9%|▉         | 7/75 [03:04<25:58, 22.92s/epoch, loss=1.2, accuracy=0.725, val_loss=2.02, val_accuracy=0.505, lr=0.1]  11%|█         | 8/75 [03:26<25:14, 22.60s/epoch, loss=1.18, accuracy=0.735, val_loss=1.96, val_accuracy=0.461, lr=0.1] 12%|█▏        | 9/75 [03:47<24:30, 22.28s/epoch, loss=1.17, accuracy=0.733, val_loss=1.36, val_accuracy=0.674, lr=0.1] 13%|█▎        | 10/75 [04:09<24:04, 22.23s/epoch, loss=1.17, accuracy=0.737, val_loss=1.52, val_accuracy=0.611, lr=0.1] 15%|█▍        | 11/75 [04:31<23:33, 22.08s/epoch, loss=1.17, accuracy=0.741, val_loss=1.61, val_accuracy=0.6, lr=0.1]   16%|█▌        | 12/75 [04:53<23:03, 21.96s/epoch, loss=1.16, accuracy=0.743, val_loss=2.28, val_accuracy=0.447, lr=0.1] 17%|█▋        | 13/75 [05:14<22:35, 21.86s/epoch, loss=1.16, accuracy=0.745, val_loss=2.75, val_accuracy=0.423, lr=0.1] 19%|█▊        | 14/75 [05:36<22:14, 21.88s/epoch, loss=1.14, accuracy=0.75, val_loss=1.64, val_accuracy=0.579, lr=0.0316] 20%|██        | 15/75 [05:58<21:48, 21.81s/epoch, loss=1.14, accuracy=0.749, val_loss=1.6, val_accuracy=0.608, lr=0.1]    21%|██▏       | 16/75 [06:20<21:24, 21.76s/epoch, loss=1.14, accuracy=0.749, val_loss=3.7, val_accuracy=0.263, lr=0.1] 23%|██▎       | 17/75 [06:42<21:05, 21.81s/epoch, loss=1.14, accuracy=0.752, val_loss=1.9, val_accuracy=0.502, lr=0.1] 24%|██▍       | 18/75 [07:03<20:40, 21.76s/epoch, loss=1.13, accuracy=0.753, val_loss=2.08, val_accuracy=0.47, lr=0.1] 25%|██▌       | 19/75 [07:25<20:17, 21.74s/epoch, loss=1.13, accuracy=0.752, val_loss=2.29, val_accuracy=0.511, lr=0.0316] 27%|██▋       | 20/75 [07:47<19:55, 21.74s/epoch, loss=1.12, accuracy=0.752, val_loss=1.77, val_accuracy=0.561, lr=0.1]    28%|██▊       | 21/75 [08:09<19:37, 21.81s/epoch, loss=1.12, accuracy=0.752, val_loss=2.71, val_accuracy=0.263, lr=0.1] 29%|██▉       | 22/75 [08:30<19:14, 21.79s/epoch, loss=1.13, accuracy=0.751, val_loss=1.88, val_accuracy=0.524, lr=0.1] 31%|███       | 23/75 [08:52<18:53, 21.79s/epoch, loss=1.12, accuracy=0.753, val_loss=1.55, val_accuracy=0.604, lr=0.1] 32%|███▏      | 24/75 [09:14<18:36, 21.90s/epoch, loss=1.12, accuracy=0.754, val_loss=2.21, val_accuracy=0.494, lr=0.0316] 33%|███▎      | 25/75 [09:36<18:14, 21.88s/epoch, loss=1.12, accuracy=0.754, val_loss=2.71, val_accuracy=0.318, lr=0.1]    35%|███▍      | 26/75 [09:58<17:49, 21.82s/epoch, loss=1.12, accuracy=0.754, val_loss=2.09, val_accuracy=0.476, lr=0.1] 36%|███▌      | 27/75 [10:20<17:24, 21.76s/epoch, loss=1.12, accuracy=0.754, val_loss=2.36, val_accuracy=0.484, lr=0.1] 37%|███▋      | 28/75 [10:41<17:01, 21.73s/epoch, loss=1.12, accuracy=0.756, val_loss=2.12, val_accuracy=0.484, lr=0.1] 39%|███▊      | 29/75 [11:03<16:36, 21.66s/epoch, loss=1.11, accuracy=0.756, val_loss=2.23, val_accuracy=0.47, lr=0.0316] 40%|████      | 30/75 [11:24<16:15, 21.69s/epoch, loss=1.12, accuracy=0.754, val_loss=2.56, val_accuracy=0.47, lr=0.1]    41%|████▏     | 31/75 [11:46<15:53, 21.67s/epoch, loss=1.11, accuracy=0.755, val_loss=5.81, val_accuracy=0.206, lr=0.1] 43%|████▎     | 32/75 [12:08<15:30, 21.63s/epoch, loss=1.11, accuracy=0.758, val_loss=2.02, val_accuracy=0.435, lr=0.1] 44%|████▍     | 33/75 [12:29<15:06, 21.59s/epoch, loss=1.11, accuracy=0.757, val_loss=1.8, val_accuracy=0.552, lr=0.1]  45%|████▌     | 34/75 [12:51<14:44, 21.57s/epoch, loss=1.11, accuracy=0.757, val_loss=1.74, val_accuracy=0.553, lr=0.0316] 47%|████▋     | 35/75 [13:13<14:26, 21.67s/epoch, loss=1.11, accuracy=0.759, val_loss=1.61, val_accuracy=0.569, lr=0.1]    48%|████▊     | 36/75 [13:34<14:07, 21.72s/epoch, loss=1.12, accuracy=0.756, val_loss=1.5, val_accuracy=0.641, lr=0.1]  49%|████▉     | 37/75 [13:56<13:45, 21.73s/epoch, loss=1.12, accuracy=0.757, val_loss=1.67, val_accuracy=0.587, lr=0.1] 51%|█████     | 38/75 [14:18<13:22, 21.68s/epoch, loss=1.1, accuracy=0.759, val_loss=1.93, val_accuracy=0.518, lr=0.1]  52%|█████▏    | 39/75 [14:39<12:59, 21.64s/epoch, loss=1.11, accuracy=0.759, val_loss=2.15, val_accuracy=0.522, lr=0.0316] 53%|█████▎    | 40/75 [15:01<12:39, 21.71s/epoch, loss=1.11, accuracy=0.759, val_loss=2.06, val_accuracy=0.541, lr=0.1]    55%|█████▍    | 41/75 [15:23<12:17, 21.68s/epoch, loss=1.11, accuracy=0.758, val_loss=2.38, val_accuracy=0.392, lr=0.1] 56%|█████▌    | 42/75 [15:44<11:54, 21.66s/epoch, loss=1.11, accuracy=0.758, val_loss=1.68, val_accuracy=0.585, lr=0.1] 57%|█████▋    | 43/75 [16:06<11:31, 21.62s/epoch, loss=1.11, accuracy=0.756, val_loss=1.81, val_accuracy=0.506, lr=0.1] 59%|█████▊    | 44/75 [16:28<11:11, 21.67s/epoch, loss=1.11, accuracy=0.759, val_loss=2.08, val_accuracy=0.464, lr=0.0316] 60%|██████    | 45/75 [16:50<10:52, 21.73s/epoch, loss=1.11, accuracy=0.756, val_loss=3, val_accuracy=0.438, lr=0.1]       61%|██████▏   | 46/75 [17:11<10:32, 21.80s/epoch, loss=1.1, accuracy=0.759, val_loss=1.58, val_accuracy=0.593, lr=0.1] 63%|██████▎   | 47/75 [17:33<10:11, 21.82s/epoch, loss=1.11, accuracy=0.759, val_loss=2.22, val_accuracy=0.446, lr=0.1] 64%|██████▍   | 48/75 [17:56<09:52, 21.93s/epoch, loss=1.11, accuracy=0.758, val_loss=3.35, val_accuracy=0.357, lr=0.1] 65%|██████▌   | 49/75 [18:18<09:30, 21.95s/epoch, loss=1.11, accuracy=0.758, val_loss=2.14, val_accuracy=0.457, lr=0.0316] 67%|██████▋   | 50/75 [18:39<09:07, 21.91s/epoch, loss=1.1, accuracy=0.76, val_loss=1.94, val_accuracy=0.58, lr=0.1]       68%|██████▊   | 51/75 [19:01<08:44, 21.87s/epoch, loss=1.1, accuracy=0.76, val_loss=1.67, val_accuracy=0.556, lr=0.1] 69%|██████▉   | 52/75 [19:23<08:22, 21.85s/epoch, loss=1.11, accuracy=0.759, val_loss=1.42, val_accuracy=0.649, lr=0.1] 71%|███████   | 53/75 [19:45<08:03, 21.96s/epoch, loss=1.11, accuracy=0.759, val_loss=2.61, val_accuracy=0.452, lr=0.1] 72%|███████▏  | 54/75 [20:07<07:40, 21.95s/epoch, loss=1.1, accuracy=0.761, val_loss=1.87, val_accuracy=0.506, lr=0.0316] 73%|███████▎  | 55/75 [20:29<07:19, 21.98s/epoch, loss=1.11, accuracy=0.758, val_loss=2, val_accuracy=0.453, lr=0.1]      75%|███████▍  | 56/75 [20:51<06:56, 21.92s/epoch, loss=1.1, accuracy=0.761, val_loss=1.68, val_accuracy=0.556, lr=0.1] 76%|███████▌  | 57/75 [21:13<06:34, 21.89s/epoch, loss=1.1, accuracy=0.762, val_loss=2.98, val_accuracy=0.371, lr=0.1] 77%|███████▋  | 58/75 [21:35<06:12, 21.90s/epoch, loss=1.11, accuracy=0.76, val_loss=1.89, val_accuracy=0.492, lr=0.1] 79%|███████▊  | 59/75 [21:56<05:50, 21.88s/epoch, loss=1.1, accuracy=0.76, val_loss=1.82, val_accuracy=0.567, lr=0.0316] 80%|████████  | 60/75 [22:18<05:27, 21.86s/epoch, loss=1.11, accuracy=0.757, val_loss=2.22, val_accuracy=0.485, lr=0.1]  81%|████████▏ | 61/75 [22:40<05:05, 21.84s/epoch, loss=1.11, accuracy=0.762, val_loss=1.47, val_accuracy=0.643, lr=0.1] 83%|████████▎ | 62/75 [23:02<04:45, 21.95s/epoch, loss=1.1, accuracy=0.759, val_loss=1.6, val_accuracy=0.59, lr=0.1]    84%|████████▍ | 63/75 [23:25<04:24, 22.03s/epoch, loss=1.11, accuracy=0.759, val_loss=1.52, val_accuracy=0.616, lr=0.1] 85%|████████▌ | 64/75 [23:46<04:01, 21.98s/epoch, loss=1.1, accuracy=0.76, val_loss=1.85, val_accuracy=0.496, lr=0.0316] 87%|████████▋ | 65/75 [24:08<03:39, 21.96s/epoch, loss=1.1, accuracy=0.763, val_loss=2.44, val_accuracy=0.481, lr=0.1]   88%|████████▊ | 66/75 [24:30<03:18, 22.03s/epoch, loss=1.11, accuracy=0.76, val_loss=2.78, val_accuracy=0.34, lr=0.1]  89%|████████▉ | 67/75 [24:52<02:55, 21.97s/epoch, loss=1.11, accuracy=0.76, val_loss=1.93, val_accuracy=0.482, lr=0.1] 91%|█████████ | 68/75 [25:14<02:33, 21.94s/epoch, loss=1.1, accuracy=0.76, val_loss=1.56, val_accuracy=0.605, lr=0.1]  92%|█████████▏| 69/75 [25:36<02:11, 21.90s/epoch, loss=1.11, accuracy=0.758, val_loss=1.52, val_accuracy=0.63, lr=0.0316] 93%|█████████▎| 70/75 [25:58<01:49, 21.91s/epoch, loss=1.1, accuracy=0.762, val_loss=1.56, val_accuracy=0.609, lr=0.1]    95%|█████████▍| 71/75 [26:20<01:27, 21.85s/epoch, loss=1.1, accuracy=0.759, val_loss=1.59, val_accuracy=0.562, lr=0.1] 96%|█████████▌| 72/75 [26:42<01:05, 21.96s/epoch, loss=1.1, accuracy=0.76, val_loss=1.59, val_accuracy=0.595, lr=0.1]  97%|█████████▋| 73/75 [27:04<00:43, 21.89s/epoch, loss=1.1, accuracy=0.762, val_loss=1.52, val_accuracy=0.594, lr=0.1] 99%|█████████▊| 74/75 [27:25<00:21, 21.81s/epoch, loss=1.1, accuracy=0.76, val_loss=1.95, val_accuracy=0.5, lr=0.0316]100%|██████████| 75/75 [27:47<00:00, 21.77s/epoch, loss=1.11, accuracy=0.756, val_loss=1.47, val_accuracy=0.632, lr=0.1]100%|██████████| 75/75 [27:47<00:00, 22.23s/epoch, loss=1.11, accuracy=0.756, val_loss=1.47, val_accuracy=0.632, lr=0.1]
Using real-time data augmentation.
Test score: 1.4734526872634888
Test accuracy: 0.6322000026702881


* * * Run SGD for ID = 20_14. * * *


2024-03-05 19:38:35.367331: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 19:38:42.066975: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 19:38:42.068200: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-05 19:38:42.108402: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-05 19:38:42.108431: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 19:38:42.113522: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 19:38:42.113563: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 19:38:42.116265: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 19:38:42.117554: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 19:38:42.120311: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 19:38:42.122114: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 19:38:42.128185: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 19:38:42.128711: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 19:38:42.128803: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 19:38:43.385529: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-05 19:38:43.386008: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 19:38:43.386531: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-05 19:38:43.386560: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 19:38:43.386593: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 19:38:43.386611: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 19:38:43.386628: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 19:38:43.386644: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 19:38:43.386661: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 19:38:43.386678: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 19:38:43.386695: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 19:38:43.387183: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 19:38:43.387222: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 19:38:44.055133: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-05 19:38:44.055195: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-05 19:38:44.055206: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-05 19:38:44.056729: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:02:00.0, compute capability: 6.1)
{'id': '20_14', 'seed': 14, 'out_folder': 'results/epoch_budget', 'batch_size': 128, 'epochs': 75, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'bootstrapping': False, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/75 [00:00<?, ?epoch/s]2024-03-05 19:38:44.940065: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-05 19:38:44.940691: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199825000 Hz
2024-03-05 19:38:47.236041: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 19:38:47.446399: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 19:38:48.238119: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-05 19:38:48.281908: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|▏         | 1/75 [00:52<1:04:37, 52.40s/epoch, loss=3.21, accuracy=0.301, val_loss=2.56, val_accuracy=0.197, lr=0.1]  3%|▎         | 2/75 [01:15<42:31, 34.95s/epoch, loss=1.6, accuracy=0.509, val_loss=1.94, val_accuracy=0.392, lr=0.1]     4%|▍         | 3/75 [01:37<35:06, 29.25s/epoch, loss=1.42, accuracy=0.603, val_loss=3.01, val_accuracy=0.25, lr=0.1]  5%|▌         | 4/75 [01:59<31:23, 26.52s/epoch, loss=1.33, accuracy=0.658, val_loss=1.65, val_accuracy=0.553, lr=0.1]  7%|▋         | 5/75 [02:22<29:05, 24.94s/epoch, loss=1.29, accuracy=0.684, val_loss=2.77, val_accuracy=0.31, lr=0.1]   8%|▊         | 6/75 [02:46<28:21, 24.65s/epoch, loss=1.27, accuracy=0.699, val_loss=2.84, val_accuracy=0.431, lr=0.1]  9%|▉         | 7/75 [03:10<27:48, 24.53s/epoch, loss=1.24, accuracy=0.711, val_loss=2.25, val_accuracy=0.516, lr=0.1] 11%|█         | 8/75 [03:32<26:39, 23.88s/epoch, loss=1.24, accuracy=0.713, val_loss=1.98, val_accuracy=0.525, lr=0.1] 12%|█▏        | 9/75 [03:55<25:48, 23.46s/epoch, loss=1.23, accuracy=0.72, val_loss=1.6, val_accuracy=0.618, lr=0.1]   13%|█▎        | 10/75 [04:17<24:58, 23.05s/epoch, loss=1.23, accuracy=0.724, val_loss=1.43, val_accuracy=0.656, lr=0.1] 15%|█▍        | 11/75 [04:42<25:03, 23.50s/epoch, loss=1.23, accuracy=0.725, val_loss=2.51, val_accuracy=0.412, lr=0.1] 16%|█▌        | 12/75 [05:06<24:51, 23.67s/epoch, loss=1.22, accuracy=0.729, val_loss=1.58, val_accuracy=0.614, lr=0.1] 17%|█▋        | 13/75 [05:30<24:34, 23.79s/epoch, loss=1.22, accuracy=0.731, val_loss=2.01, val_accuracy=0.486, lr=0.1] 19%|█▊        | 14/75 [05:54<24:27, 24.05s/epoch, loss=1.21, accuracy=0.732, val_loss=1.6, val_accuracy=0.603, lr=0.1]  20%|██        | 15/75 [06:19<24:13, 24.22s/epoch, loss=1.21, accuracy=0.734, val_loss=2.52, val_accuracy=0.43, lr=0.0316] 21%|██▏       | 16/75 [06:44<23:57, 24.37s/epoch, loss=1.2, accuracy=0.737, val_loss=3.14, val_accuracy=0.328, lr=0.1]    23%|██▎       | 17/75 [07:08<23:32, 24.36s/epoch, loss=1.21, accuracy=0.734, val_loss=1.5, val_accuracy=0.631, lr=0.1] 24%|██▍       | 18/75 [07:33<23:13, 24.45s/epoch, loss=1.2, accuracy=0.739, val_loss=1.9, val_accuracy=0.553, lr=0.1]  25%|██▌       | 19/75 [07:58<22:54, 24.55s/epoch, loss=1.2, accuracy=0.741, val_loss=2.5, val_accuracy=0.507, lr=0.1] 27%|██▋       | 20/75 [08:22<22:30, 24.56s/epoch, loss=1.2, accuracy=0.74, val_loss=2.26, val_accuracy=0.512, lr=0.0316] 28%|██▊       | 21/75 [08:47<22:09, 24.62s/epoch, loss=1.19, accuracy=0.742, val_loss=1.7, val_accuracy=0.586, lr=0.1]   29%|██▉       | 22/75 [09:11<21:44, 24.62s/epoch, loss=1.19, accuracy=0.744, val_loss=1.9, val_accuracy=0.541, lr=0.1] 31%|███       | 23/75 [09:36<21:23, 24.69s/epoch, loss=1.19, accuracy=0.743, val_loss=1.96, val_accuracy=0.475, lr=0.1] 32%|███▏      | 24/75 [10:01<20:51, 24.55s/epoch, loss=1.19, accuracy=0.742, val_loss=2.39, val_accuracy=0.391, lr=0.1] 33%|███▎      | 25/75 [10:25<20:32, 24.65s/epoch, loss=1.18, accuracy=0.746, val_loss=2.64, val_accuracy=0.44, lr=0.0316] 35%|███▍      | 26/75 [10:49<19:54, 24.38s/epoch, loss=1.18, accuracy=0.744, val_loss=2.3, val_accuracy=0.464, lr=0.1]    36%|███▌      | 27/75 [11:14<19:37, 24.53s/epoch, loss=1.18, accuracy=0.745, val_loss=1.65, val_accuracy=0.586, lr=0.1] 37%|███▋      | 28/75 [11:39<19:16, 24.61s/epoch, loss=1.18, accuracy=0.745, val_loss=2.72, val_accuracy=0.368, lr=0.1] 39%|███▊      | 29/75 [12:03<18:51, 24.61s/epoch, loss=1.18, accuracy=0.744, val_loss=2.38, val_accuracy=0.378, lr=0.1] 40%|████      | 30/75 [12:26<18:04, 24.10s/epoch, loss=1.17, accuracy=0.747, val_loss=3.1, val_accuracy=0.269, lr=0.0316] 41%|████▏     | 31/75 [12:50<17:30, 23.88s/epoch, loss=1.17, accuracy=0.745, val_loss=1.68, val_accuracy=0.573, lr=0.1]   43%|████▎     | 32/75 [13:13<17:02, 23.77s/epoch, loss=1.16, accuracy=0.75, val_loss=1.93, val_accuracy=0.563, lr=0.1]  44%|████▍     | 33/75 [13:36<16:19, 23.33s/epoch, loss=1.16, accuracy=0.75, val_loss=2.74, val_accuracy=0.346, lr=0.1] 45%|████▌     | 34/75 [13:57<15:37, 22.87s/epoch, loss=1.16, accuracy=0.747, val_loss=2.13, val_accuracy=0.465, lr=0.1] 47%|████▋     | 35/75 [14:19<15:05, 22.65s/epoch, loss=1.16, accuracy=0.748, val_loss=2, val_accuracy=0.475, lr=0.0316] 48%|████▊     | 36/75 [14:41<14:35, 22.45s/epoch, loss=1.17, accuracy=0.749, val_loss=1.71, val_accuracy=0.578, lr=0.1] 49%|████▉     | 37/75 [15:04<14:15, 22.50s/epoch, loss=1.16, accuracy=0.748, val_loss=2.11, val_accuracy=0.419, lr=0.1] 51%|█████     | 38/75 [15:27<13:57, 22.64s/epoch, loss=1.17, accuracy=0.746, val_loss=4.6, val_accuracy=0.279, lr=0.1]  52%|█████▏    | 39/75 [15:49<13:32, 22.56s/epoch, loss=1.16, accuracy=0.75, val_loss=3.04, val_accuracy=0.345, lr=0.1] 53%|█████▎    | 40/75 [16:13<13:18, 22.80s/epoch, loss=1.16, accuracy=0.748, val_loss=1.58, val_accuracy=0.608, lr=0.0316] 55%|█████▍    | 41/75 [16:36<12:57, 22.86s/epoch, loss=1.16, accuracy=0.75, val_loss=1.68, val_accuracy=0.599, lr=0.1]     56%|█████▌    | 42/75 [16:59<12:37, 22.96s/epoch, loss=1.15, accuracy=0.752, val_loss=1.45, val_accuracy=0.643, lr=0.1] 57%|█████▋    | 43/75 [17:22<12:15, 23.00s/epoch, loss=1.16, accuracy=0.751, val_loss=1.78, val_accuracy=0.585, lr=0.1] 59%|█████▊    | 44/75 [17:45<11:54, 23.04s/epoch, loss=1.15, accuracy=0.75, val_loss=1.91, val_accuracy=0.524, lr=0.1]  60%|██████    | 45/75 [18:09<11:39, 23.31s/epoch, loss=1.15, accuracy=0.75, val_loss=1.61, val_accuracy=0.601, lr=0.0316] 61%|██████▏   | 46/75 [18:32<11:08, 23.04s/epoch, loss=1.16, accuracy=0.752, val_loss=4.05, val_accuracy=0.202, lr=0.1]   63%|██████▎   | 47/75 [18:55<10:46, 23.10s/epoch, loss=1.16, accuracy=0.749, val_loss=1.29, val_accuracy=0.706, lr=0.1] 64%|██████▍   | 48/75 [19:17<10:15, 22.80s/epoch, loss=1.15, accuracy=0.752, val_loss=5.05, val_accuracy=0.279, lr=0.1] 65%|██████▌   | 49/75 [19:39<09:47, 22.58s/epoch, loss=1.16, accuracy=0.748, val_loss=1.76, val_accuracy=0.548, lr=0.1] 67%|██████▋   | 50/75 [20:02<09:28, 22.75s/epoch, loss=1.15, accuracy=0.753, val_loss=2.35, val_accuracy=0.468, lr=0.1] 68%|██████▊   | 51/75 [20:26<09:15, 23.15s/epoch, loss=1.15, accuracy=0.753, val_loss=2.36, val_accuracy=0.452, lr=0.1] 69%|██████▉   | 52/75 [20:51<09:01, 23.57s/epoch, loss=1.15, accuracy=0.755, val_loss=3.11, val_accuracy=0.418, lr=0.0316] 71%|███████   | 53/75 [21:15<08:44, 23.84s/epoch, loss=1.14, accuracy=0.755, val_loss=2.5, val_accuracy=0.426, lr=0.1]     72%|███████▏  | 54/75 [21:38<08:11, 23.40s/epoch, loss=1.14, accuracy=0.756, val_loss=2.39, val_accuracy=0.417, lr=0.1] 73%|███████▎  | 55/75 [22:00<07:44, 23.21s/epoch, loss=1.14, accuracy=0.756, val_loss=3, val_accuracy=0.382, lr=0.1]    75%|███████▍  | 56/75 [22:22<07:13, 22.83s/epoch, loss=1.14, accuracy=0.752, val_loss=1.74, val_accuracy=0.555, lr=0.1] 76%|███████▌  | 57/75 [22:45<06:50, 22.78s/epoch, loss=1.14, accuracy=0.753, val_loss=1.45, val_accuracy=0.636, lr=0.0316] 77%|███████▋  | 58/75 [23:08<06:30, 22.95s/epoch, loss=1.14, accuracy=0.754, val_loss=2.63, val_accuracy=0.459, lr=0.1]    79%|███████▊  | 59/75 [23:31<06:07, 22.96s/epoch, loss=1.14, accuracy=0.753, val_loss=2.64, val_accuracy=0.313, lr=0.1] 80%|████████  | 60/75 [23:56<05:51, 23.45s/epoch, loss=1.14, accuracy=0.755, val_loss=1.53, val_accuracy=0.619, lr=0.1] 81%|████████▏ | 61/75 [24:20<05:29, 23.52s/epoch, loss=1.14, accuracy=0.753, val_loss=1.84, val_accuracy=0.527, lr=0.1] 83%|████████▎ | 62/75 [24:43<05:06, 23.57s/epoch, loss=1.13, accuracy=0.753, val_loss=4.08, val_accuracy=0.289, lr=0.0316] 84%|████████▍ | 63/75 [25:08<04:46, 23.85s/epoch, loss=1.15, accuracy=0.755, val_loss=1.62, val_accuracy=0.608, lr=0.1]    85%|████████▌ | 64/75 [25:30<04:18, 23.50s/epoch, loss=1.13, accuracy=0.757, val_loss=1.85, val_accuracy=0.517, lr=0.1] 87%|████████▋ | 65/75 [25:54<03:56, 23.61s/epoch, loss=1.13, accuracy=0.757, val_loss=1.9, val_accuracy=0.557, lr=0.1]  88%|████████▊ | 66/75 [26:19<03:34, 23.88s/epoch, loss=1.14, accuracy=0.753, val_loss=1.39, val_accuracy=0.672, lr=0.1] 89%|████████▉ | 67/75 [26:42<03:10, 23.81s/epoch, loss=1.14, accuracy=0.755, val_loss=2.24, val_accuracy=0.368, lr=0.0316] 91%|█████████ | 68/75 [27:07<02:48, 24.05s/epoch, loss=1.14, accuracy=0.755, val_loss=2.6, val_accuracy=0.396, lr=0.1]     92%|█████████▏| 69/75 [27:32<02:25, 24.22s/epoch, loss=1.14, accuracy=0.754, val_loss=4.69, val_accuracy=0.281, lr=0.1] 93%|█████████▎| 70/75 [27:57<02:02, 24.43s/epoch, loss=1.13, accuracy=0.757, val_loss=2.29, val_accuracy=0.449, lr=0.1] 95%|█████████▍| 71/75 [28:21<01:37, 24.29s/epoch, loss=1.13, accuracy=0.759, val_loss=1.93, val_accuracy=0.488, lr=0.1] 96%|█████████▌| 72/75 [28:45<01:13, 24.38s/epoch, loss=1.12, accuracy=0.758, val_loss=1.91, val_accuracy=0.575, lr=0.0316] 97%|█████████▋| 73/75 [29:10<00:48, 24.45s/epoch, loss=1.13, accuracy=0.755, val_loss=4.31, val_accuracy=0.225, lr=0.1]    99%|█████████▊| 74/75 [29:34<00:24, 24.32s/epoch, loss=1.13, accuracy=0.756, val_loss=1.87, val_accuracy=0.531, lr=0.1]100%|██████████| 75/75 [29:58<00:00, 24.16s/epoch, loss=1.12, accuracy=0.758, val_loss=1.64, val_accuracy=0.581, lr=0.1]100%|██████████| 75/75 [29:58<00:00, 23.97s/epoch, loss=1.12, accuracy=0.758, val_loss=1.64, val_accuracy=0.581, lr=0.1]
Using real-time data augmentation.
Test score: 1.6383389234542847
Test accuracy: 0.5814999938011169


* * * Run SGD for ID = 20_15. * * *


2024-03-05 20:08:47.342837: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 20:08:50.558101: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 20:08:50.559181: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-05 20:08:50.601422: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-05 20:08:50.601470: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 20:08:50.606314: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 20:08:50.606375: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 20:08:50.610409: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 20:08:50.612315: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 20:08:50.616445: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 20:08:50.619290: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 20:08:50.625788: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 20:08:50.626600: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 20:08:50.626738: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 20:08:51.990898: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-05 20:08:51.991560: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 20:08:51.993319: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-05 20:08:51.993373: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 20:08:51.993407: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 20:08:51.993424: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 20:08:51.993440: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 20:08:51.993456: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 20:08:51.993472: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 20:08:51.993488: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 20:08:51.993503: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 20:08:51.993981: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 20:08:51.994019: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 20:08:52.824303: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-05 20:08:52.824433: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-05 20:08:52.824445: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-05 20:08:52.825632: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:02:00.0, compute capability: 6.1)
{'id': '20_15', 'seed': 15, 'out_folder': 'results/epoch_budget', 'batch_size': 128, 'epochs': 75, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'bootstrapping': False, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/75 [00:00<?, ?epoch/s]2024-03-05 20:08:53.823707: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-05 20:08:53.836198: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199825000 Hz
2024-03-05 20:08:56.163841: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 20:08:56.416915: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 20:08:57.309591: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-05 20:08:57.378156: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|▏         | 1/75 [01:02<1:16:45, 62.23s/epoch, loss=3.11, accuracy=0.31, val_loss=2.99, val_accuracy=0.173, lr=0.1]  3%|▎         | 2/75 [01:25<47:33, 39.09s/epoch, loss=1.56, accuracy=0.538, val_loss=1.85, val_accuracy=0.481, lr=0.1]   4%|▍         | 3/75 [01:48<38:26, 32.03s/epoch, loss=1.35, accuracy=0.638, val_loss=2.49, val_accuracy=0.418, lr=0.1]  5%|▌         | 4/75 [02:12<34:04, 28.80s/epoch, loss=1.29, accuracy=0.678, val_loss=1.49, val_accuracy=0.615, lr=0.1]  7%|▋         | 5/75 [02:37<31:57, 27.40s/epoch, loss=1.25, accuracy=0.7, val_loss=3.72, val_accuracy=0.283, lr=0.1]    8%|▊         | 6/75 [03:02<30:36, 26.62s/epoch, loss=1.24, accuracy=0.708, val_loss=3.58, val_accuracy=0.338, lr=0.1]  9%|▉         | 7/75 [03:26<29:08, 25.71s/epoch, loss=1.22, accuracy=0.716, val_loss=2.16, val_accuracy=0.429, lr=0.1] 11%|█         | 8/75 [03:49<27:43, 24.84s/epoch, loss=1.22, accuracy=0.723, val_loss=1.71, val_accuracy=0.575, lr=0.1] 12%|█▏        | 9/75 [04:12<26:48, 24.37s/epoch, loss=1.21, accuracy=0.725, val_loss=1.48, val_accuracy=0.63, lr=0.1]  13%|█▎        | 10/75 [04:37<26:36, 24.56s/epoch, loss=1.2, accuracy=0.732, val_loss=6.05, val_accuracy=0.224, lr=0.1] 15%|█▍        | 11/75 [05:02<26:15, 24.62s/epoch, loss=1.2, accuracy=0.733, val_loss=1.53, val_accuracy=0.602, lr=0.1] 16%|█▌        | 12/75 [05:25<25:17, 24.09s/epoch, loss=1.19, accuracy=0.735, val_loss=2.98, val_accuracy=0.328, lr=0.1] 17%|█▋        | 13/75 [05:49<24:55, 24.12s/epoch, loss=1.19, accuracy=0.736, val_loss=2.94, val_accuracy=0.406, lr=0.1] 19%|█▊        | 14/75 [06:12<24:13, 23.83s/epoch, loss=1.19, accuracy=0.737, val_loss=1.81, val_accuracy=0.585, lr=0.0316] 20%|██        | 15/75 [06:36<23:42, 23.70s/epoch, loss=1.18, accuracy=0.74, val_loss=2.93, val_accuracy=0.374, lr=0.1]     21%|██▏       | 16/75 [06:58<23:00, 23.40s/epoch, loss=1.17, accuracy=0.741, val_loss=2.55, val_accuracy=0.424, lr=0.1] 23%|██▎       | 17/75 [07:23<22:55, 23.72s/epoch, loss=1.18, accuracy=0.742, val_loss=1.99, val_accuracy=0.497, lr=0.1] 24%|██▍       | 18/75 [07:47<22:34, 23.77s/epoch, loss=1.18, accuracy=0.742, val_loss=2.06, val_accuracy=0.46, lr=0.1]  25%|██▌       | 19/75 [08:10<22:05, 23.67s/epoch, loss=1.17, accuracy=0.745, val_loss=2.4, val_accuracy=0.445, lr=0.0316] 27%|██▋       | 20/75 [08:33<21:20, 23.28s/epoch, loss=1.17, accuracy=0.746, val_loss=1.62, val_accuracy=0.573, lr=0.1]   28%|██▊       | 21/75 [08:56<20:54, 23.24s/epoch, loss=1.16, accuracy=0.746, val_loss=1.78, val_accuracy=0.585, lr=0.1] 29%|██▉       | 22/75 [09:18<20:19, 23.01s/epoch, loss=1.16, accuracy=0.748, val_loss=1.97, val_accuracy=0.526, lr=0.1] 31%|███       | 23/75 [09:41<19:48, 22.85s/epoch, loss=1.17, accuracy=0.746, val_loss=2.02, val_accuracy=0.435, lr=0.1] 32%|███▏      | 24/75 [10:03<19:19, 22.73s/epoch, loss=1.16, accuracy=0.748, val_loss=2.09, val_accuracy=0.458, lr=0.0316] 33%|███▎      | 25/75 [10:28<19:26, 23.32s/epoch, loss=1.16, accuracy=0.748, val_loss=1.63, val_accuracy=0.59, lr=0.1]     35%|███▍      | 26/75 [10:50<18:45, 22.96s/epoch, loss=1.16, accuracy=0.75, val_loss=2.04, val_accuracy=0.48, lr=0.1]  36%|███▌      | 27/75 [11:12<18:14, 22.80s/epoch, loss=1.16, accuracy=0.749, val_loss=1.53, val_accuracy=0.643, lr=0.1] 37%|███▋      | 28/75 [11:36<18:03, 23.05s/epoch, loss=1.15, accuracy=0.749, val_loss=1.55, val_accuracy=0.62, lr=0.1]  39%|███▊      | 29/75 [11:59<17:45, 23.16s/epoch, loss=1.15, accuracy=0.751, val_loss=2.21, val_accuracy=0.421, lr=0.0316] 40%|████      | 30/75 [12:23<17:33, 23.41s/epoch, loss=1.16, accuracy=0.749, val_loss=2.2, val_accuracy=0.484, lr=0.1]     41%|████▏     | 31/75 [12:46<16:55, 23.07s/epoch, loss=1.15, accuracy=0.749, val_loss=1.45, val_accuracy=0.661, lr=0.1] 43%|████▎     | 32/75 [13:08<16:26, 22.93s/epoch, loss=1.15, accuracy=0.752, val_loss=1.56, val_accuracy=0.634, lr=0.1] 44%|████▍     | 33/75 [13:31<16:02, 22.92s/epoch, loss=1.14, accuracy=0.751, val_loss=1.7, val_accuracy=0.56, lr=0.1]   45%|████▌     | 34/75 [13:55<15:47, 23.10s/epoch, loss=1.15, accuracy=0.751, val_loss=1.89, val_accuracy=0.57, lr=0.1] 47%|████▋     | 35/75 [14:17<15:14, 22.87s/epoch, loss=1.15, accuracy=0.753, val_loss=3.98, val_accuracy=0.201, lr=0.1] 48%|████▊     | 36/75 [14:42<15:11, 23.36s/epoch, loss=1.14, accuracy=0.754, val_loss=2.14, val_accuracy=0.466, lr=0.0316] 49%|████▉     | 37/75 [15:06<14:58, 23.64s/epoch, loss=1.15, accuracy=0.749, val_loss=1.41, val_accuracy=0.654, lr=0.1]    51%|█████     | 38/75 [15:31<14:48, 24.00s/epoch, loss=1.14, accuracy=0.753, val_loss=1.73, val_accuracy=0.554, lr=0.1] 52%|█████▏    | 39/75 [15:56<14:34, 24.28s/epoch, loss=1.14, accuracy=0.751, val_loss=1.99, val_accuracy=0.498, lr=0.1] 53%|█████▎    | 40/75 [16:18<13:51, 23.77s/epoch, loss=1.14, accuracy=0.755, val_loss=1.79, val_accuracy=0.573, lr=0.1] 55%|█████▍    | 41/75 [16:41<13:15, 23.39s/epoch, loss=1.14, accuracy=0.755, val_loss=2.05, val_accuracy=0.461, lr=0.1] 56%|█████▌    | 42/75 [17:04<12:51, 23.39s/epoch, loss=1.14, accuracy=0.755, val_loss=4.25, val_accuracy=0.273, lr=0.0316] 57%|█████▋    | 43/75 [17:29<12:43, 23.86s/epoch, loss=1.13, accuracy=0.754, val_loss=3.66, val_accuracy=0.374, lr=0.1]    59%|█████▊    | 44/75 [17:52<12:07, 23.46s/epoch, loss=1.13, accuracy=0.757, val_loss=3.36, val_accuracy=0.285, lr=0.1] 60%|██████    | 45/75 [18:15<11:39, 23.32s/epoch, loss=1.14, accuracy=0.755, val_loss=2.13, val_accuracy=0.513, lr=0.1] 61%|██████▏   | 46/75 [18:39<11:27, 23.71s/epoch, loss=1.14, accuracy=0.754, val_loss=1.73, val_accuracy=0.581, lr=0.1] 63%|██████▎   | 47/75 [19:03<11:08, 23.89s/epoch, loss=1.14, accuracy=0.753, val_loss=1.72, val_accuracy=0.559, lr=0.0316] 64%|██████▍   | 48/75 [19:28<10:47, 23.96s/epoch, loss=1.13, accuracy=0.754, val_loss=2.22, val_accuracy=0.471, lr=0.1]    65%|██████▌   | 49/75 [19:53<10:32, 24.34s/epoch, loss=1.13, accuracy=0.756, val_loss=2.24, val_accuracy=0.483, lr=0.1] 67%|██████▋   | 50/75 [20:18<10:13, 24.55s/epoch, loss=1.13, accuracy=0.754, val_loss=1.48, val_accuracy=0.641, lr=0.1] 68%|██████▊   | 51/75 [20:42<09:49, 24.58s/epoch, loss=1.13, accuracy=0.756, val_loss=1.52, val_accuracy=0.622, lr=0.1] 69%|██████▉   | 52/75 [21:06<09:15, 24.13s/epoch, loss=1.13, accuracy=0.755, val_loss=1.97, val_accuracy=0.506, lr=0.0316] 71%|███████   | 53/75 [21:31<08:56, 24.40s/epoch, loss=1.12, accuracy=0.754, val_loss=1.79, val_accuracy=0.571, lr=0.1]    72%|███████▏  | 54/75 [21:53<08:17, 23.69s/epoch, loss=1.12, accuracy=0.757, val_loss=1.59, val_accuracy=0.598, lr=0.1] 73%|███████▎  | 55/75 [22:17<07:57, 23.89s/epoch, loss=1.12, accuracy=0.754, val_loss=2.1, val_accuracy=0.515, lr=0.1]  75%|███████▍  | 56/75 [22:40<07:28, 23.61s/epoch, loss=1.12, accuracy=0.757, val_loss=1.68, val_accuracy=0.573, lr=0.1] 76%|███████▌  | 57/75 [23:05<07:12, 24.05s/epoch, loss=1.12, accuracy=0.756, val_loss=1.55, val_accuracy=0.601, lr=0.0316] 77%|███████▋  | 58/75 [23:27<06:40, 23.56s/epoch, loss=1.12, accuracy=0.758, val_loss=2.78, val_accuracy=0.461, lr=0.1]    79%|███████▊  | 59/75 [23:52<06:20, 23.78s/epoch, loss=1.12, accuracy=0.757, val_loss=3.73, val_accuracy=0.292, lr=0.1] 80%|████████  | 60/75 [24:14<05:50, 23.34s/epoch, loss=1.12, accuracy=0.757, val_loss=1.87, val_accuracy=0.463, lr=0.1] 81%|████████▏ | 61/75 [24:37<05:26, 23.34s/epoch, loss=1.12, accuracy=0.757, val_loss=1.9, val_accuracy=0.582, lr=0.1]  83%|████████▎ | 62/75 [25:00<05:01, 23.23s/epoch, loss=1.13, accuracy=0.755, val_loss=2.05, val_accuracy=0.472, lr=0.0316] 84%|████████▍ | 63/75 [25:25<04:42, 23.54s/epoch, loss=1.12, accuracy=0.755, val_loss=1.71, val_accuracy=0.589, lr=0.1]    85%|████████▌ | 64/75 [25:48<04:19, 23.64s/epoch, loss=1.12, accuracy=0.754, val_loss=2.14, val_accuracy=0.52, lr=0.1]  87%|████████▋ | 65/75 [26:11<03:51, 23.16s/epoch, loss=1.12, accuracy=0.755, val_loss=2.6, val_accuracy=0.367, lr=0.1] 88%|████████▊ | 66/75 [26:34<03:29, 23.27s/epoch, loss=1.12, accuracy=0.756, val_loss=2.35, val_accuracy=0.434, lr=0.1] 89%|████████▉ | 67/75 [26:58<03:08, 23.57s/epoch, loss=1.12, accuracy=0.757, val_loss=2.98, val_accuracy=0.428, lr=0.0316] 91%|█████████ | 68/75 [27:23<02:47, 23.93s/epoch, loss=1.12, accuracy=0.759, val_loss=1.48, val_accuracy=0.623, lr=0.1]    92%|█████████▏| 69/75 [27:48<02:25, 24.17s/epoch, loss=1.12, accuracy=0.757, val_loss=2.35, val_accuracy=0.384, lr=0.1] 93%|█████████▎| 70/75 [28:11<01:59, 23.85s/epoch, loss=1.12, accuracy=0.757, val_loss=3.05, val_accuracy=0.329, lr=0.1] 95%|█████████▍| 71/75 [28:34<01:35, 23.76s/epoch, loss=1.11, accuracy=0.758, val_loss=2.64, val_accuracy=0.438, lr=0.1] 96%|█████████▌| 72/75 [28:59<01:12, 24.02s/epoch, loss=1.12, accuracy=0.759, val_loss=2.12, val_accuracy=0.444, lr=0.0316] 97%|█████████▋| 73/75 [29:24<00:48, 24.24s/epoch, loss=1.12, accuracy=0.757, val_loss=2.35, val_accuracy=0.437, lr=0.1]    99%|█████████▊| 74/75 [29:46<00:23, 23.70s/epoch, loss=1.12, accuracy=0.757, val_loss=2.49, val_accuracy=0.448, lr=0.1]100%|██████████| 75/75 [30:11<00:00, 23.93s/epoch, loss=1.11, accuracy=0.758, val_loss=2.13, val_accuracy=0.402, lr=0.1]100%|██████████| 75/75 [30:11<00:00, 24.15s/epoch, loss=1.11, accuracy=0.758, val_loss=2.13, val_accuracy=0.402, lr=0.1]
Using real-time data augmentation.
Test score: 2.13269305229187
Test accuracy: 0.40209999680519104


* * * Run SGD for ID = 20_16. * * *


2024-03-05 20:39:10.453832: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 20:39:23.541138: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 20:39:23.542318: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-05 20:39:23.589294: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-05 20:39:23.589338: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 20:39:23.595090: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 20:39:23.595157: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 20:39:23.598151: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 20:39:23.599476: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 20:39:23.602426: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 20:39:23.604489: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 20:39:23.615981: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 20:39:23.625513: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 20:39:23.625677: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 20:39:25.114438: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-05 20:39:25.115011: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 20:39:25.115752: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-05 20:39:25.115789: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 20:39:25.115825: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 20:39:25.115844: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 20:39:25.115862: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 20:39:25.115879: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 20:39:25.115914: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 20:39:25.115932: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 20:39:25.115949: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 20:39:25.116476: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 20:39:25.116516: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 20:39:25.920859: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-05 20:39:25.920926: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-05 20:39:25.920936: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-05 20:39:25.922848: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:02:00.0, compute capability: 6.1)
{'id': '20_16', 'seed': 16, 'out_folder': 'results/epoch_budget', 'batch_size': 128, 'epochs': 75, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'bootstrapping': False, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/75 [00:00<?, ?epoch/s]2024-03-05 20:39:26.929530: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-05 20:39:26.930153: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199825000 Hz
2024-03-05 20:39:29.324377: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 20:39:29.617806: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 20:39:30.567210: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-05 20:39:30.618405: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|▏         | 1/75 [01:06<1:21:24, 66.01s/epoch, loss=3.87, accuracy=0.302, val_loss=2.57, val_accuracy=0.179, lr=0.1]  3%|▎         | 2/75 [01:29<49:32, 40.72s/epoch, loss=1.57, accuracy=0.537, val_loss=2.74, val_accuracy=0.252, lr=0.1]    4%|▍         | 3/75 [01:51<38:47, 32.32s/epoch, loss=1.32, accuracy=0.64, val_loss=1.82, val_accuracy=0.547, lr=0.1]   5%|▌         | 4/75 [02:15<34:18, 28.99s/epoch, loss=1.26, accuracy=0.683, val_loss=2.05, val_accuracy=0.506, lr=0.1]  7%|▋         | 5/75 [02:37<31:08, 26.70s/epoch, loss=1.24, accuracy=0.696, val_loss=2.88, val_accuracy=0.282, lr=0.1]  8%|▊         | 6/75 [03:00<29:04, 25.28s/epoch, loss=1.22, accuracy=0.708, val_loss=1.75, val_accuracy=0.516, lr=0.1]  9%|▉         | 7/75 [03:23<28:01, 24.73s/epoch, loss=1.2, accuracy=0.717, val_loss=1.45, val_accuracy=0.623, lr=0.1]  11%|█         | 8/75 [03:47<27:09, 24.33s/epoch, loss=1.19, accuracy=0.722, val_loss=1.51, val_accuracy=0.607, lr=0.1] 12%|█▏        | 9/75 [04:11<26:48, 24.38s/epoch, loss=1.18, accuracy=0.724, val_loss=1.56, val_accuracy=0.613, lr=0.1] 13%|█▎        | 10/75 [04:35<25:58, 23.98s/epoch, loss=1.18, accuracy=0.728, val_loss=1.8, val_accuracy=0.537, lr=0.1] 15%|█▍        | 11/75 [04:58<25:29, 23.89s/epoch, loss=1.18, accuracy=0.729, val_loss=1.92, val_accuracy=0.535, lr=0.1] 16%|█▌        | 12/75 [05:21<24:36, 23.43s/epoch, loss=1.17, accuracy=0.732, val_loss=2.85, val_accuracy=0.459, lr=0.0316] 17%|█▋        | 13/75 [05:45<24:25, 23.64s/epoch, loss=1.15, accuracy=0.738, val_loss=1.58, val_accuracy=0.622, lr=0.1]    19%|█▊        | 14/75 [06:07<23:38, 23.25s/epoch, loss=1.16, accuracy=0.738, val_loss=1.63, val_accuracy=0.587, lr=0.1] 20%|██        | 15/75 [06:32<23:42, 23.70s/epoch, loss=1.16, accuracy=0.736, val_loss=1.85, val_accuracy=0.491, lr=0.1] 21%|██▏       | 16/75 [06:57<23:37, 24.03s/epoch, loss=1.16, accuracy=0.74, val_loss=1.42, val_accuracy=0.644, lr=0.1]  23%|██▎       | 17/75 [07:19<22:50, 23.64s/epoch, loss=1.15, accuracy=0.742, val_loss=2.15, val_accuracy=0.419, lr=0.1] 24%|██▍       | 18/75 [07:42<22:15, 23.43s/epoch, loss=1.15, accuracy=0.742, val_loss=1.47, val_accuracy=0.622, lr=0.1] 25%|██▌       | 19/75 [08:05<21:37, 23.18s/epoch, loss=1.15, accuracy=0.742, val_loss=4.43, val_accuracy=0.284, lr=0.1] 27%|██▋       | 20/75 [08:28<21:09, 23.09s/epoch, loss=1.15, accuracy=0.744, val_loss=1.7, val_accuracy=0.564, lr=0.1]  28%|██▊       | 21/75 [08:51<20:43, 23.02s/epoch, loss=1.15, accuracy=0.746, val_loss=1.5, val_accuracy=0.622, lr=0.0316] 29%|██▉       | 22/75 [09:13<20:11, 22.85s/epoch, loss=1.14, accuracy=0.744, val_loss=1.55, val_accuracy=0.594, lr=0.1]   31%|███       | 23/75 [09:36<19:45, 22.80s/epoch, loss=1.14, accuracy=0.747, val_loss=2.01, val_accuracy=0.475, lr=0.1] 32%|███▏      | 24/75 [09:59<19:33, 23.01s/epoch, loss=1.14, accuracy=0.749, val_loss=1.47, val_accuracy=0.629, lr=0.1] 33%|███▎      | 25/75 [10:22<19:00, 22.81s/epoch, loss=1.14, accuracy=0.748, val_loss=2.12, val_accuracy=0.509, lr=0.1] 35%|███▍      | 26/75 [10:46<18:55, 23.16s/epoch, loss=1.14, accuracy=0.749, val_loss=2.07, val_accuracy=0.438, lr=0.0316] 36%|███▌      | 27/75 [11:10<18:51, 23.57s/epoch, loss=1.13, accuracy=0.749, val_loss=4.29, val_accuracy=0.294, lr=0.1]    37%|███▋      | 28/75 [11:34<18:26, 23.54s/epoch, loss=1.14, accuracy=0.751, val_loss=2.19, val_accuracy=0.488, lr=0.1] 39%|███▊      | 29/75 [11:58<18:08, 23.66s/epoch, loss=1.14, accuracy=0.75, val_loss=1.5, val_accuracy=0.622, lr=0.1]   40%|████      | 30/75 [12:23<18:03, 24.08s/epoch, loss=1.13, accuracy=0.749, val_loss=1.98, val_accuracy=0.476, lr=0.1] 41%|████▏     | 31/75 [12:45<17:23, 23.71s/epoch, loss=1.13, accuracy=0.749, val_loss=2.26, val_accuracy=0.428, lr=0.0316] 43%|████▎     | 32/75 [13:10<17:04, 23.83s/epoch, loss=1.13, accuracy=0.752, val_loss=3.63, val_accuracy=0.321, lr=0.1]    44%|████▍     | 33/75 [13:35<16:57, 24.24s/epoch, loss=1.14, accuracy=0.753, val_loss=1.76, val_accuracy=0.552, lr=0.1] 45%|████▌     | 34/75 [13:58<16:16, 23.82s/epoch, loss=1.14, accuracy=0.75, val_loss=1.84, val_accuracy=0.521, lr=0.1]  47%|████▋     | 35/75 [14:21<15:50, 23.77s/epoch, loss=1.13, accuracy=0.753, val_loss=2.06, val_accuracy=0.543, lr=0.1] 48%|████▊     | 36/75 [14:45<15:27, 23.79s/epoch, loss=1.13, accuracy=0.749, val_loss=1.41, val_accuracy=0.662, lr=0.1] 49%|████▉     | 37/75 [15:09<15:02, 23.74s/epoch, loss=1.13, accuracy=0.754, val_loss=2.81, val_accuracy=0.467, lr=0.1] 51%|█████     | 38/75 [15:31<14:27, 23.45s/epoch, loss=1.13, accuracy=0.753, val_loss=3.71, val_accuracy=0.333, lr=0.1] 52%|█████▏    | 39/75 [15:55<14:03, 23.42s/epoch, loss=1.13, accuracy=0.753, val_loss=2.4, val_accuracy=0.374, lr=0.1]  53%|█████▎    | 40/75 [16:17<13:27, 23.08s/epoch, loss=1.13, accuracy=0.754, val_loss=2.62, val_accuracy=0.445, lr=0.1] 55%|█████▍    | 41/75 [16:42<13:21, 23.58s/epoch, loss=1.13, accuracy=0.754, val_loss=1.45, val_accuracy=0.647, lr=0.0316] 56%|█████▌    | 42/75 [17:06<13:08, 23.88s/epoch, loss=1.13, accuracy=0.753, val_loss=1.89, val_accuracy=0.535, lr=0.1]    57%|█████▋    | 43/75 [17:30<12:36, 23.64s/epoch, loss=1.12, accuracy=0.756, val_loss=1.71, val_accuracy=0.573, lr=0.1] 59%|█████▊    | 44/75 [17:54<12:21, 23.91s/epoch, loss=1.12, accuracy=0.754, val_loss=1.74, val_accuracy=0.553, lr=0.1] 60%|██████    | 45/75 [18:18<11:56, 23.89s/epoch, loss=1.12, accuracy=0.756, val_loss=1.7, val_accuracy=0.547, lr=0.1]  61%|██████▏   | 46/75 [18:43<11:42, 24.23s/epoch, loss=1.12, accuracy=0.754, val_loss=1.79, val_accuracy=0.505, lr=0.0316] 63%|██████▎   | 47/75 [19:07<11:18, 24.23s/epoch, loss=1.13, accuracy=0.754, val_loss=3.34, val_accuracy=0.419, lr=0.1]    64%|██████▍   | 48/75 [19:32<10:55, 24.29s/epoch, loss=1.12, accuracy=0.754, val_loss=2.02, val_accuracy=0.5, lr=0.1]   65%|██████▌   | 49/75 [19:57<10:40, 24.64s/epoch, loss=1.12, accuracy=0.755, val_loss=1.75, val_accuracy=0.552, lr=0.1] 67%|██████▋   | 50/75 [20:20<10:06, 24.27s/epoch, loss=1.12, accuracy=0.754, val_loss=1.48, val_accuracy=0.634, lr=0.1] 68%|██████▊   | 51/75 [20:45<09:47, 24.48s/epoch, loss=1.13, accuracy=0.755, val_loss=2.13, val_accuracy=0.446, lr=0.0316] 69%|██████▉   | 52/75 [21:11<09:29, 24.75s/epoch, loss=1.12, accuracy=0.757, val_loss=2.18, val_accuracy=0.416, lr=0.1]    71%|███████   | 53/75 [21:36<09:08, 24.94s/epoch, loss=1.12, accuracy=0.757, val_loss=1.75, val_accuracy=0.549, lr=0.1] 72%|███████▏  | 54/75 [22:02<08:46, 25.07s/epoch, loss=1.11, accuracy=0.757, val_loss=1.7, val_accuracy=0.592, lr=0.1]  73%|███████▎  | 55/75 [22:27<08:23, 25.16s/epoch, loss=1.12, accuracy=0.755, val_loss=4.48, val_accuracy=0.244, lr=0.1] 75%|███████▍  | 56/75 [22:53<08:00, 25.31s/epoch, loss=1.12, accuracy=0.754, val_loss=2.76, val_accuracy=0.41, lr=0.0316] 76%|███████▌  | 57/75 [23:18<07:35, 25.33s/epoch, loss=1.12, accuracy=0.758, val_loss=2.41, val_accuracy=0.425, lr=0.1]   77%|███████▋  | 58/75 [23:43<07:09, 25.28s/epoch, loss=1.12, accuracy=0.755, val_loss=3.23, val_accuracy=0.384, lr=0.1] 79%|███████▊  | 59/75 [24:07<06:38, 24.89s/epoch, loss=1.11, accuracy=0.757, val_loss=2.8, val_accuracy=0.285, lr=0.1]  80%|████████  | 60/75 [24:31<06:09, 24.62s/epoch, loss=1.12, accuracy=0.753, val_loss=2.28, val_accuracy=0.451, lr=0.1] 81%|████████▏ | 61/75 [24:54<05:37, 24.07s/epoch, loss=1.12, accuracy=0.756, val_loss=2.72, val_accuracy=0.397, lr=0.0316] 83%|████████▎ | 62/75 [25:17<05:07, 23.65s/epoch, loss=1.12, accuracy=0.757, val_loss=4.05, val_accuracy=0.319, lr=0.1]    84%|████████▍ | 63/75 [25:39<04:40, 23.40s/epoch, loss=1.12, accuracy=0.755, val_loss=1.77, val_accuracy=0.55, lr=0.1]  85%|████████▌ | 64/75 [26:04<04:23, 23.92s/epoch, loss=1.12, accuracy=0.755, val_loss=1.78, val_accuracy=0.562, lr=0.1] 87%|████████▋ | 65/75 [26:28<03:56, 23.70s/epoch, loss=1.11, accuracy=0.756, val_loss=2.48, val_accuracy=0.454, lr=0.1] 88%|████████▊ | 66/75 [26:53<03:36, 24.08s/epoch, loss=1.12, accuracy=0.757, val_loss=2.02, val_accuracy=0.529, lr=0.0316] 89%|████████▉ | 67/75 [27:17<03:13, 24.22s/epoch, loss=1.12, accuracy=0.755, val_loss=1.62, val_accuracy=0.602, lr=0.1]    91%|█████████ | 68/75 [27:42<02:51, 24.45s/epoch, loss=1.12, accuracy=0.756, val_loss=1.85, val_accuracy=0.511, lr=0.1] 92%|█████████▏| 69/75 [28:07<02:27, 24.56s/epoch, loss=1.11, accuracy=0.756, val_loss=1.7, val_accuracy=0.599, lr=0.1]  93%|█████████▎| 70/75 [28:31<02:02, 24.52s/epoch, loss=1.12, accuracy=0.756, val_loss=1.79, val_accuracy=0.507, lr=0.1] 95%|█████████▍| 71/75 [28:56<01:37, 24.45s/epoch, loss=1.11, accuracy=0.759, val_loss=1.52, val_accuracy=0.623, lr=0.0316] 96%|█████████▌| 72/75 [29:19<01:12, 24.08s/epoch, loss=1.12, accuracy=0.756, val_loss=2.09, val_accuracy=0.525, lr=0.1]    97%|█████████▋| 73/75 [29:44<00:49, 24.51s/epoch, loss=1.12, accuracy=0.753, val_loss=1.8, val_accuracy=0.552, lr=0.1]  99%|█████████▊| 74/75 [30:10<00:24, 24.71s/epoch, loss=1.12, accuracy=0.755, val_loss=2.54, val_accuracy=0.455, lr=0.1]100%|██████████| 75/75 [30:32<00:00, 24.09s/epoch, loss=1.11, accuracy=0.756, val_loss=1.39, val_accuracy=0.675, lr=0.1]100%|██████████| 75/75 [30:32<00:00, 24.44s/epoch, loss=1.11, accuracy=0.756, val_loss=1.39, val_accuracy=0.675, lr=0.1]
Using real-time data augmentation.
Test score: 1.3939231634140015
Test accuracy: 0.6747999787330627


* * * Run SGD for ID = 20_17. * * *


2024-03-05 21:10:04.983229: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 21:10:21.685605: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 21:10:21.686843: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-05 21:10:21.733928: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-05 21:10:21.733984: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 21:10:21.759797: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 21:10:21.759886: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 21:10:21.780738: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 21:10:21.787913: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 21:10:21.798796: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 21:10:21.814455: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 21:10:21.820368: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 21:10:21.827142: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 21:10:21.827277: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 21:10:23.211978: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-05 21:10:23.213141: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 21:10:23.213618: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-05 21:10:23.213650: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 21:10:23.213683: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 21:10:23.213702: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 21:10:23.213719: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 21:10:23.213736: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 21:10:23.213753: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 21:10:23.213770: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 21:10:23.213787: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 21:10:23.214299: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 21:10:23.214337: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 21:10:24.109533: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-05 21:10:24.109616: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-05 21:10:24.109629: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-05 21:10:24.111107: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:02:00.0, compute capability: 6.1)
{'id': '20_17', 'seed': 17, 'out_folder': 'results/epoch_budget', 'batch_size': 128, 'epochs': 75, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'bootstrapping': False, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/75 [00:00<?, ?epoch/s]2024-03-05 21:10:25.069073: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-05 21:10:25.081214: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199825000 Hz
2024-03-05 21:10:27.592960: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 21:10:27.843971: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 21:10:28.877573: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-05 21:10:28.934635: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|▏         | 1/75 [01:04<1:20:03, 64.91s/epoch, loss=3, accuracy=0.362, val_loss=2.2, val_accuracy=0.291, lr=0.1]  3%|▎         | 2/75 [01:27<48:46, 40.09s/epoch, loss=1.5, accuracy=0.572, val_loss=2.25, val_accuracy=0.397, lr=0.1]  4%|▍         | 3/75 [01:51<38:59, 32.49s/epoch, loss=1.32, accuracy=0.657, val_loss=2.14, val_accuracy=0.426, lr=0.1]  5%|▌         | 4/75 [02:13<33:41, 28.47s/epoch, loss=1.27, accuracy=0.688, val_loss=1.93, val_accuracy=0.49, lr=0.1]   7%|▋         | 5/75 [02:35<30:35, 26.23s/epoch, loss=1.24, accuracy=0.702, val_loss=2.2, val_accuracy=0.379, lr=0.1]  8%|▊         | 6/75 [02:59<29:14, 25.43s/epoch, loss=1.23, accuracy=0.71, val_loss=1.47, val_accuracy=0.638, lr=0.1]  9%|▉         | 7/75 [03:23<28:15, 24.94s/epoch, loss=1.21, accuracy=0.72, val_loss=1.79, val_accuracy=0.515, lr=0.1] 11%|█         | 8/75 [03:48<27:45, 24.86s/epoch, loss=1.2, accuracy=0.723, val_loss=1.94, val_accuracy=0.515, lr=0.1] 12%|█▏        | 9/75 [04:12<27:17, 24.81s/epoch, loss=1.19, accuracy=0.726, val_loss=1.76, val_accuracy=0.542, lr=0.1] 13%|█▎        | 10/75 [04:36<26:25, 24.39s/epoch, loss=1.2, accuracy=0.73, val_loss=1.53, val_accuracy=0.599, lr=0.1]  15%|█▍        | 11/75 [05:00<26:05, 24.46s/epoch, loss=1.19, accuracy=0.73, val_loss=1.66, val_accuracy=0.551, lr=0.0316] 16%|█▌        | 12/75 [05:25<25:40, 24.46s/epoch, loss=1.18, accuracy=0.734, val_loss=1.41, val_accuracy=0.656, lr=0.1]   17%|█▋        | 13/75 [05:49<25:13, 24.41s/epoch, loss=1.19, accuracy=0.732, val_loss=3.13, val_accuracy=0.316, lr=0.1] 19%|█▊        | 14/75 [06:14<24:57, 24.55s/epoch, loss=1.17, accuracy=0.738, val_loss=1.78, val_accuracy=0.531, lr=0.1] 20%|██        | 15/75 [06:39<24:35, 24.59s/epoch, loss=1.17, accuracy=0.741, val_loss=2.06, val_accuracy=0.499, lr=0.1] 21%|██▏       | 16/75 [07:03<24:09, 24.57s/epoch, loss=1.17, accuracy=0.741, val_loss=1.99, val_accuracy=0.513, lr=0.1] 23%|██▎       | 17/75 [07:26<23:08, 23.94s/epoch, loss=1.17, accuracy=0.741, val_loss=3.17, val_accuracy=0.39, lr=0.0316] 24%|██▍       | 18/75 [07:51<23:00, 24.22s/epoch, loss=1.16, accuracy=0.746, val_loss=4.88, val_accuracy=0.258, lr=0.1]   25%|██▌       | 19/75 [08:15<22:34, 24.18s/epoch, loss=1.16, accuracy=0.745, val_loss=1.72, val_accuracy=0.543, lr=0.1] 27%|██▋       | 20/75 [08:38<22:00, 24.01s/epoch, loss=1.16, accuracy=0.745, val_loss=1.65, val_accuracy=0.573, lr=0.1] 28%|██▊       | 21/75 [09:03<21:41, 24.11s/epoch, loss=1.16, accuracy=0.746, val_loss=1.49, val_accuracy=0.613, lr=0.1] 29%|██▉       | 22/75 [09:26<21:08, 23.93s/epoch, loss=1.16, accuracy=0.746, val_loss=1.87, val_accuracy=0.541, lr=0.0316] 31%|███       | 23/75 [09:51<20:58, 24.21s/epoch, loss=1.15, accuracy=0.749, val_loss=1.91, val_accuracy=0.527, lr=0.1]   slurmstepd: error: *** JOB 3851 ON hendrixgpu17fl CANCELLED AT 2024-03-05T21:20:40 ***
