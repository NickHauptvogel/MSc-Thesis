Mon Mar 11 17:07:34 2024       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 545.23.08              Driver Version: 545.23.08    CUDA Version: 12.3     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA TITAN Xp                Off | 00000000:83:00.0 Off |                  N/A |
| 23%   24C    P8              10W / 250W |      0MiB / 12288MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|  No running processes found                                                           |
+---------------------------------------------------------------------------------------+


* * * Run SGD for ID = 11. * * *


2024-03-11 17:07:42.783699: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-11 17:08:17.694325: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-11 17:08:17.697168: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-11 17:08:17.770599: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-11 17:08:17.770645: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-11 17:08:18.208513: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-11 17:08:18.208613: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-11 17:08:18.367089: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-11 17:08:18.642225: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-11 17:08:18.810468: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-11 17:08:18.869864: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-11 17:08:19.009793: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-11 17:08:19.011465: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-11 17:08:19.011581: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-11 17:08:21.813614: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-11 17:08:21.814635: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-11 17:08:21.815285: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-11 17:08:21.815324: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-11 17:08:21.815376: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-11 17:08:21.815397: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-11 17:08:21.815413: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-11 17:08:21.815430: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-11 17:08:21.815447: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-11 17:08:21.815464: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-11 17:08:21.815480: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-11 17:08:21.815960: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-11 17:08:21.815996: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-11 17:08:24.536960: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-11 17:08:24.537114: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-11 17:08:24.537135: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-11 17:08:24.550666: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': '11', 'seed': 11, 'out_folder': 'results/cifar100_50_independent_wenzel_no_checkp_bootstr', 'batch_size': 128, 'epochs': 200, 'validation_split': 0.2, 'checkpointing': True, 'checkpoint_every': 40, 'hold_out_validation_split': 0.0, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.2, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'bootstrapping': False, 'num_classes': 10, 'SSE_lr': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
x_train shape: (40000, 32, 32, 3)
40000 train samples
10000 validation samples
10000 test samples
y_train shape: (40000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/200 [00:00<?, ?epoch/s]2024-03-11 17:08:25.475892: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-11 17:08:25.488178: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199825000 Hz
2024-03-11 17:08:27.608524: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-11 17:08:28.002766: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-11 17:08:30.401044: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-11 17:08:30.447701: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  0%|          | 1/200 [01:01<3:24:02, 61.52s/epoch, loss=2.73, accuracy=0.335, val_loss=2.26, val_accuracy=0.262, lr=0.2]  1%|          | 2/200 [01:21<2:02:45, 37.20s/epoch, loss=1.61, accuracy=0.519, val_loss=3.18, val_accuracy=0.25, lr=0.2]   2%|▏         | 3/200 [01:41<1:36:32, 29.41s/epoch, loss=1.5, accuracy=0.603, val_loss=2.62, val_accuracy=0.258, lr=0.199]  2%|▏         | 4/200 [02:01<1:24:02, 25.73s/epoch, loss=1.45, accuracy=0.644, val_loss=2.4, val_accuracy=0.352, lr=0.197]  2%|▎         | 5/200 [02:21<1:16:54, 23.66s/epoch, loss=1.43, accuracy=0.657, val_loss=2.84, val_accuracy=0.279, lr=0.195]  3%|▎         | 6/200 [02:42<1:12:42, 22.49s/epoch, loss=1.41, accuracy=0.669, val_loss=4.92, val_accuracy=0.288, lr=0.192]  4%|▎         | 7/200 [03:01<1:09:19, 21.55s/epoch, loss=1.38, accuracy=0.68, val_loss=3.73, val_accuracy=0.339, lr=0.189]   4%|▍         | 8/200 [03:21<1:07:37, 21.13s/epoch, loss=1.38, accuracy=0.679, val_loss=2.26, val_accuracy=0.4, lr=0.185]   4%|▍         | 9/200 [03:41<1:05:57, 20.72s/epoch, loss=1.35, accuracy=0.687, val_loss=3.99, val_accuracy=0.175, lr=0.181]  5%|▌         | 10/200 [04:02<1:05:08, 20.57s/epoch, loss=1.34, accuracy=0.69, val_loss=2.01, val_accuracy=0.448, lr=0.176]  6%|▌         | 11/200 [04:20<1:02:55, 19.98s/epoch, loss=1.33, accuracy=0.696, val_loss=2.18, val_accuracy=0.372, lr=0.171]  6%|▌         | 12/200 [04:39<1:01:48, 19.73s/epoch, loss=1.31, accuracy=0.702, val_loss=3.01, val_accuracy=0.336, lr=0.165]  6%|▋         | 13/200 [04:59<1:01:26, 19.71s/epoch, loss=1.29, accuracy=0.706, val_loss=2.02, val_accuracy=0.509, lr=0.159]  7%|▋         | 14/200 [05:19<1:01:34, 19.86s/epoch, loss=1.28, accuracy=0.709, val_loss=1.8, val_accuracy=0.508, lr=0.152]   8%|▊         | 15/200 [05:42<1:04:21, 20.87s/epoch, loss=1.25, accuracy=0.713, val_loss=2.24, val_accuracy=0.427, lr=0.145]  8%|▊         | 16/200 [06:03<1:03:32, 20.72s/epoch, loss=1.23, accuracy=0.721, val_loss=2.09, val_accuracy=0.499, lr=0.138]  8%|▊         | 17/200 [06:23<1:02:43, 20.56s/epoch, loss=1.22, accuracy=0.72, val_loss=2.33, val_accuracy=0.429, lr=0.131]   9%|▉         | 18/200 [06:42<1:01:18, 20.21s/epoch, loss=1.19, accuracy=0.73, val_loss=2.39, val_accuracy=0.382, lr=0.123] 10%|▉         | 19/200 [07:02<1:00:52, 20.18s/epoch, loss=1.17, accuracy=0.735, val_loss=3.14, val_accuracy=0.35, lr=0.116] 10%|█         | 20/200 [07:23<1:00:27, 20.15s/epoch, loss=1.15, accuracy=0.738, val_loss=1.89, val_accuracy=0.54, lr=0.108] 10%|█         | 21/200 [07:43<59:55, 20.09s/epoch, loss=1.12, accuracy=0.746, val_loss=1.78, val_accuracy=0.534, lr=0.1]    11%|█         | 22/200 [08:03<59:45, 20.15s/epoch, loss=1.1, accuracy=0.751, val_loss=2.57, val_accuracy=0.382, lr=0.0922] 12%|█▏        | 23/200 [08:23<59:17, 20.10s/epoch, loss=1.06, accuracy=0.758, val_loss=1.59, val_accuracy=0.582, lr=0.0844] 12%|█▏        | 24/200 [08:43<58:55, 20.09s/epoch, loss=1.04, accuracy=0.764, val_loss=2.15, val_accuracy=0.409, lr=0.0767] 12%|█▎        | 25/200 [09:01<56:52, 19.50s/epoch, loss=1, accuracy=0.772, val_loss=3.63, val_accuracy=0.373, lr=0.0691]    13%|█▎        | 26/200 [09:20<56:13, 19.39s/epoch, loss=0.978, accuracy=0.778, val_loss=1.58, val_accuracy=0.567, lr=0.0617] 14%|█▎        | 27/200 [09:40<56:12, 19.50s/epoch, loss=0.938, accuracy=0.785, val_loss=1.34, val_accuracy=0.648, lr=0.0546] 14%|█▍        | 28/200 [10:00<56:22, 19.66s/epoch, loss=0.907, accuracy=0.793, val_loss=1.22, val_accuracy=0.685, lr=0.0478] 14%|█▍        | 29/200 [10:22<58:02, 20.36s/epoch, loss=0.866, accuracy=0.803, val_loss=1.59, val_accuracy=0.603, lr=0.0412] 15%|█▌        | 30/200 [10:42<57:21, 20.25s/epoch, loss=0.826, accuracy=0.812, val_loss=1.46, val_accuracy=0.588, lr=0.0351] 16%|█▌        | 31/200 [11:02<56:53, 20.20s/epoch, loss=0.788, accuracy=0.821, val_loss=1.32, val_accuracy=0.703, lr=0.0293] 16%|█▌        | 32/200 [11:22<56:08, 20.05s/epoch, loss=0.734, accuracy=0.834, val_loss=1.32, val_accuracy=0.665, lr=0.024]  16%|█▋        | 33/200 [11:40<54:08, 19.45s/epoch, loss=0.698, accuracy=0.843, val_loss=1.01, val_accuracy=0.733, lr=0.0191] 17%|█▋        | 34/200 [12:00<54:17, 19.62s/epoch, loss=0.644, accuracy=0.854, val_loss=0.891, val_accuracy=0.774, lr=0.0147] 18%|█▊        | 35/200 [12:20<54:30, 19.82s/epoch, loss=0.589, accuracy=0.867, val_loss=0.982, val_accuracy=0.734, lr=0.0109] 18%|█▊        | 36/200 [12:40<54:16, 19.85s/epoch, loss=0.536, accuracy=0.884, val_loss=0.851, val_accuracy=0.782, lr=0.00761] 18%|█▊        | 37/200 [13:00<54:05, 19.91s/epoch, loss=0.486, accuracy=0.894, val_loss=0.605, val_accuracy=0.855, lr=0.00489] 19%|█▉        | 38/200 [13:20<53:42, 19.89s/epoch, loss=0.437, accuracy=0.91, val_loss=0.586, val_accuracy=0.861, lr=0.00276]  20%|█▉        | 39/200 [13:39<52:57, 19.74s/epoch, loss=0.399, accuracy=0.92, val_loss=0.494, val_accuracy=0.887, lr=0.00123] 20%|██        | 40/200 [13:59<52:50, 19.82s/epoch, loss=0.379, accuracy=0.927, val_loss=0.479, val_accuracy=0.892, lr=0.000308] 20%|██        | 41/200 [14:19<52:38, 19.86s/epoch, loss=4.57, accuracy=0.277, val_loss=3.2, val_accuracy=0.124, lr=0.2]         21%|██        | 42/200 [14:39<51:59, 19.74s/epoch, loss=1.63, accuracy=0.516, val_loss=1.98, val_accuracy=0.378, lr=0.2] 22%|██▏       | 43/200 [14:59<51:46, 19.79s/epoch, loss=1.47, accuracy=0.61, val_loss=2.99, val_accuracy=0.313, lr=0.199] 22%|██▏       | 44/200 [15:17<50:31, 19.43s/epoch, loss=1.42, accuracy=0.646, val_loss=2.38, val_accuracy=0.365, lr=0.197] 22%|██▎       | 45/200 [15:37<50:39, 19.61s/epoch, loss=1.37, accuracy=0.667, val_loss=3.14, val_accuracy=0.219, lr=0.195] 23%|██▎       | 46/200 [15:58<51:17, 19.98s/epoch, loss=1.37, accuracy=0.674, val_loss=5.3, val_accuracy=0.279, lr=0.192]  24%|██▎       | 47/200 [16:18<50:52, 19.95s/epoch, loss=1.35, accuracy=0.684, val_loss=4.06, val_accuracy=0.258, lr=0.189] 24%|██▍       | 48/200 [16:38<50:39, 20.00s/epoch, loss=1.34, accuracy=0.687, val_loss=2.62, val_accuracy=0.332, lr=0.185] 24%|██▍       | 49/200 [16:58<50:27, 20.05s/epoch, loss=1.32, accuracy=0.692, val_loss=1.63, val_accuracy=0.571, lr=0.181] 25%|██▌       | 50/200 [17:18<50:03, 20.02s/epoch, loss=1.31, accuracy=0.696, val_loss=4.23, val_accuracy=0.283, lr=0.176] 26%|██▌       | 51/200 [17:38<49:44, 20.03s/epoch, loss=1.3, accuracy=0.703, val_loss=2.75, val_accuracy=0.358, lr=0.171]  26%|██▌       | 52/200 [17:58<49:30, 20.07s/epoch, loss=1.29, accuracy=0.704, val_loss=2.99, val_accuracy=0.379, lr=0.165] 26%|██▋       | 53/200 [18:19<49:17, 20.12s/epoch, loss=1.27, accuracy=0.708, val_loss=2.18, val_accuracy=0.418, lr=0.159] 27%|██▋       | 54/200 [18:39<49:08, 20.20s/epoch, loss=1.24, accuracy=0.714, val_loss=1.89, val_accuracy=0.483, lr=0.152] 28%|██▊       | 55/200 [19:01<50:01, 20.70s/epoch, loss=1.23, accuracy=0.718, val_loss=1.95, val_accuracy=0.492, lr=0.145] 28%|██▊       | 56/200 [19:21<49:09, 20.49s/epoch, loss=1.22, accuracy=0.725, val_loss=1.73, val_accuracy=0.561, lr=0.138] 28%|██▊       | 57/200 [19:41<48:28, 20.34s/epoch, loss=1.19, accuracy=0.729, val_loss=2.78, val_accuracy=0.426, lr=0.131] 29%|██▉       | 58/200 [20:00<47:38, 20.13s/epoch, loss=1.18, accuracy=0.734, val_loss=1.6, val_accuracy=0.606, lr=0.123]  30%|██▉       | 59/200 [20:21<47:18, 20.13s/epoch, loss=1.15, accuracy=0.738, val_loss=2.84, val_accuracy=0.417, lr=0.116] 30%|███       | 60/200 [20:40<46:43, 20.02s/epoch, loss=1.13, accuracy=0.744, val_loss=1.99, val_accuracy=0.524, lr=0.108] 30%|███       | 61/200 [21:00<46:17, 19.98s/epoch, loss=1.1, accuracy=0.746, val_loss=1.66, val_accuracy=0.546, lr=0.1]    31%|███       | 62/200 [21:20<45:56, 19.97s/epoch, loss=1.08, accuracy=0.754, val_loss=2.25, val_accuracy=0.396, lr=0.0922] 32%|███▏      | 63/200 [21:43<47:38, 20.87s/epoch, loss=1.05, accuracy=0.761, val_loss=2.03, val_accuracy=0.468, lr=0.0844] 32%|███▏      | 64/200 [22:04<47:31, 20.97s/epoch, loss=1.02, accuracy=0.768, val_loss=2.3, val_accuracy=0.4, lr=0.0767]    32%|███▎      | 65/200 [22:24<46:33, 20.70s/epoch, loss=0.989, accuracy=0.775, val_loss=1.41, val_accuracy=0.634, lr=0.0691] 33%|███▎      | 66/200 [22:44<45:26, 20.34s/epoch, loss=0.957, accuracy=0.781, val_loss=1.27, val_accuracy=0.681, lr=0.0617] 34%|███▎      | 67/200 [23:04<44:56, 20.28s/epoch, loss=0.93, accuracy=0.787, val_loss=1.61, val_accuracy=0.567, lr=0.0546]  34%|███▍      | 68/200 [23:24<44:31, 20.24s/epoch, loss=0.893, accuracy=0.796, val_loss=1.4, val_accuracy=0.644, lr=0.0478] 34%|███▍      | 69/200 [23:44<44:11, 20.24s/epoch, loss=0.855, accuracy=0.804, val_loss=1.12, val_accuracy=0.714, lr=0.0412] 35%|███▌      | 70/200 [24:04<43:07, 19.90s/epoch, loss=0.814, accuracy=0.813, val_loss=1.16, val_accuracy=0.697, lr=0.0351] 36%|███▌      | 71/200 [24:23<42:11, 19.63s/epoch, loss=0.776, accuracy=0.823, val_loss=1.03, val_accuracy=0.74, lr=0.0293]  36%|███▌      | 72/200 [24:42<41:58, 19.68s/epoch, loss=0.735, accuracy=0.831, val_loss=0.929, val_accuracy=0.768, lr=0.024] 36%|███▋      | 73/200 [25:00<40:34, 19.17s/epoch, loss=0.696, accuracy=0.84, val_loss=1.01, val_accuracy=0.741, lr=0.0191]  37%|███▋      | 74/200 [25:20<40:29, 19.28s/epoch, loss=0.642, accuracy=0.853, val_loss=1.09, val_accuracy=0.718, lr=0.0147] 38%|███▊      | 75/200 [25:39<40:20, 19.37s/epoch, loss=0.593, accuracy=0.865, val_loss=0.864, val_accuracy=0.768, lr=0.0109] 38%|███▊      | 76/200 [25:59<39:58, 19.34s/epoch, loss=0.543, accuracy=0.879, val_loss=0.694, val_accuracy=0.834, lr=0.00761] 38%|███▊      | 77/200 [26:19<40:04, 19.55s/epoch, loss=0.491, accuracy=0.891, val_loss=0.692, val_accuracy=0.828, lr=0.00489] 39%|███▉      | 78/200 [26:40<40:38, 19.99s/epoch, loss=0.45, accuracy=0.904, val_loss=0.555, val_accuracy=0.869, lr=0.00276]  40%|███▉      | 79/200 [27:00<40:10, 19.92s/epoch, loss=0.408, accuracy=0.917, val_loss=0.509, val_accuracy=0.883, lr=0.00123] 40%|████      | 80/200 [27:20<39:52, 19.94s/epoch, loss=0.386, accuracy=0.923, val_loss=0.49, val_accuracy=0.885, lr=0.000308] 40%|████      | 81/200 [27:40<39:35, 19.96s/epoch, loss=2.53, accuracy=0.394, val_loss=2.98, val_accuracy=0.162, lr=0.2]       41%|████      | 82/200 [28:00<39:27, 20.07s/epoch, loss=1.52, accuracy=0.58, val_loss=2.79, val_accuracy=0.294, lr=0.2]  42%|████▏     | 83/200 [28:20<39:09, 20.08s/epoch, loss=1.42, accuracy=0.637, val_loss=2.57, val_accuracy=0.276, lr=0.199] 42%|████▏     | 84/200 [28:40<38:47, 20.06s/epoch, loss=1.39, accuracy=0.658, val_loss=17.5, val_accuracy=0.101, lr=0.197] 42%|████▎     | 85/200 [29:02<39:17, 20.50s/epoch, loss=1.37, accuracy=0.67, val_loss=5.76, val_accuracy=0.216, lr=0.195]  43%|████▎     | 86/200 [29:22<38:43, 20.38s/epoch, loss=1.35, accuracy=0.676, val_loss=2.96, val_accuracy=0.24, lr=0.192] 44%|████▎     | 87/200 [29:41<37:46, 20.06s/epoch, loss=1.35, accuracy=0.681, val_loss=2.67, val_accuracy=0.336, lr=0.189] 44%|████▍     | 88/200 [30:01<37:22, 20.03s/epoch, loss=1.33, accuracy=0.683, val_loss=2.06, val_accuracy=0.444, lr=0.185] 44%|████▍     | 89/200 [30:20<36:42, 19.84s/epoch, loss=1.32, accuracy=0.69, val_loss=2.6, val_accuracy=0.282, lr=0.181]   45%|████▌     | 90/200 [30:39<35:44, 19.50s/epoch, loss=1.31, accuracy=0.693, val_loss=3.62, val_accuracy=0.306, lr=0.176] 46%|████▌     | 91/200 [30:59<35:32, 19.56s/epoch, loss=1.29, accuracy=0.697, val_loss=2.8, val_accuracy=0.395, lr=0.171]  46%|████▌     | 92/200 [31:20<35:59, 20.00s/epoch, loss=1.27, accuracy=0.705, val_loss=5.06, val_accuracy=0.181, lr=0.165] 46%|████▋     | 93/200 [31:40<35:34, 19.95s/epoch, loss=1.27, accuracy=0.704, val_loss=2.32, val_accuracy=0.402, lr=0.159] 47%|████▋     | 94/200 [32:01<35:55, 20.34s/epoch, loss=1.25, accuracy=0.709, val_loss=4.11, val_accuracy=0.222, lr=0.152] 48%|████▊     | 95/200 [32:20<34:52, 19.93s/epoch, loss=1.23, accuracy=0.714, val_loss=1.84, val_accuracy=0.516, lr=0.145] 48%|████▊     | 96/200 [32:40<34:34, 19.95s/epoch, loss=1.22, accuracy=0.716, val_loss=4.35, val_accuracy=0.269, lr=0.138] 48%|████▊     | 97/200 [33:00<34:10, 19.90s/epoch, loss=1.2, accuracy=0.722, val_loss=2.52, val_accuracy=0.351, lr=0.131]  49%|████▉     | 98/200 [33:19<33:43, 19.84s/epoch, loss=1.18, accuracy=0.727, val_loss=2.15, val_accuracy=0.48, lr=0.123] 50%|████▉     | 99/200 [33:39<33:09, 19.70s/epoch, loss=1.15, accuracy=0.733, val_loss=1.7, val_accuracy=0.549, lr=0.116] 50%|█████     | 100/200 [33:58<32:53, 19.74s/epoch, loss=1.12, accuracy=0.737, val_loss=2.01, val_accuracy=0.516, lr=0.108] 50%|█████     | 101/200 [34:18<32:37, 19.78s/epoch, loss=1.11, accuracy=0.741, val_loss=1.99, val_accuracy=0.5, lr=0.1]     51%|█████     | 102/200 [34:38<32:22, 19.82s/epoch, loss=1.08, accuracy=0.748, val_loss=1.78, val_accuracy=0.509, lr=0.0922] 52%|█████▏    | 103/200 [34:58<32:07, 19.87s/epoch, loss=1.06, accuracy=0.753, val_loss=4.15, val_accuracy=0.258, lr=0.0844] 52%|█████▏    | 104/200 [35:18<31:46, 19.86s/epoch, loss=1.03, accuracy=0.757, val_loss=2.85, val_accuracy=0.48, lr=0.0767]  52%|█████▎    | 105/200 [35:37<31:05, 19.63s/epoch, loss=0.999, accuracy=0.768, val_loss=3.08, val_accuracy=0.376, lr=0.0691] 53%|█████▎    | 106/200 [35:57<30:50, 19.69s/epoch, loss=0.973, accuracy=0.775, val_loss=2.1, val_accuracy=0.408, lr=0.0617]  54%|█████▎    | 107/200 [36:16<30:19, 19.57s/epoch, loss=0.934, accuracy=0.781, val_loss=1.49, val_accuracy=0.584, lr=0.0546] 54%|█████▍    | 108/200 [36:36<30:07, 19.65s/epoch, loss=0.909, accuracy=0.787, val_loss=1.93, val_accuracy=0.502, lr=0.0478] 55%|█████▍    | 109/200 [36:56<29:57, 19.75s/epoch, loss=0.865, accuracy=0.796, val_loss=1.94, val_accuracy=0.528, lr=0.0412] 55%|█████▌    | 110/200 [37:16<29:39, 19.77s/epoch, loss=0.832, accuracy=0.804, val_loss=1.09, val_accuracy=0.711, lr=0.0351] 56%|█████▌    | 111/200 [37:36<29:25, 19.84s/epoch, loss=0.794, accuracy=0.813, val_loss=1.23, val_accuracy=0.646, lr=0.0293] 56%|█████▌    | 112/200 [37:55<28:46, 19.61s/epoch, loss=0.751, accuracy=0.822, val_loss=1.97, val_accuracy=0.542, lr=0.024]  56%|█████▋    | 113/200 [38:13<27:47, 19.17s/epoch, loss=0.704, accuracy=0.833, val_loss=1.08, val_accuracy=0.688, lr=0.0191] 57%|█████▋    | 114/200 [38:33<27:53, 19.46s/epoch, loss=0.656, accuracy=0.845, val_loss=1.03, val_accuracy=0.721, lr=0.0147] 57%|█████▊    | 115/200 [38:53<27:28, 19.40s/epoch, loss=0.613, accuracy=0.856, val_loss=0.981, val_accuracy=0.737, lr=0.0109] 58%|█████▊    | 116/200 [39:13<27:25, 19.59s/epoch, loss=0.564, accuracy=0.868, val_loss=0.665, val_accuracy=0.833, lr=0.00761] 58%|█████▊    | 117/200 [39:33<27:19, 19.75s/epoch, loss=0.515, accuracy=0.88, val_loss=0.629, val_accuracy=0.841, lr=0.00489]  59%|█████▉    | 118/200 [39:52<26:58, 19.73s/epoch, loss=0.469, accuracy=0.892, val_loss=0.566, val_accuracy=0.86, lr=0.00276] 60%|█████▉    | 119/200 [40:12<26:40, 19.76s/epoch, loss=0.435, accuracy=0.903, val_loss=0.536, val_accuracy=0.867, lr=0.00123] 60%|██████    | 120/200 [40:32<26:14, 19.68s/epoch, loss=0.416, accuracy=0.911, val_loss=0.506, val_accuracy=0.877, lr=0.000308] 60%|██████    | 121/200 [40:52<26:02, 19.78s/epoch, loss=2.65, accuracy=0.401, val_loss=3.49, val_accuracy=0.17, lr=0.2]         61%|██████    | 122/200 [41:11<25:42, 19.78s/epoch, loss=1.52, accuracy=0.578, val_loss=3.74, val_accuracy=0.066, lr=0.2] 62%|██████▏   | 123/200 [41:31<25:18, 19.72s/epoch, loss=1.43, accuracy=0.633, val_loss=2.93, val_accuracy=0.334, lr=0.199] 62%|██████▏   | 124/200 [41:51<25:09, 19.86s/epoch, loss=1.38, accuracy=0.66, val_loss=11.7, val_accuracy=0.112, lr=0.197]  62%|██████▎   | 125/200 [42:11<24:51, 19.89s/epoch, loss=1.37, accuracy=0.667, val_loss=3.32, val_accuracy=0.279, lr=0.195] 63%|██████▎   | 126/200 [42:31<24:37, 19.96s/epoch, loss=1.35, accuracy=0.677, val_loss=2.53, val_accuracy=0.366, lr=0.192] 64%|██████▎   | 127/200 [42:51<24:19, 20.00s/epoch, loss=1.33, accuracy=0.682, val_loss=2.56, val_accuracy=0.314, lr=0.189] 64%|██████▍   | 128/200 [43:11<24:00, 20.01s/epoch, loss=1.32, accuracy=0.687, val_loss=3.54, val_accuracy=0.228, lr=0.185] 64%|██████▍   | 129/200 [43:30<23:08, 19.55s/epoch, loss=1.31, accuracy=0.692, val_loss=2.19, val_accuracy=0.399, lr=0.181] 65%|██████▌   | 130/200 [43:48<22:18, 19.12s/epoch, loss=1.3, accuracy=0.695, val_loss=5.14, val_accuracy=0.232, lr=0.176]  66%|██████▌   | 131/200 [44:07<22:03, 19.18s/epoch, loss=1.28, accuracy=0.7, val_loss=5.44, val_accuracy=0.24, lr=0.171]   66%|██████▌   | 132/200 [44:27<21:47, 19.22s/epoch, loss=1.27, accuracy=0.7, val_loss=2.94, val_accuracy=0.215, lr=0.165] 66%|██████▋   | 133/200 [44:47<21:47, 19.52s/epoch, loss=1.25, accuracy=0.705, val_loss=3.24, val_accuracy=0.308, lr=0.159] 67%|██████▋   | 134/200 [45:07<21:39, 19.69s/epoch, loss=1.24, accuracy=0.71, val_loss=2.53, val_accuracy=0.345, lr=0.152]  68%|██████▊   | 135/200 [45:26<21:02, 19.42s/epoch, loss=1.22, accuracy=0.712, val_loss=3.88, val_accuracy=0.27, lr=0.145] 68%|██████▊   | 136/200 [45:46<20:54, 19.59s/epoch, loss=1.2, accuracy=0.716, val_loss=3.19, val_accuracy=0.282, lr=0.138] 68%|██████▊   | 137/200 [46:06<20:42, 19.73s/epoch, loss=1.19, accuracy=0.721, val_loss=7.94, val_accuracy=0.202, lr=0.131] 69%|██████▉   | 138/200 [46:25<20:11, 19.54s/epoch, loss=1.17, accuracy=0.729, val_loss=2.5, val_accuracy=0.347, lr=0.123]  70%|██████▉   | 139/200 [46:43<19:22, 19.06s/epoch, loss=1.15, accuracy=0.729, val_loss=2.87, val_accuracy=0.392, lr=0.116] 70%|███████   | 140/200 [47:03<19:25, 19.42s/epoch, loss=1.13, accuracy=0.737, val_loss=2.5, val_accuracy=0.307, lr=0.108]  70%|███████   | 141/200 [47:23<19:16, 19.61s/epoch, loss=1.09, accuracy=0.741, val_loss=3.87, val_accuracy=0.335, lr=0.1]  71%|███████   | 142/200 [47:42<18:44, 19.38s/epoch, loss=1.07, accuracy=0.748, val_loss=4.35, val_accuracy=0.252, lr=0.0922] 72%|███████▏  | 143/200 [48:02<18:27, 19.43s/epoch, loss=1.05, accuracy=0.75, val_loss=1.9, val_accuracy=0.527, lr=0.0844]   72%|███████▏  | 144/200 [48:22<18:17, 19.59s/epoch, loss=1.02, accuracy=0.763, val_loss=2.93, val_accuracy=0.364, lr=0.0767] 72%|███████▎  | 145/200 [48:41<17:52, 19.50s/epoch, loss=0.993, accuracy=0.767, val_loss=1.93, val_accuracy=0.53, lr=0.0691] 73%|███████▎  | 146/200 [49:01<17:40, 19.64s/epoch, loss=0.96, accuracy=0.771, val_loss=2.27, val_accuracy=0.4, lr=0.0617]   74%|███████▎  | 147/200 [49:21<17:24, 19.70s/epoch, loss=0.93, accuracy=0.779, val_loss=2.68, val_accuracy=0.396, lr=0.0546] 74%|███████▍  | 148/200 [49:41<17:07, 19.77s/epoch, loss=0.891, accuracy=0.788, val_loss=2.11, val_accuracy=0.498, lr=0.0478] 74%|███████▍  | 149/200 [50:00<16:50, 19.81s/epoch, loss=0.86, accuracy=0.795, val_loss=1.5, val_accuracy=0.599, lr=0.0412]   75%|███████▌  | 150/200 [50:20<16:21, 19.63s/epoch, loss=0.822, accuracy=0.803, val_loss=1.44, val_accuracy=0.608, lr=0.0351] 76%|███████▌  | 151/200 [50:38<15:47, 19.34s/epoch, loss=0.781, accuracy=0.812, val_loss=2.41, val_accuracy=0.438, lr=0.0293] 76%|███████▌  | 152/200 [50:58<15:37, 19.53s/epoch, loss=0.744, accuracy=0.823, val_loss=1.62, val_accuracy=0.583, lr=0.024]  76%|███████▋  | 153/200 [51:18<15:26, 19.72s/epoch, loss=0.708, accuracy=0.827, val_loss=0.93, val_accuracy=0.761, lr=0.0191] 77%|███████▋  | 154/200 [51:38<15:03, 19.65s/epoch, loss=0.657, accuracy=0.842, val_loss=1.03, val_accuracy=0.721, lr=0.0147] 78%|███████▊  | 155/200 [51:58<14:43, 19.64s/epoch, loss=0.616, accuracy=0.851, val_loss=0.749, val_accuracy=0.804, lr=0.0109] 78%|███████▊  | 156/200 [52:17<14:19, 19.54s/epoch, loss=0.562, accuracy=0.865, val_loss=0.84, val_accuracy=0.779, lr=0.00761] 78%|███████▊  | 157/200 [52:37<14:04, 19.63s/epoch, loss=0.518, accuracy=0.877, val_loss=0.741, val_accuracy=0.805, lr=0.00489] 79%|███████▉  | 158/200 [52:57<13:49, 19.74s/epoch, loss=0.48, accuracy=0.888, val_loss=0.632, val_accuracy=0.834, lr=0.00276]  80%|███████▉  | 159/200 [53:15<13:05, 19.17s/epoch, loss=0.445, accuracy=0.899, val_loss=0.535, val_accuracy=0.868, lr=0.00123] 80%|████████  | 160/200 [53:33<12:40, 19.02s/epoch, loss=0.423, accuracy=0.905, val_loss=0.515, val_accuracy=0.874, lr=0.000308] 80%|████████  | 161/200 [53:53<12:32, 19.29s/epoch, loss=2.97, accuracy=0.361, val_loss=3.33, val_accuracy=0.139, lr=0.2]        81%|████████  | 162/200 [54:11<11:57, 18.88s/epoch, loss=1.58, accuracy=0.543, val_loss=3.85, val_accuracy=0.199, lr=0.2] 82%|████████▏ | 163/200 [54:31<11:50, 19.21s/epoch, loss=1.47, accuracy=0.604, val_loss=4.74, val_accuracy=0.17, lr=0.199] 82%|████████▏ | 164/200 [54:53<11:57, 19.92s/epoch, loss=1.42, accuracy=0.639, val_loss=3.08, val_accuracy=0.29, lr=0.197] 82%|████████▎ | 165/200 [55:13<11:37, 19.94s/epoch, loss=1.38, accuracy=0.654, val_loss=3.48, val_accuracy=0.257, lr=0.195] 83%|████████▎ | 166/200 [55:33<11:27, 20.22s/epoch, loss=1.37, accuracy=0.663, val_loss=2.65, val_accuracy=0.36, lr=0.192]  84%|████████▎ | 167/200 [55:53<11:05, 20.15s/epoch, loss=1.36, accuracy=0.67, val_loss=2.85, val_accuracy=0.295, lr=0.189] 84%|████████▍ | 168/200 [56:14<10:44, 20.13s/epoch, loss=1.35, accuracy=0.68, val_loss=3.68, val_accuracy=0.235, lr=0.185] 84%|████████▍ | 169/200 [56:31<10:03, 19.47s/epoch, loss=1.33, accuracy=0.68, val_loss=2.97, val_accuracy=0.29, lr=0.181]  85%|████████▌ | 170/200 [56:51<09:43, 19.44s/epoch, loss=1.32, accuracy=0.684, val_loss=2.82, val_accuracy=0.38, lr=0.176] 86%|████████▌ | 171/200 [57:10<09:22, 19.39s/epoch, loss=1.29, accuracy=0.69, val_loss=3.91, val_accuracy=0.191, lr=0.171] 86%|████████▌ | 172/200 [57:30<09:08, 19.57s/epoch, loss=1.29, accuracy=0.694, val_loss=60.6, val_accuracy=0.1, lr=0.165]  86%|████████▋ | 173/200 [57:51<08:59, 19.98s/epoch, loss=1.28, accuracy=0.697, val_loss=4.15, val_accuracy=0.189, lr=0.159] 87%|████████▋ | 174/200 [58:10<08:30, 19.65s/epoch, loss=1.26, accuracy=0.701, val_loss=1.75, val_accuracy=0.519, lr=0.152] 88%|████████▊ | 175/200 [58:29<08:10, 19.61s/epoch, loss=1.24, accuracy=0.707, val_loss=1.89, val_accuracy=0.528, lr=0.145] 88%|████████▊ | 176/200 [58:47<07:37, 19.05s/epoch, loss=1.22, accuracy=0.709, val_loss=2.19, val_accuracy=0.428, lr=0.138] 88%|████████▊ | 177/200 [59:07<07:26, 19.40s/epoch, loss=1.21, accuracy=0.712, val_loss=2.78, val_accuracy=0.244, lr=0.131] 89%|████████▉ | 178/200 [59:27<07:08, 19.49s/epoch, loss=1.19, accuracy=0.716, val_loss=3.38, val_accuracy=0.244, lr=0.123] 90%|████████▉ | 179/200 [59:45<06:38, 18.98s/epoch, loss=1.16, accuracy=0.724, val_loss=3.17, val_accuracy=0.296, lr=0.116] 90%|█████████ | 180/200 [1:00:05<06:25, 19.26s/epoch, loss=1.13, accuracy=0.732, val_loss=3.16, val_accuracy=0.285, lr=0.108] 90%|█████████ | 181/200 [1:00:23<06:00, 18.96s/epoch, loss=1.12, accuracy=0.737, val_loss=4.19, val_accuracy=0.277, lr=0.1]   91%|█████████ | 182/200 [1:00:41<05:34, 18.57s/epoch, loss=1.09, accuracy=0.743, val_loss=3.91, val_accuracy=0.234, lr=0.0922] 92%|█████████▏| 183/200 [1:00:58<05:11, 18.32s/epoch, loss=1.07, accuracy=0.748, val_loss=1.99, val_accuracy=0.454, lr=0.0844] 92%|█████████▏| 184/200 [1:01:16<04:51, 18.23s/epoch, loss=1.04, accuracy=0.753, val_loss=3.75, val_accuracy=0.214, lr=0.0767] 92%|█████████▎| 185/200 [1:01:34<04:31, 18.11s/epoch, loss=1, accuracy=0.762, val_loss=1.87, val_accuracy=0.462, lr=0.0691]    93%|█████████▎| 186/200 [1:01:53<04:17, 18.40s/epoch, loss=0.983, accuracy=0.768, val_loss=1.9, val_accuracy=0.49, lr=0.0617] 94%|█████████▎| 187/200 [1:02:14<04:08, 19.08s/epoch, loss=0.944, accuracy=0.774, val_loss=1.27, val_accuracy=0.666, lr=0.0546] 94%|█████████▍| 188/200 [1:02:32<03:44, 18.74s/epoch, loss=0.906, accuracy=0.783, val_loss=1.96, val_accuracy=0.475, lr=0.0478] 94%|█████████▍| 189/200 [1:02:51<03:27, 18.83s/epoch, loss=0.871, accuracy=0.792, val_loss=1.56, val_accuracy=0.591, lr=0.0412] 95%|█████████▌| 190/200 [1:03:09<03:05, 18.52s/epoch, loss=0.84, accuracy=0.797, val_loss=1.98, val_accuracy=0.48, lr=0.0351]   96%|█████████▌| 191/200 [1:03:27<02:44, 18.31s/epoch, loss=0.796, accuracy=0.806, val_loss=1.4, val_accuracy=0.622, lr=0.0293] 96%|█████████▌| 192/200 [1:03:47<02:30, 18.81s/epoch, loss=0.758, accuracy=0.815, val_loss=0.98, val_accuracy=0.733, lr=0.024] 96%|█████████▋| 193/200 [1:04:05<02:11, 18.79s/epoch, loss=0.712, accuracy=0.826, val_loss=1.19, val_accuracy=0.675, lr=0.0191] 97%|█████████▋| 194/200 [1:04:23<01:50, 18.49s/epoch, loss=0.667, accuracy=0.836, val_loss=1.25, val_accuracy=0.687, lr=0.0147] 98%|█████████▊| 195/200 [1:04:41<01:31, 18.32s/epoch, loss=0.625, accuracy=0.849, val_loss=0.963, val_accuracy=0.744, lr=0.0109] 98%|█████████▊| 196/200 [1:05:01<01:14, 18.71s/epoch, loss=0.575, accuracy=0.858, val_loss=0.755, val_accuracy=0.8, lr=0.00761]  98%|█████████▊| 197/200 [1:05:19<00:55, 18.47s/epoch, loss=0.53, accuracy=0.873, val_loss=0.764, val_accuracy=0.791, lr=0.00489] 99%|█████████▉| 198/200 [1:05:37<00:37, 18.53s/epoch, loss=0.486, accuracy=0.884, val_loss=0.608, val_accuracy=0.847, lr=0.00276]100%|█████████▉| 199/200 [1:05:55<00:18, 18.37s/epoch, loss=0.454, accuracy=0.894, val_loss=0.547, val_accuracy=0.863, lr=0.00123]100%|██████████| 200/200 [1:06:15<00:00, 18.76s/epoch, loss=0.436, accuracy=0.899, val_loss=0.513, val_accuracy=0.874, lr=0.000308]100%|██████████| 200/200 [1:06:15<00:00, 19.88s/epoch, loss=0.436, accuracy=0.899, val_loss=0.513, val_accuracy=0.874, lr=0.000308]
Using real-time data augmentation.
Epoch 0, LR: 0.2
Epoch 1, LR: 0.1996917333733128
Epoch 2, LR: 0.1987688340595138
Epoch 3, LR: 0.19723699203976766
Epoch 4, LR: 0.19510565162951538
Epoch 5, LR: 0.19238795325112867
Epoch 6, LR: 0.18910065241883678
Epoch 7, LR: 0.18526401643540924
Epoch 8, LR: 0.18090169943749476
Epoch 9, LR: 0.17604059656000312
Epoch 10, LR: 0.17071067811865476
Epoch 11, LR: 0.1649448048330184
Epoch 12, LR: 0.15877852522924732
Epoch 13, LR: 0.1522498564715949
Epoch 14, LR: 0.14539904997395467
Epoch 15, LR: 0.138268343236509
Epoch 16, LR: 0.13090169943749475
Epoch 17, LR: 0.12334453638559056
Epoch 18, LR: 0.1156434465040231
Epoch 19, LR: 0.1078459095727845
Epoch 20, LR: 0.1
Epoch 21, LR: 0.09215409042721552
Epoch 22, LR: 0.08435655349597694
Epoch 23, LR: 0.07665546361440947
Epoch 24, LR: 0.06909830056250527
Epoch 25, LR: 0.06173165676349103
Epoch 26, LR: 0.05460095002604533
Epoch 27, LR: 0.04775014352840512
Epoch 28, LR: 0.0412214747707527
Epoch 29, LR: 0.03505519516698165
Epoch 30, LR: 0.029289321881345254
Epoch 31, LR: 0.023959403439996908
Epoch 32, LR: 0.019098300562505267
Epoch 33, LR: 0.014735983564590783
Epoch 34, LR: 0.010899347581163222
Epoch 35, LR: 0.007612046748871327
Epoch 36, LR: 0.004894348370484647
Epoch 37, LR: 0.0027630079602323446
Epoch 38, LR: 0.0012311659404862342
Epoch 39, LR: 0.0003082666266872036
Epoch 40, LR: 0.2
Epoch 41, LR: 0.1996917333733128
Epoch 42, LR: 0.1987688340595138
Epoch 43, LR: 0.19723699203976766
Epoch 44, LR: 0.19510565162951538
Epoch 45, LR: 0.19238795325112867
Epoch 46, LR: 0.18910065241883678
Epoch 47, LR: 0.18526401643540924
Epoch 48, LR: 0.18090169943749476
Epoch 49, LR: 0.17604059656000312
Epoch 50, LR: 0.17071067811865476
Epoch 51, LR: 0.1649448048330184
Epoch 52, LR: 0.15877852522924732
Epoch 53, LR: 0.1522498564715949
Epoch 54, LR: 0.14539904997395467
Epoch 55, LR: 0.138268343236509
Epoch 56, LR: 0.13090169943749475
Epoch 57, LR: 0.12334453638559056
Epoch 58, LR: 0.1156434465040231
Epoch 59, LR: 0.1078459095727845
Epoch 60, LR: 0.1
Epoch 61, LR: 0.09215409042721552
Epoch 62, LR: 0.08435655349597694
Epoch 63, LR: 0.07665546361440947
Epoch 64, LR: 0.06909830056250527
Epoch 65, LR: 0.06173165676349103
Epoch 66, LR: 0.05460095002604533
Epoch 67, LR: 0.04775014352840512
Epoch 68, LR: 0.0412214747707527
Epoch 69, LR: 0.03505519516698165
Epoch 70, LR: 0.029289321881345254
Epoch 71, LR: 0.023959403439996908
Epoch 72, LR: 0.019098300562505267
Epoch 73, LR: 0.014735983564590783
Epoch 74, LR: 0.010899347581163222
Epoch 75, LR: 0.007612046748871327
Epoch 76, LR: 0.004894348370484647
Epoch 77, LR: 0.0027630079602323446
Epoch 78, LR: 0.0012311659404862342
Epoch 79, LR: 0.0003082666266872036
Epoch 80, LR: 0.2
Epoch 81, LR: 0.1996917333733128
Epoch 82, LR: 0.1987688340595138
Epoch 83, LR: 0.19723699203976766
Epoch 84, LR: 0.19510565162951538
Epoch 85, LR: 0.19238795325112867
Epoch 86, LR: 0.18910065241883678
Epoch 87, LR: 0.18526401643540924
Epoch 88, LR: 0.18090169943749476
Epoch 89, LR: 0.17604059656000312
Epoch 90, LR: 0.17071067811865476
Epoch 91, LR: 0.1649448048330184
Epoch 92, LR: 0.15877852522924732
Epoch 93, LR: 0.1522498564715949
Epoch 94, LR: 0.14539904997395467
Epoch 95, LR: 0.138268343236509
Epoch 96, LR: 0.13090169943749475
Epoch 97, LR: 0.12334453638559056
Epoch 98, LR: 0.1156434465040231
Epoch 99, LR: 0.1078459095727845
Epoch 100, LR: 0.1
Epoch 101, LR: 0.09215409042721552
Epoch 102, LR: 0.08435655349597694
Epoch 103, LR: 0.07665546361440947
Epoch 104, LR: 0.06909830056250527
Epoch 105, LR: 0.06173165676349103
Epoch 106, LR: 0.05460095002604533
Epoch 107, LR: 0.04775014352840512
Epoch 108, LR: 0.0412214747707527
Epoch 109, LR: 0.03505519516698165
Epoch 110, LR: 0.029289321881345254
Epoch 111, LR: 0.023959403439996908
Epoch 112, LR: 0.019098300562505267
Epoch 113, LR: 0.014735983564590783
Epoch 114, LR: 0.010899347581163222
Epoch 115, LR: 0.007612046748871327
Epoch 116, LR: 0.004894348370484647
Epoch 117, LR: 0.0027630079602323446
Epoch 118, LR: 0.0012311659404862342
Epoch 119, LR: 0.0003082666266872036
Epoch 120, LR: 0.2
Epoch 121, LR: 0.1996917333733128
Epoch 122, LR: 0.1987688340595138
Epoch 123, LR: 0.19723699203976766
Epoch 124, LR: 0.19510565162951538
Epoch 125, LR: 0.19238795325112867
Epoch 126, LR: 0.18910065241883678
Epoch 127, LR: 0.18526401643540924
Epoch 128, LR: 0.18090169943749476
Epoch 129, LR: 0.17604059656000312
Epoch 130, LR: 0.17071067811865476
Epoch 131, LR: 0.1649448048330184
Epoch 132, LR: 0.15877852522924732
Epoch 133, LR: 0.1522498564715949
Epoch 134, LR: 0.14539904997395467
Epoch 135, LR: 0.138268343236509
Epoch 136, LR: 0.13090169943749475
Epoch 137, LR: 0.12334453638559056
Epoch 138, LR: 0.1156434465040231
Epoch 139, LR: 0.1078459095727845
Epoch 140, LR: 0.1
Epoch 141, LR: 0.09215409042721552
Epoch 142, LR: 0.08435655349597694
Epoch 143, LR: 0.07665546361440947
Epoch 144, LR: 0.06909830056250527
Epoch 145, LR: 0.06173165676349103
Epoch 146, LR: 0.05460095002604533
Epoch 147, LR: 0.04775014352840512
Epoch 148, LR: 0.0412214747707527
Epoch 149, LR: 0.03505519516698165
Epoch 150, LR: 0.029289321881345254
Epoch 151, LR: 0.023959403439996908
Epoch 152, LR: 0.019098300562505267
Epoch 153, LR: 0.014735983564590783
Epoch 154, LR: 0.010899347581163222
Epoch 155, LR: 0.007612046748871327
Epoch 156, LR: 0.004894348370484647
Epoch 157, LR: 0.0027630079602323446
Epoch 158, LR: 0.0012311659404862342
Epoch 159, LR: 0.0003082666266872036
Epoch 160, LR: 0.2
Epoch 161, LR: 0.1996917333733128
Epoch 162, LR: 0.1987688340595138
Epoch 163, LR: 0.19723699203976766
Epoch 164, LR: 0.19510565162951538
Epoch 165, LR: 0.19238795325112867
Epoch 166, LR: 0.18910065241883678
Epoch 167, LR: 0.18526401643540924
Epoch 168, LR: 0.18090169943749476
Epoch 169, LR: 0.17604059656000312
Epoch 170, LR: 0.17071067811865476
Epoch 171, LR: 0.1649448048330184
Epoch 172, LR: 0.15877852522924732
Epoch 173, LR: 0.1522498564715949
Epoch 174, LR: 0.14539904997395467
Epoch 175, LR: 0.138268343236509
Epoch 176, LR: 0.13090169943749475
Epoch 177, LR: 0.12334453638559056
Epoch 178, LR: 0.1156434465040231
Epoch 179, LR: 0.1078459095727845
Epoch 180, LR: 0.1
Epoch 181, LR: 0.09215409042721552
Epoch 182, LR: 0.08435655349597694
Epoch 183, LR: 0.07665546361440947
Epoch 184, LR: 0.06909830056250527
Epoch 185, LR: 0.06173165676349103
Epoch 186, LR: 0.05460095002604533
Epoch 187, LR: 0.04775014352840512
Epoch 188, LR: 0.0412214747707527
Epoch 189, LR: 0.03505519516698165
Epoch 190, LR: 0.029289321881345254
Epoch 191, LR: 0.023959403439996908
Epoch 192, LR: 0.019098300562505267
Epoch 193, LR: 0.014735983564590783
Epoch 194, LR: 0.010899347581163222
Epoch 195, LR: 0.007612046748871327
Epoch 196, LR: 0.004894348370484647
Epoch 197, LR: 0.0027630079602323446
Epoch 198, LR: 0.0012311659404862342
Epoch 199, LR: 0.0003082666266872036

Loading model: 11_cifar10_ResNet20v1_127.h5
Test score: 2.5741381645202637
Test accuracy: 0.3109999895095825
Val score: 2.5588083267211914
Val accuracy: 0.31380000710487366

Loading model: 11_cifar10_ResNet20v1_163.h5
Test score: 4.790241241455078
Test accuracy: 0.15960000455379486
Val score: 4.739808559417725
Val accuracy: 0.17020000517368317

Loading model: 11_cifar10_ResNet20v1_20.h5
Test score: 1.9007158279418945
Test accuracy: 0.5317999720573425
Val score: 1.8947521448135376
Val accuracy: 0.5400000214576721

Loading model: 11_cifar10_ResNet20v1_59.h5
Test score: 2.8452069759368896
Test accuracy: 0.41269999742507935
Val score: 2.835784435272217
Val accuracy: 0.4172999858856201

Loading model: 11_cifar10_ResNet20v1_99.h5
Test score: 1.7065445184707642
Test accuracy: 0.5507000088691711
Val score: 1.7016369104385376
Val accuracy: 0.5494999885559082
