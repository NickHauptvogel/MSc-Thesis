Mon Feb 19 22:25:42 2024       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 545.23.08              Driver Version: 545.23.08    CUDA Version: 12.3     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA TITAN Xp                Off | 00000000:02:00.0 Off |                  N/A |
| 47%   69C    P0              87W / 250W |      0MiB / 12288MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|  No running processes found                                                           |
+---------------------------------------------------------------------------------------+


* * * Run SGD for cluster size = 17. * * *


Budget: 88


* * * Run SGD for ID = 17_1. * * *


2024-02-19 22:25:43.015108: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-19 22:25:46.492739: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-19 22:25:46.493641: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-19 22:25:46.531811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-19 22:25:46.531842: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-19 22:25:46.535639: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-19 22:25:46.535679: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-19 22:25:46.538292: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-19 22:25:46.539198: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-19 22:25:46.541633: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-19 22:25:46.543191: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-19 22:25:46.550166: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-19 22:25:46.550838: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-19 22:25:46.550939: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-19 22:25:48.050392: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-19 22:25:48.051990: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-19 22:25:48.052762: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-19 22:25:48.052796: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-19 22:25:48.052831: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-19 22:25:48.052849: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-19 22:25:48.052867: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-19 22:25:48.052883: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-19 22:25:48.052899: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-19 22:25:48.052915: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-19 22:25:48.052931: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-19 22:25:48.053394: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-19 22:25:48.053431: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-19 22:25:48.679215: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-19 22:25:48.679279: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-19 22:25:48.679291: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-19 22:25:48.680203: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:02:00.0, compute capability: 6.1)
{'id': '17_01', 'batch_size': 128, 'epochs': 88, 'validation_split': 0.1, 'checkpointing': True, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
x_train shape: (45000, 32, 32, 3)
45000 train samples
5000 validation samples
10000 test samples
y_train shape: (45000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/88 [00:00<?, ?epoch/s]2024-02-19 22:25:49.493071: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-19 22:25:49.505169: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199825000 Hz
2024-02-19 22:25:51.503541: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-19 22:25:51.745314: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-19 22:25:52.578413: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-19 22:25:52.633432: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/88 [00:57<1:22:43, 57.05s/epoch, loss=3.52, accuracy=0.261, val_loss=3.53, val_accuracy=0.125, lr=0.1]  2%|▏         | 2/88 [01:18<51:26, 35.89s/epoch, loss=1.72, accuracy=0.457, val_loss=2.52, val_accuracy=0.295, lr=0.1]    3%|▎         | 3/88 [01:39<41:28, 29.28s/epoch, loss=1.49, accuracy=0.561, val_loss=1.94, val_accuracy=0.482, lr=0.1]  5%|▍         | 4/88 [02:00<36:23, 26.00s/epoch, loss=1.36, accuracy=0.64, val_loss=2.35, val_accuracy=0.422, lr=0.1]   6%|▌         | 5/88 [02:21<33:37, 24.31s/epoch, loss=1.3, accuracy=0.674, val_loss=2.09, val_accuracy=0.431, lr=0.1]  7%|▋         | 6/88 [02:43<32:03, 23.46s/epoch, loss=1.27, accuracy=0.694, val_loss=1.84, val_accuracy=0.554, lr=0.1]  8%|▊         | 7/88 [03:04<30:33, 22.63s/epoch, loss=1.26, accuracy=0.704, val_loss=1.75, val_accuracy=0.542, lr=0.1]  9%|▉         | 8/88 [03:26<29:48, 22.36s/epoch, loss=1.24, accuracy=0.711, val_loss=1.59, val_accuracy=0.61, lr=0.1]  10%|█         | 9/88 [03:46<28:38, 21.76s/epoch, loss=1.23, accuracy=0.718, val_loss=2.09, val_accuracy=0.461, lr=0.1] 11%|█▏        | 10/88 [04:07<28:04, 21.60s/epoch, loss=1.23, accuracy=0.721, val_loss=1.9, val_accuracy=0.559, lr=0.1] 12%|█▎        | 11/88 [04:31<28:22, 22.12s/epoch, loss=1.22, accuracy=0.723, val_loss=1.46, val_accuracy=0.639, lr=0.1] 14%|█▎        | 12/88 [04:51<27:21, 21.60s/epoch, loss=1.22, accuracy=0.725, val_loss=2.66, val_accuracy=0.448, lr=0.1] 15%|█▍        | 13/88 [05:12<26:43, 21.38s/epoch, loss=1.21, accuracy=0.728, val_loss=3.46, val_accuracy=0.352, lr=0.1] 16%|█▌        | 14/88 [05:32<25:46, 20.90s/epoch, loss=1.21, accuracy=0.731, val_loss=1.84, val_accuracy=0.515, lr=0.1] 17%|█▋        | 15/88 [05:52<25:05, 20.62s/epoch, loss=1.21, accuracy=0.734, val_loss=1.9, val_accuracy=0.558, lr=0.1]  18%|█▊        | 16/88 [06:12<24:27, 20.38s/epoch, loss=1.21, accuracy=0.732, val_loss=1.78, val_accuracy=0.57, lr=0.0316] 19%|█▉        | 17/88 [06:32<23:56, 20.24s/epoch, loss=1.2, accuracy=0.732, val_loss=1.8, val_accuracy=0.544, lr=0.1]     20%|██        | 18/88 [06:53<23:52, 20.46s/epoch, loss=1.2, accuracy=0.738, val_loss=2.41, val_accuracy=0.451, lr=0.1] 22%|██▏       | 19/88 [07:13<23:32, 20.48s/epoch, loss=1.2, accuracy=0.735, val_loss=1.96, val_accuracy=0.481, lr=0.1] 23%|██▎       | 20/88 [07:34<23:29, 20.72s/epoch, loss=1.19, accuracy=0.738, val_loss=1.76, val_accuracy=0.521, lr=0.1] 24%|██▍       | 21/88 [07:56<23:17, 20.86s/epoch, loss=1.19, accuracy=0.739, val_loss=1.86, val_accuracy=0.535, lr=0.0316] 25%|██▌       | 22/88 [08:16<22:58, 20.88s/epoch, loss=1.19, accuracy=0.739, val_loss=2.65, val_accuracy=0.389, lr=0.1]    26%|██▌       | 23/88 [08:37<22:39, 20.91s/epoch, loss=1.19, accuracy=0.742, val_loss=4.07, val_accuracy=0.293, lr=0.1] 27%|██▋       | 24/88 [08:59<22:30, 21.10s/epoch, loss=1.18, accuracy=0.742, val_loss=2.34, val_accuracy=0.409, lr=0.1] 28%|██▊       | 25/88 [09:19<21:53, 20.84s/epoch, loss=1.2, accuracy=0.741, val_loss=1.44, val_accuracy=0.654, lr=0.1]  30%|██▉       | 26/88 [09:40<21:32, 20.85s/epoch, loss=1.18, accuracy=0.744, val_loss=1.53, val_accuracy=0.63, lr=0.1] 31%|███       | 27/88 [10:01<21:21, 21.01s/epoch, loss=1.19, accuracy=0.742, val_loss=1.95, val_accuracy=0.475, lr=0.1] 32%|███▏      | 28/88 [10:22<20:42, 20.71s/epoch, loss=1.18, accuracy=0.744, val_loss=2.3, val_accuracy=0.47, lr=0.1]   33%|███▎      | 29/88 [10:43<20:38, 20.98s/epoch, loss=1.18, accuracy=0.744, val_loss=3.22, val_accuracy=0.336, lr=0.1] 34%|███▍      | 30/88 [11:04<20:14, 20.93s/epoch, loss=1.18, accuracy=0.744, val_loss=2.58, val_accuracy=0.405, lr=0.0316] 35%|███▌      | 31/88 [11:24<19:33, 20.58s/epoch, loss=1.18, accuracy=0.745, val_loss=1.74, val_accuracy=0.567, lr=0.1]    36%|███▋      | 32/88 [11:45<19:17, 20.68s/epoch, loss=1.17, accuracy=0.744, val_loss=1.99, val_accuracy=0.493, lr=0.1] 38%|███▊      | 33/88 [12:06<19:02, 20.78s/epoch, loss=1.17, accuracy=0.749, val_loss=4.3, val_accuracy=0.243, lr=0.1]  39%|███▊      | 34/88 [12:27<18:48, 20.89s/epoch, loss=1.17, accuracy=0.746, val_loss=2.01, val_accuracy=0.481, lr=0.1] 40%|███▉      | 35/88 [12:48<18:27, 20.90s/epoch, loss=1.17, accuracy=0.748, val_loss=2.71, val_accuracy=0.436, lr=0.0316] 41%|████      | 36/88 [13:09<18:11, 21.00s/epoch, loss=1.16, accuracy=0.748, val_loss=1.9, val_accuracy=0.54, lr=0.1]      42%|████▏     | 37/88 [13:30<17:53, 21.05s/epoch, loss=1.16, accuracy=0.744, val_loss=1.64, val_accuracy=0.588, lr=0.1] 43%|████▎     | 38/88 [13:51<17:31, 21.04s/epoch, loss=1.16, accuracy=0.748, val_loss=1.45, val_accuracy=0.647, lr=0.1] 44%|████▍     | 39/88 [14:12<17:10, 21.03s/epoch, loss=1.18, accuracy=0.745, val_loss=2.46, val_accuracy=0.336, lr=0.1] 45%|████▌     | 40/88 [14:33<16:48, 21.02s/epoch, loss=1.16, accuracy=0.747, val_loss=2.12, val_accuracy=0.491, lr=0.0316] 47%|████▋     | 41/88 [14:54<16:24, 20.95s/epoch, loss=1.15, accuracy=0.749, val_loss=2.71, val_accuracy=0.275, lr=0.1]    48%|████▊     | 42/88 [15:15<16:07, 21.03s/epoch, loss=1.17, accuracy=0.749, val_loss=1.84, val_accuracy=0.506, lr=0.1] 49%|████▉     | 43/88 [15:36<15:48, 21.07s/epoch, loss=1.16, accuracy=0.749, val_loss=2.23, val_accuracy=0.521, lr=0.1] 50%|█████     | 44/88 [15:57<15:27, 21.07s/epoch, loss=1.16, accuracy=0.749, val_loss=2.41, val_accuracy=0.346, lr=0.1] 51%|█████     | 45/88 [16:18<14:59, 20.92s/epoch, loss=1.16, accuracy=0.75, val_loss=1.82, val_accuracy=0.541, lr=0.0316] 52%|█████▏    | 46/88 [16:39<14:42, 21.00s/epoch, loss=1.16, accuracy=0.752, val_loss=1.88, val_accuracy=0.516, lr=0.1]   53%|█████▎    | 47/88 [17:00<14:20, 21.00s/epoch, loss=1.16, accuracy=0.753, val_loss=2.51, val_accuracy=0.458, lr=0.1] 55%|█████▍    | 48/88 [17:21<13:56, 20.92s/epoch, loss=1.16, accuracy=0.752, val_loss=1.72, val_accuracy=0.569, lr=0.1] 56%|█████▌    | 49/88 [17:41<13:22, 20.57s/epoch, loss=1.15, accuracy=0.753, val_loss=1.45, val_accuracy=0.641, lr=0.1] 57%|█████▋    | 50/88 [18:02<13:07, 20.73s/epoch, loss=1.16, accuracy=0.75, val_loss=1.45, val_accuracy=0.632, lr=0.0316] 58%|█████▊    | 51/88 [18:22<12:39, 20.52s/epoch, loss=1.16, accuracy=0.751, val_loss=2.03, val_accuracy=0.48, lr=0.1]    59%|█████▉    | 52/88 [18:41<12:10, 20.28s/epoch, loss=1.15, accuracy=0.751, val_loss=2.04, val_accuracy=0.523, lr=0.1] 60%|██████    | 53/88 [19:01<11:43, 20.11s/epoch, loss=1.15, accuracy=0.752, val_loss=2.19, val_accuracy=0.488, lr=0.1] 61%|██████▏   | 54/88 [19:22<11:30, 20.31s/epoch, loss=1.16, accuracy=0.75, val_loss=1.69, val_accuracy=0.59, lr=0.1]   62%|██████▎   | 55/88 [19:43<11:19, 20.59s/epoch, loss=1.15, accuracy=0.753, val_loss=1.67, val_accuracy=0.577, lr=0.0316] 64%|██████▎   | 56/88 [20:04<11:02, 20.69s/epoch, loss=1.15, accuracy=0.751, val_loss=2.62, val_accuracy=0.358, lr=0.1]    65%|██████▍   | 57/88 [20:24<10:31, 20.38s/epoch, loss=1.15, accuracy=0.754, val_loss=2.63, val_accuracy=0.303, lr=0.1] 66%|██████▌   | 58/88 [20:45<10:16, 20.54s/epoch, loss=1.14, accuracy=0.754, val_loss=2.69, val_accuracy=0.365, lr=0.1] 67%|██████▋   | 59/88 [21:06<09:58, 20.65s/epoch, loss=1.14, accuracy=0.752, val_loss=2.26, val_accuracy=0.474, lr=0.1] 68%|██████▊   | 60/88 [21:26<09:35, 20.55s/epoch, loss=1.14, accuracy=0.753, val_loss=1.66, val_accuracy=0.571, lr=0.0316] 69%|██████▉   | 61/88 [21:46<09:07, 20.29s/epoch, loss=1.15, accuracy=0.749, val_loss=1.86, val_accuracy=0.515, lr=0.1]    70%|███████   | 62/88 [22:06<08:49, 20.36s/epoch, loss=1.14, accuracy=0.755, val_loss=2.88, val_accuracy=0.431, lr=0.1] 72%|███████▏  | 63/88 [22:27<08:32, 20.51s/epoch, loss=1.15, accuracy=0.751, val_loss=3.08, val_accuracy=0.424, lr=0.1] 73%|███████▎  | 64/88 [22:47<08:06, 20.28s/epoch, loss=1.15, accuracy=0.751, val_loss=2.14, val_accuracy=0.443, lr=0.1] 74%|███████▍  | 65/88 [23:08<07:51, 20.51s/epoch, loss=1.14, accuracy=0.754, val_loss=2.04, val_accuracy=0.485, lr=0.0316] 75%|███████▌  | 66/88 [23:29<07:35, 20.71s/epoch, loss=1.14, accuracy=0.755, val_loss=1.94, val_accuracy=0.518, lr=0.1]    76%|███████▌  | 67/88 [23:50<07:14, 20.68s/epoch, loss=1.15, accuracy=0.753, val_loss=1.83, val_accuracy=0.517, lr=0.1] 77%|███████▋  | 68/88 [24:09<06:47, 20.38s/epoch, loss=1.14, accuracy=0.754, val_loss=1.87, val_accuracy=0.545, lr=0.1] 78%|███████▊  | 69/88 [24:30<06:31, 20.59s/epoch, loss=1.14, accuracy=0.754, val_loss=1.55, val_accuracy=0.606, lr=0.1] 80%|███████▉  | 70/88 [24:50<06:05, 20.33s/epoch, loss=1.14, accuracy=0.753, val_loss=2.56, val_accuracy=0.426, lr=0.0316] 81%|████████  | 71/88 [25:10<05:43, 20.21s/epoch, loss=1.14, accuracy=0.752, val_loss=1.39, val_accuracy=0.669, lr=0.1]    82%|████████▏ | 72/88 [25:31<05:25, 20.37s/epoch, loss=1.14, accuracy=0.753, val_loss=2.27, val_accuracy=0.38, lr=0.1]  83%|████████▎ | 73/88 [25:50<05:02, 20.16s/epoch, loss=1.14, accuracy=0.754, val_loss=1.73, val_accuracy=0.56, lr=0.1] 84%|████████▍ | 74/88 [26:11<04:45, 20.43s/epoch, loss=1.13, accuracy=0.754, val_loss=1.69, val_accuracy=0.601, lr=0.1] 85%|████████▌ | 75/88 [26:31<04:22, 20.22s/epoch, loss=1.14, accuracy=0.754, val_loss=1.71, val_accuracy=0.567, lr=0.1] 86%|████████▋ | 76/88 [26:51<04:02, 20.21s/epoch, loss=1.14, accuracy=0.754, val_loss=2.14, val_accuracy=0.518, lr=0.0316] 88%|████████▊ | 77/88 [27:11<03:40, 20.05s/epoch, loss=1.14, accuracy=0.752, val_loss=1.54, val_accuracy=0.61, lr=0.1]     89%|████████▊ | 78/88 [27:31<03:21, 20.11s/epoch, loss=1.14, accuracy=0.753, val_loss=4.4, val_accuracy=0.213, lr=0.1] 90%|████████▉ | 79/88 [27:53<03:04, 20.45s/epoch, loss=1.15, accuracy=0.755, val_loss=2, val_accuracy=0.536, lr=0.1]   91%|█████████ | 80/88 [28:13<02:42, 20.34s/epoch, loss=1.14, accuracy=0.754, val_loss=1.56, val_accuracy=0.588, lr=0.1] 92%|█████████▏| 81/88 [28:34<02:24, 20.61s/epoch, loss=1.14, accuracy=0.755, val_loss=1.38, val_accuracy=0.668, lr=0.1] 93%|█████████▎| 82/88 [28:54<02:02, 20.42s/epoch, loss=0.944, accuracy=0.811, val_loss=0.892, val_accuracy=0.812, lr=0.01] 94%|█████████▍| 83/88 [29:14<01:41, 20.21s/epoch, loss=0.757, accuracy=0.845, val_loss=0.892, val_accuracy=0.781, lr=0.01] 95%|█████████▌| 84/88 [29:34<01:20, 20.23s/epoch, loss=0.671, accuracy=0.855, val_loss=0.813, val_accuracy=0.799, lr=0.01] 97%|█████████▋| 85/88 [29:55<01:01, 20.58s/epoch, loss=0.621, accuracy=0.86, val_loss=0.732, val_accuracy=0.822, lr=0.01]  98%|█████████▊| 86/88 [30:15<00:40, 20.29s/epoch, loss=0.597, accuracy=0.859, val_loss=0.761, val_accuracy=0.801, lr=0.01] 99%|█████████▉| 87/88 [30:35<00:20, 20.12s/epoch, loss=0.583, accuracy=0.863, val_loss=1.16, val_accuracy=0.694, lr=0.01] 100%|██████████| 88/88 [30:55<00:00, 20.30s/epoch, loss=0.574, accuracy=0.862, val_loss=1.02, val_accuracy=0.702, lr=0.01]100%|██████████| 88/88 [30:55<00:00, 21.09s/epoch, loss=0.574, accuracy=0.862, val_loss=1.02, val_accuracy=0.702, lr=0.01]
Using real-time data augmentation.
Test score: 0.7681536078453064
Test accuracy: 0.8069999814033508


* * * Run SGD for ID = 17_2. * * *


2024-02-19 22:56:52.395594: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-19 22:57:00.019303: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-19 22:57:00.020204: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-19 22:57:00.060968: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-19 22:57:00.060999: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-19 22:57:00.065235: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-19 22:57:00.065280: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-19 22:57:00.069128: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-19 22:57:00.070638: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-19 22:57:00.077434: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-19 22:57:00.079401: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-19 22:57:00.085699: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-19 22:57:00.086227: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-19 22:57:00.086307: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-19 22:57:01.573353: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-19 22:57:01.573995: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-19 22:57:01.574462: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-19 22:57:01.574494: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-19 22:57:01.574527: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-19 22:57:01.574544: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-19 22:57:01.574560: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-19 22:57:01.574576: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-19 22:57:01.574591: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-19 22:57:01.574607: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-19 22:57:01.574623: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-19 22:57:01.575123: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-19 22:57:01.575162: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-19 22:57:02.235363: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-19 22:57:02.235434: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-19 22:57:02.235446: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-19 22:57:02.236802: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:02:00.0, compute capability: 6.1)
{'id': '17_02', 'batch_size': 128, 'epochs': 88, 'validation_split': 0.1, 'checkpointing': True, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
x_train shape: (45000, 32, 32, 3)
45000 train samples
5000 validation samples
10000 test samples
y_train shape: (45000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/88 [00:00<?, ?epoch/s]2024-02-19 22:57:03.083611: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-19 22:57:03.095178: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199825000 Hz
2024-02-19 22:57:05.184634: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-19 22:57:05.448231: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-19 22:57:06.224221: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-19 22:57:06.260483: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/88 [00:52<1:16:19, 52.64s/epoch, loss=3.31, accuracy=0.271, val_loss=2.36, val_accuracy=0.288, lr=0.1]  2%|▏         | 2/88 [01:13<48:43, 33.99s/epoch, loss=1.64, accuracy=0.502, val_loss=2.31, val_accuracy=0.3, lr=0.1]      3%|▎         | 3/88 [01:34<39:27, 27.85s/epoch, loss=1.4, accuracy=0.615, val_loss=4.1, val_accuracy=0.241, lr=0.1]  5%|▍         | 4/88 [01:55<35:19, 25.24s/epoch, loss=1.31, accuracy=0.663, val_loss=2.4, val_accuracy=0.343, lr=0.1]  6%|▌         | 5/88 [02:16<32:51, 23.75s/epoch, loss=1.27, accuracy=0.687, val_loss=2.01, val_accuracy=0.499, lr=0.1]  7%|▋         | 6/88 [02:36<30:35, 22.39s/epoch, loss=1.24, accuracy=0.705, val_loss=1.99, val_accuracy=0.48, lr=0.1]   8%|▊         | 7/88 [02:57<29:45, 22.04s/epoch, loss=1.23, accuracy=0.711, val_loss=1.79, val_accuracy=0.549, lr=0.1]  9%|▉         | 8/88 [03:17<28:22, 21.29s/epoch, loss=1.22, accuracy=0.717, val_loss=1.63, val_accuracy=0.594, lr=0.1] 10%|█         | 9/88 [03:37<27:41, 21.03s/epoch, loss=1.21, accuracy=0.725, val_loss=1.67, val_accuracy=0.559, lr=0.1] 11%|█▏        | 10/88 [03:58<27:18, 21.00s/epoch, loss=1.2, accuracy=0.729, val_loss=2.13, val_accuracy=0.478, lr=0.1] 12%|█▎        | 11/88 [04:19<26:51, 20.93s/epoch, loss=1.2, accuracy=0.729, val_loss=1.77, val_accuracy=0.564, lr=0.1] 14%|█▎        | 12/88 [04:39<26:04, 20.58s/epoch, loss=1.19, accuracy=0.735, val_loss=1.57, val_accuracy=0.605, lr=0.1] 15%|█▍        | 13/88 [04:58<25:25, 20.35s/epoch, loss=1.19, accuracy=0.738, val_loss=1.72, val_accuracy=0.595, lr=0.1] 16%|█▌        | 14/88 [05:19<25:20, 20.55s/epoch, loss=1.18, accuracy=0.738, val_loss=2.48, val_accuracy=0.471, lr=0.1] 17%|█▋        | 15/88 [05:40<25:09, 20.68s/epoch, loss=1.17, accuracy=0.739, val_loss=1.97, val_accuracy=0.468, lr=0.1] 18%|█▊        | 16/88 [06:01<24:54, 20.75s/epoch, loss=1.18, accuracy=0.737, val_loss=2.85, val_accuracy=0.351, lr=0.1] 19%|█▉        | 17/88 [06:22<24:28, 20.68s/epoch, loss=1.17, accuracy=0.741, val_loss=1.55, val_accuracy=0.614, lr=0.1] 20%|██        | 18/88 [06:43<24:12, 20.75s/epoch, loss=1.16, accuracy=0.745, val_loss=2.3, val_accuracy=0.454, lr=0.1]  22%|██▏       | 19/88 [07:02<23:28, 20.41s/epoch, loss=1.16, accuracy=0.745, val_loss=4.97, val_accuracy=0.214, lr=0.1] 23%|██▎       | 20/88 [07:23<23:14, 20.50s/epoch, loss=1.16, accuracy=0.744, val_loss=1.77, val_accuracy=0.532, lr=0.1] 24%|██▍       | 21/88 [07:43<22:36, 20.25s/epoch, loss=1.16, accuracy=0.743, val_loss=1.79, val_accuracy=0.536, lr=0.1] 25%|██▌       | 22/88 [08:03<22:23, 20.36s/epoch, loss=1.15, accuracy=0.746, val_loss=1.77, val_accuracy=0.544, lr=0.0316] 26%|██▌       | 23/88 [08:24<22:02, 20.34s/epoch, loss=1.16, accuracy=0.746, val_loss=1.57, val_accuracy=0.606, lr=0.1]    27%|██▋       | 24/88 [08:44<21:48, 20.45s/epoch, loss=1.16, accuracy=0.746, val_loss=1.76, val_accuracy=0.582, lr=0.1] 28%|██▊       | 25/88 [09:06<21:41, 20.67s/epoch, loss=1.15, accuracy=0.749, val_loss=1.74, val_accuracy=0.558, lr=0.1] 30%|██▉       | 26/88 [09:26<21:23, 20.70s/epoch, loss=1.15, accuracy=0.747, val_loss=1.67, val_accuracy=0.582, lr=0.1] 31%|███       | 27/88 [09:48<21:12, 20.86s/epoch, loss=1.16, accuracy=0.748, val_loss=2.19, val_accuracy=0.495, lr=0.0316] 32%|███▏      | 28/88 [10:09<20:54, 20.90s/epoch, loss=1.15, accuracy=0.749, val_loss=1.63, val_accuracy=0.613, lr=0.1]    33%|███▎      | 29/88 [10:28<20:10, 20.52s/epoch, loss=1.16, accuracy=0.749, val_loss=1.88, val_accuracy=0.533, lr=0.1] 34%|███▍      | 30/88 [10:48<19:38, 20.33s/epoch, loss=1.15, accuracy=0.75, val_loss=1.51, val_accuracy=0.643, lr=0.1]  35%|███▌      | 31/88 [11:08<19:03, 20.06s/epoch, loss=1.15, accuracy=0.747, val_loss=3.78, val_accuracy=0.332, lr=0.1] 36%|███▋      | 32/88 [11:29<18:58, 20.33s/epoch, loss=1.14, accuracy=0.75, val_loss=2.16, val_accuracy=0.458, lr=0.1]  38%|███▊      | 33/88 [11:50<18:50, 20.55s/epoch, loss=1.15, accuracy=0.749, val_loss=2.11, val_accuracy=0.464, lr=0.1] 39%|███▊      | 34/88 [12:11<18:37, 20.69s/epoch, loss=1.15, accuracy=0.75, val_loss=2.73, val_accuracy=0.409, lr=0.1]  40%|███▉      | 35/88 [12:32<18:20, 20.76s/epoch, loss=1.14, accuracy=0.751, val_loss=1.59, val_accuracy=0.601, lr=0.0316] 41%|████      | 36/88 [12:52<18:00, 20.78s/epoch, loss=1.14, accuracy=0.751, val_loss=1.92, val_accuracy=0.5, lr=0.1]      42%|████▏     | 37/88 [13:13<17:41, 20.81s/epoch, loss=1.14, accuracy=0.751, val_loss=3.34, val_accuracy=0.312, lr=0.1] 43%|████▎     | 38/88 [13:34<17:12, 20.66s/epoch, loss=1.15, accuracy=0.751, val_loss=1.89, val_accuracy=0.501, lr=0.1] 44%|████▍     | 39/88 [13:54<16:46, 20.53s/epoch, loss=1.14, accuracy=0.752, val_loss=1.36, val_accuracy=0.66, lr=0.1]  45%|████▌     | 40/88 [14:15<16:29, 20.61s/epoch, loss=1.14, accuracy=0.754, val_loss=2, val_accuracy=0.508, lr=0.1]   47%|████▋     | 41/88 [14:35<16:12, 20.70s/epoch, loss=1.14, accuracy=0.751, val_loss=1.8, val_accuracy=0.58, lr=0.1] 48%|████▊     | 42/88 [14:57<15:57, 20.81s/epoch, loss=1.13, accuracy=0.752, val_loss=3.21, val_accuracy=0.372, lr=0.1] 49%|████▉     | 43/88 [15:17<15:32, 20.72s/epoch, loss=1.14, accuracy=0.753, val_loss=2.36, val_accuracy=0.421, lr=0.1] 50%|█████     | 44/88 [15:38<15:15, 20.82s/epoch, loss=1.14, accuracy=0.753, val_loss=2, val_accuracy=0.485, lr=0.0316] 51%|█████     | 45/88 [15:59<14:50, 20.71s/epoch, loss=1.14, accuracy=0.75, val_loss=2.06, val_accuracy=0.477, lr=0.1]  52%|█████▏    | 46/88 [16:20<14:37, 20.89s/epoch, loss=1.13, accuracy=0.756, val_loss=1.8, val_accuracy=0.562, lr=0.1] 53%|█████▎    | 47/88 [16:41<14:24, 21.09s/epoch, loss=1.13, accuracy=0.754, val_loss=1.67, val_accuracy=0.569, lr=0.1] 55%|█████▍    | 48/88 [17:03<14:04, 21.12s/epoch, loss=1.13, accuracy=0.754, val_loss=1.83, val_accuracy=0.563, lr=0.1] 56%|█████▌    | 49/88 [17:24<13:45, 21.16s/epoch, loss=1.13, accuracy=0.755, val_loss=1.74, val_accuracy=0.535, lr=0.0316] 57%|█████▋    | 50/88 [17:45<13:19, 21.04s/epoch, loss=1.12, accuracy=0.755, val_loss=2.08, val_accuracy=0.419, lr=0.1]    58%|█████▊    | 51/88 [18:06<12:59, 21.06s/epoch, loss=1.13, accuracy=0.755, val_loss=2.12, val_accuracy=0.48, lr=0.1]  59%|█████▉    | 52/88 [18:25<12:23, 20.64s/epoch, loss=1.12, accuracy=0.756, val_loss=2.89, val_accuracy=0.407, lr=0.1] 60%|██████    | 53/88 [18:47<12:07, 20.80s/epoch, loss=1.12, accuracy=0.757, val_loss=3.78, val_accuracy=0.278, lr=0.1] 61%|██████▏   | 54/88 [19:08<11:51, 20.92s/epoch, loss=1.13, accuracy=0.753, val_loss=2.18, val_accuracy=0.476, lr=0.0316] 62%|██████▎   | 55/88 [19:29<11:29, 20.90s/epoch, loss=1.12, accuracy=0.757, val_loss=2.43, val_accuracy=0.469, lr=0.1]    64%|██████▎   | 56/88 [19:50<11:11, 20.97s/epoch, loss=1.13, accuracy=0.754, val_loss=2.8, val_accuracy=0.429, lr=0.1]  65%|██████▍   | 57/88 [20:10<10:39, 20.62s/epoch, loss=1.12, accuracy=0.753, val_loss=2.58, val_accuracy=0.368, lr=0.1] 66%|██████▌   | 58/88 [20:31<10:25, 20.85s/epoch, loss=1.13, accuracy=0.755, val_loss=1.57, val_accuracy=0.629, lr=0.1] 67%|██████▋   | 59/88 [20:52<10:10, 21.06s/epoch, loss=1.13, accuracy=0.756, val_loss=2.56, val_accuracy=0.489, lr=0.0316] 68%|██████▊   | 60/88 [21:14<09:53, 21.19s/epoch, loss=1.12, accuracy=0.755, val_loss=2.17, val_accuracy=0.407, lr=0.1]    69%|██████▉   | 61/88 [21:35<09:31, 21.19s/epoch, loss=1.13, accuracy=0.754, val_loss=1.79, val_accuracy=0.54, lr=0.1]  70%|███████   | 62/88 [21:56<09:06, 21.03s/epoch, loss=1.13, accuracy=0.756, val_loss=2.37, val_accuracy=0.391, lr=0.1] 72%|███████▏  | 63/88 [22:15<08:34, 20.58s/epoch, loss=1.12, accuracy=0.756, val_loss=1.84, val_accuracy=0.515, lr=0.1] 73%|███████▎  | 64/88 [22:35<08:06, 20.29s/epoch, loss=1.12, accuracy=0.757, val_loss=3.8, val_accuracy=0.386, lr=0.0316] 74%|███████▍  | 65/88 [22:56<07:51, 20.52s/epoch, loss=1.12, accuracy=0.757, val_loss=1.74, val_accuracy=0.59, lr=0.1]    75%|███████▌  | 66/88 [23:17<07:32, 20.56s/epoch, loss=1.13, accuracy=0.757, val_loss=1.72, val_accuracy=0.588, lr=0.1] 76%|███████▌  | 67/88 [23:38<07:14, 20.69s/epoch, loss=1.12, accuracy=0.757, val_loss=2.94, val_accuracy=0.424, lr=0.1] 77%|███████▋  | 68/88 [23:58<06:51, 20.60s/epoch, loss=1.11, accuracy=0.758, val_loss=1.83, val_accuracy=0.608, lr=0.1] 78%|███████▊  | 69/88 [24:18<06:25, 20.31s/epoch, loss=1.12, accuracy=0.757, val_loss=1.82, val_accuracy=0.558, lr=0.0316] 80%|███████▉  | 70/88 [24:38<06:03, 20.22s/epoch, loss=1.12, accuracy=0.758, val_loss=1.85, val_accuracy=0.552, lr=0.1]    81%|████████  | 71/88 [24:59<05:47, 20.44s/epoch, loss=1.12, accuracy=0.756, val_loss=1.96, val_accuracy=0.53, lr=0.1]  82%|████████▏ | 72/88 [25:18<05:22, 20.16s/epoch, loss=1.13, accuracy=0.753, val_loss=1.94, val_accuracy=0.494, lr=0.1] 83%|████████▎ | 73/88 [25:39<05:04, 20.29s/epoch, loss=1.12, accuracy=0.757, val_loss=1.5, val_accuracy=0.629, lr=0.1]  84%|████████▍ | 74/88 [25:58<04:40, 20.07s/epoch, loss=1.12, accuracy=0.757, val_loss=3.12, val_accuracy=0.366, lr=0.0316] 85%|████████▌ | 75/88 [26:19<04:22, 20.20s/epoch, loss=1.12, accuracy=0.758, val_loss=2.16, val_accuracy=0.433, lr=0.1]    86%|████████▋ | 76/88 [26:38<03:59, 19.98s/epoch, loss=1.12, accuracy=0.759, val_loss=2.49, val_accuracy=0.4, lr=0.1]   88%|████████▊ | 77/88 [26:59<03:40, 20.07s/epoch, loss=1.12, accuracy=0.758, val_loss=1.95, val_accuracy=0.55, lr=0.1] 89%|████████▊ | 78/88 [27:19<03:21, 20.10s/epoch, loss=1.12, accuracy=0.757, val_loss=2.02, val_accuracy=0.481, lr=0.1] 90%|████████▉ | 79/88 [27:38<02:59, 19.98s/epoch, loss=1.12, accuracy=0.756, val_loss=2.12, val_accuracy=0.46, lr=0.0316] 91%|█████████ | 80/88 [27:59<02:41, 20.19s/epoch, loss=1.12, accuracy=0.756, val_loss=2.68, val_accuracy=0.403, lr=0.1]   92%|█████████▏| 81/88 [28:20<02:22, 20.35s/epoch, loss=1.12, accuracy=0.755, val_loss=1.48, val_accuracy=0.649, lr=0.1] 93%|█████████▎| 82/88 [28:41<02:04, 20.74s/epoch, loss=0.921, accuracy=0.815, val_loss=1.02, val_accuracy=0.764, lr=0.01] 94%|█████████▍| 83/88 [29:03<01:44, 20.84s/epoch, loss=0.749, accuracy=0.845, val_loss=0.858, val_accuracy=0.801, lr=0.01] 95%|█████████▌| 84/88 [29:23<01:22, 20.70s/epoch, loss=0.663, accuracy=0.857, val_loss=0.746, val_accuracy=0.826, lr=0.01] 97%|█████████▋| 85/88 [29:43<01:01, 20.64s/epoch, loss=0.616, accuracy=0.859, val_loss=0.748, val_accuracy=0.813, lr=0.01] 98%|█████████▊| 86/88 [30:03<00:40, 20.46s/epoch, loss=0.592, accuracy=0.86, val_loss=0.703, val_accuracy=0.82, lr=0.01]   99%|█████████▉| 87/88 [30:24<00:20, 20.60s/epoch, loss=0.577, accuracy=0.862, val_loss=0.692, val_accuracy=0.826, lr=0.01]100%|██████████| 88/88 [30:44<00:00, 20.28s/epoch, loss=0.568, accuracy=0.863, val_loss=0.729, val_accuracy=0.81, lr=0.01] 100%|██████████| 88/88 [30:44<00:00, 20.96s/epoch, loss=0.568, accuracy=0.863, val_loss=0.729, val_accuracy=0.81, lr=0.01]
Using real-time data augmentation.
Test score: 0.7715898156166077
Test accuracy: 0.8130000233650208


* * * Run SGD for ID = 17_3. * * *


2024-02-19 23:27:54.067684: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-19 23:27:59.720502: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-19 23:27:59.721686: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-19 23:27:59.762328: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-19 23:27:59.762364: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-19 23:27:59.768505: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-19 23:27:59.768551: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-19 23:27:59.772143: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-19 23:27:59.774167: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-19 23:27:59.777692: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-19 23:27:59.780607: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-19 23:27:59.786740: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-19 23:27:59.787333: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-19 23:27:59.787413: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-19 23:28:01.368969: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-19 23:28:01.370653: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-19 23:28:01.371125: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-19 23:28:01.371157: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-19 23:28:01.371191: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-19 23:28:01.371210: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-19 23:28:01.371227: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-19 23:28:01.371245: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-19 23:28:01.371262: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-19 23:28:01.371280: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-19 23:28:01.371297: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-19 23:28:01.371774: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-19 23:28:01.371809: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-19 23:28:02.072098: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-19 23:28:02.072159: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-19 23:28:02.072169: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-19 23:28:02.073504: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:02:00.0, compute capability: 6.1)
{'id': '17_03', 'batch_size': 128, 'epochs': 88, 'validation_split': 0.1, 'checkpointing': True, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
x_train shape: (45000, 32, 32, 3)
45000 train samples
5000 validation samples
10000 test samples
y_train shape: (45000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/88 [00:00<?, ?epoch/s]2024-02-19 23:28:02.956777: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-19 23:28:02.969177: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199825000 Hz
2024-02-19 23:28:05.097815: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-19 23:28:05.364246: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-19 23:28:06.007565: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-19 23:28:06.050321: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/88 [00:58<1:24:30, 58.28s/epoch, loss=3.29, accuracy=0.247, val_loss=2.41, val_accuracy=0.23, lr=0.1]  2%|▏         | 2/88 [01:19<52:33, 36.67s/epoch, loss=1.67, accuracy=0.478, val_loss=2.47, val_accuracy=0.33, lr=0.1]    3%|▎         | 3/88 [01:40<41:25, 29.24s/epoch, loss=1.41, accuracy=0.606, val_loss=2.4, val_accuracy=0.309, lr=0.1]  5%|▍         | 4/88 [02:01<36:38, 26.17s/epoch, loss=1.32, accuracy=0.666, val_loss=1.71, val_accuracy=0.56, lr=0.1]  6%|▌         | 5/88 [02:22<33:38, 24.32s/epoch, loss=1.27, accuracy=0.689, val_loss=2.17, val_accuracy=0.463, lr=0.1]  7%|▋         | 6/88 [02:43<31:48, 23.27s/epoch, loss=1.24, accuracy=0.703, val_loss=1.87, val_accuracy=0.499, lr=0.1]  8%|▊         | 7/88 [03:05<30:30, 22.60s/epoch, loss=1.22, accuracy=0.714, val_loss=1.95, val_accuracy=0.473, lr=0.1]  9%|▉         | 8/88 [03:26<29:37, 22.22s/epoch, loss=1.22, accuracy=0.715, val_loss=1.65, val_accuracy=0.581, lr=0.1] 10%|█         | 9/88 [03:46<28:10, 21.40s/epoch, loss=1.2, accuracy=0.723, val_loss=2.38, val_accuracy=0.449, lr=0.1]  11%|█▏        | 10/88 [04:07<27:46, 21.37s/epoch, loss=1.2, accuracy=0.728, val_loss=2.66, val_accuracy=0.387, lr=0.1] 12%|█▎        | 11/88 [04:28<27:26, 21.38s/epoch, loss=1.2, accuracy=0.729, val_loss=1.73, val_accuracy=0.61, lr=0.1]  14%|█▎        | 12/88 [04:48<26:35, 20.99s/epoch, loss=1.18, accuracy=0.733, val_loss=2.23, val_accuracy=0.487, lr=0.1] 15%|█▍        | 13/88 [05:10<26:19, 21.06s/epoch, loss=1.18, accuracy=0.732, val_loss=3.26, val_accuracy=0.297, lr=0.0316] 16%|█▌        | 14/88 [05:31<26:03, 21.13s/epoch, loss=1.18, accuracy=0.733, val_loss=2.12, val_accuracy=0.457, lr=0.1]    17%|█▋        | 15/88 [05:52<25:36, 21.05s/epoch, loss=1.17, accuracy=0.738, val_loss=3.16, val_accuracy=0.359, lr=0.1] 18%|█▊        | 16/88 [06:12<24:47, 20.65s/epoch, loss=1.17, accuracy=0.74, val_loss=2.44, val_accuracy=0.445, lr=0.1]  19%|█▉        | 17/88 [06:32<24:12, 20.46s/epoch, loss=1.18, accuracy=0.737, val_loss=2.2, val_accuracy=0.491, lr=0.1] 20%|██        | 18/88 [06:53<24:04, 20.64s/epoch, loss=1.17, accuracy=0.74, val_loss=1.57, val_accuracy=0.607, lr=0.1] 22%|██▏       | 19/88 [07:14<23:53, 20.77s/epoch, loss=1.16, accuracy=0.744, val_loss=2.72, val_accuracy=0.398, lr=0.1] 23%|██▎       | 20/88 [07:34<23:26, 20.69s/epoch, loss=1.16, accuracy=0.741, val_loss=1.57, val_accuracy=0.602, lr=0.1] 24%|██▍       | 21/88 [07:54<22:55, 20.53s/epoch, loss=1.16, accuracy=0.744, val_loss=2.42, val_accuracy=0.414, lr=0.1] 25%|██▌       | 22/88 [08:14<22:20, 20.31s/epoch, loss=1.16, accuracy=0.743, val_loss=1.83, val_accuracy=0.524, lr=0.1] 26%|██▌       | 23/88 [08:35<22:15, 20.54s/epoch, loss=1.15, accuracy=0.745, val_loss=3.75, val_accuracy=0.379, lr=0.0316] 27%|██▋       | 24/88 [08:57<22:08, 20.76s/epoch, loss=1.16, accuracy=0.747, val_loss=3.04, val_accuracy=0.357, lr=0.1]    28%|██▊       | 25/88 [09:17<21:44, 20.70s/epoch, loss=1.15, accuracy=0.745, val_loss=4.66, val_accuracy=0.234, lr=0.1] 30%|██▉       | 26/88 [09:38<21:33, 20.86s/epoch, loss=1.15, accuracy=0.746, val_loss=1.88, val_accuracy=0.527, lr=0.1] 31%|███       | 27/88 [10:00<21:22, 21.03s/epoch, loss=1.15, accuracy=0.747, val_loss=1.45, val_accuracy=0.646, lr=0.1] 32%|███▏      | 28/88 [10:20<20:48, 20.81s/epoch, loss=1.15, accuracy=0.746, val_loss=3.7, val_accuracy=0.313, lr=0.1]  33%|███▎      | 29/88 [10:40<20:13, 20.56s/epoch, loss=1.15, accuracy=0.749, val_loss=1.6, val_accuracy=0.579, lr=0.1] 34%|███▍      | 30/88 [11:01<20:00, 20.70s/epoch, loss=1.14, accuracy=0.748, val_loss=1.73, val_accuracy=0.591, lr=0.1] 35%|███▌      | 31/88 [11:22<19:47, 20.84s/epoch, loss=1.15, accuracy=0.75, val_loss=1.84, val_accuracy=0.556, lr=0.1]  36%|███▋      | 32/88 [11:42<19:09, 20.53s/epoch, loss=1.15, accuracy=0.749, val_loss=2.1, val_accuracy=0.522, lr=0.0316] 38%|███▊      | 33/88 [12:03<19:03, 20.80s/epoch, loss=1.15, accuracy=0.747, val_loss=2.19, val_accuracy=0.453, lr=0.1]   39%|███▊      | 34/88 [12:24<18:46, 20.86s/epoch, loss=1.15, accuracy=0.749, val_loss=1.72, val_accuracy=0.573, lr=0.1] 40%|███▉      | 35/88 [12:45<18:23, 20.82s/epoch, loss=1.14, accuracy=0.748, val_loss=1.89, val_accuracy=0.519, lr=0.1] 41%|████      | 36/88 [13:06<18:08, 20.94s/epoch, loss=1.14, accuracy=0.751, val_loss=2.7, val_accuracy=0.4, lr=0.1]    42%|████▏     | 37/88 [13:28<17:51, 21.00s/epoch, loss=1.14, accuracy=0.748, val_loss=2.28, val_accuracy=0.454, lr=0.0316] 43%|████▎     | 38/88 [13:49<17:34, 21.09s/epoch, loss=1.14, accuracy=0.749, val_loss=4.43, val_accuracy=0.262, lr=0.1]    44%|████▍     | 39/88 [14:10<17:15, 21.13s/epoch, loss=1.13, accuracy=0.754, val_loss=1.86, val_accuracy=0.511, lr=0.1] 45%|████▌     | 40/88 [14:31<16:53, 21.12s/epoch, loss=1.13, accuracy=0.749, val_loss=2.08, val_accuracy=0.477, lr=0.1] 47%|████▋     | 41/88 [14:51<16:15, 20.75s/epoch, loss=1.13, accuracy=0.754, val_loss=2.18, val_accuracy=0.461, lr=0.1] 48%|████▊     | 42/88 [15:12<15:58, 20.84s/epoch, loss=1.13, accuracy=0.752, val_loss=1.59, val_accuracy=0.615, lr=0.0316] 49%|████▉     | 43/88 [15:33<15:36, 20.81s/epoch, loss=1.13, accuracy=0.753, val_loss=2.26, val_accuracy=0.465, lr=0.1]    50%|█████     | 44/88 [15:54<15:15, 20.80s/epoch, loss=1.14, accuracy=0.751, val_loss=1.51, val_accuracy=0.646, lr=0.1] 51%|█████     | 45/88 [16:14<14:42, 20.53s/epoch, loss=1.13, accuracy=0.754, val_loss=1.96, val_accuracy=0.55, lr=0.1]  52%|█████▏    | 46/88 [16:34<14:26, 20.63s/epoch, loss=1.13, accuracy=0.753, val_loss=1.69, val_accuracy=0.599, lr=0.1] 53%|█████▎    | 47/88 [16:55<14:06, 20.63s/epoch, loss=1.13, accuracy=0.754, val_loss=1.57, val_accuracy=0.62, lr=0.0316] 55%|█████▍    | 48/88 [17:16<13:53, 20.83s/epoch, loss=1.13, accuracy=0.753, val_loss=2.89, val_accuracy=0.381, lr=0.1]   56%|█████▌    | 49/88 [17:37<13:29, 20.76s/epoch, loss=1.13, accuracy=0.753, val_loss=3.11, val_accuracy=0.322, lr=0.1] 57%|█████▋    | 50/88 [17:58<13:15, 20.93s/epoch, loss=1.13, accuracy=0.753, val_loss=3.97, val_accuracy=0.319, lr=0.1] 58%|█████▊    | 51/88 [18:19<12:50, 20.82s/epoch, loss=1.13, accuracy=0.754, val_loss=2.91, val_accuracy=0.245, lr=0.1] 59%|█████▉    | 52/88 [18:40<12:33, 20.93s/epoch, loss=1.13, accuracy=0.754, val_loss=2.42, val_accuracy=0.428, lr=0.0316] 60%|██████    | 53/88 [19:00<12:07, 20.79s/epoch, loss=1.14, accuracy=0.752, val_loss=2.25, val_accuracy=0.493, lr=0.1]    61%|██████▏   | 54/88 [19:22<11:52, 20.96s/epoch, loss=1.13, accuracy=0.754, val_loss=2.77, val_accuracy=0.426, lr=0.1] 62%|██████▎   | 55/88 [19:43<11:33, 21.03s/epoch, loss=1.13, accuracy=0.754, val_loss=1.7, val_accuracy=0.586, lr=0.1]  64%|██████▎   | 56/88 [20:04<11:14, 21.09s/epoch, loss=1.13, accuracy=0.756, val_loss=2.13, val_accuracy=0.493, lr=0.1] 65%|██████▍   | 57/88 [20:24<10:41, 20.69s/epoch, loss=1.12, accuracy=0.756, val_loss=2.12, val_accuracy=0.439, lr=0.0316] 66%|██████▌   | 58/88 [20:45<10:19, 20.65s/epoch, loss=1.13, accuracy=0.756, val_loss=1.91, val_accuracy=0.478, lr=0.1]    67%|██████▋   | 59/88 [21:06<10:04, 20.84s/epoch, loss=1.13, accuracy=0.753, val_loss=2.56, val_accuracy=0.356, lr=0.1] 68%|██████▊   | 60/88 [21:26<09:38, 20.65s/epoch, loss=1.13, accuracy=0.756, val_loss=2.41, val_accuracy=0.456, lr=0.1] 69%|██████▉   | 61/88 [21:47<09:21, 20.78s/epoch, loss=1.13, accuracy=0.756, val_loss=2.28, val_accuracy=0.468, lr=0.1] 70%|███████   | 62/88 [22:07<08:53, 20.51s/epoch, loss=1.13, accuracy=0.755, val_loss=2.1, val_accuracy=0.466, lr=0.0316] 72%|███████▏  | 63/88 [22:28<08:33, 20.54s/epoch, loss=1.13, accuracy=0.753, val_loss=1.98, val_accuracy=0.487, lr=0.1]   73%|███████▎  | 64/88 [22:49<08:17, 20.74s/epoch, loss=1.12, accuracy=0.756, val_loss=1.67, val_accuracy=0.549, lr=0.1] 74%|███████▍  | 65/88 [23:10<07:58, 20.83s/epoch, loss=1.13, accuracy=0.758, val_loss=2.09, val_accuracy=0.493, lr=0.1] 75%|███████▌  | 66/88 [23:31<07:37, 20.79s/epoch, loss=1.13, accuracy=0.755, val_loss=2.37, val_accuracy=0.393, lr=0.1] 76%|███████▌  | 67/88 [23:52<07:19, 20.91s/epoch, loss=1.13, accuracy=0.755, val_loss=1.68, val_accuracy=0.582, lr=0.0316] 77%|███████▋  | 68/88 [24:13<06:58, 20.94s/epoch, loss=1.13, accuracy=0.756, val_loss=2.04, val_accuracy=0.505, lr=0.1]    78%|███████▊  | 69/88 [24:33<06:31, 20.61s/epoch, loss=1.13, accuracy=0.757, val_loss=2.55, val_accuracy=0.498, lr=0.1] 80%|███████▉  | 70/88 [24:53<06:10, 20.58s/epoch, loss=1.12, accuracy=0.758, val_loss=1.73, val_accuracy=0.567, lr=0.1] 81%|████████  | 71/88 [25:14<05:53, 20.78s/epoch, loss=1.13, accuracy=0.758, val_loss=2.36, val_accuracy=0.426, lr=0.1] 82%|████████▏ | 72/88 [25:35<05:33, 20.82s/epoch, loss=1.13, accuracy=0.755, val_loss=2.67, val_accuracy=0.41, lr=0.0316] 83%|████████▎ | 73/88 [25:57<05:14, 20.98s/epoch, loss=1.12, accuracy=0.754, val_loss=2.19, val_accuracy=0.44, lr=0.1]    84%|████████▍ | 74/88 [26:17<04:53, 20.93s/epoch, loss=1.13, accuracy=0.756, val_loss=2.53, val_accuracy=0.337, lr=0.1] 85%|████████▌ | 75/88 [26:39<04:34, 21.09s/epoch, loss=1.12, accuracy=0.758, val_loss=1.87, val_accuracy=0.563, lr=0.1] 86%|████████▋ | 76/88 [27:00<04:12, 21.02s/epoch, loss=1.13, accuracy=0.757, val_loss=1.79, val_accuracy=0.501, lr=0.1] 88%|████████▊ | 77/88 [27:21<03:51, 21.07s/epoch, loss=1.13, accuracy=0.756, val_loss=2.41, val_accuracy=0.435, lr=0.0316] 89%|████████▊ | 78/88 [27:42<03:31, 21.10s/epoch, loss=1.13, accuracy=0.756, val_loss=2.65, val_accuracy=0.43, lr=0.1]     90%|████████▉ | 79/88 [28:02<03:06, 20.76s/epoch, loss=1.13, accuracy=0.754, val_loss=2.95, val_accuracy=0.405, lr=0.1] 91%|█████████ | 80/88 [28:24<02:47, 20.96s/epoch, loss=1.13, accuracy=0.757, val_loss=2.24, val_accuracy=0.481, lr=0.1] 92%|█████████▏| 81/88 [28:44<02:26, 20.95s/epoch, loss=1.13, accuracy=0.756, val_loss=1.96, val_accuracy=0.517, lr=0.1] 93%|█████████▎| 82/88 [29:06<02:06, 21.02s/epoch, loss=0.932, accuracy=0.816, val_loss=0.903, val_accuracy=0.804, lr=0.01] 94%|█████████▍| 83/88 [29:27<01:45, 21.04s/epoch, loss=0.756, accuracy=0.845, val_loss=0.8, val_accuracy=0.817, lr=0.01]   95%|█████████▌| 84/88 [29:47<01:22, 20.74s/epoch, loss=0.669, accuracy=0.856, val_loss=0.734, val_accuracy=0.824, lr=0.01] 97%|█████████▋| 85/88 [30:07<01:01, 20.50s/epoch, loss=0.622, accuracy=0.86, val_loss=0.71, val_accuracy=0.826, lr=0.01]   98%|█████████▊| 86/88 [30:28<00:41, 20.69s/epoch, loss=0.597, accuracy=0.86, val_loss=0.775, val_accuracy=0.797, lr=0.01] 99%|█████████▉| 87/88 [30:49<00:20, 20.95s/epoch, loss=0.581, accuracy=0.861, val_loss=0.704, val_accuracy=0.819, lr=0.01]100%|██████████| 88/88 [31:10<00:00, 20.90s/epoch, loss=0.572, accuracy=0.863, val_loss=0.854, val_accuracy=0.788, lr=0.01]100%|██████████| 88/88 [31:10<00:00, 21.26s/epoch, loss=0.572, accuracy=0.863, val_loss=0.854, val_accuracy=0.788, lr=0.01]
Using real-time data augmentation.
Test score: 0.7127946019172668
Test accuracy: 0.822700023651123


* * * Run SGD for ID = 17_4. * * *


2024-02-19 23:59:21.919902: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-19 23:59:24.739846: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-19 23:59:24.740737: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-19 23:59:24.780303: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-19 23:59:24.780337: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-19 23:59:24.783252: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-19 23:59:24.783295: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-19 23:59:24.785568: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-19 23:59:24.786825: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-19 23:59:24.789432: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-19 23:59:24.790965: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-19 23:59:24.795871: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-19 23:59:24.796438: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-19 23:59:24.796520: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-19 23:59:26.315252: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-19 23:59:26.316327: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-19 23:59:26.317122: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-19 23:59:26.317157: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-19 23:59:26.317192: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-19 23:59:26.317210: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-19 23:59:26.317227: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-19 23:59:26.317244: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-19 23:59:26.317259: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-19 23:59:26.317275: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-19 23:59:26.317291: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-19 23:59:26.317753: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-19 23:59:26.317788: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-19 23:59:26.969136: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-19 23:59:26.969190: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-19 23:59:26.969207: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-19 23:59:26.970132: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:02:00.0, compute capability: 6.1)
{'id': '17_04', 'batch_size': 128, 'epochs': 88, 'validation_split': 0.1, 'checkpointing': True, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
x_train shape: (45000, 32, 32, 3)
45000 train samples
5000 validation samples
10000 test samples
y_train shape: (45000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/88 [00:00<?, ?epoch/s]2024-02-19 23:59:27.784791: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-19 23:59:27.797179: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199825000 Hz
2024-02-19 23:59:29.793558: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-19 23:59:30.067639: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-19 23:59:30.792185: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-19 23:59:30.839372: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/88 [00:55<1:19:59, 55.16s/epoch, loss=3.36, accuracy=0.294, val_loss=2.21, val_accuracy=0.325, lr=0.1]  2%|▏         | 2/88 [01:16<50:24, 35.17s/epoch, loss=1.59, accuracy=0.525, val_loss=3.17, val_accuracy=0.239, lr=0.1]    3%|▎         | 3/88 [01:38<41:21, 29.19s/epoch, loss=1.35, accuracy=0.632, val_loss=2.44, val_accuracy=0.474, lr=0.1]  5%|▍         | 4/88 [01:59<36:21, 25.97s/epoch, loss=1.28, accuracy=0.675, val_loss=2.42, val_accuracy=0.453, lr=0.1]  6%|▌         | 5/88 [02:21<33:59, 24.58s/epoch, loss=1.26, accuracy=0.691, val_loss=2.22, val_accuracy=0.426, lr=0.1]  7%|▋         | 6/88 [02:43<32:17, 23.63s/epoch, loss=1.23, accuracy=0.703, val_loss=1.51, val_accuracy=0.598, lr=0.1]  8%|▊         | 7/88 [03:04<30:57, 22.93s/epoch, loss=1.23, accuracy=0.71, val_loss=2.5, val_accuracy=0.423, lr=0.1]    9%|▉         | 8/88 [03:26<30:08, 22.60s/epoch, loss=1.21, accuracy=0.718, val_loss=1.82, val_accuracy=0.515, lr=0.1] 10%|█         | 9/88 [03:47<28:48, 21.88s/epoch, loss=1.21, accuracy=0.72, val_loss=2.34, val_accuracy=0.385, lr=0.1]  11%|█▏        | 10/88 [04:08<28:15, 21.74s/epoch, loss=1.21, accuracy=0.723, val_loss=1.77, val_accuracy=0.514, lr=0.1] 12%|█▎        | 11/88 [04:30<27:55, 21.75s/epoch, loss=1.21, accuracy=0.725, val_loss=2.23, val_accuracy=0.44, lr=0.0316] 14%|█▎        | 12/88 [04:51<27:30, 21.72s/epoch, loss=1.2, accuracy=0.73, val_loss=2.08, val_accuracy=0.448, lr=0.1]     15%|█▍        | 13/88 [05:13<26:58, 21.58s/epoch, loss=1.19, accuracy=0.732, val_loss=1.61, val_accuracy=0.601, lr=0.1] 16%|█▌        | 14/88 [05:34<26:33, 21.54s/epoch, loss=1.19, accuracy=0.734, val_loss=1.65, val_accuracy=0.552, lr=0.1] 17%|█▋        | 15/88 [05:56<26:13, 21.55s/epoch, loss=1.19, accuracy=0.736, val_loss=2.58, val_accuracy=0.403, lr=0.1] 18%|█▊        | 16/88 [06:17<25:40, 21.40s/epoch, loss=1.19, accuracy=0.735, val_loss=1.67, val_accuracy=0.571, lr=0.0316] 19%|█▉        | 17/88 [06:38<25:09, 21.27s/epoch, loss=1.19, accuracy=0.739, val_loss=1.45, val_accuracy=0.636, lr=0.1]    20%|██        | 18/88 [06:58<24:22, 20.90s/epoch, loss=1.18, accuracy=0.739, val_loss=1.61, val_accuracy=0.587, lr=0.1] 22%|██▏       | 19/88 [07:19<24:04, 20.93s/epoch, loss=1.18, accuracy=0.741, val_loss=1.88, val_accuracy=0.563, lr=0.1] 23%|██▎       | 20/88 [07:40<23:47, 20.99s/epoch, loss=1.19, accuracy=0.74, val_loss=2.44, val_accuracy=0.397, lr=0.1]  24%|██▍       | 21/88 [08:01<23:38, 21.18s/epoch, loss=1.17, accuracy=0.742, val_loss=1.71, val_accuracy=0.564, lr=0.1] 25%|██▌       | 22/88 [08:22<23:00, 20.92s/epoch, loss=1.18, accuracy=0.741, val_loss=2.69, val_accuracy=0.323, lr=0.0316] 26%|██▌       | 23/88 [08:43<22:53, 21.13s/epoch, loss=1.17, accuracy=0.745, val_loss=1.81, val_accuracy=0.536, lr=0.1]    27%|██▋       | 24/88 [09:05<22:42, 21.29s/epoch, loss=1.16, accuracy=0.744, val_loss=1.75, val_accuracy=0.578, lr=0.1] 28%|██▊       | 25/88 [09:27<22:29, 21.42s/epoch, loss=1.16, accuracy=0.744, val_loss=2.51, val_accuracy=0.317, lr=0.1] 30%|██▉       | 26/88 [09:47<21:46, 21.07s/epoch, loss=1.16, accuracy=0.745, val_loss=1.47, val_accuracy=0.628, lr=0.1] 31%|███       | 27/88 [10:09<21:37, 21.27s/epoch, loss=1.16, accuracy=0.744, val_loss=1.81, val_accuracy=0.545, lr=0.0316] 32%|███▏      | 28/88 [10:29<20:59, 21.00s/epoch, loss=1.17, accuracy=0.745, val_loss=2.31, val_accuracy=0.396, lr=0.1]    33%|███▎      | 29/88 [10:49<20:26, 20.80s/epoch, loss=1.16, accuracy=0.744, val_loss=2.1, val_accuracy=0.488, lr=0.1]  34%|███▍      | 30/88 [11:11<20:20, 21.04s/epoch, loss=1.15, accuracy=0.748, val_loss=1.69, val_accuracy=0.56, lr=0.1] 35%|███▌      | 31/88 [11:32<20:02, 21.10s/epoch, loss=1.15, accuracy=0.745, val_loss=1.67, val_accuracy=0.582, lr=0.1] 36%|███▋      | 32/88 [11:54<19:52, 21.30s/epoch, loss=1.15, accuracy=0.751, val_loss=2.32, val_accuracy=0.429, lr=0.0316] 38%|███▊      | 33/88 [12:14<19:16, 21.03s/epoch, loss=1.15, accuracy=0.746, val_loss=1.79, val_accuracy=0.496, lr=0.1]    39%|███▊      | 34/88 [12:36<19:02, 21.16s/epoch, loss=1.16, accuracy=0.748, val_loss=3.94, val_accuracy=0.262, lr=0.1] 40%|███▉      | 35/88 [12:56<18:31, 20.97s/epoch, loss=1.15, accuracy=0.75, val_loss=1.97, val_accuracy=0.517, lr=0.1]  41%|████      | 36/88 [13:18<18:12, 21.01s/epoch, loss=1.15, accuracy=0.75, val_loss=1.45, val_accuracy=0.655, lr=0.1] 42%|████▏     | 37/88 [13:39<17:57, 21.12s/epoch, loss=1.14, accuracy=0.752, val_loss=1.74, val_accuracy=0.559, lr=0.0316] 43%|████▎     | 38/88 [13:59<17:26, 20.94s/epoch, loss=1.14, accuracy=0.752, val_loss=2.11, val_accuracy=0.51, lr=0.1]     44%|████▍     | 39/88 [14:20<17:07, 20.97s/epoch, loss=1.14, accuracy=0.751, val_loss=1.89, val_accuracy=0.503, lr=0.1] 45%|████▌     | 40/88 [14:42<16:56, 21.17s/epoch, loss=1.14, accuracy=0.75, val_loss=1.86, val_accuracy=0.513, lr=0.1]  47%|████▋     | 41/88 [15:04<16:41, 21.31s/epoch, loss=1.14, accuracy=0.753, val_loss=1.58, val_accuracy=0.61, lr=0.1] 48%|████▊     | 42/88 [15:25<16:19, 21.30s/epoch, loss=1.14, accuracy=0.753, val_loss=2.28, val_accuracy=0.414, lr=0.0316] 49%|████▉     | 43/88 [15:47<16:05, 21.46s/epoch, loss=1.14, accuracy=0.753, val_loss=2.91, val_accuracy=0.407, lr=0.1]    50%|█████     | 44/88 [16:09<15:48, 21.55s/epoch, loss=1.13, accuracy=0.753, val_loss=2.97, val_accuracy=0.395, lr=0.1] 51%|█████     | 45/88 [16:30<15:26, 21.55s/epoch, loss=1.14, accuracy=0.752, val_loss=3.69, val_accuracy=0.317, lr=0.1] 52%|█████▏    | 46/88 [16:51<14:52, 21.24s/epoch, loss=1.13, accuracy=0.753, val_loss=2.23, val_accuracy=0.455, lr=0.1] 53%|█████▎    | 47/88 [17:11<14:19, 20.95s/epoch, loss=1.14, accuracy=0.751, val_loss=1.85, val_accuracy=0.536, lr=0.0316] 55%|█████▍    | 48/88 [17:32<13:57, 20.93s/epoch, loss=1.14, accuracy=0.752, val_loss=1.32, val_accuracy=0.69, lr=0.1]     56%|█████▌    | 49/88 [17:53<13:43, 21.11s/epoch, loss=1.14, accuracy=0.751, val_loss=2.18, val_accuracy=0.51, lr=0.1] 57%|█████▋    | 50/88 [18:15<13:30, 21.33s/epoch, loss=1.13, accuracy=0.749, val_loss=1.83, val_accuracy=0.518, lr=0.1] 58%|█████▊    | 51/88 [18:37<13:14, 21.48s/epoch, loss=1.12, accuracy=0.752, val_loss=1.71, val_accuracy=0.559, lr=0.1] 59%|█████▉    | 52/88 [18:59<12:56, 21.57s/epoch, loss=1.13, accuracy=0.753, val_loss=1.75, val_accuracy=0.557, lr=0.1] 60%|██████    | 53/88 [19:20<12:35, 21.58s/epoch, loss=1.13, accuracy=0.754, val_loss=3.31, val_accuracy=0.336, lr=0.0316] 61%|██████▏   | 54/88 [19:41<12:01, 21.21s/epoch, loss=1.13, accuracy=0.754, val_loss=1.78, val_accuracy=0.525, lr=0.1]    62%|██████▎   | 55/88 [20:02<11:43, 21.31s/epoch, loss=1.12, accuracy=0.755, val_loss=6.06, val_accuracy=0.2, lr=0.1]   64%|██████▎   | 56/88 [20:24<11:25, 21.42s/epoch, loss=1.12, accuracy=0.755, val_loss=3.57, val_accuracy=0.276, lr=0.1] 65%|██████▍   | 57/88 [20:46<11:06, 21.50s/epoch, loss=1.12, accuracy=0.754, val_loss=2.76, val_accuracy=0.407, lr=0.1] 66%|██████▌   | 58/88 [21:07<10:45, 21.53s/epoch, loss=1.12, accuracy=0.757, val_loss=3.57, val_accuracy=0.186, lr=0.0316] 67%|██████▋   | 59/88 [21:29<10:24, 21.53s/epoch, loss=1.12, accuracy=0.757, val_loss=2.4, val_accuracy=0.423, lr=0.1]     68%|██████▊   | 60/88 [21:50<10:03, 21.56s/epoch, loss=1.12, accuracy=0.753, val_loss=3.19, val_accuracy=0.302, lr=0.1] 69%|██████▉   | 61/88 [22:12<09:43, 21.60s/epoch, loss=1.12, accuracy=0.757, val_loss=1.6, val_accuracy=0.584, lr=0.1]  70%|███████   | 62/88 [22:34<09:22, 21.63s/epoch, loss=1.11, accuracy=0.755, val_loss=1.89, val_accuracy=0.537, lr=0.1] 72%|███████▏  | 63/88 [22:56<09:01, 21.65s/epoch, loss=1.12, accuracy=0.756, val_loss=2.52, val_accuracy=0.42, lr=0.0316] 73%|███████▎  | 64/88 [23:16<08:29, 21.24s/epoch, loss=1.12, accuracy=0.756, val_loss=2.17, val_accuracy=0.453, lr=0.1]   74%|███████▍  | 65/88 [23:37<08:11, 21.36s/epoch, loss=1.12, accuracy=0.755, val_loss=1.89, val_accuracy=0.492, lr=0.1] 75%|███████▌  | 66/88 [23:59<07:51, 21.44s/epoch, loss=1.11, accuracy=0.757, val_loss=3.17, val_accuracy=0.381, lr=0.1] 76%|███████▌  | 67/88 [24:20<07:27, 21.32s/epoch, loss=1.12, accuracy=0.756, val_loss=1.93, val_accuracy=0.498, lr=0.1] 77%|███████▋  | 68/88 [24:42<07:08, 21.45s/epoch, loss=1.12, accuracy=0.757, val_loss=3.77, val_accuracy=0.287, lr=0.0316] 78%|███████▊  | 69/88 [25:04<06:49, 21.55s/epoch, loss=1.11, accuracy=0.757, val_loss=2.87, val_accuracy=0.364, lr=0.1]    80%|███████▉  | 70/88 [25:24<06:22, 21.26s/epoch, loss=1.12, accuracy=0.754, val_loss=2.27, val_accuracy=0.386, lr=0.1] 81%|████████  | 71/88 [25:46<06:04, 21.43s/epoch, loss=1.11, accuracy=0.756, val_loss=3.59, val_accuracy=0.321, lr=0.1] 82%|████████▏ | 72/88 [26:07<05:42, 21.43s/epoch, loss=1.11, accuracy=0.758, val_loss=2.26, val_accuracy=0.475, lr=0.1] 83%|████████▎ | 73/88 [26:29<05:22, 21.52s/epoch, loss=1.11, accuracy=0.757, val_loss=2.37, val_accuracy=0.422, lr=0.0316] 84%|████████▍ | 74/88 [26:49<04:55, 21.11s/epoch, loss=1.11, accuracy=0.757, val_loss=1.99, val_accuracy=0.499, lr=0.1]    85%|████████▌ | 75/88 [27:11<04:35, 21.22s/epoch, loss=1.11, accuracy=0.758, val_loss=2.3, val_accuracy=0.421, lr=0.1]  86%|████████▋ | 76/88 [27:32<04:13, 21.09s/epoch, loss=1.11, accuracy=0.756, val_loss=1.64, val_accuracy=0.585, lr=0.1] 88%|████████▊ | 77/88 [27:53<03:53, 21.24s/epoch, loss=1.11, accuracy=0.757, val_loss=2.83, val_accuracy=0.399, lr=0.1] 89%|████████▊ | 78/88 [28:15<03:32, 21.30s/epoch, loss=1.11, accuracy=0.758, val_loss=3.76, val_accuracy=0.293, lr=0.0316] 90%|████████▉ | 79/88 [28:36<03:11, 21.25s/epoch, loss=1.11, accuracy=0.758, val_loss=3.7, val_accuracy=0.282, lr=0.1]     91%|█████████ | 80/88 [28:57<02:50, 21.34s/epoch, loss=1.11, accuracy=0.759, val_loss=2.39, val_accuracy=0.383, lr=0.1] 92%|█████████▏| 81/88 [29:18<02:27, 21.01s/epoch, loss=1.11, accuracy=0.757, val_loss=2.05, val_accuracy=0.498, lr=0.1] 93%|█████████▎| 82/88 [29:39<02:07, 21.17s/epoch, loss=0.922, accuracy=0.81, val_loss=0.958, val_accuracy=0.776, lr=0.01] 94%|█████████▍| 83/88 [30:01<01:46, 21.34s/epoch, loss=0.738, accuracy=0.848, val_loss=0.848, val_accuracy=0.799, lr=0.01] 95%|█████████▌| 84/88 [30:21<01:24, 21.12s/epoch, loss=0.663, accuracy=0.855, val_loss=0.802, val_accuracy=0.799, lr=0.01] 97%|█████████▋| 85/88 [30:43<01:04, 21.37s/epoch, loss=0.618, accuracy=0.858, val_loss=0.755, val_accuracy=0.806, lr=0.01] 98%|█████████▊| 86/88 [31:04<00:42, 21.15s/epoch, loss=0.59, accuracy=0.859, val_loss=0.86, val_accuracy=0.771, lr=0.01]   99%|█████████▉| 87/88 [31:25<00:21, 21.06s/epoch, loss=0.576, accuracy=0.863, val_loss=0.836, val_accuracy=0.782, lr=0.01]100%|██████████| 88/88 [31:46<00:00, 21.18s/epoch, loss=0.574, accuracy=0.861, val_loss=1.18, val_accuracy=0.693, lr=0.01] 100%|██████████| 88/88 [31:46<00:00, 21.67s/epoch, loss=0.574, accuracy=0.861, val_loss=1.18, val_accuracy=0.693, lr=0.01]
Using real-time data augmentation.
Test score: 0.7733532190322876
Test accuracy: 0.8069000244140625


* * * Run SGD for ID = 17_5. * * *


2024-02-20 00:31:21.312832: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 00:31:28.352868: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 00:31:28.354041: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-20 00:31:28.394165: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-20 00:31:28.394204: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 00:31:28.400568: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 00:31:28.400615: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-20 00:31:28.404237: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-20 00:31:28.406520: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-20 00:31:28.416278: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-20 00:31:28.419070: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-20 00:31:28.425245: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 00:31:28.425859: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-20 00:31:28.425939: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 00:31:30.039789: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-20 00:31:30.040740: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 00:31:30.041226: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-20 00:31:30.041260: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 00:31:30.041294: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 00:31:30.041316: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-20 00:31:30.041332: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-20 00:31:30.041349: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-20 00:31:30.041365: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-20 00:31:30.041382: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-20 00:31:30.041399: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 00:31:30.041894: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-20 00:31:30.041939: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 00:31:30.755714: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-20 00:31:30.755777: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-20 00:31:30.755787: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-20 00:31:30.757160: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:02:00.0, compute capability: 6.1)
{'id': '17_05', 'batch_size': 128, 'epochs': 88, 'validation_split': 0.1, 'checkpointing': True, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
x_train shape: (45000, 32, 32, 3)
45000 train samples
5000 validation samples
10000 test samples
y_train shape: (45000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/88 [00:00<?, ?epoch/s]2024-02-20 00:31:31.654736: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-20 00:31:31.667192: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199825000 Hz
2024-02-20 00:31:33.864558: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 00:31:34.121892: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 00:31:34.818381: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-20 00:31:34.872160: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/88 [00:57<1:23:13, 57.40s/epoch, loss=3.44, accuracy=0.299, val_loss=2.71, val_accuracy=0.196, lr=0.1]  2%|▏         | 2/88 [01:17<50:25, 35.19s/epoch, loss=1.61, accuracy=0.524, val_loss=1.8, val_accuracy=0.461, lr=0.1]     3%|▎         | 3/88 [01:36<39:50, 28.12s/epoch, loss=1.34, accuracy=0.638, val_loss=5.28, val_accuracy=0.235, lr=0.1]  5%|▍         | 4/88 [01:57<35:23, 25.28s/epoch, loss=1.27, accuracy=0.681, val_loss=2.9, val_accuracy=0.31, lr=0.1]    6%|▌         | 5/88 [02:18<32:50, 23.74s/epoch, loss=1.25, accuracy=0.7, val_loss=2.15, val_accuracy=0.493, lr=0.1]  7%|▋         | 6/88 [02:38<30:40, 22.44s/epoch, loss=1.24, accuracy=0.71, val_loss=1.57, val_accuracy=0.573, lr=0.1]  8%|▊         | 7/88 [02:58<29:06, 21.56s/epoch, loss=1.23, accuracy=0.718, val_loss=2.47, val_accuracy=0.482, lr=0.1]  9%|▉         | 8/88 [03:18<28:15, 21.19s/epoch, loss=1.23, accuracy=0.72, val_loss=1.89, val_accuracy=0.562, lr=0.1]  10%|█         | 9/88 [03:39<27:49, 21.14s/epoch, loss=1.22, accuracy=0.728, val_loss=1.82, val_accuracy=0.509, lr=0.1] 11%|█▏        | 10/88 [04:00<27:14, 20.95s/epoch, loss=1.22, accuracy=0.726, val_loss=1.49, val_accuracy=0.645, lr=0.1] 12%|█▎        | 11/88 [04:20<26:43, 20.83s/epoch, loss=1.21, accuracy=0.732, val_loss=1.87, val_accuracy=0.56, lr=0.1]  14%|█▎        | 12/88 [04:41<26:28, 20.89s/epoch, loss=1.2, accuracy=0.735, val_loss=1.94, val_accuracy=0.497, lr=0.1] 15%|█▍        | 13/88 [05:02<26:09, 20.92s/epoch, loss=1.2, accuracy=0.736, val_loss=1.57, val_accuracy=0.59, lr=0.1]  16%|█▌        | 14/88 [05:23<25:50, 20.95s/epoch, loss=1.19, accuracy=0.737, val_loss=2.03, val_accuracy=0.445, lr=0.1] 17%|█▋        | 15/88 [05:43<25:08, 20.66s/epoch, loss=1.2, accuracy=0.735, val_loss=2.61, val_accuracy=0.464, lr=0.0316] 18%|█▊        | 16/88 [06:04<24:41, 20.57s/epoch, loss=1.19, accuracy=0.738, val_loss=1.65, val_accuracy=0.604, lr=0.1]   19%|█▉        | 17/88 [06:25<24:37, 20.81s/epoch, loss=1.19, accuracy=0.742, val_loss=1.37, val_accuracy=0.691, lr=0.1] 20%|██        | 18/88 [06:44<23:45, 20.37s/epoch, loss=1.19, accuracy=0.74, val_loss=1.7, val_accuracy=0.596, lr=0.1]   22%|██▏       | 19/88 [07:04<23:18, 20.26s/epoch, loss=1.18, accuracy=0.746, val_loss=2.32, val_accuracy=0.376, lr=0.1] 23%|██▎       | 20/88 [07:26<23:15, 20.52s/epoch, loss=1.17, accuracy=0.742, val_loss=1.93, val_accuracy=0.541, lr=0.1] 24%|██▍       | 21/88 [07:47<23:03, 20.64s/epoch, loss=1.17, accuracy=0.747, val_loss=1.87, val_accuracy=0.571, lr=0.1] 25%|██▌       | 22/88 [08:08<22:57, 20.88s/epoch, loss=1.17, accuracy=0.744, val_loss=1.98, val_accuracy=0.54, lr=0.0316] 26%|██▌       | 23/88 [08:28<22:20, 20.62s/epoch, loss=1.18, accuracy=0.744, val_loss=1.64, val_accuracy=0.598, lr=0.1]   27%|██▋       | 24/88 [08:49<22:00, 20.63s/epoch, loss=1.18, accuracy=0.742, val_loss=2.31, val_accuracy=0.482, lr=0.1] 28%|██▊       | 25/88 [09:09<21:37, 20.60s/epoch, loss=1.17, accuracy=0.745, val_loss=2.4, val_accuracy=0.382, lr=0.1]  30%|██▉       | 26/88 [09:30<21:18, 20.61s/epoch, loss=1.18, accuracy=0.745, val_loss=1.56, val_accuracy=0.599, lr=0.1] 31%|███       | 27/88 [09:50<20:40, 20.34s/epoch, loss=1.18, accuracy=0.745, val_loss=1.74, val_accuracy=0.539, lr=0.0316] 32%|███▏      | 28/88 [10:10<20:22, 20.37s/epoch, loss=1.17, accuracy=0.748, val_loss=1.4, val_accuracy=0.675, lr=0.1]     33%|███▎      | 29/88 [10:31<20:13, 20.57s/epoch, loss=1.17, accuracy=0.748, val_loss=3.97, val_accuracy=0.343, lr=0.1] 34%|███▍      | 30/88 [10:51<19:36, 20.28s/epoch, loss=1.16, accuracy=0.751, val_loss=2.06, val_accuracy=0.464, lr=0.1] 35%|███▌      | 31/88 [11:12<19:32, 20.57s/epoch, loss=1.16, accuracy=0.749, val_loss=1.65, val_accuracy=0.587, lr=0.1] 36%|███▋      | 32/88 [11:33<19:17, 20.67s/epoch, loss=1.16, accuracy=0.753, val_loss=2.05, val_accuracy=0.507, lr=0.0316] 38%|███▊      | 33/88 [11:53<18:53, 20.62s/epoch, loss=1.16, accuracy=0.749, val_loss=4.02, val_accuracy=0.275, lr=0.1]    39%|███▊      | 34/88 [12:13<18:25, 20.48s/epoch, loss=1.17, accuracy=0.746, val_loss=3.02, val_accuracy=0.386, lr=0.1] 40%|███▉      | 35/88 [12:35<18:18, 20.72s/epoch, loss=1.16, accuracy=0.747, val_loss=2.07, val_accuracy=0.502, lr=0.1] 41%|████      | 36/88 [12:56<18:01, 20.79s/epoch, loss=1.16, accuracy=0.75, val_loss=1.59, val_accuracy=0.589, lr=0.1]  42%|████▏     | 37/88 [13:17<17:45, 20.89s/epoch, loss=1.17, accuracy=0.75, val_loss=1.81, val_accuracy=0.531, lr=0.0316] 43%|████▎     | 38/88 [13:38<17:25, 20.90s/epoch, loss=1.16, accuracy=0.752, val_loss=1.71, val_accuracy=0.567, lr=0.1]   44%|████▍     | 39/88 [13:58<16:56, 20.74s/epoch, loss=1.16, accuracy=0.752, val_loss=1.8, val_accuracy=0.527, lr=0.1]  45%|████▌     | 40/88 [14:18<16:24, 20.51s/epoch, loss=1.15, accuracy=0.755, val_loss=2.95, val_accuracy=0.426, lr=0.1] 47%|████▋     | 41/88 [14:38<15:51, 20.25s/epoch, loss=1.16, accuracy=0.752, val_loss=1.85, val_accuracy=0.526, lr=0.1] 48%|████▊     | 42/88 [14:59<15:41, 20.47s/epoch, loss=1.16, accuracy=0.752, val_loss=2.32, val_accuracy=0.444, lr=0.0316] 49%|████▉     | 43/88 [15:18<15:10, 20.23s/epoch, loss=1.16, accuracy=0.751, val_loss=2.18, val_accuracy=0.491, lr=0.1]    50%|█████     | 44/88 [15:39<14:56, 20.37s/epoch, loss=1.16, accuracy=0.751, val_loss=1.53, val_accuracy=0.633, lr=0.1] 51%|█████     | 45/88 [16:00<14:39, 20.45s/epoch, loss=1.15, accuracy=0.752, val_loss=1.76, val_accuracy=0.569, lr=0.1] 52%|█████▏    | 46/88 [16:21<14:23, 20.57s/epoch, loss=1.15, accuracy=0.752, val_loss=1.46, val_accuracy=0.657, lr=0.1] 53%|█████▎    | 47/88 [16:41<13:59, 20.47s/epoch, loss=1.15, accuracy=0.754, val_loss=1.83, val_accuracy=0.558, lr=0.0316] 55%|█████▍    | 48/88 [17:00<13:28, 20.20s/epoch, loss=1.16, accuracy=0.755, val_loss=1.65, val_accuracy=0.579, lr=0.1]    56%|█████▌    | 49/88 [17:22<13:22, 20.57s/epoch, loss=1.16, accuracy=0.752, val_loss=2.21, val_accuracy=0.381, lr=0.1] 57%|█████▋    | 50/88 [17:42<12:55, 20.39s/epoch, loss=1.15, accuracy=0.755, val_loss=2.13, val_accuracy=0.48, lr=0.1]  58%|█████▊    | 51/88 [18:01<12:25, 20.16s/epoch, loss=1.15, accuracy=0.755, val_loss=1.89, val_accuracy=0.507, lr=0.1] 59%|█████▉    | 52/88 [18:22<12:12, 20.35s/epoch, loss=1.14, accuracy=0.752, val_loss=2.66, val_accuracy=0.425, lr=0.0316] 60%|██████    | 53/88 [18:43<12:00, 20.58s/epoch, loss=1.15, accuracy=0.753, val_loss=1.5, val_accuracy=0.649, lr=0.1]     61%|██████▏   | 54/88 [19:04<11:39, 20.59s/epoch, loss=1.15, accuracy=0.753, val_loss=1.63, val_accuracy=0.612, lr=0.1] 62%|██████▎   | 55/88 [19:25<11:24, 20.73s/epoch, loss=1.15, accuracy=0.752, val_loss=1.37, val_accuracy=0.673, lr=0.1] 64%|██████▎   | 56/88 [19:46<11:05, 20.78s/epoch, loss=1.14, accuracy=0.754, val_loss=2.83, val_accuracy=0.311, lr=0.1] 65%|██████▍   | 57/88 [20:05<10:29, 20.31s/epoch, loss=1.14, accuracy=0.756, val_loss=1.83, val_accuracy=0.509, lr=0.0316] 66%|██████▌   | 58/88 [20:26<10:15, 20.50s/epoch, loss=1.15, accuracy=0.754, val_loss=2.15, val_accuracy=0.462, lr=0.1]    67%|██████▋   | 59/88 [20:47<09:57, 20.60s/epoch, loss=1.14, accuracy=0.756, val_loss=2.31, val_accuracy=0.462, lr=0.1] 68%|██████▊   | 60/88 [21:07<09:35, 20.57s/epoch, loss=1.14, accuracy=0.753, val_loss=4.39, val_accuracy=0.339, lr=0.1] 69%|██████▉   | 61/88 [21:28<09:15, 20.59s/epoch, loss=1.15, accuracy=0.753, val_loss=1.74, val_accuracy=0.605, lr=0.1] 70%|███████   | 62/88 [21:48<08:53, 20.53s/epoch, loss=1.15, accuracy=0.753, val_loss=1.75, val_accuracy=0.543, lr=0.0316] 72%|███████▏  | 63/88 [22:09<08:34, 20.57s/epoch, loss=1.14, accuracy=0.754, val_loss=1.7, val_accuracy=0.578, lr=0.1]     73%|███████▎  | 64/88 [22:30<08:14, 20.61s/epoch, loss=1.14, accuracy=0.756, val_loss=1.51, val_accuracy=0.646, lr=0.1] 74%|███████▍  | 65/88 [22:50<07:54, 20.64s/epoch, loss=1.14, accuracy=0.755, val_loss=1.67, val_accuracy=0.601, lr=0.1] 75%|███████▌  | 66/88 [23:11<07:33, 20.62s/epoch, loss=1.15, accuracy=0.754, val_loss=1.92, val_accuracy=0.515, lr=0.1] 76%|███████▌  | 67/88 [23:30<07:04, 20.21s/epoch, loss=1.14, accuracy=0.757, val_loss=1.96, val_accuracy=0.52, lr=0.0316] 77%|███████▋  | 68/88 [23:50<06:41, 20.06s/epoch, loss=1.14, accuracy=0.756, val_loss=2.01, val_accuracy=0.496, lr=0.1]   78%|███████▊  | 69/88 [24:11<06:24, 20.24s/epoch, loss=1.14, accuracy=0.755, val_loss=1.83, val_accuracy=0.612, lr=0.1] 80%|███████▉  | 70/88 [24:31<06:04, 20.23s/epoch, loss=1.14, accuracy=0.753, val_loss=2.39, val_accuracy=0.457, lr=0.1] 81%|████████  | 71/88 [24:51<05:43, 20.19s/epoch, loss=1.13, accuracy=0.757, val_loss=2.29, val_accuracy=0.393, lr=0.1] 82%|████████▏ | 72/88 [25:10<05:18, 19.92s/epoch, loss=1.14, accuracy=0.756, val_loss=1.89, val_accuracy=0.55, lr=0.0316] 83%|████████▎ | 73/88 [25:30<04:58, 19.91s/epoch, loss=1.13, accuracy=0.756, val_loss=2.37, val_accuracy=0.469, lr=0.1]   84%|████████▍ | 74/88 [25:51<04:41, 20.13s/epoch, loss=1.14, accuracy=0.759, val_loss=2.46, val_accuracy=0.43, lr=0.1]  85%|████████▌ | 75/88 [26:10<04:19, 19.95s/epoch, loss=1.13, accuracy=0.757, val_loss=1.72, val_accuracy=0.576, lr=0.1] 86%|████████▋ | 76/88 [26:31<04:01, 20.16s/epoch, loss=1.13, accuracy=0.756, val_loss=1.91, val_accuracy=0.505, lr=0.1] 88%|████████▊ | 77/88 [26:50<03:38, 19.88s/epoch, loss=1.13, accuracy=0.756, val_loss=1.86, val_accuracy=0.494, lr=0.0316] 89%|████████▊ | 78/88 [27:11<03:21, 20.14s/epoch, loss=1.13, accuracy=0.756, val_loss=3.09, val_accuracy=0.351, lr=0.1]    90%|████████▉ | 79/88 [27:32<03:02, 20.31s/epoch, loss=1.13, accuracy=0.76, val_loss=2.27, val_accuracy=0.525, lr=0.1]  91%|█████████ | 80/88 [27:51<02:41, 20.16s/epoch, loss=1.14, accuracy=0.755, val_loss=1.83, val_accuracy=0.564, lr=0.1] 92%|█████████▏| 81/88 [28:12<02:21, 20.28s/epoch, loss=1.14, accuracy=0.756, val_loss=1.89, val_accuracy=0.563, lr=0.1] 93%|█████████▎| 82/88 [28:32<02:00, 20.14s/epoch, loss=0.939, accuracy=0.812, val_loss=0.98, val_accuracy=0.784, lr=0.01] 94%|█████████▍| 83/88 [28:52<01:40, 20.16s/epoch, loss=0.757, accuracy=0.848, val_loss=0.809, val_accuracy=0.815, lr=0.01] 95%|█████████▌| 84/88 [29:11<01:19, 19.96s/epoch, loss=0.671, accuracy=0.857, val_loss=0.74, val_accuracy=0.825, lr=0.01]  97%|█████████▋| 85/88 [29:31<00:59, 19.74s/epoch, loss=0.619, accuracy=0.862, val_loss=0.849, val_accuracy=0.78, lr=0.01] 98%|█████████▊| 86/88 [29:51<00:39, 19.92s/epoch, loss=0.591, accuracy=0.862, val_loss=0.787, val_accuracy=0.787, lr=0.01] 99%|█████████▉| 87/88 [30:11<00:20, 20.07s/epoch, loss=0.578, accuracy=0.864, val_loss=0.76, val_accuracy=0.801, lr=0.01] 100%|██████████| 88/88 [30:31<00:00, 19.95s/epoch, loss=0.57, accuracy=0.866, val_loss=0.811, val_accuracy=0.792, lr=0.01]100%|██████████| 88/88 [30:31<00:00, 20.81s/epoch, loss=0.57, accuracy=0.866, val_loss=0.811, val_accuracy=0.792, lr=0.01]
Using real-time data augmentation.
Test score: 0.7377286553382874
Test accuracy: 0.8230999708175659


* * * Run SGD for ID = 17_6. * * *


2024-02-20 01:02:10.311185: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 01:02:14.440955: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 01:02:14.442015: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-20 01:02:14.479970: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-20 01:02:14.480015: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 01:02:14.485234: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 01:02:14.485278: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-20 01:02:14.487881: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-20 01:02:14.490134: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-20 01:02:14.493146: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-20 01:02:14.498585: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-20 01:02:14.504048: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 01:02:14.504611: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-20 01:02:14.504693: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 01:02:15.986669: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-20 01:02:15.987772: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 01:02:15.988545: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-20 01:02:15.988579: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 01:02:15.988614: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 01:02:15.988631: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-20 01:02:15.988649: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-20 01:02:15.988666: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-20 01:02:15.988682: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-20 01:02:15.988699: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-20 01:02:15.988715: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 01:02:15.989177: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-20 01:02:15.989210: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 01:02:16.624733: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-20 01:02:16.624800: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-20 01:02:16.624813: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-20 01:02:16.625736: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:02:00.0, compute capability: 6.1)
{'id': '17_06', 'batch_size': 128, 'epochs': 88, 'validation_split': 0.1, 'checkpointing': True, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
x_train shape: (45000, 32, 32, 3)
45000 train samples
5000 validation samples
10000 test samples
y_train shape: (45000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/88 [00:00<?, ?epoch/s]2024-02-20 01:02:17.437445: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-20 01:02:17.449167: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199825000 Hz
2024-02-20 01:02:19.431758: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 01:02:19.677523: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 01:02:20.405688: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-20 01:02:20.455706: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/88 [00:55<1:20:28, 55.50s/epoch, loss=3.37, accuracy=0.276, val_loss=2.61, val_accuracy=0.139, lr=0.1]  2%|▏         | 2/88 [01:16<50:48, 35.44s/epoch, loss=1.63, accuracy=0.509, val_loss=1.92, val_accuracy=0.428, lr=0.1]    3%|▎         | 3/88 [01:37<40:28, 28.57s/epoch, loss=1.38, accuracy=0.624, val_loss=1.69, val_accuracy=0.549, lr=0.1]  5%|▍         | 4/88 [01:57<35:09, 25.11s/epoch, loss=1.3, accuracy=0.675, val_loss=1.92, val_accuracy=0.527, lr=0.1]   6%|▌         | 5/88 [02:17<32:13, 23.30s/epoch, loss=1.26, accuracy=0.696, val_loss=1.68, val_accuracy=0.577, lr=0.1]  7%|▋         | 6/88 [02:36<30:03, 21.99s/epoch, loss=1.24, accuracy=0.709, val_loss=2.36, val_accuracy=0.397, lr=0.1]  8%|▊         | 7/88 [02:56<28:44, 21.29s/epoch, loss=1.23, accuracy=0.715, val_loss=1.76, val_accuracy=0.535, lr=0.1]  9%|▉         | 8/88 [03:17<28:23, 21.29s/epoch, loss=1.22, accuracy=0.723, val_loss=2.28, val_accuracy=0.433, lr=0.1] 10%|█         | 9/88 [03:39<28:07, 21.36s/epoch, loss=1.21, accuracy=0.725, val_loss=2.04, val_accuracy=0.479, lr=0.1] 11%|█▏        | 10/88 [04:00<27:42, 21.31s/epoch, loss=1.21, accuracy=0.731, val_loss=1.84, val_accuracy=0.523, lr=0.0316] 12%|█▎        | 11/88 [04:21<27:19, 21.30s/epoch, loss=1.2, accuracy=0.733, val_loss=2, val_accuracy=0.516, lr=0.1]        14%|█▎        | 12/88 [04:43<27:10, 21.45s/epoch, loss=1.2, accuracy=0.735, val_loss=1.63, val_accuracy=0.596, lr=0.1] 15%|█▍        | 13/88 [05:04<26:30, 21.21s/epoch, loss=1.19, accuracy=0.737, val_loss=1.64, val_accuracy=0.596, lr=0.1] 16%|█▌        | 14/88 [05:25<26:04, 21.14s/epoch, loss=1.2, accuracy=0.736, val_loss=1.87, val_accuracy=0.546, lr=0.1]  17%|█▋        | 15/88 [05:46<25:46, 21.18s/epoch, loss=1.19, accuracy=0.74, val_loss=2.15, val_accuracy=0.488, lr=0.1] 18%|█▊        | 16/88 [06:08<25:32, 21.29s/epoch, loss=1.19, accuracy=0.74, val_loss=1.59, val_accuracy=0.64, lr=0.1]  19%|█▉        | 17/88 [06:29<25:05, 21.21s/epoch, loss=1.18, accuracy=0.744, val_loss=1.53, val_accuracy=0.612, lr=0.1] 20%|██        | 18/88 [06:50<24:48, 21.27s/epoch, loss=1.19, accuracy=0.744, val_loss=3.62, val_accuracy=0.252, lr=0.1] 22%|██▏       | 19/88 [07:11<24:30, 21.31s/epoch, loss=1.18, accuracy=0.746, val_loss=1.94, val_accuracy=0.51, lr=0.1]  23%|██▎       | 20/88 [07:33<24:09, 21.32s/epoch, loss=1.17, accuracy=0.746, val_loss=1.73, val_accuracy=0.553, lr=0.1] 24%|██▍       | 21/88 [07:53<23:20, 20.91s/epoch, loss=1.18, accuracy=0.744, val_loss=1.56, val_accuracy=0.622, lr=0.1] 25%|██▌       | 22/88 [08:14<23:04, 20.98s/epoch, loss=1.17, accuracy=0.747, val_loss=1.99, val_accuracy=0.474, lr=0.0316] 26%|██▌       | 23/88 [08:35<22:42, 20.96s/epoch, loss=1.17, accuracy=0.746, val_loss=1.6, val_accuracy=0.603, lr=0.1]     27%|██▋       | 24/88 [08:56<22:25, 21.03s/epoch, loss=1.18, accuracy=0.746, val_loss=2.14, val_accuracy=0.481, lr=0.1] 28%|██▊       | 25/88 [09:17<21:56, 20.90s/epoch, loss=1.17, accuracy=0.746, val_loss=2.75, val_accuracy=0.282, lr=0.1] 30%|██▉       | 26/88 [09:38<21:38, 20.94s/epoch, loss=1.17, accuracy=0.747, val_loss=1.72, val_accuracy=0.547, lr=0.1] 31%|███       | 27/88 [09:59<21:25, 21.08s/epoch, loss=1.17, accuracy=0.748, val_loss=2.81, val_accuracy=0.379, lr=0.0316] 32%|███▏      | 28/88 [10:20<21:10, 21.18s/epoch, loss=1.17, accuracy=0.747, val_loss=1.9, val_accuracy=0.534, lr=0.1]     33%|███▎      | 29/88 [10:41<20:44, 21.10s/epoch, loss=1.16, accuracy=0.749, val_loss=2.75, val_accuracy=0.42, lr=0.1] 34%|███▍      | 30/88 [11:02<20:21, 21.06s/epoch, loss=1.16, accuracy=0.752, val_loss=5.3, val_accuracy=0.199, lr=0.1] 35%|███▌      | 31/88 [11:23<20:02, 21.09s/epoch, loss=1.15, accuracy=0.751, val_loss=2.05, val_accuracy=0.579, lr=0.1] 36%|███▋      | 32/88 [11:44<19:40, 21.07s/epoch, loss=1.17, accuracy=0.749, val_loss=1.69, val_accuracy=0.588, lr=0.0316] 38%|███▊      | 33/88 [12:05<19:08, 20.89s/epoch, loss=1.16, accuracy=0.751, val_loss=1.59, val_accuracy=0.604, lr=0.1]    39%|███▊      | 34/88 [12:26<18:56, 21.05s/epoch, loss=1.16, accuracy=0.752, val_loss=2.23, val_accuracy=0.442, lr=0.1] 40%|███▉      | 35/88 [12:47<18:35, 21.04s/epoch, loss=1.16, accuracy=0.75, val_loss=1.93, val_accuracy=0.477, lr=0.1]  41%|████      | 36/88 [13:09<18:17, 21.10s/epoch, loss=1.15, accuracy=0.753, val_loss=1.74, val_accuracy=0.569, lr=0.1] 42%|████▏     | 37/88 [13:29<17:43, 20.84s/epoch, loss=1.16, accuracy=0.751, val_loss=1.51, val_accuracy=0.63, lr=0.1]  43%|████▎     | 38/88 [13:50<17:28, 20.98s/epoch, loss=1.14, accuracy=0.756, val_loss=2.02, val_accuracy=0.489, lr=0.1] 44%|████▍     | 39/88 [14:11<17:13, 21.08s/epoch, loss=1.15, accuracy=0.752, val_loss=1.83, val_accuracy=0.529, lr=0.1] 45%|████▌     | 40/88 [14:33<16:56, 21.17s/epoch, loss=1.15, accuracy=0.751, val_loss=1.95, val_accuracy=0.557, lr=0.1] 47%|████▋     | 41/88 [14:53<16:20, 20.85s/epoch, loss=1.15, accuracy=0.753, val_loss=2.66, val_accuracy=0.448, lr=0.1] 48%|████▊     | 42/88 [15:14<15:56, 20.80s/epoch, loss=1.15, accuracy=0.753, val_loss=2.87, val_accuracy=0.225, lr=0.0316] 49%|████▉     | 43/88 [15:35<15:45, 21.01s/epoch, loss=1.15, accuracy=0.755, val_loss=2.36, val_accuracy=0.398, lr=0.1]    50%|█████     | 44/88 [15:57<15:32, 21.18s/epoch, loss=1.15, accuracy=0.754, val_loss=1.91, val_accuracy=0.497, lr=0.1] 51%|█████     | 45/88 [16:17<14:55, 20.83s/epoch, loss=1.14, accuracy=0.753, val_loss=1.63, val_accuracy=0.603, lr=0.1] 52%|█████▏    | 46/88 [16:38<14:38, 20.91s/epoch, loss=1.15, accuracy=0.755, val_loss=1.81, val_accuracy=0.508, lr=0.1] 53%|█████▎    | 47/88 [16:58<14:10, 20.74s/epoch, loss=1.14, accuracy=0.757, val_loss=1.64, val_accuracy=0.638, lr=0.0316] 55%|█████▍    | 48/88 [17:19<13:45, 20.63s/epoch, loss=1.15, accuracy=0.755, val_loss=2.98, val_accuracy=0.341, lr=0.1]    56%|█████▌    | 49/88 [17:40<13:30, 20.77s/epoch, loss=1.14, accuracy=0.753, val_loss=2.65, val_accuracy=0.406, lr=0.1] 57%|█████▋    | 50/88 [18:01<13:18, 21.01s/epoch, loss=1.14, accuracy=0.754, val_loss=2.46, val_accuracy=0.338, lr=0.1] 58%|█████▊    | 51/88 [18:23<13:02, 21.14s/epoch, loss=1.14, accuracy=0.754, val_loss=3.05, val_accuracy=0.404, lr=0.1] 59%|█████▉    | 52/88 [18:44<12:42, 21.19s/epoch, loss=1.14, accuracy=0.755, val_loss=3.09, val_accuracy=0.411, lr=0.0316] 60%|██████    | 53/88 [19:06<12:28, 21.37s/epoch, loss=1.14, accuracy=0.752, val_loss=2.37, val_accuracy=0.47, lr=0.1]     61%|██████▏   | 54/88 [19:26<11:51, 20.94s/epoch, loss=1.14, accuracy=0.758, val_loss=1.69, val_accuracy=0.576, lr=0.1] 62%|██████▎   | 55/88 [19:47<11:34, 21.04s/epoch, loss=1.14, accuracy=0.757, val_loss=2.55, val_accuracy=0.425, lr=0.1] 64%|██████▎   | 56/88 [20:08<11:15, 21.11s/epoch, loss=1.13, accuracy=0.756, val_loss=3.19, val_accuracy=0.281, lr=0.1] 65%|██████▍   | 57/88 [20:30<10:57, 21.22s/epoch, loss=1.14, accuracy=0.755, val_loss=2.11, val_accuracy=0.492, lr=0.0316] 66%|██████▌   | 58/88 [20:50<10:25, 20.85s/epoch, loss=1.13, accuracy=0.757, val_loss=2.83, val_accuracy=0.331, lr=0.1]    67%|██████▋   | 59/88 [21:10<09:57, 20.61s/epoch, loss=1.15, accuracy=0.753, val_loss=4.35, val_accuracy=0.219, lr=0.1] 68%|██████▊   | 60/88 [21:31<09:40, 20.74s/epoch, loss=1.14, accuracy=0.755, val_loss=1.59, val_accuracy=0.605, lr=0.1] 69%|██████▉   | 61/88 [21:51<09:13, 20.52s/epoch, loss=1.15, accuracy=0.755, val_loss=2.02, val_accuracy=0.482, lr=0.1] 70%|███████   | 62/88 [22:11<08:54, 20.57s/epoch, loss=1.14, accuracy=0.756, val_loss=2.2, val_accuracy=0.416, lr=0.0316] 72%|███████▏  | 63/88 [22:33<08:38, 20.75s/epoch, loss=1.14, accuracy=0.756, val_loss=2.61, val_accuracy=0.451, lr=0.1]   73%|███████▎  | 64/88 [22:53<08:18, 20.77s/epoch, loss=1.13, accuracy=0.756, val_loss=1.94, val_accuracy=0.534, lr=0.1] 74%|███████▍  | 65/88 [23:14<07:58, 20.82s/epoch, loss=1.13, accuracy=0.755, val_loss=2.1, val_accuracy=0.482, lr=0.1]  75%|███████▌  | 66/88 [23:35<07:38, 20.83s/epoch, loss=1.13, accuracy=0.755, val_loss=2.11, val_accuracy=0.435, lr=0.1] 76%|███████▌  | 67/88 [23:57<07:20, 20.98s/epoch, loss=1.14, accuracy=0.753, val_loss=1.62, val_accuracy=0.613, lr=0.0316] 77%|███████▋  | 68/88 [24:18<07:00, 21.02s/epoch, loss=1.13, accuracy=0.758, val_loss=2.14, val_accuracy=0.476, lr=0.1]    78%|███████▊  | 69/88 [24:39<06:40, 21.09s/epoch, loss=1.14, accuracy=0.757, val_loss=1.86, val_accuracy=0.535, lr=0.1] 80%|███████▉  | 70/88 [25:00<06:21, 21.21s/epoch, loss=1.13, accuracy=0.756, val_loss=1.71, val_accuracy=0.56, lr=0.1]  81%|████████  | 71/88 [25:22<06:00, 21.18s/epoch, loss=1.13, accuracy=0.756, val_loss=2.64, val_accuracy=0.423, lr=0.1] 82%|████████▏ | 72/88 [25:43<05:38, 21.17s/epoch, loss=1.14, accuracy=0.756, val_loss=2.38, val_accuracy=0.415, lr=0.0316] 83%|████████▎ | 73/88 [26:03<05:12, 20.81s/epoch, loss=1.13, accuracy=0.759, val_loss=1.97, val_accuracy=0.466, lr=0.1]    84%|████████▍ | 74/88 [26:24<04:52, 20.90s/epoch, loss=1.13, accuracy=0.758, val_loss=2.66, val_accuracy=0.412, lr=0.1] 85%|████████▌ | 75/88 [26:45<04:32, 20.95s/epoch, loss=1.13, accuracy=0.755, val_loss=1.96, val_accuracy=0.506, lr=0.1] 86%|████████▋ | 76/88 [27:06<04:12, 21.01s/epoch, loss=1.13, accuracy=0.758, val_loss=1.79, val_accuracy=0.535, lr=0.1] 88%|████████▊ | 77/88 [27:26<03:49, 20.84s/epoch, loss=1.14, accuracy=0.757, val_loss=1.62, val_accuracy=0.61, lr=0.0316] 89%|████████▊ | 78/88 [27:48<03:30, 21.04s/epoch, loss=1.13, accuracy=0.756, val_loss=4.49, val_accuracy=0.321, lr=0.1]   90%|████████▉ | 79/88 [28:08<03:07, 20.82s/epoch, loss=1.13, accuracy=0.758, val_loss=3.56, val_accuracy=0.357, lr=0.1] 91%|█████████ | 80/88 [28:28<02:44, 20.59s/epoch, loss=1.14, accuracy=0.757, val_loss=2.13, val_accuracy=0.402, lr=0.1] 92%|█████████▏| 81/88 [28:49<02:25, 20.78s/epoch, loss=1.13, accuracy=0.759, val_loss=2.1, val_accuracy=0.446, lr=0.1]  93%|█████████▎| 82/88 [29:11<02:05, 20.92s/epoch, loss=0.933, accuracy=0.813, val_loss=0.901, val_accuracy=0.807, lr=0.01] 94%|█████████▍| 83/88 [29:32<01:45, 21.09s/epoch, loss=0.747, accuracy=0.848, val_loss=0.796, val_accuracy=0.82, lr=0.01]  95%|█████████▌| 84/88 [29:52<01:23, 20.81s/epoch, loss=0.665, accuracy=0.856, val_loss=0.749, val_accuracy=0.82, lr=0.01] 97%|█████████▋| 85/88 [30:13<01:02, 20.77s/epoch, loss=0.613, accuracy=0.862, val_loss=0.769, val_accuracy=0.809, lr=0.01] 98%|█████████▊| 86/88 [30:35<00:42, 21.00s/epoch, loss=0.588, accuracy=0.864, val_loss=0.925, val_accuracy=0.749, lr=0.01] 99%|█████████▉| 87/88 [30:56<00:20, 20.99s/epoch, loss=0.577, accuracy=0.863, val_loss=0.776, val_accuracy=0.798, lr=0.01]100%|██████████| 88/88 [31:16<00:00, 20.86s/epoch, loss=0.57, accuracy=0.865, val_loss=0.91, val_accuracy=0.773, lr=0.01]  100%|██████████| 88/88 [31:16<00:00, 21.33s/epoch, loss=0.57, accuracy=0.865, val_loss=0.91, val_accuracy=0.773, lr=0.01]
Using real-time data augmentation.
Test score: 0.7684046626091003
Test accuracy: 0.8141999840736389


* * * Run SGD for ID = 17_7. * * *


2024-02-20 01:33:42.358623: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 01:33:47.219717: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 01:33:47.220751: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-20 01:33:47.261214: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-20 01:33:47.261250: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 01:33:47.265922: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 01:33:47.265966: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-20 01:33:47.269165: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-20 01:33:47.270682: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-20 01:33:47.273719: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-20 01:33:47.276377: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-20 01:33:47.282103: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 01:33:47.282645: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-20 01:33:47.282719: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 01:33:48.770773: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-20 01:33:48.771821: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 01:33:48.772593: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-20 01:33:48.772634: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 01:33:48.772670: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 01:33:48.772688: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-20 01:33:48.772705: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-20 01:33:48.772722: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-20 01:33:48.772738: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-20 01:33:48.772754: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-20 01:33:48.772770: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 01:33:48.773217: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-20 01:33:48.773250: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 01:33:49.404470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-20 01:33:49.404538: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-20 01:33:49.404552: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-20 01:33:49.405495: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:02:00.0, compute capability: 6.1)
{'id': '17_07', 'batch_size': 128, 'epochs': 88, 'validation_split': 0.1, 'checkpointing': True, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
x_train shape: (45000, 32, 32, 3)
45000 train samples
5000 validation samples
10000 test samples
y_train shape: (45000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/88 [00:00<?, ?epoch/s]2024-02-20 01:33:50.214220: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-20 01:33:50.226177: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199825000 Hz
2024-02-20 01:33:52.191736: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 01:33:52.476703: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 01:33:53.248602: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-20 01:33:53.303796: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/88 [00:58<1:25:30, 58.98s/epoch, loss=3.32, accuracy=0.3, val_loss=2.78, val_accuracy=0.179, lr=0.1]  2%|▏         | 2/88 [01:18<51:25, 35.88s/epoch, loss=1.69, accuracy=0.474, val_loss=2.17, val_accuracy=0.35, lr=0.1]   3%|▎         | 3/88 [01:38<40:41, 28.73s/epoch, loss=1.47, accuracy=0.575, val_loss=1.98, val_accuracy=0.467, lr=0.1]  5%|▍         | 4/88 [01:58<35:10, 25.13s/epoch, loss=1.36, accuracy=0.648, val_loss=1.92, val_accuracy=0.524, lr=0.1]  6%|▌         | 5/88 [02:19<32:48, 23.72s/epoch, loss=1.29, accuracy=0.682, val_loss=1.74, val_accuracy=0.527, lr=0.1]  7%|▋         | 6/88 [02:40<30:59, 22.68s/epoch, loss=1.27, accuracy=0.699, val_loss=2.04, val_accuracy=0.461, lr=0.1]  8%|▊         | 7/88 [03:01<30:00, 22.23s/epoch, loss=1.26, accuracy=0.708, val_loss=1.67, val_accuracy=0.572, lr=0.1]  9%|▉         | 8/88 [03:22<29:03, 21.80s/epoch, loss=1.25, accuracy=0.714, val_loss=1.53, val_accuracy=0.613, lr=0.1] 10%|█         | 9/88 [03:42<27:44, 21.06s/epoch, loss=1.23, accuracy=0.722, val_loss=2.52, val_accuracy=0.48, lr=0.1]  11%|█▏        | 10/88 [04:03<27:26, 21.11s/epoch, loss=1.22, accuracy=0.724, val_loss=2.17, val_accuracy=0.51, lr=0.1] 12%|█▎        | 11/88 [04:24<27:01, 21.05s/epoch, loss=1.21, accuracy=0.731, val_loss=1.61, val_accuracy=0.589, lr=0.1] 14%|█▎        | 12/88 [04:44<26:27, 20.89s/epoch, loss=1.21, accuracy=0.733, val_loss=1.91, val_accuracy=0.495, lr=0.1] 15%|█▍        | 13/88 [05:05<26:07, 20.91s/epoch, loss=1.21, accuracy=0.731, val_loss=1.55, val_accuracy=0.613, lr=0.0316] 16%|█▌        | 14/88 [05:26<25:51, 20.96s/epoch, loss=1.21, accuracy=0.735, val_loss=3.31, val_accuracy=0.338, lr=0.1]    17%|█▋        | 15/88 [05:47<25:15, 20.77s/epoch, loss=1.2, accuracy=0.739, val_loss=1.88, val_accuracy=0.528, lr=0.1]  18%|█▊        | 16/88 [06:07<24:44, 20.61s/epoch, loss=1.2, accuracy=0.738, val_loss=2.12, val_accuracy=0.45, lr=0.1]  19%|█▉        | 17/88 [06:28<24:32, 20.74s/epoch, loss=1.2, accuracy=0.738, val_loss=1.87, val_accuracy=0.508, lr=0.1] 20%|██        | 18/88 [06:49<24:18, 20.84s/epoch, loss=1.19, accuracy=0.741, val_loss=2.07, val_accuracy=0.492, lr=0.0316] 22%|██▏       | 19/88 [07:10<24:02, 20.91s/epoch, loss=1.19, accuracy=0.744, val_loss=1.93, val_accuracy=0.555, lr=0.1]    23%|██▎       | 20/88 [07:30<23:24, 20.65s/epoch, loss=1.19, accuracy=0.744, val_loss=1.73, val_accuracy=0.576, lr=0.1] 24%|██▍       | 21/88 [07:50<22:45, 20.38s/epoch, loss=1.19, accuracy=0.742, val_loss=2.16, val_accuracy=0.465, lr=0.1] 25%|██▌       | 22/88 [08:10<22:14, 20.22s/epoch, loss=1.18, accuracy=0.743, val_loss=2.13, val_accuracy=0.456, lr=0.1] 26%|██▌       | 23/88 [08:31<22:10, 20.47s/epoch, loss=1.17, accuracy=0.747, val_loss=2.44, val_accuracy=0.479, lr=0.0316] 27%|██▋       | 24/88 [08:52<21:58, 20.59s/epoch, loss=1.18, accuracy=0.746, val_loss=2.03, val_accuracy=0.528, lr=0.1]    28%|██▊       | 25/88 [09:13<21:49, 20.79s/epoch, loss=1.17, accuracy=0.749, val_loss=2.3, val_accuracy=0.472, lr=0.1]  30%|██▉       | 26/88 [09:34<21:41, 20.99s/epoch, loss=1.17, accuracy=0.747, val_loss=1.51, val_accuracy=0.643, lr=0.1] 31%|███       | 27/88 [09:54<20:52, 20.53s/epoch, loss=1.18, accuracy=0.747, val_loss=2.54, val_accuracy=0.385, lr=0.1] 32%|███▏      | 28/88 [10:13<20:18, 20.31s/epoch, loss=1.17, accuracy=0.749, val_loss=1.66, val_accuracy=0.595, lr=0.1] 33%|███▎      | 29/88 [10:35<20:13, 20.56s/epoch, loss=1.16, accuracy=0.75, val_loss=1.45, val_accuracy=0.639, lr=0.1]  34%|███▍      | 30/88 [10:56<20:03, 20.74s/epoch, loss=1.18, accuracy=0.748, val_loss=2.58, val_accuracy=0.447, lr=0.1] 35%|███▌      | 31/88 [11:16<19:32, 20.57s/epoch, loss=1.16, accuracy=0.753, val_loss=1.77, val_accuracy=0.579, lr=0.1] 36%|███▋      | 32/88 [11:36<18:58, 20.33s/epoch, loss=1.16, accuracy=0.751, val_loss=2.19, val_accuracy=0.468, lr=0.1] 38%|███▊      | 33/88 [11:56<18:33, 20.25s/epoch, loss=1.16, accuracy=0.752, val_loss=1.66, val_accuracy=0.608, lr=0.1] 39%|███▊      | 34/88 [12:17<18:28, 20.53s/epoch, loss=1.17, accuracy=0.751, val_loss=1.45, val_accuracy=0.65, lr=0.0316] 40%|███▉      | 35/88 [12:38<18:13, 20.63s/epoch, loss=1.16, accuracy=0.751, val_loss=1.77, val_accuracy=0.566, lr=0.1]   41%|████      | 36/88 [12:57<17:36, 20.31s/epoch, loss=1.16, accuracy=0.751, val_loss=1.74, val_accuracy=0.519, lr=0.1] 42%|████▏     | 37/88 [13:18<17:13, 20.26s/epoch, loss=1.16, accuracy=0.751, val_loss=1.67, val_accuracy=0.582, lr=0.1] 43%|████▎     | 38/88 [13:38<16:59, 20.40s/epoch, loss=1.16, accuracy=0.753, val_loss=2.83, val_accuracy=0.403, lr=0.1] 44%|████▍     | 39/88 [13:58<16:30, 20.21s/epoch, loss=1.16, accuracy=0.752, val_loss=1.82, val_accuracy=0.569, lr=0.0316] 45%|████▌     | 40/88 [14:19<16:25, 20.52s/epoch, loss=1.16, accuracy=0.753, val_loss=1.97, val_accuracy=0.554, lr=0.1]    47%|████▋     | 41/88 [14:40<16:11, 20.68s/epoch, loss=1.16, accuracy=0.753, val_loss=2.78, val_accuracy=0.367, lr=0.1] 48%|████▊     | 42/88 [15:00<15:38, 20.41s/epoch, loss=1.17, accuracy=0.751, val_loss=1.57, val_accuracy=0.641, lr=0.1] 49%|████▉     | 43/88 [15:21<15:24, 20.55s/epoch, loss=1.16, accuracy=0.754, val_loss=2.14, val_accuracy=0.487, lr=0.1] 50%|█████     | 44/88 [15:42<15:12, 20.73s/epoch, loss=1.16, accuracy=0.75, val_loss=2.18, val_accuracy=0.475, lr=0.0316] 51%|█████     | 45/88 [16:03<14:56, 20.85s/epoch, loss=1.15, accuracy=0.752, val_loss=2.8, val_accuracy=0.359, lr=0.1]    52%|█████▏    | 46/88 [16:24<14:39, 20.94s/epoch, loss=1.15, accuracy=0.757, val_loss=3.46, val_accuracy=0.364, lr=0.1] 53%|█████▎    | 47/88 [16:45<14:08, 20.69s/epoch, loss=1.15, accuracy=0.755, val_loss=1.92, val_accuracy=0.521, lr=0.1] 55%|█████▍    | 48/88 [17:06<13:51, 20.79s/epoch, loss=1.15, accuracy=0.756, val_loss=2.1, val_accuracy=0.452, lr=0.1]  56%|█████▌    | 49/88 [17:25<13:15, 20.40s/epoch, loss=1.15, accuracy=0.754, val_loss=2.46, val_accuracy=0.48, lr=0.0316] 57%|█████▋    | 50/88 [17:46<13:00, 20.53s/epoch, loss=1.16, accuracy=0.752, val_loss=3.99, val_accuracy=0.336, lr=0.1]   58%|█████▊    | 51/88 [18:06<12:31, 20.30s/epoch, loss=1.14, accuracy=0.754, val_loss=1.82, val_accuracy=0.546, lr=0.1] 59%|█████▉    | 52/88 [18:27<12:20, 20.56s/epoch, loss=1.14, accuracy=0.753, val_loss=1.83, val_accuracy=0.562, lr=0.1] 60%|██████    | 53/88 [18:47<11:54, 20.43s/epoch, loss=1.14, accuracy=0.756, val_loss=1.94, val_accuracy=0.534, lr=0.1] 61%|██████▏   | 54/88 [19:07<11:30, 20.32s/epoch, loss=1.16, accuracy=0.752, val_loss=1.63, val_accuracy=0.571, lr=0.0316] 62%|██████▎   | 55/88 [19:29<11:23, 20.70s/epoch, loss=1.15, accuracy=0.755, val_loss=1.35, val_accuracy=0.683, lr=0.1]    64%|██████▎   | 56/88 [19:48<10:51, 20.35s/epoch, loss=1.14, accuracy=0.754, val_loss=1.81, val_accuracy=0.546, lr=0.1] 65%|██████▍   | 57/88 [20:09<10:34, 20.47s/epoch, loss=1.14, accuracy=0.754, val_loss=1.88, val_accuracy=0.582, lr=0.1] 66%|██████▌   | 58/88 [20:29<10:06, 20.23s/epoch, loss=1.15, accuracy=0.757, val_loss=2.69, val_accuracy=0.401, lr=0.1] 67%|██████▋   | 59/88 [20:49<09:52, 20.44s/epoch, loss=1.15, accuracy=0.753, val_loss=1.47, val_accuracy=0.653, lr=0.1] 68%|██████▊   | 60/88 [21:10<09:36, 20.59s/epoch, loss=1.15, accuracy=0.755, val_loss=1.8, val_accuracy=0.573, lr=0.0316] 69%|██████▉   | 61/88 [21:30<09:10, 20.40s/epoch, loss=1.14, accuracy=0.757, val_loss=3.3, val_accuracy=0.219, lr=0.1]    70%|███████   | 62/88 [21:51<08:55, 20.60s/epoch, loss=1.14, accuracy=0.757, val_loss=1.56, val_accuracy=0.61, lr=0.1] 72%|███████▏  | 63/88 [22:12<08:33, 20.54s/epoch, loss=1.14, accuracy=0.757, val_loss=2.06, val_accuracy=0.52, lr=0.1] 73%|███████▎  | 64/88 [22:33<08:17, 20.71s/epoch, loss=1.14, accuracy=0.757, val_loss=2.3, val_accuracy=0.456, lr=0.1] 74%|███████▍  | 65/88 [22:54<07:57, 20.76s/epoch, loss=1.14, accuracy=0.757, val_loss=2.88, val_accuracy=0.421, lr=0.0316] 75%|███████▌  | 66/88 [23:15<07:38, 20.84s/epoch, loss=1.15, accuracy=0.756, val_loss=1.97, val_accuracy=0.511, lr=0.1]    76%|███████▌  | 67/88 [23:36<07:19, 20.93s/epoch, loss=1.13, accuracy=0.756, val_loss=1.53, val_accuracy=0.626, lr=0.1] 77%|███████▋  | 68/88 [23:56<06:51, 20.56s/epoch, loss=1.14, accuracy=0.758, val_loss=7.06, val_accuracy=0.226, lr=0.1] 78%|███████▊  | 69/88 [24:16<06:27, 20.41s/epoch, loss=1.14, accuracy=0.757, val_loss=2.79, val_accuracy=0.484, lr=0.1] 80%|███████▉  | 70/88 [24:37<06:11, 20.62s/epoch, loss=1.14, accuracy=0.757, val_loss=1.81, val_accuracy=0.576, lr=0.0316] 81%|████████  | 71/88 [24:58<05:51, 20.69s/epoch, loss=1.15, accuracy=0.755, val_loss=3.46, val_accuracy=0.296, lr=0.1]    82%|████████▏ | 72/88 [25:19<05:32, 20.79s/epoch, loss=1.14, accuracy=0.759, val_loss=3.53, val_accuracy=0.345, lr=0.1] 83%|████████▎ | 73/88 [25:39<05:09, 20.64s/epoch, loss=1.14, accuracy=0.756, val_loss=2.17, val_accuracy=0.448, lr=0.1] 84%|████████▍ | 74/88 [26:00<04:51, 20.80s/epoch, loss=1.14, accuracy=0.757, val_loss=2.49, val_accuracy=0.448, lr=0.1] 85%|████████▌ | 75/88 [26:21<04:30, 20.84s/epoch, loss=1.14, accuracy=0.754, val_loss=1.86, val_accuracy=0.545, lr=0.0316] 86%|████████▋ | 76/88 [26:42<04:08, 20.75s/epoch, loss=1.14, accuracy=0.755, val_loss=1.51, val_accuracy=0.637, lr=0.1]    88%|████████▊ | 77/88 [27:02<03:47, 20.68s/epoch, loss=1.14, accuracy=0.758, val_loss=2.24, val_accuracy=0.497, lr=0.1] 89%|████████▊ | 78/88 [27:23<03:27, 20.80s/epoch, loss=1.14, accuracy=0.756, val_loss=3.16, val_accuracy=0.339, lr=0.1] 90%|████████▉ | 79/88 [27:44<03:06, 20.75s/epoch, loss=1.13, accuracy=0.759, val_loss=1.76, val_accuracy=0.516, lr=0.1] 91%|█████████ | 80/88 [28:05<02:46, 20.84s/epoch, loss=1.13, accuracy=0.758, val_loss=1.73, val_accuracy=0.612, lr=0.0316] 92%|█████████▏| 81/88 [28:25<02:23, 20.52s/epoch, loss=1.14, accuracy=0.756, val_loss=1.77, val_accuracy=0.589, lr=0.1]    93%|█████████▎| 82/88 [28:46<02:04, 20.76s/epoch, loss=0.941, accuracy=0.813, val_loss=0.962, val_accuracy=0.788, lr=0.01] 94%|█████████▍| 83/88 [29:07<01:43, 20.78s/epoch, loss=0.755, accuracy=0.848, val_loss=0.76, val_accuracy=0.836, lr=0.01]  95%|█████████▌| 84/88 [29:28<01:23, 20.75s/epoch, loss=0.673, accuracy=0.856, val_loss=0.741, val_accuracy=0.827, lr=0.01] 97%|█████████▋| 85/88 [29:47<01:01, 20.44s/epoch, loss=0.62, accuracy=0.86, val_loss=0.811, val_accuracy=0.793, lr=0.01]   98%|█████████▊| 86/88 [30:08<00:41, 20.60s/epoch, loss=0.593, accuracy=0.863, val_loss=0.753, val_accuracy=0.812, lr=0.01] 99%|█████████▉| 87/88 [30:28<00:20, 20.30s/epoch, loss=0.576, accuracy=0.866, val_loss=0.758, val_accuracy=0.811, lr=0.01]100%|██████████| 88/88 [30:49<00:00, 20.45s/epoch, loss=0.571, accuracy=0.866, val_loss=0.735, val_accuracy=0.807, lr=0.01]100%|██████████| 88/88 [30:49<00:00, 21.01s/epoch, loss=0.571, accuracy=0.866, val_loss=0.735, val_accuracy=0.807, lr=0.01]
Using real-time data augmentation.
Test score: 0.7816999554634094
Test accuracy: 0.83160001039505


* * * Run SGD for ID = 17_8. * * *


2024-02-20 02:04:47.422872: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 02:04:51.900828: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 02:04:51.902006: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-20 02:04:51.942470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-20 02:04:51.942523: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 02:04:51.946774: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 02:04:51.946825: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-20 02:04:51.949594: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-20 02:04:51.950719: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-20 02:04:51.953912: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-20 02:04:51.955903: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-20 02:04:51.961370: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 02:04:51.962006: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-20 02:04:51.962097: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 02:04:53.565283: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-20 02:04:53.566224: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 02:04:53.566679: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-20 02:04:53.566712: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 02:04:53.566745: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 02:04:53.566764: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-20 02:04:53.566782: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-20 02:04:53.566799: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-20 02:04:53.566816: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-20 02:04:53.566834: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-20 02:04:53.566851: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 02:04:53.567348: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-20 02:04:53.567387: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 02:04:54.266286: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-20 02:04:54.266360: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-20 02:04:54.266370: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-20 02:04:54.267826: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:02:00.0, compute capability: 6.1)
{'id': '17_08', 'batch_size': 128, 'epochs': 88, 'validation_split': 0.1, 'checkpointing': True, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
x_train shape: (45000, 32, 32, 3)
45000 train samples
5000 validation samples
10000 test samples
y_train shape: (45000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/88 [00:00<?, ?epoch/s]2024-02-20 02:04:55.164571: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-20 02:04:55.177183: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199825000 Hz
2024-02-20 02:04:57.319696: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 02:04:57.567163: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 02:04:58.270511: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-20 02:04:58.318195: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/88 [01:02<1:31:14, 62.92s/epoch, loss=3.41, accuracy=0.276, val_loss=3.15, val_accuracy=0.127, lr=0.1]  2%|▏         | 2/88 [01:23<54:42, 38.17s/epoch, loss=1.68, accuracy=0.477, val_loss=1.72, val_accuracy=0.477, lr=0.1]    3%|▎         | 3/88 [01:44<42:43, 30.15s/epoch, loss=1.45, accuracy=0.583, val_loss=2.06, val_accuracy=0.48, lr=0.1]   5%|▍         | 4/88 [02:04<36:56, 26.38s/epoch, loss=1.35, accuracy=0.639, val_loss=1.71, val_accuracy=0.508, lr=0.1]  6%|▌         | 5/88 [02:25<33:25, 24.16s/epoch, loss=1.29, accuracy=0.677, val_loss=2.78, val_accuracy=0.337, lr=0.1]  7%|▋         | 6/88 [02:44<30:47, 22.53s/epoch, loss=1.26, accuracy=0.696, val_loss=2.49, val_accuracy=0.378, lr=0.1]  8%|▊         | 7/88 [03:04<29:04, 21.54s/epoch, loss=1.24, accuracy=0.709, val_loss=2.16, val_accuracy=0.403, lr=0.1]  9%|▉         | 8/88 [03:23<27:48, 20.86s/epoch, loss=1.23, accuracy=0.715, val_loss=1.86, val_accuracy=0.508, lr=0.1] 10%|█         | 9/88 [03:44<27:35, 20.95s/epoch, loss=1.21, accuracy=0.723, val_loss=1.94, val_accuracy=0.536, lr=0.0316] 11%|█▏        | 10/88 [04:04<26:56, 20.72s/epoch, loss=1.21, accuracy=0.727, val_loss=3.37, val_accuracy=0.302, lr=0.1]   12%|█▎        | 11/88 [04:25<26:41, 20.79s/epoch, loss=1.22, accuracy=0.729, val_loss=1.62, val_accuracy=0.588, lr=0.1] 14%|█▎        | 12/88 [04:46<26:17, 20.76s/epoch, loss=1.2, accuracy=0.733, val_loss=1.57, val_accuracy=0.612, lr=0.1]  15%|█▍        | 13/88 [05:06<25:33, 20.44s/epoch, loss=1.21, accuracy=0.734, val_loss=3.44, val_accuracy=0.339, lr=0.1] 16%|█▌        | 14/88 [05:26<25:08, 20.39s/epoch, loss=1.2, accuracy=0.738, val_loss=2.63, val_accuracy=0.397, lr=0.1]  17%|█▋        | 15/88 [05:47<24:58, 20.53s/epoch, loss=1.2, accuracy=0.738, val_loss=1.89, val_accuracy=0.524, lr=0.1] 18%|█▊        | 16/88 [06:08<24:46, 20.65s/epoch, loss=1.19, accuracy=0.741, val_loss=2.26, val_accuracy=0.525, lr=0.1] 19%|█▉        | 17/88 [06:29<24:29, 20.69s/epoch, loss=1.19, accuracy=0.74, val_loss=2.23, val_accuracy=0.479, lr=0.0316] 20%|██        | 18/88 [06:48<23:52, 20.46s/epoch, loss=1.18, accuracy=0.743, val_loss=2.95, val_accuracy=0.378, lr=0.1]   22%|██▏       | 19/88 [07:08<23:20, 20.30s/epoch, loss=1.18, accuracy=0.745, val_loss=2.32, val_accuracy=0.402, lr=0.1] 23%|██▎       | 20/88 [07:29<23:16, 20.53s/epoch, loss=1.17, accuracy=0.744, val_loss=1.64, val_accuracy=0.583, lr=0.1] 24%|██▍       | 21/88 [07:49<22:35, 20.24s/epoch, loss=1.18, accuracy=0.745, val_loss=1.68, val_accuracy=0.579, lr=0.1] 25%|██▌       | 22/88 [08:09<22:10, 20.17s/epoch, loss=1.18, accuracy=0.743, val_loss=2.3, val_accuracy=0.443, lr=0.0316] 26%|██▌       | 23/88 [08:30<21:58, 20.29s/epoch, loss=1.17, accuracy=0.746, val_loss=2.06, val_accuracy=0.5, lr=0.1]     27%|██▋       | 24/88 [08:51<21:53, 20.52s/epoch, loss=1.16, accuracy=0.748, val_loss=2.11, val_accuracy=0.444, lr=0.1] 28%|██▊       | 25/88 [09:11<21:29, 20.47s/epoch, loss=1.17, accuracy=0.748, val_loss=1.85, val_accuracy=0.514, lr=0.1] 30%|██▉       | 26/88 [09:31<20:51, 20.19s/epoch, loss=1.17, accuracy=0.747, val_loss=1.6, val_accuracy=0.595, lr=0.1]  31%|███       | 27/88 [09:50<20:22, 20.05s/epoch, loss=1.16, accuracy=0.75, val_loss=2.29, val_accuracy=0.401, lr=0.0316] 32%|███▏      | 28/88 [10:10<19:51, 19.85s/epoch, loss=1.15, accuracy=0.753, val_loss=2.4, val_accuracy=0.41, lr=0.1]     33%|███▎      | 29/88 [10:30<19:43, 20.05s/epoch, loss=1.16, accuracy=0.751, val_loss=1.65, val_accuracy=0.59, lr=0.1] 34%|███▍      | 30/88 [10:51<19:31, 20.20s/epoch, loss=1.17, accuracy=0.75, val_loss=2.15, val_accuracy=0.465, lr=0.1] 35%|███▌      | 31/88 [11:11<19:14, 20.25s/epoch, loss=1.15, accuracy=0.751, val_loss=1.47, val_accuracy=0.635, lr=0.1] 36%|███▋      | 32/88 [11:30<18:38, 19.97s/epoch, loss=1.16, accuracy=0.751, val_loss=1.55, val_accuracy=0.616, lr=0.1] 38%|███▊      | 33/88 [11:51<18:31, 20.21s/epoch, loss=1.15, accuracy=0.75, val_loss=1.81, val_accuracy=0.54, lr=0.1]   39%|███▊      | 34/88 [12:12<18:22, 20.42s/epoch, loss=1.15, accuracy=0.752, val_loss=2.36, val_accuracy=0.464, lr=0.1] 40%|███▉      | 35/88 [12:32<18:01, 20.41s/epoch, loss=1.15, accuracy=0.754, val_loss=1.53, val_accuracy=0.617, lr=0.1] 41%|████      | 36/88 [12:53<17:46, 20.52s/epoch, loss=1.15, accuracy=0.751, val_loss=2.4, val_accuracy=0.414, lr=0.0316] 42%|████▏     | 37/88 [13:14<17:32, 20.64s/epoch, loss=1.14, accuracy=0.754, val_loss=2.12, val_accuracy=0.453, lr=0.1]   43%|████▎     | 38/88 [13:35<17:15, 20.71s/epoch, loss=1.15, accuracy=0.752, val_loss=1.77, val_accuracy=0.522, lr=0.1] 44%|████▍     | 39/88 [13:55<16:37, 20.35s/epoch, loss=1.15, accuracy=0.753, val_loss=2.07, val_accuracy=0.525, lr=0.1] 45%|████▌     | 40/88 [14:15<16:20, 20.44s/epoch, loss=1.15, accuracy=0.753, val_loss=1.71, val_accuracy=0.586, lr=0.1] 47%|████▋     | 41/88 [14:35<15:52, 20.27s/epoch, loss=1.15, accuracy=0.751, val_loss=1.67, val_accuracy=0.576, lr=0.0316] 48%|████▊     | 42/88 [14:55<15:34, 20.32s/epoch, loss=1.14, accuracy=0.752, val_loss=3.31, val_accuracy=0.251, lr=0.1]    49%|████▉     | 43/88 [15:16<15:22, 20.50s/epoch, loss=1.14, accuracy=0.754, val_loss=1.75, val_accuracy=0.573, lr=0.1] 50%|█████     | 44/88 [15:36<14:56, 20.38s/epoch, loss=1.14, accuracy=0.755, val_loss=2.71, val_accuracy=0.346, lr=0.1] 51%|█████     | 45/88 [15:57<14:41, 20.51s/epoch, loss=1.13, accuracy=0.757, val_loss=1.77, val_accuracy=0.539, lr=0.1] 52%|█████▏    | 46/88 [16:17<14:09, 20.22s/epoch, loss=1.15, accuracy=0.753, val_loss=2.97, val_accuracy=0.373, lr=0.0316] 53%|█████▎    | 47/88 [16:36<13:39, 19.98s/epoch, loss=1.14, accuracy=0.756, val_loss=2.32, val_accuracy=0.485, lr=0.1]    55%|█████▍    | 48/88 [16:57<13:29, 20.23s/epoch, loss=1.13, accuracy=0.757, val_loss=6.35, val_accuracy=0.241, lr=0.1] 56%|█████▌    | 49/88 [17:17<13:09, 20.23s/epoch, loss=1.14, accuracy=0.755, val_loss=1.79, val_accuracy=0.532, lr=0.1] 57%|█████▋    | 50/88 [17:38<12:58, 20.48s/epoch, loss=1.14, accuracy=0.751, val_loss=2.3, val_accuracy=0.492, lr=0.1]  58%|█████▊    | 51/88 [17:58<12:25, 20.15s/epoch, loss=1.13, accuracy=0.755, val_loss=2.39, val_accuracy=0.355, lr=0.0316] 59%|█████▉    | 52/88 [18:18<12:03, 20.08s/epoch, loss=1.13, accuracy=0.756, val_loss=1.97, val_accuracy=0.496, lr=0.1]    60%|██████    | 53/88 [18:39<11:53, 20.40s/epoch, loss=1.13, accuracy=0.757, val_loss=4.77, val_accuracy=0.29, lr=0.1]  61%|██████▏   | 54/88 [18:58<11:23, 20.09s/epoch, loss=1.12, accuracy=0.757, val_loss=1.95, val_accuracy=0.504, lr=0.1] 62%|██████▎   | 55/88 [19:19<11:07, 20.23s/epoch, loss=1.13, accuracy=0.756, val_loss=1.69, val_accuracy=0.556, lr=0.1] 64%|██████▎   | 56/88 [19:39<10:48, 20.28s/epoch, loss=1.13, accuracy=0.758, val_loss=1.71, val_accuracy=0.555, lr=0.0316] 65%|██████▍   | 57/88 [19:59<10:20, 20.03s/epoch, loss=1.13, accuracy=0.755, val_loss=2.2, val_accuracy=0.497, lr=0.1]     66%|██████▌   | 58/88 [20:19<10:08, 20.28s/epoch, loss=1.13, accuracy=0.757, val_loss=1.58, val_accuracy=0.586, lr=0.1] 67%|██████▋   | 59/88 [20:40<09:53, 20.47s/epoch, loss=1.13, accuracy=0.757, val_loss=1.6, val_accuracy=0.62, lr=0.1]   68%|██████▊   | 60/88 [21:01<09:33, 20.48s/epoch, loss=1.13, accuracy=0.757, val_loss=1.75, val_accuracy=0.532, lr=0.1] 69%|██████▉   | 61/88 [21:22<09:14, 20.54s/epoch, loss=1.13, accuracy=0.755, val_loss=1.91, val_accuracy=0.489, lr=0.0316] 70%|███████   | 62/88 [21:42<08:56, 20.65s/epoch, loss=1.13, accuracy=0.754, val_loss=2.37, val_accuracy=0.506, lr=0.1]    72%|███████▏  | 63/88 [22:03<08:37, 20.71s/epoch, loss=1.13, accuracy=0.758, val_loss=1.73, val_accuracy=0.566, lr=0.1] 73%|███████▎  | 64/88 [22:23<08:07, 20.33s/epoch, loss=1.13, accuracy=0.758, val_loss=4.84, val_accuracy=0.212, lr=0.1] 74%|███████▍  | 65/88 [22:44<07:51, 20.51s/epoch, loss=1.13, accuracy=0.758, val_loss=2.59, val_accuracy=0.413, lr=0.1] 75%|███████▌  | 66/88 [23:04<07:26, 20.31s/epoch, loss=1.13, accuracy=0.756, val_loss=2.11, val_accuracy=0.532, lr=0.0316] 76%|███████▌  | 67/88 [23:23<07:03, 20.14s/epoch, loss=1.13, accuracy=0.756, val_loss=1.83, val_accuracy=0.529, lr=0.1]    77%|███████▋  | 68/88 [23:44<06:48, 20.40s/epoch, loss=1.12, accuracy=0.76, val_loss=3.77, val_accuracy=0.289, lr=0.1]  78%|███████▊  | 69/88 [24:05<06:30, 20.56s/epoch, loss=1.13, accuracy=0.756, val_loss=3.66, val_accuracy=0.397, lr=0.1] 80%|███████▉  | 70/88 [24:26<06:11, 20.65s/epoch, loss=1.13, accuracy=0.757, val_loss=1.87, val_accuracy=0.56, lr=0.1]  81%|████████  | 71/88 [24:47<05:51, 20.70s/epoch, loss=1.13, accuracy=0.756, val_loss=1.65, val_accuracy=0.593, lr=0.0316] 82%|████████▏ | 72/88 [25:08<05:34, 20.92s/epoch, loss=1.13, accuracy=0.755, val_loss=1.46, val_accuracy=0.647, lr=0.1]    83%|████████▎ | 73/88 [25:28<05:08, 20.54s/epoch, loss=1.12, accuracy=0.757, val_loss=2.64, val_accuracy=0.452, lr=0.1] 84%|████████▍ | 74/88 [25:48<04:45, 20.38s/epoch, loss=1.12, accuracy=0.759, val_loss=2.2, val_accuracy=0.464, lr=0.1]  85%|████████▌ | 75/88 [26:08<04:23, 20.27s/epoch, loss=1.12, accuracy=0.758, val_loss=2.05, val_accuracy=0.428, lr=0.1] 86%|████████▋ | 76/88 [26:29<04:05, 20.45s/epoch, loss=1.12, accuracy=0.759, val_loss=3.28, val_accuracy=0.395, lr=0.1] 88%|████████▊ | 77/88 [26:49<03:43, 20.30s/epoch, loss=1.12, accuracy=0.759, val_loss=1.74, val_accuracy=0.569, lr=0.0316] 89%|████████▊ | 78/88 [27:10<03:24, 20.45s/epoch, loss=1.13, accuracy=0.756, val_loss=1.65, val_accuracy=0.59, lr=0.1]     90%|████████▉ | 79/88 [27:30<03:04, 20.54s/epoch, loss=1.13, accuracy=0.755, val_loss=2.17, val_accuracy=0.44, lr=0.1] 91%|█████████ | 80/88 [27:51<02:45, 20.70s/epoch, loss=1.13, accuracy=0.756, val_loss=1.95, val_accuracy=0.55, lr=0.1] 92%|█████████▏| 81/88 [28:12<02:24, 20.71s/epoch, loss=1.12, accuracy=0.759, val_loss=2.3, val_accuracy=0.408, lr=0.1] 93%|█████████▎| 82/88 [28:33<02:05, 20.84s/epoch, loss=0.918, accuracy=0.817, val_loss=0.928, val_accuracy=0.798, lr=0.01] 94%|█████████▍| 83/88 [28:53<01:42, 20.49s/epoch, loss=0.739, accuracy=0.85, val_loss=0.976, val_accuracy=0.767, lr=0.01]  95%|█████████▌| 84/88 [29:14<01:22, 20.62s/epoch, loss=0.658, accuracy=0.861, val_loss=0.794, val_accuracy=0.809, lr=0.01] 97%|█████████▋| 85/88 [29:33<01:00, 20.25s/epoch, loss=0.608, accuracy=0.863, val_loss=0.87, val_accuracy=0.777, lr=0.01]  98%|█████████▊| 86/88 [29:54<00:40, 20.44s/epoch, loss=0.585, accuracy=0.864, val_loss=0.828, val_accuracy=0.785, lr=0.01] 99%|█████████▉| 87/88 [30:14<00:20, 20.29s/epoch, loss=0.571, accuracy=0.866, val_loss=0.947, val_accuracy=0.748, lr=0.01]100%|██████████| 88/88 [30:34<00:00, 20.27s/epoch, loss=0.564, accuracy=0.867, val_loss=0.795, val_accuracy=0.804, lr=0.01]100%|██████████| 88/88 [30:34<00:00, 20.85s/epoch, loss=0.564, accuracy=0.867, val_loss=0.795, val_accuracy=0.804, lr=0.01]
Using real-time data augmentation.
Test score: 0.7908887267112732
Test accuracy: 0.8044999837875366


* * * Run SGD for ID = 17_9. * * *


2024-02-20 02:35:38.968960: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 02:35:43.858231: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 02:35:43.859190: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-20 02:35:43.897505: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-20 02:35:43.897536: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 02:35:43.902093: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 02:35:43.902137: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-20 02:35:43.905218: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-20 02:35:43.906703: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-20 02:35:43.909999: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-20 02:35:43.912655: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-20 02:35:43.918577: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 02:35:43.919122: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-20 02:35:43.919201: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 02:35:45.440851: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-20 02:35:45.441993: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 02:35:45.444139: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-20 02:35:45.444191: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 02:35:45.444239: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 02:35:45.444259: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-20 02:35:45.444283: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-20 02:35:45.444302: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-20 02:35:45.444319: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-20 02:35:45.444335: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-20 02:35:45.444352: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 02:35:45.444836: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-20 02:35:45.444880: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 02:35:46.156325: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-20 02:35:46.156387: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-20 02:35:46.156404: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-20 02:35:46.157428: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:02:00.0, compute capability: 6.1)
{'id': '17_09', 'batch_size': 128, 'epochs': 88, 'validation_split': 0.1, 'checkpointing': True, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
x_train shape: (45000, 32, 32, 3)
45000 train samples
5000 validation samples
10000 test samples
y_train shape: (45000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/88 [00:00<?, ?epoch/s]2024-02-20 02:35:47.036090: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-20 02:35:47.048187: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199825000 Hz
2024-02-20 02:35:49.160997: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 02:35:49.422313: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 02:35:50.202072: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-20 02:35:50.248658: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/88 [00:54<1:19:44, 54.99s/epoch, loss=3.62, accuracy=0.263, val_loss=3.54, val_accuracy=0.126, lr=0.1]  2%|▏         | 2/88 [01:14<48:54, 34.12s/epoch, loss=1.65, accuracy=0.499, val_loss=2.34, val_accuracy=0.323, lr=0.1]    3%|▎         | 3/88 [01:34<39:14, 27.70s/epoch, loss=1.42, accuracy=0.603, val_loss=2.26, val_accuracy=0.327, lr=0.1]  5%|▍         | 4/88 [01:55<34:58, 24.98s/epoch, loss=1.32, accuracy=0.661, val_loss=2.18, val_accuracy=0.463, lr=0.1]  6%|▌         | 5/88 [02:14<31:48, 22.99s/epoch, loss=1.29, accuracy=0.687, val_loss=3.75, val_accuracy=0.306, lr=0.1]  7%|▋         | 6/88 [02:36<30:37, 22.41s/epoch, loss=1.27, accuracy=0.698, val_loss=1.59, val_accuracy=0.59, lr=0.1]   8%|▊         | 7/88 [02:57<29:36, 21.93s/epoch, loss=1.25, accuracy=0.708, val_loss=2.26, val_accuracy=0.379, lr=0.1]  9%|▉         | 8/88 [03:18<28:50, 21.64s/epoch, loss=1.24, accuracy=0.712, val_loss=2.58, val_accuracy=0.441, lr=0.1] 10%|█         | 9/88 [03:39<28:23, 21.56s/epoch, loss=1.22, accuracy=0.721, val_loss=1.54, val_accuracy=0.625, lr=0.1] 11%|█▏        | 10/88 [04:00<27:39, 21.28s/epoch, loss=1.22, accuracy=0.723, val_loss=1.8, val_accuracy=0.536, lr=0.1] 12%|█▎        | 11/88 [04:21<27:10, 21.17s/epoch, loss=1.22, accuracy=0.726, val_loss=2.02, val_accuracy=0.508, lr=0.1] 14%|█▎        | 12/88 [04:41<26:27, 20.88s/epoch, loss=1.21, accuracy=0.73, val_loss=1.73, val_accuracy=0.569, lr=0.1]  15%|█▍        | 13/88 [05:01<26:02, 20.83s/epoch, loss=1.2, accuracy=0.73, val_loss=1.69, val_accuracy=0.579, lr=0.1]  16%|█▌        | 14/88 [05:22<25:39, 20.81s/epoch, loss=1.19, accuracy=0.73, val_loss=2.23, val_accuracy=0.383, lr=0.0316] 17%|█▋        | 15/88 [05:43<25:17, 20.79s/epoch, loss=1.2, accuracy=0.732, val_loss=2.15, val_accuracy=0.448, lr=0.1]    18%|█▊        | 16/88 [06:04<24:59, 20.83s/epoch, loss=1.2, accuracy=0.73, val_loss=1.69, val_accuracy=0.584, lr=0.1]  19%|█▉        | 17/88 [06:25<24:38, 20.82s/epoch, loss=1.18, accuracy=0.737, val_loss=2.63, val_accuracy=0.446, lr=0.1] 20%|██        | 18/88 [06:46<24:24, 20.92s/epoch, loss=1.19, accuracy=0.739, val_loss=1.62, val_accuracy=0.584, lr=0.1] 22%|██▏       | 19/88 [07:06<23:54, 20.79s/epoch, loss=1.18, accuracy=0.736, val_loss=1.79, val_accuracy=0.586, lr=0.0316] 23%|██▎       | 20/88 [07:27<23:29, 20.73s/epoch, loss=1.18, accuracy=0.741, val_loss=1.49, val_accuracy=0.631, lr=0.1]    24%|██▍       | 21/88 [07:48<23:19, 20.89s/epoch, loss=1.18, accuracy=0.738, val_loss=2.52, val_accuracy=0.431, lr=0.1] 25%|██▌       | 22/88 [08:08<22:45, 20.69s/epoch, loss=1.18, accuracy=0.74, val_loss=2.21, val_accuracy=0.498, lr=0.1]  26%|██▌       | 23/88 [08:29<22:15, 20.54s/epoch, loss=1.18, accuracy=0.74, val_loss=1.61, val_accuracy=0.588, lr=0.1] 27%|██▋       | 24/88 [08:49<21:43, 20.37s/epoch, loss=1.16, accuracy=0.744, val_loss=1.98, val_accuracy=0.528, lr=0.1] 28%|██▊       | 25/88 [09:08<21:13, 20.21s/epoch, loss=1.16, accuracy=0.742, val_loss=1.71, val_accuracy=0.526, lr=0.0316] 30%|██▉       | 26/88 [09:29<21:07, 20.44s/epoch, loss=1.17, accuracy=0.744, val_loss=1.72, val_accuracy=0.567, lr=0.1]    31%|███       | 27/88 [09:49<20:32, 20.21s/epoch, loss=1.16, accuracy=0.743, val_loss=1.87, val_accuracy=0.512, lr=0.1] 32%|███▏      | 28/88 [10:09<20:06, 20.10s/epoch, loss=1.16, accuracy=0.747, val_loss=2.1, val_accuracy=0.443, lr=0.1]  33%|███▎      | 29/88 [10:30<20:05, 20.43s/epoch, loss=1.16, accuracy=0.744, val_loss=1.52, val_accuracy=0.615, lr=0.1] 34%|███▍      | 30/88 [10:51<19:57, 20.64s/epoch, loss=1.15, accuracy=0.748, val_loss=1.8, val_accuracy=0.557, lr=0.0316] 35%|███▌      | 31/88 [11:12<19:42, 20.75s/epoch, loss=1.17, accuracy=0.746, val_loss=1.43, val_accuracy=0.652, lr=0.1]   36%|███▋      | 32/88 [11:33<19:20, 20.73s/epoch, loss=1.15, accuracy=0.745, val_loss=1.71, val_accuracy=0.534, lr=0.1] 38%|███▊      | 33/88 [11:53<18:42, 20.41s/epoch, loss=1.15, accuracy=0.749, val_loss=1.54, val_accuracy=0.59, lr=0.1]  39%|███▊      | 34/88 [12:14<18:30, 20.57s/epoch, loss=1.14, accuracy=0.748, val_loss=1.65, val_accuracy=0.588, lr=0.1] 40%|███▉      | 35/88 [12:35<18:16, 20.69s/epoch, loss=1.15, accuracy=0.751, val_loss=1.93, val_accuracy=0.516, lr=0.1] 41%|████      | 36/88 [12:55<17:47, 20.53s/epoch, loss=1.15, accuracy=0.75, val_loss=2.39, val_accuracy=0.489, lr=0.0316] 42%|████▏     | 37/88 [13:15<17:24, 20.49s/epoch, loss=1.14, accuracy=0.75, val_loss=2.24, val_accuracy=0.38, lr=0.1]     43%|████▎     | 38/88 [13:36<17:14, 20.69s/epoch, loss=1.14, accuracy=0.752, val_loss=1.78, val_accuracy=0.57, lr=0.1] 44%|████▍     | 39/88 [13:57<16:58, 20.78s/epoch, loss=1.14, accuracy=0.75, val_loss=1.9, val_accuracy=0.496, lr=0.1]  45%|████▌     | 40/88 [14:18<16:38, 20.80s/epoch, loss=1.14, accuracy=0.75, val_loss=1.89, val_accuracy=0.548, lr=0.1] 47%|████▋     | 41/88 [14:39<16:21, 20.88s/epoch, loss=1.14, accuracy=0.75, val_loss=1.73, val_accuracy=0.539, lr=0.0316] 48%|████▊     | 42/88 [15:00<16:06, 21.01s/epoch, loss=1.14, accuracy=0.753, val_loss=2.21, val_accuracy=0.459, lr=0.1]   49%|████▉     | 43/88 [15:22<15:46, 21.04s/epoch, loss=1.14, accuracy=0.75, val_loss=3.48, val_accuracy=0.355, lr=0.1]  50%|█████     | 44/88 [15:42<15:23, 21.00s/epoch, loss=1.14, accuracy=0.751, val_loss=3.43, val_accuracy=0.358, lr=0.1] 51%|█████     | 45/88 [16:03<14:53, 20.78s/epoch, loss=1.14, accuracy=0.751, val_loss=2.29, val_accuracy=0.466, lr=0.1] 52%|█████▏    | 46/88 [16:23<14:26, 20.63s/epoch, loss=1.14, accuracy=0.751, val_loss=1.69, val_accuracy=0.546, lr=0.0316] 53%|█████▎    | 47/88 [16:43<13:53, 20.32s/epoch, loss=1.14, accuracy=0.751, val_loss=2.22, val_accuracy=0.459, lr=0.1]    55%|█████▍    | 48/88 [17:03<13:28, 20.21s/epoch, loss=1.13, accuracy=0.753, val_loss=3.28, val_accuracy=0.38, lr=0.1]  56%|█████▌    | 49/88 [17:23<13:15, 20.39s/epoch, loss=1.14, accuracy=0.75, val_loss=3.58, val_accuracy=0.34, lr=0.1]  57%|█████▋    | 50/88 [17:43<12:46, 20.17s/epoch, loss=1.14, accuracy=0.753, val_loss=1.53, val_accuracy=0.615, lr=0.1] 58%|█████▊    | 51/88 [18:04<12:35, 20.43s/epoch, loss=1.14, accuracy=0.752, val_loss=1.66, val_accuracy=0.587, lr=0.0316] 59%|█████▉    | 52/88 [18:24<12:12, 20.35s/epoch, loss=1.14, accuracy=0.75, val_loss=3.77, val_accuracy=0.315, lr=0.1]     60%|██████    | 53/88 [18:45<12:00, 20.58s/epoch, loss=1.13, accuracy=0.754, val_loss=1.98, val_accuracy=0.53, lr=0.1] 61%|██████▏   | 54/88 [19:07<11:46, 20.77s/epoch, loss=1.13, accuracy=0.752, val_loss=2.62, val_accuracy=0.38, lr=0.1] 62%|██████▎   | 55/88 [19:27<11:22, 20.68s/epoch, loss=1.13, accuracy=0.753, val_loss=1.92, val_accuracy=0.55, lr=0.1] 64%|██████▎   | 56/88 [19:48<11:02, 20.71s/epoch, loss=1.13, accuracy=0.753, val_loss=1.8, val_accuracy=0.562, lr=0.0316] 65%|██████▍   | 57/88 [20:09<10:42, 20.73s/epoch, loss=1.13, accuracy=0.755, val_loss=1.89, val_accuracy=0.505, lr=0.1]   66%|██████▌   | 58/88 [20:29<10:23, 20.78s/epoch, loss=1.13, accuracy=0.754, val_loss=1.99, val_accuracy=0.488, lr=0.1] 67%|██████▋   | 59/88 [20:49<09:53, 20.46s/epoch, loss=1.14, accuracy=0.755, val_loss=2.75, val_accuracy=0.403, lr=0.1] 68%|██████▊   | 60/88 [21:09<09:25, 20.21s/epoch, loss=1.13, accuracy=0.755, val_loss=1.63, val_accuracy=0.598, lr=0.1] 69%|██████▉   | 61/88 [21:29<09:05, 20.20s/epoch, loss=1.13, accuracy=0.754, val_loss=2.73, val_accuracy=0.344, lr=0.0316] 70%|███████   | 62/88 [21:50<08:50, 20.42s/epoch, loss=1.14, accuracy=0.754, val_loss=1.74, val_accuracy=0.573, lr=0.1]    72%|███████▏  | 63/88 [22:10<08:24, 20.18s/epoch, loss=1.14, accuracy=0.752, val_loss=2.17, val_accuracy=0.499, lr=0.1] 73%|███████▎  | 64/88 [22:30<08:07, 20.33s/epoch, loss=1.13, accuracy=0.751, val_loss=2.54, val_accuracy=0.48, lr=0.1]  74%|███████▍  | 65/88 [22:51<07:50, 20.46s/epoch, loss=1.13, accuracy=0.755, val_loss=2.02, val_accuracy=0.497, lr=0.1] 75%|███████▌  | 66/88 [23:11<07:29, 20.44s/epoch, loss=1.13, accuracy=0.754, val_loss=5, val_accuracy=0.313, lr=0.0316] 76%|███████▌  | 67/88 [23:31<07:03, 20.19s/epoch, loss=1.14, accuracy=0.754, val_loss=1.8, val_accuracy=0.548, lr=0.1]  77%|███████▋  | 68/88 [23:52<06:47, 20.38s/epoch, loss=1.13, accuracy=0.754, val_loss=1.63, val_accuracy=0.588, lr=0.1] 78%|███████▊  | 69/88 [24:12<06:26, 20.33s/epoch, loss=1.12, accuracy=0.754, val_loss=1.74, val_accuracy=0.529, lr=0.1] 80%|███████▉  | 70/88 [24:33<06:10, 20.58s/epoch, loss=1.13, accuracy=0.753, val_loss=1.73, val_accuracy=0.587, lr=0.1] 81%|████████  | 71/88 [24:54<05:51, 20.66s/epoch, loss=1.13, accuracy=0.754, val_loss=2.11, val_accuracy=0.496, lr=0.0316] 82%|████████▏ | 72/88 [25:15<05:32, 20.79s/epoch, loss=1.13, accuracy=0.755, val_loss=1.69, val_accuracy=0.579, lr=0.1]    83%|████████▎ | 73/88 [25:36<05:10, 20.72s/epoch, loss=1.13, accuracy=0.753, val_loss=2.08, val_accuracy=0.555, lr=0.1] 84%|████████▍ | 74/88 [25:57<04:51, 20.79s/epoch, loss=1.13, accuracy=0.757, val_loss=1.56, val_accuracy=0.607, lr=0.1] 85%|████████▌ | 75/88 [26:16<04:25, 20.44s/epoch, loss=1.13, accuracy=0.753, val_loss=1.84, val_accuracy=0.593, lr=0.1] 86%|████████▋ | 76/88 [26:37<04:07, 20.64s/epoch, loss=1.12, accuracy=0.757, val_loss=2.07, val_accuracy=0.548, lr=0.0316] 88%|████████▊ | 77/88 [26:58<03:45, 20.51s/epoch, loss=1.12, accuracy=0.755, val_loss=1.78, val_accuracy=0.546, lr=0.1]    89%|████████▊ | 78/88 [27:19<03:26, 20.67s/epoch, loss=1.13, accuracy=0.756, val_loss=3.21, val_accuracy=0.348, lr=0.1] 90%|████████▉ | 79/88 [27:40<03:06, 20.74s/epoch, loss=1.13, accuracy=0.755, val_loss=1.42, val_accuracy=0.64, lr=0.1]  91%|█████████ | 80/88 [28:00<02:45, 20.66s/epoch, loss=1.12, accuracy=0.756, val_loss=2.91, val_accuracy=0.302, lr=0.1] 92%|█████████▏| 81/88 [28:21<02:25, 20.74s/epoch, loss=1.12, accuracy=0.757, val_loss=2.68, val_accuracy=0.393, lr=0.1] 93%|█████████▎| 82/88 [28:41<02:03, 20.53s/epoch, loss=0.923, accuracy=0.812, val_loss=0.962, val_accuracy=0.782, lr=0.01] 94%|█████████▍| 83/88 [29:02<01:43, 20.72s/epoch, loss=0.75, accuracy=0.845, val_loss=0.892, val_accuracy=0.789, lr=0.01]  95%|█████████▌| 84/88 [29:23<01:22, 20.68s/epoch, loss=0.671, accuracy=0.852, val_loss=0.723, val_accuracy=0.825, lr=0.01] 97%|█████████▋| 85/88 [29:42<01:01, 20.40s/epoch, loss=0.618, accuracy=0.858, val_loss=0.773, val_accuracy=0.805, lr=0.01] 98%|█████████▊| 86/88 [30:04<00:41, 20.65s/epoch, loss=0.594, accuracy=0.859, val_loss=0.677, val_accuracy=0.829, lr=0.01] 99%|█████████▉| 87/88 [30:24<00:20, 20.69s/epoch, loss=0.581, accuracy=0.861, val_loss=0.816, val_accuracy=0.783, lr=0.01]100%|██████████| 88/88 [30:46<00:00, 20.83s/epoch, loss=0.576, accuracy=0.861, val_loss=0.753, val_accuracy=0.8, lr=0.01]  100%|██████████| 88/88 [30:46<00:00, 20.98s/epoch, loss=0.576, accuracy=0.861, val_loss=0.753, val_accuracy=0.8, lr=0.01]
Using real-time data augmentation.
Test score: 0.6963164210319519
Test accuracy: 0.8258000016212463


* * * Run SGD for ID = 17_10. * * *


2024-02-20 03:06:42.308758: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 03:06:47.647994: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 03:06:47.648945: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-20 03:06:47.691000: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-20 03:06:47.691091: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 03:06:47.695207: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 03:06:47.695253: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-20 03:06:47.698614: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-20 03:06:47.700543: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-20 03:06:47.704752: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-20 03:06:47.707197: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-20 03:06:47.713281: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 03:06:47.713835: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-20 03:06:47.713914: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 03:06:49.240135: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-20 03:06:49.241222: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 03:06:49.241995: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-20 03:06:49.242027: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 03:06:49.242092: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 03:06:49.242114: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-20 03:06:49.242132: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-20 03:06:49.242149: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-20 03:06:49.242165: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-20 03:06:49.242182: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-20 03:06:49.242199: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 03:06:49.242679: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-20 03:06:49.242719: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 03:06:49.923743: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-20 03:06:49.923798: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-20 03:06:49.923808: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-20 03:06:49.924779: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:02:00.0, compute capability: 6.1)
{'id': '17_10', 'batch_size': 128, 'epochs': 88, 'validation_split': 0.1, 'checkpointing': True, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
x_train shape: (45000, 32, 32, 3)
45000 train samples
5000 validation samples
10000 test samples
y_train shape: (45000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/88 [00:00<?, ?epoch/s]2024-02-20 03:06:50.741871: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-20 03:06:50.754180: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199825000 Hz
2024-02-20 03:06:52.794985: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 03:06:53.068722: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 03:06:53.851313: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-20 03:06:53.904651: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/88 [01:00<1:27:43, 60.50s/epoch, loss=3.29, accuracy=0.268, val_loss=2.39, val_accuracy=0.237, lr=0.1]  2%|▏         | 2/88 [01:21<53:22, 37.24s/epoch, loss=1.61, accuracy=0.508, val_loss=2.64, val_accuracy=0.322, lr=0.1]    3%|▎         | 3/88 [01:42<42:24, 29.94s/epoch, loss=1.35, accuracy=0.624, val_loss=1.66, val_accuracy=0.528, lr=0.1]  5%|▍         | 4/88 [02:03<36:43, 26.23s/epoch, loss=1.26, accuracy=0.678, val_loss=2.07, val_accuracy=0.496, lr=0.1]  6%|▌         | 5/88 [02:23<33:30, 24.23s/epoch, loss=1.23, accuracy=0.696, val_loss=2.7, val_accuracy=0.409, lr=0.1]   7%|▋         | 6/88 [02:43<30:54, 22.61s/epoch, loss=1.22, accuracy=0.707, val_loss=1.86, val_accuracy=0.511, lr=0.1]  8%|▊         | 7/88 [03:04<29:59, 22.21s/epoch, loss=1.21, accuracy=0.718, val_loss=2.57, val_accuracy=0.361, lr=0.1]  9%|▉         | 8/88 [03:25<29:08, 21.86s/epoch, loss=1.2, accuracy=0.721, val_loss=2.61, val_accuracy=0.446, lr=0.0316] 10%|█         | 9/88 [03:47<28:39, 21.77s/epoch, loss=1.19, accuracy=0.728, val_loss=1.5, val_accuracy=0.622, lr=0.1]    11%|█▏        | 10/88 [04:08<27:50, 21.41s/epoch, loss=1.19, accuracy=0.73, val_loss=2.15, val_accuracy=0.393, lr=0.1] 12%|█▎        | 11/88 [04:29<27:20, 21.30s/epoch, loss=1.18, accuracy=0.734, val_loss=2.35, val_accuracy=0.364, lr=0.1] 14%|█▎        | 12/88 [04:48<26:20, 20.80s/epoch, loss=1.18, accuracy=0.734, val_loss=4.14, val_accuracy=0.334, lr=0.1] 15%|█▍        | 13/88 [05:08<25:34, 20.46s/epoch, loss=1.18, accuracy=0.734, val_loss=3.22, val_accuracy=0.387, lr=0.1] 16%|█▌        | 14/88 [05:27<24:52, 20.17s/epoch, loss=1.16, accuracy=0.739, val_loss=2.74, val_accuracy=0.306, lr=0.0316] 17%|█▋        | 15/88 [05:47<24:18, 19.98s/epoch, loss=1.17, accuracy=0.741, val_loss=2.22, val_accuracy=0.425, lr=0.1]    18%|█▊        | 16/88 [06:07<23:51, 19.89s/epoch, loss=1.16, accuracy=0.742, val_loss=1.92, val_accuracy=0.532, lr=0.1] 19%|█▉        | 17/88 [06:28<23:54, 20.20s/epoch, loss=1.15, accuracy=0.744, val_loss=1.7, val_accuracy=0.614, lr=0.1]  20%|██        | 18/88 [06:47<23:19, 20.00s/epoch, loss=1.15, accuracy=0.745, val_loss=2.2, val_accuracy=0.507, lr=0.1] 22%|██▏       | 19/88 [07:07<23:04, 20.07s/epoch, loss=1.15, accuracy=0.742, val_loss=1.58, val_accuracy=0.616, lr=0.0316] 23%|██▎       | 20/88 [07:28<22:49, 20.14s/epoch, loss=1.16, accuracy=0.745, val_loss=1.82, val_accuracy=0.501, lr=0.1]    24%|██▍       | 21/88 [07:48<22:23, 20.06s/epoch, loss=1.14, accuracy=0.748, val_loss=1.92, val_accuracy=0.505, lr=0.1] 25%|██▌       | 22/88 [08:09<22:33, 20.51s/epoch, loss=1.14, accuracy=0.748, val_loss=1.49, val_accuracy=0.635, lr=0.1] 26%|██▌       | 23/88 [08:30<22:19, 20.61s/epoch, loss=1.15, accuracy=0.747, val_loss=1.68, val_accuracy=0.552, lr=0.1] 27%|██▋       | 24/88 [08:51<22:11, 20.81s/epoch, loss=1.13, accuracy=0.749, val_loss=1.6, val_accuracy=0.584, lr=0.1]  28%|██▊       | 25/88 [09:12<21:58, 20.92s/epoch, loss=1.14, accuracy=0.749, val_loss=2.3, val_accuracy=0.453, lr=0.1] 30%|██▉       | 26/88 [09:32<21:21, 20.67s/epoch, loss=1.14, accuracy=0.747, val_loss=11.5, val_accuracy=0.114, lr=0.1] 31%|███       | 27/88 [09:53<20:56, 20.61s/epoch, loss=1.14, accuracy=0.748, val_loss=3.08, val_accuracy=0.4, lr=0.0316] 32%|███▏      | 28/88 [10:13<20:18, 20.30s/epoch, loss=1.13, accuracy=0.75, val_loss=2.02, val_accuracy=0.495, lr=0.1]   33%|███▎      | 29/88 [10:34<20:11, 20.54s/epoch, loss=1.13, accuracy=0.753, val_loss=1.96, val_accuracy=0.464, lr=0.1] 34%|███▍      | 30/88 [10:53<19:35, 20.26s/epoch, loss=1.13, accuracy=0.751, val_loss=1.72, val_accuracy=0.559, lr=0.1] 35%|███▌      | 31/88 [11:14<19:20, 20.36s/epoch, loss=1.13, accuracy=0.752, val_loss=2.28, val_accuracy=0.468, lr=0.1] 36%|███▋      | 32/88 [11:33<18:48, 20.14s/epoch, loss=1.12, accuracy=0.752, val_loss=3.67, val_accuracy=0.269, lr=0.0316] 38%|███▊      | 33/88 [11:53<18:20, 20.02s/epoch, loss=1.13, accuracy=0.75, val_loss=1.66, val_accuracy=0.561, lr=0.1]     39%|███▊      | 34/88 [12:14<18:12, 20.24s/epoch, loss=1.12, accuracy=0.753, val_loss=4.69, val_accuracy=0.252, lr=0.1] 40%|███▉      | 35/88 [12:34<17:45, 20.10s/epoch, loss=1.13, accuracy=0.754, val_loss=2.08, val_accuracy=0.528, lr=0.1] 41%|████      | 36/88 [12:55<17:41, 20.41s/epoch, loss=1.12, accuracy=0.751, val_loss=4.19, val_accuracy=0.292, lr=0.1] 42%|████▏     | 37/88 [13:15<17:15, 20.30s/epoch, loss=1.12, accuracy=0.755, val_loss=1.64, val_accuracy=0.565, lr=0.0316] 43%|████▎     | 38/88 [13:35<16:56, 20.34s/epoch, loss=1.12, accuracy=0.754, val_loss=2.82, val_accuracy=0.434, lr=0.1]    44%|████▍     | 39/88 [13:56<16:42, 20.47s/epoch, loss=1.12, accuracy=0.754, val_loss=2.15, val_accuracy=0.463, lr=0.1] 45%|████▌     | 40/88 [14:17<16:32, 20.68s/epoch, loss=1.12, accuracy=0.754, val_loss=1.99, val_accuracy=0.476, lr=0.1] 47%|████▋     | 41/88 [14:38<16:16, 20.77s/epoch, loss=1.12, accuracy=0.756, val_loss=2.09, val_accuracy=0.463, lr=0.1] 48%|████▊     | 42/88 [14:59<15:50, 20.66s/epoch, loss=1.12, accuracy=0.756, val_loss=1.58, val_accuracy=0.574, lr=0.0316] 49%|████▉     | 43/88 [15:20<15:35, 20.78s/epoch, loss=1.11, accuracy=0.756, val_loss=2.71, val_accuracy=0.306, lr=0.1]    50%|█████     | 44/88 [15:41<15:17, 20.86s/epoch, loss=1.12, accuracy=0.754, val_loss=1.76, val_accuracy=0.558, lr=0.1] 51%|█████     | 45/88 [16:01<14:52, 20.77s/epoch, loss=1.11, accuracy=0.753, val_loss=2.07, val_accuracy=0.525, lr=0.1] 52%|█████▏    | 46/88 [16:22<14:32, 20.78s/epoch, loss=1.11, accuracy=0.755, val_loss=2.3, val_accuracy=0.432, lr=0.1]  53%|█████▎    | 47/88 [16:43<14:10, 20.74s/epoch, loss=1.11, accuracy=0.756, val_loss=1.66, val_accuracy=0.548, lr=0.0316] 55%|█████▍    | 48/88 [17:03<13:40, 20.51s/epoch, loss=1.12, accuracy=0.755, val_loss=1.74, val_accuracy=0.563, lr=0.1]    56%|█████▌    | 49/88 [17:23<13:20, 20.51s/epoch, loss=1.11, accuracy=0.756, val_loss=2.04, val_accuracy=0.525, lr=0.1] 57%|█████▋    | 50/88 [17:44<12:58, 20.48s/epoch, loss=1.12, accuracy=0.753, val_loss=4.87, val_accuracy=0.183, lr=0.1] 58%|█████▊    | 51/88 [18:04<12:37, 20.48s/epoch, loss=1.11, accuracy=0.757, val_loss=2.35, val_accuracy=0.497, lr=0.1] 59%|█████▉    | 52/88 [18:24<12:15, 20.42s/epoch, loss=1.11, accuracy=0.755, val_loss=2.29, val_accuracy=0.468, lr=0.0316] 60%|██████    | 53/88 [18:45<11:53, 20.38s/epoch, loss=1.11, accuracy=0.756, val_loss=1.47, val_accuracy=0.623, lr=0.1]    61%|██████▏   | 54/88 [19:06<11:38, 20.55s/epoch, loss=1.11, accuracy=0.757, val_loss=2.39, val_accuracy=0.392, lr=0.1] 62%|██████▎   | 55/88 [19:27<11:23, 20.72s/epoch, loss=1.11, accuracy=0.755, val_loss=1.6, val_accuracy=0.607, lr=0.1]  64%|██████▎   | 56/88 [19:48<11:04, 20.77s/epoch, loss=1.11, accuracy=0.757, val_loss=2.22, val_accuracy=0.406, lr=0.1] 65%|██████▍   | 57/88 [20:08<10:40, 20.67s/epoch, loss=1.11, accuracy=0.756, val_loss=2.13, val_accuracy=0.509, lr=0.1] 66%|██████▌   | 58/88 [20:27<10:08, 20.29s/epoch, loss=1.11, accuracy=0.758, val_loss=2.32, val_accuracy=0.386, lr=0.0316] 67%|██████▋   | 59/88 [20:48<09:53, 20.46s/epoch, loss=1.11, accuracy=0.758, val_loss=2.97, val_accuracy=0.354, lr=0.1]    68%|██████▊   | 60/88 [21:09<09:30, 20.37s/epoch, loss=1.11, accuracy=0.756, val_loss=2.39, val_accuracy=0.476, lr=0.1] 69%|██████▉   | 61/88 [21:29<09:12, 20.48s/epoch, loss=1.11, accuracy=0.757, val_loss=1.89, val_accuracy=0.566, lr=0.1] 70%|███████   | 62/88 [21:50<08:55, 20.59s/epoch, loss=1.11, accuracy=0.759, val_loss=2.62, val_accuracy=0.482, lr=0.1] 72%|███████▏  | 63/88 [22:11<08:39, 20.76s/epoch, loss=1.11, accuracy=0.754, val_loss=3.9, val_accuracy=0.314, lr=0.0316] 73%|███████▎  | 64/88 [22:31<08:14, 20.60s/epoch, loss=1.11, accuracy=0.756, val_loss=2.53, val_accuracy=0.495, lr=0.1]   74%|███████▍  | 65/88 [22:53<07:57, 20.75s/epoch, loss=1.12, accuracy=0.759, val_loss=1.87, val_accuracy=0.542, lr=0.1] 75%|███████▌  | 66/88 [23:13<07:35, 20.69s/epoch, loss=1.11, accuracy=0.76, val_loss=1.74, val_accuracy=0.553, lr=0.1]  76%|███████▌  | 67/88 [23:33<07:10, 20.52s/epoch, loss=1.11, accuracy=0.758, val_loss=2.9, val_accuracy=0.361, lr=0.1] 77%|███████▋  | 68/88 [23:53<06:45, 20.26s/epoch, loss=1.11, accuracy=0.756, val_loss=2.47, val_accuracy=0.478, lr=0.0316] 78%|███████▊  | 69/88 [24:13<06:26, 20.34s/epoch, loss=1.11, accuracy=0.756, val_loss=1.92, val_accuracy=0.536, lr=0.1]    80%|███████▉  | 70/88 [24:34<06:06, 20.35s/epoch, loss=1.11, accuracy=0.758, val_loss=1.97, val_accuracy=0.556, lr=0.1] 81%|████████  | 71/88 [24:54<05:44, 20.26s/epoch, loss=1.12, accuracy=0.757, val_loss=2.31, val_accuracy=0.438, lr=0.1] 82%|████████▏ | 72/88 [25:14<05:21, 20.07s/epoch, loss=1.1, accuracy=0.761, val_loss=1.85, val_accuracy=0.526, lr=0.1]  83%|████████▎ | 73/88 [25:34<05:03, 20.23s/epoch, loss=1.11, accuracy=0.758, val_loss=1.87, val_accuracy=0.556, lr=0.0316] 84%|████████▍ | 74/88 [25:54<04:39, 19.99s/epoch, loss=1.11, accuracy=0.758, val_loss=1.7, val_accuracy=0.604, lr=0.1]     85%|████████▌ | 75/88 [26:14<04:22, 20.16s/epoch, loss=1.1, accuracy=0.759, val_loss=3.67, val_accuracy=0.248, lr=0.1] 86%|████████▋ | 76/88 [26:34<04:02, 20.19s/epoch, loss=1.11, accuracy=0.757, val_loss=2.2, val_accuracy=0.51, lr=0.1]  88%|████████▊ | 77/88 [26:54<03:41, 20.16s/epoch, loss=1.1, accuracy=0.761, val_loss=1.72, val_accuracy=0.532, lr=0.1] 89%|████████▊ | 78/88 [27:14<03:21, 20.12s/epoch, loss=1.11, accuracy=0.758, val_loss=1.53, val_accuracy=0.617, lr=0.0316] 90%|████████▉ | 79/88 [27:35<03:02, 20.30s/epoch, loss=1.11, accuracy=0.758, val_loss=2.68, val_accuracy=0.416, lr=0.1]    91%|█████████ | 80/88 [27:56<02:43, 20.44s/epoch, loss=1.11, accuracy=0.761, val_loss=1.59, val_accuracy=0.613, lr=0.1] 92%|█████████▏| 81/88 [28:17<02:23, 20.51s/epoch, loss=1.11, accuracy=0.757, val_loss=1.67, val_accuracy=0.567, lr=0.1] 93%|█████████▎| 82/88 [28:37<02:01, 20.32s/epoch, loss=0.909, accuracy=0.815, val_loss=0.924, val_accuracy=0.794, lr=0.01] 94%|█████████▍| 83/88 [28:57<01:42, 20.47s/epoch, loss=0.737, accuracy=0.847, val_loss=0.82, val_accuracy=0.806, lr=0.01]  95%|█████████▌| 84/88 [29:18<01:22, 20.62s/epoch, loss=0.66, accuracy=0.856, val_loss=0.739, val_accuracy=0.82, lr=0.01]  97%|█████████▋| 85/88 [29:39<01:01, 20.62s/epoch, loss=0.616, accuracy=0.858, val_loss=0.966, val_accuracy=0.729, lr=0.01] 98%|█████████▊| 86/88 [30:00<00:41, 20.75s/epoch, loss=0.591, accuracy=0.859, val_loss=0.76, val_accuracy=0.801, lr=0.01]  99%|█████████▉| 87/88 [30:20<00:20, 20.63s/epoch, loss=0.574, accuracy=0.862, val_loss=0.828, val_accuracy=0.784, lr=0.01]100%|██████████| 88/88 [30:41<00:00, 20.65s/epoch, loss=0.566, accuracy=0.863, val_loss=0.691, val_accuracy=0.813, lr=0.01]100%|██████████| 88/88 [30:41<00:00, 20.93s/epoch, loss=0.566, accuracy=0.863, val_loss=0.691, val_accuracy=0.813, lr=0.01]
Using real-time data augmentation.
Test score: 0.7397826313972473
Test accuracy: 0.819100022315979


* * * Run SGD for ID = 17_11. * * *


2024-02-20 03:37:37.757150: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 03:37:41.232832: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 03:37:41.233999: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-20 03:37:41.272964: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-20 03:37:41.273003: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 03:37:41.276302: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 03:37:41.276371: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-20 03:37:41.279095: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-20 03:37:41.280171: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-20 03:37:41.282725: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-20 03:37:41.284339: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-20 03:37:41.289431: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 03:37:41.290042: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-20 03:37:41.290145: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 03:37:42.860197: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-20 03:37:42.861259: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 03:37:42.861900: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-20 03:37:42.861943: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 03:37:42.861978: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 03:37:42.861997: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-20 03:37:42.862013: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-20 03:37:42.862030: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-20 03:37:42.862046: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-20 03:37:42.862090: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-20 03:37:42.862108: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 03:37:42.862600: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-20 03:37:42.862637: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 03:37:43.547927: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-20 03:37:43.547983: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-20 03:37:43.547994: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-20 03:37:43.548988: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:02:00.0, compute capability: 6.1)
{'id': '17_11', 'batch_size': 128, 'epochs': 88, 'validation_split': 0.1, 'checkpointing': True, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
x_train shape: (45000, 32, 32, 3)
45000 train samples
5000 validation samples
10000 test samples
y_train shape: (45000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/88 [00:00<?, ?epoch/s]2024-02-20 03:37:44.425846: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-20 03:37:44.438175: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199825000 Hz
2024-02-20 03:37:46.647542: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 03:37:46.884985: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 03:37:47.628938: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-20 03:37:47.687679: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/88 [00:59<1:26:15, 59.49s/epoch, loss=3.54, accuracy=0.25, val_loss=2.89, val_accuracy=0.156, lr=0.1]  2%|▏         | 2/88 [01:18<51:21, 35.83s/epoch, loss=1.72, accuracy=0.464, val_loss=1.9, val_accuracy=0.363, lr=0.1]    3%|▎         | 3/88 [01:38<40:07, 28.32s/epoch, loss=1.51, accuracy=0.56, val_loss=2.08, val_accuracy=0.35, lr=0.1]   5%|▍         | 4/88 [01:57<34:46, 24.84s/epoch, loss=1.42, accuracy=0.61, val_loss=1.77, val_accuracy=0.515, lr=0.1]  6%|▌         | 5/88 [02:16<31:21, 22.67s/epoch, loss=1.37, accuracy=0.649, val_loss=4.71, val_accuracy=0.292, lr=0.1]  7%|▋         | 6/88 [02:37<30:08, 22.05s/epoch, loss=1.34, accuracy=0.673, val_loss=2.61, val_accuracy=0.378, lr=0.1]  8%|▊         | 7/88 [02:58<29:18, 21.70s/epoch, loss=1.3, accuracy=0.695, val_loss=1.73, val_accuracy=0.523, lr=0.1]   9%|▉         | 8/88 [03:19<28:35, 21.44s/epoch, loss=1.28, accuracy=0.702, val_loss=1.77, val_accuracy=0.55, lr=0.1] 10%|█         | 9/88 [03:38<27:22, 20.80s/epoch, loss=1.27, accuracy=0.712, val_loss=1.98, val_accuracy=0.53, lr=0.1] 11%|█▏        | 10/88 [03:59<26:56, 20.72s/epoch, loss=1.25, accuracy=0.72, val_loss=2.21, val_accuracy=0.452, lr=0.1] 12%|█▎        | 11/88 [04:19<26:24, 20.58s/epoch, loss=1.25, accuracy=0.724, val_loss=2.65, val_accuracy=0.393, lr=0.1] 14%|█▎        | 12/88 [04:39<25:46, 20.35s/epoch, loss=1.23, accuracy=0.727, val_loss=2.12, val_accuracy=0.451, lr=0.0316] 15%|█▍        | 13/88 [04:59<25:30, 20.40s/epoch, loss=1.23, accuracy=0.725, val_loss=1.5, val_accuracy=0.636, lr=0.1]     16%|█▌        | 14/88 [05:18<24:42, 20.04s/epoch, loss=1.22, accuracy=0.732, val_loss=2.28, val_accuracy=0.496, lr=0.1] 17%|█▋        | 15/88 [05:38<24:22, 20.04s/epoch, loss=1.21, accuracy=0.734, val_loss=3.47, val_accuracy=0.402, lr=0.1] 18%|█▊        | 16/88 [05:59<24:15, 20.22s/epoch, loss=1.21, accuracy=0.735, val_loss=2, val_accuracy=0.456, lr=0.1]    19%|█▉        | 17/88 [06:19<23:57, 20.25s/epoch, loss=1.21, accuracy=0.736, val_loss=2.06, val_accuracy=0.49, lr=0.1] 20%|██        | 18/88 [06:40<23:53, 20.48s/epoch, loss=1.21, accuracy=0.739, val_loss=2.11, val_accuracy=0.414, lr=0.0316] 22%|██▏       | 19/88 [07:01<23:43, 20.63s/epoch, loss=1.21, accuracy=0.737, val_loss=2.15, val_accuracy=0.493, lr=0.1]    23%|██▎       | 20/88 [07:21<23:00, 20.30s/epoch, loss=1.2, accuracy=0.741, val_loss=2.01, val_accuracy=0.525, lr=0.1]  24%|██▍       | 21/88 [07:41<22:35, 20.24s/epoch, loss=1.2, accuracy=0.743, val_loss=3.02, val_accuracy=0.45, lr=0.1]  25%|██▌       | 22/88 [08:01<22:03, 20.05s/epoch, loss=1.19, accuracy=0.743, val_loss=1.78, val_accuracy=0.553, lr=0.1] 26%|██▌       | 23/88 [08:21<21:54, 20.22s/epoch, loss=1.19, accuracy=0.742, val_loss=1.94, val_accuracy=0.563, lr=0.0316] 27%|██▋       | 24/88 [08:42<21:49, 20.46s/epoch, loss=1.19, accuracy=0.743, val_loss=3, val_accuracy=0.341, lr=0.1]       28%|██▊       | 25/88 [09:02<21:10, 20.17s/epoch, loss=1.19, accuracy=0.743, val_loss=3.44, val_accuracy=0.374, lr=0.1] 30%|██▉       | 26/88 [09:22<20:49, 20.15s/epoch, loss=1.19, accuracy=0.745, val_loss=2.41, val_accuracy=0.417, lr=0.1] 31%|███       | 27/88 [09:43<20:47, 20.45s/epoch, loss=1.18, accuracy=0.747, val_loss=2.95, val_accuracy=0.334, lr=0.1] 32%|███▏      | 28/88 [10:04<20:34, 20.58s/epoch, loss=1.18, accuracy=0.746, val_loss=1.68, val_accuracy=0.6, lr=0.0316] 33%|███▎      | 29/88 [10:24<20:05, 20.44s/epoch, loss=1.18, accuracy=0.746, val_loss=1.63, val_accuracy=0.576, lr=0.1]  34%|███▍      | 30/88 [10:45<19:53, 20.58s/epoch, loss=1.17, accuracy=0.749, val_loss=1.59, val_accuracy=0.624, lr=0.1] 35%|███▌      | 31/88 [11:05<19:18, 20.33s/epoch, loss=1.18, accuracy=0.746, val_loss=1.72, val_accuracy=0.548, lr=0.1] 36%|███▋      | 32/88 [11:26<19:07, 20.48s/epoch, loss=1.17, accuracy=0.749, val_loss=1.82, val_accuracy=0.565, lr=0.1] 38%|███▊      | 33/88 [11:46<18:52, 20.59s/epoch, loss=1.18, accuracy=0.749, val_loss=2, val_accuracy=0.491, lr=0.0316] 39%|███▊      | 34/88 [12:08<18:45, 20.85s/epoch, loss=1.17, accuracy=0.75, val_loss=1.54, val_accuracy=0.641, lr=0.1]  40%|███▉      | 35/88 [12:28<18:08, 20.53s/epoch, loss=1.17, accuracy=0.748, val_loss=1.79, val_accuracy=0.53, lr=0.1] 41%|████      | 36/88 [12:49<17:53, 20.64s/epoch, loss=1.17, accuracy=0.747, val_loss=3.35, val_accuracy=0.267, lr=0.1] 42%|████▏     | 37/88 [13:08<17:14, 20.29s/epoch, loss=1.17, accuracy=0.748, val_loss=3.51, val_accuracy=0.443, lr=0.1] 43%|████▎     | 38/88 [13:29<16:59, 20.39s/epoch, loss=1.16, accuracy=0.752, val_loss=1.93, val_accuracy=0.474, lr=0.0316] 44%|████▍     | 39/88 [13:50<16:47, 20.56s/epoch, loss=1.16, accuracy=0.752, val_loss=2.02, val_accuracy=0.476, lr=0.1]    45%|████▌     | 40/88 [14:11<16:34, 20.73s/epoch, loss=1.15, accuracy=0.752, val_loss=1.97, val_accuracy=0.431, lr=0.1] 47%|████▋     | 41/88 [14:32<16:15, 20.76s/epoch, loss=1.16, accuracy=0.751, val_loss=2.08, val_accuracy=0.425, lr=0.1] 48%|████▊     | 42/88 [14:53<15:58, 20.84s/epoch, loss=1.16, accuracy=0.751, val_loss=4.61, val_accuracy=0.229, lr=0.1] 49%|████▉     | 43/88 [15:14<15:41, 20.92s/epoch, loss=1.16, accuracy=0.751, val_loss=2.47, val_accuracy=0.335, lr=0.0316] 50%|█████     | 44/88 [15:34<15:19, 20.90s/epoch, loss=1.16, accuracy=0.75, val_loss=2.25, val_accuracy=0.484, lr=0.1]     51%|█████     | 45/88 [15:56<15:00, 20.94s/epoch, loss=1.16, accuracy=0.751, val_loss=1.38, val_accuracy=0.679, lr=0.1] 52%|█████▏    | 46/88 [16:15<14:25, 20.61s/epoch, loss=1.15, accuracy=0.755, val_loss=1.82, val_accuracy=0.535, lr=0.1] 53%|█████▎    | 47/88 [16:36<14:01, 20.51s/epoch, loss=1.15, accuracy=0.752, val_loss=2.04, val_accuracy=0.44, lr=0.1]  55%|█████▍    | 48/88 [16:57<13:46, 20.66s/epoch, loss=1.15, accuracy=0.756, val_loss=2.43, val_accuracy=0.382, lr=0.1] 56%|█████▌    | 49/88 [17:17<13:26, 20.67s/epoch, loss=1.15, accuracy=0.752, val_loss=1.42, val_accuracy=0.659, lr=0.1] 57%|█████▋    | 50/88 [17:37<12:59, 20.50s/epoch, loss=1.15, accuracy=0.752, val_loss=2.26, val_accuracy=0.443, lr=0.0316] 58%|█████▊    | 51/88 [17:58<12:41, 20.58s/epoch, loss=1.14, accuracy=0.755, val_loss=1.88, val_accuracy=0.514, lr=0.1]    59%|█████▉    | 52/88 [18:18<12:14, 20.41s/epoch, loss=1.15, accuracy=0.755, val_loss=5.64, val_accuracy=0.23, lr=0.1]  60%|██████    | 53/88 [18:39<11:55, 20.45s/epoch, loss=1.15, accuracy=0.751, val_loss=2.37, val_accuracy=0.45, lr=0.1] 61%|██████▏   | 54/88 [19:00<11:40, 20.61s/epoch, loss=1.14, accuracy=0.754, val_loss=1.95, val_accuracy=0.534, lr=0.1] 62%|██████▎   | 55/88 [19:21<11:22, 20.69s/epoch, loss=1.14, accuracy=0.755, val_loss=1.63, val_accuracy=0.605, lr=0.0316] 64%|██████▎   | 56/88 [19:42<11:04, 20.76s/epoch, loss=1.14, accuracy=0.755, val_loss=1.48, val_accuracy=0.654, lr=0.1]    65%|██████▍   | 57/88 [20:01<10:34, 20.48s/epoch, loss=1.14, accuracy=0.754, val_loss=2.38, val_accuracy=0.474, lr=0.1] 66%|██████▌   | 58/88 [20:21<10:10, 20.36s/epoch, loss=1.14, accuracy=0.754, val_loss=2.08, val_accuracy=0.486, lr=0.1] 67%|██████▋   | 59/88 [20:42<09:53, 20.47s/epoch, loss=1.14, accuracy=0.753, val_loss=1.74, val_accuracy=0.547, lr=0.1] 68%|██████▊   | 60/88 [21:03<09:37, 20.61s/epoch, loss=1.14, accuracy=0.755, val_loss=2.72, val_accuracy=0.323, lr=0.0316] 69%|██████▉   | 61/88 [21:24<09:19, 20.72s/epoch, loss=1.14, accuracy=0.753, val_loss=1.64, val_accuracy=0.596, lr=0.1]    70%|███████   | 62/88 [21:44<08:52, 20.49s/epoch, loss=1.14, accuracy=0.755, val_loss=2.07, val_accuracy=0.462, lr=0.1] 72%|███████▏  | 63/88 [22:04<08:30, 20.42s/epoch, loss=1.14, accuracy=0.755, val_loss=2.7, val_accuracy=0.413, lr=0.1]  73%|███████▎  | 64/88 [22:25<08:11, 20.48s/epoch, loss=1.14, accuracy=0.755, val_loss=2.22, val_accuracy=0.406, lr=0.1] 74%|███████▍  | 65/88 [22:45<07:51, 20.50s/epoch, loss=1.14, accuracy=0.754, val_loss=2.45, val_accuracy=0.488, lr=0.0316] 75%|███████▌  | 66/88 [23:06<07:29, 20.44s/epoch, loss=1.13, accuracy=0.755, val_loss=1.91, val_accuracy=0.509, lr=0.1]    76%|███████▌  | 67/88 [23:27<07:12, 20.61s/epoch, loss=1.14, accuracy=0.754, val_loss=2.09, val_accuracy=0.535, lr=0.1] 77%|███████▋  | 68/88 [23:47<06:49, 20.46s/epoch, loss=1.14, accuracy=0.754, val_loss=1.58, val_accuracy=0.588, lr=0.1] 78%|███████▊  | 69/88 [24:07<06:24, 20.23s/epoch, loss=1.13, accuracy=0.759, val_loss=4.45, val_accuracy=0.321, lr=0.1] 80%|███████▉  | 70/88 [24:26<06:01, 20.08s/epoch, loss=1.13, accuracy=0.757, val_loss=4.02, val_accuracy=0.309, lr=0.0316] 81%|████████  | 71/88 [24:46<05:38, 19.89s/epoch, loss=1.14, accuracy=0.755, val_loss=2.28, val_accuracy=0.494, lr=0.1]    82%|████████▏ | 72/88 [25:05<05:16, 19.76s/epoch, loss=1.14, accuracy=0.755, val_loss=3.08, val_accuracy=0.285, lr=0.1] 83%|████████▎ | 73/88 [25:26<05:02, 20.19s/epoch, loss=1.14, accuracy=0.757, val_loss=3.29, val_accuracy=0.424, lr=0.1] 84%|████████▍ | 74/88 [25:47<04:44, 20.33s/epoch, loss=1.14, accuracy=0.754, val_loss=2.11, val_accuracy=0.48, lr=0.1]  85%|████████▌ | 75/88 [26:08<04:28, 20.62s/epoch, loss=1.14, accuracy=0.758, val_loss=2.14, val_accuracy=0.474, lr=0.0316] 86%|████████▋ | 76/88 [26:30<04:09, 20.82s/epoch, loss=1.13, accuracy=0.757, val_loss=1.96, val_accuracy=0.478, lr=0.1]    88%|████████▊ | 77/88 [26:49<03:43, 20.36s/epoch, loss=1.14, accuracy=0.754, val_loss=1.98, val_accuracy=0.469, lr=0.1] 89%|████████▊ | 78/88 [27:10<03:24, 20.43s/epoch, loss=1.13, accuracy=0.757, val_loss=2.24, val_accuracy=0.388, lr=0.1] 90%|████████▉ | 79/88 [27:29<03:00, 20.01s/epoch, loss=1.13, accuracy=0.755, val_loss=1.98, val_accuracy=0.475, lr=0.1] 91%|█████████ | 80/88 [27:49<02:40, 20.12s/epoch, loss=1.14, accuracy=0.754, val_loss=1.99, val_accuracy=0.511, lr=0.0316] 92%|█████████▏| 81/88 [28:08<02:18, 19.80s/epoch, loss=1.13, accuracy=0.755, val_loss=2.18, val_accuracy=0.467, lr=0.1]    93%|█████████▎| 82/88 [28:27<01:57, 19.65s/epoch, loss=0.934, accuracy=0.814, val_loss=0.889, val_accuracy=0.818, lr=0.01] 94%|█████████▍| 83/88 [28:47<01:38, 19.61s/epoch, loss=0.753, accuracy=0.847, val_loss=0.87, val_accuracy=0.801, lr=0.01]  95%|█████████▌| 84/88 [29:07<01:19, 19.90s/epoch, loss=0.67, accuracy=0.857, val_loss=0.903, val_accuracy=0.77, lr=0.01]  97%|█████████▋| 85/88 [29:28<01:00, 20.17s/epoch, loss=0.62, accuracy=0.861, val_loss=1.13, val_accuracy=0.695, lr=0.01] 98%|█████████▊| 86/88 [29:48<00:40, 20.12s/epoch, loss=0.601, accuracy=0.862, val_loss=0.874, val_accuracy=0.769, lr=0.01] 99%|█████████▉| 87/88 [30:08<00:20, 20.09s/epoch, loss=0.578, accuracy=0.866, val_loss=0.725, val_accuracy=0.815, lr=0.01]100%|██████████| 88/88 [30:28<00:00, 19.94s/epoch, loss=0.577, accuracy=0.863, val_loss=1.26, val_accuracy=0.673, lr=0.01] 100%|██████████| 88/88 [30:28<00:00, 20.78s/epoch, loss=0.577, accuracy=0.863, val_loss=1.26, val_accuracy=0.673, lr=0.01]
Using real-time data augmentation.
Test score: 0.9030041694641113
Test accuracy: 0.8097000122070312


* * * Run SGD for ID = 17_12. * * *


2024-02-20 04:08:18.885765: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 04:08:24.811967: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 04:08:24.813594: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-20 04:08:24.851764: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-20 04:08:24.851794: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 04:08:24.878654: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 04:08:24.878706: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-20 04:08:24.891935: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-20 04:08:24.910413: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-20 04:08:24.937304: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-20 04:08:24.955675: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-20 04:08:24.971512: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 04:08:24.972174: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-20 04:08:24.972284: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 04:08:26.634390: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-20 04:08:26.634976: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 04:08:26.635480: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-20 04:08:26.635512: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 04:08:26.635546: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 04:08:26.635563: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-20 04:08:26.635578: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-20 04:08:26.635594: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-20 04:08:26.635609: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-20 04:08:26.635625: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-20 04:08:26.635640: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 04:08:26.636105: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-20 04:08:26.636138: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 04:08:27.584876: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-20 04:08:27.584941: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-20 04:08:27.584952: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-20 04:08:27.586147: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:02:00.0, compute capability: 6.1)
{'id': '17_12', 'batch_size': 128, 'epochs': 88, 'validation_split': 0.1, 'checkpointing': True, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
x_train shape: (45000, 32, 32, 3)
45000 train samples
5000 validation samples
10000 test samples
y_train shape: (45000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/88 [00:00<?, ?epoch/s]2024-02-20 04:08:28.396384: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-20 04:08:28.408282: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199825000 Hz
2024-02-20 04:08:30.367003: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 04:08:30.670438: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 04:08:31.665506: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-20 04:08:31.701966: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/88 [00:47<1:08:12, 47.04s/epoch, loss=3.35, accuracy=0.257, val_loss=3.22, val_accuracy=0.177, lr=0.1]  2%|▏         | 2/88 [01:06<44:13, 30.86s/epoch, loss=1.66, accuracy=0.488, val_loss=1.75, val_accuracy=0.468, lr=0.1]    3%|▎         | 3/88 [01:26<36:20, 25.65s/epoch, loss=1.39, accuracy=0.618, val_loss=1.87, val_accuracy=0.481, lr=0.1]  5%|▍         | 4/88 [01:45<32:29, 23.20s/epoch, loss=1.29, accuracy=0.674, val_loss=1.82, val_accuracy=0.515, lr=0.1]  6%|▌         | 5/88 [02:05<30:31, 22.07s/epoch, loss=1.26, accuracy=0.695, val_loss=2.35, val_accuracy=0.352, lr=0.1]  7%|▋         | 6/88 [02:25<29:01, 21.24s/epoch, loss=1.25, accuracy=0.705, val_loss=2.02, val_accuracy=0.484, lr=0.1]  8%|▊         | 7/88 [02:44<28:00, 20.75s/epoch, loss=1.22, accuracy=0.717, val_loss=3.08, val_accuracy=0.248, lr=0.0316]  9%|▉         | 8/88 [03:04<27:04, 20.30s/epoch, loss=1.22, accuracy=0.722, val_loss=2.15, val_accuracy=0.44, lr=0.1]     10%|█         | 9/88 [03:25<26:59, 20.50s/epoch, loss=1.21, accuracy=0.725, val_loss=1.93, val_accuracy=0.522, lr=0.1] 11%|█▏        | 10/88 [03:44<26:07, 20.09s/epoch, loss=1.21, accuracy=0.728, val_loss=2.61, val_accuracy=0.414, lr=0.1] 12%|█▎        | 11/88 [04:04<25:47, 20.10s/epoch, loss=1.21, accuracy=0.731, val_loss=2.51, val_accuracy=0.412, lr=0.1] 14%|█▎        | 12/88 [04:25<25:38, 20.24s/epoch, loss=1.19, accuracy=0.735, val_loss=3.19, val_accuracy=0.367, lr=0.0316] 15%|█▍        | 13/88 [04:46<25:45, 20.61s/epoch, loss=1.2, accuracy=0.736, val_loss=2.31, val_accuracy=0.493, lr=0.1]     16%|█▌        | 14/88 [05:06<25:15, 20.48s/epoch, loss=1.2, accuracy=0.736, val_loss=1.71, val_accuracy=0.571, lr=0.1] 17%|█▋        | 15/88 [05:26<24:50, 20.42s/epoch, loss=1.2, accuracy=0.739, val_loss=2.05, val_accuracy=0.484, lr=0.1] 18%|█▊        | 16/88 [05:47<24:38, 20.53s/epoch, loss=1.19, accuracy=0.738, val_loss=1.65, val_accuracy=0.594, lr=0.1] 19%|█▉        | 17/88 [06:07<23:55, 20.22s/epoch, loss=1.18, accuracy=0.743, val_loss=1.97, val_accuracy=0.534, lr=0.1] 20%|██        | 18/88 [06:27<23:33, 20.19s/epoch, loss=1.18, accuracy=0.742, val_loss=1.48, val_accuracy=0.643, lr=0.1] 22%|██▏       | 19/88 [06:47<23:07, 20.11s/epoch, loss=1.19, accuracy=0.738, val_loss=1.65, val_accuracy=0.608, lr=0.1] 23%|██▎       | 20/88 [07:06<22:35, 19.94s/epoch, loss=1.18, accuracy=0.741, val_loss=1.58, val_accuracy=0.601, lr=0.1] 24%|██▍       | 21/88 [07:26<22:13, 19.91s/epoch, loss=1.18, accuracy=0.742, val_loss=1.55, val_accuracy=0.631, lr=0.1] 25%|██▌       | 22/88 [07:46<21:48, 19.83s/epoch, loss=1.18, accuracy=0.744, val_loss=1.87, val_accuracy=0.569, lr=0.1] 26%|██▌       | 23/88 [08:06<21:38, 19.98s/epoch, loss=1.17, accuracy=0.743, val_loss=1.83, val_accuracy=0.549, lr=0.0316] 27%|██▋       | 24/88 [08:26<21:18, 19.97s/epoch, loss=1.18, accuracy=0.744, val_loss=1.69, val_accuracy=0.573, lr=0.1]    28%|██▊       | 25/88 [08:46<20:52, 19.88s/epoch, loss=1.17, accuracy=0.744, val_loss=3.26, val_accuracy=0.354, lr=0.1] 30%|██▉       | 26/88 [09:07<20:51, 20.19s/epoch, loss=1.17, accuracy=0.746, val_loss=2.32, val_accuracy=0.481, lr=0.1] 31%|███       | 27/88 [09:27<20:36, 20.26s/epoch, loss=1.18, accuracy=0.743, val_loss=1.96, val_accuracy=0.467, lr=0.1] 32%|███▏      | 28/88 [09:49<20:36, 20.61s/epoch, loss=1.16, accuracy=0.75, val_loss=2.74, val_accuracy=0.331, lr=0.0316] 33%|███▎      | 29/88 [10:08<19:58, 20.32s/epoch, loss=1.16, accuracy=0.75, val_loss=1.96, val_accuracy=0.466, lr=0.1]    34%|███▍      | 30/88 [10:29<19:54, 20.59s/epoch, loss=1.16, accuracy=0.748, val_loss=2.28, val_accuracy=0.488, lr=0.1] 35%|███▌      | 31/88 [10:49<19:16, 20.28s/epoch, loss=1.17, accuracy=0.748, val_loss=1.74, val_accuracy=0.51, lr=0.1]  36%|███▋      | 32/88 [11:09<18:44, 20.08s/epoch, loss=1.16, accuracy=0.748, val_loss=1.8, val_accuracy=0.566, lr=0.1] 38%|███▊      | 33/88 [11:28<18:14, 19.90s/epoch, loss=1.16, accuracy=0.749, val_loss=2.04, val_accuracy=0.486, lr=0.0316] 39%|███▊      | 34/88 [11:48<17:53, 19.88s/epoch, loss=1.16, accuracy=0.749, val_loss=1.51, val_accuracy=0.639, lr=0.1]    40%|███▉      | 35/88 [12:08<17:33, 19.87s/epoch, loss=1.17, accuracy=0.751, val_loss=1.47, val_accuracy=0.622, lr=0.1] 41%|████      | 36/88 [12:28<17:17, 19.95s/epoch, loss=1.16, accuracy=0.749, val_loss=1.99, val_accuracy=0.547, lr=0.1] 42%|████▏     | 37/88 [12:49<17:20, 20.41s/epoch, loss=1.16, accuracy=0.751, val_loss=1.79, val_accuracy=0.564, lr=0.1] 43%|████▎     | 38/88 [13:09<16:51, 20.22s/epoch, loss=1.16, accuracy=0.75, val_loss=1.77, val_accuracy=0.555, lr=0.1]  44%|████▍     | 39/88 [13:29<16:23, 20.08s/epoch, loss=1.16, accuracy=0.751, val_loss=1.85, val_accuracy=0.542, lr=0.1] 45%|████▌     | 40/88 [13:48<15:54, 19.88s/epoch, loss=1.16, accuracy=0.751, val_loss=1.5, val_accuracy=0.62, lr=0.0316] 47%|████▋     | 41/88 [14:08<15:28, 19.75s/epoch, loss=1.16, accuracy=0.75, val_loss=2.13, val_accuracy=0.409, lr=0.1]   48%|████▊     | 42/88 [14:27<15:06, 19.71s/epoch, loss=1.15, accuracy=0.754, val_loss=1.8, val_accuracy=0.532, lr=0.1] 49%|████▉     | 43/88 [14:47<14:52, 19.83s/epoch, loss=1.15, accuracy=0.752, val_loss=1.65, val_accuracy=0.563, lr=0.1] 50%|█████     | 44/88 [15:07<14:30, 19.78s/epoch, loss=1.15, accuracy=0.754, val_loss=1.88, val_accuracy=0.534, lr=0.1] 51%|█████     | 45/88 [15:27<14:17, 19.95s/epoch, loss=1.15, accuracy=0.754, val_loss=3.11, val_accuracy=0.409, lr=0.0316] 52%|█████▏    | 46/88 [15:47<13:53, 19.84s/epoch, loss=1.16, accuracy=0.75, val_loss=1.62, val_accuracy=0.6, lr=0.1]       53%|█████▎    | 47/88 [16:08<13:45, 20.15s/epoch, loss=1.15, accuracy=0.751, val_loss=2.86, val_accuracy=0.404, lr=0.1] 55%|█████▍    | 48/88 [16:29<13:39, 20.48s/epoch, loss=1.14, accuracy=0.754, val_loss=1.63, val_accuracy=0.598, lr=0.1] 56%|█████▌    | 49/88 [16:49<13:11, 20.28s/epoch, loss=1.15, accuracy=0.753, val_loss=1.53, val_accuracy=0.618, lr=0.1] 57%|█████▋    | 50/88 [17:09<12:46, 20.16s/epoch, loss=1.14, accuracy=0.754, val_loss=2.24, val_accuracy=0.361, lr=0.0316] 58%|█████▊    | 51/88 [17:29<12:20, 20.02s/epoch, loss=1.14, accuracy=0.755, val_loss=1.55, val_accuracy=0.597, lr=0.1]    59%|█████▉    | 52/88 [17:49<12:07, 20.20s/epoch, loss=1.15, accuracy=0.754, val_loss=2.32, val_accuracy=0.456, lr=0.1] 60%|██████    | 53/88 [18:10<11:51, 20.32s/epoch, loss=1.15, accuracy=0.754, val_loss=2.06, val_accuracy=0.442, lr=0.1] 61%|██████▏   | 54/88 [18:29<11:22, 20.06s/epoch, loss=1.15, accuracy=0.753, val_loss=2.29, val_accuracy=0.426, lr=0.1] 62%|██████▎   | 55/88 [18:49<11:01, 20.04s/epoch, loss=1.14, accuracy=0.755, val_loss=1.96, val_accuracy=0.541, lr=0.0316] 64%|██████▎   | 56/88 [19:09<10:39, 19.98s/epoch, loss=1.14, accuracy=0.754, val_loss=3.35, val_accuracy=0.276, lr=0.1]    65%|██████▍   | 57/88 [19:29<10:15, 19.87s/epoch, loss=1.14, accuracy=0.754, val_loss=1.9, val_accuracy=0.476, lr=0.1]  66%|██████▌   | 58/88 [19:48<09:52, 19.74s/epoch, loss=1.14, accuracy=0.755, val_loss=2.03, val_accuracy=0.52, lr=0.1] 67%|██████▋   | 59/88 [20:08<09:30, 19.68s/epoch, loss=1.14, accuracy=0.755, val_loss=1.85, val_accuracy=0.574, lr=0.1] 68%|██████▊   | 60/88 [20:27<09:10, 19.65s/epoch, loss=1.14, accuracy=0.753, val_loss=1.47, val_accuracy=0.64, lr=0.1]  69%|██████▉   | 61/88 [20:47<08:50, 19.64s/epoch, loss=1.14, accuracy=0.754, val_loss=1.8, val_accuracy=0.589, lr=0.1] 70%|███████   | 62/88 [21:08<08:41, 20.07s/epoch, loss=1.14, accuracy=0.753, val_loss=2.37, val_accuracy=0.415, lr=0.1] 72%|███████▏  | 63/88 [21:27<08:17, 19.89s/epoch, loss=1.14, accuracy=0.754, val_loss=1.59, val_accuracy=0.602, lr=0.1] 73%|███████▎  | 64/88 [21:47<07:54, 19.77s/epoch, loss=1.14, accuracy=0.753, val_loss=2.6, val_accuracy=0.444, lr=0.1]  74%|███████▍  | 65/88 [22:08<07:45, 20.26s/epoch, loss=1.14, accuracy=0.756, val_loss=5.71, val_accuracy=0.174, lr=0.0316] 75%|███████▌  | 66/88 [22:30<07:32, 20.55s/epoch, loss=1.15, accuracy=0.75, val_loss=3.54, val_accuracy=0.394, lr=0.1]     76%|███████▌  | 67/88 [22:51<07:15, 20.75s/epoch, loss=1.15, accuracy=0.755, val_loss=2.51, val_accuracy=0.411, lr=0.1] 77%|███████▋  | 68/88 [23:12<06:55, 20.79s/epoch, loss=1.14, accuracy=0.755, val_loss=1.81, val_accuracy=0.55, lr=0.1]  78%|███████▊  | 69/88 [23:32<06:31, 20.63s/epoch, loss=1.14, accuracy=0.754, val_loss=2.55, val_accuracy=0.408, lr=0.1] 80%|███████▉  | 70/88 [23:53<06:12, 20.70s/epoch, loss=1.14, accuracy=0.753, val_loss=1.71, val_accuracy=0.579, lr=0.0316] 81%|████████  | 71/88 [24:13<05:50, 20.60s/epoch, loss=1.14, accuracy=0.753, val_loss=2.41, val_accuracy=0.449, lr=0.1]    82%|████████▏ | 72/88 [24:33<05:24, 20.29s/epoch, loss=1.13, accuracy=0.758, val_loss=2.72, val_accuracy=0.395, lr=0.1] 83%|████████▎ | 73/88 [24:53<05:03, 20.26s/epoch, loss=1.14, accuracy=0.756, val_loss=2.41, val_accuracy=0.393, lr=0.1] 84%|████████▍ | 74/88 [25:12<04:40, 20.04s/epoch, loss=1.15, accuracy=0.752, val_loss=2.42, val_accuracy=0.469, lr=0.1] 85%|████████▌ | 75/88 [25:32<04:17, 19.81s/epoch, loss=1.14, accuracy=0.756, val_loss=2.07, val_accuracy=0.489, lr=0.0316] 86%|████████▋ | 76/88 [25:52<03:59, 19.93s/epoch, loss=1.14, accuracy=0.758, val_loss=2.23, val_accuracy=0.526, lr=0.1]    88%|████████▊ | 77/88 [26:12<03:39, 19.99s/epoch, loss=1.14, accuracy=0.757, val_loss=2.21, val_accuracy=0.417, lr=0.1] 89%|████████▊ | 78/88 [26:32<03:19, 19.96s/epoch, loss=1.14, accuracy=0.758, val_loss=2.41, val_accuracy=0.461, lr=0.1] 90%|████████▉ | 79/88 [26:52<02:59, 19.89s/epoch, loss=1.15, accuracy=0.756, val_loss=2.23, val_accuracy=0.441, lr=0.1] 91%|█████████ | 80/88 [27:11<02:37, 19.73s/epoch, loss=1.14, accuracy=0.756, val_loss=2.21, val_accuracy=0.468, lr=0.0316] 92%|█████████▏| 81/88 [27:30<02:17, 19.65s/epoch, loss=1.13, accuracy=0.757, val_loss=2.51, val_accuracy=0.323, lr=0.1]    93%|█████████▎| 82/88 [27:51<01:59, 19.91s/epoch, loss=0.928, accuracy=0.813, val_loss=0.876, val_accuracy=0.812, lr=0.01] 94%|█████████▍| 83/88 [28:11<01:39, 19.82s/epoch, loss=0.753, accuracy=0.845, val_loss=0.786, val_accuracy=0.818, lr=0.01] 95%|█████████▌| 84/88 [28:30<01:18, 19.74s/epoch, loss=0.671, accuracy=0.855, val_loss=0.746, val_accuracy=0.824, lr=0.01] 97%|█████████▋| 85/88 [28:50<00:59, 19.70s/epoch, loss=0.622, accuracy=0.857, val_loss=0.845, val_accuracy=0.785, lr=0.01] 98%|█████████▊| 86/88 [29:09<00:39, 19.60s/epoch, loss=0.599, accuracy=0.861, val_loss=0.725, val_accuracy=0.822, lr=0.01] 99%|█████████▉| 87/88 [29:30<00:19, 19.95s/epoch, loss=0.584, accuracy=0.86, val_loss=0.806, val_accuracy=0.781, lr=0.01] 100%|██████████| 88/88 [29:51<00:00, 20.22s/epoch, loss=0.574, accuracy=0.864, val_loss=0.825, val_accuracy=0.779, lr=0.01]100%|██████████| 88/88 [29:51<00:00, 20.35s/epoch, loss=0.574, accuracy=0.864, val_loss=0.825, val_accuracy=0.779, lr=0.01]
Using real-time data augmentation.
Test score: 0.7631126642227173
Test accuracy: 0.8184999823570251


* * * Run SGD for ID = 17_13. * * *


2024-02-20 04:38:24.643495: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 04:38:28.508966: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 04:38:28.509875: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-20 04:38:28.548844: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-20 04:38:28.548873: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 04:38:28.551932: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 04:38:28.551972: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-20 04:38:28.554223: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-20 04:38:28.555406: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-20 04:38:28.558049: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-20 04:38:28.559598: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-20 04:38:28.564379: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 04:38:28.564905: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-20 04:38:28.564995: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 04:38:30.001485: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-20 04:38:30.002525: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 04:38:30.003341: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-20 04:38:30.003405: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 04:38:30.003449: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 04:38:30.003467: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-20 04:38:30.003485: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-20 04:38:30.003502: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-20 04:38:30.003517: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-20 04:38:30.003533: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-20 04:38:30.003550: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 04:38:30.004028: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-20 04:38:30.004092: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 04:38:30.618096: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-20 04:38:30.618161: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-20 04:38:30.618172: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-20 04:38:30.619102: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:02:00.0, compute capability: 6.1)
{'id': '17_13', 'batch_size': 128, 'epochs': 88, 'validation_split': 0.1, 'checkpointing': True, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
x_train shape: (45000, 32, 32, 3)
45000 train samples
5000 validation samples
10000 test samples
y_train shape: (45000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/88 [00:00<?, ?epoch/s]2024-02-20 04:38:31.422831: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-20 04:38:31.435248: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199825000 Hz
2024-02-20 04:38:33.390639: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 04:38:33.570500: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 04:38:34.268708: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-20 04:38:34.307413: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/88 [00:46<1:08:01, 46.92s/epoch, loss=3.48, accuracy=0.318, val_loss=2.67, val_accuracy=0.183, lr=0.1]  2%|▏         | 2/88 [01:06<44:02, 30.73s/epoch, loss=1.63, accuracy=0.524, val_loss=1.87, val_accuracy=0.449, lr=0.1]    3%|▎         | 3/88 [01:25<36:19, 25.64s/epoch, loss=1.45, accuracy=0.597, val_loss=3.17, val_accuracy=0.263, lr=0.1]  5%|▍         | 4/88 [01:45<32:35, 23.28s/epoch, loss=1.39, accuracy=0.638, val_loss=1.87, val_accuracy=0.472, lr=0.1]  6%|▌         | 5/88 [02:04<30:04, 21.75s/epoch, loss=1.35, accuracy=0.664, val_loss=2.16, val_accuracy=0.434, lr=0.1]  7%|▋         | 6/88 [02:25<29:23, 21.50s/epoch, loss=1.31, accuracy=0.685, val_loss=1.67, val_accuracy=0.59, lr=0.1]   8%|▊         | 7/88 [02:44<27:56, 20.69s/epoch, loss=1.29, accuracy=0.697, val_loss=1.72, val_accuracy=0.58, lr=0.1]  9%|▉         | 8/88 [03:03<26:58, 20.23s/epoch, loss=1.27, accuracy=0.707, val_loss=1.62, val_accuracy=0.581, lr=0.1] 10%|█         | 9/88 [03:22<26:10, 19.88s/epoch, loss=1.25, accuracy=0.716, val_loss=3.05, val_accuracy=0.372, lr=0.1] 11%|█▏        | 10/88 [03:43<25:58, 19.98s/epoch, loss=1.24, accuracy=0.72, val_loss=1.71, val_accuracy=0.57, lr=0.1]  12%|█▎        | 11/88 [04:03<25:42, 20.04s/epoch, loss=1.23, accuracy=0.726, val_loss=1.38, val_accuracy=0.666, lr=0.1] 14%|█▎        | 12/88 [04:23<25:24, 20.06s/epoch, loss=1.23, accuracy=0.727, val_loss=1.44, val_accuracy=0.649, lr=0.1] 15%|█▍        | 13/88 [04:43<25:14, 20.19s/epoch, loss=1.22, accuracy=0.727, val_loss=1.89, val_accuracy=0.519, lr=0.1] 16%|█▌        | 14/88 [05:04<24:54, 20.20s/epoch, loss=1.22, accuracy=0.729, val_loss=1.74, val_accuracy=0.528, lr=0.1] 17%|█▋        | 15/88 [05:23<24:12, 19.90s/epoch, loss=1.22, accuracy=0.729, val_loss=1.61, val_accuracy=0.6, lr=0.1]   18%|█▊        | 16/88 [05:44<24:21, 20.30s/epoch, loss=1.21, accuracy=0.731, val_loss=1.56, val_accuracy=0.618, lr=0.0316] 19%|█▉        | 17/88 [06:04<23:58, 20.27s/epoch, loss=1.21, accuracy=0.733, val_loss=1.52, val_accuracy=0.621, lr=0.1]    20%|██        | 18/88 [06:24<23:32, 20.18s/epoch, loss=1.2, accuracy=0.737, val_loss=1.44, val_accuracy=0.65, lr=0.1]   22%|██▏       | 19/88 [06:45<23:16, 20.24s/epoch, loss=1.2, accuracy=0.738, val_loss=1.4, val_accuracy=0.674, lr=0.1] 23%|██▎       | 20/88 [07:05<22:53, 20.20s/epoch, loss=1.2, accuracy=0.738, val_loss=1.58, val_accuracy=0.607, lr=0.1] 24%|██▍       | 21/88 [07:25<22:41, 20.32s/epoch, loss=1.19, accuracy=0.74, val_loss=2.42, val_accuracy=0.38, lr=0.0316] 25%|██▌       | 22/88 [07:45<22:13, 20.20s/epoch, loss=1.19, accuracy=0.74, val_loss=2.25, val_accuracy=0.421, lr=0.1]   26%|██▌       | 23/88 [08:06<22:03, 20.36s/epoch, loss=1.19, accuracy=0.739, val_loss=1.74, val_accuracy=0.54, lr=0.1] 27%|██▋       | 24/88 [08:26<21:34, 20.23s/epoch, loss=1.18, accuracy=0.744, val_loss=2.07, val_accuracy=0.511, lr=0.1] 28%|██▊       | 25/88 [08:47<21:23, 20.37s/epoch, loss=1.18, accuracy=0.743, val_loss=1.74, val_accuracy=0.564, lr=0.1] 30%|██▉       | 26/88 [09:08<21:14, 20.55s/epoch, loss=1.18, accuracy=0.744, val_loss=1.84, val_accuracy=0.555, lr=0.0316] 31%|███       | 27/88 [09:28<20:58, 20.62s/epoch, loss=1.18, accuracy=0.746, val_loss=1.72, val_accuracy=0.537, lr=0.1]    32%|███▏      | 28/88 [09:48<20:19, 20.32s/epoch, loss=1.18, accuracy=0.744, val_loss=1.86, val_accuracy=0.533, lr=0.1] 33%|███▎      | 29/88 [10:09<20:11, 20.53s/epoch, loss=1.18, accuracy=0.745, val_loss=2, val_accuracy=0.503, lr=0.1]    34%|███▍      | 30/88 [10:29<19:44, 20.42s/epoch, loss=1.17, accuracy=0.746, val_loss=3.7, val_accuracy=0.29, lr=0.1] 35%|███▌      | 31/88 [10:50<19:27, 20.48s/epoch, loss=1.18, accuracy=0.747, val_loss=2.37, val_accuracy=0.376, lr=0.0316] 36%|███▋      | 32/88 [11:10<19:02, 20.39s/epoch, loss=1.17, accuracy=0.749, val_loss=1.5, val_accuracy=0.65, lr=0.1]      38%|███▊      | 33/88 [11:30<18:26, 20.12s/epoch, loss=1.18, accuracy=0.747, val_loss=1.89, val_accuracy=0.53, lr=0.1] 39%|███▊      | 34/88 [11:49<17:54, 19.90s/epoch, loss=1.17, accuracy=0.747, val_loss=1.75, val_accuracy=0.52, lr=0.1] 40%|███▉      | 35/88 [12:08<17:25, 19.73s/epoch, loss=1.17, accuracy=0.747, val_loss=2.37, val_accuracy=0.365, lr=0.1] 41%|████      | 36/88 [12:28<17:13, 19.87s/epoch, loss=1.17, accuracy=0.75, val_loss=1.99, val_accuracy=0.494, lr=0.0316] 42%|████▏     | 37/88 [12:48<16:45, 19.72s/epoch, loss=1.17, accuracy=0.75, val_loss=2.75, val_accuracy=0.423, lr=0.1]    43%|████▎     | 38/88 [13:07<16:21, 19.63s/epoch, loss=1.16, accuracy=0.752, val_loss=1.77, val_accuracy=0.526, lr=0.1] 44%|████▍     | 39/88 [13:27<15:58, 19.55s/epoch, loss=1.16, accuracy=0.749, val_loss=2.06, val_accuracy=0.485, lr=0.1] 45%|████▌     | 40/88 [13:46<15:34, 19.47s/epoch, loss=1.16, accuracy=0.746, val_loss=2.04, val_accuracy=0.519, lr=0.1] 47%|████▋     | 41/88 [14:06<15:17, 19.53s/epoch, loss=1.17, accuracy=0.749, val_loss=2.11, val_accuracy=0.473, lr=0.0316] 48%|████▊     | 42/88 [14:25<14:55, 19.46s/epoch, loss=1.16, accuracy=0.751, val_loss=2.1, val_accuracy=0.419, lr=0.1]     49%|████▉     | 43/88 [14:44<14:31, 19.38s/epoch, loss=1.16, accuracy=0.75, val_loss=2.76, val_accuracy=0.393, lr=0.1] 50%|█████     | 44/88 [15:05<14:36, 19.92s/epoch, loss=1.16, accuracy=0.751, val_loss=2.03, val_accuracy=0.495, lr=0.1] 51%|█████     | 45/88 [15:25<14:13, 19.84s/epoch, loss=1.15, accuracy=0.752, val_loss=4.29, val_accuracy=0.33, lr=0.1]  52%|█████▏    | 46/88 [15:44<13:47, 19.70s/epoch, loss=1.15, accuracy=0.75, val_loss=1.76, val_accuracy=0.581, lr=0.0316] 53%|█████▎    | 47/88 [16:04<13:22, 19.58s/epoch, loss=1.15, accuracy=0.752, val_loss=1.59, val_accuracy=0.58, lr=0.1]    55%|█████▍    | 48/88 [16:23<13:00, 19.51s/epoch, loss=1.15, accuracy=0.749, val_loss=3.35, val_accuracy=0.319, lr=0.1] 56%|█████▌    | 49/88 [16:43<12:44, 19.60s/epoch, loss=1.15, accuracy=0.752, val_loss=1.69, val_accuracy=0.581, lr=0.1] 57%|█████▋    | 50/88 [17:03<12:35, 19.89s/epoch, loss=1.14, accuracy=0.752, val_loss=2.13, val_accuracy=0.438, lr=0.1] 58%|█████▊    | 51/88 [17:24<12:27, 20.20s/epoch, loss=1.15, accuracy=0.751, val_loss=1.41, val_accuracy=0.653, lr=0.0316] 59%|█████▉    | 52/88 [17:44<12:00, 20.02s/epoch, loss=1.15, accuracy=0.754, val_loss=1.88, val_accuracy=0.555, lr=0.1]    60%|██████    | 53/88 [18:03<11:32, 19.79s/epoch, loss=1.15, accuracy=0.753, val_loss=2.1, val_accuracy=0.456, lr=0.1]  61%|██████▏   | 54/88 [18:22<11:08, 19.66s/epoch, loss=1.15, accuracy=0.751, val_loss=1.95, val_accuracy=0.512, lr=0.1] 62%|██████▎   | 55/88 [18:42<10:45, 19.56s/epoch, loss=1.14, accuracy=0.751, val_loss=2.26, val_accuracy=0.478, lr=0.1] 64%|██████▎   | 56/88 [19:02<10:32, 19.77s/epoch, loss=1.15, accuracy=0.754, val_loss=1.79, val_accuracy=0.544, lr=0.0316] 65%|██████▍   | 57/88 [19:22<10:12, 19.77s/epoch, loss=1.14, accuracy=0.753, val_loss=1.81, val_accuracy=0.588, lr=0.1]    66%|██████▌   | 58/88 [19:43<10:02, 20.09s/epoch, loss=1.14, accuracy=0.754, val_loss=1.92, val_accuracy=0.55, lr=0.1]  67%|██████▋   | 59/88 [20:02<09:38, 19.94s/epoch, loss=1.14, accuracy=0.756, val_loss=1.76, val_accuracy=0.593, lr=0.1] 68%|██████▊   | 60/88 [20:21<09:11, 19.70s/epoch, loss=1.14, accuracy=0.753, val_loss=2.37, val_accuracy=0.459, lr=0.1] 69%|██████▉   | 61/88 [20:41<08:48, 19.56s/epoch, loss=1.14, accuracy=0.753, val_loss=1.81, val_accuracy=0.538, lr=0.0316] 70%|███████   | 62/88 [21:00<08:29, 19.61s/epoch, loss=1.14, accuracy=0.752, val_loss=3.16, val_accuracy=0.382, lr=0.1]    72%|███████▏  | 63/88 [21:19<08:06, 19.47s/epoch, loss=1.14, accuracy=0.753, val_loss=2.79, val_accuracy=0.467, lr=0.1] 73%|███████▎  | 64/88 [21:39<07:46, 19.42s/epoch, loss=1.14, accuracy=0.754, val_loss=2.11, val_accuracy=0.442, lr=0.1] 74%|███████▍  | 65/88 [22:00<07:37, 19.90s/epoch, loss=1.14, accuracy=0.753, val_loss=1.37, val_accuracy=0.682, lr=0.1] 75%|███████▌  | 66/88 [22:19<07:11, 19.64s/epoch, loss=1.14, accuracy=0.753, val_loss=2.75, val_accuracy=0.389, lr=0.1] 76%|███████▌  | 67/88 [22:40<07:00, 20.02s/epoch, loss=1.14, accuracy=0.754, val_loss=2.31, val_accuracy=0.486, lr=0.1] 77%|███████▋  | 68/88 [23:00<06:42, 20.11s/epoch, loss=1.14, accuracy=0.753, val_loss=3.12, val_accuracy=0.332, lr=0.1] 78%|███████▊  | 69/88 [23:19<06:17, 19.85s/epoch, loss=1.15, accuracy=0.752, val_loss=2.73, val_accuracy=0.407, lr=0.1] 80%|███████▉  | 70/88 [23:39<05:54, 19.69s/epoch, loss=1.14, accuracy=0.755, val_loss=2.04, val_accuracy=0.545, lr=0.0316] 81%|████████  | 71/88 [23:59<05:36, 19.77s/epoch, loss=1.14, accuracy=0.755, val_loss=1.52, val_accuracy=0.605, lr=0.1]    82%|████████▏ | 72/88 [24:19<05:18, 19.88s/epoch, loss=1.14, accuracy=0.753, val_loss=1.79, val_accuracy=0.547, lr=0.1] 83%|████████▎ | 73/88 [24:38<04:57, 19.84s/epoch, loss=1.14, accuracy=0.755, val_loss=1.69, val_accuracy=0.575, lr=0.1] 84%|████████▍ | 74/88 [24:58<04:35, 19.68s/epoch, loss=1.13, accuracy=0.757, val_loss=1.91, val_accuracy=0.509, lr=0.1] 85%|████████▌ | 75/88 [25:17<04:14, 19.56s/epoch, loss=1.14, accuracy=0.759, val_loss=2.48, val_accuracy=0.423, lr=0.0316] 86%|████████▋ | 76/88 [25:37<03:54, 19.56s/epoch, loss=1.14, accuracy=0.756, val_loss=3.89, val_accuracy=0.324, lr=0.1]    88%|████████▊ | 77/88 [25:57<03:36, 19.69s/epoch, loss=1.13, accuracy=0.757, val_loss=3.03, val_accuracy=0.396, lr=0.1] 89%|████████▊ | 78/88 [26:17<03:18, 19.87s/epoch, loss=1.13, accuracy=0.758, val_loss=1.59, val_accuracy=0.602, lr=0.1] 90%|████████▉ | 79/88 [26:36<02:57, 19.74s/epoch, loss=1.13, accuracy=0.756, val_loss=1.4, val_accuracy=0.665, lr=0.1]  91%|█████████ | 80/88 [26:56<02:36, 19.61s/epoch, loss=1.13, accuracy=0.755, val_loss=1.97, val_accuracy=0.457, lr=0.0316] 92%|█████████▏| 81/88 [27:15<02:16, 19.49s/epoch, loss=1.14, accuracy=0.753, val_loss=2.94, val_accuracy=0.29, lr=0.1]     93%|█████████▎| 82/88 [27:36<01:59, 19.88s/epoch, loss=0.936, accuracy=0.812, val_loss=0.948, val_accuracy=0.791, lr=0.01] 94%|█████████▍| 83/88 [27:55<01:38, 19.78s/epoch, loss=0.755, accuracy=0.845, val_loss=0.81, val_accuracy=0.812, lr=0.01]  95%|█████████▌| 84/88 [28:14<01:18, 19.64s/epoch, loss=0.666, accuracy=0.858, val_loss=0.736, val_accuracy=0.824, lr=0.01] 97%|█████████▋| 85/88 [28:35<00:59, 19.92s/epoch, loss=0.616, accuracy=0.861, val_loss=0.745, val_accuracy=0.812, lr=0.01] 98%|█████████▊| 86/88 [28:54<00:39, 19.69s/epoch, loss=0.595, accuracy=0.86, val_loss=0.934, val_accuracy=0.752, lr=0.01]  99%|█████████▉| 87/88 [29:13<00:19, 19.56s/epoch, loss=0.58, accuracy=0.865, val_loss=0.742, val_accuracy=0.815, lr=0.01]100%|██████████| 88/88 [29:34<00:00, 19.88s/epoch, loss=0.569, accuracy=0.864, val_loss=0.885, val_accuracy=0.766, lr=0.01]100%|██████████| 88/88 [29:34<00:00, 20.17s/epoch, loss=0.569, accuracy=0.864, val_loss=0.885, val_accuracy=0.766, lr=0.01]
Using real-time data augmentation.
Test score: 0.7610169649124146
Test accuracy: 0.8205999732017517


* * * Run SGD for ID = 17_14. * * *


2024-02-20 05:08:11.259132: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 05:08:14.967701: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 05:08:14.968713: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-20 05:08:15.005333: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-20 05:08:15.005378: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 05:08:15.008138: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 05:08:15.008189: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-20 05:08:15.010491: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-20 05:08:15.011146: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-20 05:08:15.013781: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-20 05:08:15.015205: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-20 05:08:15.019825: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 05:08:15.020349: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-20 05:08:15.020436: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 05:08:16.436816: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-20 05:08:16.437913: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 05:08:16.438659: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-20 05:08:16.438692: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 05:08:16.438727: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 05:08:16.438745: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-20 05:08:16.438762: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-20 05:08:16.438778: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-20 05:08:16.438793: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-20 05:08:16.438808: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-20 05:08:16.438824: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 05:08:16.439302: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-20 05:08:16.439334: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 05:08:17.048600: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-20 05:08:17.048669: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-20 05:08:17.048679: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-20 05:08:17.049599: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:02:00.0, compute capability: 6.1)
{'id': '17_14', 'batch_size': 128, 'epochs': 88, 'validation_split': 0.1, 'checkpointing': True, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
x_train shape: (45000, 32, 32, 3)
45000 train samples
5000 validation samples
10000 test samples
y_train shape: (45000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/88 [00:00<?, ?epoch/s]2024-02-20 05:08:17.850705: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-20 05:08:17.851182: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199825000 Hz
2024-02-20 05:08:19.818909: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 05:08:20.063643: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 05:08:20.677957: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-20 05:08:20.711215: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/88 [00:43<1:03:27, 43.76s/epoch, loss=3.32, accuracy=0.267, val_loss=2.44, val_accuracy=0.265, lr=0.1]  2%|▏         | 2/88 [01:04<42:57, 29.97s/epoch, loss=1.66, accuracy=0.491, val_loss=1.65, val_accuracy=0.499, lr=0.1]    3%|▎         | 3/88 [01:23<35:25, 25.00s/epoch, loss=1.42, accuracy=0.605, val_loss=1.94, val_accuracy=0.523, lr=0.1]  5%|▍         | 4/88 [01:41<31:31, 22.52s/epoch, loss=1.33, accuracy=0.658, val_loss=2.19, val_accuracy=0.441, lr=0.1]  6%|▌         | 5/88 [02:02<30:11, 21.82s/epoch, loss=1.29, accuracy=0.682, val_loss=1.73, val_accuracy=0.533, lr=0.1]  7%|▋         | 6/88 [02:23<29:24, 21.51s/epoch, loss=1.26, accuracy=0.697, val_loss=1.61, val_accuracy=0.566, lr=0.1]  8%|▊         | 7/88 [02:42<27:55, 20.68s/epoch, loss=1.24, accuracy=0.707, val_loss=4.5, val_accuracy=0.227, lr=0.1]   9%|▉         | 8/88 [03:02<27:25, 20.57s/epoch, loss=1.23, accuracy=0.715, val_loss=1.76, val_accuracy=0.566, lr=0.1] 10%|█         | 9/88 [03:23<27:12, 20.67s/epoch, loss=1.22, accuracy=0.717, val_loss=1.79, val_accuracy=0.558, lr=0.1] 11%|█▏        | 10/88 [03:43<26:28, 20.37s/epoch, loss=1.21, accuracy=0.72, val_loss=2.04, val_accuracy=0.543, lr=0.1] 12%|█▎        | 11/88 [04:02<25:47, 20.10s/epoch, loss=1.21, accuracy=0.726, val_loss=1.78, val_accuracy=0.575, lr=0.0316] 14%|█▎        | 12/88 [04:22<25:08, 19.85s/epoch, loss=1.21, accuracy=0.726, val_loss=1.53, val_accuracy=0.64, lr=0.1]     15%|█▍        | 13/88 [04:40<24:28, 19.58s/epoch, loss=1.2, accuracy=0.73, val_loss=2.14, val_accuracy=0.473, lr=0.1]  16%|█▌        | 14/88 [05:00<24:02, 19.49s/epoch, loss=1.19, accuracy=0.734, val_loss=1.6, val_accuracy=0.592, lr=0.1] 17%|█▋        | 15/88 [05:21<24:13, 19.92s/epoch, loss=1.18, accuracy=0.737, val_loss=1.6, val_accuracy=0.594, lr=0.1] 18%|█▊        | 16/88 [05:40<23:52, 19.89s/epoch, loss=1.18, accuracy=0.738, val_loss=1.61, val_accuracy=0.579, lr=0.1] 19%|█▉        | 17/88 [06:00<23:20, 19.73s/epoch, loss=1.18, accuracy=0.737, val_loss=1.48, val_accuracy=0.63, lr=0.1]  20%|██        | 18/88 [06:19<22:52, 19.60s/epoch, loss=1.18, accuracy=0.74, val_loss=2.04, val_accuracy=0.526, lr=0.1] 22%|██▏       | 19/88 [06:38<22:23, 19.48s/epoch, loss=1.18, accuracy=0.741, val_loss=1.53, val_accuracy=0.612, lr=0.1] 23%|██▎       | 20/88 [06:58<22:04, 19.47s/epoch, loss=1.17, accuracy=0.741, val_loss=1.59, val_accuracy=0.615, lr=0.1] 24%|██▍       | 21/88 [07:17<21:41, 19.43s/epoch, loss=1.16, accuracy=0.743, val_loss=2.3, val_accuracy=0.487, lr=0.1]  25%|██▌       | 22/88 [07:36<21:18, 19.37s/epoch, loss=1.16, accuracy=0.741, val_loss=2.15, val_accuracy=0.519, lr=0.0316] 26%|██▌       | 23/88 [07:57<21:27, 19.80s/epoch, loss=1.16, accuracy=0.745, val_loss=1.64, val_accuracy=0.571, lr=0.1]    27%|██▋       | 24/88 [08:18<21:31, 20.18s/epoch, loss=1.16, accuracy=0.746, val_loss=1.63, val_accuracy=0.598, lr=0.1] 28%|██▊       | 25/88 [08:39<21:26, 20.43s/epoch, loss=1.17, accuracy=0.745, val_loss=1.98, val_accuracy=0.503, lr=0.1] 30%|██▉       | 26/88 [08:58<20:43, 20.05s/epoch, loss=1.16, accuracy=0.746, val_loss=1.72, val_accuracy=0.562, lr=0.1] 31%|███       | 27/88 [09:19<20:31, 20.18s/epoch, loss=1.16, accuracy=0.746, val_loss=2.62, val_accuracy=0.388, lr=0.0316] 32%|███▏      | 28/88 [09:38<19:56, 19.94s/epoch, loss=1.16, accuracy=0.75, val_loss=4.96, val_accuracy=0.204, lr=0.1]     33%|███▎      | 29/88 [09:58<19:26, 19.78s/epoch, loss=1.16, accuracy=0.746, val_loss=1.46, val_accuracy=0.639, lr=0.1] 34%|███▍      | 30/88 [10:17<19:01, 19.67s/epoch, loss=1.16, accuracy=0.747, val_loss=1.56, val_accuracy=0.622, lr=0.1] 35%|███▌      | 31/88 [10:37<18:42, 19.70s/epoch, loss=1.15, accuracy=0.747, val_loss=1.69, val_accuracy=0.58, lr=0.1]  36%|███▋      | 32/88 [10:57<18:26, 19.75s/epoch, loss=1.15, accuracy=0.747, val_loss=2.11, val_accuracy=0.5, lr=0.1]  38%|███▊      | 33/88 [11:17<18:18, 19.98s/epoch, loss=1.15, accuracy=0.748, val_loss=1.49, val_accuracy=0.611, lr=0.1] 39%|███▊      | 34/88 [11:38<18:07, 20.13s/epoch, loss=1.15, accuracy=0.75, val_loss=1.53, val_accuracy=0.6, lr=0.0316] 40%|███▉      | 35/88 [11:57<17:35, 19.91s/epoch, loss=1.15, accuracy=0.75, val_loss=1.46, val_accuracy=0.632, lr=0.1]  41%|████      | 36/88 [12:17<17:11, 19.84s/epoch, loss=1.14, accuracy=0.753, val_loss=2.9, val_accuracy=0.373, lr=0.1] 42%|████▏     | 37/88 [12:37<16:56, 19.92s/epoch, loss=1.15, accuracy=0.749, val_loss=2.01, val_accuracy=0.528, lr=0.1] 43%|████▎     | 38/88 [12:56<16:24, 19.69s/epoch, loss=1.14, accuracy=0.75, val_loss=1.7, val_accuracy=0.568, lr=0.1]   44%|████▍     | 39/88 [13:16<16:15, 19.91s/epoch, loss=1.14, accuracy=0.75, val_loss=1.63, val_accuracy=0.601, lr=0.1] 45%|████▌     | 40/88 [13:37<16:02, 20.06s/epoch, loss=1.13, accuracy=0.754, val_loss=2.06, val_accuracy=0.516, lr=0.0316] 47%|████▋     | 41/88 [13:57<15:46, 20.13s/epoch, loss=1.14, accuracy=0.751, val_loss=2.91, val_accuracy=0.4, lr=0.1]      48%|████▊     | 42/88 [14:16<15:11, 19.82s/epoch, loss=1.14, accuracy=0.752, val_loss=1.54, val_accuracy=0.622, lr=0.1] 49%|████▉     | 43/88 [14:35<14:42, 19.60s/epoch, loss=1.13, accuracy=0.755, val_loss=1.63, val_accuracy=0.603, lr=0.1] 50%|█████     | 44/88 [14:55<14:17, 19.49s/epoch, loss=1.12, accuracy=0.754, val_loss=1.71, val_accuracy=0.554, lr=0.1] 51%|█████     | 45/88 [15:14<13:55, 19.44s/epoch, loss=1.14, accuracy=0.75, val_loss=1.88, val_accuracy=0.538, lr=0.0316] 52%|█████▏    | 46/88 [15:35<13:50, 19.78s/epoch, loss=1.13, accuracy=0.756, val_loss=1.88, val_accuracy=0.566, lr=0.1]   53%|█████▎    | 47/88 [15:54<13:23, 19.60s/epoch, loss=1.13, accuracy=0.751, val_loss=1.57, val_accuracy=0.608, lr=0.1] 55%|█████▍    | 48/88 [16:13<12:57, 19.43s/epoch, loss=1.13, accuracy=0.754, val_loss=1.52, val_accuracy=0.63, lr=0.1]  56%|█████▌    | 49/88 [16:32<12:39, 19.47s/epoch, loss=1.13, accuracy=0.755, val_loss=2.22, val_accuracy=0.449, lr=0.1] 57%|█████▋    | 50/88 [16:52<12:21, 19.50s/epoch, loss=1.13, accuracy=0.755, val_loss=3.41, val_accuracy=0.343, lr=0.0316] 58%|█████▊    | 51/88 [17:11<11:57, 19.40s/epoch, loss=1.13, accuracy=0.753, val_loss=3.29, val_accuracy=0.381, lr=0.1]    59%|█████▉    | 52/88 [17:31<11:43, 19.55s/epoch, loss=1.14, accuracy=0.751, val_loss=1.56, val_accuracy=0.612, lr=0.1] 60%|██████    | 53/88 [17:50<11:19, 19.40s/epoch, loss=1.14, accuracy=0.753, val_loss=1.59, val_accuracy=0.606, lr=0.1] 61%|██████▏   | 54/88 [18:09<10:59, 19.39s/epoch, loss=1.13, accuracy=0.754, val_loss=2.32, val_accuracy=0.44, lr=0.1]  62%|██████▎   | 55/88 [18:29<10:42, 19.48s/epoch, loss=1.12, accuracy=0.754, val_loss=2.04, val_accuracy=0.499, lr=0.0316] 64%|██████▎   | 56/88 [18:48<10:19, 19.35s/epoch, loss=1.13, accuracy=0.751, val_loss=1.67, val_accuracy=0.574, lr=0.1]    65%|██████▍   | 57/88 [19:07<09:56, 19.23s/epoch, loss=1.12, accuracy=0.755, val_loss=1.62, val_accuracy=0.577, lr=0.1] 66%|██████▌   | 58/88 [19:26<09:38, 19.27s/epoch, loss=1.13, accuracy=0.753, val_loss=1.8, val_accuracy=0.553, lr=0.1]  67%|██████▋   | 59/88 [19:45<09:16, 19.17s/epoch, loss=1.13, accuracy=0.754, val_loss=3.19, val_accuracy=0.323, lr=0.1] 68%|██████▊   | 60/88 [20:05<08:56, 19.17s/epoch, loss=1.13, accuracy=0.757, val_loss=1.89, val_accuracy=0.545, lr=0.0316] 69%|██████▉   | 61/88 [20:25<08:47, 19.53s/epoch, loss=1.13, accuracy=0.753, val_loss=2, val_accuracy=0.519, lr=0.1]       70%|███████   | 62/88 [20:45<08:31, 19.66s/epoch, loss=1.12, accuracy=0.754, val_loss=2.06, val_accuracy=0.483, lr=0.1] 72%|███████▏  | 63/88 [21:05<08:15, 19.83s/epoch, loss=1.12, accuracy=0.755, val_loss=1.97, val_accuracy=0.496, lr=0.1] 73%|███████▎  | 64/88 [21:25<07:53, 19.74s/epoch, loss=1.12, accuracy=0.755, val_loss=1.96, val_accuracy=0.505, lr=0.1] 74%|███████▍  | 65/88 [21:44<07:33, 19.74s/epoch, loss=1.12, accuracy=0.756, val_loss=2.04, val_accuracy=0.523, lr=0.0316] 75%|███████▌  | 66/88 [22:04<07:15, 19.79s/epoch, loss=1.12, accuracy=0.755, val_loss=1.95, val_accuracy=0.506, lr=0.1]    76%|███████▌  | 67/88 [22:24<06:57, 19.89s/epoch, loss=1.11, accuracy=0.756, val_loss=2.15, val_accuracy=0.442, lr=0.1] 77%|███████▋  | 68/88 [22:44<06:37, 19.86s/epoch, loss=1.12, accuracy=0.752, val_loss=2.96, val_accuracy=0.451, lr=0.1] 78%|███████▊  | 69/88 [23:05<06:21, 20.07s/epoch, loss=1.11, accuracy=0.755, val_loss=1.84, val_accuracy=0.53, lr=0.1]  80%|███████▉  | 70/88 [23:25<06:03, 20.20s/epoch, loss=1.12, accuracy=0.756, val_loss=2.45, val_accuracy=0.463, lr=0.0316] 81%|████████  | 71/88 [23:44<05:36, 19.82s/epoch, loss=1.12, accuracy=0.754, val_loss=2.53, val_accuracy=0.449, lr=0.1]    82%|████████▏ | 72/88 [24:05<05:21, 20.12s/epoch, loss=1.12, accuracy=0.755, val_loss=1.93, val_accuracy=0.546, lr=0.1] 83%|████████▎ | 73/88 [24:25<05:01, 20.12s/epoch, loss=1.12, accuracy=0.755, val_loss=1.63, val_accuracy=0.575, lr=0.1] 84%|████████▍ | 74/88 [24:45<04:39, 19.93s/epoch, loss=1.12, accuracy=0.754, val_loss=2.87, val_accuracy=0.361, lr=0.1] 85%|████████▌ | 75/88 [25:04<04:16, 19.74s/epoch, loss=1.11, accuracy=0.756, val_loss=1.95, val_accuracy=0.468, lr=0.0316] 86%|████████▋ | 76/88 [25:23<03:54, 19.57s/epoch, loss=1.12, accuracy=0.755, val_loss=2.13, val_accuracy=0.494, lr=0.1]    88%|████████▊ | 77/88 [25:43<03:35, 19.63s/epoch, loss=1.11, accuracy=0.756, val_loss=1.64, val_accuracy=0.611, lr=0.1] 89%|████████▊ | 78/88 [26:02<03:14, 19.46s/epoch, loss=1.11, accuracy=0.755, val_loss=1.94, val_accuracy=0.531, lr=0.1] 90%|████████▉ | 79/88 [26:21<02:53, 19.33s/epoch, loss=1.11, accuracy=0.756, val_loss=1.52, val_accuracy=0.622, lr=0.1] 91%|█████████ | 80/88 [26:40<02:34, 19.27s/epoch, loss=1.11, accuracy=0.755, val_loss=2.23, val_accuracy=0.434, lr=0.0316] 92%|█████████▏| 81/88 [27:00<02:17, 19.58s/epoch, loss=1.12, accuracy=0.754, val_loss=2.03, val_accuracy=0.481, lr=0.1]    93%|█████████▎| 82/88 [27:20<01:57, 19.65s/epoch, loss=0.924, accuracy=0.81, val_loss=0.904, val_accuracy=0.805, lr=0.01] 94%|█████████▍| 83/88 [27:40<01:38, 19.66s/epoch, loss=0.747, accuracy=0.844, val_loss=0.79, val_accuracy=0.819, lr=0.01] 95%|█████████▌| 84/88 [28:00<01:18, 19.72s/epoch, loss=0.664, accuracy=0.853, val_loss=0.7, val_accuracy=0.832, lr=0.01]  97%|█████████▋| 85/88 [28:19<00:58, 19.45s/epoch, loss=0.62, accuracy=0.859, val_loss=0.71, val_accuracy=0.82, lr=0.01]  98%|█████████▊| 86/88 [28:38<00:38, 19.36s/epoch, loss=0.594, accuracy=0.857, val_loss=0.974, val_accuracy=0.755, lr=0.01] 99%|█████████▉| 87/88 [28:57<00:19, 19.24s/epoch, loss=0.584, accuracy=0.859, val_loss=0.698, val_accuracy=0.818, lr=0.01]100%|██████████| 88/88 [29:16<00:00, 19.15s/epoch, loss=0.573, accuracy=0.861, val_loss=0.775, val_accuracy=0.798, lr=0.01]100%|██████████| 88/88 [29:16<00:00, 19.96s/epoch, loss=0.573, accuracy=0.861, val_loss=0.775, val_accuracy=0.798, lr=0.01]
Using real-time data augmentation.
Test score: 0.7289535999298096
Test accuracy: 0.8259999752044678


* * * Run SGD for ID = 17_15. * * *


2024-02-20 05:37:39.055902: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 05:37:44.504398: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 05:37:44.505311: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-20 05:37:44.543001: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-20 05:37:44.543029: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 05:37:44.547961: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 05:37:44.548002: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-20 05:37:44.552095: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-20 05:37:44.554430: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-20 05:37:44.557921: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-20 05:37:44.560845: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-20 05:37:44.567113: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 05:37:44.567634: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-20 05:37:44.567722: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 05:37:45.987315: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-20 05:37:45.988715: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 05:37:45.989163: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-20 05:37:45.989196: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 05:37:45.989228: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 05:37:45.989255: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-20 05:37:45.989272: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-20 05:37:45.989287: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-20 05:37:45.989302: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-20 05:37:45.989318: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-20 05:37:45.989333: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 05:37:45.989789: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-20 05:37:45.989826: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 05:37:46.605839: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-20 05:37:46.605898: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-20 05:37:46.605908: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-20 05:37:46.607175: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:02:00.0, compute capability: 6.1)
{'id': '17_15', 'batch_size': 128, 'epochs': 88, 'validation_split': 0.1, 'checkpointing': True, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
x_train shape: (45000, 32, 32, 3)
45000 train samples
5000 validation samples
10000 test samples
y_train shape: (45000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/88 [00:00<?, ?epoch/s]2024-02-20 05:37:47.412614: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-20 05:37:47.413142: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199825000 Hz
2024-02-20 05:37:49.371069: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 05:37:49.610176: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 05:37:50.228242: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-20 05:37:50.264768: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/88 [00:43<1:02:45, 43.29s/epoch, loss=3.27, accuracy=0.311, val_loss=2.47, val_accuracy=0.282, lr=0.1]  2%|▏         | 2/88 [01:02<42:02, 29.34s/epoch, loss=1.57, accuracy=0.535, val_loss=2.53, val_accuracy=0.402, lr=0.1]    3%|▎         | 3/88 [01:22<35:02, 24.74s/epoch, loss=1.35, accuracy=0.638, val_loss=2.5, val_accuracy=0.409, lr=0.1]   5%|▍         | 4/88 [01:42<32:23, 23.13s/epoch, loss=1.28, accuracy=0.677, val_loss=1.9, val_accuracy=0.511, lr=0.1]  6%|▌         | 5/88 [02:02<30:15, 21.87s/epoch, loss=1.25, accuracy=0.698, val_loss=3.19, val_accuracy=0.368, lr=0.1]  7%|▋         | 6/88 [02:22<28:52, 21.13s/epoch, loss=1.23, accuracy=0.711, val_loss=2.59, val_accuracy=0.464, lr=0.1]  8%|▊         | 7/88 [02:42<28:19, 20.99s/epoch, loss=1.23, accuracy=0.719, val_loss=1.85, val_accuracy=0.517, lr=0.1]  9%|▉         | 8/88 [03:03<27:39, 20.74s/epoch, loss=1.22, accuracy=0.721, val_loss=1.59, val_accuracy=0.608, lr=0.1] 10%|█         | 9/88 [03:23<27:16, 20.71s/epoch, loss=1.2, accuracy=0.729, val_loss=2.19, val_accuracy=0.524, lr=0.1]  11%|█▏        | 10/88 [03:43<26:31, 20.41s/epoch, loss=1.2, accuracy=0.731, val_loss=1.85, val_accuracy=0.52, lr=0.1] 12%|█▎        | 11/88 [04:02<25:52, 20.16s/epoch, loss=1.21, accuracy=0.729, val_loss=1.35, val_accuracy=0.681, lr=0.1] 14%|█▎        | 12/88 [04:22<25:19, 19.99s/epoch, loss=1.2, accuracy=0.733, val_loss=1.76, val_accuracy=0.565, lr=0.1]  15%|█▍        | 13/88 [04:42<25:03, 20.04s/epoch, loss=1.19, accuracy=0.738, val_loss=1.87, val_accuracy=0.483, lr=0.1] 16%|█▌        | 14/88 [05:03<24:56, 20.22s/epoch, loss=1.19, accuracy=0.738, val_loss=2.12, val_accuracy=0.47, lr=0.1]  17%|█▋        | 15/88 [05:23<24:24, 20.06s/epoch, loss=1.18, accuracy=0.739, val_loss=1.45, val_accuracy=0.653, lr=0.1] 18%|█▊        | 16/88 [05:43<24:11, 20.15s/epoch, loss=1.18, accuracy=0.74, val_loss=1.92, val_accuracy=0.549, lr=0.0316] 19%|█▉        | 17/88 [06:04<24:01, 20.30s/epoch, loss=1.18, accuracy=0.742, val_loss=1.91, val_accuracy=0.522, lr=0.1]   20%|██        | 18/88 [06:23<23:19, 20.00s/epoch, loss=1.18, accuracy=0.741, val_loss=1.67, val_accuracy=0.576, lr=0.1] 22%|██▏       | 19/88 [06:43<22:55, 19.93s/epoch, loss=1.17, accuracy=0.743, val_loss=1.83, val_accuracy=0.554, lr=0.1] 23%|██▎       | 20/88 [07:02<22:21, 19.73s/epoch, loss=1.17, accuracy=0.744, val_loss=2.08, val_accuracy=0.523, lr=0.1] 24%|██▍       | 21/88 [07:21<21:51, 19.58s/epoch, loss=1.17, accuracy=0.746, val_loss=2, val_accuracy=0.533, lr=0.0316] 25%|██▌       | 22/88 [07:40<21:26, 19.50s/epoch, loss=1.16, accuracy=0.749, val_loss=2.07, val_accuracy=0.479, lr=0.1] 26%|██▌       | 23/88 [08:01<21:26, 19.79s/epoch, loss=1.17, accuracy=0.745, val_loss=2.02, val_accuracy=0.531, lr=0.1] 27%|██▋       | 24/88 [08:20<21:01, 19.72s/epoch, loss=1.17, accuracy=0.745, val_loss=3.3, val_accuracy=0.389, lr=0.1]  28%|██▊       | 25/88 [08:40<20:33, 19.58s/epoch, loss=1.17, accuracy=0.748, val_loss=2.85, val_accuracy=0.403, lr=0.1] 30%|██▉       | 26/88 [08:59<20:12, 19.56s/epoch, loss=1.16, accuracy=0.747, val_loss=1.76, val_accuracy=0.52, lr=0.0316] 31%|███       | 27/88 [09:19<19:55, 19.59s/epoch, loss=1.16, accuracy=0.749, val_loss=2.24, val_accuracy=0.48, lr=0.1]    32%|███▏      | 28/88 [09:40<19:54, 19.90s/epoch, loss=1.15, accuracy=0.753, val_loss=2.31, val_accuracy=0.527, lr=0.1] 33%|███▎      | 29/88 [10:00<19:39, 20.00s/epoch, loss=1.16, accuracy=0.749, val_loss=2.65, val_accuracy=0.412, lr=0.1] 34%|███▍      | 30/88 [10:19<19:15, 19.92s/epoch, loss=1.16, accuracy=0.751, val_loss=4.55, val_accuracy=0.258, lr=0.1] 35%|███▌      | 31/88 [10:41<19:14, 20.26s/epoch, loss=1.15, accuracy=0.751, val_loss=2.41, val_accuracy=0.488, lr=0.0316] 36%|███▋      | 32/88 [11:00<18:41, 20.02s/epoch, loss=1.15, accuracy=0.751, val_loss=2.77, val_accuracy=0.448, lr=0.1]    38%|███▊      | 33/88 [11:19<18:06, 19.76s/epoch, loss=1.16, accuracy=0.748, val_loss=1.94, val_accuracy=0.513, lr=0.1] 39%|███▊      | 34/88 [11:38<17:37, 19.59s/epoch, loss=1.15, accuracy=0.75, val_loss=2.32, val_accuracy=0.401, lr=0.1]  40%|███▉      | 35/88 [11:58<17:22, 19.67s/epoch, loss=1.16, accuracy=0.749, val_loss=4.26, val_accuracy=0.261, lr=0.1] 41%|████      | 36/88 [12:18<16:58, 19.58s/epoch, loss=1.15, accuracy=0.751, val_loss=2.77, val_accuracy=0.311, lr=0.0316] 42%|████▏     | 37/88 [12:37<16:28, 19.39s/epoch, loss=1.15, accuracy=0.751, val_loss=1.66, val_accuracy=0.582, lr=0.1]    43%|████▎     | 38/88 [12:56<16:07, 19.36s/epoch, loss=1.15, accuracy=0.752, val_loss=1.67, val_accuracy=0.619, lr=0.1] 44%|████▍     | 39/88 [13:15<15:46, 19.32s/epoch, loss=1.15, accuracy=0.753, val_loss=1.63, val_accuracy=0.622, lr=0.1] 45%|████▌     | 40/88 [13:34<15:26, 19.30s/epoch, loss=1.15, accuracy=0.754, val_loss=1.57, val_accuracy=0.62, lr=0.1]  47%|████▋     | 41/88 [13:54<15:15, 19.48s/epoch, loss=1.14, accuracy=0.752, val_loss=1.98, val_accuracy=0.488, lr=0.0316] 48%|████▊     | 42/88 [14:14<14:55, 19.47s/epoch, loss=1.15, accuracy=0.752, val_loss=1.91, val_accuracy=0.529, lr=0.1]    49%|████▉     | 43/88 [14:33<14:30, 19.35s/epoch, loss=1.15, accuracy=0.752, val_loss=2.85, val_accuracy=0.391, lr=0.1] 50%|█████     | 44/88 [14:54<14:31, 19.80s/epoch, loss=1.15, accuracy=0.752, val_loss=2.85, val_accuracy=0.397, lr=0.1] 51%|█████     | 45/88 [15:14<14:25, 20.13s/epoch, loss=1.15, accuracy=0.752, val_loss=1.71, val_accuracy=0.553, lr=0.1] 52%|█████▏    | 46/88 [15:35<14:06, 20.15s/epoch, loss=1.15, accuracy=0.755, val_loss=2.12, val_accuracy=0.529, lr=0.0316] 53%|█████▎    | 47/88 [15:56<13:58, 20.44s/epoch, loss=1.15, accuracy=0.754, val_loss=1.78, val_accuracy=0.571, lr=0.1]    55%|█████▍    | 48/88 [16:15<13:22, 20.07s/epoch, loss=1.15, accuracy=0.756, val_loss=2.25, val_accuracy=0.49, lr=0.1]  56%|█████▌    | 49/88 [16:36<13:08, 20.22s/epoch, loss=1.14, accuracy=0.757, val_loss=2.02, val_accuracy=0.49, lr=0.1] 57%|█████▋    | 50/88 [16:55<12:36, 19.90s/epoch, loss=1.15, accuracy=0.753, val_loss=3.38, val_accuracy=0.423, lr=0.1] 58%|█████▊    | 51/88 [17:15<12:19, 20.00s/epoch, loss=1.15, accuracy=0.754, val_loss=2.08, val_accuracy=0.505, lr=0.0316] 59%|█████▉    | 52/88 [17:35<11:59, 19.99s/epoch, loss=1.14, accuracy=0.753, val_loss=1.86, val_accuracy=0.583, lr=0.1]    60%|██████    | 53/88 [17:55<11:42, 20.07s/epoch, loss=1.13, accuracy=0.757, val_loss=2.14, val_accuracy=0.465, lr=0.1] 61%|██████▏   | 54/88 [18:14<11:12, 19.78s/epoch, loss=1.14, accuracy=0.755, val_loss=1.46, val_accuracy=0.649, lr=0.1] 62%|██████▎   | 55/88 [18:35<11:00, 20.00s/epoch, loss=1.15, accuracy=0.751, val_loss=2.2, val_accuracy=0.461, lr=0.1]  64%|██████▎   | 56/88 [18:55<10:42, 20.09s/epoch, loss=1.14, accuracy=0.757, val_loss=3.81, val_accuracy=0.272, lr=0.0316] 65%|██████▍   | 57/88 [19:15<10:22, 20.08s/epoch, loss=1.14, accuracy=0.758, val_loss=1.77, val_accuracy=0.595, lr=0.1]    66%|██████▌   | 58/88 [19:36<10:10, 20.34s/epoch, loss=1.14, accuracy=0.754, val_loss=1.89, val_accuracy=0.545, lr=0.1] 67%|██████▋   | 59/88 [19:56<09:45, 20.18s/epoch, loss=1.14, accuracy=0.752, val_loss=3.07, val_accuracy=0.363, lr=0.1] 68%|██████▊   | 60/88 [20:15<09:18, 19.96s/epoch, loss=1.13, accuracy=0.756, val_loss=1.89, val_accuracy=0.508, lr=0.1] 69%|██████▉   | 61/88 [20:35<08:52, 19.73s/epoch, loss=1.14, accuracy=0.753, val_loss=1.55, val_accuracy=0.625, lr=0.0316] 70%|███████   | 62/88 [20:54<08:28, 19.56s/epoch, loss=1.13, accuracy=0.756, val_loss=2.5, val_accuracy=0.419, lr=0.1]     72%|███████▏  | 63/88 [21:14<08:14, 19.76s/epoch, loss=1.14, accuracy=0.753, val_loss=1.4, val_accuracy=0.67, lr=0.1]  73%|███████▎  | 64/88 [21:33<07:50, 19.62s/epoch, loss=1.14, accuracy=0.756, val_loss=1.43, val_accuracy=0.663, lr=0.1] 74%|███████▍  | 65/88 [21:54<07:39, 19.99s/epoch, loss=1.14, accuracy=0.756, val_loss=2.13, val_accuracy=0.457, lr=0.1] 75%|███████▌  | 66/88 [22:13<07:14, 19.73s/epoch, loss=1.14, accuracy=0.754, val_loss=2.35, val_accuracy=0.488, lr=0.0316] 76%|███████▌  | 67/88 [22:33<06:55, 19.78s/epoch, loss=1.13, accuracy=0.755, val_loss=2.6, val_accuracy=0.441, lr=0.1]     77%|███████▋  | 68/88 [22:53<06:38, 19.94s/epoch, loss=1.13, accuracy=0.758, val_loss=1.55, val_accuracy=0.586, lr=0.1] 78%|███████▊  | 69/88 [23:13<06:14, 19.70s/epoch, loss=1.13, accuracy=0.755, val_loss=2.55, val_accuracy=0.449, lr=0.1] 80%|███████▉  | 70/88 [23:32<05:51, 19.55s/epoch, loss=1.13, accuracy=0.755, val_loss=2.09, val_accuracy=0.472, lr=0.1] 81%|████████  | 71/88 [23:51<05:30, 19.46s/epoch, loss=1.13, accuracy=0.756, val_loss=2.01, val_accuracy=0.509, lr=0.0316] 82%|████████▏ | 72/88 [24:10<05:09, 19.32s/epoch, loss=1.14, accuracy=0.754, val_loss=1.87, val_accuracy=0.569, lr=0.1]    83%|████████▎ | 73/88 [24:29<04:48, 19.23s/epoch, loss=1.13, accuracy=0.756, val_loss=2.24, val_accuracy=0.454, lr=0.1] 84%|████████▍ | 74/88 [24:48<04:28, 19.15s/epoch, loss=1.13, accuracy=0.755, val_loss=1.78, val_accuracy=0.563, lr=0.1] 85%|████████▌ | 75/88 [25:08<04:12, 19.39s/epoch, loss=1.14, accuracy=0.755, val_loss=1.55, val_accuracy=0.612, lr=0.1] 86%|████████▋ | 76/88 [25:27<03:51, 19.33s/epoch, loss=1.13, accuracy=0.755, val_loss=1.86, val_accuracy=0.538, lr=0.0316] 88%|████████▊ | 77/88 [25:46<03:31, 19.20s/epoch, loss=1.13, accuracy=0.752, val_loss=2.27, val_accuracy=0.489, lr=0.1]    89%|████████▊ | 78/88 [26:05<03:11, 19.12s/epoch, loss=1.14, accuracy=0.755, val_loss=1.78, val_accuracy=0.554, lr=0.1] 90%|████████▉ | 79/88 [26:24<02:52, 19.12s/epoch, loss=1.13, accuracy=0.756, val_loss=3.36, val_accuracy=0.364, lr=0.1] 91%|█████████ | 80/88 [26:43<02:32, 19.09s/epoch, loss=1.13, accuracy=0.757, val_loss=2.93, val_accuracy=0.377, lr=0.1] 92%|█████████▏| 81/88 [27:02<02:13, 19.04s/epoch, loss=1.13, accuracy=0.755, val_loss=1.66, val_accuracy=0.587, lr=0.0316] 93%|█████████▎| 82/88 [27:21<01:54, 19.03s/epoch, loss=0.912, accuracy=0.818, val_loss=0.879, val_accuracy=0.815, lr=0.01] 94%|█████████▍| 83/88 [27:40<01:34, 18.98s/epoch, loss=0.744, accuracy=0.847, val_loss=0.855, val_accuracy=0.801, lr=0.01] 95%|█████████▌| 84/88 [27:59<01:16, 19.13s/epoch, loss=0.66, accuracy=0.857, val_loss=0.753, val_accuracy=0.818, lr=0.01]  97%|█████████▋| 85/88 [28:19<00:57, 19.22s/epoch, loss=0.618, accuracy=0.86, val_loss=0.834, val_accuracy=0.791, lr=0.01] 98%|█████████▊| 86/88 [28:38<00:38, 19.33s/epoch, loss=0.594, accuracy=0.86, val_loss=0.688, val_accuracy=0.823, lr=0.01] 99%|█████████▉| 87/88 [28:59<00:19, 19.58s/epoch, loss=0.574, accuracy=0.865, val_loss=0.736, val_accuracy=0.808, lr=0.01]100%|██████████| 88/88 [29:18<00:00, 19.65s/epoch, loss=0.572, accuracy=0.864, val_loss=0.886, val_accuracy=0.774, lr=0.01]100%|██████████| 88/88 [29:18<00:00, 19.99s/epoch, loss=0.572, accuracy=0.864, val_loss=0.886, val_accuracy=0.774, lr=0.01]
Using real-time data augmentation.
Test score: 0.7039117217063904
Test accuracy: 0.8191999793052673


* * * Run SGD for ID = 17_16. * * *


2024-02-20 06:07:11.264661: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 06:07:15.308361: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 06:07:15.309272: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-20 06:07:15.347227: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-20 06:07:15.347254: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 06:07:15.350399: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 06:07:15.350439: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-20 06:07:15.352761: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-20 06:07:15.353422: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-20 06:07:15.355781: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-20 06:07:15.357191: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-20 06:07:15.361846: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 06:07:15.362368: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-20 06:07:15.362455: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 06:07:16.780773: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-20 06:07:16.781770: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 06:07:16.782226: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-20 06:07:16.782258: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 06:07:16.782291: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 06:07:16.782308: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-20 06:07:16.782323: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-20 06:07:16.782338: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-20 06:07:16.782353: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-20 06:07:16.782369: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-20 06:07:16.782384: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 06:07:16.782843: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-20 06:07:16.782880: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 06:07:17.409647: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-20 06:07:17.409709: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-20 06:07:17.409718: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-20 06:07:17.410985: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:02:00.0, compute capability: 6.1)
{'id': '17_16', 'batch_size': 128, 'epochs': 88, 'validation_split': 0.1, 'checkpointing': True, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
x_train shape: (45000, 32, 32, 3)
45000 train samples
5000 validation samples
10000 test samples
y_train shape: (45000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/88 [00:00<?, ?epoch/s]2024-02-20 06:07:18.281446: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-20 06:07:18.281921: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199825000 Hz
2024-02-20 06:07:20.266586: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 06:07:20.517608: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 06:07:21.271552: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-20 06:07:21.310581: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/88 [00:47<1:08:32, 47.27s/epoch, loss=3.29, accuracy=0.3, val_loss=2.41, val_accuracy=0.233, lr=0.1]  2%|▏         | 2/88 [01:06<44:13, 30.85s/epoch, loss=1.63, accuracy=0.512, val_loss=2.36, val_accuracy=0.344, lr=0.1]  3%|▎         | 3/88 [01:26<36:18, 25.63s/epoch, loss=1.46, accuracy=0.59, val_loss=1.65, val_accuracy=0.534, lr=0.1]   5%|▍         | 4/88 [01:45<32:24, 23.15s/epoch, loss=1.4, accuracy=0.626, val_loss=1.78, val_accuracy=0.499, lr=0.1]  6%|▌         | 5/88 [02:04<30:00, 21.69s/epoch, loss=1.34, accuracy=0.663, val_loss=2.64, val_accuracy=0.42, lr=0.1]  7%|▋         | 6/88 [02:23<28:24, 20.78s/epoch, loss=1.3, accuracy=0.684, val_loss=2.28, val_accuracy=0.411, lr=0.1]  8%|▊         | 7/88 [02:42<27:24, 20.31s/epoch, loss=1.26, accuracy=0.701, val_loss=1.87, val_accuracy=0.5, lr=0.1]   9%|▉         | 8/88 [03:03<27:10, 20.38s/epoch, loss=1.25, accuracy=0.711, val_loss=2.13, val_accuracy=0.466, lr=0.0316] 10%|█         | 9/88 [03:23<26:47, 20.34s/epoch, loss=1.23, accuracy=0.716, val_loss=1.7, val_accuracy=0.558, lr=0.1]     11%|█▏        | 10/88 [03:43<26:14, 20.18s/epoch, loss=1.23, accuracy=0.721, val_loss=1.64, val_accuracy=0.585, lr=0.1] 12%|█▎        | 11/88 [04:03<25:41, 20.01s/epoch, loss=1.22, accuracy=0.723, val_loss=2.35, val_accuracy=0.431, lr=0.1] 14%|█▎        | 12/88 [04:23<25:36, 20.22s/epoch, loss=1.21, accuracy=0.728, val_loss=1.68, val_accuracy=0.58, lr=0.1]  15%|█▍        | 13/88 [04:44<25:33, 20.45s/epoch, loss=1.21, accuracy=0.731, val_loss=1.33, val_accuracy=0.695, lr=0.1] 16%|█▌        | 14/88 [05:05<25:09, 20.40s/epoch, loss=1.21, accuracy=0.73, val_loss=1.77, val_accuracy=0.576, lr=0.1]  17%|█▋        | 15/88 [05:25<24:39, 20.27s/epoch, loss=1.2, accuracy=0.735, val_loss=1.48, val_accuracy=0.647, lr=0.1] 18%|█▊        | 16/88 [05:44<24:03, 20.04s/epoch, loss=1.19, accuracy=0.735, val_loss=1.76, val_accuracy=0.562, lr=0.1] 19%|█▉        | 17/88 [06:05<23:58, 20.26s/epoch, loss=1.2, accuracy=0.738, val_loss=1.51, val_accuracy=0.627, lr=0.1]  20%|██        | 18/88 [06:26<23:54, 20.50s/epoch, loss=1.18, accuracy=0.741, val_loss=2.07, val_accuracy=0.508, lr=0.0316] 22%|██▏       | 19/88 [06:45<23:09, 20.14s/epoch, loss=1.18, accuracy=0.741, val_loss=2.36, val_accuracy=0.464, lr=0.1]    23%|██▎       | 20/88 [07:05<22:41, 20.02s/epoch, loss=1.17, accuracy=0.742, val_loss=2.14, val_accuracy=0.431, lr=0.1] 24%|██▍       | 21/88 [07:24<22:09, 19.84s/epoch, loss=1.17, accuracy=0.746, val_loss=4.24, val_accuracy=0.352, lr=0.1] 25%|██▌       | 22/88 [07:43<21:34, 19.61s/epoch, loss=1.17, accuracy=0.745, val_loss=2.57, val_accuracy=0.422, lr=0.1] 26%|██▌       | 23/88 [08:04<21:31, 19.87s/epoch, loss=1.16, accuracy=0.745, val_loss=1.99, val_accuracy=0.458, lr=0.0316] 27%|██▋       | 24/88 [08:24<21:22, 20.04s/epoch, loss=1.17, accuracy=0.745, val_loss=2.3, val_accuracy=0.46, lr=0.1]      28%|██▊       | 25/88 [08:45<21:17, 20.28s/epoch, loss=1.15, accuracy=0.747, val_loss=2.44, val_accuracy=0.484, lr=0.1] 30%|██▉       | 26/88 [09:06<21:10, 20.49s/epoch, loss=1.16, accuracy=0.749, val_loss=1.63, val_accuracy=0.588, lr=0.1] 31%|███       | 27/88 [09:27<20:58, 20.64s/epoch, loss=1.16, accuracy=0.747, val_loss=1.65, val_accuracy=0.586, lr=0.1] 32%|███▏      | 28/88 [09:46<20:12, 20.22s/epoch, loss=1.16, accuracy=0.748, val_loss=1.57, val_accuracy=0.609, lr=0.0316] 33%|███▎      | 29/88 [10:06<19:43, 20.06s/epoch, loss=1.15, accuracy=0.746, val_loss=1.57, val_accuracy=0.594, lr=0.1]    34%|███▍      | 30/88 [10:26<19:22, 20.05s/epoch, loss=1.14, accuracy=0.751, val_loss=8.38, val_accuracy=0.178, lr=0.1] 35%|███▌      | 31/88 [10:45<18:49, 19.82s/epoch, loss=1.15, accuracy=0.75, val_loss=3.26, val_accuracy=0.329, lr=0.1]  36%|███▋      | 32/88 [11:04<18:11, 19.49s/epoch, loss=1.15, accuracy=0.748, val_loss=1.56, val_accuracy=0.604, lr=0.1] 38%|███▊      | 33/88 [11:23<17:43, 19.33s/epoch, loss=1.14, accuracy=0.749, val_loss=1.82, val_accuracy=0.516, lr=0.0316] 39%|███▊      | 34/88 [11:42<17:20, 19.27s/epoch, loss=1.14, accuracy=0.754, val_loss=2.07, val_accuracy=0.478, lr=0.1]    40%|███▉      | 35/88 [12:01<16:56, 19.18s/epoch, loss=1.15, accuracy=0.748, val_loss=1.74, val_accuracy=0.567, lr=0.1] 41%|████      | 36/88 [12:20<16:36, 19.16s/epoch, loss=1.14, accuracy=0.752, val_loss=1.54, val_accuracy=0.592, lr=0.1] 42%|████▏     | 37/88 [12:41<16:40, 19.63s/epoch, loss=1.14, accuracy=0.752, val_loss=1.97, val_accuracy=0.505, lr=0.1] 43%|████▎     | 38/88 [13:02<16:36, 19.92s/epoch, loss=1.13, accuracy=0.754, val_loss=2.08, val_accuracy=0.499, lr=0.0316] 44%|████▍     | 39/88 [13:22<16:26, 20.13s/epoch, loss=1.15, accuracy=0.75, val_loss=2.37, val_accuracy=0.424, lr=0.1]     45%|████▌     | 40/88 [13:43<16:14, 20.31s/epoch, loss=1.14, accuracy=0.751, val_loss=1.92, val_accuracy=0.552, lr=0.1] 47%|████▋     | 41/88 [14:02<15:39, 19.99s/epoch, loss=1.14, accuracy=0.752, val_loss=3.45, val_accuracy=0.412, lr=0.1] 48%|████▊     | 42/88 [14:23<15:26, 20.13s/epoch, loss=1.14, accuracy=0.753, val_loss=1.67, val_accuracy=0.614, lr=0.1] 49%|████▉     | 43/88 [14:42<15:02, 20.06s/epoch, loss=1.13, accuracy=0.753, val_loss=2.08, val_accuracy=0.5, lr=0.0316] 50%|█████     | 44/88 [15:02<14:31, 19.81s/epoch, loss=1.13, accuracy=0.752, val_loss=2.58, val_accuracy=0.401, lr=0.1]  51%|█████     | 45/88 [15:21<14:02, 19.59s/epoch, loss=1.13, accuracy=0.751, val_loss=1.94, val_accuracy=0.487, lr=0.1] 52%|█████▏    | 46/88 [15:40<13:40, 19.54s/epoch, loss=1.13, accuracy=0.752, val_loss=1.64, val_accuracy=0.656, lr=0.1] 53%|█████▎    | 47/88 [15:59<13:15, 19.40s/epoch, loss=1.13, accuracy=0.753, val_loss=4.01, val_accuracy=0.32, lr=0.1]  55%|█████▍    | 48/88 [16:20<13:14, 19.86s/epoch, loss=1.13, accuracy=0.751, val_loss=1.48, val_accuracy=0.64, lr=0.0316] 56%|█████▌    | 49/88 [16:39<12:45, 19.62s/epoch, loss=1.13, accuracy=0.75, val_loss=2.4, val_accuracy=0.417, lr=0.1]     57%|█████▋    | 50/88 [17:00<12:33, 19.82s/epoch, loss=1.13, accuracy=0.752, val_loss=1.29, val_accuracy=0.699, lr=0.1] 58%|█████▊    | 51/88 [17:18<12:01, 19.50s/epoch, loss=1.13, accuracy=0.752, val_loss=2.3, val_accuracy=0.471, lr=0.1]  59%|█████▉    | 52/88 [17:38<11:40, 19.46s/epoch, loss=1.13, accuracy=0.751, val_loss=3.22, val_accuracy=0.362, lr=0.1] 60%|██████    | 53/88 [17:57<11:19, 19.42s/epoch, loss=1.13, accuracy=0.753, val_loss=2.14, val_accuracy=0.526, lr=0.1] 61%|██████▏   | 54/88 [18:16<10:56, 19.30s/epoch, loss=1.13, accuracy=0.755, val_loss=2.68, val_accuracy=0.398, lr=0.1] 62%|██████▎   | 55/88 [18:35<10:33, 19.21s/epoch, loss=1.13, accuracy=0.753, val_loss=1.54, val_accuracy=0.591, lr=0.0316] 64%|██████▎   | 56/88 [18:54<10:13, 19.19s/epoch, loss=1.13, accuracy=0.754, val_loss=3.58, val_accuracy=0.357, lr=0.1]    65%|██████▍   | 57/88 [19:14<10:05, 19.52s/epoch, loss=1.13, accuracy=0.754, val_loss=1.39, val_accuracy=0.669, lr=0.1] 66%|██████▌   | 58/88 [19:34<09:45, 19.52s/epoch, loss=1.13, accuracy=0.755, val_loss=2.1, val_accuracy=0.518, lr=0.1]  67%|██████▋   | 59/88 [19:55<09:35, 19.86s/epoch, loss=1.13, accuracy=0.755, val_loss=2.08, val_accuracy=0.435, lr=0.1] 68%|██████▊   | 60/88 [20:14<09:10, 19.68s/epoch, loss=1.12, accuracy=0.756, val_loss=2.58, val_accuracy=0.313, lr=0.0316] 69%|██████▉   | 61/88 [20:33<08:48, 19.59s/epoch, loss=1.12, accuracy=0.754, val_loss=1.95, val_accuracy=0.576, lr=0.1]    70%|███████   | 62/88 [20:52<08:25, 19.44s/epoch, loss=1.13, accuracy=0.752, val_loss=2.82, val_accuracy=0.357, lr=0.1] 72%|███████▏  | 63/88 [21:12<08:04, 19.39s/epoch, loss=1.13, accuracy=0.755, val_loss=3.53, val_accuracy=0.36, lr=0.1]  73%|███████▎  | 64/88 [21:31<07:45, 19.38s/epoch, loss=1.13, accuracy=0.752, val_loss=1.63, val_accuracy=0.588, lr=0.1] 74%|███████▍  | 65/88 [21:51<07:29, 19.55s/epoch, loss=1.13, accuracy=0.754, val_loss=3.57, val_accuracy=0.217, lr=0.0316] 75%|███████▌  | 66/88 [22:11<07:10, 19.56s/epoch, loss=1.12, accuracy=0.754, val_loss=1.56, val_accuracy=0.606, lr=0.1]    76%|███████▌  | 67/88 [22:30<06:47, 19.39s/epoch, loss=1.13, accuracy=0.754, val_loss=2.97, val_accuracy=0.384, lr=0.1] 77%|███████▋  | 68/88 [22:49<06:28, 19.43s/epoch, loss=1.13, accuracy=0.754, val_loss=1.77, val_accuracy=0.578, lr=0.1] 78%|███████▊  | 69/88 [23:08<06:06, 19.26s/epoch, loss=1.12, accuracy=0.756, val_loss=1.42, val_accuracy=0.649, lr=0.1] 80%|███████▉  | 70/88 [23:27<05:45, 19.21s/epoch, loss=1.13, accuracy=0.755, val_loss=1.64, val_accuracy=0.603, lr=0.0316] 81%|████████  | 71/88 [23:47<05:28, 19.30s/epoch, loss=1.13, accuracy=0.754, val_loss=1.98, val_accuracy=0.515, lr=0.1]    82%|████████▏ | 72/88 [24:07<05:14, 19.64s/epoch, loss=1.12, accuracy=0.754, val_loss=2.09, val_accuracy=0.498, lr=0.1] 83%|████████▎ | 73/88 [24:26<04:53, 19.55s/epoch, loss=1.13, accuracy=0.757, val_loss=1.8, val_accuracy=0.544, lr=0.1]  84%|████████▍ | 74/88 [24:45<04:31, 19.37s/epoch, loss=1.11, accuracy=0.757, val_loss=1.92, val_accuracy=0.49, lr=0.1] 85%|████████▌ | 75/88 [25:05<04:12, 19.41s/epoch, loss=1.12, accuracy=0.757, val_loss=2.05, val_accuracy=0.451, lr=0.0316] 86%|████████▋ | 76/88 [25:24<03:53, 19.50s/epoch, loss=1.12, accuracy=0.757, val_loss=1.91, val_accuracy=0.526, lr=0.1]    88%|████████▊ | 77/88 [25:44<03:34, 19.46s/epoch, loss=1.12, accuracy=0.755, val_loss=1.89, val_accuracy=0.515, lr=0.1] 89%|████████▊ | 78/88 [26:03<03:15, 19.52s/epoch, loss=1.12, accuracy=0.756, val_loss=1.95, val_accuracy=0.538, lr=0.1] 90%|████████▉ | 79/88 [26:23<02:54, 19.38s/epoch, loss=1.12, accuracy=0.757, val_loss=2.34, val_accuracy=0.469, lr=0.1] 91%|█████████ | 80/88 [26:41<02:33, 19.21s/epoch, loss=1.11, accuracy=0.757, val_loss=1.52, val_accuracy=0.641, lr=0.0316] 92%|█████████▏| 81/88 [27:01<02:15, 19.36s/epoch, loss=1.12, accuracy=0.757, val_loss=1.56, val_accuracy=0.631, lr=0.1]    93%|█████████▎| 82/88 [27:20<01:55, 19.33s/epoch, loss=0.928, accuracy=0.809, val_loss=0.888, val_accuracy=0.812, lr=0.01] 94%|█████████▍| 83/88 [27:40<01:36, 19.35s/epoch, loss=0.742, accuracy=0.845, val_loss=0.749, val_accuracy=0.833, lr=0.01] 95%|█████████▌| 84/88 [27:59<01:17, 19.28s/epoch, loss=0.659, accuracy=0.855, val_loss=0.723, val_accuracy=0.827, lr=0.01] 97%|█████████▋| 85/88 [28:18<00:57, 19.22s/epoch, loss=0.615, accuracy=0.858, val_loss=0.714, val_accuracy=0.815, lr=0.01] 98%|█████████▊| 86/88 [28:37<00:38, 19.20s/epoch, loss=0.589, accuracy=0.861, val_loss=0.718, val_accuracy=0.809, lr=0.01] 99%|█████████▉| 87/88 [28:57<00:19, 19.34s/epoch, loss=0.577, accuracy=0.862, val_loss=0.762, val_accuracy=0.793, lr=0.01]100%|██████████| 88/88 [29:15<00:00, 19.16s/epoch, loss=0.576, accuracy=0.861, val_loss=0.828, val_accuracy=0.783, lr=0.01]100%|██████████| 88/88 [29:15<00:00, 19.95s/epoch, loss=0.576, accuracy=0.861, val_loss=0.828, val_accuracy=0.783, lr=0.01]
Using real-time data augmentation.
Test score: 0.7831169962882996
Test accuracy: 0.8205000162124634


* * * Run SGD for ID = 17_17. * * *


2024-02-20 06:36:39.208413: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 06:36:41.937713: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 06:36:41.938629: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-20 06:36:41.975668: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-20 06:36:41.975697: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 06:36:41.978395: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 06:36:41.978435: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-20 06:36:41.980568: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-20 06:36:41.981206: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-20 06:36:41.983566: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-20 06:36:41.984968: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-20 06:36:41.989616: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 06:36:41.990131: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-20 06:36:41.990219: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 06:36:43.401340: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-20 06:36:43.402818: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 06:36:43.403551: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-20 06:36:43.403585: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 06:36:43.403620: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 06:36:43.403638: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-20 06:36:43.403664: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-20 06:36:43.403681: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-20 06:36:43.403696: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-20 06:36:43.403711: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-20 06:36:43.403727: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 06:36:43.404192: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-20 06:36:43.404230: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 06:36:44.009650: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-20 06:36:44.009703: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-20 06:36:44.009713: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-20 06:36:44.010616: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:02:00.0, compute capability: 6.1)
{'id': '17_17', 'batch_size': 128, 'epochs': 88, 'validation_split': 0.1, 'checkpointing': True, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
x_train shape: (45000, 32, 32, 3)
45000 train samples
5000 validation samples
10000 test samples
y_train shape: (45000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/88 [00:00<?, ?epoch/s]2024-02-20 06:36:44.809615: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-20 06:36:44.810075: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199825000 Hz
2024-02-20 06:36:46.764117: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 06:36:46.996037: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 06:36:47.765081: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-20 06:36:47.799031: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/88 [00:47<1:08:17, 47.10s/epoch, loss=3.31, accuracy=0.266, val_loss=2.37, val_accuracy=0.213, lr=0.1]  2%|▏         | 2/88 [01:07<45:03, 31.44s/epoch, loss=1.67, accuracy=0.483, val_loss=2.16, val_accuracy=0.421, lr=0.1]    3%|▎         | 3/88 [01:26<36:27, 25.73s/epoch, loss=1.41, accuracy=0.599, val_loss=3.52, val_accuracy=0.287, lr=0.1]  5%|▍         | 4/88 [01:46<32:45, 23.39s/epoch, loss=1.3, accuracy=0.663, val_loss=1.66, val_accuracy=0.526, lr=0.1]   6%|▌         | 5/88 [02:07<31:00, 22.42s/epoch, loss=1.26, accuracy=0.689, val_loss=1.79, val_accuracy=0.494, lr=0.1]  7%|▋         | 6/88 [02:27<29:51, 21.85s/epoch, loss=1.25, accuracy=0.706, val_loss=3.88, val_accuracy=0.226, lr=0.1]  8%|▊         | 7/88 [02:47<28:35, 21.18s/epoch, loss=1.23, accuracy=0.713, val_loss=3.78, val_accuracy=0.301, lr=0.1]  9%|▉         | 8/88 [03:08<27:57, 20.97s/epoch, loss=1.22, accuracy=0.72, val_loss=1.82, val_accuracy=0.526, lr=0.1]  10%|█         | 9/88 [03:29<27:42, 21.04s/epoch, loss=1.21, accuracy=0.724, val_loss=1.99, val_accuracy=0.496, lr=0.0316] 11%|█▏        | 10/88 [03:50<27:18, 21.00s/epoch, loss=1.21, accuracy=0.728, val_loss=2, val_accuracy=0.522, lr=0.1]      12%|█▎        | 11/88 [04:09<26:22, 20.56s/epoch, loss=1.2, accuracy=0.732, val_loss=2.11, val_accuracy=0.524, lr=0.1] 14%|█▎        | 12/88 [04:29<25:45, 20.33s/epoch, loss=1.2, accuracy=0.733, val_loss=1.58, val_accuracy=0.588, lr=0.1] 15%|█▍        | 13/88 [04:49<25:06, 20.08s/epoch, loss=1.2, accuracy=0.735, val_loss=1.76, val_accuracy=0.557, lr=0.1] 16%|█▌        | 14/88 [05:10<25:22, 20.58s/epoch, loss=1.2, accuracy=0.734, val_loss=1.64, val_accuracy=0.598, lr=0.1] 17%|█▋        | 15/88 [05:30<24:39, 20.27s/epoch, loss=1.19, accuracy=0.735, val_loss=2.54, val_accuracy=0.455, lr=0.1] 18%|█▊        | 16/88 [05:49<24:01, 20.01s/epoch, loss=1.18, accuracy=0.741, val_loss=1.85, val_accuracy=0.557, lr=0.1] 19%|█▉        | 17/88 [06:10<23:54, 20.21s/epoch, loss=1.19, accuracy=0.739, val_loss=1.97, val_accuracy=0.498, lr=0.0316] 20%|██        | 18/88 [06:31<23:52, 20.46s/epoch, loss=1.18, accuracy=0.74, val_loss=1.61, val_accuracy=0.599, lr=0.1]     22%|██▏       | 19/88 [06:50<23:09, 20.14s/epoch, loss=1.18, accuracy=0.74, val_loss=5, val_accuracy=0.313, lr=0.1]    23%|██▎       | 20/88 [07:10<22:47, 20.11s/epoch, loss=1.17, accuracy=0.745, val_loss=1.7, val_accuracy=0.559, lr=0.1] 24%|██▍       | 21/88 [07:30<22:18, 19.97s/epoch, loss=1.17, accuracy=0.744, val_loss=1.85, val_accuracy=0.546, lr=0.1] 25%|██▌       | 22/88 [07:49<21:47, 19.81s/epoch, loss=1.17, accuracy=0.744, val_loss=1.99, val_accuracy=0.479, lr=0.0316] 26%|██▌       | 23/88 [08:11<21:58, 20.28s/epoch, loss=1.17, accuracy=0.743, val_loss=2.11, val_accuracy=0.466, lr=0.1]    27%|██▋       | 24/88 [08:31<21:31, 20.18s/epoch, loss=1.16, accuracy=0.744, val_loss=1.55, val_accuracy=0.616, lr=0.1] 28%|██▊       | 25/88 [08:51<21:04, 20.08s/epoch, loss=1.17, accuracy=0.744, val_loss=2.18, val_accuracy=0.441, lr=0.1] 30%|██▉       | 26/88 [09:10<20:37, 19.97s/epoch, loss=1.16, accuracy=0.749, val_loss=1.61, val_accuracy=0.587, lr=0.1] 31%|███       | 27/88 [09:30<20:10, 19.85s/epoch, loss=1.16, accuracy=0.748, val_loss=1.54, val_accuracy=0.614, lr=0.1] 32%|███▏      | 28/88 [09:49<19:43, 19.73s/epoch, loss=1.15, accuracy=0.748, val_loss=1.76, val_accuracy=0.584, lr=0.1] 33%|███▎      | 29/88 [10:09<19:18, 19.63s/epoch, loss=1.16, accuracy=0.749, val_loss=2.37, val_accuracy=0.404, lr=0.1] 34%|███▍      | 30/88 [10:28<18:58, 19.62s/epoch, loss=1.15, accuracy=0.752, val_loss=1.78, val_accuracy=0.545, lr=0.1] 35%|███▌      | 31/88 [10:48<18:31, 19.50s/epoch, loss=1.16, accuracy=0.748, val_loss=1.86, val_accuracy=0.555, lr=0.1] 36%|███▋      | 32/88 [11:08<18:25, 19.75s/epoch, loss=1.15, accuracy=0.749, val_loss=1.89, val_accuracy=0.537, lr=0.0316] 38%|███▊      | 33/88 [11:29<18:24, 20.09s/epoch, loss=1.15, accuracy=0.75, val_loss=1.48, val_accuracy=0.622, lr=0.1]     39%|███▊      | 34/88 [11:50<18:19, 20.37s/epoch, loss=1.15, accuracy=0.748, val_loss=2.32, val_accuracy=0.416, lr=0.1] 40%|███▉      | 35/88 [12:10<17:55, 20.29s/epoch, loss=1.15, accuracy=0.748, val_loss=3.08, val_accuracy=0.382, lr=0.1] 41%|████      | 36/88 [12:31<17:48, 20.55s/epoch, loss=1.14, accuracy=0.754, val_loss=2.49, val_accuracy=0.397, lr=0.1] 42%|████▏     | 37/88 [12:51<17:15, 20.30s/epoch, loss=1.14, accuracy=0.751, val_loss=1.68, val_accuracy=0.599, lr=0.1] 43%|████▎     | 38/88 [13:11<16:53, 20.27s/epoch, loss=1.15, accuracy=0.751, val_loss=1.57, val_accuracy=0.587, lr=0.0316] 44%|████▍     | 39/88 [13:31<16:25, 20.11s/epoch, loss=1.15, accuracy=0.749, val_loss=1.69, val_accuracy=0.589, lr=0.1]    45%|████▌     | 40/88 [13:50<16:00, 20.00s/epoch, loss=1.13, accuracy=0.755, val_loss=1.97, val_accuracy=0.495, lr=0.1] 47%|████▋     | 41/88 [14:10<15:39, 19.99s/epoch, loss=1.14, accuracy=0.754, val_loss=2.01, val_accuracy=0.476, lr=0.1] 48%|████▊     | 42/88 [14:30<15:08, 19.74s/epoch, loss=1.15, accuracy=0.75, val_loss=2.46, val_accuracy=0.442, lr=0.1]  49%|████▉     | 43/88 [14:49<14:45, 19.69s/epoch, loss=1.14, accuracy=0.755, val_loss=1.64, val_accuracy=0.568, lr=0.0316] 50%|█████     | 44/88 [15:08<14:21, 19.57s/epoch, loss=1.14, accuracy=0.753, val_loss=1.88, val_accuracy=0.513, lr=0.1]    51%|█████     | 45/88 [15:28<14:02, 19.60s/epoch, loss=1.14, accuracy=0.752, val_loss=1.81, val_accuracy=0.574, lr=0.1] 52%|█████▏    | 46/88 [15:48<13:40, 19.53s/epoch, loss=1.14, accuracy=0.752, val_loss=2.85, val_accuracy=0.455, lr=0.1] 53%|█████▎    | 47/88 [16:08<13:34, 19.87s/epoch, loss=1.14, accuracy=0.753, val_loss=2.78, val_accuracy=0.432, lr=0.1] 55%|█████▍    | 48/88 [16:28<13:11, 19.79s/epoch, loss=1.14, accuracy=0.752, val_loss=1.98, val_accuracy=0.471, lr=0.0316] 56%|█████▌    | 49/88 [16:47<12:46, 19.66s/epoch, loss=1.14, accuracy=0.754, val_loss=3.13, val_accuracy=0.295, lr=0.1]    57%|█████▋    | 50/88 [17:07<12:28, 19.71s/epoch, loss=1.14, accuracy=0.753, val_loss=1.86, val_accuracy=0.497, lr=0.1] 58%|█████▊    | 51/88 [17:27<12:17, 19.94s/epoch, loss=1.13, accuracy=0.757, val_loss=2.31, val_accuracy=0.443, lr=0.1] 59%|█████▉    | 52/88 [17:47<11:51, 19.77s/epoch, loss=1.13, accuracy=0.754, val_loss=1.67, val_accuracy=0.566, lr=0.1] 60%|██████    | 53/88 [18:07<11:32, 19.78s/epoch, loss=1.13, accuracy=0.756, val_loss=1.85, val_accuracy=0.581, lr=0.0316] 61%|██████▏   | 54/88 [18:26<11:09, 19.69s/epoch, loss=1.13, accuracy=0.754, val_loss=2.24, val_accuracy=0.458, lr=0.1]    62%|██████▎   | 55/88 [18:46<10:55, 19.86s/epoch, loss=1.12, accuracy=0.758, val_loss=1.84, val_accuracy=0.537, lr=0.1] 64%|██████▎   | 56/88 [19:07<10:42, 20.08s/epoch, loss=1.13, accuracy=0.754, val_loss=1.76, val_accuracy=0.543, lr=0.1] 65%|██████▍   | 57/88 [19:27<10:24, 20.16s/epoch, loss=1.13, accuracy=0.756, val_loss=4.26, val_accuracy=0.317, lr=0.1] 66%|██████▌   | 58/88 [19:47<09:56, 19.90s/epoch, loss=1.13, accuracy=0.754, val_loss=2.21, val_accuracy=0.538, lr=0.0316] 67%|██████▋   | 59/88 [20:06<09:34, 19.81s/epoch, loss=1.13, accuracy=0.755, val_loss=3.77, val_accuracy=0.355, lr=0.1]    68%|██████▊   | 60/88 [20:26<09:13, 19.77s/epoch, loss=1.12, accuracy=0.756, val_loss=2.08, val_accuracy=0.46, lr=0.1]  69%|██████▉   | 61/88 [20:45<08:52, 19.72s/epoch, loss=1.13, accuracy=0.754, val_loss=1.5, val_accuracy=0.626, lr=0.1] 70%|███████   | 62/88 [21:05<08:29, 19.61s/epoch, loss=1.13, accuracy=0.756, val_loss=1.88, val_accuracy=0.538, lr=0.1] 72%|███████▏  | 63/88 [21:24<08:08, 19.55s/epoch, loss=1.12, accuracy=0.756, val_loss=2.07, val_accuracy=0.492, lr=0.0316] 73%|███████▎  | 64/88 [21:43<07:47, 19.47s/epoch, loss=1.12, accuracy=0.759, val_loss=1.64, val_accuracy=0.58, lr=0.1]     74%|███████▍  | 65/88 [22:04<07:36, 19.83s/epoch, loss=1.12, accuracy=0.757, val_loss=2.4, val_accuracy=0.298, lr=0.1] 75%|███████▌  | 66/88 [22:25<07:20, 20.04s/epoch, loss=1.12, accuracy=0.756, val_loss=2.11, val_accuracy=0.44, lr=0.1] 76%|███████▌  | 67/88 [22:44<06:57, 19.90s/epoch, loss=1.12, accuracy=0.76, val_loss=2.25, val_accuracy=0.438, lr=0.1] 77%|███████▋  | 68/88 [23:03<06:33, 19.68s/epoch, loss=1.11, accuracy=0.759, val_loss=3.66, val_accuracy=0.365, lr=0.0316] 78%|███████▊  | 69/88 [23:23<06:11, 19.55s/epoch, loss=1.11, accuracy=0.76, val_loss=1.8, val_accuracy=0.532, lr=0.1]      80%|███████▉  | 70/88 [23:42<05:50, 19.47s/epoch, loss=1.11, accuracy=0.757, val_loss=2.2, val_accuracy=0.456, lr=0.1] 81%|████████  | 71/88 [24:02<05:32, 19.54s/epoch, loss=1.12, accuracy=0.756, val_loss=2.12, val_accuracy=0.458, lr=0.1] 82%|████████▏ | 72/88 [24:21<05:11, 19.46s/epoch, loss=1.12, accuracy=0.758, val_loss=1.94, val_accuracy=0.536, lr=0.1] 83%|████████▎ | 73/88 [24:41<04:52, 19.51s/epoch, loss=1.12, accuracy=0.756, val_loss=3.34, val_accuracy=0.287, lr=0.0316] 84%|████████▍ | 74/88 [25:01<04:36, 19.73s/epoch, loss=1.11, accuracy=0.757, val_loss=1.56, val_accuracy=0.617, lr=0.1]    85%|████████▌ | 75/88 [25:21<04:18, 19.88s/epoch, loss=1.12, accuracy=0.753, val_loss=1.42, val_accuracy=0.656, lr=0.1] 86%|████████▋ | 76/88 [25:40<03:55, 19.66s/epoch, loss=1.11, accuracy=0.756, val_loss=1.87, val_accuracy=0.527, lr=0.1] 88%|████████▊ | 77/88 [25:59<03:35, 19.55s/epoch, loss=1.11, accuracy=0.756, val_loss=2.51, val_accuracy=0.395, lr=0.1] 89%|████████▊ | 78/88 [26:19<03:16, 19.60s/epoch, loss=1.12, accuracy=0.755, val_loss=1.83, val_accuracy=0.559, lr=0.1] 90%|████████▉ | 79/88 [26:39<02:55, 19.52s/epoch, loss=1.11, accuracy=0.759, val_loss=2.91, val_accuracy=0.419, lr=0.1] 91%|█████████ | 80/88 [26:58<02:35, 19.41s/epoch, loss=1.11, accuracy=0.757, val_loss=1.66, val_accuracy=0.595, lr=0.0316] 92%|█████████▏| 81/88 [27:17<02:15, 19.38s/epoch, loss=1.11, accuracy=0.759, val_loss=1.7, val_accuracy=0.564, lr=0.1]     93%|█████████▎| 82/88 [27:37<01:56, 19.46s/epoch, loss=0.922, accuracy=0.813, val_loss=0.984, val_accuracy=0.785, lr=0.01] 94%|█████████▍| 83/88 [27:58<01:39, 19.91s/epoch, loss=0.744, accuracy=0.845, val_loss=0.829, val_accuracy=0.802, lr=0.01] 95%|█████████▌| 84/88 [28:19<01:20, 20.21s/epoch, loss=0.661, accuracy=0.855, val_loss=0.75, val_accuracy=0.819, lr=0.01]  97%|█████████▋| 85/88 [28:38<00:59, 19.99s/epoch, loss=0.614, accuracy=0.858, val_loss=0.774, val_accuracy=0.799, lr=0.01] 98%|█████████▊| 86/88 [28:57<00:39, 19.81s/epoch, loss=0.59, accuracy=0.862, val_loss=0.77, val_accuracy=0.797, lr=0.01]   99%|█████████▉| 87/88 [29:18<00:20, 20.19s/epoch, loss=0.579, accuracy=0.862, val_loss=0.82, val_accuracy=0.781, lr=0.01]100%|██████████| 88/88 [29:38<00:00, 19.97s/epoch, loss=0.568, accuracy=0.863, val_loss=0.726, val_accuracy=0.816, lr=0.01]100%|██████████| 88/88 [29:38<00:00, 20.21s/epoch, loss=0.568, accuracy=0.863, val_loss=0.726, val_accuracy=0.816, lr=0.01]
Using real-time data augmentation.
Test score: 0.7662996649742126
Test accuracy: 0.8149999976158142
