Sat Mar 16 23:23:44 2024       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 545.23.08              Driver Version: 545.23.08    CUDA Version: 12.3     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA TITAN Xp                Off | 00000000:83:00.0 Off |                  N/A |
| 59%   79C    P0             109W / 250W |      0MiB / 12288MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|  No running processes found                                                           |
+---------------------------------------------------------------------------------------+


* * * Run SGD for ID = 30. * * *


2024-03-16 23:23:44.673555: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-16 23:23:49.027698: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-16 23:23:49.028832: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-16 23:23:49.078466: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-16 23:23:49.078500: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-16 23:23:49.087229: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-16 23:23:49.087279: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-16 23:23:49.095520: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-16 23:23:49.112502: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-16 23:23:49.120933: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-16 23:23:49.129877: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-16 23:23:49.147047: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-16 23:23:49.149031: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-16 23:23:49.149150: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-16 23:23:50.725945: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-16 23:23:50.727283: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-16 23:23:50.727726: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-16 23:23:50.727760: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-16 23:23:50.727793: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-16 23:23:50.727813: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-16 23:23:50.727831: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-16 23:23:50.727849: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-16 23:23:50.727867: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-16 23:23:50.727884: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-16 23:23:50.727903: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-16 23:23:50.728435: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-16 23:23:50.728478: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-16 23:23:51.534633: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-16 23:23:51.534699: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-16 23:23:51.534710: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-16 23:23:51.538618: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': '30', 'seed': 30, 'out_folder': 'results/cifar10/resnet110/30_independent_wenzel_no_checkp_0_2_val', 'batch_size': 128, 'epochs': 200, 'validation_split': 0.2, 'checkpointing': False, 'checkpoint_every': -1, 'hold_out_validation_split': 0.0, 'model_type': 'ResNet110v1', 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.01, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'bootstrapping': False, 'num_classes': 10, 'SSE_lr': False, 'test_time_augmentation': False, 'store_models': False, 'debug': False, 'model': 'ResNet110v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
x_train shape: (40000, 32, 32, 3)
y_train shape: (40000, 10)
x_val shape: (10000, 32, 32, 3)
y_val shape: (10000, 10)
ResNet110v1
0epoch [00:00, ?epoch/s]  0%|          | 0/200 [00:00<?, ?epoch/s]2024-03-16 23:23:53.718409: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-16 23:23:53.730183: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199825000 Hz
2024-03-16 23:24:05.295538: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-16 23:24:05.490524: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-16 23:24:06.220102: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-16 23:24:06.266174: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  0%|          | 1/200 [01:23<4:38:34, 83.99s/epoch, loss=16.8, accuracy=0.324, val_loss=15.1, val_accuracy=0.241, lr=0.01]  1%|          | 2/200 [01:56<2:56:30, 53.49s/epoch, loss=12.9, accuracy=0.506, val_loss=11.5, val_accuracy=0.527, lr=0.01]  2%|▏         | 3/200 [02:28<2:23:53, 43.83s/epoch, loss=10.2, accuracy=0.591, val_loss=9.28, val_accuracy=0.546, lr=0.01]  2%|▏         | 4/200 [03:00<2:08:21, 39.29s/epoch, loss=8.07, accuracy=0.65, val_loss=7.54, val_accuracy=0.572, lr=0.01]   2%|▎         | 5/200 [03:33<1:59:38, 36.81s/epoch, loss=6.43, accuracy=0.689, val_loss=6.39, val_accuracy=0.545, lr=0.01]  3%|▎         | 6/200 [04:05<1:54:24, 35.38s/epoch, loss=5.18, accuracy=0.716, val_loss=4.96, val_accuracy=0.623, lr=0.01]  4%|▎         | 7/200 [04:37<1:50:18, 34.29s/epoch, loss=4.2, accuracy=0.743, val_loss=4.06, val_accuracy=0.672, lr=0.01]   4%|▍         | 8/200 [05:10<1:47:37, 33.63s/epoch, loss=3.44, accuracy=0.757, val_loss=3.71, val_accuracy=0.605, lr=0.01]  4%|▍         | 9/200 [05:42<1:45:47, 33.24s/epoch, loss=2.86, accuracy=0.77, val_loss=2.98, val_accuracy=0.673, lr=0.01]   5%|▌         | 10/200 [06:15<1:44:37, 33.04s/epoch, loss=2.4, accuracy=0.78, val_loss=2.38, val_accuracy=0.732, lr=0.01]  6%|▌         | 11/200 [06:47<1:43:31, 32.87s/epoch, loss=2.04, accuracy=0.791, val_loss=2.54, val_accuracy=0.602, lr=0.01]  6%|▌         | 12/200 [07:19<1:42:26, 32.69s/epoch, loss=1.77, accuracy=0.796, val_loss=2.22, val_accuracy=0.644, lr=0.01]  6%|▋         | 13/200 [07:52<1:41:30, 32.57s/epoch, loss=1.57, accuracy=0.799, val_loss=2.03, val_accuracy=0.622, lr=0.01]  7%|▋         | 14/200 [08:24<1:40:49, 32.52s/epoch, loss=1.39, accuracy=0.811, val_loss=1.71, val_accuracy=0.692, lr=0.01]  8%|▊         | 15/200 [08:57<1:40:18, 32.53s/epoch, loss=1.26, accuracy=0.816, val_loss=1.49, val_accuracy=0.73, lr=0.01]   8%|▊         | 16/200 [09:29<1:39:32, 32.46s/epoch, loss=1.15, accuracy=0.817, val_loss=1.48, val_accuracy=0.714, lr=0.01]  8%|▊         | 17/200 [10:01<1:39:03, 32.48s/epoch, loss=1.07, accuracy=0.825, val_loss=1.39, val_accuracy=0.722, lr=0.01]  9%|▉         | 18/200 [10:34<1:38:33, 32.49s/epoch, loss=1, accuracy=0.826, val_loss=1.41, val_accuracy=0.722, lr=0.01]    10%|▉         | 19/200 [11:07<1:38:21, 32.60s/epoch, loss=0.954, accuracy=0.831, val_loss=1.64, val_accuracy=0.599, lr=0.01] 10%|█         | 20/200 [11:39<1:37:54, 32.64s/epoch, loss=0.903, accuracy=0.836, val_loss=1.39, val_accuracy=0.688, lr=0.01] 10%|█         | 21/200 [12:12<1:37:30, 32.69s/epoch, loss=0.878, accuracy=0.835, val_loss=1.3, val_accuracy=0.708, lr=0.01]  11%|█         | 22/200 [12:45<1:36:54, 32.66s/epoch, loss=0.857, accuracy=0.837, val_loss=1.54, val_accuracy=0.619, lr=0.01] 12%|█▏        | 23/200 [13:18<1:36:29, 32.71s/epoch, loss=0.82, accuracy=0.844, val_loss=1.13, val_accuracy=0.736, lr=0.01]  12%|█▏        | 24/200 [13:50<1:35:59, 32.72s/epoch, loss=0.795, accuracy=0.847, val_loss=1.29, val_accuracy=0.693, lr=0.01] 12%|█▎        | 25/200 [14:23<1:35:22, 32.70s/epoch, loss=0.782, accuracy=0.851, val_loss=1.12, val_accuracy=0.737, lr=0.01] 13%|█▎        | 26/200 [14:56<1:35:02, 32.77s/epoch, loss=0.784, accuracy=0.847, val_loss=1.7, val_accuracy=0.619, lr=0.01]  14%|█▎        | 27/200 [15:29<1:34:16, 32.70s/epoch, loss=0.757, accuracy=0.854, val_loss=1.17, val_accuracy=0.743, lr=0.01] 14%|█▍        | 28/200 [16:01<1:33:35, 32.65s/epoch, loss=0.76, accuracy=0.854, val_loss=1.29, val_accuracy=0.693, lr=0.01]  14%|█▍        | 29/200 [16:33<1:32:35, 32.49s/epoch, loss=0.745, accuracy=0.857, val_loss=1.35, val_accuracy=0.691, lr=0.01] 15%|█▌        | 30/200 [17:06<1:32:10, 32.53s/epoch, loss=0.731, accuracy=0.859, val_loss=1.47, val_accuracy=0.656, lr=0.01] 16%|█▌        | 31/200 [17:39<1:31:56, 32.64s/epoch, loss=0.719, accuracy=0.862, val_loss=0.98, val_accuracy=0.785, lr=0.01] 16%|█▌        | 32/200 [18:11<1:31:11, 32.57s/epoch, loss=0.714, accuracy=0.864, val_loss=1, val_accuracy=0.776, lr=0.01]    16%|█▋        | 33/200 [18:44<1:30:42, 32.59s/epoch, loss=0.708, accuracy=0.864, val_loss=1.24, val_accuracy=0.709, lr=0.01] 17%|█▋        | 34/200 [19:16<1:30:04, 32.55s/epoch, loss=0.709, accuracy=0.865, val_loss=1.11, val_accuracy=0.746, lr=0.01] 18%|█▊        | 35/200 [19:49<1:29:23, 32.51s/epoch, loss=0.702, accuracy=0.867, val_loss=1.2, val_accuracy=0.739, lr=0.01]  18%|█▊        | 36/200 [20:21<1:28:41, 32.45s/epoch, loss=0.701, accuracy=0.867, val_loss=1.7, val_accuracy=0.619, lr=0.01] 18%|█▊        | 37/200 [20:53<1:27:53, 32.35s/epoch, loss=0.695, accuracy=0.868, val_loss=0.933, val_accuracy=0.789, lr=0.01] 19%|█▉        | 38/200 [21:25<1:27:20, 32.35s/epoch, loss=0.692, accuracy=0.87, val_loss=2.04, val_accuracy=0.589, lr=0.01]   20%|█▉        | 39/200 [21:58<1:27:12, 32.50s/epoch, loss=0.689, accuracy=0.87, val_loss=0.946, val_accuracy=0.784, lr=0.01] 20%|██        | 40/200 [22:30<1:26:23, 32.39s/epoch, loss=0.679, accuracy=0.874, val_loss=1.44, val_accuracy=0.663, lr=0.01] 20%|██        | 41/200 [23:03<1:25:43, 32.35s/epoch, loss=0.682, accuracy=0.873, val_loss=1.01, val_accuracy=0.766, lr=0.01] 21%|██        | 42/200 [23:35<1:25:27, 32.46s/epoch, loss=0.68, accuracy=0.875, val_loss=1.13, val_accuracy=0.76, lr=0.01]   22%|██▏       | 43/200 [24:08<1:25:11, 32.56s/epoch, loss=0.681, accuracy=0.876, val_loss=0.984, val_accuracy=0.793, lr=0.01] 22%|██▏       | 44/200 [24:40<1:24:24, 32.47s/epoch, loss=0.672, accuracy=0.876, val_loss=0.87, val_accuracy=0.824, lr=0.01]  22%|██▎       | 45/200 [25:13<1:23:47, 32.44s/epoch, loss=0.67, accuracy=0.879, val_loss=1.79, val_accuracy=0.619, lr=0.01]  23%|██▎       | 46/200 [25:45<1:23:15, 32.44s/epoch, loss=0.666, accuracy=0.879, val_loss=1.19, val_accuracy=0.747, lr=0.01] 24%|██▎       | 47/200 [26:17<1:22:29, 32.35s/epoch, loss=0.67, accuracy=0.88, val_loss=1, val_accuracy=0.77, lr=0.01]       24%|██▍       | 48/200 [26:50<1:22:12, 32.45s/epoch, loss=0.668, accuracy=0.882, val_loss=1.54, val_accuracy=0.657, lr=0.01] 24%|██▍       | 49/200 [27:23<1:21:42, 32.47s/epoch, loss=0.669, accuracy=0.88, val_loss=1.77, val_accuracy=0.629, lr=0.01]  25%|██▌       | 50/200 [27:55<1:21:09, 32.46s/epoch, loss=0.656, accuracy=0.885, val_loss=1.23, val_accuracy=0.718, lr=0.01] 26%|██▌       | 51/200 [28:28<1:20:44, 32.51s/epoch, loss=0.665, accuracy=0.882, val_loss=0.965, val_accuracy=0.791, lr=0.01] 26%|██▌       | 52/200 [29:00<1:20:14, 32.53s/epoch, loss=0.651, accuracy=0.885, val_loss=1.04, val_accuracy=0.761, lr=0.01]  26%|██▋       | 53/200 [29:33<1:19:56, 32.63s/epoch, loss=0.659, accuracy=0.882, val_loss=1.38, val_accuracy=0.695, lr=0.01] 27%|██▋       | 54/200 [30:06<1:19:29, 32.67s/epoch, loss=0.652, accuracy=0.884, val_loss=1.29, val_accuracy=0.718, lr=0.01] 28%|██▊       | 55/200 [30:38<1:18:42, 32.57s/epoch, loss=0.651, accuracy=0.885, val_loss=1.13, val_accuracy=0.765, lr=0.01] 28%|██▊       | 56/200 [31:11<1:18:19, 32.64s/epoch, loss=0.652, accuracy=0.885, val_loss=1.14, val_accuracy=0.752, lr=0.01] 28%|██▊       | 57/200 [31:43<1:17:38, 32.58s/epoch, loss=0.651, accuracy=0.886, val_loss=1.09, val_accuracy=0.75, lr=0.01]  29%|██▉       | 58/200 [32:16<1:16:50, 32.47s/epoch, loss=0.646, accuracy=0.888, val_loss=1.02, val_accuracy=0.782, lr=0.01] 30%|██▉       | 59/200 [32:48<1:16:13, 32.43s/epoch, loss=0.645, accuracy=0.887, val_loss=1.24, val_accuracy=0.75, lr=0.01]  30%|███       | 60/200 [33:21<1:15:44, 32.46s/epoch, loss=0.643, accuracy=0.889, val_loss=1.5, val_accuracy=0.667, lr=0.01] 30%|███       | 61/200 [33:53<1:15:15, 32.49s/epoch, loss=0.648, accuracy=0.887, val_loss=1.23, val_accuracy=0.733, lr=0.01] 31%|███       | 62/200 [34:25<1:14:32, 32.41s/epoch, loss=0.643, accuracy=0.889, val_loss=0.916, val_accuracy=0.824, lr=0.01] 32%|███▏      | 63/200 [34:58<1:14:01, 32.42s/epoch, loss=0.642, accuracy=0.891, val_loss=1.2, val_accuracy=0.743, lr=0.01]   32%|███▏      | 64/200 [35:31<1:13:48, 32.56s/epoch, loss=0.64, accuracy=0.891, val_loss=0.92, val_accuracy=0.802, lr=0.01] 32%|███▎      | 65/200 [36:03<1:13:08, 32.51s/epoch, loss=0.641, accuracy=0.891, val_loss=1.15, val_accuracy=0.748, lr=0.01] 33%|███▎      | 66/200 [36:36<1:12:39, 32.53s/epoch, loss=0.637, accuracy=0.891, val_loss=0.88, val_accuracy=0.821, lr=0.01] 34%|███▎      | 67/200 [37:08<1:12:09, 32.55s/epoch, loss=0.638, accuracy=0.892, val_loss=0.93, val_accuracy=0.803, lr=0.01] 34%|███▍      | 68/200 [37:41<1:11:32, 32.52s/epoch, loss=0.631, accuracy=0.892, val_loss=1.08, val_accuracy=0.759, lr=0.01] 34%|███▍      | 69/200 [38:13<1:10:58, 32.51s/epoch, loss=0.636, accuracy=0.893, val_loss=0.971, val_accuracy=0.784, lr=0.01] 35%|███▌      | 70/200 [38:45<1:10:18, 32.45s/epoch, loss=0.643, accuracy=0.889, val_loss=0.881, val_accuracy=0.822, lr=0.01] 36%|███▌      | 71/200 [39:18<1:09:40, 32.41s/epoch, loss=0.636, accuracy=0.894, val_loss=1.02, val_accuracy=0.788, lr=0.01]  36%|███▌      | 72/200 [39:50<1:09:05, 32.38s/epoch, loss=0.637, accuracy=0.892, val_loss=1.28, val_accuracy=0.716, lr=0.01] 36%|███▋      | 73/200 [40:22<1:08:21, 32.29s/epoch, loss=0.639, accuracy=0.891, val_loss=1.27, val_accuracy=0.736, lr=0.01] 37%|███▋      | 74/200 [40:54<1:07:50, 32.31s/epoch, loss=0.633, accuracy=0.895, val_loss=0.936, val_accuracy=0.801, lr=0.01] 38%|███▊      | 75/200 [41:27<1:07:07, 32.22s/epoch, loss=0.626, accuracy=0.895, val_loss=0.824, val_accuracy=0.842, lr=0.01] 38%|███▊      | 76/200 [41:59<1:06:39, 32.25s/epoch, loss=0.629, accuracy=0.895, val_loss=0.89, val_accuracy=0.81, lr=0.01]   38%|███▊      | 77/200 [42:31<1:06:11, 32.28s/epoch, loss=0.645, accuracy=0.89, val_loss=0.796, val_accuracy=0.84, lr=0.01] 39%|███▉      | 78/200 [43:04<1:05:45, 32.34s/epoch, loss=0.631, accuracy=0.894, val_loss=1.01, val_accuracy=0.775, lr=0.01] 40%|███▉      | 79/200 [43:36<1:05:10, 32.32s/epoch, loss=0.627, accuracy=0.898, val_loss=1.66, val_accuracy=0.622, lr=0.01] 40%|████      | 80/200 [44:08<1:04:32, 32.27s/epoch, loss=0.627, accuracy=0.897, val_loss=1.08, val_accuracy=0.771, lr=0.01] 40%|████      | 81/200 [44:40<1:03:53, 32.22s/epoch, loss=0.622, accuracy=0.898, val_loss=1.28, val_accuracy=0.729, lr=0.01] 41%|████      | 82/200 [45:13<1:03:29, 32.29s/epoch, loss=0.528, accuracy=0.931, val_loss=0.579, val_accuracy=0.915, lr=0.001] 42%|████▏     | 83/200 [45:45<1:02:55, 32.27s/epoch, loss=0.454, accuracy=0.954, val_loss=0.562, val_accuracy=0.919, lr=0.001] 42%|████▏     | 84/200 [46:17<1:02:13, 32.18s/epoch, loss=0.428, accuracy=0.96, val_loss=0.55, val_accuracy=0.923, lr=0.001]   42%|████▎     | 85/200 [46:49<1:01:33, 32.12s/epoch, loss=0.407, accuracy=0.966, val_loss=0.544, val_accuracy=0.922, lr=0.001] 43%|████▎     | 86/200 [47:21<1:01:02, 32.13s/epoch, loss=0.389, accuracy=0.969, val_loss=0.542, val_accuracy=0.921, lr=0.001] 44%|████▎     | 87/200 [47:53<1:00:24, 32.07s/epoch, loss=0.375, accuracy=0.971, val_loss=0.537, val_accuracy=0.923, lr=0.001] 44%|████▍     | 88/200 [48:25<59:52, 32.07s/epoch, loss=0.36, accuracy=0.974, val_loss=0.533, val_accuracy=0.925, lr=0.001]    44%|████▍     | 89/200 [48:57<59:21, 32.09s/epoch, loss=0.348, accuracy=0.976, val_loss=0.579, val_accuracy=0.911, lr=0.001] 45%|████▌     | 90/200 [49:29<58:45, 32.05s/epoch, loss=0.335, accuracy=0.978, val_loss=0.528, val_accuracy=0.923, lr=0.001] 46%|████▌     | 91/200 [50:01<58:18, 32.09s/epoch, loss=0.327, accuracy=0.979, val_loss=0.551, val_accuracy=0.918, lr=0.001] 46%|████▌     | 92/200 [50:33<57:40, 32.04s/epoch, loss=0.319, accuracy=0.981, val_loss=0.562, val_accuracy=0.911, lr=0.001] 46%|████▋     | 93/200 [51:05<57:07, 32.03s/epoch, loss=0.306, accuracy=0.982, val_loss=0.549, val_accuracy=0.917, lr=0.001] 47%|████▋     | 94/200 [51:37<56:30, 31.98s/epoch, loss=0.301, accuracy=0.981, val_loss=0.531, val_accuracy=0.924, lr=0.001] 48%|████▊     | 95/200 [52:09<56:04, 32.04s/epoch, loss=0.294, accuracy=0.982, val_loss=0.53, val_accuracy=0.922, lr=0.001]  48%|████▊     | 96/200 [52:41<55:30, 32.03s/epoch, loss=0.285, accuracy=0.983, val_loss=0.539, val_accuracy=0.924, lr=0.001] 48%|████▊     | 97/200 [53:13<54:59, 32.03s/epoch, loss=0.28, accuracy=0.984, val_loss=0.598, val_accuracy=0.908, lr=0.001]  49%|████▉     | 98/200 [53:45<54:25, 32.02s/epoch, loss=0.273, accuracy=0.985, val_loss=0.553, val_accuracy=0.916, lr=0.001] 50%|████▉     | 99/200 [54:17<53:52, 32.01s/epoch, loss=0.271, accuracy=0.984, val_loss=0.545, val_accuracy=0.916, lr=0.001] 50%|█████     | 100/200 [54:50<53:30, 32.10s/epoch, loss=0.262, accuracy=0.986, val_loss=0.551, val_accuracy=0.916, lr=0.001] 50%|█████     | 101/200 [55:22<52:56, 32.08s/epoch, loss=0.257, accuracy=0.985, val_loss=0.555, val_accuracy=0.916, lr=0.001] 51%|█████     | 102/200 [55:54<52:33, 32.17s/epoch, loss=0.252, accuracy=0.986, val_loss=0.534, val_accuracy=0.92, lr=0.001]  52%|█████▏    | 103/200 [56:26<51:57, 32.14s/epoch, loss=0.249, accuracy=0.986, val_loss=0.538, val_accuracy=0.916, lr=0.001] 52%|█████▏    | 104/200 [56:58<51:28, 32.17s/epoch, loss=0.244, accuracy=0.986, val_loss=0.603, val_accuracy=0.904, lr=0.001] 52%|█████▎    | 105/200 [57:30<50:56, 32.18s/epoch, loss=0.237, accuracy=0.988, val_loss=0.573, val_accuracy=0.909, lr=0.001] 53%|█████▎    | 106/200 [58:03<50:32, 32.26s/epoch, loss=0.236, accuracy=0.987, val_loss=0.631, val_accuracy=0.9, lr=0.001]   54%|█████▎    | 107/200 [58:35<50:04, 32.30s/epoch, loss=0.234, accuracy=0.986, val_loss=0.537, val_accuracy=0.917, lr=0.001] 54%|█████▍    | 108/200 [59:08<49:28, 32.26s/epoch, loss=0.228, accuracy=0.987, val_loss=0.573, val_accuracy=0.907, lr=0.001] 55%|█████▍    | 109/200 [59:40<48:59, 32.30s/epoch, loss=0.228, accuracy=0.986, val_loss=0.566, val_accuracy=0.913, lr=0.001] 55%|█████▌    | 110/200 [1:00:13<48:38, 32.42s/epoch, loss=0.225, accuracy=0.986, val_loss=0.516, val_accuracy=0.921, lr=0.001] 56%|█████▌    | 111/200 [1:00:45<48:05, 32.43s/epoch, loss=0.222, accuracy=0.987, val_loss=0.557, val_accuracy=0.909, lr=0.001] 56%|█████▌    | 112/200 [1:01:18<47:34, 32.44s/epoch, loss=0.218, accuracy=0.987, val_loss=0.536, val_accuracy=0.912, lr=0.001] 56%|█████▋    | 113/200 [1:01:50<47:01, 32.43s/epoch, loss=0.216, accuracy=0.986, val_loss=0.535, val_accuracy=0.913, lr=0.001] 57%|█████▋    | 114/200 [1:02:22<46:24, 32.38s/epoch, loss=0.212, accuracy=0.987, val_loss=0.596, val_accuracy=0.899, lr=0.001] 57%|█████▊    | 115/200 [1:02:54<45:49, 32.34s/epoch, loss=0.211, accuracy=0.986, val_loss=0.553, val_accuracy=0.909, lr=0.001] 58%|█████▊    | 116/200 [1:03:27<45:13, 32.30s/epoch, loss=0.21, accuracy=0.986, val_loss=0.591, val_accuracy=0.902, lr=0.001]  58%|█████▊    | 117/200 [1:03:59<44:37, 32.26s/epoch, loss=0.211, accuracy=0.985, val_loss=0.561, val_accuracy=0.908, lr=0.001] 59%|█████▉    | 118/200 [1:04:31<44:04, 32.25s/epoch, loss=0.208, accuracy=0.985, val_loss=0.599, val_accuracy=0.9, lr=0.001]   60%|█████▉    | 119/200 [1:05:03<43:29, 32.22s/epoch, loss=0.205, accuracy=0.986, val_loss=0.573, val_accuracy=0.907, lr=0.001] 60%|██████    | 120/200 [1:05:35<42:50, 32.13s/epoch, loss=0.196, accuracy=0.988, val_loss=0.566, val_accuracy=0.901, lr=0.001] 60%|██████    | 121/200 [1:06:07<42:19, 32.15s/epoch, loss=0.197, accuracy=0.987, val_loss=0.571, val_accuracy=0.9, lr=0.001]   61%|██████    | 122/200 [1:06:39<41:43, 32.10s/epoch, loss=0.186, accuracy=0.99, val_loss=0.452, val_accuracy=0.925, lr=1e-04] 62%|██████▏   | 123/200 [1:07:12<41:15, 32.15s/epoch, loss=0.174, accuracy=0.995, val_loss=0.443, val_accuracy=0.929, lr=1e-04] 62%|██████▏   | 124/200 [1:07:44<40:42, 32.14s/epoch, loss=0.171, accuracy=0.996, val_loss=0.445, val_accuracy=0.93, lr=1e-04]  62%|██████▎   | 125/200 [1:08:16<40:12, 32.16s/epoch, loss=0.168, accuracy=0.997, val_loss=0.44, val_accuracy=0.929, lr=1e-04] 63%|██████▎   | 126/200 [1:08:48<39:40, 32.17s/epoch, loss=0.166, accuracy=0.998, val_loss=0.44, val_accuracy=0.929, lr=1e-04] 64%|██████▎   | 127/200 [1:09:20<39:05, 32.13s/epoch, loss=0.165, accuracy=0.998, val_loss=0.445, val_accuracy=0.93, lr=1e-04] 64%|██████▍   | 128/200 [1:09:52<38:33, 32.13s/epoch, loss=0.163, accuracy=0.998, val_loss=0.444, val_accuracy=0.93, lr=1e-04] 64%|██████▍   | 129/200 [1:10:25<38:06, 32.21s/epoch, loss=0.163, accuracy=0.999, val_loss=0.444, val_accuracy=0.93, lr=1e-04] 65%|██████▌   | 130/200 [1:10:57<37:40, 32.29s/epoch, loss=0.162, accuracy=0.999, val_loss=0.445, val_accuracy=0.931, lr=1e-04] 66%|██████▌   | 131/200 [1:11:29<37:08, 32.30s/epoch, loss=0.161, accuracy=0.999, val_loss=0.447, val_accuracy=0.931, lr=1e-04] 66%|██████▌   | 132/200 [1:12:02<36:39, 32.34s/epoch, loss=0.161, accuracy=0.999, val_loss=0.447, val_accuracy=0.931, lr=1e-04] 66%|██████▋   | 133/200 [1:12:34<36:00, 32.25s/epoch, loss=0.159, accuracy=0.999, val_loss=0.448, val_accuracy=0.931, lr=1e-04] 67%|██████▋   | 134/200 [1:13:06<35:30, 32.29s/epoch, loss=0.159, accuracy=0.999, val_loss=0.449, val_accuracy=0.931, lr=1e-04] 68%|██████▊   | 135/200 [1:13:39<35:03, 32.36s/epoch, loss=0.159, accuracy=0.999, val_loss=0.447, val_accuracy=0.932, lr=1e-04] 68%|██████▊   | 136/200 [1:14:11<34:28, 32.32s/epoch, loss=0.159, accuracy=0.999, val_loss=0.449, val_accuracy=0.932, lr=1e-04] 68%|██████▊   | 137/200 [1:14:43<33:50, 32.24s/epoch, loss=0.157, accuracy=0.999, val_loss=0.451, val_accuracy=0.931, lr=1e-04] 69%|██████▉   | 138/200 [1:15:15<33:19, 32.25s/epoch, loss=0.157, accuracy=0.999, val_loss=0.452, val_accuracy=0.932, lr=1e-04] 70%|██████▉   | 139/200 [1:15:47<32:44, 32.20s/epoch, loss=0.157, accuracy=0.999, val_loss=0.454, val_accuracy=0.932, lr=1e-04] 70%|███████   | 140/200 [1:16:20<32:10, 32.18s/epoch, loss=0.156, accuracy=0.999, val_loss=0.453, val_accuracy=0.931, lr=1e-04] 70%|███████   | 141/200 [1:16:52<31:36, 32.14s/epoch, loss=0.156, accuracy=0.999, val_loss=0.456, val_accuracy=0.932, lr=1e-04] 71%|███████   | 142/200 [1:17:24<31:04, 32.15s/epoch, loss=0.155, accuracy=0.999, val_loss=0.454, val_accuracy=0.932, lr=1e-04] 72%|███████▏  | 143/200 [1:17:56<30:33, 32.16s/epoch, loss=0.154, accuracy=0.999, val_loss=0.455, val_accuracy=0.932, lr=1e-04] 72%|███████▏  | 144/200 [1:18:28<29:58, 32.11s/epoch, loss=0.154, accuracy=0.999, val_loss=0.456, val_accuracy=0.932, lr=1e-04] 72%|███████▎  | 145/200 [1:19:00<29:27, 32.14s/epoch, loss=0.154, accuracy=0.999, val_loss=0.46, val_accuracy=0.933, lr=1e-04]  73%|███████▎  | 146/200 [1:19:32<28:53, 32.11s/epoch, loss=0.153, accuracy=0.999, val_loss=0.46, val_accuracy=0.933, lr=1e-04] 74%|███████▎  | 147/200 [1:20:04<28:22, 32.11s/epoch, loss=0.153, accuracy=0.999, val_loss=0.463, val_accuracy=0.933, lr=1e-04] 74%|███████▍  | 148/200 [1:20:37<27:51, 32.14s/epoch, loss=0.152, accuracy=0.999, val_loss=0.463, val_accuracy=0.932, lr=1e-04] 74%|███████▍  | 149/200 [1:21:09<27:18, 32.12s/epoch, loss=0.152, accuracy=0.999, val_loss=0.46, val_accuracy=0.933, lr=1e-04]  75%|███████▌  | 150/200 [1:21:41<26:44, 32.08s/epoch, loss=0.151, accuracy=0.999, val_loss=0.462, val_accuracy=0.933, lr=1e-04] 76%|███████▌  | 151/200 [1:22:13<26:15, 32.14s/epoch, loss=0.151, accuracy=1, val_loss=0.463, val_accuracy=0.932, lr=1e-04]     76%|███████▌  | 152/200 [1:22:45<25:42, 32.13s/epoch, loss=0.15, accuracy=0.999, val_loss=0.462, val_accuracy=0.933, lr=1e-04] 76%|███████▋  | 153/200 [1:23:17<25:10, 32.14s/epoch, loss=0.15, accuracy=0.999, val_loss=0.464, val_accuracy=0.933, lr=1e-04] 77%|███████▋  | 154/200 [1:23:49<24:38, 32.14s/epoch, loss=0.149, accuracy=0.999, val_loss=0.464, val_accuracy=0.933, lr=1e-04] 78%|███████▊  | 155/200 [1:24:22<24:12, 32.27s/epoch, loss=0.149, accuracy=0.999, val_loss=0.465, val_accuracy=0.932, lr=1e-04] 78%|███████▊  | 156/200 [1:24:54<23:39, 32.25s/epoch, loss=0.149, accuracy=0.999, val_loss=0.465, val_accuracy=0.932, lr=1e-04] 78%|███████▊  | 157/200 [1:25:27<23:10, 32.35s/epoch, loss=0.148, accuracy=0.999, val_loss=0.463, val_accuracy=0.933, lr=1e-04] 79%|███████▉  | 158/200 [1:25:59<22:38, 32.35s/epoch, loss=0.148, accuracy=0.999, val_loss=0.461, val_accuracy=0.934, lr=1e-04] 80%|███████▉  | 159/200 [1:26:31<22:06, 32.35s/epoch, loss=0.147, accuracy=1, val_loss=0.463, val_accuracy=0.932, lr=1e-04]     80%|████████  | 160/200 [1:27:04<21:31, 32.30s/epoch, loss=0.147, accuracy=0.999, val_loss=0.465, val_accuracy=0.933, lr=1e-04] 80%|████████  | 161/200 [1:27:36<20:57, 32.26s/epoch, loss=0.147, accuracy=1, val_loss=0.462, val_accuracy=0.933, lr=1e-04]     81%|████████  | 162/200 [1:28:08<20:28, 32.33s/epoch, loss=0.146, accuracy=1, val_loss=0.463, val_accuracy=0.933, lr=1e-5]  82%|████████▏ | 163/200 [1:28:40<19:54, 32.30s/epoch, loss=0.146, accuracy=1, val_loss=0.463, val_accuracy=0.933, lr=1e-5] 82%|████████▏ | 164/200 [1:29:13<19:23, 32.33s/epoch, loss=0.146, accuracy=1, val_loss=0.463, val_accuracy=0.933, lr=1e-5] 82%|████████▎ | 165/200 [1:29:45<18:50, 32.31s/epoch, loss=0.146, accuracy=1, val_loss=0.463, val_accuracy=0.933, lr=1e-5] 83%|████████▎ | 166/200 [1:30:17<18:15, 32.23s/epoch, loss=0.146, accuracy=1, val_loss=0.463, val_accuracy=0.933, lr=1e-5] 84%|████████▎ | 167/200 [1:30:49<17:39, 32.12s/epoch, loss=0.146, accuracy=1, val_loss=0.463, val_accuracy=0.933, lr=1e-5] 84%|████████▍ | 168/200 [1:31:21<17:06, 32.08s/epoch, loss=0.146, accuracy=1, val_loss=0.463, val_accuracy=0.933, lr=1e-5] 84%|████████▍ | 169/200 [1:31:53<16:32, 32.00s/epoch, loss=0.146, accuracy=1, val_loss=0.462, val_accuracy=0.934, lr=1e-5] 85%|████████▌ | 170/200 [1:32:25<16:00, 32.03s/epoch, loss=0.146, accuracy=1, val_loss=0.463, val_accuracy=0.933, lr=1e-5] 86%|████████▌ | 171/200 [1:32:57<15:28, 32.02s/epoch, loss=0.146, accuracy=1, val_loss=0.463, val_accuracy=0.934, lr=1e-5] 86%|████████▌ | 172/200 [1:33:29<15:00, 32.15s/epoch, loss=0.146, accuracy=1, val_loss=0.463, val_accuracy=0.933, lr=1e-5] 86%|████████▋ | 173/200 [1:34:02<14:29, 32.19s/epoch, loss=0.146, accuracy=1, val_loss=0.463, val_accuracy=0.933, lr=1e-5] 87%|████████▋ | 174/200 [1:34:34<13:56, 32.17s/epoch, loss=0.146, accuracy=0.999, val_loss=0.463, val_accuracy=0.933, lr=1e-5] 88%|████████▊ | 175/200 [1:35:06<13:23, 32.14s/epoch, loss=0.146, accuracy=1, val_loss=0.463, val_accuracy=0.933, lr=1e-5]     88%|████████▊ | 176/200 [1:35:38<12:52, 32.18s/epoch, loss=0.145, accuracy=1, val_loss=0.463, val_accuracy=0.933, lr=1e-5] 88%|████████▊ | 177/200 [1:36:10<12:20, 32.19s/epoch, loss=0.145, accuracy=1, val_loss=0.463, val_accuracy=0.934, lr=1e-5] 89%|████████▉ | 178/200 [1:36:43<11:48, 32.22s/epoch, loss=0.145, accuracy=1, val_loss=0.463, val_accuracy=0.934, lr=1e-5] 90%|████████▉ | 179/200 [1:37:15<11:14, 32.14s/epoch, loss=0.145, accuracy=0.999, val_loss=0.463, val_accuracy=0.934, lr=1e-5] 90%|█████████ | 180/200 [1:37:47<10:41, 32.10s/epoch, loss=0.145, accuracy=1, val_loss=0.464, val_accuracy=0.934, lr=1e-5]     90%|█████████ | 181/200 [1:38:19<10:09, 32.05s/epoch, loss=0.145, accuracy=1, val_loss=0.464, val_accuracy=0.934, lr=1e-5] 91%|█████████ | 182/200 [1:38:51<09:37, 32.08s/epoch, loss=0.145, accuracy=1, val_loss=0.464, val_accuracy=0.934, lr=5e-6] 92%|█████████▏| 183/200 [1:39:23<09:05, 32.12s/epoch, loss=0.145, accuracy=1, val_loss=0.464, val_accuracy=0.934, lr=5e-6] 92%|█████████▏| 184/200 [1:39:55<08:33, 32.12s/epoch, loss=0.145, accuracy=1, val_loss=0.464, val_accuracy=0.934, lr=5e-6] 92%|█████████▎| 185/200 [1:40:27<08:02, 32.17s/epoch, loss=0.145, accuracy=1, val_loss=0.463, val_accuracy=0.934, lr=5e-6] 93%|█████████▎| 186/200 [1:40:59<07:29, 32.11s/epoch, loss=0.145, accuracy=1, val_loss=0.464, val_accuracy=0.934, lr=5e-6] 94%|█████████▎| 187/200 [1:41:31<06:56, 32.04s/epoch, loss=0.145, accuracy=1, val_loss=0.463, val_accuracy=0.934, lr=5e-6] 94%|█████████▍| 188/200 [1:42:03<06:24, 32.05s/epoch, loss=0.145, accuracy=1, val_loss=0.464, val_accuracy=0.934, lr=5e-6] 94%|█████████▍| 189/200 [1:42:35<05:52, 32.05s/epoch, loss=0.145, accuracy=1, val_loss=0.464, val_accuracy=0.933, lr=5e-6] 95%|█████████▌| 190/200 [1:43:07<05:20, 32.08s/epoch, loss=0.145, accuracy=1, val_loss=0.464, val_accuracy=0.934, lr=5e-6] 96%|█████████▌| 191/200 [1:43:40<04:48, 32.09s/epoch, loss=0.145, accuracy=1, val_loss=0.464, val_accuracy=0.933, lr=5e-6] 96%|█████████▌| 192/200 [1:44:12<04:17, 32.18s/epoch, loss=0.145, accuracy=1, val_loss=0.464, val_accuracy=0.933, lr=5e-6] 96%|█████████▋| 193/200 [1:44:44<03:45, 32.15s/epoch, loss=0.145, accuracy=1, val_loss=0.464, val_accuracy=0.934, lr=5e-6] 97%|█████████▋| 194/200 [1:45:17<03:13, 32.27s/epoch, loss=0.145, accuracy=1, val_loss=0.464, val_accuracy=0.933, lr=5e-6] 98%|█████████▊| 195/200 [1:45:49<02:41, 32.34s/epoch, loss=0.145, accuracy=1, val_loss=0.464, val_accuracy=0.933, lr=5e-6] 98%|█████████▊| 196/200 [1:46:21<02:09, 32.29s/epoch, loss=0.145, accuracy=1, val_loss=0.464, val_accuracy=0.933, lr=5e-6] 98%|█████████▊| 197/200 [1:46:53<01:36, 32.23s/epoch, loss=0.145, accuracy=1, val_loss=0.465, val_accuracy=0.933, lr=5e-6] 99%|█████████▉| 198/200 [1:47:25<01:04, 32.13s/epoch, loss=0.145, accuracy=1, val_loss=0.464, val_accuracy=0.933, lr=5e-6]100%|█████████▉| 199/200 [1:47:58<00:32, 32.24s/epoch, loss=0.145, accuracy=1, val_loss=0.464, val_accuracy=0.933, lr=5e-6]100%|██████████| 200/200 [1:48:30<00:00, 32.27s/epoch, loss=0.145, accuracy=1, val_loss=0.464, val_accuracy=0.933, lr=5e-6]100%|██████████| 200/200 [1:48:30<00:00, 32.55s/epoch, loss=0.145, accuracy=1, val_loss=0.464, val_accuracy=0.933, lr=5e-6]
Using real-time data augmentation.
Only one model saved

Loading model: 30_cifar10_ResNet110v1.h5
Test score: 0.4817695915699005
Test accuracy: 0.9291999936103821
Val score: 0.46420609951019287
Val accuracy: 0.9330999851226807


* * * Run Prediction for ensemble = 30. * * *


2024-03-17 01:12:44.280240: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
Traceback (most recent call last):
  File "/home/gkb738/.conda/envs/TF_KERAS_GPU/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/gkb738/.conda/envs/TF_KERAS_GPU/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/gkb738/MSc-Thesis/ensemble_prediction.py", line 14, in <module>
    from MajorityVoteBounds.NeurIPS2020.optimize import optimize
ModuleNotFoundError: No module named 'MajorityVoteBounds'
