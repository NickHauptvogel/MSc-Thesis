Tue Mar 12 21:27:30 2024       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 545.23.08              Driver Version: 545.23.08    CUDA Version: 12.3     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA TITAN Xp                Off | 00000000:3B:00.0 Off |                  N/A |
| 48%   64C    P8              12W / 250W |      0MiB / 12288MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|  No running processes found                                                           |
+---------------------------------------------------------------------------------------+


* * * Run SGD for cluster size = 9. * * *


Budget: 166


* * * Run SGD for ID = 9_1. * * *


2024-03-12 21:27:36.517368: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-12 21:27:55.033699: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-12 21:27:55.034703: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-12 21:27:55.079510: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:3b:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-12 21:27:55.079546: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-12 21:27:55.147342: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-12 21:27:55.147407: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-12 21:27:55.185821: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-12 21:27:55.254470: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-12 21:27:55.316515: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-12 21:27:55.355080: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-12 21:27:55.446105: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-12 21:27:55.447237: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-12 21:27:55.447323: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-12 21:27:56.990381: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-12 21:27:56.991417: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-12 21:27:56.998353: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:3b:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-12 21:27:56.998404: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-12 21:27:56.998452: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-12 21:27:56.998467: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-12 21:27:56.998482: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-12 21:27:56.998496: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-12 21:27:56.998511: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-12 21:27:56.998525: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-12 21:27:56.998539: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-12 21:27:57.000458: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-12 21:27:57.000506: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-12 21:27:58.442581: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-12 21:27:58.442634: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-12 21:27:58.442643: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-12 21:27:58.443640: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:3b:00.0, compute capability: 6.1)
{'id': '09_01', 'seed': 1, 'out_folder': 'results/epoch_budget_2', 'batch_size': 128, 'epochs': 166, 'validation_split': 0.0, 'checkpointing': False, 'checkpoint_every': -1, 'hold_out_validation_split': 0.0, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'bootstrapping': False, 'num_classes': 10, 'SSE_lr': False, 'test_time_augmentation': False, 'debug': False, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
y_train shape: (50000, 10)
x_val shape: (10000, 32, 32, 3)
y_val shape: (10000, 10)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/166 [00:00<?, ?epoch/s]2024-03-12 21:27:59.048287: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-12 21:27:59.048761: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2100000000 Hz
2024-03-12 21:28:00.958165: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-12 21:28:01.266468: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-12 21:28:02.602306: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-12 21:28:02.663552: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/166 [01:01<2:49:29, 61.63s/epoch, loss=3.25, accuracy=0.284, val_loss=2.22, val_accuracy=0.265, lr=0.1]  1%|          | 2/166 [01:27<1:50:57, 40.59s/epoch, loss=1.68, accuracy=0.467, val_loss=2.66, val_accuracy=0.26, lr=0.1]   2%|▏         | 3/166 [01:52<1:31:27, 33.67s/epoch, loss=1.47, accuracy=0.57, val_loss=2.41, val_accuracy=0.382, lr=0.1]  2%|▏         | 4/166 [02:18<1:22:14, 30.46s/epoch, loss=1.34, accuracy=0.648, val_loss=2.03, val_accuracy=0.475, lr=0.1]  3%|▎         | 5/166 [02:43<1:16:57, 28.68s/epoch, loss=1.26, accuracy=0.688, val_loss=2.13, val_accuracy=0.418, lr=0.1]  4%|▎         | 6/166 [03:09<1:13:49, 27.68s/epoch, loss=1.24, accuracy=0.703, val_loss=2.12, val_accuracy=0.409, lr=0.1]  4%|▍         | 7/166 [03:35<1:11:30, 26.99s/epoch, loss=1.23, accuracy=0.714, val_loss=1.9, val_accuracy=0.521, lr=0.1]   5%|▍         | 8/166 [04:00<1:09:51, 26.53s/epoch, loss=1.22, accuracy=0.722, val_loss=2.22, val_accuracy=0.454, lr=0.1]  5%|▌         | 9/166 [04:26<1:08:41, 26.25s/epoch, loss=1.21, accuracy=0.726, val_loss=3.88, val_accuracy=0.273, lr=0.1]  6%|▌         | 10/166 [04:51<1:07:37, 26.01s/epoch, loss=1.2, accuracy=0.729, val_loss=1.53, val_accuracy=0.612, lr=0.1]  7%|▋         | 11/166 [05:17<1:06:46, 25.85s/epoch, loss=1.21, accuracy=0.732, val_loss=1.76, val_accuracy=0.544, lr=0.1]  7%|▋         | 12/166 [05:42<1:06:03, 25.74s/epoch, loss=1.19, accuracy=0.735, val_loss=2.22, val_accuracy=0.486, lr=0.1]  8%|▊         | 13/166 [06:08<1:05:29, 25.69s/epoch, loss=1.19, accuracy=0.737, val_loss=1.65, val_accuracy=0.596, lr=0.1]  8%|▊         | 14/166 [06:34<1:05:03, 25.68s/epoch, loss=1.19, accuracy=0.738, val_loss=2.29, val_accuracy=0.391, lr=0.1]  9%|▉         | 15/166 [06:59<1:04:41, 25.70s/epoch, loss=1.18, accuracy=0.74, val_loss=2.39, val_accuracy=0.479, lr=0.1]  10%|▉         | 16/166 [07:25<1:04:11, 25.68s/epoch, loss=1.18, accuracy=0.74, val_loss=3.11, val_accuracy=0.28, lr=0.1]  10%|█         | 17/166 [07:51<1:03:48, 25.70s/epoch, loss=1.18, accuracy=0.741, val_loss=2.16, val_accuracy=0.536, lr=0.1] 11%|█         | 18/166 [08:16<1:03:15, 25.65s/epoch, loss=1.17, accuracy=0.743, val_loss=2.01, val_accuracy=0.49, lr=0.1]  11%|█▏        | 19/166 [08:42<1:03:00, 25.72s/epoch, loss=1.17, accuracy=0.744, val_loss=2.72, val_accuracy=0.344, lr=0.1] 12%|█▏        | 20/166 [09:08<1:02:32, 25.70s/epoch, loss=1.16, accuracy=0.746, val_loss=2.53, val_accuracy=0.417, lr=0.1] 13%|█▎        | 21/166 [09:34<1:02:10, 25.73s/epoch, loss=1.17, accuracy=0.744, val_loss=2.26, val_accuracy=0.488, lr=0.1] 13%|█▎        | 22/166 [09:59<1:01:43, 25.72s/epoch, loss=1.16, accuracy=0.745, val_loss=2, val_accuracy=0.546, lr=0.1]    14%|█▍        | 23/166 [10:25<1:01:15, 25.71s/epoch, loss=1.17, accuracy=0.747, val_loss=4.78, val_accuracy=0.301, lr=0.1] 14%|█▍        | 24/166 [10:51<1:00:49, 25.70s/epoch, loss=1.17, accuracy=0.747, val_loss=1.7, val_accuracy=0.594, lr=0.1]  15%|█▌        | 25/166 [11:17<1:00:29, 25.74s/epoch, loss=1.16, accuracy=0.747, val_loss=1.92, val_accuracy=0.51, lr=0.1] 16%|█▌        | 26/166 [11:42<59:55, 25.68s/epoch, loss=1.16, accuracy=0.747, val_loss=1.87, val_accuracy=0.54, lr=0.1]   16%|█▋        | 27/166 [12:08<59:37, 25.74s/epoch, loss=1.16, accuracy=0.747, val_loss=1.74, val_accuracy=0.552, lr=0.1] 17%|█▋        | 28/166 [12:34<59:14, 25.76s/epoch, loss=1.15, accuracy=0.751, val_loss=2.02, val_accuracy=0.46, lr=0.1]  17%|█▋        | 29/166 [13:00<59:01, 25.85s/epoch, loss=1.17, accuracy=0.748, val_loss=3.99, val_accuracy=0.287, lr=0.1] 18%|█▊        | 30/166 [13:26<58:33, 25.83s/epoch, loss=1.15, accuracy=0.752, val_loss=1.67, val_accuracy=0.594, lr=0.1] 19%|█▊        | 31/166 [13:51<57:54, 25.74s/epoch, loss=1.15, accuracy=0.752, val_loss=1.88, val_accuracy=0.543, lr=0.1] 19%|█▉        | 32/166 [14:17<57:29, 25.74s/epoch, loss=1.15, accuracy=0.751, val_loss=1.62, val_accuracy=0.591, lr=0.1] 20%|█▉        | 33/166 [14:43<57:04, 25.75s/epoch, loss=1.15, accuracy=0.75, val_loss=1.87, val_accuracy=0.504, lr=0.1]  20%|██        | 34/166 [15:08<56:29, 25.68s/epoch, loss=1.14, accuracy=0.753, val_loss=2.57, val_accuracy=0.394, lr=0.1] 21%|██        | 35/166 [15:34<56:04, 25.68s/epoch, loss=1.14, accuracy=0.753, val_loss=4.02, val_accuracy=0.213, lr=0.1] 22%|██▏       | 36/166 [15:59<55:35, 25.66s/epoch, loss=1.15, accuracy=0.751, val_loss=1.75, val_accuracy=0.568, lr=0.1] 22%|██▏       | 37/166 [16:25<55:05, 25.62s/epoch, loss=1.14, accuracy=0.752, val_loss=3.74, val_accuracy=0.291, lr=0.1] 23%|██▎       | 38/166 [16:51<54:38, 25.61s/epoch, loss=1.14, accuracy=0.753, val_loss=2.16, val_accuracy=0.493, lr=0.1] 23%|██▎       | 39/166 [17:16<54:11, 25.60s/epoch, loss=1.15, accuracy=0.75, val_loss=1.74, val_accuracy=0.609, lr=0.1]  24%|██▍       | 40/166 [17:42<53:40, 25.56s/epoch, loss=1.14, accuracy=0.756, val_loss=1.74, val_accuracy=0.556, lr=0.1] 25%|██▍       | 41/166 [18:07<53:16, 25.57s/epoch, loss=1.15, accuracy=0.752, val_loss=1.88, val_accuracy=0.516, lr=0.1] 25%|██▌       | 42/166 [18:33<52:54, 25.60s/epoch, loss=1.14, accuracy=0.754, val_loss=2.34, val_accuracy=0.386, lr=0.1] 26%|██▌       | 43/166 [18:59<52:32, 25.63s/epoch, loss=1.14, accuracy=0.752, val_loss=1.53, val_accuracy=0.622, lr=0.1] 27%|██▋       | 44/166 [19:24<52:08, 25.64s/epoch, loss=1.14, accuracy=0.752, val_loss=4.61, val_accuracy=0.262, lr=0.1] 27%|██▋       | 45/166 [19:50<51:52, 25.73s/epoch, loss=1.14, accuracy=0.753, val_loss=1.64, val_accuracy=0.609, lr=0.1] 28%|██▊       | 46/166 [20:16<51:28, 25.73s/epoch, loss=1.14, accuracy=0.756, val_loss=3.74, val_accuracy=0.246, lr=0.1] 28%|██▊       | 47/166 [20:42<51:03, 25.74s/epoch, loss=1.14, accuracy=0.753, val_loss=3.1, val_accuracy=0.318, lr=0.1]  29%|██▉       | 48/166 [21:07<50:38, 25.75s/epoch, loss=1.14, accuracy=0.752, val_loss=3.26, val_accuracy=0.259, lr=0.1] 30%|██▉       | 49/166 [21:33<50:13, 25.76s/epoch, loss=1.13, accuracy=0.754, val_loss=2.62, val_accuracy=0.452, lr=0.1] 30%|███       | 50/166 [21:59<49:43, 25.72s/epoch, loss=1.13, accuracy=0.755, val_loss=1.88, val_accuracy=0.53, lr=0.1]  31%|███       | 51/166 [22:25<49:19, 25.73s/epoch, loss=1.13, accuracy=0.756, val_loss=2.65, val_accuracy=0.419, lr=0.1] 31%|███▏      | 52/166 [22:50<48:49, 25.70s/epoch, loss=1.14, accuracy=0.756, val_loss=2.02, val_accuracy=0.46, lr=0.1]  32%|███▏      | 53/166 [23:16<48:23, 25.69s/epoch, loss=1.13, accuracy=0.755, val_loss=2.95, val_accuracy=0.385, lr=0.1] 33%|███▎      | 54/166 [23:42<48:03, 25.74s/epoch, loss=1.13, accuracy=0.756, val_loss=4.17, val_accuracy=0.266, lr=0.1] 33%|███▎      | 55/166 [24:08<47:45, 25.81s/epoch, loss=1.14, accuracy=0.758, val_loss=1.82, val_accuracy=0.526, lr=0.1] 34%|███▎      | 56/166 [24:34<47:18, 25.81s/epoch, loss=1.14, accuracy=0.754, val_loss=3.09, val_accuracy=0.359, lr=0.1] 34%|███▍      | 57/166 [24:59<46:48, 25.76s/epoch, loss=1.13, accuracy=0.758, val_loss=1.65, val_accuracy=0.573, lr=0.1] 35%|███▍      | 58/166 [25:25<46:28, 25.82s/epoch, loss=1.13, accuracy=0.757, val_loss=2.22, val_accuracy=0.41, lr=0.1]  36%|███▌      | 59/166 [25:51<46:01, 25.81s/epoch, loss=1.13, accuracy=0.755, val_loss=3.1, val_accuracy=0.34, lr=0.1]  36%|███▌      | 60/166 [26:17<45:35, 25.81s/epoch, loss=1.13, accuracy=0.757, val_loss=2.43, val_accuracy=0.374, lr=0.1] 37%|███▋      | 61/166 [26:43<45:11, 25.83s/epoch, loss=1.14, accuracy=0.755, val_loss=1.91, val_accuracy=0.536, lr=0.1] 37%|███▋      | 62/166 [27:08<44:41, 25.79s/epoch, loss=1.13, accuracy=0.753, val_loss=3.29, val_accuracy=0.253, lr=0.1] 38%|███▊      | 63/166 [27:34<44:15, 25.79s/epoch, loss=1.14, accuracy=0.754, val_loss=2.1, val_accuracy=0.535, lr=0.1]  39%|███▊      | 64/166 [28:00<43:54, 25.82s/epoch, loss=1.13, accuracy=0.755, val_loss=1.62, val_accuracy=0.601, lr=0.1] 39%|███▉      | 65/166 [28:26<43:27, 25.82s/epoch, loss=1.13, accuracy=0.757, val_loss=1.93, val_accuracy=0.543, lr=0.1] 40%|███▉      | 66/166 [28:51<42:55, 25.76s/epoch, loss=1.13, accuracy=0.753, val_loss=1.51, val_accuracy=0.644, lr=0.1] 40%|████      | 67/166 [29:17<42:22, 25.69s/epoch, loss=1.13, accuracy=0.757, val_loss=1.82, val_accuracy=0.533, lr=0.1] 41%|████      | 68/166 [29:43<41:59, 25.71s/epoch, loss=0.907, accuracy=0.817, val_loss=0.947, val_accuracy=0.785, lr=0.01] 42%|████▏     | 69/166 [30:08<41:29, 25.67s/epoch, loss=0.731, accuracy=0.85, val_loss=0.757, val_accuracy=0.83, lr=0.01]   42%|████▏     | 70/166 [30:34<41:00, 25.63s/epoch, loss=0.652, accuracy=0.857, val_loss=0.747, val_accuracy=0.822, lr=0.01] 43%|████▎     | 71/166 [30:59<40:32, 25.61s/epoch, loss=0.604, accuracy=0.862, val_loss=0.803, val_accuracy=0.792, lr=0.01] 43%|████▎     | 72/166 [31:25<40:03, 25.57s/epoch, loss=0.585, accuracy=0.862, val_loss=0.811, val_accuracy=0.796, lr=0.01] 44%|████▍     | 73/166 [31:50<39:37, 25.57s/epoch, loss=0.573, accuracy=0.862, val_loss=0.888, val_accuracy=0.768, lr=0.01] 45%|████▍     | 74/166 [32:16<39:15, 25.61s/epoch, loss=0.57, accuracy=0.866, val_loss=0.745, val_accuracy=0.813, lr=0.01]  45%|████▌     | 75/166 [32:42<38:59, 25.71s/epoch, loss=0.561, accuracy=0.869, val_loss=0.74, val_accuracy=0.806, lr=0.01] 46%|████▌     | 76/166 [33:08<38:37, 25.75s/epoch, loss=0.563, accuracy=0.866, val_loss=0.726, val_accuracy=0.817, lr=0.01] 46%|████▋     | 77/166 [33:34<38:15, 25.80s/epoch, loss=0.559, accuracy=0.87, val_loss=0.996, val_accuracy=0.718, lr=0.01]  47%|████▋     | 78/166 [34:00<37:53, 25.84s/epoch, loss=0.56, accuracy=0.871, val_loss=0.806, val_accuracy=0.797, lr=0.01] 48%|████▊     | 79/166 [34:25<37:24, 25.80s/epoch, loss=0.558, accuracy=0.873, val_loss=1.22, val_accuracy=0.693, lr=0.01] 48%|████▊     | 80/166 [34:51<36:57, 25.79s/epoch, loss=0.558, accuracy=0.873, val_loss=0.871, val_accuracy=0.785, lr=0.01] 49%|████▉     | 81/166 [35:17<36:32, 25.80s/epoch, loss=0.553, accuracy=0.876, val_loss=0.832, val_accuracy=0.789, lr=0.01] 49%|████▉     | 82/166 [35:43<36:05, 25.78s/epoch, loss=0.556, accuracy=0.877, val_loss=0.801, val_accuracy=0.794, lr=0.01] 50%|█████     | 83/166 [36:08<35:36, 25.74s/epoch, loss=0.556, accuracy=0.876, val_loss=1.02, val_accuracy=0.732, lr=0.01]  51%|█████     | 84/166 [36:34<35:13, 25.78s/epoch, loss=0.554, accuracy=0.877, val_loss=0.758, val_accuracy=0.817, lr=0.01] 51%|█████     | 85/166 [37:00<34:44, 25.74s/epoch, loss=0.556, accuracy=0.877, val_loss=0.707, val_accuracy=0.829, lr=0.01] 52%|█████▏    | 86/166 [37:26<34:17, 25.72s/epoch, loss=0.552, accuracy=0.878, val_loss=0.978, val_accuracy=0.747, lr=0.01] 52%|█████▏    | 87/166 [37:51<33:51, 25.71s/epoch, loss=0.556, accuracy=0.878, val_loss=0.887, val_accuracy=0.773, lr=0.01] 53%|█████▎    | 88/166 [38:17<33:22, 25.67s/epoch, loss=0.554, accuracy=0.881, val_loss=1.06, val_accuracy=0.742, lr=0.01]  54%|█████▎    | 89/166 [38:43<32:57, 25.69s/epoch, loss=0.553, accuracy=0.882, val_loss=0.798, val_accuracy=0.805, lr=0.01] 54%|█████▍    | 90/166 [39:08<32:31, 25.68s/epoch, loss=0.555, accuracy=0.882, val_loss=0.808, val_accuracy=0.796, lr=0.01] 55%|█████▍    | 91/166 [39:34<31:57, 25.57s/epoch, loss=0.552, accuracy=0.882, val_loss=0.837, val_accuracy=0.79, lr=0.01]  55%|█████▌    | 92/166 [39:59<31:35, 25.62s/epoch, loss=0.554, accuracy=0.884, val_loss=0.992, val_accuracy=0.762, lr=0.01] 56%|█████▌    | 93/166 [40:25<31:03, 25.53s/epoch, loss=0.549, accuracy=0.884, val_loss=0.862, val_accuracy=0.78, lr=0.01]  57%|█████▋    | 94/166 [40:50<30:38, 25.54s/epoch, loss=0.554, accuracy=0.884, val_loss=0.841, val_accuracy=0.793, lr=0.01] 57%|█████▋    | 95/166 [41:16<30:18, 25.61s/epoch, loss=0.552, accuracy=0.882, val_loss=0.949, val_accuracy=0.751, lr=0.01] 58%|█████▊    | 96/166 [41:42<29:55, 25.66s/epoch, loss=0.553, accuracy=0.884, val_loss=0.681, val_accuracy=0.842, lr=0.01] 58%|█████▊    | 97/166 [42:07<29:31, 25.68s/epoch, loss=0.551, accuracy=0.884, val_loss=0.77, val_accuracy=0.815, lr=0.01]  59%|█████▉    | 98/166 [42:33<29:09, 25.72s/epoch, loss=0.551, accuracy=0.886, val_loss=1.04, val_accuracy=0.742, lr=0.01] 60%|█████▉    | 99/166 [42:59<28:46, 25.77s/epoch, loss=0.552, accuracy=0.885, val_loss=0.938, val_accuracy=0.781, lr=0.01] 60%|██████    | 100/166 [43:25<28:15, 25.70s/epoch, loss=0.551, accuracy=0.884, val_loss=0.791, val_accuracy=0.808, lr=0.01] 61%|██████    | 101/166 [43:51<27:53, 25.75s/epoch, loss=0.472, accuracy=0.915, val_loss=0.537, val_accuracy=0.89, lr=0.001] 61%|██████▏   | 102/166 [44:16<27:29, 25.77s/epoch, loss=0.423, accuracy=0.928, val_loss=0.514, val_accuracy=0.895, lr=0.001] 62%|██████▏   | 103/166 [44:42<27:04, 25.79s/epoch, loss=0.397, accuracy=0.936, val_loss=0.511, val_accuracy=0.894, lr=0.001] 63%|██████▎   | 104/166 [45:08<26:38, 25.78s/epoch, loss=0.386, accuracy=0.938, val_loss=0.504, val_accuracy=0.899, lr=0.001] 63%|██████▎   | 105/166 [45:34<26:11, 25.77s/epoch, loss=0.369, accuracy=0.942, val_loss=0.492, val_accuracy=0.901, lr=0.001] 64%|██████▍   | 106/166 [46:00<25:48, 25.81s/epoch, loss=0.356, accuracy=0.945, val_loss=0.49, val_accuracy=0.897, lr=0.001]  64%|██████▍   | 107/166 [46:26<25:25, 25.86s/epoch, loss=0.347, accuracy=0.946, val_loss=0.475, val_accuracy=0.903, lr=0.001] 65%|██████▌   | 108/166 [46:51<24:58, 25.84s/epoch, loss=0.335, accuracy=0.948, val_loss=0.492, val_accuracy=0.895, lr=0.001] 66%|██████▌   | 109/166 [47:17<24:29, 25.78s/epoch, loss=0.325, accuracy=0.951, val_loss=0.479, val_accuracy=0.899, lr=0.001] 66%|██████▋   | 110/166 [47:43<24:00, 25.72s/epoch, loss=0.317, accuracy=0.95, val_loss=0.471, val_accuracy=0.902, lr=0.001]  67%|██████▋   | 111/166 [48:08<23:33, 25.70s/epoch, loss=0.311, accuracy=0.951, val_loss=0.458, val_accuracy=0.903, lr=0.001] 67%|██████▋   | 112/166 [48:34<23:06, 25.68s/epoch, loss=0.301, accuracy=0.952, val_loss=0.47, val_accuracy=0.9, lr=0.001]    68%|██████▊   | 113/166 [49:00<22:40, 25.67s/epoch, loss=0.292, accuracy=0.956, val_loss=0.462, val_accuracy=0.9, lr=0.001] 69%|██████▊   | 114/166 [49:25<22:13, 25.64s/epoch, loss=0.289, accuracy=0.955, val_loss=0.473, val_accuracy=0.898, lr=0.001] 69%|██████▉   | 115/166 [49:51<21:46, 25.62s/epoch, loss=0.28, accuracy=0.957, val_loss=0.462, val_accuracy=0.899, lr=0.001]  70%|██████▉   | 116/166 [50:16<21:22, 25.65s/epoch, loss=0.277, accuracy=0.957, val_loss=0.506, val_accuracy=0.888, lr=0.001] 70%|███████   | 117/166 [50:42<20:53, 25.59s/epoch, loss=0.27, accuracy=0.958, val_loss=0.475, val_accuracy=0.896, lr=0.001]  71%|███████   | 118/166 [51:07<20:27, 25.57s/epoch, loss=0.269, accuracy=0.957, val_loss=0.475, val_accuracy=0.892, lr=0.001] 72%|███████▏  | 119/166 [51:33<20:05, 25.64s/epoch, loss=0.259, accuracy=0.959, val_loss=0.454, val_accuracy=0.899, lr=0.001] 72%|███████▏  | 120/166 [51:59<19:39, 25.64s/epoch, loss=0.255, accuracy=0.959, val_loss=0.458, val_accuracy=0.9, lr=0.001]   73%|███████▎  | 121/166 [52:25<19:14, 25.67s/epoch, loss=0.251, accuracy=0.96, val_loss=0.46, val_accuracy=0.895, lr=0.001] 73%|███████▎  | 122/166 [52:50<18:50, 25.69s/epoch, loss=0.247, accuracy=0.96, val_loss=0.465, val_accuracy=0.897, lr=0.001] 74%|███████▍  | 123/166 [53:16<18:26, 25.73s/epoch, loss=0.243, accuracy=0.96, val_loss=0.458, val_accuracy=0.894, lr=0.001] 75%|███████▍  | 124/166 [53:42<18:02, 25.78s/epoch, loss=0.239, accuracy=0.962, val_loss=0.463, val_accuracy=0.893, lr=0.001] 75%|███████▌  | 125/166 [54:08<17:38, 25.82s/epoch, loss=0.239, accuracy=0.961, val_loss=0.467, val_accuracy=0.892, lr=0.001] 76%|███████▌  | 126/166 [54:34<17:14, 25.87s/epoch, loss=0.236, accuracy=0.961, val_loss=0.49, val_accuracy=0.888, lr=0.001]  77%|███████▋  | 127/166 [55:00<16:47, 25.84s/epoch, loss=0.228, accuracy=0.964, val_loss=0.45, val_accuracy=0.9, lr=0.001]   77%|███████▋  | 128/166 [55:25<16:20, 25.81s/epoch, loss=0.228, accuracy=0.963, val_loss=0.534, val_accuracy=0.878, lr=0.001] 78%|███████▊  | 129/166 [55:51<15:52, 25.74s/epoch, loss=0.225, accuracy=0.963, val_loss=0.478, val_accuracy=0.889, lr=0.001] 78%|███████▊  | 130/166 [56:17<15:25, 25.71s/epoch, loss=0.224, accuracy=0.963, val_loss=0.482, val_accuracy=0.888, lr=0.001] 79%|███████▉  | 131/166 [56:42<14:59, 25.70s/epoch, loss=0.223, accuracy=0.962, val_loss=0.482, val_accuracy=0.885, lr=0.001] 80%|███████▉  | 132/166 [57:08<14:33, 25.71s/epoch, loss=0.218, accuracy=0.964, val_loss=0.518, val_accuracy=0.878, lr=0.001] 80%|████████  | 133/166 [57:34<14:07, 25.67s/epoch, loss=0.219, accuracy=0.964, val_loss=0.462, val_accuracy=0.894, lr=0.001] 81%|████████  | 134/166 [57:59<13:40, 25.65s/epoch, loss=0.199, accuracy=0.971, val_loss=0.418, val_accuracy=0.906, lr=1e-04] 81%|████████▏ | 135/166 [58:25<13:13, 25.61s/epoch, loss=0.188, accuracy=0.975, val_loss=0.416, val_accuracy=0.906, lr=1e-04] 82%|████████▏ | 136/166 [58:51<12:50, 25.67s/epoch, loss=0.182, accuracy=0.978, val_loss=0.414, val_accuracy=0.906, lr=1e-04] 83%|████████▎ | 137/166 [59:16<12:24, 25.68s/epoch, loss=0.179, accuracy=0.978, val_loss=0.414, val_accuracy=0.906, lr=1e-04] 83%|████████▎ | 138/166 [59:42<11:59, 25.69s/epoch, loss=0.176, accuracy=0.98, val_loss=0.414, val_accuracy=0.907, lr=1e-04]  84%|████████▎ | 139/166 [1:00:08<11:32, 25.66s/epoch, loss=0.175, accuracy=0.98, val_loss=0.412, val_accuracy=0.909, lr=1e-04] 84%|████████▍ | 140/166 [1:00:33<11:07, 25.68s/epoch, loss=0.173, accuracy=0.981, val_loss=0.416, val_accuracy=0.908, lr=1e-04] 85%|████████▍ | 141/166 [1:00:59<10:43, 25.72s/epoch, loss=0.172, accuracy=0.98, val_loss=0.416, val_accuracy=0.907, lr=1e-04]  86%|████████▌ | 142/166 [1:01:25<10:16, 25.67s/epoch, loss=0.17, accuracy=0.981, val_loss=0.415, val_accuracy=0.907, lr=1e-04] 86%|████████▌ | 143/166 [1:01:50<09:50, 25.69s/epoch, loss=0.17, accuracy=0.981, val_loss=0.419, val_accuracy=0.905, lr=1e-04] 87%|████████▋ | 144/166 [1:02:16<09:24, 25.64s/epoch, loss=0.169, accuracy=0.982, val_loss=0.415, val_accuracy=0.907, lr=1e-04] 87%|████████▋ | 145/166 [1:02:42<08:58, 25.63s/epoch, loss=0.166, accuracy=0.983, val_loss=0.419, val_accuracy=0.909, lr=1e-04] 88%|████████▊ | 146/166 [1:03:07<08:33, 25.65s/epoch, loss=0.167, accuracy=0.982, val_loss=0.419, val_accuracy=0.907, lr=1e-04] 89%|████████▊ | 147/166 [1:03:33<08:07, 25.65s/epoch, loss=0.166, accuracy=0.983, val_loss=0.419, val_accuracy=0.906, lr=1e-04] 89%|████████▉ | 148/166 [1:03:59<07:42, 25.69s/epoch, loss=0.165, accuracy=0.983, val_loss=0.418, val_accuracy=0.906, lr=1e-04] 90%|████████▉ | 149/166 [1:04:24<07:16, 25.70s/epoch, loss=0.165, accuracy=0.982, val_loss=0.415, val_accuracy=0.908, lr=1e-04] 90%|█████████ | 150/166 [1:04:50<06:50, 25.67s/epoch, loss=0.164, accuracy=0.983, val_loss=0.418, val_accuracy=0.909, lr=1e-04] 91%|█████████ | 151/166 [1:05:16<06:25, 25.69s/epoch, loss=0.161, accuracy=0.984, val_loss=0.417, val_accuracy=0.908, lr=5e-5]  92%|█████████▏| 152/166 [1:05:41<05:59, 25.66s/epoch, loss=0.16, accuracy=0.985, val_loss=0.416, val_accuracy=0.908, lr=5e-5]  92%|█████████▏| 153/166 [1:06:07<05:32, 25.59s/epoch, loss=0.16, accuracy=0.985, val_loss=0.416, val_accuracy=0.908, lr=5e-5] 93%|█████████▎| 154/166 [1:06:32<05:07, 25.59s/epoch, loss=0.16, accuracy=0.985, val_loss=0.417, val_accuracy=0.908, lr=5e-5] 93%|█████████▎| 155/166 [1:06:58<04:41, 25.61s/epoch, loss=0.159, accuracy=0.985, val_loss=0.418, val_accuracy=0.908, lr=5e-5] 94%|█████████▍| 156/166 [1:07:23<04:15, 25.53s/epoch, loss=0.159, accuracy=0.984, val_loss=0.419, val_accuracy=0.908, lr=5e-5] 95%|█████████▍| 157/166 [1:07:49<03:49, 25.52s/epoch, loss=0.158, accuracy=0.984, val_loss=0.417, val_accuracy=0.907, lr=5e-5] 95%|█████████▌| 158/166 [1:08:14<03:23, 25.48s/epoch, loss=0.159, accuracy=0.985, val_loss=0.419, val_accuracy=0.908, lr=5e-5] 96%|█████████▌| 159/166 [1:08:40<02:58, 25.48s/epoch, loss=0.157, accuracy=0.985, val_loss=0.42, val_accuracy=0.909, lr=5e-5]  96%|█████████▋| 160/166 [1:09:05<02:32, 25.48s/epoch, loss=0.157, accuracy=0.985, val_loss=0.421, val_accuracy=0.907, lr=5e-5] 97%|█████████▋| 161/166 [1:09:31<02:07, 25.51s/epoch, loss=0.156, accuracy=0.985, val_loss=0.419, val_accuracy=0.909, lr=5e-5] 98%|█████████▊| 162/166 [1:09:56<01:42, 25.55s/epoch, loss=0.156, accuracy=0.986, val_loss=0.418, val_accuracy=0.908, lr=5e-5] 98%|█████████▊| 163/166 [1:10:22<01:16, 25.52s/epoch, loss=0.154, accuracy=0.986, val_loss=0.419, val_accuracy=0.908, lr=5e-5] 99%|█████████▉| 164/166 [1:10:47<00:51, 25.52s/epoch, loss=0.154, accuracy=0.985, val_loss=0.419, val_accuracy=0.908, lr=5e-5] 99%|█████████▉| 165/166 [1:11:13<00:25, 25.48s/epoch, loss=0.154, accuracy=0.986, val_loss=0.42, val_accuracy=0.909, lr=5e-5] 100%|██████████| 166/166 [1:11:38<00:00, 25.46s/epoch, loss=0.155, accuracy=0.985, val_loss=0.419, val_accuracy=0.908, lr=5e-5]100%|██████████| 166/166 [1:11:38<00:00, 25.90s/epoch, loss=0.155, accuracy=0.985, val_loss=0.419, val_accuracy=0.908, lr=5e-5]
Using real-time data augmentation.
Only one model saved

Loading model: 09_01_cifar10_ResNet20v1.h5
Test score: 0.4190826714038849
Test accuracy: 0.90829998254776


* * * Run SGD for ID = 9_2. * * *


2024-03-12 22:39:47.925853: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-12 22:39:51.673194: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-12 22:39:51.674499: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-12 22:39:51.741098: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:3b:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-12 22:39:51.741142: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-12 22:39:51.744684: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-12 22:39:51.744757: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-12 22:39:51.747521: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-12 22:39:51.748646: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-12 22:39:51.751759: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-12 22:39:51.753600: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-12 22:39:51.759176: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-12 22:39:51.759879: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-12 22:39:51.759977: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-12 22:39:53.059691: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-12 22:39:53.060272: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-12 22:39:53.060803: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:3b:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-12 22:39:53.060848: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-12 22:39:53.060885: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-12 22:39:53.060900: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-12 22:39:53.060914: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-12 22:39:53.060928: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-12 22:39:53.060942: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-12 22:39:53.060956: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-12 22:39:53.060970: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-12 22:39:53.061516: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-12 22:39:53.061559: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-12 22:39:53.733451: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-12 22:39:53.733504: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-12 22:39:53.733515: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-12 22:39:53.734592: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:3b:00.0, compute capability: 6.1)
{'id': '09_02', 'seed': 2, 'out_folder': 'results/epoch_budget_2', 'batch_size': 128, 'epochs': 166, 'validation_split': 0.0, 'checkpointing': False, 'checkpoint_every': -1, 'hold_out_validation_split': 0.0, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'bootstrapping': False, 'num_classes': 10, 'SSE_lr': False, 'test_time_augmentation': False, 'debug': False, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
y_train shape: (50000, 10)
x_val shape: (10000, 32, 32, 3)
y_val shape: (10000, 10)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/166 [00:00<?, ?epoch/s]2024-03-12 22:39:54.413009: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-12 22:39:54.425018: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2100000000 Hz
2024-03-12 22:39:56.503458: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-12 22:39:56.740250: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-12 22:39:58.118439: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-12 22:39:58.164458: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/166 [01:23<3:49:55, 83.61s/epoch, loss=2.8, accuracy=0.4, val_loss=2.36, val_accuracy=0.337, lr=0.1]  1%|          | 2/166 [01:49<2:15:01, 49.40s/epoch, loss=1.45, accuracy=0.595, val_loss=1.71, val_accuracy=0.487, lr=0.1]  2%|▏         | 3/166 [02:14<1:44:44, 38.56s/epoch, loss=1.29, accuracy=0.665, val_loss=2.25, val_accuracy=0.388, lr=0.1]  2%|▏         | 4/166 [02:40<1:30:06, 33.37s/epoch, loss=1.24, accuracy=0.693, val_loss=1.67, val_accuracy=0.532, lr=0.1]  3%|▎         | 5/166 [03:05<1:21:59, 30.56s/epoch, loss=1.23, accuracy=0.707, val_loss=2.19, val_accuracy=0.466, lr=0.1]  4%|▎         | 6/166 [03:30<1:16:38, 28.74s/epoch, loss=1.22, accuracy=0.716, val_loss=1.86, val_accuracy=0.498, lr=0.1]  4%|▍         | 7/166 [03:56<1:13:31, 27.75s/epoch, loss=1.2, accuracy=0.722, val_loss=2.17, val_accuracy=0.497, lr=0.1]   5%|▍         | 8/166 [04:22<1:11:17, 27.07s/epoch, loss=1.2, accuracy=0.725, val_loss=1.43, val_accuracy=0.631, lr=0.1]  5%|▌         | 9/166 [04:47<1:09:37, 26.61s/epoch, loss=1.19, accuracy=0.734, val_loss=1.9, val_accuracy=0.543, lr=0.1]  6%|▌         | 10/166 [05:13<1:08:15, 26.25s/epoch, loss=1.18, accuracy=0.734, val_loss=3.07, val_accuracy=0.366, lr=0.1]  7%|▋         | 11/166 [05:38<1:07:09, 26.00s/epoch, loss=1.18, accuracy=0.737, val_loss=2.46, val_accuracy=0.438, lr=0.1]  7%|▋         | 12/166 [06:04<1:06:27, 25.89s/epoch, loss=1.18, accuracy=0.738, val_loss=1.34, val_accuracy=0.67, lr=0.1]   8%|▊         | 13/166 [06:29<1:05:46, 25.79s/epoch, loss=1.16, accuracy=0.74, val_loss=2.16, val_accuracy=0.498, lr=0.1]  8%|▊         | 14/166 [06:55<1:05:00, 25.66s/epoch, loss=1.17, accuracy=0.74, val_loss=1.92, val_accuracy=0.499, lr=0.1]  9%|▉         | 15/166 [07:20<1:04:28, 25.62s/epoch, loss=1.16, accuracy=0.745, val_loss=2.1, val_accuracy=0.519, lr=0.1] 10%|▉         | 16/166 [07:46<1:03:58, 25.59s/epoch, loss=1.15, accuracy=0.746, val_loss=1.75, val_accuracy=0.582, lr=0.1] 10%|█         | 17/166 [08:11<1:03:30, 25.57s/epoch, loss=1.16, accuracy=0.744, val_loss=1.66, val_accuracy=0.576, lr=0.1] 11%|█         | 18/166 [08:37<1:02:55, 25.51s/epoch, loss=1.15, accuracy=0.748, val_loss=1.65, val_accuracy=0.593, lr=0.1] 11%|█▏        | 19/166 [09:02<1:02:35, 25.55s/epoch, loss=1.14, accuracy=0.75, val_loss=1.74, val_accuracy=0.57, lr=0.1]   12%|█▏        | 20/166 [09:28<1:02:07, 25.53s/epoch, loss=1.14, accuracy=0.746, val_loss=2.09, val_accuracy=0.438, lr=0.1] 13%|█▎        | 21/166 [09:53<1:01:41, 25.53s/epoch, loss=1.14, accuracy=0.75, val_loss=1.65, val_accuracy=0.57, lr=0.1]   13%|█▎        | 22/166 [10:19<1:01:17, 25.54s/epoch, loss=1.14, accuracy=0.75, val_loss=2.04, val_accuracy=0.519, lr=0.1] 14%|█▍        | 23/166 [10:44<1:00:50, 25.53s/epoch, loss=1.14, accuracy=0.752, val_loss=4.82, val_accuracy=0.28, lr=0.1] 14%|█▍        | 24/166 [11:10<1:00:35, 25.60s/epoch, loss=1.13, accuracy=0.751, val_loss=1.57, val_accuracy=0.624, lr=0.1] 15%|█▌        | 25/166 [11:36<1:00:17, 25.66s/epoch, loss=1.13, accuracy=0.752, val_loss=2.02, val_accuracy=0.45, lr=0.1]  16%|█▌        | 26/166 [12:01<59:37, 25.56s/epoch, loss=1.13, accuracy=0.753, val_loss=1.67, val_accuracy=0.584, lr=0.1]  16%|█▋        | 27/166 [12:27<59:10, 25.54s/epoch, loss=1.12, accuracy=0.754, val_loss=2.11, val_accuracy=0.463, lr=0.1] 17%|█▋        | 28/166 [12:52<58:47, 25.56s/epoch, loss=1.12, accuracy=0.752, val_loss=2.63, val_accuracy=0.267, lr=0.1] 17%|█▋        | 29/166 [13:18<58:25, 25.59s/epoch, loss=1.12, accuracy=0.754, val_loss=3.54, val_accuracy=0.271, lr=0.1] 18%|█▊        | 30/166 [13:44<58:05, 25.63s/epoch, loss=1.12, accuracy=0.754, val_loss=1.75, val_accuracy=0.602, lr=0.1] 19%|█▊        | 31/166 [14:09<57:36, 25.60s/epoch, loss=1.12, accuracy=0.757, val_loss=2.64, val_accuracy=0.379, lr=0.1] 19%|█▉        | 32/166 [14:35<57:06, 25.57s/epoch, loss=1.12, accuracy=0.754, val_loss=1.83, val_accuracy=0.522, lr=0.1] 20%|█▉        | 33/166 [15:00<56:42, 25.58s/epoch, loss=1.12, accuracy=0.753, val_loss=2.9, val_accuracy=0.445, lr=0.1]  20%|██        | 34/166 [15:26<56:20, 25.61s/epoch, loss=1.11, accuracy=0.757, val_loss=2.43, val_accuracy=0.489, lr=0.1] 21%|██        | 35/166 [15:52<55:54, 25.61s/epoch, loss=1.12, accuracy=0.756, val_loss=1.74, val_accuracy=0.578, lr=0.1] 22%|██▏       | 36/166 [16:17<55:29, 25.61s/epoch, loss=1.11, accuracy=0.758, val_loss=3.26, val_accuracy=0.188, lr=0.1] 22%|██▏       | 37/166 [16:43<54:58, 25.57s/epoch, loss=1.11, accuracy=0.756, val_loss=1.71, val_accuracy=0.549, lr=0.1] 23%|██▎       | 38/166 [17:08<54:30, 25.55s/epoch, loss=1.12, accuracy=0.756, val_loss=2.23, val_accuracy=0.435, lr=0.1] 23%|██▎       | 39/166 [17:34<54:03, 25.54s/epoch, loss=1.12, accuracy=0.756, val_loss=2.38, val_accuracy=0.42, lr=0.1]  24%|██▍       | 40/166 [17:59<53:33, 25.51s/epoch, loss=1.11, accuracy=0.757, val_loss=2.81, val_accuracy=0.321, lr=0.1] 25%|██▍       | 41/166 [18:25<53:10, 25.53s/epoch, loss=1.12, accuracy=0.754, val_loss=1.74, val_accuracy=0.545, lr=0.1] 25%|██▌       | 42/166 [18:50<52:43, 25.51s/epoch, loss=1.11, accuracy=0.758, val_loss=3.64, val_accuracy=0.33, lr=0.1]  26%|██▌       | 43/166 [19:16<52:25, 25.57s/epoch, loss=1.1, accuracy=0.758, val_loss=1.73, val_accuracy=0.577, lr=0.1] 27%|██▋       | 44/166 [19:42<51:59, 25.57s/epoch, loss=1.11, accuracy=0.756, val_loss=1.8, val_accuracy=0.562, lr=0.1] 27%|██▋       | 45/166 [20:07<51:28, 25.52s/epoch, loss=1.11, accuracy=0.757, val_loss=3.78, val_accuracy=0.283, lr=0.1] 28%|██▊       | 46/166 [20:33<51:01, 25.52s/epoch, loss=1.11, accuracy=0.758, val_loss=2.43, val_accuracy=0.371, lr=0.1] 28%|██▊       | 47/166 [20:58<50:36, 25.52s/epoch, loss=1.11, accuracy=0.757, val_loss=1.89, val_accuracy=0.493, lr=0.1] 29%|██▉       | 48/166 [21:24<50:14, 25.54s/epoch, loss=1.1, accuracy=0.759, val_loss=2.5, val_accuracy=0.482, lr=0.1]   30%|██▉       | 49/166 [21:49<49:46, 25.52s/epoch, loss=1.11, accuracy=0.757, val_loss=2.65, val_accuracy=0.339, lr=0.1] 30%|███       | 50/166 [22:15<49:17, 25.50s/epoch, loss=1.11, accuracy=0.757, val_loss=2.29, val_accuracy=0.452, lr=0.1] 31%|███       | 51/166 [22:40<48:53, 25.51s/epoch, loss=1.11, accuracy=0.761, val_loss=2.61, val_accuracy=0.476, lr=0.1] 31%|███▏      | 52/166 [23:06<48:26, 25.50s/epoch, loss=1.1, accuracy=0.758, val_loss=2.09, val_accuracy=0.475, lr=0.1]  32%|███▏      | 53/166 [23:31<48:10, 25.58s/epoch, loss=1.11, accuracy=0.757, val_loss=2.38, val_accuracy=0.443, lr=0.1] 33%|███▎      | 54/166 [23:57<47:51, 25.64s/epoch, loss=1.11, accuracy=0.758, val_loss=4.77, val_accuracy=0.225, lr=0.1] 33%|███▎      | 55/166 [24:23<47:20, 25.59s/epoch, loss=1.1, accuracy=0.76, val_loss=1.7, val_accuracy=0.565, lr=0.1]    34%|███▎      | 56/166 [24:48<46:57, 25.61s/epoch, loss=1.11, accuracy=0.76, val_loss=1.57, val_accuracy=0.597, lr=0.1] 34%|███▍      | 57/166 [25:14<46:27, 25.57s/epoch, loss=1.11, accuracy=0.757, val_loss=1.75, val_accuracy=0.534, lr=0.1] 35%|███▍      | 58/166 [25:39<46:02, 25.58s/epoch, loss=1.1, accuracy=0.76, val_loss=1.72, val_accuracy=0.566, lr=0.1]   36%|███▌      | 59/166 [26:05<45:41, 25.62s/epoch, loss=1.11, accuracy=0.756, val_loss=1.41, val_accuracy=0.655, lr=0.1] 36%|███▌      | 60/166 [26:31<45:11, 25.58s/epoch, loss=1.1, accuracy=0.758, val_loss=3.36, val_accuracy=0.423, lr=0.1]  37%|███▋      | 61/166 [26:56<44:46, 25.59s/epoch, loss=1.1, accuracy=0.758, val_loss=4.17, val_accuracy=0.302, lr=0.1] 37%|███▋      | 62/166 [27:22<44:23, 25.61s/epoch, loss=1.1, accuracy=0.759, val_loss=1.87, val_accuracy=0.544, lr=0.1] 38%|███▊      | 63/166 [27:47<44:00, 25.64s/epoch, loss=1.1, accuracy=0.759, val_loss=2.65, val_accuracy=0.352, lr=0.1] 39%|███▊      | 64/166 [28:13<43:36, 25.65s/epoch, loss=1.1, accuracy=0.755, val_loss=1.96, val_accuracy=0.486, lr=0.1] 39%|███▉      | 65/166 [28:39<43:07, 25.62s/epoch, loss=1.1, accuracy=0.761, val_loss=1.58, val_accuracy=0.593, lr=0.1] 40%|███▉      | 66/166 [29:04<42:46, 25.67s/epoch, loss=1.1, accuracy=0.759, val_loss=1.95, val_accuracy=0.555, lr=0.1] 40%|████      | 67/166 [29:30<42:16, 25.62s/epoch, loss=1.1, accuracy=0.759, val_loss=3.16, val_accuracy=0.238, lr=0.1] 41%|████      | 68/166 [29:56<41:56, 25.68s/epoch, loss=0.903, accuracy=0.815, val_loss=0.929, val_accuracy=0.787, lr=0.01] 42%|████▏     | 69/166 [30:21<41:29, 25.67s/epoch, loss=0.719, accuracy=0.848, val_loss=0.761, val_accuracy=0.828, lr=0.01] 42%|████▏     | 70/166 [30:47<40:55, 25.57s/epoch, loss=0.642, accuracy=0.857, val_loss=0.801, val_accuracy=0.799, lr=0.01] 43%|████▎     | 71/166 [31:12<40:22, 25.50s/epoch, loss=0.597, accuracy=0.862, val_loss=0.742, val_accuracy=0.805, lr=0.01] 43%|████▎     | 72/166 [31:38<39:55, 25.49s/epoch, loss=0.58, accuracy=0.862, val_loss=0.794, val_accuracy=0.793, lr=0.01]  44%|████▍     | 73/166 [32:03<39:32, 25.51s/epoch, loss=0.569, accuracy=0.864, val_loss=0.763, val_accuracy=0.799, lr=0.01] 45%|████▍     | 74/166 [32:29<39:17, 25.63s/epoch, loss=0.558, accuracy=0.866, val_loss=0.928, val_accuracy=0.752, lr=0.01] 45%|████▌     | 75/166 [32:54<38:44, 25.54s/epoch, loss=0.555, accuracy=0.866, val_loss=0.686, val_accuracy=0.823, lr=0.01] 46%|████▌     | 76/166 [33:20<38:20, 25.56s/epoch, loss=0.556, accuracy=0.867, val_loss=0.875, val_accuracy=0.761, lr=0.01] 46%|████▋     | 77/166 [33:46<37:55, 25.57s/epoch, loss=0.55, accuracy=0.87, val_loss=1.01, val_accuracy=0.741, lr=0.01]    47%|████▋     | 78/166 [34:11<37:38, 25.66s/epoch, loss=0.545, accuracy=0.873, val_loss=1.05, val_accuracy=0.698, lr=0.01] 48%|████▊     | 79/166 [34:37<37:15, 25.69s/epoch, loss=0.547, accuracy=0.872, val_loss=0.83, val_accuracy=0.785, lr=0.01] 48%|████▊     | 80/166 [35:03<36:45, 25.65s/epoch, loss=0.551, accuracy=0.873, val_loss=0.963, val_accuracy=0.746, lr=0.01] 49%|████▉     | 81/166 [35:28<36:15, 25.60s/epoch, loss=0.548, accuracy=0.877, val_loss=0.929, val_accuracy=0.749, lr=0.01] 49%|████▉     | 82/166 [35:54<35:41, 25.50s/epoch, loss=0.549, accuracy=0.874, val_loss=0.761, val_accuracy=0.811, lr=0.01] 50%|█████     | 83/166 [36:19<35:13, 25.47s/epoch, loss=0.549, accuracy=0.877, val_loss=0.773, val_accuracy=0.803, lr=0.01] 51%|█████     | 84/166 [36:44<34:43, 25.41s/epoch, loss=0.548, accuracy=0.877, val_loss=0.828, val_accuracy=0.787, lr=0.01] 51%|█████     | 85/166 [37:10<34:19, 25.43s/epoch, loss=0.547, accuracy=0.877, val_loss=0.768, val_accuracy=0.803, lr=0.01] 52%|█████▏    | 86/166 [37:35<33:53, 25.41s/epoch, loss=0.544, accuracy=0.881, val_loss=0.829, val_accuracy=0.795, lr=0.01] 52%|█████▏    | 87/166 [38:01<33:29, 25.44s/epoch, loss=0.548, accuracy=0.879, val_loss=0.901, val_accuracy=0.777, lr=0.01] 53%|█████▎    | 88/166 [38:26<33:01, 25.41s/epoch, loss=0.546, accuracy=0.879, val_loss=0.788, val_accuracy=0.803, lr=0.01] 54%|█████▎    | 89/166 [38:51<32:33, 25.37s/epoch, loss=0.546, accuracy=0.88, val_loss=0.784, val_accuracy=0.809, lr=0.01]  54%|█████▍    | 90/166 [39:17<32:12, 25.43s/epoch, loss=0.547, accuracy=0.88, val_loss=1.21, val_accuracy=0.665, lr=0.01]  55%|█████▍    | 91/166 [39:42<31:46, 25.42s/epoch, loss=0.544, accuracy=0.882, val_loss=0.859, val_accuracy=0.783, lr=0.01] 55%|█████▌    | 92/166 [40:08<31:22, 25.43s/epoch, loss=0.544, accuracy=0.882, val_loss=1.78, val_accuracy=0.571, lr=0.01]  56%|█████▌    | 93/166 [40:33<30:51, 25.36s/epoch, loss=0.544, accuracy=0.884, val_loss=1.02, val_accuracy=0.748, lr=0.01] 57%|█████▋    | 94/166 [40:58<30:22, 25.32s/epoch, loss=0.545, accuracy=0.884, val_loss=0.859, val_accuracy=0.808, lr=0.01] 57%|█████▋    | 95/166 [41:23<29:56, 25.31s/epoch, loss=0.54, accuracy=0.885, val_loss=0.903, val_accuracy=0.777, lr=0.01]  58%|█████▊    | 96/166 [41:49<29:32, 25.32s/epoch, loss=0.545, accuracy=0.885, val_loss=0.954, val_accuracy=0.758, lr=0.01] 58%|█████▊    | 97/166 [42:14<29:10, 25.36s/epoch, loss=0.541, accuracy=0.886, val_loss=0.97, val_accuracy=0.771, lr=0.01]  59%|█████▉    | 98/166 [42:40<28:49, 25.43s/epoch, loss=0.543, accuracy=0.885, val_loss=0.857, val_accuracy=0.786, lr=0.01] 60%|█████▉    | 99/166 [43:05<28:23, 25.42s/epoch, loss=0.542, accuracy=0.887, val_loss=0.902, val_accuracy=0.783, lr=0.01] 60%|██████    | 100/166 [43:31<28:00, 25.46s/epoch, loss=0.539, accuracy=0.888, val_loss=0.676, val_accuracy=0.844, lr=0.01] 61%|██████    | 101/166 [43:56<27:29, 25.38s/epoch, loss=0.462, accuracy=0.914, val_loss=0.526, val_accuracy=0.892, lr=0.001] 61%|██████▏   | 102/166 [44:22<27:10, 25.48s/epoch, loss=0.412, accuracy=0.93, val_loss=0.509, val_accuracy=0.895, lr=0.001]  62%|██████▏   | 103/166 [44:47<26:40, 25.40s/epoch, loss=0.392, accuracy=0.936, val_loss=0.499, val_accuracy=0.896, lr=0.001] 63%|██████▎   | 104/166 [45:12<26:15, 25.42s/epoch, loss=0.374, accuracy=0.94, val_loss=0.496, val_accuracy=0.897, lr=0.001]  63%|██████▎   | 105/166 [45:38<25:48, 25.39s/epoch, loss=0.361, accuracy=0.942, val_loss=0.482, val_accuracy=0.901, lr=0.001] 64%|██████▍   | 106/166 [46:03<25:24, 25.41s/epoch, loss=0.349, accuracy=0.944, val_loss=0.487, val_accuracy=0.898, lr=0.001] 64%|██████▍   | 107/166 [46:28<24:57, 25.39s/epoch, loss=0.34, accuracy=0.946, val_loss=0.487, val_accuracy=0.898, lr=0.001]  65%|██████▌   | 108/166 [46:53<24:28, 25.32s/epoch, loss=0.328, accuracy=0.948, val_loss=0.488, val_accuracy=0.895, lr=0.001] 66%|██████▌   | 109/166 [47:19<24:02, 25.31s/epoch, loss=0.32, accuracy=0.95, val_loss=0.47, val_accuracy=0.898, lr=0.001]    66%|██████▋   | 110/166 [47:44<23:37, 25.32s/epoch, loss=0.308, accuracy=0.951, val_loss=0.471, val_accuracy=0.9, lr=0.001] 67%|██████▋   | 111/166 [48:09<23:08, 25.24s/epoch, loss=0.301, accuracy=0.953, val_loss=0.458, val_accuracy=0.901, lr=0.001] 67%|██████▋   | 112/166 [48:34<22:43, 25.25s/epoch, loss=0.297, accuracy=0.953, val_loss=0.466, val_accuracy=0.9, lr=0.001]   68%|██████▊   | 113/166 [49:00<22:19, 25.27s/epoch, loss=0.286, accuracy=0.955, val_loss=0.483, val_accuracy=0.894, lr=0.001] 69%|██████▊   | 114/166 [49:25<21:57, 25.34s/epoch, loss=0.285, accuracy=0.954, val_loss=0.455, val_accuracy=0.9, lr=0.001]   69%|██████▉   | 115/166 [49:51<21:31, 25.33s/epoch, loss=0.276, accuracy=0.957, val_loss=0.467, val_accuracy=0.897, lr=0.001] 70%|██████▉   | 116/166 [50:16<21:04, 25.29s/epoch, loss=0.268, accuracy=0.958, val_loss=0.464, val_accuracy=0.898, lr=0.001] 70%|███████   | 117/166 [50:41<20:38, 25.27s/epoch, loss=0.267, accuracy=0.957, val_loss=0.452, val_accuracy=0.898, lr=0.001] 71%|███████   | 118/166 [51:06<20:10, 25.22s/epoch, loss=0.258, accuracy=0.959, val_loss=0.448, val_accuracy=0.901, lr=0.001] 72%|███████▏  | 119/166 [51:31<19:46, 25.24s/epoch, loss=0.252, accuracy=0.96, val_loss=0.452, val_accuracy=0.898, lr=0.001]  72%|███████▏  | 120/166 [51:57<19:19, 25.21s/epoch, loss=0.251, accuracy=0.959, val_loss=0.451, val_accuracy=0.901, lr=0.001] 73%|███████▎  | 121/166 [52:22<18:56, 25.25s/epoch, loss=0.246, accuracy=0.959, val_loss=0.444, val_accuracy=0.899, lr=0.001] 73%|███████▎  | 122/166 [52:47<18:33, 25.30s/epoch, loss=0.242, accuracy=0.961, val_loss=0.462, val_accuracy=0.898, lr=0.001] 74%|███████▍  | 123/166 [53:12<18:05, 25.25s/epoch, loss=0.237, accuracy=0.962, val_loss=0.436, val_accuracy=0.9, lr=0.001]   75%|███████▍  | 124/166 [53:38<17:43, 25.33s/epoch, loss=0.235, accuracy=0.961, val_loss=0.495, val_accuracy=0.883, lr=0.001] 75%|███████▌  | 125/166 [54:03<17:17, 25.32s/epoch, loss=0.234, accuracy=0.961, val_loss=0.51, val_accuracy=0.882, lr=0.001]  76%|███████▌  | 126/166 [54:28<16:51, 25.29s/epoch, loss=0.23, accuracy=0.962, val_loss=0.478, val_accuracy=0.891, lr=0.001] 77%|███████▋  | 127/166 [54:54<16:27, 25.32s/epoch, loss=0.227, accuracy=0.961, val_loss=0.489, val_accuracy=0.888, lr=0.001] 77%|███████▋  | 128/166 [55:19<16:02, 25.34s/epoch, loss=0.224, accuracy=0.963, val_loss=0.463, val_accuracy=0.895, lr=0.001] 78%|███████▊  | 129/166 [55:44<15:36, 25.30s/epoch, loss=0.223, accuracy=0.962, val_loss=0.457, val_accuracy=0.894, lr=0.001] 78%|███████▊  | 130/166 [56:10<15:10, 25.28s/epoch, loss=0.22, accuracy=0.962, val_loss=0.472, val_accuracy=0.889, lr=0.001]  79%|███████▉  | 131/166 [56:35<14:43, 25.26s/epoch, loss=0.218, accuracy=0.964, val_loss=0.472, val_accuracy=0.89, lr=0.001] 80%|███████▉  | 132/166 [57:00<14:17, 25.21s/epoch, loss=0.216, accuracy=0.963, val_loss=0.469, val_accuracy=0.888, lr=0.001] 80%|████████  | 133/166 [57:25<13:53, 25.25s/epoch, loss=0.217, accuracy=0.963, val_loss=0.487, val_accuracy=0.886, lr=0.001] 81%|████████  | 134/166 [57:50<13:26, 25.20s/epoch, loss=0.198, accuracy=0.97, val_loss=0.407, val_accuracy=0.91, lr=1e-04]   81%|████████▏ | 135/166 [58:16<13:01, 25.22s/epoch, loss=0.184, accuracy=0.975, val_loss=0.406, val_accuracy=0.91, lr=1e-04] 82%|████████▏ | 136/166 [58:40<12:33, 25.11s/epoch, loss=0.181, accuracy=0.977, val_loss=0.407, val_accuracy=0.91, lr=1e-04] 83%|████████▎ | 137/166 [59:06<12:09, 25.17s/epoch, loss=0.178, accuracy=0.978, val_loss=0.405, val_accuracy=0.91, lr=1e-04] 83%|████████▎ | 138/166 [59:31<11:45, 25.19s/epoch, loss=0.175, accuracy=0.979, val_loss=0.405, val_accuracy=0.91, lr=1e-04] 84%|████████▎ | 139/166 [59:56<11:20, 25.21s/epoch, loss=0.171, accuracy=0.98, val_loss=0.405, val_accuracy=0.911, lr=1e-04] 84%|████████▍ | 140/166 [1:00:22<10:55, 25.22s/epoch, loss=0.17, accuracy=0.98, val_loss=0.406, val_accuracy=0.912, lr=1e-04] 85%|████████▍ | 141/166 [1:00:47<10:29, 25.16s/epoch, loss=0.17, accuracy=0.98, val_loss=0.407, val_accuracy=0.911, lr=1e-04] 86%|████████▌ | 142/166 [1:01:12<10:04, 25.18s/epoch, loss=0.168, accuracy=0.981, val_loss=0.409, val_accuracy=0.911, lr=1e-04] 86%|████████▌ | 143/166 [1:01:37<09:39, 25.21s/epoch, loss=0.166, accuracy=0.982, val_loss=0.408, val_accuracy=0.912, lr=1e-04] 87%|████████▋ | 144/166 [1:02:02<09:15, 25.25s/epoch, loss=0.167, accuracy=0.981, val_loss=0.408, val_accuracy=0.911, lr=1e-04] 87%|████████▋ | 145/166 [1:02:28<08:50, 25.28s/epoch, loss=0.164, accuracy=0.982, val_loss=0.406, val_accuracy=0.911, lr=1e-04] 88%|████████▊ | 146/166 [1:02:53<08:26, 25.31s/epoch, loss=0.163, accuracy=0.982, val_loss=0.406, val_accuracy=0.911, lr=1e-04] 89%|████████▊ | 147/166 [1:03:18<08:00, 25.28s/epoch, loss=0.161, accuracy=0.983, val_loss=0.409, val_accuracy=0.912, lr=1e-04] 89%|████████▉ | 148/166 [1:03:44<07:34, 25.25s/epoch, loss=0.162, accuracy=0.982, val_loss=0.41, val_accuracy=0.91, lr=1e-04]   90%|████████▉ | 149/166 [1:04:09<07:09, 25.25s/epoch, loss=0.161, accuracy=0.983, val_loss=0.41, val_accuracy=0.912, lr=1e-04] 90%|█████████ | 150/166 [1:04:34<06:44, 25.28s/epoch, loss=0.16, accuracy=0.983, val_loss=0.409, val_accuracy=0.91, lr=1e-04]  91%|█████████ | 151/166 [1:05:00<06:20, 25.36s/epoch, loss=0.159, accuracy=0.983, val_loss=0.408, val_accuracy=0.911, lr=5e-5] 92%|█████████▏| 152/166 [1:05:25<05:53, 25.28s/epoch, loss=0.156, accuracy=0.984, val_loss=0.409, val_accuracy=0.912, lr=5e-5] 92%|█████████▏| 153/166 [1:05:50<05:28, 25.24s/epoch, loss=0.156, accuracy=0.985, val_loss=0.408, val_accuracy=0.912, lr=5e-5] 93%|█████████▎| 154/166 [1:06:15<05:03, 25.26s/epoch, loss=0.156, accuracy=0.985, val_loss=0.407, val_accuracy=0.911, lr=5e-5] 93%|█████████▎| 155/166 [1:06:40<04:37, 25.27s/epoch, loss=0.155, accuracy=0.985, val_loss=0.407, val_accuracy=0.911, lr=5e-5] 94%|█████████▍| 156/166 [1:07:06<04:12, 25.24s/epoch, loss=0.156, accuracy=0.984, val_loss=0.41, val_accuracy=0.912, lr=5e-5]  95%|█████████▍| 157/166 [1:07:31<03:46, 25.20s/epoch, loss=0.153, accuracy=0.985, val_loss=0.409, val_accuracy=0.911, lr=5e-5] 95%|█████████▌| 158/166 [1:07:56<03:21, 25.20s/epoch, loss=0.154, accuracy=0.985, val_loss=0.408, val_accuracy=0.912, lr=5e-5] 96%|█████████▌| 159/166 [1:08:21<02:56, 25.20s/epoch, loss=0.154, accuracy=0.984, val_loss=0.408, val_accuracy=0.911, lr=5e-5] 96%|█████████▋| 160/166 [1:08:46<02:30, 25.14s/epoch, loss=0.153, accuracy=0.985, val_loss=0.409, val_accuracy=0.912, lr=5e-5] 97%|█████████▋| 161/166 [1:09:11<02:05, 25.15s/epoch, loss=0.152, accuracy=0.985, val_loss=0.41, val_accuracy=0.912, lr=5e-5]  98%|█████████▊| 162/166 [1:09:36<01:40, 25.09s/epoch, loss=0.155, accuracy=0.984, val_loss=0.41, val_accuracy=0.911, lr=5e-5] 98%|█████████▊| 163/166 [1:10:02<01:15, 25.15s/epoch, loss=0.154, accuracy=0.985, val_loss=0.408, val_accuracy=0.912, lr=5e-5] 99%|█████████▉| 164/166 [1:10:27<00:50, 25.18s/epoch, loss=0.152, accuracy=0.985, val_loss=0.409, val_accuracy=0.911, lr=5e-5] 99%|█████████▉| 165/166 [1:10:52<00:25, 25.15s/epoch, loss=0.152, accuracy=0.986, val_loss=0.409, val_accuracy=0.912, lr=5e-5]100%|██████████| 166/166 [1:11:17<00:00, 25.14s/epoch, loss=0.152, accuracy=0.985, val_loss=0.41, val_accuracy=0.912, lr=5e-5] 100%|██████████| 166/166 [1:11:17<00:00, 25.77s/epoch, loss=0.152, accuracy=0.985, val_loss=0.41, val_accuracy=0.912, lr=5e-5]
Using real-time data augmentation.
Only one model saved

Loading model: 09_02_cifar10_ResNet20v1.h5
Test score: 0.4096638560295105
Test accuracy: 0.9115999937057495


* * * Run SGD for ID = 9_3. * * *


2024-03-12 23:51:16.603261: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-12 23:51:24.507783: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-12 23:51:24.509189: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-12 23:51:24.553645: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:3b:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-12 23:51:24.553695: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-12 23:51:24.561946: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-12 23:51:24.562017: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-12 23:51:24.566752: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-12 23:51:24.569356: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-12 23:51:24.575416: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-12 23:51:24.578703: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-12 23:51:24.586379: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-12 23:51:24.587089: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-12 23:51:24.587177: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-12 23:51:25.893377: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-12 23:51:25.894416: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-12 23:51:25.895221: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:3b:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-12 23:51:25.895259: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-12 23:51:25.895302: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-12 23:51:25.895317: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-12 23:51:25.895331: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-12 23:51:25.895345: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-12 23:51:25.895362: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-12 23:51:25.895376: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-12 23:51:25.895390: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-12 23:51:25.895948: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-12 23:51:25.895993: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-12 23:51:26.569186: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-12 23:51:26.569240: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-12 23:51:26.569251: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-12 23:51:26.570337: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:3b:00.0, compute capability: 6.1)
{'id': '09_03', 'seed': 3, 'out_folder': 'results/epoch_budget_2', 'batch_size': 128, 'epochs': 166, 'validation_split': 0.0, 'checkpointing': False, 'checkpoint_every': -1, 'hold_out_validation_split': 0.0, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'bootstrapping': False, 'num_classes': 10, 'SSE_lr': False, 'test_time_augmentation': False, 'debug': False, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
y_train shape: (50000, 10)
x_val shape: (10000, 32, 32, 3)
y_val shape: (10000, 10)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/166 [00:00<?, ?epoch/s]2024-03-12 23:51:27.235549: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-12 23:51:27.247985: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2100000000 Hz
2024-03-12 23:51:29.345410: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-12 23:51:29.640393: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-12 23:51:30.570079: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-12 23:51:30.618127: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/166 [00:56<2:36:15, 56.82s/epoch, loss=2.95, accuracy=0.365, val_loss=2.07, val_accuracy=0.38, lr=0.1]  1%|          | 2/166 [01:22<1:44:55, 38.39s/epoch, loss=1.51, accuracy=0.564, val_loss=4.31, val_accuracy=0.243, lr=0.1]  2%|▏         | 3/166 [01:47<1:28:04, 32.42s/epoch, loss=1.31, accuracy=0.66, val_loss=2, val_accuracy=0.472, lr=0.1]      2%|▏         | 4/166 [02:13<1:20:04, 29.66s/epoch, loss=1.25, accuracy=0.696, val_loss=1.48, val_accuracy=0.613, lr=0.1]  3%|▎         | 5/166 [02:38<1:15:16, 28.05s/epoch, loss=1.23, accuracy=0.712, val_loss=1.72, val_accuracy=0.551, lr=0.1]  4%|▎         | 6/166 [03:03<1:12:14, 27.09s/epoch, loss=1.22, accuracy=0.722, val_loss=1.94, val_accuracy=0.491, lr=0.1]  4%|▍         | 7/166 [03:29<1:10:29, 26.60s/epoch, loss=1.21, accuracy=0.725, val_loss=1.66, val_accuracy=0.571, lr=0.1]  5%|▍         | 8/166 [03:54<1:09:14, 26.29s/epoch, loss=1.2, accuracy=0.729, val_loss=2.06, val_accuracy=0.491, lr=0.1]   5%|▌         | 9/166 [04:20<1:08:11, 26.06s/epoch, loss=1.2, accuracy=0.734, val_loss=3.11, val_accuracy=0.369, lr=0.1]  6%|▌         | 10/166 [04:45<1:07:03, 25.79s/epoch, loss=1.19, accuracy=0.735, val_loss=2.09, val_accuracy=0.409, lr=0.1]  7%|▋         | 11/166 [05:10<1:06:18, 25.67s/epoch, loss=1.18, accuracy=0.74, val_loss=1.88, val_accuracy=0.556, lr=0.1]   7%|▋         | 12/166 [05:36<1:05:46, 25.63s/epoch, loss=1.18, accuracy=0.739, val_loss=2.17, val_accuracy=0.507, lr=0.1]  8%|▊         | 13/166 [06:01<1:05:03, 25.51s/epoch, loss=1.18, accuracy=0.739, val_loss=2.24, val_accuracy=0.487, lr=0.1]  8%|▊         | 14/166 [06:26<1:04:31, 25.47s/epoch, loss=1.17, accuracy=0.744, val_loss=1.82, val_accuracy=0.54, lr=0.1]   9%|▉         | 15/166 [06:52<1:04:00, 25.43s/epoch, loss=1.18, accuracy=0.743, val_loss=2.68, val_accuracy=0.415, lr=0.1] 10%|▉         | 16/166 [07:17<1:03:43, 25.49s/epoch, loss=1.16, accuracy=0.745, val_loss=3.33, val_accuracy=0.376, lr=0.1] 10%|█         | 17/166 [07:43<1:03:14, 25.46s/epoch, loss=1.17, accuracy=0.746, val_loss=1.5, val_accuracy=0.618, lr=0.1]  11%|█         | 18/166 [08:08<1:02:42, 25.42s/epoch, loss=1.16, accuracy=0.748, val_loss=1.88, val_accuracy=0.485, lr=0.1] 11%|█▏        | 19/166 [08:34<1:02:14, 25.41s/epoch, loss=1.16, accuracy=0.746, val_loss=1.9, val_accuracy=0.514, lr=0.1]  12%|█▏        | 20/166 [08:59<1:02:03, 25.50s/epoch, loss=1.16, accuracy=0.748, val_loss=3.43, val_accuracy=0.25, lr=0.1] 13%|█▎        | 21/166 [09:25<1:01:43, 25.54s/epoch, loss=1.15, accuracy=0.748, val_loss=2.29, val_accuracy=0.385, lr=0.1] 13%|█▎        | 22/166 [09:51<1:01:24, 25.59s/epoch, loss=1.15, accuracy=0.751, val_loss=1.52, val_accuracy=0.628, lr=0.1] 14%|█▍        | 23/166 [10:16<1:00:53, 25.55s/epoch, loss=1.15, accuracy=0.751, val_loss=2.47, val_accuracy=0.467, lr=0.1] 14%|█▍        | 24/166 [10:42<1:00:36, 25.61s/epoch, loss=1.15, accuracy=0.751, val_loss=1.99, val_accuracy=0.486, lr=0.1] 15%|█▌        | 25/166 [11:07<1:00:06, 25.58s/epoch, loss=1.15, accuracy=0.754, val_loss=2.25, val_accuracy=0.52, lr=0.1]  16%|█▌        | 26/166 [11:33<59:28, 25.49s/epoch, loss=1.15, accuracy=0.753, val_loss=1.39, val_accuracy=0.677, lr=0.1]  16%|█▋        | 27/166 [11:58<59:01, 25.48s/epoch, loss=1.14, accuracy=0.753, val_loss=2.15, val_accuracy=0.491, lr=0.1] 17%|█▋        | 28/166 [12:24<58:45, 25.55s/epoch, loss=1.14, accuracy=0.751, val_loss=1.8, val_accuracy=0.572, lr=0.1]  17%|█▋        | 29/166 [12:49<58:19, 25.55s/epoch, loss=1.14, accuracy=0.756, val_loss=2.39, val_accuracy=0.353, lr=0.1] 18%|█▊        | 30/166 [13:15<57:45, 25.48s/epoch, loss=1.14, accuracy=0.752, val_loss=1.7, val_accuracy=0.572, lr=0.1]  19%|█▊        | 31/166 [13:40<57:12, 25.43s/epoch, loss=1.14, accuracy=0.752, val_loss=2.29, val_accuracy=0.457, lr=0.1] 19%|█▉        | 32/166 [14:06<56:54, 25.48s/epoch, loss=1.13, accuracy=0.755, val_loss=1.79, val_accuracy=0.549, lr=0.1] 20%|█▉        | 33/166 [14:31<56:21, 25.42s/epoch, loss=1.13, accuracy=0.755, val_loss=3.04, val_accuracy=0.325, lr=0.1] 20%|██        | 34/166 [14:56<55:53, 25.41s/epoch, loss=1.13, accuracy=0.756, val_loss=2.09, val_accuracy=0.461, lr=0.1] 21%|██        | 35/166 [15:22<55:26, 25.39s/epoch, loss=1.13, accuracy=0.756, val_loss=3.46, val_accuracy=0.33, lr=0.1]  22%|██▏       | 36/166 [15:47<54:58, 25.37s/epoch, loss=1.13, accuracy=0.756, val_loss=3.74, val_accuracy=0.343, lr=0.1] 22%|██▏       | 37/166 [16:11<53:59, 25.11s/epoch, loss=1.14, accuracy=0.755, val_loss=1.77, val_accuracy=0.537, lr=0.1] 23%|██▎       | 38/166 [16:37<53:36, 25.13s/epoch, loss=1.13, accuracy=0.758, val_loss=1.75, val_accuracy=0.53, lr=0.1]  23%|██▎       | 39/166 [17:02<53:21, 25.21s/epoch, loss=1.12, accuracy=0.757, val_loss=3.68, val_accuracy=0.277, lr=0.1] 24%|██▍       | 40/166 [17:27<52:58, 25.23s/epoch, loss=1.12, accuracy=0.758, val_loss=1.88, val_accuracy=0.503, lr=0.1] 25%|██▍       | 41/166 [17:53<52:38, 25.27s/epoch, loss=1.13, accuracy=0.755, val_loss=1.7, val_accuracy=0.565, lr=0.1]  25%|██▌       | 42/166 [18:18<52:28, 25.39s/epoch, loss=1.13, accuracy=0.758, val_loss=1.55, val_accuracy=0.624, lr=0.1] 26%|██▌       | 43/166 [18:44<52:12, 25.47s/epoch, loss=1.12, accuracy=0.758, val_loss=1.77, val_accuracy=0.528, lr=0.1] 27%|██▋       | 44/166 [19:09<51:44, 25.44s/epoch, loss=1.12, accuracy=0.756, val_loss=3.65, val_accuracy=0.347, lr=0.1] 27%|██▋       | 45/166 [19:35<51:22, 25.47s/epoch, loss=1.13, accuracy=0.758, val_loss=3.68, val_accuracy=0.305, lr=0.1] 28%|██▊       | 46/166 [20:00<51:02, 25.52s/epoch, loss=1.12, accuracy=0.758, val_loss=2.11, val_accuracy=0.46, lr=0.1]  28%|██▊       | 47/166 [20:26<50:39, 25.55s/epoch, loss=1.13, accuracy=0.754, val_loss=1.75, val_accuracy=0.584, lr=0.1] 29%|██▉       | 48/166 [20:52<50:12, 25.53s/epoch, loss=1.12, accuracy=0.759, val_loss=2.08, val_accuracy=0.517, lr=0.1] 30%|██▉       | 49/166 [21:17<49:56, 25.61s/epoch, loss=1.11, accuracy=0.757, val_loss=2.29, val_accuracy=0.37, lr=0.1]  30%|███       | 50/166 [21:43<49:30, 25.61s/epoch, loss=1.12, accuracy=0.759, val_loss=4.28, val_accuracy=0.213, lr=0.1] 31%|███       | 51/166 [22:09<49:01, 25.58s/epoch, loss=1.12, accuracy=0.759, val_loss=2.38, val_accuracy=0.507, lr=0.1] 31%|███▏      | 52/166 [22:34<48:35, 25.57s/epoch, loss=1.12, accuracy=0.758, val_loss=1.98, val_accuracy=0.47, lr=0.1]  32%|███▏      | 53/166 [22:59<48:03, 25.52s/epoch, loss=1.12, accuracy=0.758, val_loss=1.37, val_accuracy=0.685, lr=0.1] 33%|███▎      | 54/166 [23:25<47:40, 25.54s/epoch, loss=1.11, accuracy=0.76, val_loss=2.6, val_accuracy=0.39, lr=0.1]    33%|███▎      | 55/166 [23:51<47:12, 25.51s/epoch, loss=1.12, accuracy=0.758, val_loss=2, val_accuracy=0.529, lr=0.1] 34%|███▎      | 56/166 [24:16<46:52, 25.57s/epoch, loss=1.12, accuracy=0.757, val_loss=2.1, val_accuracy=0.529, lr=0.1] 34%|███▍      | 57/166 [24:42<46:35, 25.64s/epoch, loss=1.13, accuracy=0.756, val_loss=3.01, val_accuracy=0.404, lr=0.1] 35%|███▍      | 58/166 [25:07<46:04, 25.60s/epoch, loss=1.12, accuracy=0.757, val_loss=1.82, val_accuracy=0.549, lr=0.1] 36%|███▌      | 59/166 [25:33<45:41, 25.63s/epoch, loss=1.12, accuracy=0.758, val_loss=1.72, val_accuracy=0.559, lr=0.1] 36%|███▌      | 60/166 [25:59<45:14, 25.61s/epoch, loss=1.11, accuracy=0.759, val_loss=2.05, val_accuracy=0.474, lr=0.1] 37%|███▋      | 61/166 [26:24<44:43, 25.56s/epoch, loss=1.12, accuracy=0.758, val_loss=1.82, val_accuracy=0.565, lr=0.1] 37%|███▋      | 62/166 [26:50<44:13, 25.51s/epoch, loss=1.11, accuracy=0.759, val_loss=2.36, val_accuracy=0.412, lr=0.1] 38%|███▊      | 63/166 [27:15<43:42, 25.46s/epoch, loss=1.12, accuracy=0.757, val_loss=1.83, val_accuracy=0.561, lr=0.1] 39%|███▊      | 64/166 [27:41<43:20, 25.49s/epoch, loss=1.12, accuracy=0.759, val_loss=1.83, val_accuracy=0.581, lr=0.1] 39%|███▉      | 65/166 [28:06<42:56, 25.51s/epoch, loss=1.11, accuracy=0.761, val_loss=2.72, val_accuracy=0.408, lr=0.1] 40%|███▉      | 66/166 [28:32<42:29, 25.50s/epoch, loss=1.12, accuracy=0.758, val_loss=1.69, val_accuracy=0.566, lr=0.1] 40%|████      | 67/166 [28:57<42:06, 25.52s/epoch, loss=1.11, accuracy=0.761, val_loss=1.66, val_accuracy=0.582, lr=0.1] 41%|████      | 68/166 [29:22<41:36, 25.47s/epoch, loss=0.899, accuracy=0.819, val_loss=0.913, val_accuracy=0.798, lr=0.01] 42%|████▏     | 69/166 [29:48<41:12, 25.49s/epoch, loss=0.725, accuracy=0.85, val_loss=0.823, val_accuracy=0.805, lr=0.01]  42%|████▏     | 70/166 [30:13<40:41, 25.43s/epoch, loss=0.644, accuracy=0.858, val_loss=0.719, val_accuracy=0.828, lr=0.01] 43%|████▎     | 71/166 [30:39<40:15, 25.43s/epoch, loss=0.599, accuracy=0.864, val_loss=0.707, val_accuracy=0.821, lr=0.01] 43%|████▎     | 72/166 [31:04<39:49, 25.42s/epoch, loss=0.579, accuracy=0.864, val_loss=1.01, val_accuracy=0.726, lr=0.01]  44%|████▍     | 73/166 [31:30<39:24, 25.42s/epoch, loss=0.567, accuracy=0.864, val_loss=0.794, val_accuracy=0.795, lr=0.01] 45%|████▍     | 74/166 [31:55<39:04, 25.48s/epoch, loss=0.564, accuracy=0.865, val_loss=1.08, val_accuracy=0.716, lr=0.01]  45%|████▌     | 75/166 [32:21<38:42, 25.52s/epoch, loss=0.563, accuracy=0.865, val_loss=0.77, val_accuracy=0.8, lr=0.01]   46%|████▌     | 76/166 [32:46<38:18, 25.54s/epoch, loss=0.559, accuracy=0.867, val_loss=0.715, val_accuracy=0.824, lr=0.01] 46%|████▋     | 77/166 [33:12<37:58, 25.60s/epoch, loss=0.554, accuracy=0.87, val_loss=0.821, val_accuracy=0.793, lr=0.01]  47%|████▋     | 78/166 [33:38<37:34, 25.62s/epoch, loss=0.556, accuracy=0.87, val_loss=0.854, val_accuracy=0.78, lr=0.01]  48%|████▊     | 79/166 [34:03<37:04, 25.57s/epoch, loss=0.55, accuracy=0.874, val_loss=0.835, val_accuracy=0.777, lr=0.01] 48%|████▊     | 80/166 [34:29<36:43, 25.62s/epoch, loss=0.551, accuracy=0.874, val_loss=0.735, val_accuracy=0.812, lr=0.01] 49%|████▉     | 81/166 [34:55<36:21, 25.67s/epoch, loss=0.551, accuracy=0.873, val_loss=0.786, val_accuracy=0.801, lr=0.01] 49%|████▉     | 82/166 [35:20<35:53, 25.64s/epoch, loss=0.551, accuracy=0.875, val_loss=0.763, val_accuracy=0.803, lr=0.01] 50%|█████     | 83/166 [35:46<35:23, 25.58s/epoch, loss=0.552, accuracy=0.876, val_loss=0.937, val_accuracy=0.758, lr=0.01] 51%|█████     | 84/166 [36:11<34:58, 25.59s/epoch, loss=0.549, accuracy=0.878, val_loss=0.856, val_accuracy=0.775, lr=0.01] 51%|█████     | 85/166 [36:37<34:24, 25.49s/epoch, loss=0.551, accuracy=0.877, val_loss=0.708, val_accuracy=0.827, lr=0.01] 52%|█████▏    | 86/166 [37:02<34:02, 25.53s/epoch, loss=0.548, accuracy=0.878, val_loss=0.864, val_accuracy=0.78, lr=0.01]  52%|█████▏    | 87/166 [37:28<33:32, 25.48s/epoch, loss=0.545, accuracy=0.881, val_loss=1.04, val_accuracy=0.727, lr=0.01] 53%|█████▎    | 88/166 [37:53<33:05, 25.46s/epoch, loss=0.552, accuracy=0.878, val_loss=0.821, val_accuracy=0.808, lr=0.01] 54%|█████▎    | 89/166 [38:18<32:39, 25.45s/epoch, loss=0.549, accuracy=0.882, val_loss=0.885, val_accuracy=0.773, lr=0.01] 54%|█████▍    | 90/166 [38:44<32:13, 25.44s/epoch, loss=0.548, accuracy=0.882, val_loss=1.28, val_accuracy=0.711, lr=0.01]  55%|█████▍    | 91/166 [39:10<31:52, 25.50s/epoch, loss=0.549, accuracy=0.882, val_loss=0.886, val_accuracy=0.782, lr=0.01] 55%|█████▌    | 92/166 [39:35<31:27, 25.51s/epoch, loss=0.548, accuracy=0.882, val_loss=0.815, val_accuracy=0.805, lr=0.01] 56%|█████▌    | 93/166 [40:01<31:03, 25.52s/epoch, loss=0.546, accuracy=0.884, val_loss=0.817, val_accuracy=0.803, lr=0.01] 57%|█████▋    | 94/166 [40:26<30:36, 25.51s/epoch, loss=0.551, accuracy=0.883, val_loss=0.855, val_accuracy=0.794, lr=0.01] 57%|█████▋    | 95/166 [40:52<30:10, 25.51s/epoch, loss=0.55, accuracy=0.883, val_loss=0.919, val_accuracy=0.776, lr=0.01]  58%|█████▊    | 96/166 [41:17<29:45, 25.50s/epoch, loss=0.548, accuracy=0.883, val_loss=0.831, val_accuracy=0.804, lr=0.01] 58%|█████▊    | 97/166 [41:42<29:14, 25.43s/epoch, loss=0.547, accuracy=0.884, val_loss=0.98, val_accuracy=0.763, lr=0.01]  59%|█████▉    | 98/166 [42:08<28:55, 25.52s/epoch, loss=0.549, accuracy=0.885, val_loss=0.765, val_accuracy=0.807, lr=0.01] 60%|█████▉    | 99/166 [42:33<28:28, 25.50s/epoch, loss=0.548, accuracy=0.885, val_loss=0.858, val_accuracy=0.789, lr=0.01] 60%|██████    | 100/166 [42:59<28:07, 25.56s/epoch, loss=0.551, accuracy=0.885, val_loss=0.755, val_accuracy=0.82, lr=0.01] 61%|██████    | 101/166 [43:25<27:39, 25.53s/epoch, loss=0.474, accuracy=0.911, val_loss=0.533, val_accuracy=0.891, lr=0.001] 61%|██████▏   | 102/166 [43:50<27:17, 25.59s/epoch, loss=0.419, accuracy=0.93, val_loss=0.519, val_accuracy=0.896, lr=0.001]  62%|██████▏   | 103/166 [44:16<26:49, 25.55s/epoch, loss=0.401, accuracy=0.932, val_loss=0.504, val_accuracy=0.898, lr=0.001] 63%|██████▎   | 104/166 [44:41<26:21, 25.51s/epoch, loss=0.383, accuracy=0.938, val_loss=0.509, val_accuracy=0.894, lr=0.001] 63%|██████▎   | 105/166 [45:07<25:53, 25.46s/epoch, loss=0.37, accuracy=0.941, val_loss=0.496, val_accuracy=0.898, lr=0.001]  64%|██████▍   | 106/166 [45:32<25:24, 25.40s/epoch, loss=0.357, accuracy=0.942, val_loss=0.483, val_accuracy=0.902, lr=0.001] 64%|██████▍   | 107/166 [45:57<24:56, 25.37s/epoch, loss=0.348, accuracy=0.944, val_loss=0.479, val_accuracy=0.898, lr=0.001] 65%|██████▌   | 108/166 [46:23<24:31, 25.37s/epoch, loss=0.335, accuracy=0.947, val_loss=0.48, val_accuracy=0.899, lr=0.001]  66%|██████▌   | 109/166 [46:48<24:04, 25.34s/epoch, loss=0.328, accuracy=0.947, val_loss=0.467, val_accuracy=0.9, lr=0.001]  66%|██████▋   | 110/166 [47:13<23:38, 25.33s/epoch, loss=0.316, accuracy=0.95, val_loss=0.467, val_accuracy=0.903, lr=0.001] 67%|██████▋   | 111/166 [47:38<23:11, 25.29s/epoch, loss=0.309, accuracy=0.952, val_loss=0.462, val_accuracy=0.902, lr=0.001] 67%|██████▋   | 112/166 [48:04<22:48, 25.34s/epoch, loss=0.302, accuracy=0.953, val_loss=0.473, val_accuracy=0.901, lr=0.001] 68%|██████▊   | 113/166 [48:29<22:21, 25.32s/epoch, loss=0.297, accuracy=0.952, val_loss=0.467, val_accuracy=0.9, lr=0.001]   69%|██████▊   | 114/166 [48:54<21:53, 25.27s/epoch, loss=0.289, accuracy=0.954, val_loss=0.451, val_accuracy=0.904, lr=0.001] 69%|██████▉   | 115/166 [49:19<21:27, 25.25s/epoch, loss=0.28, accuracy=0.955, val_loss=0.457, val_accuracy=0.902, lr=0.001]  70%|██████▉   | 116/166 [49:45<21:03, 25.27s/epoch, loss=0.277, accuracy=0.955, val_loss=0.456, val_accuracy=0.902, lr=0.001] 70%|███████   | 117/166 [50:10<20:37, 25.25s/epoch, loss=0.271, accuracy=0.956, val_loss=0.465, val_accuracy=0.9, lr=0.001]   71%|███████   | 118/166 [50:35<20:11, 25.25s/epoch, loss=0.265, accuracy=0.958, val_loss=0.463, val_accuracy=0.898, lr=0.001] 72%|███████▏  | 119/166 [51:00<19:45, 25.22s/epoch, loss=0.259, accuracy=0.958, val_loss=0.487, val_accuracy=0.891, lr=0.001] 72%|███████▏  | 120/166 [51:25<19:19, 25.21s/epoch, loss=0.258, accuracy=0.958, val_loss=0.461, val_accuracy=0.898, lr=0.001] 73%|███████▎  | 121/166 [51:51<18:57, 25.28s/epoch, loss=0.25, accuracy=0.959, val_loss=0.456, val_accuracy=0.898, lr=0.001]  73%|███████▎  | 122/166 [52:16<18:33, 25.30s/epoch, loss=0.25, accuracy=0.958, val_loss=0.45, val_accuracy=0.897, lr=0.001]  74%|███████▍  | 123/166 [52:42<18:08, 25.31s/epoch, loss=0.243, accuracy=0.961, val_loss=0.442, val_accuracy=0.9, lr=0.001] 75%|███████▍  | 124/166 [53:07<17:44, 25.35s/epoch, loss=0.24, accuracy=0.96, val_loss=0.467, val_accuracy=0.89, lr=0.001]  75%|███████▌  | 125/166 [53:32<17:19, 25.35s/epoch, loss=0.237, accuracy=0.961, val_loss=0.482, val_accuracy=0.89, lr=0.001] 76%|███████▌  | 126/166 [53:58<16:55, 25.40s/epoch, loss=0.236, accuracy=0.961, val_loss=0.459, val_accuracy=0.893, lr=0.001] 77%|███████▋  | 127/166 [54:23<16:30, 25.39s/epoch, loss=0.233, accuracy=0.96, val_loss=0.474, val_accuracy=0.89, lr=0.001]   77%|███████▋  | 128/166 [54:49<16:03, 25.34s/epoch, loss=0.23, accuracy=0.962, val_loss=0.478, val_accuracy=0.889, lr=0.001] 78%|███████▊  | 129/166 [55:14<15:37, 25.33s/epoch, loss=0.228, accuracy=0.962, val_loss=0.489, val_accuracy=0.885, lr=0.001] 78%|███████▊  | 130/166 [55:39<15:10, 25.29s/epoch, loss=0.227, accuracy=0.96, val_loss=0.45, val_accuracy=0.898, lr=0.001]   79%|███████▉  | 131/166 [56:04<14:44, 25.26s/epoch, loss=0.226, accuracy=0.962, val_loss=0.483, val_accuracy=0.884, lr=0.001] 80%|███████▉  | 132/166 [56:30<14:19, 25.28s/epoch, loss=0.221, accuracy=0.962, val_loss=0.473, val_accuracy=0.885, lr=0.001] 80%|████████  | 133/166 [56:54<13:51, 25.19s/epoch, loss=0.221, accuracy=0.962, val_loss=0.502, val_accuracy=0.885, lr=0.001] 81%|████████  | 134/166 [57:20<13:24, 25.15s/epoch, loss=0.203, accuracy=0.968, val_loss=0.408, val_accuracy=0.906, lr=1e-04] 81%|████████▏ | 135/166 [57:45<12:59, 25.13s/epoch, loss=0.189, accuracy=0.974, val_loss=0.403, val_accuracy=0.908, lr=1e-04] 82%|████████▏ | 136/166 [58:10<12:35, 25.19s/epoch, loss=0.184, accuracy=0.976, val_loss=0.403, val_accuracy=0.909, lr=1e-04] 83%|████████▎ | 137/166 [58:35<12:08, 25.12s/epoch, loss=0.183, accuracy=0.977, val_loss=0.402, val_accuracy=0.911, lr=1e-04] 83%|████████▎ | 138/166 [59:00<11:44, 25.17s/epoch, loss=0.18, accuracy=0.978, val_loss=0.404, val_accuracy=0.91, lr=1e-04]   84%|████████▎ | 139/166 [59:25<11:18, 25.14s/epoch, loss=0.178, accuracy=0.977, val_loss=0.4, val_accuracy=0.911, lr=1e-04] 84%|████████▍ | 140/166 [59:51<10:54, 25.17s/epoch, loss=0.175, accuracy=0.979, val_loss=0.405, val_accuracy=0.909, lr=1e-04] 85%|████████▍ | 141/166 [1:00:16<10:28, 25.15s/epoch, loss=0.175, accuracy=0.979, val_loss=0.403, val_accuracy=0.91, lr=1e-04] 86%|████████▌ | 142/166 [1:00:41<10:05, 25.22s/epoch, loss=0.172, accuracy=0.98, val_loss=0.406, val_accuracy=0.909, lr=1e-04] 86%|████████▌ | 143/166 [1:01:06<09:39, 25.21s/epoch, loss=0.172, accuracy=0.98, val_loss=0.404, val_accuracy=0.909, lr=1e-04] 87%|████████▋ | 144/166 [1:01:31<09:15, 25.24s/epoch, loss=0.17, accuracy=0.98, val_loss=0.408, val_accuracy=0.909, lr=1e-04]  87%|████████▋ | 145/166 [1:01:57<08:49, 25.20s/epoch, loss=0.169, accuracy=0.981, val_loss=0.406, val_accuracy=0.911, lr=1e-04] 88%|████████▊ | 146/166 [1:02:22<08:25, 25.25s/epoch, loss=0.168, accuracy=0.982, val_loss=0.409, val_accuracy=0.908, lr=1e-04] 89%|████████▊ | 147/166 [1:02:47<08:00, 25.29s/epoch, loss=0.166, accuracy=0.982, val_loss=0.408, val_accuracy=0.91, lr=1e-04]  89%|████████▉ | 148/166 [1:03:13<07:34, 25.26s/epoch, loss=0.167, accuracy=0.981, val_loss=0.407, val_accuracy=0.908, lr=1e-04] 90%|████████▉ | 149/166 [1:03:38<07:10, 25.33s/epoch, loss=0.166, accuracy=0.982, val_loss=0.408, val_accuracy=0.909, lr=1e-04] 90%|█████████ | 150/166 [1:04:03<06:44, 25.27s/epoch, loss=0.164, accuracy=0.983, val_loss=0.409, val_accuracy=0.91, lr=1e-04]  91%|█████████ | 151/166 [1:04:29<06:19, 25.29s/epoch, loss=0.162, accuracy=0.983, val_loss=0.409, val_accuracy=0.91, lr=5e-5]  92%|█████████▏| 152/166 [1:04:54<05:54, 25.30s/epoch, loss=0.162, accuracy=0.983, val_loss=0.408, val_accuracy=0.909, lr=5e-5] 92%|█████████▏| 153/166 [1:05:19<05:27, 25.22s/epoch, loss=0.162, accuracy=0.983, val_loss=0.408, val_accuracy=0.909, lr=5e-5] 93%|█████████▎| 154/166 [1:05:44<05:01, 25.14s/epoch, loss=0.159, accuracy=0.984, val_loss=0.408, val_accuracy=0.909, lr=5e-5] 93%|█████████▎| 155/166 [1:06:09<04:36, 25.09s/epoch, loss=0.161, accuracy=0.983, val_loss=0.409, val_accuracy=0.91, lr=5e-5]  94%|█████████▍| 156/166 [1:06:34<04:10, 25.07s/epoch, loss=0.159, accuracy=0.983, val_loss=0.409, val_accuracy=0.909, lr=5e-5] 95%|█████████▍| 157/166 [1:06:59<03:45, 25.11s/epoch, loss=0.159, accuracy=0.984, val_loss=0.408, val_accuracy=0.909, lr=5e-5] 95%|█████████▌| 158/166 [1:07:24<03:20, 25.10s/epoch, loss=0.159, accuracy=0.983, val_loss=0.41, val_accuracy=0.909, lr=5e-5]  96%|█████████▌| 159/166 [1:07:49<02:55, 25.08s/epoch, loss=0.158, accuracy=0.984, val_loss=0.41, val_accuracy=0.91, lr=5e-5]  96%|█████████▋| 160/166 [1:08:14<02:30, 25.08s/epoch, loss=0.157, accuracy=0.985, val_loss=0.41, val_accuracy=0.909, lr=5e-5] 97%|█████████▋| 161/166 [1:08:39<02:05, 25.11s/epoch, loss=0.157, accuracy=0.985, val_loss=0.409, val_accuracy=0.908, lr=5e-5] 98%|█████████▊| 162/166 [1:09:04<01:40, 25.11s/epoch, loss=0.157, accuracy=0.984, val_loss=0.409, val_accuracy=0.909, lr=5e-5] 98%|█████████▊| 163/166 [1:09:30<01:15, 25.08s/epoch, loss=0.156, accuracy=0.985, val_loss=0.408, val_accuracy=0.908, lr=5e-5] 99%|█████████▉| 164/166 [1:09:55<00:50, 25.08s/epoch, loss=0.156, accuracy=0.984, val_loss=0.41, val_accuracy=0.908, lr=5e-5]  99%|█████████▉| 165/166 [1:10:20<00:25, 25.05s/epoch, loss=0.156, accuracy=0.984, val_loss=0.41, val_accuracy=0.909, lr=5e-5]100%|██████████| 166/166 [1:10:45<00:00, 25.07s/epoch, loss=0.156, accuracy=0.985, val_loss=0.41, val_accuracy=0.908, lr=5e-5]100%|██████████| 166/166 [1:10:45<00:00, 25.57s/epoch, loss=0.156, accuracy=0.985, val_loss=0.41, val_accuracy=0.908, lr=5e-5]
Using real-time data augmentation.
Only one model saved

Loading model: 09_03_cifar10_ResNet20v1.h5
Test score: 0.41035979986190796
Test accuracy: 0.90829998254776


* * * Run SGD for ID = 9_4. * * *


2024-03-13 01:02:18.778265: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-13 01:02:25.428442: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-13 01:02:25.429845: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-13 01:02:25.474461: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:3b:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-13 01:02:25.474505: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-13 01:02:25.481590: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-13 01:02:25.481658: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-13 01:02:25.486426: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-13 01:02:25.488371: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-13 01:02:25.494797: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-13 01:02:25.497989: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-13 01:02:25.505110: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-13 01:02:25.505742: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-13 01:02:25.505825: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-13 01:02:26.785265: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-13 01:02:26.786221: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-13 01:02:26.786985: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:3b:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-13 01:02:26.787019: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-13 01:02:26.787056: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-13 01:02:26.787071: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-13 01:02:26.787085: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-13 01:02:26.787099: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-13 01:02:26.787113: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-13 01:02:26.787136: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-13 01:02:26.787150: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-13 01:02:26.787693: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-13 01:02:26.787730: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-13 01:02:27.454584: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-13 01:02:27.454638: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-13 01:02:27.454649: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-13 01:02:27.455730: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:3b:00.0, compute capability: 6.1)
{'id': '09_04', 'seed': 4, 'out_folder': 'results/epoch_budget_2', 'batch_size': 128, 'epochs': 166, 'validation_split': 0.0, 'checkpointing': False, 'checkpoint_every': -1, 'hold_out_validation_split': 0.0, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'bootstrapping': False, 'num_classes': 10, 'SSE_lr': False, 'test_time_augmentation': False, 'debug': False, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
y_train shape: (50000, 10)
x_val shape: (10000, 32, 32, 3)
y_val shape: (10000, 10)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/166 [00:00<?, ?epoch/s]2024-03-13 01:02:28.121810: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-13 01:02:28.133988: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2100000000 Hz
2024-03-13 01:02:30.183439: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-13 01:02:30.417600: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-13 01:02:31.331118: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-13 01:02:31.374640: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/166 [00:58<2:40:52, 58.50s/epoch, loss=2.8, accuracy=0.418, val_loss=2.26, val_accuracy=0.351, lr=0.1]  1%|          | 2/166 [01:24<1:47:00, 39.15s/epoch, loss=1.43, accuracy=0.608, val_loss=1.72, val_accuracy=0.51, lr=0.1]  2%|▏         | 3/166 [01:49<1:29:23, 32.90s/epoch, loss=1.29, accuracy=0.671, val_loss=4.68, val_accuracy=0.319, lr=0.1]  2%|▏         | 4/166 [02:15<1:21:06, 30.04s/epoch, loss=1.24, accuracy=0.698, val_loss=1.85, val_accuracy=0.534, lr=0.1]  3%|▎         | 5/166 [02:40<1:16:20, 28.45s/epoch, loss=1.23, accuracy=0.709, val_loss=2.38, val_accuracy=0.341, lr=0.1]  4%|▎         | 6/166 [03:06<1:13:19, 27.50s/epoch, loss=1.22, accuracy=0.72, val_loss=2.02, val_accuracy=0.491, lr=0.1]   4%|▍         | 7/166 [03:32<1:11:13, 26.87s/epoch, loss=1.21, accuracy=0.724, val_loss=2.34, val_accuracy=0.466, lr=0.1]  5%|▍         | 8/166 [03:57<1:09:36, 26.43s/epoch, loss=1.21, accuracy=0.727, val_loss=2.15, val_accuracy=0.449, lr=0.1]  5%|▌         | 9/166 [04:23<1:08:25, 26.15s/epoch, loss=1.2, accuracy=0.73, val_loss=1.63, val_accuracy=0.561, lr=0.1]    6%|▌         | 10/166 [04:48<1:07:26, 25.94s/epoch, loss=1.2, accuracy=0.732, val_loss=1.88, val_accuracy=0.547, lr=0.1]  7%|▋         | 11/166 [05:14<1:06:48, 25.86s/epoch, loss=1.19, accuracy=0.734, val_loss=1.95, val_accuracy=0.513, lr=0.1]  7%|▋         | 12/166 [05:39<1:06:02, 25.73s/epoch, loss=1.18, accuracy=0.738, val_loss=1.7, val_accuracy=0.567, lr=0.1]   8%|▊         | 13/166 [06:05<1:05:33, 25.71s/epoch, loss=1.18, accuracy=0.74, val_loss=1.76, val_accuracy=0.553, lr=0.1]  8%|▊         | 14/166 [06:30<1:04:57, 25.64s/epoch, loss=1.18, accuracy=0.741, val_loss=1.87, val_accuracy=0.557, lr=0.1]  9%|▉         | 15/166 [06:56<1:04:23, 25.59s/epoch, loss=1.18, accuracy=0.742, val_loss=2.19, val_accuracy=0.483, lr=0.1] 10%|▉         | 16/166 [07:21<1:04:01, 25.61s/epoch, loss=1.17, accuracy=0.745, val_loss=2.18, val_accuracy=0.48, lr=0.1]  10%|█         | 17/166 [07:47<1:03:34, 25.60s/epoch, loss=1.17, accuracy=0.745, val_loss=1.93, val_accuracy=0.5, lr=0.1]  11%|█         | 18/166 [08:13<1:03:02, 25.56s/epoch, loss=1.16, accuracy=0.748, val_loss=1.9, val_accuracy=0.509, lr=0.1] 11%|█▏        | 19/166 [08:38<1:02:39, 25.58s/epoch, loss=1.17, accuracy=0.747, val_loss=3.04, val_accuracy=0.316, lr=0.1] 12%|█▏        | 20/166 [09:04<1:02:16, 25.60s/epoch, loss=1.17, accuracy=0.748, val_loss=1.58, val_accuracy=0.608, lr=0.1] 13%|█▎        | 21/166 [09:29<1:01:47, 25.57s/epoch, loss=1.16, accuracy=0.747, val_loss=2.19, val_accuracy=0.452, lr=0.1] 13%|█▎        | 22/166 [09:55<1:01:18, 25.55s/epoch, loss=1.16, accuracy=0.75, val_loss=1.54, val_accuracy=0.614, lr=0.1]  14%|█▍        | 23/166 [10:20<1:00:52, 25.54s/epoch, loss=1.16, accuracy=0.748, val_loss=3.23, val_accuracy=0.224, lr=0.1] 14%|█▍        | 24/166 [10:46<1:00:27, 25.55s/epoch, loss=1.15, accuracy=0.752, val_loss=2.91, val_accuracy=0.361, lr=0.1] 15%|█▌        | 25/166 [11:12<1:00:11, 25.61s/epoch, loss=1.16, accuracy=0.749, val_loss=1.74, val_accuracy=0.537, lr=0.1] 16%|█▌        | 26/166 [11:37<59:49, 25.64s/epoch, loss=1.15, accuracy=0.752, val_loss=2.25, val_accuracy=0.382, lr=0.1]   16%|█▋        | 27/166 [12:03<59:23, 25.64s/epoch, loss=1.15, accuracy=0.753, val_loss=2.81, val_accuracy=0.311, lr=0.1] 17%|█▋        | 28/166 [12:28<58:50, 25.58s/epoch, loss=1.15, accuracy=0.755, val_loss=1.7, val_accuracy=0.577, lr=0.1]  17%|█▋        | 29/166 [12:54<58:27, 25.60s/epoch, loss=1.15, accuracy=0.752, val_loss=2.96, val_accuracy=0.362, lr=0.1] 18%|█▊        | 30/166 [13:20<58:03, 25.61s/epoch, loss=1.15, accuracy=0.751, val_loss=1.92, val_accuracy=0.526, lr=0.1] 19%|█▊        | 31/166 [13:45<57:37, 25.61s/epoch, loss=1.15, accuracy=0.753, val_loss=2.08, val_accuracy=0.482, lr=0.1] 19%|█▉        | 32/166 [14:11<57:08, 25.59s/epoch, loss=1.14, accuracy=0.753, val_loss=1.66, val_accuracy=0.574, lr=0.1] 20%|█▉        | 33/166 [14:36<56:37, 25.54s/epoch, loss=1.15, accuracy=0.753, val_loss=1.51, val_accuracy=0.627, lr=0.1] 20%|██        | 34/166 [15:02<56:07, 25.51s/epoch, loss=1.15, accuracy=0.752, val_loss=1.68, val_accuracy=0.571, lr=0.1] 21%|██        | 35/166 [15:27<55:44, 25.53s/epoch, loss=1.14, accuracy=0.754, val_loss=2.05, val_accuracy=0.47, lr=0.1]  22%|██▏       | 36/166 [15:53<55:15, 25.51s/epoch, loss=1.14, accuracy=0.755, val_loss=1.81, val_accuracy=0.512, lr=0.1] 22%|██▏       | 37/166 [16:18<54:55, 25.55s/epoch, loss=1.14, accuracy=0.757, val_loss=1.78, val_accuracy=0.541, lr=0.1] 23%|██▎       | 38/166 [16:44<54:31, 25.56s/epoch, loss=1.14, accuracy=0.754, val_loss=2.38, val_accuracy=0.481, lr=0.1] 23%|██▎       | 39/166 [17:09<54:03, 25.54s/epoch, loss=1.13, accuracy=0.757, val_loss=1.64, val_accuracy=0.571, lr=0.1] 24%|██▍       | 40/166 [17:35<53:38, 25.55s/epoch, loss=1.13, accuracy=0.757, val_loss=2.01, val_accuracy=0.461, lr=0.1] 25%|██▍       | 41/166 [18:01<53:19, 25.60s/epoch, loss=1.13, accuracy=0.756, val_loss=1.51, val_accuracy=0.636, lr=0.1] 25%|██▌       | 42/166 [18:26<52:41, 25.49s/epoch, loss=1.14, accuracy=0.756, val_loss=1.85, val_accuracy=0.538, lr=0.1] 26%|██▌       | 43/166 [18:52<52:16, 25.50s/epoch, loss=1.13, accuracy=0.755, val_loss=1.47, val_accuracy=0.639, lr=0.1] 27%|██▋       | 44/166 [19:17<51:53, 25.52s/epoch, loss=1.13, accuracy=0.757, val_loss=1.85, val_accuracy=0.582, lr=0.1] 27%|██▋       | 45/166 [19:43<51:36, 25.59s/epoch, loss=1.14, accuracy=0.758, val_loss=1.81, val_accuracy=0.511, lr=0.1] 28%|██▊       | 46/166 [20:09<51:19, 25.66s/epoch, loss=1.14, accuracy=0.755, val_loss=1.78, val_accuracy=0.551, lr=0.1] 28%|██▊       | 47/166 [20:34<50:49, 25.63s/epoch, loss=1.13, accuracy=0.758, val_loss=1.55, val_accuracy=0.609, lr=0.1] 29%|██▉       | 48/166 [21:00<50:29, 25.68s/epoch, loss=1.13, accuracy=0.756, val_loss=2.24, val_accuracy=0.444, lr=0.1] 30%|██▉       | 49/166 [21:26<50:06, 25.70s/epoch, loss=1.13, accuracy=0.756, val_loss=3.27, val_accuracy=0.329, lr=0.1] 30%|███       | 50/166 [21:51<49:36, 25.66s/epoch, loss=1.13, accuracy=0.756, val_loss=3.2, val_accuracy=0.251, lr=0.1]  31%|███       | 51/166 [22:17<49:06, 25.62s/epoch, loss=1.13, accuracy=0.759, val_loss=2.48, val_accuracy=0.414, lr=0.1] 31%|███▏      | 52/166 [22:42<48:32, 25.55s/epoch, loss=1.12, accuracy=0.758, val_loss=2.05, val_accuracy=0.564, lr=0.1] 32%|███▏      | 53/166 [23:08<48:08, 25.56s/epoch, loss=1.12, accuracy=0.756, val_loss=1.77, val_accuracy=0.558, lr=0.1] 33%|███▎      | 54/166 [23:34<47:49, 25.62s/epoch, loss=1.12, accuracy=0.756, val_loss=3.04, val_accuracy=0.366, lr=0.1] 33%|███▎      | 55/166 [23:59<47:24, 25.63s/epoch, loss=1.12, accuracy=0.76, val_loss=1.61, val_accuracy=0.555, lr=0.1]  34%|███▎      | 56/166 [24:25<46:56, 25.61s/epoch, loss=1.13, accuracy=0.756, val_loss=2.64, val_accuracy=0.361, lr=0.1] 34%|███▍      | 57/166 [24:50<46:28, 25.58s/epoch, loss=1.12, accuracy=0.758, val_loss=2.25, val_accuracy=0.398, lr=0.1] 35%|███▍      | 58/166 [25:16<46:01, 25.57s/epoch, loss=1.13, accuracy=0.755, val_loss=2.03, val_accuracy=0.516, lr=0.1] 36%|███▌      | 59/166 [25:42<45:41, 25.63s/epoch, loss=1.12, accuracy=0.758, val_loss=1.61, val_accuracy=0.574, lr=0.1] 36%|███▌      | 60/166 [26:07<45:12, 25.59s/epoch, loss=1.12, accuracy=0.76, val_loss=1.9, val_accuracy=0.528, lr=0.1]   37%|███▋      | 61/166 [26:33<44:42, 25.55s/epoch, loss=1.12, accuracy=0.759, val_loss=3.75, val_accuracy=0.262, lr=0.1] 37%|███▋      | 62/166 [26:58<44:16, 25.55s/epoch, loss=1.12, accuracy=0.761, val_loss=1.71, val_accuracy=0.525, lr=0.1] 38%|███▊      | 63/166 [27:24<43:50, 25.53s/epoch, loss=1.11, accuracy=0.76, val_loss=2.35, val_accuracy=0.399, lr=0.1]  39%|███▊      | 64/166 [27:49<43:20, 25.50s/epoch, loss=1.12, accuracy=0.759, val_loss=1.65, val_accuracy=0.591, lr=0.1] 39%|███▉      | 65/166 [28:14<42:49, 25.44s/epoch, loss=1.12, accuracy=0.758, val_loss=1.88, val_accuracy=0.557, lr=0.1] 40%|███▉      | 66/166 [28:40<42:28, 25.49s/epoch, loss=1.11, accuracy=0.759, val_loss=2.15, val_accuracy=0.432, lr=0.1] 40%|████      | 67/166 [29:05<42:03, 25.49s/epoch, loss=1.12, accuracy=0.758, val_loss=1.54, val_accuracy=0.633, lr=0.1] 41%|████      | 68/166 [29:31<41:39, 25.50s/epoch, loss=0.901, accuracy=0.819, val_loss=0.975, val_accuracy=0.775, lr=0.01] 42%|████▏     | 69/166 [29:56<41:10, 25.47s/epoch, loss=0.728, accuracy=0.849, val_loss=0.886, val_accuracy=0.783, lr=0.01] 42%|████▏     | 70/166 [30:22<40:46, 25.48s/epoch, loss=0.645, accuracy=0.857, val_loss=0.734, val_accuracy=0.819, lr=0.01] 43%|████▎     | 71/166 [30:47<40:21, 25.48s/epoch, loss=0.597, accuracy=0.864, val_loss=0.871, val_accuracy=0.775, lr=0.01] 43%|████▎     | 72/166 [31:13<39:52, 25.45s/epoch, loss=0.581, accuracy=0.863, val_loss=0.746, val_accuracy=0.802, lr=0.01] 44%|████▍     | 73/166 [31:38<39:27, 25.45s/epoch, loss=0.574, accuracy=0.862, val_loss=0.805, val_accuracy=0.783, lr=0.01] 45%|████▍     | 74/166 [32:04<39:05, 25.49s/epoch, loss=0.563, accuracy=0.867, val_loss=1.01, val_accuracy=0.732, lr=0.01]  45%|████▌     | 75/166 [32:30<38:47, 25.58s/epoch, loss=0.56, accuracy=0.866, val_loss=0.721, val_accuracy=0.812, lr=0.01] 46%|████▌     | 76/166 [32:55<38:29, 25.66s/epoch, loss=0.559, accuracy=0.866, val_loss=0.668, val_accuracy=0.832, lr=0.01] 46%|████▋     | 77/166 [33:21<37:58, 25.60s/epoch, loss=0.558, accuracy=0.868, val_loss=0.898, val_accuracy=0.765, lr=0.01] 47%|████▋     | 78/166 [33:47<37:34, 25.62s/epoch, loss=0.556, accuracy=0.869, val_loss=0.856, val_accuracy=0.783, lr=0.01] 48%|████▊     | 79/166 [34:12<37:09, 25.63s/epoch, loss=0.555, accuracy=0.872, val_loss=0.783, val_accuracy=0.796, lr=0.01] 48%|████▊     | 80/166 [34:38<36:40, 25.59s/epoch, loss=0.553, accuracy=0.872, val_loss=0.855, val_accuracy=0.781, lr=0.01] 49%|████▉     | 81/166 [35:03<36:17, 25.61s/epoch, loss=0.558, accuracy=0.873, val_loss=0.878, val_accuracy=0.783, lr=0.01] 49%|████▉     | 82/166 [35:29<35:51, 25.62s/epoch, loss=0.555, accuracy=0.874, val_loss=0.748, val_accuracy=0.818, lr=0.01] 50%|█████     | 83/166 [35:54<35:21, 25.56s/epoch, loss=0.553, accuracy=0.875, val_loss=0.888, val_accuracy=0.786, lr=0.01] 51%|█████     | 84/166 [36:20<34:51, 25.51s/epoch, loss=0.55, accuracy=0.878, val_loss=0.724, val_accuracy=0.823, lr=0.01]  51%|█████     | 85/166 [36:45<34:23, 25.47s/epoch, loss=0.55, accuracy=0.878, val_loss=0.762, val_accuracy=0.814, lr=0.01] 52%|█████▏    | 86/166 [37:11<33:58, 25.49s/epoch, loss=0.559, accuracy=0.875, val_loss=0.957, val_accuracy=0.767, lr=0.01] 52%|█████▏    | 87/166 [37:36<33:35, 25.51s/epoch, loss=0.551, accuracy=0.879, val_loss=0.948, val_accuracy=0.768, lr=0.01] 53%|█████▎    | 88/166 [38:02<33:13, 25.55s/epoch, loss=0.547, accuracy=0.88, val_loss=1.14, val_accuracy=0.718, lr=0.01]   54%|█████▎    | 89/166 [38:27<32:43, 25.50s/epoch, loss=0.548, accuracy=0.88, val_loss=0.851, val_accuracy=0.786, lr=0.01] 54%|█████▍    | 90/166 [38:53<32:18, 25.51s/epoch, loss=0.549, accuracy=0.879, val_loss=0.812, val_accuracy=0.799, lr=0.01] 55%|█████▍    | 91/166 [39:18<31:53, 25.51s/epoch, loss=0.551, accuracy=0.88, val_loss=0.761, val_accuracy=0.81, lr=0.01]   55%|█████▌    | 92/166 [39:44<31:31, 25.57s/epoch, loss=0.552, accuracy=0.881, val_loss=1.17, val_accuracy=0.715, lr=0.01] 56%|█████▌    | 93/166 [40:10<31:09, 25.61s/epoch, loss=0.55, accuracy=0.882, val_loss=0.719, val_accuracy=0.832, lr=0.01] 57%|█████▋    | 94/166 [40:35<30:38, 25.54s/epoch, loss=0.551, accuracy=0.882, val_loss=0.814, val_accuracy=0.812, lr=0.01] 57%|█████▋    | 95/166 [41:01<30:11, 25.52s/epoch, loss=0.546, accuracy=0.883, val_loss=0.99, val_accuracy=0.764, lr=0.01]  58%|█████▊    | 96/166 [41:26<29:44, 25.49s/epoch, loss=0.552, accuracy=0.882, val_loss=0.857, val_accuracy=0.785, lr=0.01] 58%|█████▊    | 97/166 [41:52<29:19, 25.51s/epoch, loss=0.547, accuracy=0.885, val_loss=0.892, val_accuracy=0.774, lr=0.01] 59%|█████▉    | 98/166 [42:17<28:54, 25.51s/epoch, loss=0.551, accuracy=0.883, val_loss=0.849, val_accuracy=0.784, lr=0.01] 60%|█████▉    | 99/166 [42:42<28:25, 25.45s/epoch, loss=0.553, accuracy=0.884, val_loss=0.821, val_accuracy=0.805, lr=0.01] 60%|██████    | 100/166 [43:08<28:02, 25.49s/epoch, loss=0.549, accuracy=0.885, val_loss=0.793, val_accuracy=0.81, lr=0.01] 61%|██████    | 101/166 [43:34<27:40, 25.54s/epoch, loss=0.471, accuracy=0.914, val_loss=0.536, val_accuracy=0.888, lr=0.001] 61%|██████▏   | 102/166 [43:59<27:16, 25.57s/epoch, loss=0.421, accuracy=0.927, val_loss=0.521, val_accuracy=0.895, lr=0.001] 62%|██████▏   | 103/166 [44:25<26:50, 25.57s/epoch, loss=0.399, accuracy=0.933, val_loss=0.511, val_accuracy=0.895, lr=0.001] 63%|██████▎   | 104/166 [44:50<26:25, 25.57s/epoch, loss=0.385, accuracy=0.936, val_loss=0.509, val_accuracy=0.895, lr=0.001] 63%|██████▎   | 105/166 [45:16<25:59, 25.56s/epoch, loss=0.368, accuracy=0.94, val_loss=0.496, val_accuracy=0.898, lr=0.001]  64%|██████▍   | 106/166 [45:41<25:33, 25.56s/epoch, loss=0.359, accuracy=0.941, val_loss=0.491, val_accuracy=0.896, lr=0.001] 64%|██████▍   | 107/166 [46:07<25:05, 25.52s/epoch, loss=0.35, accuracy=0.942, val_loss=0.488, val_accuracy=0.897, lr=0.001]  65%|██████▌   | 108/166 [46:32<24:34, 25.42s/epoch, loss=0.338, accuracy=0.945, val_loss=0.479, val_accuracy=0.9, lr=0.001]  66%|██████▌   | 109/166 [46:58<24:11, 25.47s/epoch, loss=0.329, accuracy=0.947, val_loss=0.475, val_accuracy=0.9, lr=0.001] 66%|██████▋   | 110/166 [47:23<23:46, 25.47s/epoch, loss=0.319, accuracy=0.949, val_loss=0.475, val_accuracy=0.896, lr=0.001] 67%|██████▋   | 111/166 [47:49<23:19, 25.45s/epoch, loss=0.31, accuracy=0.95, val_loss=0.471, val_accuracy=0.896, lr=0.001]   67%|██████▋   | 112/166 [48:14<22:54, 25.45s/epoch, loss=0.305, accuracy=0.951, val_loss=0.457, val_accuracy=0.9, lr=0.001] 68%|██████▊   | 113/166 [48:39<22:25, 25.38s/epoch, loss=0.298, accuracy=0.951, val_loss=0.477, val_accuracy=0.894, lr=0.001] 69%|██████▊   | 114/166 [49:05<21:59, 25.37s/epoch, loss=0.291, accuracy=0.953, val_loss=0.472, val_accuracy=0.896, lr=0.001] 69%|██████▉   | 115/166 [49:30<21:33, 25.37s/epoch, loss=0.285, accuracy=0.953, val_loss=0.466, val_accuracy=0.899, lr=0.001] 70%|██████▉   | 116/166 [49:55<21:06, 25.34s/epoch, loss=0.277, accuracy=0.955, val_loss=0.478, val_accuracy=0.895, lr=0.001] 70%|███████   | 117/166 [50:21<20:42, 25.35s/epoch, loss=0.271, accuracy=0.956, val_loss=0.455, val_accuracy=0.903, lr=0.001] 71%|███████   | 118/166 [50:46<20:19, 25.40s/epoch, loss=0.271, accuracy=0.955, val_loss=0.461, val_accuracy=0.899, lr=0.001] 72%|███████▏  | 119/166 [51:11<19:52, 25.38s/epoch, loss=0.262, accuracy=0.956, val_loss=0.476, val_accuracy=0.892, lr=0.001] 72%|███████▏  | 120/166 [51:37<19:25, 25.33s/epoch, loss=0.261, accuracy=0.956, val_loss=0.459, val_accuracy=0.895, lr=0.001] 73%|███████▎  | 121/166 [52:02<18:59, 25.31s/epoch, loss=0.256, accuracy=0.958, val_loss=0.462, val_accuracy=0.897, lr=0.001] 73%|███████▎  | 122/166 [52:27<18:31, 25.27s/epoch, loss=0.249, accuracy=0.96, val_loss=0.467, val_accuracy=0.897, lr=0.001]  74%|███████▍  | 123/166 [52:53<18:08, 25.33s/epoch, loss=0.247, accuracy=0.958, val_loss=0.475, val_accuracy=0.894, lr=0.001] 75%|███████▍  | 124/166 [53:18<17:43, 25.31s/epoch, loss=0.243, accuracy=0.959, val_loss=0.485, val_accuracy=0.886, lr=0.001] 75%|███████▌  | 125/166 [53:43<17:17, 25.31s/epoch, loss=0.241, accuracy=0.959, val_loss=0.513, val_accuracy=0.877, lr=0.001] 76%|███████▌  | 126/166 [54:09<16:53, 25.35s/epoch, loss=0.237, accuracy=0.961, val_loss=0.465, val_accuracy=0.895, lr=0.001] 77%|███████▋  | 127/166 [54:34<16:28, 25.36s/epoch, loss=0.236, accuracy=0.96, val_loss=0.463, val_accuracy=0.893, lr=0.001]  77%|███████▋  | 128/166 [54:59<16:03, 25.35s/epoch, loss=0.231, accuracy=0.96, val_loss=0.466, val_accuracy=0.895, lr=0.001] 78%|███████▊  | 129/166 [55:25<15:36, 25.32s/epoch, loss=0.231, accuracy=0.96, val_loss=0.459, val_accuracy=0.894, lr=0.001] 78%|███████▊  | 130/166 [55:50<15:10, 25.29s/epoch, loss=0.229, accuracy=0.96, val_loss=0.465, val_accuracy=0.894, lr=0.001] 79%|███████▉  | 131/166 [56:15<14:46, 25.32s/epoch, loss=0.227, accuracy=0.96, val_loss=0.472, val_accuracy=0.887, lr=0.001] 80%|███████▉  | 132/166 [56:40<14:21, 25.33s/epoch, loss=0.225, accuracy=0.959, val_loss=0.544, val_accuracy=0.876, lr=0.001] 80%|████████  | 133/166 [57:06<13:54, 25.27s/epoch, loss=0.222, accuracy=0.962, val_loss=0.467, val_accuracy=0.89, lr=0.001]  81%|████████  | 134/166 [57:31<13:27, 25.23s/epoch, loss=0.206, accuracy=0.968, val_loss=0.419, val_accuracy=0.906, lr=1e-04] 81%|████████▏ | 135/166 [57:56<13:02, 25.23s/epoch, loss=0.193, accuracy=0.973, val_loss=0.419, val_accuracy=0.907, lr=1e-04] 82%|████████▏ | 136/166 [58:21<12:37, 25.25s/epoch, loss=0.188, accuracy=0.975, val_loss=0.417, val_accuracy=0.907, lr=1e-04] 83%|████████▎ | 137/166 [58:47<12:12, 25.27s/epoch, loss=0.186, accuracy=0.975, val_loss=0.417, val_accuracy=0.907, lr=1e-04] 83%|████████▎ | 138/166 [59:12<11:49, 25.32s/epoch, loss=0.181, accuracy=0.977, val_loss=0.415, val_accuracy=0.907, lr=1e-04] 84%|████████▎ | 139/166 [59:37<11:24, 25.34s/epoch, loss=0.18, accuracy=0.977, val_loss=0.42, val_accuracy=0.908, lr=1e-04]   84%|████████▍ | 140/166 [1:00:03<10:58, 25.35s/epoch, loss=0.179, accuracy=0.978, val_loss=0.416, val_accuracy=0.91, lr=1e-04] 85%|████████▍ | 141/166 [1:00:28<10:31, 25.25s/epoch, loss=0.178, accuracy=0.978, val_loss=0.418, val_accuracy=0.906, lr=1e-04] 86%|████████▌ | 142/166 [1:00:53<10:04, 25.20s/epoch, loss=0.175, accuracy=0.979, val_loss=0.419, val_accuracy=0.907, lr=1e-04] 86%|████████▌ | 143/166 [1:01:18<09:39, 25.21s/epoch, loss=0.175, accuracy=0.979, val_loss=0.422, val_accuracy=0.907, lr=1e-04] 87%|████████▋ | 144/166 [1:01:43<09:15, 25.23s/epoch, loss=0.173, accuracy=0.979, val_loss=0.42, val_accuracy=0.909, lr=1e-04]  87%|████████▋ | 145/166 [1:02:09<08:51, 25.32s/epoch, loss=0.173, accuracy=0.979, val_loss=0.419, val_accuracy=0.907, lr=1e-04] 88%|████████▊ | 146/166 [1:02:34<08:26, 25.33s/epoch, loss=0.171, accuracy=0.98, val_loss=0.419, val_accuracy=0.908, lr=1e-04]  89%|████████▊ | 147/166 [1:03:00<08:02, 25.39s/epoch, loss=0.17, accuracy=0.98, val_loss=0.42, val_accuracy=0.909, lr=1e-04]   89%|████████▉ | 148/166 [1:03:25<07:36, 25.36s/epoch, loss=0.171, accuracy=0.98, val_loss=0.418, val_accuracy=0.908, lr=1e-04] 90%|████████▉ | 149/166 [1:03:51<07:11, 25.38s/epoch, loss=0.169, accuracy=0.98, val_loss=0.422, val_accuracy=0.907, lr=1e-04] 90%|█████████ | 150/166 [1:04:16<06:46, 25.41s/epoch, loss=0.167, accuracy=0.981, val_loss=0.422, val_accuracy=0.906, lr=1e-04] 91%|█████████ | 151/166 [1:04:41<06:20, 25.36s/epoch, loss=0.164, accuracy=0.982, val_loss=0.422, val_accuracy=0.909, lr=5e-5]  92%|█████████▏| 152/166 [1:05:06<05:54, 25.32s/epoch, loss=0.165, accuracy=0.982, val_loss=0.423, val_accuracy=0.908, lr=5e-5] 92%|█████████▏| 153/166 [1:05:32<05:28, 25.27s/epoch, loss=0.164, accuracy=0.982, val_loss=0.424, val_accuracy=0.908, lr=5e-5] 93%|█████████▎| 154/166 [1:05:57<05:03, 25.28s/epoch, loss=0.163, accuracy=0.982, val_loss=0.422, val_accuracy=0.908, lr=5e-5] 93%|█████████▎| 155/166 [1:06:22<04:38, 25.31s/epoch, loss=0.164, accuracy=0.982, val_loss=0.422, val_accuracy=0.907, lr=5e-5] 94%|█████████▍| 156/166 [1:06:48<04:13, 25.31s/epoch, loss=0.163, accuracy=0.982, val_loss=0.421, val_accuracy=0.907, lr=5e-5] 95%|█████████▍| 157/166 [1:07:13<03:47, 25.30s/epoch, loss=0.162, accuracy=0.983, val_loss=0.421, val_accuracy=0.908, lr=5e-5] 95%|█████████▌| 158/166 [1:07:38<03:22, 25.30s/epoch, loss=0.162, accuracy=0.982, val_loss=0.42, val_accuracy=0.909, lr=5e-5]  96%|█████████▌| 159/166 [1:08:04<02:57, 25.32s/epoch, loss=0.162, accuracy=0.983, val_loss=0.423, val_accuracy=0.907, lr=5e-5] 96%|█████████▋| 160/166 [1:08:29<02:31, 25.27s/epoch, loss=0.16, accuracy=0.983, val_loss=0.421, val_accuracy=0.909, lr=5e-5]  97%|█████████▋| 161/166 [1:08:54<02:06, 25.29s/epoch, loss=0.161, accuracy=0.983, val_loss=0.422, val_accuracy=0.909, lr=5e-5] 98%|█████████▊| 162/166 [1:09:19<01:41, 25.26s/epoch, loss=0.16, accuracy=0.983, val_loss=0.423, val_accuracy=0.908, lr=5e-5]  98%|█████████▊| 163/166 [1:09:44<01:15, 25.24s/epoch, loss=0.16, accuracy=0.983, val_loss=0.422, val_accuracy=0.908, lr=5e-5] 99%|█████████▉| 164/166 [1:10:10<00:50, 25.26s/epoch, loss=0.159, accuracy=0.983, val_loss=0.421, val_accuracy=0.909, lr=5e-5] 99%|█████████▉| 165/166 [1:10:35<00:25, 25.18s/epoch, loss=0.16, accuracy=0.983, val_loss=0.422, val_accuracy=0.908, lr=5e-5] 100%|██████████| 166/166 [1:11:00<00:00, 25.11s/epoch, loss=0.16, accuracy=0.984, val_loss=0.422, val_accuracy=0.908, lr=5e-5]100%|██████████| 166/166 [1:11:00<00:00, 25.66s/epoch, loss=0.16, accuracy=0.984, val_loss=0.422, val_accuracy=0.908, lr=5e-5]
Using real-time data augmentation.
Only one model saved

Loading model: 09_04_cifar10_ResNet20v1.h5
Test score: 0.42236757278442383
Test accuracy: 0.9075000286102295


* * * Run SGD for ID = 9_5. * * *


2024-03-13 02:13:45.137586: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-13 02:13:57.113371: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-13 02:13:57.114758: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-13 02:13:57.161307: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:3b:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-13 02:13:57.161356: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-13 02:13:57.173884: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-13 02:13:57.173957: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-13 02:13:57.185047: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-13 02:13:57.200621: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-13 02:13:57.204596: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-13 02:13:57.212941: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-13 02:13:57.220967: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-13 02:13:57.221682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-13 02:13:57.221770: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-13 02:13:58.556104: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-13 02:13:58.556691: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-13 02:13:58.557486: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:3b:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-13 02:13:58.557531: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-13 02:13:58.557576: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-13 02:13:58.557591: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-13 02:13:58.557604: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-13 02:13:58.557618: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-13 02:13:58.557632: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-13 02:13:58.557646: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-13 02:13:58.557660: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-13 02:13:58.558218: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-13 02:13:58.558260: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-13 02:13:59.238493: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-13 02:13:59.238547: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-13 02:13:59.238558: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-13 02:13:59.239652: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:3b:00.0, compute capability: 6.1)
{'id': '09_05', 'seed': 5, 'out_folder': 'results/epoch_budget_2', 'batch_size': 128, 'epochs': 166, 'validation_split': 0.0, 'checkpointing': False, 'checkpoint_every': -1, 'hold_out_validation_split': 0.0, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'bootstrapping': False, 'num_classes': 10, 'SSE_lr': False, 'test_time_augmentation': False, 'debug': False, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
y_train shape: (50000, 10)
x_val shape: (10000, 32, 32, 3)
y_val shape: (10000, 10)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/166 [00:00<?, ?epoch/s]2024-03-13 02:13:59.908787: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-13 02:13:59.920984: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2100000000 Hz
2024-03-13 02:14:01.999036: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-13 02:14:02.271608: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-13 02:14:03.206580: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-13 02:14:03.251046: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/166 [00:56<2:36:25, 56.88s/epoch, loss=2.96, accuracy=0.33, val_loss=2.65, val_accuracy=0.281, lr=0.1]  1%|          | 2/166 [01:22<1:45:19, 38.53s/epoch, loss=1.51, accuracy=0.556, val_loss=2.57, val_accuracy=0.373, lr=0.1]  2%|▏         | 3/166 [01:47<1:28:20, 32.52s/epoch, loss=1.32, accuracy=0.651, val_loss=2.34, val_accuracy=0.36, lr=0.1]   2%|▏         | 4/166 [02:13<1:20:07, 29.67s/epoch, loss=1.25, accuracy=0.688, val_loss=1.95, val_accuracy=0.438, lr=0.1]  3%|▎         | 5/166 [02:38<1:15:24, 28.10s/epoch, loss=1.21, accuracy=0.707, val_loss=1.81, val_accuracy=0.502, lr=0.1]  4%|▎         | 6/166 [03:04<1:12:32, 27.20s/epoch, loss=1.21, accuracy=0.715, val_loss=2.87, val_accuracy=0.328, lr=0.1]  4%|▍         | 7/166 [03:29<1:10:26, 26.58s/epoch, loss=1.19, accuracy=0.722, val_loss=2.01, val_accuracy=0.511, lr=0.1]  5%|▍         | 8/166 [03:54<1:08:49, 26.14s/epoch, loss=1.18, accuracy=0.731, val_loss=1.61, val_accuracy=0.578, lr=0.1]  5%|▌         | 9/166 [04:19<1:07:44, 25.89s/epoch, loss=1.18, accuracy=0.733, val_loss=2.53, val_accuracy=0.385, lr=0.1]  6%|▌         | 10/166 [04:45<1:06:45, 25.68s/epoch, loss=1.17, accuracy=0.739, val_loss=2.02, val_accuracy=0.452, lr=0.1]  7%|▋         | 11/166 [05:10<1:06:19, 25.67s/epoch, loss=1.17, accuracy=0.737, val_loss=1.75, val_accuracy=0.546, lr=0.1]  7%|▋         | 12/166 [05:35<1:05:34, 25.55s/epoch, loss=1.16, accuracy=0.741, val_loss=1.95, val_accuracy=0.49, lr=0.1]   8%|▊         | 13/166 [06:01<1:05:16, 25.60s/epoch, loss=1.16, accuracy=0.741, val_loss=4.39, val_accuracy=0.221, lr=0.1]  8%|▊         | 14/166 [06:27<1:04:45, 25.56s/epoch, loss=1.16, accuracy=0.741, val_loss=1.65, val_accuracy=0.56, lr=0.1]   9%|▉         | 15/166 [06:52<1:04:19, 25.56s/epoch, loss=1.15, accuracy=0.744, val_loss=1.72, val_accuracy=0.567, lr=0.1] 10%|▉         | 16/166 [07:17<1:03:35, 25.44s/epoch, loss=1.15, accuracy=0.746, val_loss=1.87, val_accuracy=0.558, lr=0.1] 10%|█         | 17/166 [07:43<1:03:12, 25.45s/epoch, loss=1.15, accuracy=0.747, val_loss=2.18, val_accuracy=0.486, lr=0.1] 11%|█         | 18/166 [08:08<1:02:43, 25.43s/epoch, loss=1.14, accuracy=0.749, val_loss=1.45, val_accuracy=0.648, lr=0.1] 11%|█▏        | 19/166 [08:34<1:02:21, 25.46s/epoch, loss=1.13, accuracy=0.75, val_loss=1.63, val_accuracy=0.57, lr=0.1]   12%|█▏        | 20/166 [08:59<1:01:59, 25.48s/epoch, loss=1.14, accuracy=0.748, val_loss=2.92, val_accuracy=0.468, lr=0.1] 13%|█▎        | 21/166 [09:25<1:01:38, 25.51s/epoch, loss=1.14, accuracy=0.747, val_loss=1.61, val_accuracy=0.603, lr=0.1] 13%|█▎        | 22/166 [09:51<1:01:23, 25.58s/epoch, loss=1.14, accuracy=0.751, val_loss=2.19, val_accuracy=0.454, lr=0.1] 14%|█▍        | 23/166 [10:16<1:00:58, 25.58s/epoch, loss=1.14, accuracy=0.747, val_loss=2.65, val_accuracy=0.427, lr=0.1] 14%|█▍        | 24/166 [10:42<1:00:27, 25.54s/epoch, loss=1.13, accuracy=0.75, val_loss=2.22, val_accuracy=0.441, lr=0.1]  15%|█▌        | 25/166 [11:07<59:57, 25.52s/epoch, loss=1.13, accuracy=0.752, val_loss=2.35, val_accuracy=0.518, lr=0.1]  16%|█▌        | 26/166 [11:32<59:21, 25.44s/epoch, loss=1.13, accuracy=0.752, val_loss=2.36, val_accuracy=0.495, lr=0.1] 16%|█▋        | 27/166 [11:58<59:03, 25.50s/epoch, loss=1.14, accuracy=0.75, val_loss=1.76, val_accuracy=0.53, lr=0.1]   17%|█▋        | 28/166 [12:23<58:32, 25.45s/epoch, loss=1.12, accuracy=0.754, val_loss=2.03, val_accuracy=0.472, lr=0.1] 17%|█▋        | 29/166 [12:49<58:03, 25.42s/epoch, loss=1.13, accuracy=0.753, val_loss=1.55, val_accuracy=0.625, lr=0.1] 18%|█▊        | 30/166 [13:14<57:33, 25.39s/epoch, loss=1.13, accuracy=0.752, val_loss=2.38, val_accuracy=0.495, lr=0.1] 19%|█▊        | 31/166 [13:39<57:06, 25.38s/epoch, loss=1.13, accuracy=0.751, val_loss=1.35, val_accuracy=0.686, lr=0.1] 19%|█▉        | 32/166 [14:05<56:38, 25.36s/epoch, loss=1.13, accuracy=0.754, val_loss=1.56, val_accuracy=0.608, lr=0.1] 20%|█▉        | 33/166 [14:30<56:16, 25.39s/epoch, loss=1.12, accuracy=0.755, val_loss=2.49, val_accuracy=0.435, lr=0.1] 20%|██        | 34/166 [14:56<55:52, 25.40s/epoch, loss=1.12, accuracy=0.754, val_loss=1.96, val_accuracy=0.487, lr=0.1] 21%|██        | 35/166 [15:21<55:29, 25.41s/epoch, loss=1.12, accuracy=0.756, val_loss=2.35, val_accuracy=0.384, lr=0.1] 22%|██▏       | 36/166 [15:46<54:58, 25.37s/epoch, loss=1.12, accuracy=0.754, val_loss=1.61, val_accuracy=0.596, lr=0.1] 22%|██▏       | 37/166 [16:12<54:34, 25.38s/epoch, loss=1.12, accuracy=0.754, val_loss=1.66, val_accuracy=0.59, lr=0.1]  23%|██▎       | 38/166 [16:37<54:06, 25.36s/epoch, loss=1.11, accuracy=0.757, val_loss=2.57, val_accuracy=0.47, lr=0.1] 23%|██▎       | 39/166 [17:02<53:41, 25.37s/epoch, loss=1.11, accuracy=0.755, val_loss=2.01, val_accuracy=0.499, lr=0.1] 24%|██▍       | 40/166 [17:28<53:16, 25.37s/epoch, loss=1.11, accuracy=0.758, val_loss=3.25, val_accuracy=0.358, lr=0.1] 25%|██▍       | 41/166 [17:53<52:59, 25.44s/epoch, loss=1.11, accuracy=0.758, val_loss=2.44, val_accuracy=0.349, lr=0.1] 25%|██▌       | 42/166 [18:19<52:38, 25.47s/epoch, loss=1.11, accuracy=0.756, val_loss=1.8, val_accuracy=0.536, lr=0.1]  26%|██▌       | 43/166 [18:44<52:13, 25.48s/epoch, loss=1.12, accuracy=0.757, val_loss=1.38, val_accuracy=0.678, lr=0.1] 27%|██▋       | 44/166 [19:10<51:48, 25.48s/epoch, loss=1.12, accuracy=0.755, val_loss=1.79, val_accuracy=0.545, lr=0.1] 27%|██▋       | 45/166 [19:36<51:29, 25.53s/epoch, loss=1.12, accuracy=0.754, val_loss=2.06, val_accuracy=0.41, lr=0.1]  28%|██▊       | 46/166 [20:01<51:00, 25.50s/epoch, loss=1.11, accuracy=0.757, val_loss=2.53, val_accuracy=0.388, lr=0.1] 28%|██▊       | 47/166 [20:27<50:37, 25.52s/epoch, loss=1.11, accuracy=0.756, val_loss=2.51, val_accuracy=0.32, lr=0.1]  29%|██▉       | 48/166 [20:52<50:16, 25.56s/epoch, loss=1.11, accuracy=0.756, val_loss=1.86, val_accuracy=0.536, lr=0.1] 30%|██▉       | 49/166 [21:18<49:53, 25.58s/epoch, loss=1.11, accuracy=0.756, val_loss=1.68, val_accuracy=0.547, lr=0.1] 30%|███       | 50/166 [21:43<49:26, 25.57s/epoch, loss=1.1, accuracy=0.758, val_loss=2.27, val_accuracy=0.503, lr=0.1]  31%|███       | 51/166 [22:09<48:57, 25.54s/epoch, loss=1.11, accuracy=0.757, val_loss=3.45, val_accuracy=0.361, lr=0.1] 31%|███▏      | 52/166 [22:34<48:34, 25.56s/epoch, loss=1.11, accuracy=0.758, val_loss=2.09, val_accuracy=0.512, lr=0.1] 32%|███▏      | 53/166 [23:00<48:13, 25.61s/epoch, loss=1.1, accuracy=0.759, val_loss=2, val_accuracy=0.518, lr=0.1]     33%|███▎      | 54/166 [23:26<47:52, 25.65s/epoch, loss=1.11, accuracy=0.758, val_loss=2.11, val_accuracy=0.545, lr=0.1] 33%|███▎      | 55/166 [23:52<47:26, 25.64s/epoch, loss=1.1, accuracy=0.758, val_loss=1.83, val_accuracy=0.516, lr=0.1]  34%|███▎      | 56/166 [24:17<46:57, 25.61s/epoch, loss=1.11, accuracy=0.757, val_loss=1.95, val_accuracy=0.524, lr=0.1] 34%|███▍      | 57/166 [24:43<46:37, 25.66s/epoch, loss=1.11, accuracy=0.756, val_loss=1.66, val_accuracy=0.611, lr=0.1] 35%|███▍      | 58/166 [25:08<46:08, 25.63s/epoch, loss=1.1, accuracy=0.758, val_loss=1.68, val_accuracy=0.558, lr=0.1]  36%|███▌      | 59/166 [25:34<45:45, 25.66s/epoch, loss=1.11, accuracy=0.757, val_loss=4.91, val_accuracy=0.298, lr=0.1] 36%|███▌      | 60/166 [26:00<45:10, 25.57s/epoch, loss=1.1, accuracy=0.756, val_loss=2, val_accuracy=0.517, lr=0.1]     37%|███▋      | 61/166 [26:25<44:46, 25.59s/epoch, loss=1.11, accuracy=0.757, val_loss=1.77, val_accuracy=0.553, lr=0.1] 37%|███▋      | 62/166 [26:51<44:14, 25.52s/epoch, loss=1.11, accuracy=0.759, val_loss=2.5, val_accuracy=0.463, lr=0.1]  38%|███▊      | 63/166 [27:16<43:46, 25.50s/epoch, loss=1.1, accuracy=0.758, val_loss=1.39, val_accuracy=0.669, lr=0.1] 39%|███▊      | 64/166 [27:42<43:22, 25.52s/epoch, loss=1.1, accuracy=0.76, val_loss=1.78, val_accuracy=0.575, lr=0.1]  39%|███▉      | 65/166 [28:07<42:59, 25.54s/epoch, loss=1.1, accuracy=0.758, val_loss=3.12, val_accuracy=0.364, lr=0.1] 40%|███▉      | 66/166 [28:33<42:33, 25.53s/epoch, loss=1.11, accuracy=0.757, val_loss=1.65, val_accuracy=0.607, lr=0.1] 40%|████      | 67/166 [28:58<42:02, 25.48s/epoch, loss=1.11, accuracy=0.756, val_loss=1.93, val_accuracy=0.478, lr=0.1] 41%|████      | 68/166 [29:23<41:36, 25.47s/epoch, loss=0.894, accuracy=0.819, val_loss=0.877, val_accuracy=0.812, lr=0.01] 42%|████▏     | 69/166 [29:49<41:08, 25.44s/epoch, loss=0.722, accuracy=0.848, val_loss=0.764, val_accuracy=0.823, lr=0.01] 42%|████▏     | 70/166 [30:15<40:49, 25.52s/epoch, loss=0.642, accuracy=0.857, val_loss=0.712, val_accuracy=0.825, lr=0.01] 43%|████▎     | 71/166 [30:40<40:15, 25.43s/epoch, loss=0.605, accuracy=0.859, val_loss=0.771, val_accuracy=0.802, lr=0.01] 43%|████▎     | 72/166 [31:05<39:53, 25.46s/epoch, loss=0.578, accuracy=0.862, val_loss=0.791, val_accuracy=0.783, lr=0.01] 44%|████▍     | 73/166 [31:31<39:29, 25.47s/epoch, loss=0.571, accuracy=0.861, val_loss=0.92, val_accuracy=0.756, lr=0.01]  45%|████▍     | 74/166 [31:56<39:02, 25.46s/epoch, loss=0.565, accuracy=0.862, val_loss=0.79, val_accuracy=0.79, lr=0.01]  45%|████▌     | 75/166 [32:22<38:40, 25.50s/epoch, loss=0.562, accuracy=0.866, val_loss=0.856, val_accuracy=0.759, lr=0.01] 46%|████▌     | 76/166 [32:47<38:15, 25.51s/epoch, loss=0.559, accuracy=0.867, val_loss=0.837, val_accuracy=0.793, lr=0.01] 46%|████▋     | 77/166 [33:13<37:51, 25.53s/epoch, loss=0.557, accuracy=0.867, val_loss=0.793, val_accuracy=0.8, lr=0.01]   47%|████▋     | 78/166 [33:38<37:27, 25.54s/epoch, loss=0.558, accuracy=0.868, val_loss=0.716, val_accuracy=0.819, lr=0.01] 48%|████▊     | 79/166 [34:04<37:04, 25.57s/epoch, loss=0.556, accuracy=0.869, val_loss=0.68, val_accuracy=0.826, lr=0.01]  48%|████▊     | 80/166 [34:30<36:37, 25.55s/epoch, loss=0.552, accuracy=0.871, val_loss=0.848, val_accuracy=0.776, lr=0.01] 49%|████▉     | 81/166 [34:55<36:05, 25.47s/epoch, loss=0.552, accuracy=0.873, val_loss=0.998, val_accuracy=0.747, lr=0.01] 49%|████▉     | 82/166 [35:20<35:34, 25.41s/epoch, loss=0.553, accuracy=0.874, val_loss=0.83, val_accuracy=0.788, lr=0.01]  50%|█████     | 83/166 [35:45<35:03, 25.34s/epoch, loss=0.557, accuracy=0.872, val_loss=1.01, val_accuracy=0.743, lr=0.01] 51%|█████     | 84/166 [36:11<34:33, 25.29s/epoch, loss=0.549, accuracy=0.877, val_loss=0.865, val_accuracy=0.776, lr=0.01] 51%|█████     | 85/166 [36:35<33:59, 25.18s/epoch, loss=0.551, accuracy=0.876, val_loss=0.873, val_accuracy=0.771, lr=0.01] 52%|█████▏    | 86/166 [37:01<33:33, 25.17s/epoch, loss=0.551, accuracy=0.878, val_loss=0.868, val_accuracy=0.783, lr=0.01] 52%|█████▏    | 87/166 [37:26<33:05, 25.13s/epoch, loss=0.548, accuracy=0.878, val_loss=0.731, val_accuracy=0.817, lr=0.01] 53%|█████▎    | 88/166 [37:51<32:47, 25.23s/epoch, loss=0.553, accuracy=0.874, val_loss=0.723, val_accuracy=0.821, lr=0.01] 54%|█████▎    | 89/166 [38:16<32:26, 25.28s/epoch, loss=0.547, accuracy=0.88, val_loss=0.732, val_accuracy=0.826, lr=0.01]  54%|█████▍    | 90/166 [38:42<32:02, 25.29s/epoch, loss=0.556, accuracy=0.877, val_loss=0.811, val_accuracy=0.791, lr=0.01] 55%|█████▍    | 91/166 [39:07<31:35, 25.27s/epoch, loss=0.551, accuracy=0.879, val_loss=0.763, val_accuracy=0.81, lr=0.01]  55%|█████▌    | 92/166 [39:32<31:09, 25.26s/epoch, loss=0.547, accuracy=0.882, val_loss=0.824, val_accuracy=0.8, lr=0.01]  56%|█████▌    | 93/166 [39:57<30:41, 25.22s/epoch, loss=0.549, accuracy=0.88, val_loss=0.679, val_accuracy=0.84, lr=0.01] 57%|█████▋    | 94/166 [40:23<30:15, 25.22s/epoch, loss=0.549, accuracy=0.88, val_loss=0.836, val_accuracy=0.808, lr=0.01] 57%|█████▋    | 95/166 [40:48<29:48, 25.19s/epoch, loss=0.547, accuracy=0.882, val_loss=0.741, val_accuracy=0.813, lr=0.01] 58%|█████▊    | 96/166 [41:13<29:28, 25.27s/epoch, loss=0.549, accuracy=0.881, val_loss=1.03, val_accuracy=0.759, lr=0.01]  58%|█████▊    | 97/166 [41:38<29:00, 25.22s/epoch, loss=0.549, accuracy=0.879, val_loss=0.795, val_accuracy=0.811, lr=0.01] 59%|█████▉    | 98/166 [42:03<28:33, 25.20s/epoch, loss=0.552, accuracy=0.88, val_loss=0.819, val_accuracy=0.796, lr=0.01]  60%|█████▉    | 99/166 [42:29<28:10, 25.23s/epoch, loss=0.55, accuracy=0.883, val_loss=1.35, val_accuracy=0.687, lr=0.01]  60%|██████    | 100/166 [42:54<27:50, 25.31s/epoch, loss=0.554, accuracy=0.882, val_loss=0.764, val_accuracy=0.811, lr=0.01] 61%|██████    | 101/166 [43:20<27:27, 25.34s/epoch, loss=0.469, accuracy=0.911, val_loss=0.53, val_accuracy=0.891, lr=0.001] 61%|██████▏   | 102/166 [43:45<27:00, 25.31s/epoch, loss=0.418, accuracy=0.927, val_loss=0.513, val_accuracy=0.896, lr=0.001] 62%|██████▏   | 103/166 [44:10<26:33, 25.29s/epoch, loss=0.397, accuracy=0.931, val_loss=0.497, val_accuracy=0.899, lr=0.001] 63%|██████▎   | 104/166 [44:35<26:09, 25.32s/epoch, loss=0.381, accuracy=0.936, val_loss=0.497, val_accuracy=0.9, lr=0.001]   63%|██████▎   | 105/166 [45:01<25:41, 25.27s/epoch, loss=0.37, accuracy=0.939, val_loss=0.488, val_accuracy=0.902, lr=0.001] 64%|██████▍   | 106/166 [45:26<25:16, 25.27s/epoch, loss=0.354, accuracy=0.942, val_loss=0.483, val_accuracy=0.901, lr=0.001] 64%|██████▍   | 107/166 [45:51<24:50, 25.27s/epoch, loss=0.349, accuracy=0.941, val_loss=0.481, val_accuracy=0.899, lr=0.001] 65%|██████▌   | 108/166 [46:16<24:22, 25.22s/epoch, loss=0.338, accuracy=0.945, val_loss=0.47, val_accuracy=0.897, lr=0.001]  66%|██████▌   | 109/166 [46:41<23:56, 25.20s/epoch, loss=0.328, accuracy=0.945, val_loss=0.466, val_accuracy=0.902, lr=0.001] 66%|██████▋   | 110/166 [47:07<23:33, 25.23s/epoch, loss=0.319, accuracy=0.948, val_loss=0.46, val_accuracy=0.9, lr=0.001]    67%|██████▋   | 111/166 [47:32<23:04, 25.18s/epoch, loss=0.315, accuracy=0.946, val_loss=0.463, val_accuracy=0.901, lr=0.001] 67%|██████▋   | 112/166 [47:57<22:40, 25.20s/epoch, loss=0.303, accuracy=0.95, val_loss=0.458, val_accuracy=0.9, lr=0.001]    68%|██████▊   | 113/166 [48:22<22:15, 25.20s/epoch, loss=0.297, accuracy=0.951, val_loss=0.451, val_accuracy=0.9, lr=0.001] 69%|██████▊   | 114/166 [48:47<21:49, 25.19s/epoch, loss=0.291, accuracy=0.951, val_loss=0.466, val_accuracy=0.897, lr=0.001] 69%|██████▉   | 115/166 [49:13<21:25, 25.21s/epoch, loss=0.287, accuracy=0.952, val_loss=0.469, val_accuracy=0.893, lr=0.001] 70%|██████▉   | 116/166 [49:38<21:01, 25.23s/epoch, loss=0.278, accuracy=0.953, val_loss=0.464, val_accuracy=0.898, lr=0.001] 70%|███████   | 117/166 [50:03<20:38, 25.28s/epoch, loss=0.275, accuracy=0.953, val_loss=0.465, val_accuracy=0.896, lr=0.001] 71%|███████   | 118/166 [50:29<20:12, 25.26s/epoch, loss=0.269, accuracy=0.954, val_loss=0.457, val_accuracy=0.897, lr=0.001] 72%|███████▏  | 119/166 [50:54<19:45, 25.23s/epoch, loss=0.263, accuracy=0.955, val_loss=0.467, val_accuracy=0.897, lr=0.001] 72%|███████▏  | 120/166 [51:19<19:21, 25.24s/epoch, loss=0.26, accuracy=0.956, val_loss=0.458, val_accuracy=0.893, lr=0.001]  73%|███████▎  | 121/166 [51:44<18:57, 25.28s/epoch, loss=0.255, accuracy=0.956, val_loss=0.468, val_accuracy=0.894, lr=0.001] 73%|███████▎  | 122/166 [52:10<18:33, 25.31s/epoch, loss=0.252, accuracy=0.957, val_loss=0.477, val_accuracy=0.89, lr=0.001]  74%|███████▍  | 123/166 [52:35<18:09, 25.33s/epoch, loss=0.249, accuracy=0.957, val_loss=0.457, val_accuracy=0.896, lr=0.001] 75%|███████▍  | 124/166 [53:00<17:42, 25.31s/epoch, loss=0.246, accuracy=0.957, val_loss=0.442, val_accuracy=0.9, lr=0.001]   75%|███████▌  | 125/166 [53:26<17:16, 25.28s/epoch, loss=0.244, accuracy=0.957, val_loss=0.456, val_accuracy=0.895, lr=0.001] 76%|███████▌  | 126/166 [53:51<16:53, 25.34s/epoch, loss=0.238, accuracy=0.959, val_loss=0.481, val_accuracy=0.885, lr=0.001] 77%|███████▋  | 127/166 [54:16<16:27, 25.33s/epoch, loss=0.237, accuracy=0.959, val_loss=0.449, val_accuracy=0.894, lr=0.001] 77%|███████▋  | 128/166 [54:42<16:01, 25.32s/epoch, loss=0.236, accuracy=0.958, val_loss=0.445, val_accuracy=0.897, lr=0.001] 78%|███████▊  | 129/166 [55:07<15:35, 25.30s/epoch, loss=0.232, accuracy=0.96, val_loss=0.462, val_accuracy=0.89, lr=0.001]   78%|███████▊  | 130/166 [55:32<15:09, 25.27s/epoch, loss=0.228, accuracy=0.959, val_loss=0.473, val_accuracy=0.891, lr=0.001] 79%|███████▉  | 131/166 [55:57<14:43, 25.23s/epoch, loss=0.229, accuracy=0.958, val_loss=0.47, val_accuracy=0.89, lr=0.001]   80%|███████▉  | 132/166 [56:22<14:17, 25.22s/epoch, loss=0.225, accuracy=0.96, val_loss=0.575, val_accuracy=0.861, lr=0.001] 80%|████████  | 133/166 [56:47<13:49, 25.15s/epoch, loss=0.228, accuracy=0.958, val_loss=0.474, val_accuracy=0.89, lr=0.001] 81%|████████  | 134/166 [57:13<13:24, 25.13s/epoch, loss=0.204, accuracy=0.968, val_loss=0.409, val_accuracy=0.906, lr=1e-04] 81%|████████▏ | 135/166 [57:38<13:00, 25.19s/epoch, loss=0.188, accuracy=0.974, val_loss=0.406, val_accuracy=0.908, lr=1e-04] 82%|████████▏ | 136/166 [58:03<12:34, 25.15s/epoch, loss=0.185, accuracy=0.975, val_loss=0.407, val_accuracy=0.909, lr=1e-04] 83%|████████▎ | 137/166 [58:28<12:11, 25.21s/epoch, loss=0.183, accuracy=0.976, val_loss=0.408, val_accuracy=0.91, lr=1e-04]  83%|████████▎ | 138/166 [58:53<11:42, 25.10s/epoch, loss=0.18, accuracy=0.976, val_loss=0.407, val_accuracy=0.91, lr=1e-04]  84%|████████▎ | 139/166 [59:18<11:17, 25.09s/epoch, loss=0.177, accuracy=0.978, val_loss=0.407, val_accuracy=0.91, lr=1e-04] 84%|████████▍ | 140/166 [59:43<10:51, 25.07s/epoch, loss=0.176, accuracy=0.978, val_loss=0.407, val_accuracy=0.912, lr=1e-04] 85%|████████▍ | 141/166 [1:00:08<10:26, 25.07s/epoch, loss=0.175, accuracy=0.978, val_loss=0.405, val_accuracy=0.91, lr=1e-04] 86%|████████▌ | 142/166 [1:00:34<10:03, 25.14s/epoch, loss=0.173, accuracy=0.979, val_loss=0.408, val_accuracy=0.911, lr=1e-04] 86%|████████▌ | 143/166 [1:00:59<09:38, 25.14s/epoch, loss=0.173, accuracy=0.978, val_loss=0.406, val_accuracy=0.911, lr=1e-04] 87%|████████▋ | 144/166 [1:01:24<09:13, 25.15s/epoch, loss=0.172, accuracy=0.979, val_loss=0.407, val_accuracy=0.911, lr=1e-04] 87%|████████▋ | 145/166 [1:01:49<08:49, 25.23s/epoch, loss=0.17, accuracy=0.98, val_loss=0.407, val_accuracy=0.911, lr=1e-04]   88%|████████▊ | 146/166 [1:02:15<08:24, 25.24s/epoch, loss=0.168, accuracy=0.98, val_loss=0.406, val_accuracy=0.911, lr=1e-04] 89%|████████▊ | 147/166 [1:02:40<07:59, 25.23s/epoch, loss=0.169, accuracy=0.98, val_loss=0.408, val_accuracy=0.912, lr=1e-04] 89%|████████▉ | 148/166 [1:03:05<07:34, 25.26s/epoch, loss=0.167, accuracy=0.98, val_loss=0.407, val_accuracy=0.91, lr=1e-04]  90%|████████▉ | 149/166 [1:03:30<07:08, 25.21s/epoch, loss=0.166, accuracy=0.98, val_loss=0.406, val_accuracy=0.911, lr=1e-04] 90%|█████████ | 150/166 [1:03:55<06:42, 25.18s/epoch, loss=0.165, accuracy=0.981, val_loss=0.405, val_accuracy=0.91, lr=1e-04] 91%|█████████ | 151/166 [1:04:20<06:17, 25.17s/epoch, loss=0.163, accuracy=0.982, val_loss=0.407, val_accuracy=0.91, lr=5e-5]  92%|█████████▏| 152/166 [1:04:46<05:52, 25.19s/epoch, loss=0.163, accuracy=0.982, val_loss=0.406, val_accuracy=0.91, lr=5e-5] 92%|█████████▏| 153/166 [1:05:11<05:27, 25.17s/epoch, loss=0.162, accuracy=0.982, val_loss=0.407, val_accuracy=0.911, lr=5e-5] 93%|█████████▎| 154/166 [1:05:36<05:03, 25.27s/epoch, loss=0.161, accuracy=0.982, val_loss=0.408, val_accuracy=0.911, lr=5e-5] 93%|█████████▎| 155/166 [1:06:01<04:37, 25.22s/epoch, loss=0.16, accuracy=0.982, val_loss=0.406, val_accuracy=0.911, lr=5e-5]  94%|█████████▍| 156/166 [1:06:27<04:12, 25.21s/epoch, loss=0.161, accuracy=0.982, val_loss=0.406, val_accuracy=0.911, lr=5e-5] 95%|█████████▍| 157/166 [1:06:52<03:46, 25.22s/epoch, loss=0.158, accuracy=0.984, val_loss=0.406, val_accuracy=0.911, lr=5e-5] 95%|█████████▌| 158/166 [1:07:17<03:21, 25.20s/epoch, loss=0.16, accuracy=0.983, val_loss=0.407, val_accuracy=0.911, lr=5e-5]  96%|█████████▌| 159/166 [1:07:42<02:56, 25.17s/epoch, loss=0.158, accuracy=0.983, val_loss=0.408, val_accuracy=0.91, lr=5e-5] 96%|█████████▋| 160/166 [1:08:07<02:31, 25.19s/epoch, loss=0.159, accuracy=0.983, val_loss=0.407, val_accuracy=0.91, lr=5e-5] 97%|█████████▋| 161/166 [1:08:32<02:05, 25.16s/epoch, loss=0.157, accuracy=0.983, val_loss=0.406, val_accuracy=0.91, lr=5e-5] 98%|█████████▊| 162/166 [1:08:57<01:40, 25.13s/epoch, loss=0.157, accuracy=0.983, val_loss=0.408, val_accuracy=0.91, lr=5e-5] 98%|█████████▊| 163/166 [1:09:23<01:15, 25.15s/epoch, loss=0.157, accuracy=0.983, val_loss=0.406, val_accuracy=0.91, lr=5e-5] 99%|█████████▉| 164/166 [1:09:48<00:50, 25.12s/epoch, loss=0.156, accuracy=0.983, val_loss=0.407, val_accuracy=0.91, lr=5e-5] 99%|█████████▉| 165/166 [1:10:13<00:25, 25.08s/epoch, loss=0.156, accuracy=0.983, val_loss=0.407, val_accuracy=0.911, lr=5e-5]100%|██████████| 166/166 [1:10:38<00:00, 25.15s/epoch, loss=0.157, accuracy=0.983, val_loss=0.407, val_accuracy=0.91, lr=5e-5] 100%|██████████| 166/166 [1:10:38<00:00, 25.53s/epoch, loss=0.157, accuracy=0.983, val_loss=0.407, val_accuracy=0.91, lr=5e-5]
Using real-time data augmentation.
Only one model saved

Loading model: 09_05_cifar10_ResNet20v1.h5
Test score: 0.4066525101661682
Test accuracy: 0.9103000164031982


* * * Run SGD for ID = 9_6. * * *


2024-03-13 03:24:43.016821: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-13 03:24:59.261047: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-13 03:24:59.262433: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-13 03:24:59.307866: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:3b:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-13 03:24:59.307909: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-13 03:24:59.345077: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-13 03:24:59.345145: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-13 03:24:59.354574: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-13 03:24:59.363907: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-13 03:24:59.381585: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-13 03:24:59.393918: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-13 03:24:59.407481: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-13 03:24:59.408203: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-13 03:24:59.408291: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-13 03:25:00.879860: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-13 03:25:00.880998: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-13 03:25:00.881498: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:3b:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-13 03:25:00.881531: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-13 03:25:00.881565: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-13 03:25:00.881580: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-13 03:25:00.881594: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-13 03:25:00.881608: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-13 03:25:00.881622: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-13 03:25:00.881636: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-13 03:25:00.881651: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-13 03:25:00.882210: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-13 03:25:00.882249: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-13 03:25:01.608505: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-13 03:25:02.601637: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-13 03:25:02.601688: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-13 03:25:02.603569: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:3b:00.0, compute capability: 6.1)
{'id': '09_06', 'seed': 6, 'out_folder': 'results/epoch_budget_2', 'batch_size': 128, 'epochs': 166, 'validation_split': 0.0, 'checkpointing': False, 'checkpoint_every': -1, 'hold_out_validation_split': 0.0, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'bootstrapping': False, 'num_classes': 10, 'SSE_lr': False, 'test_time_augmentation': False, 'debug': False, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
y_train shape: (50000, 10)
x_val shape: (10000, 32, 32, 3)
y_val shape: (10000, 10)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/166 [00:00<?, ?epoch/s]2024-03-13 03:25:03.319741: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-13 03:25:03.331985: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2100000000 Hz
2024-03-13 03:25:05.445611: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-13 03:25:05.683094: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-13 03:25:06.828030: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-13 03:25:06.887934: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/166 [00:56<2:35:28, 56.54s/epoch, loss=3.11, accuracy=0.318, val_loss=2.63, val_accuracy=0.207, lr=0.1]  1%|          | 2/166 [01:21<1:44:29, 38.23s/epoch, loss=1.56, accuracy=0.535, val_loss=2.56, val_accuracy=0.288, lr=0.1]  2%|▏         | 3/166 [01:47<1:28:13, 32.47s/epoch, loss=1.33, accuracy=0.646, val_loss=1.58, val_accuracy=0.546, lr=0.1]  2%|▏         | 4/166 [02:13<1:20:09, 29.69s/epoch, loss=1.27, accuracy=0.685, val_loss=2.12, val_accuracy=0.459, lr=0.1]  3%|▎         | 5/166 [02:38<1:15:33, 28.16s/epoch, loss=1.24, accuracy=0.703, val_loss=1.64, val_accuracy=0.564, lr=0.1]  4%|▎         | 6/166 [03:03<1:12:41, 27.26s/epoch, loss=1.23, accuracy=0.711, val_loss=1.47, val_accuracy=0.632, lr=0.1]  4%|▍         | 7/166 [03:29<1:10:43, 26.69s/epoch, loss=1.22, accuracy=0.718, val_loss=2.31, val_accuracy=0.483, lr=0.1]  5%|▍         | 8/166 [03:54<1:09:11, 26.28s/epoch, loss=1.2, accuracy=0.723, val_loss=1.73, val_accuracy=0.52, lr=0.1]    5%|▌         | 9/166 [04:20<1:08:07, 26.03s/epoch, loss=1.2, accuracy=0.725, val_loss=1.38, val_accuracy=0.669, lr=0.1]  6%|▌         | 10/166 [04:45<1:07:22, 25.91s/epoch, loss=1.2, accuracy=0.729, val_loss=1.41, val_accuracy=0.654, lr=0.1]  7%|▋         | 11/166 [05:11<1:06:23, 25.70s/epoch, loss=1.19, accuracy=0.731, val_loss=1.79, val_accuracy=0.514, lr=0.1]  7%|▋         | 12/166 [05:36<1:05:50, 25.66s/epoch, loss=1.19, accuracy=0.731, val_loss=1.57, val_accuracy=0.607, lr=0.1]  8%|▊         | 13/166 [06:02<1:05:09, 25.55s/epoch, loss=1.18, accuracy=0.737, val_loss=1.55, val_accuracy=0.603, lr=0.1]  8%|▊         | 14/166 [06:27<1:04:40, 25.53s/epoch, loss=1.17, accuracy=0.737, val_loss=2.17, val_accuracy=0.5, lr=0.1]    9%|▉         | 15/166 [06:52<1:04:09, 25.49s/epoch, loss=1.17, accuracy=0.739, val_loss=1.91, val_accuracy=0.495, lr=0.1] 10%|▉         | 16/166 [07:18<1:03:39, 25.46s/epoch, loss=1.16, accuracy=0.741, val_loss=1.92, val_accuracy=0.53, lr=0.1]  10%|█         | 17/166 [07:43<1:03:07, 25.42s/epoch, loss=1.17, accuracy=0.741, val_loss=2.28, val_accuracy=0.444, lr=0.1] 11%|█         | 18/166 [08:09<1:02:51, 25.48s/epoch, loss=1.16, accuracy=0.742, val_loss=2.59, val_accuracy=0.378, lr=0.1] 11%|█▏        | 19/166 [08:34<1:02:30, 25.51s/epoch, loss=1.16, accuracy=0.745, val_loss=3.08, val_accuracy=0.366, lr=0.1] 12%|█▏        | 20/166 [09:00<1:02:03, 25.50s/epoch, loss=1.16, accuracy=0.744, val_loss=1.97, val_accuracy=0.501, lr=0.1] 13%|█▎        | 21/166 [09:25<1:01:33, 25.47s/epoch, loss=1.16, accuracy=0.745, val_loss=1.9, val_accuracy=0.495, lr=0.1]  13%|█▎        | 22/166 [09:51<1:01:09, 25.48s/epoch, loss=1.16, accuracy=0.745, val_loss=1.46, val_accuracy=0.641, lr=0.1] 14%|█▍        | 23/166 [10:16<1:00:45, 25.49s/epoch, loss=1.14, accuracy=0.747, val_loss=2.36, val_accuracy=0.414, lr=0.1] 14%|█▍        | 24/166 [10:42<1:00:26, 25.54s/epoch, loss=1.14, accuracy=0.75, val_loss=1.49, val_accuracy=0.629, lr=0.1]  15%|█▌        | 25/166 [11:07<59:56, 25.51s/epoch, loss=1.14, accuracy=0.749, val_loss=2.81, val_accuracy=0.388, lr=0.1]  16%|█▌        | 26/166 [11:33<59:35, 25.54s/epoch, loss=1.14, accuracy=0.751, val_loss=2.06, val_accuracy=0.533, lr=0.1] 16%|█▋        | 27/166 [11:58<59:04, 25.50s/epoch, loss=1.14, accuracy=0.751, val_loss=3.38, val_accuracy=0.33, lr=0.1]  17%|█▋        | 28/166 [12:24<58:35, 25.48s/epoch, loss=1.14, accuracy=0.754, val_loss=1.88, val_accuracy=0.53, lr=0.1] 17%|█▋        | 29/166 [12:49<58:08, 25.46s/epoch, loss=1.14, accuracy=0.751, val_loss=2.25, val_accuracy=0.51, lr=0.1] 18%|█▊        | 30/166 [13:15<57:41, 25.46s/epoch, loss=1.13, accuracy=0.756, val_loss=2.11, val_accuracy=0.472, lr=0.1] 19%|█▊        | 31/166 [13:40<57:09, 25.41s/epoch, loss=1.13, accuracy=0.752, val_loss=1.64, val_accuracy=0.635, lr=0.1] 19%|█▉        | 32/166 [14:05<56:46, 25.42s/epoch, loss=1.13, accuracy=0.752, val_loss=1.9, val_accuracy=0.522, lr=0.1]  20%|█▉        | 33/166 [14:31<56:25, 25.45s/epoch, loss=1.13, accuracy=0.752, val_loss=3.04, val_accuracy=0.299, lr=0.1] 20%|██        | 34/166 [14:56<55:59, 25.45s/epoch, loss=1.13, accuracy=0.752, val_loss=2.22, val_accuracy=0.455, lr=0.1] 21%|██        | 35/166 [15:22<55:30, 25.42s/epoch, loss=1.13, accuracy=0.755, val_loss=2.53, val_accuracy=0.393, lr=0.1] 22%|██▏       | 36/166 [15:47<54:59, 25.38s/epoch, loss=1.13, accuracy=0.754, val_loss=2.34, val_accuracy=0.438, lr=0.1] 22%|██▏       | 37/166 [16:12<54:32, 25.37s/epoch, loss=1.12, accuracy=0.757, val_loss=2.55, val_accuracy=0.416, lr=0.1] 23%|██▎       | 38/166 [16:38<54:09, 25.38s/epoch, loss=1.12, accuracy=0.758, val_loss=1.99, val_accuracy=0.457, lr=0.1] 23%|██▎       | 39/166 [17:03<53:46, 25.41s/epoch, loss=1.13, accuracy=0.754, val_loss=1.8, val_accuracy=0.561, lr=0.1]  24%|██▍       | 40/166 [17:29<53:18, 25.38s/epoch, loss=1.12, accuracy=0.755, val_loss=1.69, val_accuracy=0.569, lr=0.1] 25%|██▍       | 41/166 [17:54<52:51, 25.37s/epoch, loss=1.12, accuracy=0.756, val_loss=2.1, val_accuracy=0.53, lr=0.1]   25%|██▌       | 42/166 [18:19<52:23, 25.35s/epoch, loss=1.12, accuracy=0.759, val_loss=1.71, val_accuracy=0.598, lr=0.1] 26%|██▌       | 43/166 [18:45<51:59, 25.36s/epoch, loss=1.12, accuracy=0.755, val_loss=2.86, val_accuracy=0.387, lr=0.1] 27%|██▋       | 44/166 [19:10<51:38, 25.39s/epoch, loss=1.12, accuracy=0.757, val_loss=3.98, val_accuracy=0.35, lr=0.1]  27%|██▋       | 45/166 [19:36<51:20, 25.45s/epoch, loss=1.12, accuracy=0.758, val_loss=1.95, val_accuracy=0.499, lr=0.1] 28%|██▊       | 46/166 [20:01<50:57, 25.48s/epoch, loss=1.12, accuracy=0.758, val_loss=2.06, val_accuracy=0.461, lr=0.1] 28%|██▊       | 47/166 [20:27<50:36, 25.52s/epoch, loss=1.11, accuracy=0.76, val_loss=2.01, val_accuracy=0.542, lr=0.1]  29%|██▉       | 48/166 [20:53<50:18, 25.58s/epoch, loss=1.12, accuracy=0.758, val_loss=1.65, val_accuracy=0.585, lr=0.1] 30%|██▉       | 49/166 [21:18<49:47, 25.54s/epoch, loss=1.11, accuracy=0.758, val_loss=1.97, val_accuracy=0.527, lr=0.1] 30%|███       | 50/166 [21:44<49:21, 25.53s/epoch, loss=1.11, accuracy=0.76, val_loss=1.59, val_accuracy=0.607, lr=0.1]  31%|███       | 51/166 [22:09<48:55, 25.53s/epoch, loss=1.11, accuracy=0.759, val_loss=1.6, val_accuracy=0.572, lr=0.1] 31%|███▏      | 52/166 [22:35<48:28, 25.51s/epoch, loss=1.11, accuracy=0.76, val_loss=3.21, val_accuracy=0.368, lr=0.1] 32%|███▏      | 53/166 [23:00<48:04, 25.52s/epoch, loss=1.11, accuracy=0.76, val_loss=2.78, val_accuracy=0.418, lr=0.1] 33%|███▎      | 54/166 [23:26<47:45, 25.59s/epoch, loss=1.11, accuracy=0.759, val_loss=1.8, val_accuracy=0.513, lr=0.1] 33%|███▎      | 55/166 [23:51<47:15, 25.55s/epoch, loss=1.11, accuracy=0.758, val_loss=3.5, val_accuracy=0.33, lr=0.1]  34%|███▎      | 56/166 [24:17<46:44, 25.49s/epoch, loss=1.12, accuracy=0.755, val_loss=3.15, val_accuracy=0.298, lr=0.1] 34%|███▍      | 57/166 [24:42<46:25, 25.55s/epoch, loss=1.12, accuracy=0.759, val_loss=2.23, val_accuracy=0.493, lr=0.1] 35%|███▍      | 58/166 [25:08<46:01, 25.57s/epoch, loss=1.11, accuracy=0.759, val_loss=1.72, val_accuracy=0.557, lr=0.1] 36%|███▌      | 59/166 [25:33<45:31, 25.52s/epoch, loss=1.12, accuracy=0.759, val_loss=3.48, val_accuracy=0.355, lr=0.1] 36%|███▌      | 60/166 [25:59<45:10, 25.57s/epoch, loss=1.11, accuracy=0.759, val_loss=2.36, val_accuracy=0.407, lr=0.1] 37%|███▋      | 61/166 [26:24<44:39, 25.51s/epoch, loss=1.11, accuracy=0.759, val_loss=4.31, val_accuracy=0.212, lr=0.1] 37%|███▋      | 62/166 [26:50<44:16, 25.54s/epoch, loss=1.11, accuracy=0.759, val_loss=2.07, val_accuracy=0.498, lr=0.1] 38%|███▊      | 63/166 [27:15<43:46, 25.50s/epoch, loss=1.11, accuracy=0.761, val_loss=2.35, val_accuracy=0.391, lr=0.1] 39%|███▊      | 64/166 [27:41<43:27, 25.57s/epoch, loss=1.11, accuracy=0.76, val_loss=2.21, val_accuracy=0.471, lr=0.1]  39%|███▉      | 65/166 [28:07<43:01, 25.56s/epoch, loss=1.11, accuracy=0.761, val_loss=2.76, val_accuracy=0.444, lr=0.1] 40%|███▉      | 66/166 [28:32<42:30, 25.50s/epoch, loss=1.11, accuracy=0.757, val_loss=1.71, val_accuracy=0.569, lr=0.1] 40%|████      | 67/166 [28:57<42:01, 25.47s/epoch, loss=1.11, accuracy=0.759, val_loss=1.97, val_accuracy=0.464, lr=0.1] 41%|████      | 68/166 [29:23<41:36, 25.47s/epoch, loss=0.906, accuracy=0.817, val_loss=0.892, val_accuracy=0.803, lr=0.01] 42%|████▏     | 69/166 [29:48<41:08, 25.45s/epoch, loss=0.721, accuracy=0.85, val_loss=0.791, val_accuracy=0.816, lr=0.01]  42%|████▏     | 70/166 [30:14<40:44, 25.47s/epoch, loss=0.639, accuracy=0.859, val_loss=0.747, val_accuracy=0.816, lr=0.01] 43%|████▎     | 71/166 [30:39<40:23, 25.51s/epoch, loss=0.602, accuracy=0.86, val_loss=0.754, val_accuracy=0.808, lr=0.01]  43%|████▎     | 72/166 [31:05<39:56, 25.50s/epoch, loss=0.577, accuracy=0.863, val_loss=0.838, val_accuracy=0.777, lr=0.01] 44%|████▍     | 73/166 [31:30<39:30, 25.49s/epoch, loss=0.568, accuracy=0.863, val_loss=0.724, val_accuracy=0.813, lr=0.01] 45%|████▍     | 74/166 [31:56<39:07, 25.51s/epoch, loss=0.562, accuracy=0.865, val_loss=0.73, val_accuracy=0.813, lr=0.01]  45%|████▌     | 75/166 [32:22<38:42, 25.52s/epoch, loss=0.563, accuracy=0.865, val_loss=0.915, val_accuracy=0.751, lr=0.01] 46%|████▌     | 76/166 [32:47<38:19, 25.55s/epoch, loss=0.557, accuracy=0.869, val_loss=0.796, val_accuracy=0.799, lr=0.01] 46%|████▋     | 77/166 [33:13<37:56, 25.58s/epoch, loss=0.554, accuracy=0.87, val_loss=0.878, val_accuracy=0.769, lr=0.01]  47%|████▋     | 78/166 [33:38<37:34, 25.62s/epoch, loss=0.548, accuracy=0.873, val_loss=0.859, val_accuracy=0.774, lr=0.01] 48%|████▊     | 79/166 [34:04<37:08, 25.61s/epoch, loss=0.553, accuracy=0.872, val_loss=0.999, val_accuracy=0.754, lr=0.01] 48%|████▊     | 80/166 [34:30<36:38, 25.57s/epoch, loss=0.553, accuracy=0.874, val_loss=0.844, val_accuracy=0.781, lr=0.01] 49%|████▉     | 81/166 [34:55<36:11, 25.55s/epoch, loss=0.549, accuracy=0.876, val_loss=0.982, val_accuracy=0.739, lr=0.01] 49%|████▉     | 82/166 [35:21<35:44, 25.52s/epoch, loss=0.548, accuracy=0.876, val_loss=0.715, val_accuracy=0.826, lr=0.01] 50%|█████     | 83/166 [35:46<35:18, 25.53s/epoch, loss=0.546, accuracy=0.879, val_loss=0.906, val_accuracy=0.762, lr=0.01] 51%|█████     | 84/166 [36:12<34:53, 25.53s/epoch, loss=0.547, accuracy=0.877, val_loss=0.733, val_accuracy=0.821, lr=0.01] 51%|█████     | 85/166 [36:37<34:23, 25.48s/epoch, loss=0.546, accuracy=0.879, val_loss=1.27, val_accuracy=0.686, lr=0.01]  52%|█████▏    | 86/166 [37:02<33:59, 25.49s/epoch, loss=0.548, accuracy=0.88, val_loss=0.816, val_accuracy=0.797, lr=0.01] 52%|█████▏    | 87/166 [37:28<33:35, 25.51s/epoch, loss=0.546, accuracy=0.88, val_loss=1.91, val_accuracy=0.617, lr=0.01]  53%|█████▎    | 88/166 [37:54<33:09, 25.51s/epoch, loss=0.549, accuracy=0.88, val_loss=0.94, val_accuracy=0.76, lr=0.01]  54%|█████▎    | 89/166 [38:19<32:41, 25.48s/epoch, loss=0.544, accuracy=0.881, val_loss=0.777, val_accuracy=0.814, lr=0.01] 54%|█████▍    | 90/166 [38:45<32:20, 25.54s/epoch, loss=0.548, accuracy=0.881, val_loss=0.924, val_accuracy=0.76, lr=0.01]  55%|█████▍    | 91/166 [39:10<31:53, 25.52s/epoch, loss=0.547, accuracy=0.883, val_loss=1.11, val_accuracy=0.71, lr=0.01]  55%|█████▌    | 92/166 [39:36<31:28, 25.52s/epoch, loss=0.545, accuracy=0.884, val_loss=0.896, val_accuracy=0.78, lr=0.01] 56%|█████▌    | 93/166 [40:01<30:57, 25.44s/epoch, loss=0.548, accuracy=0.884, val_loss=0.79, val_accuracy=0.809, lr=0.01] 57%|█████▋    | 94/166 [40:26<30:30, 25.43s/epoch, loss=0.545, accuracy=0.883, val_loss=0.875, val_accuracy=0.78, lr=0.01] 57%|█████▋    | 95/166 [40:52<30:04, 25.41s/epoch, loss=0.543, accuracy=0.886, val_loss=0.78, val_accuracy=0.811, lr=0.01] 58%|█████▊    | 96/166 [41:17<29:42, 25.46s/epoch, loss=0.547, accuracy=0.885, val_loss=0.947, val_accuracy=0.768, lr=0.01] 58%|█████▊    | 97/166 [41:43<29:14, 25.43s/epoch, loss=0.545, accuracy=0.885, val_loss=0.955, val_accuracy=0.757, lr=0.01] 59%|█████▉    | 98/166 [42:08<28:50, 25.45s/epoch, loss=0.545, accuracy=0.887, val_loss=0.897, val_accuracy=0.766, lr=0.01] 60%|█████▉    | 99/166 [42:33<28:21, 25.39s/epoch, loss=0.542, accuracy=0.887, val_loss=0.903, val_accuracy=0.783, lr=0.01] 60%|██████    | 100/166 [42:58<27:48, 25.28s/epoch, loss=0.541, accuracy=0.889, val_loss=0.801, val_accuracy=0.801, lr=0.01] 61%|██████    | 101/166 [43:24<27:22, 25.28s/epoch, loss=0.467, accuracy=0.916, val_loss=0.523, val_accuracy=0.893, lr=0.001] 61%|██████▏   | 102/166 [43:49<27:01, 25.33s/epoch, loss=0.413, accuracy=0.93, val_loss=0.509, val_accuracy=0.899, lr=0.001]  62%|██████▏   | 103/166 [44:14<26:34, 25.31s/epoch, loss=0.393, accuracy=0.936, val_loss=0.498, val_accuracy=0.9, lr=0.001]  63%|██████▎   | 104/166 [44:40<26:12, 25.36s/epoch, loss=0.379, accuracy=0.938, val_loss=0.485, val_accuracy=0.904, lr=0.001] 63%|██████▎   | 105/166 [45:05<25:48, 25.39s/epoch, loss=0.363, accuracy=0.943, val_loss=0.487, val_accuracy=0.899, lr=0.001] 64%|██████▍   | 106/166 [45:31<25:21, 25.36s/epoch, loss=0.35, accuracy=0.945, val_loss=0.478, val_accuracy=0.901, lr=0.001]  64%|██████▍   | 107/166 [45:55<24:49, 25.24s/epoch, loss=0.343, accuracy=0.945, val_loss=0.47, val_accuracy=0.903, lr=0.001] 65%|██████▌   | 108/166 [46:21<24:25, 25.27s/epoch, loss=0.331, accuracy=0.947, val_loss=0.465, val_accuracy=0.905, lr=0.001] 66%|██████▌   | 109/166 [46:46<23:57, 25.23s/epoch, loss=0.321, accuracy=0.95, val_loss=0.463, val_accuracy=0.904, lr=0.001]  66%|██████▋   | 110/166 [47:11<23:32, 25.23s/epoch, loss=0.317, accuracy=0.95, val_loss=0.47, val_accuracy=0.901, lr=0.001]  67%|██████▋   | 111/166 [47:36<23:02, 25.13s/epoch, loss=0.307, accuracy=0.952, val_loss=0.451, val_accuracy=0.903, lr=0.001] 67%|██████▋   | 112/166 [48:01<22:39, 25.18s/epoch, loss=0.298, accuracy=0.953, val_loss=0.448, val_accuracy=0.903, lr=0.001] 68%|██████▊   | 113/166 [48:26<22:13, 25.16s/epoch, loss=0.291, accuracy=0.955, val_loss=0.453, val_accuracy=0.903, lr=0.001] 69%|██████▊   | 114/166 [48:52<21:46, 25.12s/epoch, loss=0.284, accuracy=0.956, val_loss=0.466, val_accuracy=0.904, lr=0.001] 69%|██████▉   | 115/166 [49:17<21:21, 25.13s/epoch, loss=0.278, accuracy=0.956, val_loss=0.442, val_accuracy=0.903, lr=0.001] 70%|██████▉   | 116/166 [49:42<21:01, 25.22s/epoch, loss=0.272, accuracy=0.957, val_loss=0.44, val_accuracy=0.906, lr=0.001]  70%|███████   | 117/166 [50:07<20:36, 25.23s/epoch, loss=0.268, accuracy=0.958, val_loss=0.463, val_accuracy=0.898, lr=0.001] 71%|███████   | 118/166 [50:33<20:15, 25.31s/epoch, loss=0.264, accuracy=0.958, val_loss=0.439, val_accuracy=0.9, lr=0.001]   72%|███████▏  | 119/166 [50:58<19:47, 25.27s/epoch, loss=0.257, accuracy=0.959, val_loss=0.455, val_accuracy=0.9, lr=0.001] 72%|███████▏  | 120/166 [51:23<19:22, 25.27s/epoch, loss=0.255, accuracy=0.958, val_loss=0.441, val_accuracy=0.899, lr=0.001] 73%|███████▎  | 121/166 [51:49<18:59, 25.32s/epoch, loss=0.248, accuracy=0.96, val_loss=0.426, val_accuracy=0.903, lr=0.001]  73%|███████▎  | 122/166 [52:14<18:34, 25.32s/epoch, loss=0.243, accuracy=0.961, val_loss=0.475, val_accuracy=0.892, lr=0.001] 74%|███████▍  | 123/166 [52:39<18:08, 25.31s/epoch, loss=0.244, accuracy=0.959, val_loss=0.446, val_accuracy=0.9, lr=0.001]   75%|███████▍  | 124/166 [53:05<17:41, 25.28s/epoch, loss=0.239, accuracy=0.961, val_loss=0.47, val_accuracy=0.892, lr=0.001] 75%|███████▌  | 125/166 [53:30<17:18, 25.32s/epoch, loss=0.234, accuracy=0.961, val_loss=0.441, val_accuracy=0.898, lr=0.001] 76%|███████▌  | 126/166 [53:55<16:51, 25.28s/epoch, loss=0.231, accuracy=0.961, val_loss=0.44, val_accuracy=0.9, lr=0.001]    77%|███████▋  | 127/166 [54:20<16:25, 25.28s/epoch, loss=0.229, accuracy=0.962, val_loss=0.447, val_accuracy=0.898, lr=0.001] 77%|███████▋  | 128/166 [54:46<15:59, 25.26s/epoch, loss=0.222, accuracy=0.963, val_loss=0.475, val_accuracy=0.891, lr=0.001] 78%|███████▊  | 129/166 [55:11<15:32, 25.20s/epoch, loss=0.226, accuracy=0.962, val_loss=0.44, val_accuracy=0.896, lr=0.001]  78%|███████▊  | 130/166 [55:36<15:07, 25.21s/epoch, loss=0.223, accuracy=0.962, val_loss=0.489, val_accuracy=0.888, lr=0.001] 79%|███████▉  | 131/166 [56:01<14:40, 25.15s/epoch, loss=0.22, accuracy=0.962, val_loss=0.455, val_accuracy=0.892, lr=0.001]  80%|███████▉  | 132/166 [56:26<14:16, 25.19s/epoch, loss=0.22, accuracy=0.962, val_loss=0.494, val_accuracy=0.886, lr=0.001] 80%|████████  | 133/166 [56:51<13:49, 25.15s/epoch, loss=0.216, accuracy=0.963, val_loss=0.475, val_accuracy=0.885, lr=0.001] 81%|████████  | 134/166 [57:17<13:26, 25.19s/epoch, loss=0.197, accuracy=0.97, val_loss=0.406, val_accuracy=0.907, lr=1e-04]  81%|████████▏ | 135/166 [57:42<12:59, 25.15s/epoch, loss=0.186, accuracy=0.975, val_loss=0.402, val_accuracy=0.909, lr=1e-04] 82%|████████▏ | 136/166 [58:07<12:34, 25.14s/epoch, loss=0.181, accuracy=0.977, val_loss=0.403, val_accuracy=0.908, lr=1e-04] 83%|████████▎ | 137/166 [58:32<12:08, 25.14s/epoch, loss=0.178, accuracy=0.978, val_loss=0.4, val_accuracy=0.91, lr=1e-04]    83%|████████▎ | 138/166 [58:57<11:44, 25.15s/epoch, loss=0.176, accuracy=0.979, val_loss=0.4, val_accuracy=0.91, lr=1e-04] 84%|████████▎ | 139/166 [59:22<11:18, 25.14s/epoch, loss=0.174, accuracy=0.98, val_loss=0.399, val_accuracy=0.909, lr=1e-04] 84%|████████▍ | 140/166 [59:47<10:53, 25.15s/epoch, loss=0.172, accuracy=0.98, val_loss=0.401, val_accuracy=0.91, lr=1e-04]  85%|████████▍ | 141/166 [1:00:13<10:30, 25.22s/epoch, loss=0.172, accuracy=0.979, val_loss=0.401, val_accuracy=0.909, lr=1e-04] 86%|████████▌ | 142/166 [1:00:38<10:03, 25.13s/epoch, loss=0.17, accuracy=0.98, val_loss=0.403, val_accuracy=0.91, lr=1e-04]    86%|████████▌ | 143/166 [1:01:03<09:37, 25.11s/epoch, loss=0.168, accuracy=0.981, val_loss=0.401, val_accuracy=0.909, lr=1e-04] 87%|████████▋ | 144/166 [1:01:28<09:11, 25.09s/epoch, loss=0.168, accuracy=0.981, val_loss=0.404, val_accuracy=0.908, lr=1e-04] 87%|████████▋ | 145/166 [1:01:53<08:46, 25.06s/epoch, loss=0.167, accuracy=0.981, val_loss=0.4, val_accuracy=0.907, lr=1e-04]   88%|████████▊ | 146/166 [1:02:18<08:22, 25.13s/epoch, loss=0.164, accuracy=0.982, val_loss=0.402, val_accuracy=0.909, lr=1e-04] 89%|████████▊ | 147/166 [1:02:43<07:58, 25.19s/epoch, loss=0.164, accuracy=0.982, val_loss=0.403, val_accuracy=0.909, lr=1e-04] 89%|████████▉ | 148/166 [1:03:09<07:33, 25.21s/epoch, loss=0.164, accuracy=0.982, val_loss=0.402, val_accuracy=0.91, lr=1e-04]  90%|████████▉ | 149/166 [1:03:34<07:07, 25.16s/epoch, loss=0.161, accuracy=0.983, val_loss=0.402, val_accuracy=0.91, lr=1e-04] 90%|█████████ | 150/166 [1:03:59<06:43, 25.21s/epoch, loss=0.161, accuracy=0.983, val_loss=0.404, val_accuracy=0.909, lr=1e-04] 91%|█████████ | 151/166 [1:04:24<06:18, 25.21s/epoch, loss=0.159, accuracy=0.984, val_loss=0.404, val_accuracy=0.91, lr=5e-5]   92%|█████████▏| 152/166 [1:04:50<05:54, 25.30s/epoch, loss=0.16, accuracy=0.984, val_loss=0.404, val_accuracy=0.91, lr=5e-5]  92%|█████████▏| 153/166 [1:05:15<05:27, 25.23s/epoch, loss=0.158, accuracy=0.984, val_loss=0.403, val_accuracy=0.909, lr=5e-5] 93%|█████████▎| 154/166 [1:05:40<05:02, 25.23s/epoch, loss=0.158, accuracy=0.984, val_loss=0.405, val_accuracy=0.909, lr=5e-5] 93%|█████████▎| 155/166 [1:06:05<04:37, 25.21s/epoch, loss=0.158, accuracy=0.984, val_loss=0.403, val_accuracy=0.909, lr=5e-5] 94%|█████████▍| 156/166 [1:06:30<04:11, 25.16s/epoch, loss=0.158, accuracy=0.984, val_loss=0.405, val_accuracy=0.908, lr=5e-5] 95%|█████████▍| 157/166 [1:06:55<03:46, 25.15s/epoch, loss=0.155, accuracy=0.986, val_loss=0.405, val_accuracy=0.909, lr=5e-5] 95%|█████████▌| 158/166 [1:07:20<03:20, 25.10s/epoch, loss=0.156, accuracy=0.983, val_loss=0.405, val_accuracy=0.91, lr=5e-5]  96%|█████████▌| 159/166 [1:07:46<02:55, 25.14s/epoch, loss=0.156, accuracy=0.985, val_loss=0.404, val_accuracy=0.909, lr=5e-5] 96%|█████████▋| 160/166 [1:08:11<02:30, 25.15s/epoch, loss=0.155, accuracy=0.984, val_loss=0.405, val_accuracy=0.908, lr=5e-5] 97%|█████████▋| 161/166 [1:08:36<02:05, 25.13s/epoch, loss=0.155, accuracy=0.984, val_loss=0.406, val_accuracy=0.907, lr=5e-5] 98%|█████████▊| 162/166 [1:09:01<01:40, 25.09s/epoch, loss=0.154, accuracy=0.984, val_loss=0.404, val_accuracy=0.908, lr=5e-5] 98%|█████████▊| 163/166 [1:09:26<01:15, 25.08s/epoch, loss=0.153, accuracy=0.985, val_loss=0.405, val_accuracy=0.909, lr=5e-5] 99%|█████████▉| 164/166 [1:09:51<00:50, 25.08s/epoch, loss=0.154, accuracy=0.985, val_loss=0.404, val_accuracy=0.91, lr=5e-5]  99%|█████████▉| 165/166 [1:10:16<00:25, 25.04s/epoch, loss=0.153, accuracy=0.985, val_loss=0.406, val_accuracy=0.911, lr=5e-5]100%|██████████| 166/166 [1:10:41<00:00, 25.07s/epoch, loss=0.154, accuracy=0.984, val_loss=0.405, val_accuracy=0.91, lr=5e-5] 100%|██████████| 166/166 [1:10:41<00:00, 25.55s/epoch, loss=0.154, accuracy=0.984, val_loss=0.405, val_accuracy=0.91, lr=5e-5]
Using real-time data augmentation.
Only one model saved

Loading model: 09_06_cifar10_ResNet20v1.h5
Test score: 0.4049389660358429
Test accuracy: 0.909600019454956


* * * Run SGD for ID = 9_7. * * *


2024-03-13 04:35:48.740107: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-13 04:35:51.487272: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-13 04:35:51.488643: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-13 04:35:51.532959: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:3b:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-13 04:35:51.533004: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-13 04:35:51.536453: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-13 04:35:51.536524: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-13 04:35:51.539260: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-13 04:35:51.539998: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-13 04:35:51.542959: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-13 04:35:51.544822: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-13 04:35:51.550707: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-13 04:35:51.551407: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-13 04:35:51.551495: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-13 04:35:52.860419: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-13 04:35:52.860989: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-13 04:35:52.861781: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:3b:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-13 04:35:52.861817: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-13 04:35:52.861869: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-13 04:35:52.861884: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-13 04:35:52.861900: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-13 04:35:52.861913: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-13 04:35:52.861927: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-13 04:35:52.861941: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-13 04:35:52.861955: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-13 04:35:52.862508: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-13 04:35:52.862545: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-13 04:35:53.526869: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-13 04:35:53.526922: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-13 04:35:53.526933: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-13 04:35:53.527990: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:3b:00.0, compute capability: 6.1)
{'id': '09_07', 'seed': 7, 'out_folder': 'results/epoch_budget_2', 'batch_size': 128, 'epochs': 166, 'validation_split': 0.0, 'checkpointing': False, 'checkpoint_every': -1, 'hold_out_validation_split': 0.0, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'bootstrapping': False, 'num_classes': 10, 'SSE_lr': False, 'test_time_augmentation': False, 'debug': False, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
y_train shape: (50000, 10)
x_val shape: (10000, 32, 32, 3)
y_val shape: (10000, 10)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/166 [00:00<?, ?epoch/s]2024-03-13 04:35:54.153662: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-13 04:35:54.166013: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2100000000 Hz
2024-03-13 04:35:56.235208: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-13 04:35:56.578678: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-13 04:35:57.644719: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-13 04:35:57.691962: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/166 [01:04<2:58:13, 64.81s/epoch, loss=3.24, accuracy=0.3, val_loss=3.86, val_accuracy=0.184, lr=0.1]  1%|          | 2/166 [01:30<1:53:56, 41.68s/epoch, loss=1.6, accuracy=0.507, val_loss=3.1, val_accuracy=0.317, lr=0.1]  2%|▏         | 3/166 [01:55<1:33:20, 34.36s/epoch, loss=1.35, accuracy=0.631, val_loss=1.9, val_accuracy=0.508, lr=0.1]  2%|▏         | 4/166 [02:21<1:23:21, 30.87s/epoch, loss=1.28, accuracy=0.676, val_loss=4.7, val_accuracy=0.273, lr=0.1]  3%|▎         | 5/166 [02:46<1:17:37, 28.93s/epoch, loss=1.25, accuracy=0.697, val_loss=3.2, val_accuracy=0.36, lr=0.1]   4%|▎         | 6/166 [03:12<1:13:58, 27.74s/epoch, loss=1.23, accuracy=0.711, val_loss=2.34, val_accuracy=0.433, lr=0.1]  4%|▍         | 7/166 [03:37<1:11:32, 27.00s/epoch, loss=1.21, accuracy=0.72, val_loss=2.15, val_accuracy=0.465, lr=0.1]   5%|▍         | 8/166 [04:03<1:09:50, 26.52s/epoch, loss=1.21, accuracy=0.722, val_loss=2.13, val_accuracy=0.513, lr=0.1]  5%|▌         | 9/166 [04:28<1:08:30, 26.18s/epoch, loss=1.2, accuracy=0.731, val_loss=2.02, val_accuracy=0.476, lr=0.1]   6%|▌         | 10/166 [04:54<1:07:29, 25.96s/epoch, loss=1.2, accuracy=0.733, val_loss=2.01, val_accuracy=0.523, lr=0.1]  7%|▋         | 11/166 [05:19<1:06:43, 25.83s/epoch, loss=1.19, accuracy=0.734, val_loss=2.34, val_accuracy=0.362, lr=0.1]  7%|▋         | 12/166 [05:45<1:06:01, 25.72s/epoch, loss=1.19, accuracy=0.736, val_loss=1.96, val_accuracy=0.496, lr=0.1]  8%|▊         | 13/166 [06:10<1:05:16, 25.60s/epoch, loss=1.19, accuracy=0.738, val_loss=1.91, val_accuracy=0.527, lr=0.1]  8%|▊         | 14/166 [06:36<1:04:45, 25.56s/epoch, loss=1.18, accuracy=0.742, val_loss=1.99, val_accuracy=0.477, lr=0.1]  9%|▉         | 15/166 [07:01<1:04:11, 25.51s/epoch, loss=1.19, accuracy=0.741, val_loss=2.36, val_accuracy=0.439, lr=0.1] 10%|▉         | 16/166 [07:26<1:03:44, 25.49s/epoch, loss=1.17, accuracy=0.745, val_loss=2.09, val_accuracy=0.479, lr=0.1] 10%|█         | 17/166 [07:52<1:03:14, 25.47s/epoch, loss=1.18, accuracy=0.741, val_loss=2.68, val_accuracy=0.308, lr=0.1] 11%|█         | 18/166 [08:17<1:02:47, 25.46s/epoch, loss=1.17, accuracy=0.744, val_loss=2.08, val_accuracy=0.41, lr=0.1]  11%|█▏        | 19/166 [08:43<1:02:13, 25.40s/epoch, loss=1.18, accuracy=0.745, val_loss=2.1, val_accuracy=0.415, lr=0.1] 12%|█▏        | 20/166 [09:08<1:01:54, 25.44s/epoch, loss=1.17, accuracy=0.746, val_loss=1.62, val_accuracy=0.602, lr=0.1] 13%|█▎        | 21/166 [09:34<1:01:32, 25.46s/epoch, loss=1.17, accuracy=0.745, val_loss=1.85, val_accuracy=0.562, lr=0.1] 13%|█▎        | 22/166 [09:59<1:01:07, 25.47s/epoch, loss=1.16, accuracy=0.747, val_loss=1.88, val_accuracy=0.518, lr=0.1] 14%|█▍        | 23/166 [10:25<1:00:58, 25.58s/epoch, loss=1.17, accuracy=0.748, val_loss=2.02, val_accuracy=0.532, lr=0.1] 14%|█▍        | 24/166 [10:51<1:00:37, 25.62s/epoch, loss=1.16, accuracy=0.749, val_loss=1.64, val_accuracy=0.604, lr=0.1] 15%|█▌        | 25/166 [11:16<1:00:04, 25.56s/epoch, loss=1.16, accuracy=0.747, val_loss=2.05, val_accuracy=0.448, lr=0.1] 16%|█▌        | 26/166 [11:42<59:38, 25.56s/epoch, loss=1.17, accuracy=0.748, val_loss=2.21, val_accuracy=0.505, lr=0.1]   16%|█▋        | 27/166 [12:07<59:01, 25.48s/epoch, loss=1.16, accuracy=0.75, val_loss=2.02, val_accuracy=0.451, lr=0.1]  17%|█▋        | 28/166 [12:32<58:37, 25.49s/epoch, loss=1.15, accuracy=0.75, val_loss=1.71, val_accuracy=0.54, lr=0.1]  17%|█▋        | 29/166 [12:58<58:08, 25.46s/epoch, loss=1.15, accuracy=0.749, val_loss=2.3, val_accuracy=0.415, lr=0.1] 18%|█▊        | 30/166 [13:23<57:46, 25.49s/epoch, loss=1.15, accuracy=0.752, val_loss=1.74, val_accuracy=0.549, lr=0.1] 19%|█▊        | 31/166 [13:49<57:12, 25.43s/epoch, loss=1.15, accuracy=0.751, val_loss=2.07, val_accuracy=0.446, lr=0.1] 19%|█▉        | 32/166 [14:14<56:53, 25.47s/epoch, loss=1.15, accuracy=0.751, val_loss=2.17, val_accuracy=0.516, lr=0.1] 20%|█▉        | 33/166 [14:40<56:23, 25.44s/epoch, loss=1.14, accuracy=0.756, val_loss=2.43, val_accuracy=0.313, lr=0.1] 20%|██        | 34/166 [15:05<56:01, 25.47s/epoch, loss=1.16, accuracy=0.752, val_loss=2.15, val_accuracy=0.426, lr=0.1] 21%|██        | 35/166 [15:31<55:35, 25.46s/epoch, loss=1.14, accuracy=0.753, val_loss=2.95, val_accuracy=0.331, lr=0.1] 22%|██▏       | 36/166 [15:56<55:15, 25.51s/epoch, loss=1.14, accuracy=0.753, val_loss=1.91, val_accuracy=0.53, lr=0.1]  22%|██▏       | 37/166 [16:21<54:44, 25.46s/epoch, loss=1.14, accuracy=0.751, val_loss=2.63, val_accuracy=0.39, lr=0.1] 23%|██▎       | 38/166 [16:47<54:21, 25.48s/epoch, loss=1.14, accuracy=0.754, val_loss=1.81, val_accuracy=0.53, lr=0.1] 23%|██▎       | 39/166 [17:13<54:04, 25.55s/epoch, loss=1.13, accuracy=0.757, val_loss=2.26, val_accuracy=0.44, lr=0.1] 24%|██▍       | 40/166 [17:38<53:33, 25.50s/epoch, loss=1.14, accuracy=0.752, val_loss=2.08, val_accuracy=0.482, lr=0.1] 25%|██▍       | 41/166 [18:04<53:06, 25.49s/epoch, loss=1.13, accuracy=0.753, val_loss=3.08, val_accuracy=0.351, lr=0.1] 25%|██▌       | 42/166 [18:29<52:44, 25.52s/epoch, loss=1.13, accuracy=0.756, val_loss=1.82, val_accuracy=0.539, lr=0.1] 26%|██▌       | 43/166 [18:55<52:17, 25.51s/epoch, loss=1.13, accuracy=0.753, val_loss=2.43, val_accuracy=0.338, lr=0.1] 27%|██▋       | 44/166 [19:20<51:56, 25.55s/epoch, loss=1.13, accuracy=0.756, val_loss=1.91, val_accuracy=0.502, lr=0.1] 27%|██▋       | 45/166 [19:45<51:18, 25.44s/epoch, loss=1.13, accuracy=0.754, val_loss=1.81, val_accuracy=0.5, lr=0.1]   28%|██▊       | 46/166 [20:11<50:58, 25.49s/epoch, loss=1.13, accuracy=0.756, val_loss=4.05, val_accuracy=0.291, lr=0.1] 28%|██▊       | 47/166 [20:36<50:28, 25.45s/epoch, loss=1.12, accuracy=0.757, val_loss=1.74, val_accuracy=0.558, lr=0.1] 29%|██▉       | 48/166 [21:02<49:59, 25.42s/epoch, loss=1.13, accuracy=0.756, val_loss=1.41, val_accuracy=0.658, lr=0.1] 30%|██▉       | 49/166 [21:27<49:32, 25.41s/epoch, loss=1.13, accuracy=0.758, val_loss=1.95, val_accuracy=0.484, lr=0.1] 30%|███       | 50/166 [21:53<49:19, 25.51s/epoch, loss=1.13, accuracy=0.758, val_loss=4.46, val_accuracy=0.263, lr=0.1] 31%|███       | 51/166 [22:18<48:51, 25.49s/epoch, loss=1.13, accuracy=0.755, val_loss=2.59, val_accuracy=0.411, lr=0.1] 31%|███▏      | 52/166 [22:44<48:29, 25.52s/epoch, loss=1.12, accuracy=0.758, val_loss=2.85, val_accuracy=0.308, lr=0.1] 32%|███▏      | 53/166 [23:10<48:09, 25.57s/epoch, loss=1.13, accuracy=0.756, val_loss=1.41, val_accuracy=0.651, lr=0.1] 33%|███▎      | 54/166 [23:35<47:53, 25.65s/epoch, loss=1.12, accuracy=0.754, val_loss=2.1, val_accuracy=0.512, lr=0.1]  33%|███▎      | 55/166 [24:01<47:23, 25.62s/epoch, loss=1.12, accuracy=0.758, val_loss=1.64, val_accuracy=0.576, lr=0.1] 34%|███▎      | 56/166 [24:26<46:52, 25.57s/epoch, loss=1.12, accuracy=0.755, val_loss=4.19, val_accuracy=0.297, lr=0.1] 34%|███▍      | 57/166 [24:52<46:26, 25.56s/epoch, loss=1.13, accuracy=0.754, val_loss=3.83, val_accuracy=0.332, lr=0.1] 35%|███▍      | 58/166 [25:17<45:56, 25.52s/epoch, loss=1.12, accuracy=0.759, val_loss=2.47, val_accuracy=0.359, lr=0.1] 36%|███▌      | 59/166 [25:43<45:39, 25.60s/epoch, loss=1.13, accuracy=0.756, val_loss=1.61, val_accuracy=0.582, lr=0.1] 36%|███▌      | 60/166 [26:09<45:10, 25.57s/epoch, loss=1.12, accuracy=0.758, val_loss=2.53, val_accuracy=0.433, lr=0.1] 37%|███▋      | 61/166 [26:34<44:43, 25.56s/epoch, loss=1.13, accuracy=0.754, val_loss=2.7, val_accuracy=0.298, lr=0.1]  37%|███▋      | 62/166 [26:59<44:06, 25.44s/epoch, loss=1.12, accuracy=0.759, val_loss=4.28, val_accuracy=0.346, lr=0.1] 38%|███▊      | 63/166 [27:25<43:41, 25.45s/epoch, loss=1.13, accuracy=0.754, val_loss=2.33, val_accuracy=0.422, lr=0.1] 39%|███▊      | 64/166 [27:50<43:19, 25.48s/epoch, loss=1.12, accuracy=0.758, val_loss=1.91, val_accuracy=0.486, lr=0.1] 39%|███▉      | 65/166 [28:16<42:51, 25.46s/epoch, loss=1.12, accuracy=0.756, val_loss=2.45, val_accuracy=0.422, lr=0.1] 40%|███▉      | 66/166 [28:41<42:30, 25.51s/epoch, loss=1.11, accuracy=0.758, val_loss=2.38, val_accuracy=0.445, lr=0.1] 40%|████      | 67/166 [29:07<42:03, 25.49s/epoch, loss=1.12, accuracy=0.757, val_loss=1.99, val_accuracy=0.464, lr=0.1] 41%|████      | 68/166 [29:33<41:44, 25.55s/epoch, loss=0.918, accuracy=0.816, val_loss=0.909, val_accuracy=0.799, lr=0.01] 42%|████▏     | 69/166 [29:58<41:16, 25.53s/epoch, loss=0.731, accuracy=0.85, val_loss=0.873, val_accuracy=0.789, lr=0.01]  42%|████▏     | 70/166 [30:24<40:47, 25.49s/epoch, loss=0.651, accuracy=0.858, val_loss=0.762, val_accuracy=0.815, lr=0.01] 43%|████▎     | 71/166 [30:49<40:28, 25.56s/epoch, loss=0.608, accuracy=0.859, val_loss=0.832, val_accuracy=0.785, lr=0.01] 43%|████▎     | 72/166 [31:15<40:03, 25.56s/epoch, loss=0.582, accuracy=0.861, val_loss=0.816, val_accuracy=0.79, lr=0.01]  44%|████▍     | 73/166 [31:40<39:31, 25.50s/epoch, loss=0.578, accuracy=0.862, val_loss=1.27, val_accuracy=0.676, lr=0.01] 45%|████▍     | 74/166 [32:06<39:11, 25.56s/epoch, loss=0.563, accuracy=0.864, val_loss=0.814, val_accuracy=0.789, lr=0.01] 45%|████▌     | 75/166 [32:31<38:43, 25.54s/epoch, loss=0.563, accuracy=0.866, val_loss=0.693, val_accuracy=0.825, lr=0.01] 46%|████▌     | 76/166 [32:57<38:22, 25.58s/epoch, loss=0.562, accuracy=0.866, val_loss=0.892, val_accuracy=0.761, lr=0.01] 46%|████▋     | 77/166 [33:23<37:57, 25.59s/epoch, loss=0.559, accuracy=0.869, val_loss=0.95, val_accuracy=0.752, lr=0.01]  47%|████▋     | 78/166 [33:48<37:31, 25.58s/epoch, loss=0.558, accuracy=0.87, val_loss=0.797, val_accuracy=0.792, lr=0.01] 48%|████▊     | 79/166 [34:14<37:09, 25.63s/epoch, loss=0.555, accuracy=0.871, val_loss=1.2, val_accuracy=0.705, lr=0.01]  48%|████▊     | 80/166 [34:40<36:42, 25.61s/epoch, loss=0.557, accuracy=0.872, val_loss=0.824, val_accuracy=0.787, lr=0.01] 49%|████▉     | 81/166 [35:05<36:17, 25.61s/epoch, loss=0.557, accuracy=0.873, val_loss=0.901, val_accuracy=0.775, lr=0.01] 49%|████▉     | 82/166 [35:31<35:50, 25.60s/epoch, loss=0.556, accuracy=0.875, val_loss=1.37, val_accuracy=0.676, lr=0.01]  50%|█████     | 83/166 [35:56<35:18, 25.53s/epoch, loss=0.553, accuracy=0.875, val_loss=0.828, val_accuracy=0.775, lr=0.01] 51%|█████     | 84/166 [36:22<34:52, 25.52s/epoch, loss=0.555, accuracy=0.875, val_loss=0.92, val_accuracy=0.775, lr=0.01]  51%|█████     | 85/166 [36:47<34:27, 25.53s/epoch, loss=0.551, accuracy=0.877, val_loss=0.928, val_accuracy=0.768, lr=0.01] 52%|█████▏    | 86/166 [37:12<33:58, 25.49s/epoch, loss=0.56, accuracy=0.874, val_loss=0.767, val_accuracy=0.809, lr=0.01]  52%|█████▏    | 87/166 [37:38<33:34, 25.49s/epoch, loss=0.552, accuracy=0.879, val_loss=0.962, val_accuracy=0.767, lr=0.01] 53%|█████▎    | 88/166 [38:03<33:06, 25.47s/epoch, loss=0.551, accuracy=0.88, val_loss=0.704, val_accuracy=0.83, lr=0.01]   54%|█████▎    | 89/166 [38:29<32:41, 25.47s/epoch, loss=0.556, accuracy=0.877, val_loss=0.863, val_accuracy=0.78, lr=0.01] 54%|█████▍    | 90/166 [38:54<32:19, 25.52s/epoch, loss=0.557, accuracy=0.878, val_loss=0.762, val_accuracy=0.814, lr=0.01] 55%|█████▍    | 91/166 [39:20<31:59, 25.60s/epoch, loss=0.553, accuracy=0.88, val_loss=0.863, val_accuracy=0.782, lr=0.01]  55%|█████▌    | 92/166 [39:46<31:33, 25.59s/epoch, loss=0.551, accuracy=0.88, val_loss=0.75, val_accuracy=0.82, lr=0.01]   56%|█████▌    | 93/166 [40:11<31:02, 25.51s/epoch, loss=0.553, accuracy=0.88, val_loss=0.79, val_accuracy=0.8, lr=0.01]  57%|█████▋    | 94/166 [40:37<30:33, 25.46s/epoch, loss=0.552, accuracy=0.881, val_loss=0.807, val_accuracy=0.799, lr=0.01] 57%|█████▋    | 95/166 [41:02<30:07, 25.46s/epoch, loss=0.555, accuracy=0.88, val_loss=0.768, val_accuracy=0.813, lr=0.01]  58%|█████▊    | 96/166 [41:28<29:45, 25.51s/epoch, loss=0.551, accuracy=0.883, val_loss=0.727, val_accuracy=0.83, lr=0.01] 58%|█████▊    | 97/166 [41:53<29:24, 25.57s/epoch, loss=0.554, accuracy=0.882, val_loss=0.811, val_accuracy=0.803, lr=0.01] 59%|█████▉    | 98/166 [42:19<28:59, 25.58s/epoch, loss=0.549, accuracy=0.883, val_loss=0.935, val_accuracy=0.764, lr=0.01] 60%|█████▉    | 99/166 [42:45<28:34, 25.59s/epoch, loss=0.549, accuracy=0.885, val_loss=0.848, val_accuracy=0.795, lr=0.01] 60%|██████    | 100/166 [43:10<28:04, 25.52s/epoch, loss=0.55, accuracy=0.885, val_loss=0.97, val_accuracy=0.758, lr=0.01]  61%|██████    | 101/166 [43:35<27:37, 25.50s/epoch, loss=0.473, accuracy=0.912, val_loss=0.536, val_accuracy=0.888, lr=0.001] 61%|██████▏   | 102/166 [44:01<27:16, 25.57s/epoch, loss=0.421, accuracy=0.928, val_loss=0.519, val_accuracy=0.893, lr=0.001] 62%|██████▏   | 103/166 [44:27<26:51, 25.58s/epoch, loss=0.399, accuracy=0.933, val_loss=0.503, val_accuracy=0.897, lr=0.001] 63%|██████▎   | 104/166 [44:52<26:22, 25.53s/epoch, loss=0.384, accuracy=0.936, val_loss=0.503, val_accuracy=0.897, lr=0.001] 63%|██████▎   | 105/166 [45:17<25:53, 25.47s/epoch, loss=0.37, accuracy=0.94, val_loss=0.487, val_accuracy=0.902, lr=0.001]   64%|██████▍   | 106/166 [45:43<25:26, 25.44s/epoch, loss=0.357, accuracy=0.942, val_loss=0.49, val_accuracy=0.897, lr=0.001] 64%|██████▍   | 107/166 [46:08<24:57, 25.39s/epoch, loss=0.346, accuracy=0.944, val_loss=0.482, val_accuracy=0.901, lr=0.001] 65%|██████▌   | 108/166 [46:33<24:31, 25.36s/epoch, loss=0.336, accuracy=0.946, val_loss=0.465, val_accuracy=0.902, lr=0.001] 66%|██████▌   | 109/166 [46:59<24:06, 25.37s/epoch, loss=0.326, accuracy=0.948, val_loss=0.473, val_accuracy=0.902, lr=0.001] 66%|██████▋   | 110/166 [47:24<23:43, 25.42s/epoch, loss=0.318, accuracy=0.949, val_loss=0.475, val_accuracy=0.899, lr=0.001] 67%|██████▋   | 111/166 [47:50<23:17, 25.40s/epoch, loss=0.311, accuracy=0.949, val_loss=0.472, val_accuracy=0.896, lr=0.001] 67%|██████▋   | 112/166 [48:15<22:47, 25.33s/epoch, loss=0.305, accuracy=0.951, val_loss=0.472, val_accuracy=0.895, lr=0.001] 68%|██████▊   | 113/166 [48:40<22:19, 25.28s/epoch, loss=0.296, accuracy=0.953, val_loss=0.466, val_accuracy=0.898, lr=0.001] 69%|██████▊   | 114/166 [49:05<21:54, 25.29s/epoch, loss=0.288, accuracy=0.954, val_loss=0.462, val_accuracy=0.9, lr=0.001]   69%|██████▉   | 115/166 [49:31<21:30, 25.29s/epoch, loss=0.283, accuracy=0.954, val_loss=0.47, val_accuracy=0.899, lr=0.001] 70%|██████▉   | 116/166 [49:56<21:03, 25.26s/epoch, loss=0.279, accuracy=0.955, val_loss=0.47, val_accuracy=0.892, lr=0.001] 70%|███████   | 117/166 [50:21<20:44, 25.40s/epoch, loss=0.273, accuracy=0.956, val_loss=0.474, val_accuracy=0.898, lr=0.001] 71%|███████   | 118/166 [50:47<20:20, 25.42s/epoch, loss=0.268, accuracy=0.957, val_loss=0.463, val_accuracy=0.897, lr=0.001] 72%|███████▏  | 119/166 [51:12<19:52, 25.37s/epoch, loss=0.26, accuracy=0.959, val_loss=0.456, val_accuracy=0.899, lr=0.001]  72%|███████▏  | 120/166 [51:38<19:27, 25.38s/epoch, loss=0.257, accuracy=0.958, val_loss=0.463, val_accuracy=0.896, lr=0.001] 73%|███████▎  | 121/166 [52:03<19:00, 25.35s/epoch, loss=0.25, accuracy=0.959, val_loss=0.459, val_accuracy=0.896, lr=0.001]  73%|███████▎  | 122/166 [52:28<18:34, 25.32s/epoch, loss=0.251, accuracy=0.957, val_loss=0.473, val_accuracy=0.893, lr=0.001] 74%|███████▍  | 123/166 [52:53<18:08, 25.32s/epoch, loss=0.246, accuracy=0.96, val_loss=0.458, val_accuracy=0.896, lr=0.001]  75%|███████▍  | 124/166 [53:19<17:45, 25.36s/epoch, loss=0.237, accuracy=0.962, val_loss=0.485, val_accuracy=0.892, lr=0.001] 75%|███████▌  | 125/166 [53:44<17:15, 25.26s/epoch, loss=0.241, accuracy=0.958, val_loss=0.47, val_accuracy=0.896, lr=0.001]  76%|███████▌  | 126/166 [54:09<16:51, 25.29s/epoch, loss=0.234, accuracy=0.96, val_loss=0.477, val_accuracy=0.892, lr=0.001] 77%|███████▋  | 127/166 [54:35<16:28, 25.35s/epoch, loss=0.233, accuracy=0.961, val_loss=0.466, val_accuracy=0.893, lr=0.001] 77%|███████▋  | 128/166 [55:00<16:04, 25.38s/epoch, loss=0.231, accuracy=0.961, val_loss=0.47, val_accuracy=0.891, lr=0.001]  78%|███████▊  | 129/166 [55:25<15:36, 25.32s/epoch, loss=0.227, accuracy=0.962, val_loss=0.472, val_accuracy=0.891, lr=0.001] 78%|███████▊  | 130/166 [55:51<15:10, 25.29s/epoch, loss=0.224, accuracy=0.963, val_loss=0.468, val_accuracy=0.89, lr=0.001]  79%|███████▉  | 131/166 [56:16<14:44, 25.27s/epoch, loss=0.225, accuracy=0.961, val_loss=0.463, val_accuracy=0.893, lr=0.001] 80%|███████▉  | 132/166 [56:41<14:20, 25.32s/epoch, loss=0.223, accuracy=0.962, val_loss=0.478, val_accuracy=0.888, lr=0.001] 80%|████████  | 133/166 [57:06<13:53, 25.26s/epoch, loss=0.224, accuracy=0.961, val_loss=0.478, val_accuracy=0.889, lr=0.001] 81%|████████  | 134/166 [57:32<13:29, 25.30s/epoch, loss=0.203, accuracy=0.969, val_loss=0.422, val_accuracy=0.905, lr=1e-04] 81%|████████▏ | 135/166 [57:57<13:02, 25.26s/epoch, loss=0.19, accuracy=0.974, val_loss=0.411, val_accuracy=0.906, lr=1e-04]  82%|████████▏ | 136/166 [58:22<12:38, 25.28s/epoch, loss=0.185, accuracy=0.977, val_loss=0.412, val_accuracy=0.905, lr=1e-04] 83%|████████▎ | 137/166 [58:48<12:14, 25.33s/epoch, loss=0.182, accuracy=0.977, val_loss=0.411, val_accuracy=0.907, lr=1e-04] 83%|████████▎ | 138/166 [59:13<11:48, 25.30s/epoch, loss=0.18, accuracy=0.978, val_loss=0.412, val_accuracy=0.905, lr=1e-04]  84%|████████▎ | 139/166 [59:38<11:21, 25.25s/epoch, loss=0.177, accuracy=0.979, val_loss=0.41, val_accuracy=0.905, lr=1e-04] 84%|████████▍ | 140/166 [1:00:03<10:55, 25.21s/epoch, loss=0.176, accuracy=0.979, val_loss=0.409, val_accuracy=0.906, lr=1e-04] 85%|████████▍ | 141/166 [1:00:29<10:31, 25.26s/epoch, loss=0.174, accuracy=0.979, val_loss=0.406, val_accuracy=0.907, lr=1e-04] 86%|████████▌ | 142/166 [1:00:54<10:04, 25.19s/epoch, loss=0.173, accuracy=0.981, val_loss=0.411, val_accuracy=0.908, lr=1e-04] 86%|████████▌ | 143/166 [1:01:19<09:39, 25.20s/epoch, loss=0.171, accuracy=0.981, val_loss=0.408, val_accuracy=0.907, lr=1e-04] 87%|████████▋ | 144/166 [1:01:44<09:14, 25.21s/epoch, loss=0.171, accuracy=0.98, val_loss=0.41, val_accuracy=0.907, lr=1e-04]   87%|████████▋ | 145/166 [1:02:09<08:49, 25.22s/epoch, loss=0.168, accuracy=0.981, val_loss=0.411, val_accuracy=0.907, lr=1e-04] 88%|████████▊ | 146/166 [1:02:35<08:24, 25.22s/epoch, loss=0.167, accuracy=0.982, val_loss=0.412, val_accuracy=0.907, lr=1e-04] 89%|████████▊ | 147/166 [1:03:00<07:59, 25.22s/epoch, loss=0.166, accuracy=0.982, val_loss=0.414, val_accuracy=0.908, lr=1e-04] 89%|████████▉ | 148/166 [1:03:25<07:33, 25.18s/epoch, loss=0.166, accuracy=0.982, val_loss=0.416, val_accuracy=0.907, lr=1e-04] 90%|████████▉ | 149/166 [1:03:50<07:08, 25.19s/epoch, loss=0.164, accuracy=0.983, val_loss=0.413, val_accuracy=0.907, lr=1e-04] 90%|█████████ | 150/166 [1:04:15<06:43, 25.21s/epoch, loss=0.163, accuracy=0.982, val_loss=0.411, val_accuracy=0.906, lr=1e-04] 91%|█████████ | 151/166 [1:04:41<06:18, 25.23s/epoch, loss=0.162, accuracy=0.983, val_loss=0.413, val_accuracy=0.906, lr=5e-5]  92%|█████████▏| 152/166 [1:05:06<05:53, 25.25s/epoch, loss=0.161, accuracy=0.983, val_loss=0.412, val_accuracy=0.907, lr=5e-5] 92%|█████████▏| 153/166 [1:05:31<05:27, 25.22s/epoch, loss=0.161, accuracy=0.983, val_loss=0.412, val_accuracy=0.907, lr=5e-5] 93%|█████████▎| 154/166 [1:05:56<05:03, 25.28s/epoch, loss=0.16, accuracy=0.983, val_loss=0.413, val_accuracy=0.908, lr=5e-5]  93%|█████████▎| 155/166 [1:06:22<04:37, 25.22s/epoch, loss=0.16, accuracy=0.984, val_loss=0.413, val_accuracy=0.907, lr=5e-5] 94%|█████████▍| 156/166 [1:06:47<04:11, 25.19s/epoch, loss=0.159, accuracy=0.984, val_loss=0.412, val_accuracy=0.907, lr=5e-5] 95%|█████████▍| 157/166 [1:07:11<03:45, 25.05s/epoch, loss=0.16, accuracy=0.984, val_loss=0.415, val_accuracy=0.907, lr=5e-5]  95%|█████████▌| 158/166 [1:07:36<03:20, 25.05s/epoch, loss=0.159, accuracy=0.984, val_loss=0.414, val_accuracy=0.906, lr=5e-5] 96%|█████████▌| 159/166 [1:08:02<02:55, 25.06s/epoch, loss=0.158, accuracy=0.985, val_loss=0.417, val_accuracy=0.906, lr=5e-5] 96%|█████████▋| 160/166 [1:08:27<02:30, 25.05s/epoch, loss=0.157, accuracy=0.985, val_loss=0.416, val_accuracy=0.907, lr=5e-5] 97%|█████████▋| 161/166 [1:08:52<02:05, 25.04s/epoch, loss=0.157, accuracy=0.984, val_loss=0.413, val_accuracy=0.909, lr=5e-5] 98%|█████████▊| 162/166 [1:09:17<01:40, 25.13s/epoch, loss=0.156, accuracy=0.984, val_loss=0.418, val_accuracy=0.909, lr=5e-5] 98%|█████████▊| 163/166 [1:09:42<01:15, 25.19s/epoch, loss=0.157, accuracy=0.984, val_loss=0.415, val_accuracy=0.907, lr=5e-5] 99%|█████████▉| 164/166 [1:10:07<00:50, 25.12s/epoch, loss=0.156, accuracy=0.984, val_loss=0.415, val_accuracy=0.909, lr=5e-5] 99%|█████████▉| 165/166 [1:10:32<00:25, 25.11s/epoch, loss=0.156, accuracy=0.985, val_loss=0.415, val_accuracy=0.907, lr=5e-5]100%|██████████| 166/166 [1:10:57<00:00, 25.12s/epoch, loss=0.155, accuracy=0.985, val_loss=0.417, val_accuracy=0.908, lr=5e-5]100%|██████████| 166/166 [1:10:57<00:00, 25.65s/epoch, loss=0.155, accuracy=0.985, val_loss=0.417, val_accuracy=0.908, lr=5e-5]
Using real-time data augmentation.
Only one model saved

Loading model: 09_07_cifar10_ResNet20v1.h5
Test score: 0.4169355034828186
Test accuracy: 0.9081000089645386


* * * Run SGD for ID = 9_8. * * *


2024-03-13 05:46:55.842112: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-13 05:46:58.844557: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-13 05:46:58.845913: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-13 05:46:58.892492: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:3b:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-13 05:46:58.892541: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-13 05:46:58.896522: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-13 05:46:58.896597: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-13 05:46:58.899617: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-13 05:46:58.900512: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-13 05:46:58.903767: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-13 05:46:58.905796: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-13 05:46:58.912269: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-13 05:46:58.913043: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-13 05:46:58.913133: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-13 05:47:00.211031: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-13 05:47:00.211695: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-13 05:47:00.212474: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:3b:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-13 05:47:00.212511: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-13 05:47:00.212554: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-13 05:47:00.212568: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-13 05:47:00.212582: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-13 05:47:00.212596: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-13 05:47:00.212609: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-13 05:47:00.212623: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-13 05:47:00.212637: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-13 05:47:00.213187: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-13 05:47:00.213230: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-13 05:47:00.895854: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-13 05:47:00.895916: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-13 05:47:00.895928: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-13 05:47:00.896978: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:3b:00.0, compute capability: 6.1)
{'id': '09_08', 'seed': 8, 'out_folder': 'results/epoch_budget_2', 'batch_size': 128, 'epochs': 166, 'validation_split': 0.0, 'checkpointing': False, 'checkpoint_every': -1, 'hold_out_validation_split': 0.0, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'bootstrapping': False, 'num_classes': 10, 'SSE_lr': False, 'test_time_augmentation': False, 'debug': False, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
y_train shape: (50000, 10)
x_val shape: (10000, 32, 32, 3)
y_val shape: (10000, 10)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/166 [00:00<?, ?epoch/s]2024-03-13 05:47:01.538132: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-13 05:47:01.549998: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2100000000 Hz
2024-03-13 05:47:03.609014: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-13 05:47:03.856789: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-13 05:47:04.902607: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-13 05:47:04.943736: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/166 [00:54<2:30:25, 54.70s/epoch, loss=2.75, accuracy=0.443, val_loss=2.28, val_accuracy=0.428, lr=0.1]  1%|          | 2/166 [01:20<1:42:36, 37.54s/epoch, loss=1.4, accuracy=0.629, val_loss=2.11, val_accuracy=0.479, lr=0.1]   2%|▏         | 3/166 [01:45<1:27:08, 32.07s/epoch, loss=1.27, accuracy=0.682, val_loss=1.76, val_accuracy=0.543, lr=0.1]  2%|▏         | 4/166 [02:11<1:19:47, 29.55s/epoch, loss=1.23, accuracy=0.705, val_loss=1.74, val_accuracy=0.561, lr=0.1]  3%|▎         | 5/166 [02:36<1:15:22, 28.09s/epoch, loss=1.21, accuracy=0.716, val_loss=1.98, val_accuracy=0.514, lr=0.1]  4%|▎         | 6/166 [03:02<1:12:30, 27.19s/epoch, loss=1.2, accuracy=0.723, val_loss=2.87, val_accuracy=0.386, lr=0.1]   4%|▍         | 7/166 [03:28<1:10:43, 26.69s/epoch, loss=1.19, accuracy=0.73, val_loss=1.77, val_accuracy=0.556, lr=0.1]  5%|▍         | 8/166 [03:53<1:09:21, 26.34s/epoch, loss=1.18, accuracy=0.733, val_loss=1.51, val_accuracy=0.612, lr=0.1]  5%|▌         | 9/166 [04:19<1:08:13, 26.07s/epoch, loss=1.17, accuracy=0.733, val_loss=3.23, val_accuracy=0.325, lr=0.1]  6%|▌         | 10/166 [04:44<1:07:18, 25.89s/epoch, loss=1.16, accuracy=0.738, val_loss=1.62, val_accuracy=0.593, lr=0.1]  7%|▋         | 11/166 [05:10<1:06:38, 25.80s/epoch, loss=1.16, accuracy=0.741, val_loss=2.35, val_accuracy=0.442, lr=0.1]  7%|▋         | 12/166 [05:35<1:05:53, 25.67s/epoch, loss=1.15, accuracy=0.743, val_loss=2.18, val_accuracy=0.449, lr=0.1]  8%|▊         | 13/166 [06:01<1:05:14, 25.59s/epoch, loss=1.16, accuracy=0.744, val_loss=1.5, val_accuracy=0.631, lr=0.1]   8%|▊         | 14/166 [06:26<1:04:43, 25.55s/epoch, loss=1.15, accuracy=0.748, val_loss=1.76, val_accuracy=0.511, lr=0.1]  9%|▉         | 15/166 [06:51<1:04:06, 25.47s/epoch, loss=1.14, accuracy=0.749, val_loss=2.3, val_accuracy=0.453, lr=0.1]  10%|▉         | 16/166 [07:17<1:03:40, 25.47s/epoch, loss=1.14, accuracy=0.747, val_loss=2.53, val_accuracy=0.424, lr=0.1] 10%|█         | 17/166 [07:42<1:03:08, 25.43s/epoch, loss=1.14, accuracy=0.75, val_loss=2.69, val_accuracy=0.375, lr=0.1]  11%|█         | 18/166 [08:08<1:02:50, 25.48s/epoch, loss=1.14, accuracy=0.748, val_loss=2.47, val_accuracy=0.419, lr=0.1] 11%|█▏        | 19/166 [08:33<1:02:28, 25.50s/epoch, loss=1.14, accuracy=0.75, val_loss=2.11, val_accuracy=0.436, lr=0.1]  12%|█▏        | 20/166 [08:59<1:01:56, 25.45s/epoch, loss=1.13, accuracy=0.748, val_loss=1.79, val_accuracy=0.555, lr=0.1] 13%|█▎        | 21/166 [09:24<1:01:41, 25.53s/epoch, loss=1.13, accuracy=0.751, val_loss=1.73, val_accuracy=0.583, lr=0.1] 13%|█▎        | 22/166 [09:50<1:01:08, 25.48s/epoch, loss=1.13, accuracy=0.751, val_loss=2.22, val_accuracy=0.483, lr=0.1] 14%|█▍        | 23/166 [10:15<1:00:48, 25.51s/epoch, loss=1.13, accuracy=0.751, val_loss=1.88, val_accuracy=0.476, lr=0.1] 14%|█▍        | 24/166 [10:41<1:00:22, 25.51s/epoch, loss=1.13, accuracy=0.751, val_loss=2, val_accuracy=0.493, lr=0.1]    15%|█▌        | 25/166 [11:06<1:00:04, 25.57s/epoch, loss=1.13, accuracy=0.752, val_loss=1.81, val_accuracy=0.545, lr=0.1] 16%|█▌        | 26/166 [11:32<59:39, 25.57s/epoch, loss=1.12, accuracy=0.752, val_loss=3.39, val_accuracy=0.289, lr=0.1]   16%|█▋        | 27/166 [11:57<59:06, 25.52s/epoch, loss=1.12, accuracy=0.754, val_loss=1.82, val_accuracy=0.549, lr=0.1] 17%|█▋        | 28/166 [12:23<58:33, 25.46s/epoch, loss=1.12, accuracy=0.755, val_loss=2.12, val_accuracy=0.511, lr=0.1] 17%|█▋        | 29/166 [12:48<58:06, 25.45s/epoch, loss=1.12, accuracy=0.755, val_loss=1.9, val_accuracy=0.486, lr=0.1]  18%|█▊        | 30/166 [13:14<57:45, 25.48s/epoch, loss=1.11, accuracy=0.755, val_loss=2.16, val_accuracy=0.439, lr=0.1] 19%|█▊        | 31/166 [13:39<57:22, 25.50s/epoch, loss=1.12, accuracy=0.754, val_loss=1.87, val_accuracy=0.552, lr=0.1] 19%|█▉        | 32/166 [14:05<57:02, 25.54s/epoch, loss=1.11, accuracy=0.756, val_loss=2.08, val_accuracy=0.538, lr=0.1] 20%|█▉        | 33/166 [14:30<56:25, 25.46s/epoch, loss=1.12, accuracy=0.755, val_loss=2.17, val_accuracy=0.446, lr=0.1] 20%|██        | 34/166 [14:56<56:09, 25.52s/epoch, loss=1.11, accuracy=0.757, val_loss=2.17, val_accuracy=0.409, lr=0.1] 21%|██        | 35/166 [15:21<55:48, 25.56s/epoch, loss=1.11, accuracy=0.757, val_loss=1.77, val_accuracy=0.577, lr=0.1] 22%|██▏       | 36/166 [15:47<55:15, 25.50s/epoch, loss=1.12, accuracy=0.755, val_loss=2.34, val_accuracy=0.386, lr=0.1] 22%|██▏       | 37/166 [16:12<54:50, 25.51s/epoch, loss=1.11, accuracy=0.756, val_loss=2.38, val_accuracy=0.436, lr=0.1] 23%|██▎       | 38/166 [16:38<54:17, 25.45s/epoch, loss=1.11, accuracy=0.757, val_loss=2.31, val_accuracy=0.507, lr=0.1] 23%|██▎       | 39/166 [17:03<53:53, 25.46s/epoch, loss=1.11, accuracy=0.755, val_loss=1.67, val_accuracy=0.579, lr=0.1] 24%|██▍       | 40/166 [17:29<53:29, 25.47s/epoch, loss=1.11, accuracy=0.756, val_loss=3.8, val_accuracy=0.353, lr=0.1]  25%|██▍       | 41/166 [17:54<53:03, 25.47s/epoch, loss=1.11, accuracy=0.755, val_loss=1.54, val_accuracy=0.619, lr=0.1] 25%|██▌       | 42/166 [18:20<52:40, 25.49s/epoch, loss=1.11, accuracy=0.754, val_loss=1.61, val_accuracy=0.583, lr=0.1] 26%|██▌       | 43/166 [18:45<52:23, 25.56s/epoch, loss=1.11, accuracy=0.759, val_loss=2.59, val_accuracy=0.461, lr=0.1] 27%|██▋       | 44/166 [19:11<51:59, 25.57s/epoch, loss=1.1, accuracy=0.757, val_loss=2.42, val_accuracy=0.468, lr=0.1]  27%|██▋       | 45/166 [19:37<51:37, 25.60s/epoch, loss=1.11, accuracy=0.757, val_loss=1.49, val_accuracy=0.616, lr=0.1] 28%|██▊       | 46/166 [20:02<51:09, 25.58s/epoch, loss=1.1, accuracy=0.758, val_loss=2.59, val_accuracy=0.331, lr=0.1]  28%|██▊       | 47/166 [20:28<50:45, 25.60s/epoch, loss=1.11, accuracy=0.756, val_loss=2.18, val_accuracy=0.505, lr=0.1] 29%|██▉       | 48/166 [20:53<50:24, 25.63s/epoch, loss=1.11, accuracy=0.757, val_loss=1.7, val_accuracy=0.586, lr=0.1]  30%|██▉       | 49/166 [21:19<49:50, 25.56s/epoch, loss=1.11, accuracy=0.758, val_loss=1.35, val_accuracy=0.662, lr=0.1] 30%|███       | 50/166 [21:44<49:20, 25.52s/epoch, loss=1.1, accuracy=0.762, val_loss=3.02, val_accuracy=0.421, lr=0.1]  31%|███       | 51/166 [22:10<48:58, 25.55s/epoch, loss=1.11, accuracy=0.758, val_loss=2.2, val_accuracy=0.417, lr=0.1] 31%|███▏      | 52/166 [22:35<48:27, 25.50s/epoch, loss=1.1, accuracy=0.759, val_loss=1.81, val_accuracy=0.517, lr=0.1] 32%|███▏      | 53/166 [23:01<48:15, 25.63s/epoch, loss=1.11, accuracy=0.76, val_loss=1.92, val_accuracy=0.544, lr=0.1] 33%|███▎      | 54/166 [23:27<48:01, 25.72s/epoch, loss=1.1, accuracy=0.76, val_loss=2.38, val_accuracy=0.419, lr=0.1]  33%|███▎      | 55/166 [23:53<47:35, 25.73s/epoch, loss=1.11, accuracy=0.758, val_loss=1.6, val_accuracy=0.579, lr=0.1] 34%|███▎      | 56/166 [24:19<47:09, 25.72s/epoch, loss=1.11, accuracy=0.759, val_loss=1.91, val_accuracy=0.486, lr=0.1] 34%|███▍      | 57/166 [24:44<46:42, 25.71s/epoch, loss=1.11, accuracy=0.76, val_loss=2.09, val_accuracy=0.504, lr=0.1]  35%|███▍      | 58/166 [25:10<46:10, 25.65s/epoch, loss=1.11, accuracy=0.757, val_loss=2.04, val_accuracy=0.403, lr=0.1] 36%|███▌      | 59/166 [25:36<45:46, 25.67s/epoch, loss=1.1, accuracy=0.758, val_loss=1.46, val_accuracy=0.653, lr=0.1]  36%|███▌      | 60/166 [26:01<45:16, 25.63s/epoch, loss=1.1, accuracy=0.76, val_loss=1.63, val_accuracy=0.582, lr=0.1]  37%|███▋      | 61/166 [26:27<44:48, 25.61s/epoch, loss=1.11, accuracy=0.76, val_loss=2.07, val_accuracy=0.521, lr=0.1] 37%|███▋      | 62/166 [26:52<44:23, 25.62s/epoch, loss=1.1, accuracy=0.759, val_loss=1.78, val_accuracy=0.535, lr=0.1] 38%|███▊      | 63/166 [27:18<43:51, 25.55s/epoch, loss=1.11, accuracy=0.759, val_loss=3.08, val_accuracy=0.391, lr=0.1] 39%|███▊      | 64/166 [27:43<43:29, 25.59s/epoch, loss=1.11, accuracy=0.76, val_loss=2, val_accuracy=0.533, lr=0.1]     39%|███▉      | 65/166 [28:09<42:57, 25.52s/epoch, loss=1.11, accuracy=0.758, val_loss=1.87, val_accuracy=0.532, lr=0.1] 40%|███▉      | 66/166 [28:34<42:38, 25.59s/epoch, loss=1.11, accuracy=0.759, val_loss=1.3, val_accuracy=0.688, lr=0.1]  40%|████      | 67/166 [29:00<42:06, 25.52s/epoch, loss=1.1, accuracy=0.759, val_loss=1.6, val_accuracy=0.574, lr=0.1]  41%|████      | 68/166 [29:25<41:43, 25.55s/epoch, loss=0.89, accuracy=0.82, val_loss=0.893, val_accuracy=0.808, lr=0.01] 42%|████▏     | 69/166 [29:51<41:15, 25.52s/epoch, loss=0.718, accuracy=0.85, val_loss=0.798, val_accuracy=0.811, lr=0.01] 42%|████▏     | 70/166 [30:16<40:52, 25.54s/epoch, loss=0.641, accuracy=0.859, val_loss=0.816, val_accuracy=0.791, lr=0.01] 43%|████▎     | 71/166 [30:42<40:21, 25.49s/epoch, loss=0.6, accuracy=0.861, val_loss=1.01, val_accuracy=0.737, lr=0.01]    43%|████▎     | 72/166 [31:07<39:42, 25.35s/epoch, loss=0.577, accuracy=0.863, val_loss=0.835, val_accuracy=0.775, lr=0.01] 44%|████▍     | 73/166 [31:32<39:15, 25.32s/epoch, loss=0.569, accuracy=0.863, val_loss=0.892, val_accuracy=0.76, lr=0.01]  45%|████▍     | 74/166 [31:58<38:58, 25.42s/epoch, loss=0.562, accuracy=0.865, val_loss=0.926, val_accuracy=0.751, lr=0.01] 45%|████▌     | 75/166 [32:23<38:34, 25.44s/epoch, loss=0.559, accuracy=0.867, val_loss=0.785, val_accuracy=0.79, lr=0.01]  46%|████▌     | 76/166 [32:49<38:15, 25.51s/epoch, loss=0.555, accuracy=0.869, val_loss=0.808, val_accuracy=0.781, lr=0.01] 46%|████▋     | 77/166 [33:14<37:50, 25.51s/epoch, loss=0.556, accuracy=0.868, val_loss=0.743, val_accuracy=0.807, lr=0.01] 47%|████▋     | 78/166 [33:40<37:29, 25.56s/epoch, loss=0.553, accuracy=0.87, val_loss=0.797, val_accuracy=0.794, lr=0.01]  48%|████▊     | 79/166 [34:06<37:01, 25.53s/epoch, loss=0.55, accuracy=0.871, val_loss=1.11, val_accuracy=0.694, lr=0.01]  48%|████▊     | 80/166 [34:31<36:32, 25.50s/epoch, loss=0.55, accuracy=0.872, val_loss=0.87, val_accuracy=0.78, lr=0.01]  49%|████▉     | 81/166 [34:56<36:03, 25.45s/epoch, loss=0.549, accuracy=0.873, val_loss=0.9, val_accuracy=0.761, lr=0.01] 49%|████▉     | 82/166 [35:22<35:36, 25.43s/epoch, loss=0.55, accuracy=0.875, val_loss=0.727, val_accuracy=0.822, lr=0.01] 50%|█████     | 83/166 [35:47<35:07, 25.40s/epoch, loss=0.549, accuracy=0.876, val_loss=0.873, val_accuracy=0.776, lr=0.01] 51%|█████     | 84/166 [36:12<34:39, 25.36s/epoch, loss=0.55, accuracy=0.876, val_loss=0.74, val_accuracy=0.815, lr=0.01]   51%|█████     | 85/166 [36:38<34:10, 25.31s/epoch, loss=0.549, accuracy=0.877, val_loss=0.792, val_accuracy=0.793, lr=0.01] 52%|█████▏    | 86/166 [37:03<33:42, 25.28s/epoch, loss=0.546, accuracy=0.879, val_loss=0.959, val_accuracy=0.756, lr=0.01] 52%|█████▏    | 87/166 [37:28<33:10, 25.19s/epoch, loss=0.547, accuracy=0.88, val_loss=0.814, val_accuracy=0.804, lr=0.01]  53%|█████▎    | 88/166 [37:53<32:46, 25.21s/epoch, loss=0.549, accuracy=0.879, val_loss=0.756, val_accuracy=0.815, lr=0.01] 54%|█████▎    | 89/166 [38:18<32:20, 25.21s/epoch, loss=0.544, accuracy=0.881, val_loss=1.18, val_accuracy=0.699, lr=0.01]  54%|█████▍    | 90/166 [38:44<32:01, 25.28s/epoch, loss=0.545, accuracy=0.88, val_loss=0.935, val_accuracy=0.774, lr=0.01] 55%|█████▍    | 91/166 [39:09<31:29, 25.19s/epoch, loss=0.548, accuracy=0.879, val_loss=0.773, val_accuracy=0.808, lr=0.01] 55%|█████▌    | 92/166 [39:34<31:02, 25.17s/epoch, loss=0.541, accuracy=0.883, val_loss=0.959, val_accuracy=0.744, lr=0.01] 56%|█████▌    | 93/166 [39:59<30:40, 25.22s/epoch, loss=0.543, accuracy=0.881, val_loss=0.733, val_accuracy=0.821, lr=0.01] 57%|█████▋    | 94/166 [40:25<30:21, 25.30s/epoch, loss=0.546, accuracy=0.882, val_loss=0.819, val_accuracy=0.808, lr=0.01] 57%|█████▋    | 95/166 [40:50<29:56, 25.30s/epoch, loss=0.544, accuracy=0.882, val_loss=0.761, val_accuracy=0.811, lr=0.01] 58%|█████▊    | 96/166 [41:15<29:32, 25.32s/epoch, loss=0.544, accuracy=0.882, val_loss=0.776, val_accuracy=0.812, lr=0.01] 58%|█████▊    | 97/166 [41:41<29:12, 25.40s/epoch, loss=0.543, accuracy=0.882, val_loss=0.829, val_accuracy=0.79, lr=0.01]  59%|█████▉    | 98/166 [42:06<28:52, 25.48s/epoch, loss=0.543, accuracy=0.885, val_loss=1.06, val_accuracy=0.734, lr=0.01] 60%|█████▉    | 99/166 [42:32<28:25, 25.45s/epoch, loss=0.546, accuracy=0.884, val_loss=0.755, val_accuracy=0.827, lr=0.01] 60%|██████    | 100/166 [42:57<27:59, 25.45s/epoch, loss=0.543, accuracy=0.885, val_loss=0.89, val_accuracy=0.787, lr=0.01] 61%|██████    | 101/166 [43:23<27:36, 25.49s/epoch, loss=0.469, accuracy=0.912, val_loss=0.531, val_accuracy=0.89, lr=0.001] 61%|██████▏   | 102/166 [43:48<27:10, 25.48s/epoch, loss=0.418, accuracy=0.928, val_loss=0.511, val_accuracy=0.895, lr=0.001] 62%|██████▏   | 103/166 [44:14<26:44, 25.46s/epoch, loss=0.393, accuracy=0.935, val_loss=0.5, val_accuracy=0.897, lr=0.001]   63%|██████▎   | 104/166 [44:39<26:11, 25.35s/epoch, loss=0.378, accuracy=0.938, val_loss=0.497, val_accuracy=0.901, lr=0.001] 63%|██████▎   | 105/166 [45:04<25:46, 25.36s/epoch, loss=0.367, accuracy=0.939, val_loss=0.486, val_accuracy=0.898, lr=0.001] 64%|██████▍   | 106/166 [45:30<25:21, 25.36s/epoch, loss=0.354, accuracy=0.942, val_loss=0.482, val_accuracy=0.9, lr=0.001]   64%|██████▍   | 107/166 [45:55<24:56, 25.36s/epoch, loss=0.341, accuracy=0.945, val_loss=0.483, val_accuracy=0.897, lr=0.001] 65%|██████▌   | 108/166 [46:20<24:29, 25.33s/epoch, loss=0.332, accuracy=0.946, val_loss=0.47, val_accuracy=0.898, lr=0.001]  66%|██████▌   | 109/166 [46:46<24:04, 25.34s/epoch, loss=0.321, accuracy=0.948, val_loss=0.46, val_accuracy=0.899, lr=0.001] 66%|██████▋   | 110/166 [47:11<23:40, 25.37s/epoch, loss=0.317, accuracy=0.948, val_loss=0.462, val_accuracy=0.9, lr=0.001]  67%|██████▋   | 111/166 [47:36<23:12, 25.32s/epoch, loss=0.306, accuracy=0.95, val_loss=0.46, val_accuracy=0.9, lr=0.001]   67%|██████▋   | 112/166 [48:01<22:45, 25.28s/epoch, loss=0.299, accuracy=0.951, val_loss=0.458, val_accuracy=0.9, lr=0.001] 68%|██████▊   | 113/166 [48:27<22:19, 25.27s/epoch, loss=0.293, accuracy=0.951, val_loss=0.453, val_accuracy=0.902, lr=0.001] 69%|██████▊   | 114/166 [48:52<21:51, 25.23s/epoch, loss=0.289, accuracy=0.952, val_loss=0.467, val_accuracy=0.896, lr=0.001] 69%|██████▉   | 115/166 [49:17<21:29, 25.27s/epoch, loss=0.28, accuracy=0.955, val_loss=0.462, val_accuracy=0.898, lr=0.001]  70%|██████▉   | 116/166 [49:42<21:00, 25.21s/epoch, loss=0.275, accuracy=0.954, val_loss=0.457, val_accuracy=0.897, lr=0.001] 70%|███████   | 117/166 [50:08<20:38, 25.27s/epoch, loss=0.267, accuracy=0.956, val_loss=0.459, val_accuracy=0.896, lr=0.001] 71%|███████   | 118/166 [50:33<20:11, 25.25s/epoch, loss=0.26, accuracy=0.958, val_loss=0.456, val_accuracy=0.901, lr=0.001]  72%|███████▏  | 119/166 [50:58<19:45, 25.23s/epoch, loss=0.26, accuracy=0.957, val_loss=0.464, val_accuracy=0.894, lr=0.001] 72%|███████▏  | 120/166 [51:23<19:18, 25.18s/epoch, loss=0.252, accuracy=0.958, val_loss=0.488, val_accuracy=0.889, lr=0.001] 73%|███████▎  | 121/166 [51:48<18:54, 25.21s/epoch, loss=0.248, accuracy=0.959, val_loss=0.466, val_accuracy=0.895, lr=0.001] 73%|███████▎  | 122/166 [52:14<18:29, 25.21s/epoch, loss=0.245, accuracy=0.959, val_loss=0.483, val_accuracy=0.893, lr=0.001] 74%|███████▍  | 123/166 [52:39<18:04, 25.22s/epoch, loss=0.243, accuracy=0.96, val_loss=0.477, val_accuracy=0.891, lr=0.001]  75%|███████▍  | 124/166 [53:04<17:40, 25.26s/epoch, loss=0.239, accuracy=0.96, val_loss=0.494, val_accuracy=0.883, lr=0.001] 75%|███████▌  | 125/166 [53:29<17:14, 25.24s/epoch, loss=0.235, accuracy=0.961, val_loss=0.467, val_accuracy=0.892, lr=0.001] 76%|███████▌  | 126/166 [53:55<16:51, 25.29s/epoch, loss=0.23, accuracy=0.961, val_loss=0.467, val_accuracy=0.893, lr=0.001]  77%|███████▋  | 127/166 [54:20<16:26, 25.29s/epoch, loss=0.232, accuracy=0.96, val_loss=0.462, val_accuracy=0.892, lr=0.001] 77%|███████▋  | 128/166 [54:46<16:03, 25.37s/epoch, loss=0.225, accuracy=0.962, val_loss=0.47, val_accuracy=0.893, lr=0.001] 78%|███████▊  | 129/166 [55:11<15:37, 25.34s/epoch, loss=0.225, accuracy=0.961, val_loss=0.488, val_accuracy=0.884, lr=0.001] 78%|███████▊  | 130/166 [55:36<15:09, 25.26s/epoch, loss=0.225, accuracy=0.961, val_loss=0.494, val_accuracy=0.883, lr=0.001] 79%|███████▉  | 131/166 [56:01<14:41, 25.19s/epoch, loss=0.22, accuracy=0.962, val_loss=0.505, val_accuracy=0.881, lr=0.001]  80%|███████▉  | 132/166 [56:26<14:17, 25.23s/epoch, loss=0.223, accuracy=0.959, val_loss=0.477, val_accuracy=0.885, lr=0.001] 80%|████████  | 133/166 [56:51<13:52, 25.21s/epoch, loss=0.22, accuracy=0.962, val_loss=0.482, val_accuracy=0.884, lr=0.001]  81%|████████  | 134/166 [57:17<13:27, 25.24s/epoch, loss=0.196, accuracy=0.97, val_loss=0.406, val_accuracy=0.906, lr=1e-04] 81%|████████▏ | 135/166 [57:42<13:02, 25.23s/epoch, loss=0.189, accuracy=0.974, val_loss=0.403, val_accuracy=0.908, lr=1e-04] 82%|████████▏ | 136/166 [58:07<12:37, 25.25s/epoch, loss=0.181, accuracy=0.976, val_loss=0.403, val_accuracy=0.909, lr=1e-04] 83%|████████▎ | 137/166 [58:32<12:11, 25.22s/epoch, loss=0.179, accuracy=0.977, val_loss=0.405, val_accuracy=0.909, lr=1e-04] 83%|████████▎ | 138/166 [58:58<11:45, 25.21s/epoch, loss=0.177, accuracy=0.978, val_loss=0.404, val_accuracy=0.908, lr=1e-04] 84%|████████▎ | 139/166 [59:23<11:19, 25.17s/epoch, loss=0.174, accuracy=0.979, val_loss=0.401, val_accuracy=0.91, lr=1e-04]  84%|████████▍ | 140/166 [59:48<10:55, 25.22s/epoch, loss=0.173, accuracy=0.979, val_loss=0.404, val_accuracy=0.909, lr=1e-04] 85%|████████▍ | 141/166 [1:00:13<10:30, 25.21s/epoch, loss=0.171, accuracy=0.979, val_loss=0.404, val_accuracy=0.91, lr=1e-04] 86%|████████▌ | 142/166 [1:00:38<10:04, 25.19s/epoch, loss=0.169, accuracy=0.981, val_loss=0.405, val_accuracy=0.909, lr=1e-04] 86%|████████▌ | 143/166 [1:01:03<09:37, 25.10s/epoch, loss=0.168, accuracy=0.98, val_loss=0.407, val_accuracy=0.909, lr=1e-04]  87%|████████▋ | 144/166 [1:01:29<09:15, 25.23s/epoch, loss=0.167, accuracy=0.981, val_loss=0.405, val_accuracy=0.91, lr=1e-04] 87%|████████▋ | 145/166 [1:01:54<08:49, 25.20s/epoch, loss=0.166, accuracy=0.982, val_loss=0.405, val_accuracy=0.91, lr=1e-04] 88%|████████▊ | 146/166 [1:02:19<08:23, 25.17s/epoch, loss=0.165, accuracy=0.981, val_loss=0.404, val_accuracy=0.909, lr=1e-04] 89%|████████▊ | 147/166 [1:02:44<07:59, 25.24s/epoch, loss=0.165, accuracy=0.982, val_loss=0.408, val_accuracy=0.91, lr=1e-04]  89%|████████▉ | 148/166 [1:03:10<07:34, 25.24s/epoch, loss=0.163, accuracy=0.982, val_loss=0.407, val_accuracy=0.909, lr=1e-04] 90%|████████▉ | 149/166 [1:03:35<07:08, 25.23s/epoch, loss=0.164, accuracy=0.981, val_loss=0.411, val_accuracy=0.908, lr=1e-04] 90%|█████████ | 150/166 [1:04:00<06:43, 25.20s/epoch, loss=0.162, accuracy=0.983, val_loss=0.409, val_accuracy=0.909, lr=1e-04] 91%|█████████ | 151/166 [1:04:25<06:19, 25.27s/epoch, loss=0.159, accuracy=0.983, val_loss=0.407, val_accuracy=0.909, lr=5e-5]  92%|█████████▏| 152/166 [1:04:51<05:53, 25.25s/epoch, loss=0.159, accuracy=0.984, val_loss=0.408, val_accuracy=0.909, lr=5e-5] 92%|█████████▏| 153/166 [1:05:16<05:28, 25.23s/epoch, loss=0.159, accuracy=0.983, val_loss=0.407, val_accuracy=0.909, lr=5e-5] 93%|█████████▎| 154/166 [1:05:41<05:02, 25.19s/epoch, loss=0.158, accuracy=0.983, val_loss=0.409, val_accuracy=0.908, lr=5e-5] 93%|█████████▎| 155/166 [1:06:06<04:37, 25.26s/epoch, loss=0.157, accuracy=0.984, val_loss=0.408, val_accuracy=0.91, lr=5e-5]  94%|█████████▍| 156/166 [1:06:32<04:12, 25.28s/epoch, loss=0.158, accuracy=0.984, val_loss=0.408, val_accuracy=0.909, lr=5e-5] 95%|█████████▍| 157/166 [1:06:57<03:48, 25.34s/epoch, loss=0.156, accuracy=0.984, val_loss=0.408, val_accuracy=0.909, lr=5e-5] 95%|█████████▌| 158/166 [1:07:22<03:21, 25.25s/epoch, loss=0.157, accuracy=0.983, val_loss=0.409, val_accuracy=0.91, lr=5e-5]  96%|█████████▌| 159/166 [1:07:47<02:56, 25.22s/epoch, loss=0.155, accuracy=0.984, val_loss=0.408, val_accuracy=0.91, lr=5e-5] 96%|█████████▋| 160/166 [1:08:12<02:31, 25.19s/epoch, loss=0.155, accuracy=0.984, val_loss=0.409, val_accuracy=0.91, lr=5e-5] 97%|█████████▋| 161/166 [1:08:38<02:06, 25.21s/epoch, loss=0.156, accuracy=0.983, val_loss=0.411, val_accuracy=0.908, lr=5e-5] 98%|█████████▊| 162/166 [1:09:03<01:40, 25.18s/epoch, loss=0.155, accuracy=0.984, val_loss=0.41, val_accuracy=0.909, lr=5e-5]  98%|█████████▊| 163/166 [1:09:28<01:15, 25.16s/epoch, loss=0.155, accuracy=0.984, val_loss=0.409, val_accuracy=0.909, lr=5e-5] 99%|█████████▉| 164/166 [1:09:53<00:50, 25.14s/epoch, loss=0.152, accuracy=0.985, val_loss=0.411, val_accuracy=0.908, lr=5e-5] 99%|█████████▉| 165/166 [1:10:18<00:25, 25.15s/epoch, loss=0.152, accuracy=0.985, val_loss=0.41, val_accuracy=0.91, lr=5e-5]  100%|██████████| 166/166 [1:10:43<00:00, 25.16s/epoch, loss=0.154, accuracy=0.984, val_loss=0.41, val_accuracy=0.91, lr=5e-5]100%|██████████| 166/166 [1:10:43<00:00, 25.57s/epoch, loss=0.154, accuracy=0.984, val_loss=0.41, val_accuracy=0.91, lr=5e-5]
Using real-time data augmentation.
Only one model saved

Loading model: 09_08_cifar10_ResNet20v1.h5
Test score: 0.41030555963516235
Test accuracy: 0.909600019454956


* * * Run SGD for ID = 9_9. * * *


2024-03-13 06:57:49.112133: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-13 06:57:51.749947: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-13 06:57:51.751286: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-13 06:57:51.793516: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:3b:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-13 06:57:51.793558: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-13 06:57:51.797066: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-13 06:57:51.797132: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-13 06:57:51.799865: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-13 06:57:51.800623: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-13 06:57:51.803581: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-13 06:57:51.805329: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-13 06:57:51.811082: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-13 06:57:51.811884: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-13 06:57:51.811969: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-13 06:57:53.066528: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-13 06:57:53.067131: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-13 06:57:53.068334: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:3b:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-13 06:57:53.068373: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-13 06:57:53.068421: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-13 06:57:53.068436: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-13 06:57:53.068451: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-13 06:57:53.068467: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-13 06:57:53.068490: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-13 06:57:53.068506: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-13 06:57:53.068523: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-13 06:57:53.069087: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-13 06:57:53.069122: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-13 06:57:53.744063: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-13 06:57:53.744119: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-13 06:57:53.744138: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-13 06:57:53.745206: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:3b:00.0, compute capability: 6.1)
{'id': '09_09', 'seed': 9, 'out_folder': 'results/epoch_budget_2', 'batch_size': 128, 'epochs': 166, 'validation_split': 0.0, 'checkpointing': False, 'checkpoint_every': -1, 'hold_out_validation_split': 0.0, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'bootstrapping': False, 'num_classes': 10, 'SSE_lr': False, 'test_time_augmentation': False, 'debug': False, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
y_train shape: (50000, 10)
x_val shape: (10000, 32, 32, 3)
y_val shape: (10000, 10)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/166 [00:00<?, ?epoch/s]2024-03-13 06:57:54.400560: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-13 06:57:54.412988: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2100000000 Hz
2024-03-13 06:57:56.437738: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-13 06:57:56.730689: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-13 06:57:57.674095: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-13 06:57:57.713898: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/166 [00:59<2:42:22, 59.04s/epoch, loss=2.77, accuracy=0.432, val_loss=2.19, val_accuracy=0.338, lr=0.1]  1%|          | 2/166 [01:24<1:48:10, 39.58s/epoch, loss=1.41, accuracy=0.618, val_loss=2.04, val_accuracy=0.473, lr=0.1]  2%|▏         | 3/166 [01:50<1:30:08, 33.18s/epoch, loss=1.28, accuracy=0.682, val_loss=1.79, val_accuracy=0.503, lr=0.1]  2%|▏         | 4/166 [02:16<1:21:27, 30.17s/epoch, loss=1.24, accuracy=0.701, val_loss=1.69, val_accuracy=0.543, lr=0.1]  3%|▎         | 5/166 [02:41<1:16:37, 28.56s/epoch, loss=1.22, accuracy=0.714, val_loss=1.68, val_accuracy=0.555, lr=0.1]  4%|▎         | 6/166 [03:07<1:13:19, 27.50s/epoch, loss=1.21, accuracy=0.72, val_loss=2.57, val_accuracy=0.419, lr=0.1]   4%|▍         | 7/166 [03:33<1:11:21, 26.93s/epoch, loss=1.2, accuracy=0.726, val_loss=1.86, val_accuracy=0.493, lr=0.1]  5%|▍         | 8/166 [03:58<1:09:44, 26.49s/epoch, loss=1.19, accuracy=0.73, val_loss=2.06, val_accuracy=0.44, lr=0.1]   5%|▌         | 9/166 [04:24<1:08:32, 26.19s/epoch, loss=1.19, accuracy=0.734, val_loss=1.76, val_accuracy=0.535, lr=0.1]  6%|▌         | 10/166 [04:49<1:07:28, 25.95s/epoch, loss=1.18, accuracy=0.737, val_loss=2.43, val_accuracy=0.377, lr=0.1]  7%|▋         | 11/166 [05:15<1:06:42, 25.82s/epoch, loss=1.18, accuracy=0.735, val_loss=2.26, val_accuracy=0.431, lr=0.1]  7%|▋         | 12/166 [05:40<1:06:14, 25.81s/epoch, loss=1.18, accuracy=0.738, val_loss=1.94, val_accuracy=0.503, lr=0.1]  8%|▊         | 13/166 [06:06<1:05:44, 25.78s/epoch, loss=1.17, accuracy=0.741, val_loss=1.92, val_accuracy=0.539, lr=0.1]  8%|▊         | 14/166 [06:32<1:05:15, 25.76s/epoch, loss=1.17, accuracy=0.741, val_loss=1.86, val_accuracy=0.507, lr=0.1]  9%|▉         | 15/166 [06:57<1:04:43, 25.72s/epoch, loss=1.16, accuracy=0.743, val_loss=1.81, val_accuracy=0.5, lr=0.1]   10%|▉         | 16/166 [07:23<1:04:09, 25.66s/epoch, loss=1.16, accuracy=0.743, val_loss=2.53, val_accuracy=0.289, lr=0.1] 10%|█         | 17/166 [07:48<1:03:32, 25.59s/epoch, loss=1.16, accuracy=0.746, val_loss=2.26, val_accuracy=0.556, lr=0.1] 11%|█         | 18/166 [08:14<1:03:01, 25.55s/epoch, loss=1.16, accuracy=0.745, val_loss=2.46, val_accuracy=0.505, lr=0.1] 11%|█▏        | 19/166 [08:39<1:02:39, 25.57s/epoch, loss=1.15, accuracy=0.745, val_loss=2.05, val_accuracy=0.456, lr=0.1] 12%|█▏        | 20/166 [09:05<1:02:16, 25.59s/epoch, loss=1.14, accuracy=0.749, val_loss=1.79, val_accuracy=0.541, lr=0.1] 13%|█▎        | 21/166 [09:30<1:01:42, 25.54s/epoch, loss=1.14, accuracy=0.751, val_loss=2.7, val_accuracy=0.397, lr=0.1]  13%|█▎        | 22/166 [09:56<1:01:15, 25.53s/epoch, loss=1.15, accuracy=0.751, val_loss=2.03, val_accuracy=0.488, lr=0.1] 14%|█▍        | 23/166 [10:22<1:00:58, 25.58s/epoch, loss=1.14, accuracy=0.751, val_loss=2.3, val_accuracy=0.394, lr=0.1]  14%|█▍        | 24/166 [10:47<1:00:35, 25.60s/epoch, loss=1.14, accuracy=0.752, val_loss=2, val_accuracy=0.437, lr=0.1]   15%|█▌        | 25/166 [11:13<1:00:14, 25.64s/epoch, loss=1.13, accuracy=0.753, val_loss=1.78, val_accuracy=0.548, lr=0.1] 16%|█▌        | 26/166 [11:39<59:57, 25.69s/epoch, loss=1.14, accuracy=0.751, val_loss=2.01, val_accuracy=0.47, lr=0.1]    16%|█▋        | 27/166 [12:04<59:22, 25.63s/epoch, loss=1.13, accuracy=0.751, val_loss=2.6, val_accuracy=0.486, lr=0.1] 17%|█▋        | 28/166 [12:30<58:45, 25.54s/epoch, loss=1.14, accuracy=0.75, val_loss=2.72, val_accuracy=0.287, lr=0.1] 17%|█▋        | 29/166 [12:55<58:20, 25.55s/epoch, loss=1.14, accuracy=0.752, val_loss=1.47, val_accuracy=0.654, lr=0.1] 18%|█▊        | 30/166 [13:21<57:58, 25.58s/epoch, loss=1.13, accuracy=0.755, val_loss=1.62, val_accuracy=0.595, lr=0.1] 19%|█▊        | 31/166 [13:46<57:31, 25.57s/epoch, loss=1.12, accuracy=0.753, val_loss=3.56, val_accuracy=0.376, lr=0.1] 19%|█▉        | 32/166 [14:12<57:04, 25.55s/epoch, loss=1.13, accuracy=0.754, val_loss=1.76, val_accuracy=0.569, lr=0.1] 20%|█▉        | 33/166 [14:37<56:32, 25.51s/epoch, loss=1.13, accuracy=0.754, val_loss=2.24, val_accuracy=0.489, lr=0.1] 20%|██        | 34/166 [15:03<56:07, 25.51s/epoch, loss=1.13, accuracy=0.753, val_loss=2.24, val_accuracy=0.504, lr=0.1] 21%|██        | 35/166 [15:29<55:48, 25.56s/epoch, loss=1.12, accuracy=0.756, val_loss=1.62, val_accuracy=0.586, lr=0.1] 22%|██▏       | 36/166 [15:54<55:18, 25.53s/epoch, loss=1.12, accuracy=0.756, val_loss=1.82, val_accuracy=0.601, lr=0.1] 22%|██▏       | 37/166 [16:20<54:57, 25.56s/epoch, loss=1.13, accuracy=0.757, val_loss=1.47, val_accuracy=0.631, lr=0.1] 23%|██▎       | 38/166 [16:45<54:33, 25.58s/epoch, loss=1.12, accuracy=0.757, val_loss=1.93, val_accuracy=0.535, lr=0.1] 23%|██▎       | 39/166 [17:11<54:03, 25.54s/epoch, loss=1.13, accuracy=0.754, val_loss=1.42, val_accuracy=0.657, lr=0.1] 24%|██▍       | 40/166 [17:36<53:41, 25.57s/epoch, loss=1.12, accuracy=0.756, val_loss=4.15, val_accuracy=0.278, lr=0.1] 25%|██▍       | 41/166 [18:02<53:09, 25.51s/epoch, loss=1.12, accuracy=0.759, val_loss=3.12, val_accuracy=0.29, lr=0.1]  25%|██▌       | 42/166 [18:27<52:36, 25.45s/epoch, loss=1.12, accuracy=0.757, val_loss=1.89, val_accuracy=0.565, lr=0.1] 26%|██▌       | 43/166 [18:53<52:14, 25.49s/epoch, loss=1.11, accuracy=0.758, val_loss=1.55, val_accuracy=0.584, lr=0.1] 27%|██▋       | 44/166 [19:18<51:49, 25.49s/epoch, loss=1.12, accuracy=0.756, val_loss=3.48, val_accuracy=0.348, lr=0.1] 27%|██▋       | 45/166 [19:44<51:30, 25.54s/epoch, loss=1.12, accuracy=0.756, val_loss=2.41, val_accuracy=0.442, lr=0.1] 28%|██▊       | 46/166 [20:10<51:13, 25.61s/epoch, loss=1.12, accuracy=0.759, val_loss=2.87, val_accuracy=0.342, lr=0.1] 28%|██▊       | 47/166 [20:35<50:54, 25.67s/epoch, loss=1.12, accuracy=0.758, val_loss=3.28, val_accuracy=0.392, lr=0.1] 29%|██▉       | 48/166 [21:01<50:34, 25.72s/epoch, loss=1.12, accuracy=0.754, val_loss=1.74, val_accuracy=0.556, lr=0.1] 30%|██▉       | 49/166 [21:27<50:09, 25.72s/epoch, loss=1.12, accuracy=0.757, val_loss=3.23, val_accuracy=0.337, lr=0.1] 30%|███       | 50/166 [21:52<49:31, 25.62s/epoch, loss=1.12, accuracy=0.757, val_loss=3.7, val_accuracy=0.306, lr=0.1]  31%|███       | 51/166 [22:18<48:58, 25.55s/epoch, loss=1.11, accuracy=0.758, val_loss=3.29, val_accuracy=0.375, lr=0.1] 31%|███▏      | 52/166 [22:43<48:28, 25.51s/epoch, loss=1.12, accuracy=0.758, val_loss=1.55, val_accuracy=0.619, lr=0.1] 32%|███▏      | 53/166 [23:09<48:07, 25.55s/epoch, loss=1.12, accuracy=0.757, val_loss=2.14, val_accuracy=0.466, lr=0.1] 33%|███▎      | 54/166 [23:35<47:51, 25.63s/epoch, loss=1.11, accuracy=0.76, val_loss=2.12, val_accuracy=0.45, lr=0.1]   33%|███▎      | 55/166 [24:00<47:25, 25.64s/epoch, loss=1.11, accuracy=0.757, val_loss=2.05, val_accuracy=0.524, lr=0.1] 34%|███▎      | 56/166 [24:26<47:05, 25.68s/epoch, loss=1.11, accuracy=0.759, val_loss=1.75, val_accuracy=0.56, lr=0.1]  34%|███▍      | 57/166 [24:52<46:45, 25.74s/epoch, loss=1.11, accuracy=0.76, val_loss=2.51, val_accuracy=0.331, lr=0.1] 35%|███▍      | 58/166 [25:18<46:21, 25.76s/epoch, loss=1.12, accuracy=0.759, val_loss=1.85, val_accuracy=0.543, lr=0.1] 36%|███▌      | 59/166 [25:43<45:52, 25.72s/epoch, loss=1.12, accuracy=0.756, val_loss=2.38, val_accuracy=0.467, lr=0.1] 36%|███▌      | 60/166 [26:09<45:29, 25.75s/epoch, loss=1.12, accuracy=0.755, val_loss=1.57, val_accuracy=0.613, lr=0.1] 37%|███▋      | 61/166 [26:35<44:55, 25.67s/epoch, loss=1.11, accuracy=0.76, val_loss=2.56, val_accuracy=0.441, lr=0.1]  37%|███▋      | 62/166 [27:00<44:25, 25.63s/epoch, loss=1.11, accuracy=0.757, val_loss=1.73, val_accuracy=0.542, lr=0.1] 38%|███▊      | 63/166 [27:26<44:02, 25.65s/epoch, loss=1.11, accuracy=0.759, val_loss=2, val_accuracy=0.461, lr=0.1]    39%|███▊      | 64/166 [27:51<43:33, 25.62s/epoch, loss=1.11, accuracy=0.761, val_loss=3.88, val_accuracy=0.218, lr=0.1] 39%|███▉      | 65/166 [28:17<43:12, 25.67s/epoch, loss=1.11, accuracy=0.758, val_loss=1.59, val_accuracy=0.64, lr=0.1]  40%|███▉      | 66/166 [28:43<42:45, 25.65s/epoch, loss=1.11, accuracy=0.759, val_loss=2.81, val_accuracy=0.428, lr=0.1] 40%|████      | 67/166 [29:08<42:14, 25.60s/epoch, loss=1.11, accuracy=0.757, val_loss=4.75, val_accuracy=0.212, lr=0.1] 41%|████      | 68/166 [29:34<41:52, 25.64s/epoch, loss=0.904, accuracy=0.817, val_loss=1.04, val_accuracy=0.748, lr=0.01] 42%|████▏     | 69/166 [30:00<41:24, 25.62s/epoch, loss=0.721, accuracy=0.852, val_loss=0.755, val_accuracy=0.828, lr=0.01] 42%|████▏     | 70/166 [30:25<40:54, 25.57s/epoch, loss=0.642, accuracy=0.857, val_loss=0.743, val_accuracy=0.817, lr=0.01] 43%|████▎     | 71/166 [30:51<40:30, 25.59s/epoch, loss=0.598, accuracy=0.862, val_loss=0.692, val_accuracy=0.828, lr=0.01] 43%|████▎     | 72/166 [31:16<39:59, 25.52s/epoch, loss=0.579, accuracy=0.862, val_loss=0.693, val_accuracy=0.823, lr=0.01] 44%|████▍     | 73/166 [31:42<39:39, 25.58s/epoch, loss=0.567, accuracy=0.863, val_loss=0.834, val_accuracy=0.776, lr=0.01] 45%|████▍     | 74/166 [32:07<39:14, 25.59s/epoch, loss=0.56, accuracy=0.867, val_loss=0.679, val_accuracy=0.824, lr=0.01]  45%|████▌     | 75/166 [32:33<38:49, 25.59s/epoch, loss=0.558, accuracy=0.867, val_loss=0.71, val_accuracy=0.821, lr=0.01] 46%|████▌     | 76/166 [32:59<38:26, 25.63s/epoch, loss=0.557, accuracy=0.87, val_loss=0.823, val_accuracy=0.785, lr=0.01] 46%|████▋     | 77/166 [33:24<38:02, 25.65s/epoch, loss=0.553, accuracy=0.871, val_loss=0.791, val_accuracy=0.796, lr=0.01] 47%|████▋     | 78/166 [33:50<37:38, 25.67s/epoch, loss=0.553, accuracy=0.87, val_loss=0.845, val_accuracy=0.782, lr=0.01]  48%|████▊     | 79/166 [34:16<37:09, 25.63s/epoch, loss=0.552, accuracy=0.872, val_loss=0.743, val_accuracy=0.811, lr=0.01] 48%|████▊     | 80/166 [34:41<36:42, 25.61s/epoch, loss=0.553, accuracy=0.874, val_loss=1.19, val_accuracy=0.699, lr=0.01]  49%|████▉     | 81/166 [35:07<36:15, 25.59s/epoch, loss=0.551, accuracy=0.876, val_loss=0.775, val_accuracy=0.806, lr=0.01] 49%|████▉     | 82/166 [35:32<35:51, 25.61s/epoch, loss=0.546, accuracy=0.876, val_loss=0.8, val_accuracy=0.8, lr=0.01]     50%|█████     | 83/166 [35:58<35:26, 25.62s/epoch, loss=0.549, accuracy=0.876, val_loss=0.806, val_accuracy=0.79, lr=0.01] 51%|█████     | 84/166 [36:24<35:00, 25.61s/epoch, loss=0.55, accuracy=0.877, val_loss=0.758, val_accuracy=0.807, lr=0.01] 51%|█████     | 85/166 [36:49<34:34, 25.61s/epoch, loss=0.551, accuracy=0.879, val_loss=0.732, val_accuracy=0.816, lr=0.01] 52%|█████▏    | 86/166 [37:15<34:04, 25.55s/epoch, loss=0.543, accuracy=0.88, val_loss=0.938, val_accuracy=0.75, lr=0.01]   52%|█████▏    | 87/166 [37:40<33:34, 25.50s/epoch, loss=0.545, accuracy=0.88, val_loss=0.733, val_accuracy=0.826, lr=0.01] 53%|█████▎    | 88/166 [38:06<33:11, 25.53s/epoch, loss=0.545, accuracy=0.882, val_loss=0.758, val_accuracy=0.812, lr=0.01] 54%|█████▎    | 89/166 [38:31<32:43, 25.50s/epoch, loss=0.55, accuracy=0.88, val_loss=0.816, val_accuracy=0.796, lr=0.01]   54%|█████▍    | 90/166 [38:57<32:24, 25.58s/epoch, loss=0.548, accuracy=0.882, val_loss=0.752, val_accuracy=0.822, lr=0.01] 55%|█████▍    | 91/166 [39:23<32:00, 25.61s/epoch, loss=0.549, accuracy=0.882, val_loss=0.886, val_accuracy=0.777, lr=0.01] 55%|█████▌    | 92/166 [39:48<31:33, 25.59s/epoch, loss=0.548, accuracy=0.883, val_loss=0.833, val_accuracy=0.797, lr=0.01] 56%|█████▌    | 93/166 [40:14<31:06, 25.57s/epoch, loss=0.547, accuracy=0.882, val_loss=0.919, val_accuracy=0.766, lr=0.01] 57%|█████▋    | 94/166 [40:39<30:39, 25.55s/epoch, loss=0.544, accuracy=0.885, val_loss=0.903, val_accuracy=0.785, lr=0.01] 57%|█████▋    | 95/166 [41:04<30:09, 25.48s/epoch, loss=0.544, accuracy=0.885, val_loss=0.73, val_accuracy=0.829, lr=0.01]  58%|█████▊    | 96/166 [41:30<29:47, 25.54s/epoch, loss=0.551, accuracy=0.883, val_loss=0.836, val_accuracy=0.802, lr=0.01] 58%|█████▊    | 97/166 [41:56<29:25, 25.59s/epoch, loss=0.544, accuracy=0.885, val_loss=0.878, val_accuracy=0.795, lr=0.01] 59%|█████▉    | 98/166 [42:21<28:59, 25.58s/epoch, loss=0.549, accuracy=0.883, val_loss=0.826, val_accuracy=0.79, lr=0.01]  60%|█████▉    | 99/166 [42:47<28:37, 25.63s/epoch, loss=0.548, accuracy=0.884, val_loss=1.12, val_accuracy=0.73, lr=0.01]  60%|██████    | 100/166 [43:13<28:10, 25.61s/epoch, loss=0.547, accuracy=0.885, val_loss=0.802, val_accuracy=0.805, lr=0.01] 61%|██████    | 101/166 [43:38<27:42, 25.57s/epoch, loss=0.47, accuracy=0.912, val_loss=0.53, val_accuracy=0.891, lr=0.001]  61%|██████▏   | 102/166 [44:04<27:23, 25.68s/epoch, loss=0.418, accuracy=0.929, val_loss=0.514, val_accuracy=0.896, lr=0.001] 62%|██████▏   | 103/166 [44:30<26:57, 25.67s/epoch, loss=0.396, accuracy=0.936, val_loss=0.506, val_accuracy=0.896, lr=0.001] 63%|██████▎   | 104/166 [44:55<26:30, 25.66s/epoch, loss=0.379, accuracy=0.938, val_loss=0.494, val_accuracy=0.901, lr=0.001] 63%|██████▎   | 105/166 [45:21<26:04, 25.64s/epoch, loss=0.368, accuracy=0.94, val_loss=0.482, val_accuracy=0.905, lr=0.001]  64%|██████▍   | 106/166 [45:47<25:39, 25.66s/epoch, loss=0.354, accuracy=0.944, val_loss=0.485, val_accuracy=0.9, lr=0.001]  64%|██████▍   | 107/166 [46:12<25:14, 25.67s/epoch, loss=0.346, accuracy=0.945, val_loss=0.467, val_accuracy=0.904, lr=0.001] 65%|██████▌   | 108/166 [46:38<24:43, 25.58s/epoch, loss=0.333, accuracy=0.947, val_loss=0.468, val_accuracy=0.904, lr=0.001] 66%|██████▌   | 109/166 [47:03<24:20, 25.63s/epoch, loss=0.327, accuracy=0.948, val_loss=0.47, val_accuracy=0.9, lr=0.001]    66%|██████▋   | 110/166 [47:29<23:51, 25.57s/epoch, loss=0.317, accuracy=0.949, val_loss=0.454, val_accuracy=0.902, lr=0.001] 67%|██████▋   | 111/166 [47:54<23:25, 25.55s/epoch, loss=0.306, accuracy=0.952, val_loss=0.462, val_accuracy=0.898, lr=0.001] 67%|██████▋   | 112/166 [48:20<23:02, 25.60s/epoch, loss=0.3, accuracy=0.953, val_loss=0.458, val_accuracy=0.903, lr=0.001]   68%|██████▊   | 113/166 [48:46<22:37, 25.61s/epoch, loss=0.294, accuracy=0.953, val_loss=0.47, val_accuracy=0.898, lr=0.001] 69%|██████▊   | 114/166 [49:11<22:09, 25.56s/epoch, loss=0.287, accuracy=0.955, val_loss=0.458, val_accuracy=0.902, lr=0.001] 69%|██████▉   | 115/166 [49:37<21:39, 25.49s/epoch, loss=0.277, accuracy=0.957, val_loss=0.453, val_accuracy=0.901, lr=0.001] 70%|██████▉   | 116/166 [50:02<21:13, 25.47s/epoch, loss=0.275, accuracy=0.956, val_loss=0.455, val_accuracy=0.897, lr=0.001] 70%|███████   | 117/166 [50:27<20:47, 25.47s/epoch, loss=0.271, accuracy=0.957, val_loss=0.456, val_accuracy=0.897, lr=0.001] 71%|███████   | 118/166 [50:53<20:22, 25.47s/epoch, loss=0.264, accuracy=0.957, val_loss=0.448, val_accuracy=0.9, lr=0.001]   72%|███████▏  | 119/166 [51:19<19:59, 25.53s/epoch, loss=0.261, accuracy=0.958, val_loss=0.456, val_accuracy=0.897, lr=0.001] 72%|███████▏  | 120/166 [51:44<19:34, 25.53s/epoch, loss=0.255, accuracy=0.958, val_loss=0.454, val_accuracy=0.897, lr=0.001] 73%|███████▎  | 121/166 [52:10<19:08, 25.53s/epoch, loss=0.252, accuracy=0.959, val_loss=0.457, val_accuracy=0.898, lr=0.001] 73%|███████▎  | 122/166 [52:35<18:45, 25.57s/epoch, loss=0.246, accuracy=0.96, val_loss=0.459, val_accuracy=0.893, lr=0.001]  74%|███████▍  | 123/166 [53:01<18:21, 25.62s/epoch, loss=0.242, accuracy=0.961, val_loss=0.458, val_accuracy=0.896, lr=0.001] 75%|███████▍  | 124/166 [53:27<17:54, 25.59s/epoch, loss=0.238, accuracy=0.961, val_loss=0.457, val_accuracy=0.893, lr=0.001] 75%|███████▌  | 125/166 [53:52<17:27, 25.56s/epoch, loss=0.234, accuracy=0.963, val_loss=0.482, val_accuracy=0.889, lr=0.001] 76%|███████▌  | 126/166 [54:17<17:00, 25.52s/epoch, loss=0.234, accuracy=0.96, val_loss=0.46, val_accuracy=0.894, lr=0.001]   77%|███████▋  | 127/166 [54:43<16:33, 25.48s/epoch, loss=0.23, accuracy=0.962, val_loss=0.459, val_accuracy=0.895, lr=0.001] 77%|███████▋  | 128/166 [55:08<16:06, 25.44s/epoch, loss=0.227, accuracy=0.962, val_loss=0.456, val_accuracy=0.892, lr=0.001] 78%|███████▊  | 129/166 [55:34<15:40, 25.42s/epoch, loss=0.225, accuracy=0.962, val_loss=0.495, val_accuracy=0.886, lr=0.001] 78%|███████▊  | 130/166 [55:59<15:15, 25.44s/epoch, loss=0.224, accuracy=0.962, val_loss=0.473, val_accuracy=0.89, lr=0.001]  79%|███████▉  | 131/166 [56:24<14:50, 25.44s/epoch, loss=0.219, accuracy=0.962, val_loss=0.457, val_accuracy=0.892, lr=0.001] 80%|███████▉  | 132/166 [56:50<14:23, 25.38s/epoch, loss=0.22, accuracy=0.963, val_loss=0.499, val_accuracy=0.885, lr=0.001]  80%|████████  | 133/166 [57:15<13:59, 25.43s/epoch, loss=0.218, accuracy=0.962, val_loss=0.563, val_accuracy=0.878, lr=0.001] 81%|████████  | 134/166 [57:40<13:31, 25.34s/epoch, loss=0.199, accuracy=0.97, val_loss=0.409, val_accuracy=0.907, lr=1e-04]  81%|████████▏ | 135/166 [58:06<13:06, 25.36s/epoch, loss=0.188, accuracy=0.974, val_loss=0.404, val_accuracy=0.909, lr=1e-04] 82%|████████▏ | 136/166 [58:31<12:41, 25.37s/epoch, loss=0.183, accuracy=0.977, val_loss=0.408, val_accuracy=0.907, lr=1e-04] 83%|████████▎ | 137/166 [58:56<12:14, 25.34s/epoch, loss=0.18, accuracy=0.978, val_loss=0.406, val_accuracy=0.909, lr=1e-04]  83%|████████▎ | 138/166 [59:22<11:48, 25.31s/epoch, loss=0.177, accuracy=0.978, val_loss=0.407, val_accuracy=0.91, lr=1e-04] 84%|████████▎ | 139/166 [59:47<11:24, 25.33s/epoch, loss=0.177, accuracy=0.978, val_loss=0.405, val_accuracy=0.91, lr=1e-04] 84%|████████▍ | 140/166 [1:00:13<11:00, 25.40s/epoch, loss=0.174, accuracy=0.979, val_loss=0.406, val_accuracy=0.909, lr=1e-04] 85%|████████▍ | 141/166 [1:00:38<10:33, 25.36s/epoch, loss=0.172, accuracy=0.98, val_loss=0.406, val_accuracy=0.908, lr=1e-04]  86%|████████▌ | 142/166 [1:01:03<10:07, 25.31s/epoch, loss=0.173, accuracy=0.98, val_loss=0.406, val_accuracy=0.909, lr=1e-04] 86%|████████▌ | 143/166 [1:01:28<09:40, 25.25s/epoch, loss=0.17, accuracy=0.98, val_loss=0.406, val_accuracy=0.909, lr=1e-04]  87%|████████▋ | 144/166 [1:01:53<09:15, 25.24s/epoch, loss=0.169, accuracy=0.981, val_loss=0.407, val_accuracy=0.909, lr=1e-04] 87%|████████▋ | 145/166 [1:02:19<08:52, 25.34s/epoch, loss=0.166, accuracy=0.982, val_loss=0.406, val_accuracy=0.91, lr=1e-04]  88%|████████▊ | 146/166 [1:02:44<08:27, 25.38s/epoch, loss=0.167, accuracy=0.982, val_loss=0.407, val_accuracy=0.91, lr=1e-04] 89%|████████▊ | 147/166 [1:03:10<08:00, 25.31s/epoch, loss=0.166, accuracy=0.981, val_loss=0.409, val_accuracy=0.909, lr=1e-04] 89%|████████▉ | 148/166 [1:03:35<07:35, 25.31s/epoch, loss=0.164, accuracy=0.983, val_loss=0.405, val_accuracy=0.91, lr=1e-04]  90%|████████▉ | 149/166 [1:04:00<07:10, 25.33s/epoch, loss=0.164, accuracy=0.982, val_loss=0.408, val_accuracy=0.908, lr=1e-04] 90%|█████████ | 150/166 [1:04:26<06:44, 25.31s/epoch, loss=0.163, accuracy=0.983, val_loss=0.41, val_accuracy=0.909, lr=1e-04]  91%|█████████ | 151/166 [1:04:51<06:20, 25.34s/epoch, loss=0.16, accuracy=0.984, val_loss=0.408, val_accuracy=0.909, lr=5e-5]  92%|█████████▏| 152/166 [1:05:16<05:54, 25.29s/epoch, loss=0.161, accuracy=0.983, val_loss=0.41, val_accuracy=0.91, lr=5e-5]  92%|█████████▏| 153/166 [1:05:41<05:28, 25.24s/epoch, loss=0.16, accuracy=0.983, val_loss=0.409, val_accuracy=0.909, lr=5e-5] 93%|█████████▎| 154/166 [1:06:06<05:02, 25.22s/epoch, loss=0.158, accuracy=0.984, val_loss=0.41, val_accuracy=0.91, lr=5e-5]  93%|█████████▎| 155/166 [1:06:32<04:37, 25.24s/epoch, loss=0.159, accuracy=0.983, val_loss=0.41, val_accuracy=0.91, lr=5e-5] 94%|█████████▍| 156/166 [1:06:57<04:11, 25.16s/epoch, loss=0.159, accuracy=0.984, val_loss=0.41, val_accuracy=0.91, lr=5e-5] 95%|█████████▍| 157/166 [1:07:22<03:46, 25.22s/epoch, loss=0.157, accuracy=0.984, val_loss=0.408, val_accuracy=0.91, lr=5e-5] 95%|█████████▌| 158/166 [1:07:47<03:21, 25.19s/epoch, loss=0.158, accuracy=0.983, val_loss=0.409, val_accuracy=0.91, lr=5e-5] 96%|█████████▌| 159/166 [1:08:12<02:56, 25.20s/epoch, loss=0.158, accuracy=0.984, val_loss=0.41, val_accuracy=0.91, lr=5e-5]  96%|█████████▋| 160/166 [1:08:39<02:33, 25.65s/epoch, loss=0.156, accuracy=0.984, val_loss=0.409, val_accuracy=0.91, lr=5e-5] 97%|█████████▋| 161/166 [1:09:02<02:03, 24.72s/epoch, loss=0.156, accuracy=0.985, val_loss=0.408, val_accuracy=0.91, lr=5e-5] 98%|█████████▊| 162/166 [1:09:24<01:36, 24.08s/epoch, loss=0.155, accuracy=0.985, val_loss=0.411, val_accuracy=0.91, lr=5e-5] 98%|█████████▊| 163/166 [1:09:47<01:10, 23.61s/epoch, loss=0.156, accuracy=0.985, val_loss=0.411, val_accuracy=0.909, lr=5e-5] 99%|█████████▉| 164/166 [1:10:09<00:46, 23.28s/epoch, loss=0.154, accuracy=0.985, val_loss=0.411, val_accuracy=0.911, lr=5e-5] 99%|█████████▉| 165/166 [1:10:32<00:23, 23.06s/epoch, loss=0.154, accuracy=0.985, val_loss=0.41, val_accuracy=0.911, lr=5e-5] 100%|██████████| 166/166 [1:10:54<00:00, 22.88s/epoch, loss=0.154, accuracy=0.984, val_loss=0.411, val_accuracy=0.911, lr=5e-5]100%|██████████| 166/166 [1:10:54<00:00, 25.63s/epoch, loss=0.154, accuracy=0.984, val_loss=0.411, val_accuracy=0.911, lr=5e-5]
Using real-time data augmentation.
Only one model saved

Loading model: 09_09_cifar10_ResNet20v1.h5
Test score: 0.41126489639282227
Test accuracy: 0.9107000231742859
