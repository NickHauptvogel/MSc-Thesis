Tue Mar  5 10:59:46 2024       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 545.23.08              Driver Version: 545.23.08    CUDA Version: 12.3     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA TITAN Xp                Off | 00000000:03:00.0 Off |                  N/A |
| 32%   44C    P8              10W / 250W |      0MiB / 12288MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|  No running processes found                                                           |
+---------------------------------------------------------------------------------------+


* * * Run SGD for cluster size = 19. * * *


Budget: 78


* * * Run SGD for ID = 19_1. * * *


2024-03-05 10:59:47.586950: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 10:59:57.328916: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 10:59:57.330809: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-05 10:59:57.372266: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-05 10:59:57.372568: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 10:59:57.429970: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 10:59:57.430059: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 10:59:57.491493: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 10:59:57.547916: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 10:59:57.597586: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 10:59:57.629643: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 10:59:57.711687: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 10:59:57.712390: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 10:59:57.712481: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 10:59:59.315418: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-05 10:59:59.316396: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 10:59:59.316823: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-05 10:59:59.316865: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 10:59:59.316898: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 10:59:59.316916: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 10:59:59.316933: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 10:59:59.316949: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 10:59:59.316966: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 10:59:59.316983: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 10:59:59.316999: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 10:59:59.317440: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 10:59:59.317475: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 11:00:00.286945: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-05 11:00:00.287010: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-05 11:00:00.287021: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-05 11:00:00.288240: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:03:00.0, compute capability: 6.1)
{'id': '19_01', 'seed': 1, 'out_folder': 'results/epoch_budget', 'batch_size': 128, 'epochs': 78, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'bootstrapping': False, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/78 [00:00<?, ?epoch/s]2024-03-05 11:00:01.143160: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-05 11:00:01.143579: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199945000 Hz
2024-03-05 11:00:03.097048: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 11:00:03.373539: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 11:00:04.388298: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-05 11:00:04.425113: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|▏         | 1/78 [00:49<1:03:11, 49.24s/epoch, loss=3.27, accuracy=0.321, val_loss=2.3, val_accuracy=0.266, lr=0.1]  3%|▎         | 2/78 [01:11<42:02, 33.18s/epoch, loss=1.55, accuracy=0.545, val_loss=1.96, val_accuracy=0.441, lr=0.1]   4%|▍         | 3/78 [01:32<34:56, 27.95s/epoch, loss=1.34, accuracy=0.646, val_loss=1.66, val_accuracy=0.536, lr=0.1]  5%|▌         | 4/78 [01:54<31:32, 25.57s/epoch, loss=1.29, accuracy=0.68, val_loss=2.01, val_accuracy=0.472, lr=0.1]   6%|▋         | 5/78 [02:16<29:32, 24.28s/epoch, loss=1.27, accuracy=0.698, val_loss=2.31, val_accuracy=0.451, lr=0.1]  8%|▊         | 6/78 [02:38<28:07, 23.44s/epoch, loss=1.25, accuracy=0.709, val_loss=2.06, val_accuracy=0.524, lr=0.1]  9%|▉         | 7/78 [03:00<27:14, 23.02s/epoch, loss=1.23, accuracy=0.717, val_loss=1.64, val_accuracy=0.559, lr=0.1] 10%|█         | 8/78 [03:22<26:17, 22.54s/epoch, loss=1.22, accuracy=0.723, val_loss=2.21, val_accuracy=0.448, lr=0.1] 12%|█▏        | 9/78 [03:43<25:34, 22.24s/epoch, loss=1.21, accuracy=0.725, val_loss=2.07, val_accuracy=0.525, lr=0.1] 13%|█▎        | 10/78 [04:05<24:58, 22.04s/epoch, loss=1.21, accuracy=0.727, val_loss=1.63, val_accuracy=0.591, lr=0.1] 14%|█▍        | 11/78 [04:27<24:26, 21.89s/epoch, loss=1.2, accuracy=0.731, val_loss=3.72, val_accuracy=0.283, lr=0.1]  15%|█▌        | 12/78 [04:48<24:01, 21.85s/epoch, loss=1.2, accuracy=0.732, val_loss=2.77, val_accuracy=0.292, lr=0.1] 17%|█▋        | 13/78 [05:10<23:34, 21.76s/epoch, loss=1.2, accuracy=0.736, val_loss=2.27, val_accuracy=0.447, lr=0.1] 18%|█▊        | 14/78 [05:31<23:08, 21.69s/epoch, loss=1.19, accuracy=0.739, val_loss=1.65, val_accuracy=0.585, lr=0.1] 19%|█▉        | 15/78 [05:53<22:44, 21.67s/epoch, loss=1.19, accuracy=0.738, val_loss=2.05, val_accuracy=0.431, lr=0.0316] 21%|██        | 16/78 [06:15<22:25, 21.71s/epoch, loss=1.19, accuracy=0.739, val_loss=2.04, val_accuracy=0.564, lr=0.1]    22%|██▏       | 17/78 [06:36<22:03, 21.69s/epoch, loss=1.19, accuracy=0.74, val_loss=2.27, val_accuracy=0.468, lr=0.1]  23%|██▎       | 18/78 [06:58<21:46, 21.78s/epoch, loss=1.18, accuracy=0.742, val_loss=1.65, val_accuracy=0.567, lr=0.1] 24%|██▍       | 19/78 [07:20<21:23, 21.76s/epoch, loss=1.19, accuracy=0.741, val_loss=2.03, val_accuracy=0.472, lr=0.1] 26%|██▌       | 20/78 [07:42<21:01, 21.74s/epoch, loss=1.18, accuracy=0.742, val_loss=2.34, val_accuracy=0.415, lr=0.0316] 27%|██▋       | 21/78 [08:04<20:38, 21.73s/epoch, loss=1.18, accuracy=0.742, val_loss=2.06, val_accuracy=0.46, lr=0.1]     28%|██▊       | 22/78 [08:25<20:16, 21.72s/epoch, loss=1.18, accuracy=0.745, val_loss=1.39, val_accuracy=0.674, lr=0.1] 29%|██▉       | 23/78 [08:47<19:56, 21.75s/epoch, loss=1.18, accuracy=0.745, val_loss=1.68, val_accuracy=0.593, lr=0.1] 31%|███       | 24/78 [09:09<19:35, 21.78s/epoch, loss=1.17, accuracy=0.746, val_loss=2.01, val_accuracy=0.541, lr=0.1] 32%|███▏      | 25/78 [09:31<19:12, 21.75s/epoch, loss=1.17, accuracy=0.747, val_loss=1.96, val_accuracy=0.53, lr=0.1]  33%|███▎      | 26/78 [09:52<18:50, 21.74s/epoch, loss=1.18, accuracy=0.745, val_loss=2.18, val_accuracy=0.468, lr=0.1] 35%|███▍      | 27/78 [10:14<18:28, 21.74s/epoch, loss=1.17, accuracy=0.747, val_loss=2.69, val_accuracy=0.407, lr=0.0316] 36%|███▌      | 28/78 [10:36<18:07, 21.75s/epoch, loss=1.17, accuracy=0.745, val_loss=2.86, val_accuracy=0.321, lr=0.1]    37%|███▋      | 29/78 [10:57<17:43, 21.69s/epoch, loss=1.17, accuracy=0.748, val_loss=2.95, val_accuracy=0.41, lr=0.1]  38%|███▊      | 30/78 [11:19<17:19, 21.65s/epoch, loss=1.17, accuracy=0.751, val_loss=2.65, val_accuracy=0.42, lr=0.1] 40%|███▉      | 31/78 [11:41<16:58, 21.67s/epoch, loss=1.17, accuracy=0.749, val_loss=2.56, val_accuracy=0.442, lr=0.1] 41%|████      | 32/78 [12:03<16:39, 21.73s/epoch, loss=1.16, accuracy=0.748, val_loss=1.99, val_accuracy=0.473, lr=0.0316] 42%|████▏     | 33/78 [12:24<16:20, 21.79s/epoch, loss=1.16, accuracy=0.748, val_loss=1.65, val_accuracy=0.56, lr=0.1]     44%|████▎     | 34/78 [12:46<15:57, 21.77s/epoch, loss=1.16, accuracy=0.75, val_loss=1.71, val_accuracy=0.528, lr=0.1] 45%|████▍     | 35/78 [13:08<15:34, 21.72s/epoch, loss=1.16, accuracy=0.753, val_loss=5.13, val_accuracy=0.204, lr=0.1] 46%|████▌     | 36/78 [13:30<15:15, 21.79s/epoch, loss=1.16, accuracy=0.753, val_loss=2.79, val_accuracy=0.318, lr=0.1] 47%|████▋     | 37/78 [13:51<14:50, 21.71s/epoch, loss=1.16, accuracy=0.75, val_loss=1.95, val_accuracy=0.512, lr=0.0316] 49%|████▊     | 38/78 [14:13<14:28, 21.72s/epoch, loss=1.16, accuracy=0.749, val_loss=2.31, val_accuracy=0.454, lr=0.1]   50%|█████     | 39/78 [14:34<14:03, 21.63s/epoch, loss=1.16, accuracy=0.748, val_loss=2.52, val_accuracy=0.4, lr=0.1]   51%|█████▏    | 40/78 [14:56<13:40, 21.61s/epoch, loss=1.15, accuracy=0.752, val_loss=3.23, val_accuracy=0.374, lr=0.1] 53%|█████▎    | 41/78 [15:18<13:21, 21.66s/epoch, loss=1.15, accuracy=0.751, val_loss=3.5, val_accuracy=0.294, lr=0.1]  54%|█████▍    | 42/78 [15:39<12:56, 21.57s/epoch, loss=1.15, accuracy=0.752, val_loss=1.65, val_accuracy=0.571, lr=0.0316] 55%|█████▌    | 43/78 [16:01<12:35, 21.58s/epoch, loss=1.16, accuracy=0.751, val_loss=2.13, val_accuracy=0.475, lr=0.1]    56%|█████▋    | 44/78 [16:22<12:12, 21.55s/epoch, loss=1.16, accuracy=0.751, val_loss=1.73, val_accuracy=0.55, lr=0.1]  58%|█████▊    | 45/78 [16:44<11:50, 21.54s/epoch, loss=1.16, accuracy=0.752, val_loss=1.66, val_accuracy=0.562, lr=0.1] 59%|█████▉    | 46/78 [17:05<11:29, 21.55s/epoch, loss=1.15, accuracy=0.755, val_loss=2.45, val_accuracy=0.511, lr=0.1] 60%|██████    | 47/78 [17:27<11:12, 21.69s/epoch, loss=1.16, accuracy=0.751, val_loss=2.57, val_accuracy=0.435, lr=0.0316] 62%|██████▏   | 48/78 [17:49<10:49, 21.65s/epoch, loss=1.15, accuracy=0.753, val_loss=1.62, val_accuracy=0.588, lr=0.1]    63%|██████▎   | 49/78 [18:10<10:26, 21.60s/epoch, loss=1.15, accuracy=0.752, val_loss=1.62, val_accuracy=0.595, lr=0.1] 64%|██████▍   | 50/78 [18:33<10:13, 21.91s/epoch, loss=1.15, accuracy=0.753, val_loss=1.94, val_accuracy=0.533, lr=0.1] 65%|██████▌   | 51/78 [18:55<09:54, 22.01s/epoch, loss=1.15, accuracy=0.752, val_loss=4.99, val_accuracy=0.179, lr=0.1] 67%|██████▋   | 52/78 [19:18<09:35, 22.14s/epoch, loss=1.15, accuracy=0.752, val_loss=3.07, val_accuracy=0.335, lr=0.0316] 68%|██████▊   | 53/78 [19:41<09:18, 22.35s/epoch, loss=1.16, accuracy=0.751, val_loss=2.86, val_accuracy=0.326, lr=0.1]    69%|██████▉   | 54/78 [20:03<09:00, 22.51s/epoch, loss=1.15, accuracy=0.755, val_loss=2.17, val_accuracy=0.382, lr=0.1] 71%|███████   | 55/78 [20:26<08:39, 22.57s/epoch, loss=1.15, accuracy=0.753, val_loss=2.08, val_accuracy=0.457, lr=0.1] 72%|███████▏  | 56/78 [20:48<08:13, 22.45s/epoch, loss=1.15, accuracy=0.751, val_loss=4.08, val_accuracy=0.226, lr=0.1] 73%|███████▎  | 57/78 [21:10<07:47, 22.24s/epoch, loss=1.14, accuracy=0.752, val_loss=2.09, val_accuracy=0.504, lr=0.0316] 74%|███████▍  | 58/78 [21:32<07:20, 22.02s/epoch, loss=1.15, accuracy=0.754, val_loss=1.88, val_accuracy=0.471, lr=0.1]    76%|███████▌  | 59/78 [21:53<06:57, 21.99s/epoch, loss=1.15, accuracy=0.752, val_loss=1.71, val_accuracy=0.577, lr=0.1] 77%|███████▋  | 60/78 [22:15<06:33, 21.87s/epoch, loss=1.15, accuracy=0.751, val_loss=2.24, val_accuracy=0.474, lr=0.1] 78%|███████▊  | 61/78 [22:37<06:10, 21.79s/epoch, loss=1.15, accuracy=0.753, val_loss=1.53, val_accuracy=0.623, lr=0.1] 79%|███████▉  | 62/78 [22:58<05:47, 21.69s/epoch, loss=1.15, accuracy=0.751, val_loss=2.08, val_accuracy=0.487, lr=0.0316] 81%|████████  | 63/78 [23:20<05:26, 21.74s/epoch, loss=1.16, accuracy=0.751, val_loss=2.23, val_accuracy=0.483, lr=0.1]    82%|████████▏ | 64/78 [23:41<05:03, 21.65s/epoch, loss=1.15, accuracy=0.753, val_loss=1.79, val_accuracy=0.542, lr=0.1] 83%|████████▎ | 65/78 [24:03<04:40, 21.55s/epoch, loss=1.15, accuracy=0.752, val_loss=2.79, val_accuracy=0.426, lr=0.1] 85%|████████▍ | 66/78 [24:24<04:19, 21.60s/epoch, loss=1.14, accuracy=0.754, val_loss=1.51, val_accuracy=0.613, lr=0.1] 86%|████████▌ | 67/78 [24:46<03:57, 21.59s/epoch, loss=1.15, accuracy=0.753, val_loss=4.11, val_accuracy=0.266, lr=0.0316] 87%|████████▋ | 68/78 [25:07<03:35, 21.52s/epoch, loss=1.14, accuracy=0.755, val_loss=1.65, val_accuracy=0.606, lr=0.1]    88%|████████▊ | 69/78 [25:29<03:13, 21.48s/epoch, loss=1.14, accuracy=0.753, val_loss=1.77, val_accuracy=0.53, lr=0.1]  90%|████████▉ | 70/78 [25:51<02:53, 21.69s/epoch, loss=1.15, accuracy=0.752, val_loss=1.57, val_accuracy=0.595, lr=0.1] 91%|█████████ | 71/78 [26:13<02:32, 21.76s/epoch, loss=1.14, accuracy=0.754, val_loss=2.64, val_accuracy=0.38, lr=0.1]  92%|█████████▏| 72/78 [26:34<02:09, 21.62s/epoch, loss=1.14, accuracy=0.751, val_loss=2.59, val_accuracy=0.36, lr=0.0316] 94%|█████████▎| 73/78 [26:56<01:47, 21.59s/epoch, loss=1.15, accuracy=0.75, val_loss=2.44, val_accuracy=0.428, lr=0.1]    95%|█████████▍| 74/78 [27:17<01:26, 21.54s/epoch, loss=1.14, accuracy=0.754, val_loss=2.05, val_accuracy=0.471, lr=0.1] 96%|█████████▌| 75/78 [27:39<01:04, 21.54s/epoch, loss=1.14, accuracy=0.756, val_loss=1.73, val_accuracy=0.587, lr=0.1] 97%|█████████▋| 76/78 [28:00<00:43, 21.56s/epoch, loss=1.14, accuracy=0.756, val_loss=4.45, val_accuracy=0.264, lr=0.1] 99%|█████████▊| 77/78 [28:22<00:21, 21.70s/epoch, loss=1.15, accuracy=0.754, val_loss=2.08, val_accuracy=0.533, lr=0.0316]100%|██████████| 78/78 [28:44<00:00, 21.64s/epoch, loss=1.15, accuracy=0.754, val_loss=2.52, val_accuracy=0.451, lr=0.1]   100%|██████████| 78/78 [28:44<00:00, 22.11s/epoch, loss=1.15, accuracy=0.754, val_loss=2.52, val_accuracy=0.451, lr=0.1]
Using real-time data augmentation.
Test score: 2.5180139541625977
Test accuracy: 0.4512999951839447


* * * Run SGD for ID = 19_2. * * *


2024-03-05 11:28:49.832997: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 11:28:56.783890: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 11:28:56.784771: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-05 11:28:56.822321: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-05 11:28:56.822352: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 11:28:56.825961: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 11:28:56.826002: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 11:28:56.828432: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 11:28:56.829831: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 11:28:56.840940: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 11:28:56.842744: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 11:28:56.847011: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 11:28:56.847503: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 11:28:56.847591: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 11:28:58.047217: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-05 11:28:58.048222: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 11:28:58.048642: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-05 11:28:58.048671: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 11:28:58.048703: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 11:28:58.048720: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 11:28:58.048735: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 11:28:58.048751: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 11:28:58.048766: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 11:28:58.048781: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 11:28:58.048797: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 11:28:58.049305: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 11:28:58.049337: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 11:28:58.684373: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-05 11:28:58.684430: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-05 11:28:58.684447: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-05 11:28:58.685317: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:03:00.0, compute capability: 6.1)
{'id': '19_02', 'seed': 2, 'out_folder': 'results/epoch_budget', 'batch_size': 128, 'epochs': 78, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'bootstrapping': False, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/78 [00:00<?, ?epoch/s]2024-03-05 11:28:59.500603: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-05 11:28:59.501053: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199945000 Hz
2024-03-05 11:29:01.427074: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 11:29:01.636010: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 11:29:02.358822: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-05 11:29:02.391149: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|▏         | 1/78 [00:47<1:00:41, 47.30s/epoch, loss=3.04, accuracy=0.342, val_loss=2.54, val_accuracy=0.245, lr=0.1]  3%|▎         | 2/78 [01:08<40:44, 32.16s/epoch, loss=1.57, accuracy=0.531, val_loss=3.31, val_accuracy=0.256, lr=0.1]    4%|▍         | 3/78 [01:30<34:06, 27.28s/epoch, loss=1.33, accuracy=0.645, val_loss=1.72, val_accuracy=0.516, lr=0.1]  5%|▌         | 4/78 [01:51<30:43, 24.92s/epoch, loss=1.27, accuracy=0.687, val_loss=1.97, val_accuracy=0.417, lr=0.1]  6%|▋         | 5/78 [02:13<28:46, 23.65s/epoch, loss=1.24, accuracy=0.707, val_loss=2.12, val_accuracy=0.499, lr=0.1]  8%|▊         | 6/78 [02:34<27:22, 22.82s/epoch, loss=1.23, accuracy=0.716, val_loss=1.71, val_accuracy=0.578, lr=0.1]  9%|▉         | 7/78 [02:55<26:23, 22.30s/epoch, loss=1.22, accuracy=0.723, val_loss=1.84, val_accuracy=0.541, lr=0.1] 10%|█         | 8/78 [03:16<25:43, 22.05s/epoch, loss=1.22, accuracy=0.728, val_loss=1.65, val_accuracy=0.612, lr=0.1] 12%|█▏        | 9/78 [03:38<25:07, 21.84s/epoch, loss=1.21, accuracy=0.731, val_loss=2.12, val_accuracy=0.465, lr=0.1] 13%|█▎        | 10/78 [03:59<24:32, 21.66s/epoch, loss=1.21, accuracy=0.732, val_loss=1.72, val_accuracy=0.534, lr=0.1] 14%|█▍        | 11/78 [04:21<24:05, 21.58s/epoch, loss=1.21, accuracy=0.733, val_loss=1.76, val_accuracy=0.55, lr=0.1]  15%|█▌        | 12/78 [04:42<23:36, 21.46s/epoch, loss=1.2, accuracy=0.735, val_loss=3.29, val_accuracy=0.341, lr=0.1] 17%|█▋        | 13/78 [05:03<23:07, 21.34s/epoch, loss=1.19, accuracy=0.74, val_loss=2.66, val_accuracy=0.366, lr=0.0316] 18%|█▊        | 14/78 [05:24<22:45, 21.33s/epoch, loss=1.2, accuracy=0.736, val_loss=1.97, val_accuracy=0.545, lr=0.1]    19%|█▉        | 15/78 [05:45<22:20, 21.28s/epoch, loss=1.19, accuracy=0.74, val_loss=2.28, val_accuracy=0.407, lr=0.1] 21%|██        | 16/78 [06:06<21:58, 21.27s/epoch, loss=1.18, accuracy=0.742, val_loss=2.08, val_accuracy=0.495, lr=0.1] 22%|██▏       | 17/78 [06:29<21:58, 21.62s/epoch, loss=1.19, accuracy=0.74, val_loss=2.07, val_accuracy=0.489, lr=0.1]  23%|██▎       | 18/78 [06:51<21:37, 21.63s/epoch, loss=1.19, accuracy=0.742, val_loss=2.03, val_accuracy=0.458, lr=0.0316] 24%|██▍       | 19/78 [07:12<21:08, 21.49s/epoch, loss=1.18, accuracy=0.743, val_loss=1.95, val_accuracy=0.525, lr=0.1]    26%|██▌       | 20/78 [07:33<20:41, 21.40s/epoch, loss=1.18, accuracy=0.745, val_loss=3.89, val_accuracy=0.345, lr=0.1] 27%|██▋       | 21/78 [07:54<20:17, 21.36s/epoch, loss=1.18, accuracy=0.743, val_loss=1.55, val_accuracy=0.618, lr=0.1] 28%|██▊       | 22/78 [08:16<20:00, 21.43s/epoch, loss=1.17, accuracy=0.749, val_loss=1.86, val_accuracy=0.564, lr=0.1] 29%|██▉       | 23/78 [08:37<19:39, 21.45s/epoch, loss=1.17, accuracy=0.747, val_loss=1.84, val_accuracy=0.543, lr=0.1] 31%|███       | 24/78 [08:59<19:14, 21.38s/epoch, loss=1.17, accuracy=0.747, val_loss=1.88, val_accuracy=0.515, lr=0.1] 32%|███▏      | 25/78 [09:20<18:52, 21.37s/epoch, loss=1.17, accuracy=0.747, val_loss=2.7, val_accuracy=0.301, lr=0.1]  33%|███▎      | 26/78 [09:41<18:29, 21.34s/epoch, loss=1.17, accuracy=0.75, val_loss=1.86, val_accuracy=0.519, lr=0.0316] 35%|███▍      | 27/78 [10:02<18:05, 21.29s/epoch, loss=1.17, accuracy=0.748, val_loss=1.68, val_accuracy=0.577, lr=0.1]   36%|███▌      | 28/78 [10:24<17:50, 21.40s/epoch, loss=1.17, accuracy=0.748, val_loss=1.53, val_accuracy=0.637, lr=0.1] 37%|███▋      | 29/78 [10:45<17:24, 21.32s/epoch, loss=1.16, accuracy=0.751, val_loss=2.64, val_accuracy=0.44, lr=0.1]  38%|███▊      | 30/78 [11:06<16:59, 21.24s/epoch, loss=1.16, accuracy=0.752, val_loss=2, val_accuracy=0.508, lr=0.1]   40%|███▉      | 31/78 [11:27<16:37, 21.23s/epoch, loss=1.15, accuracy=0.752, val_loss=1.95, val_accuracy=0.525, lr=0.1] 41%|████      | 32/78 [11:48<16:14, 21.18s/epoch, loss=1.17, accuracy=0.75, val_loss=1.87, val_accuracy=0.545, lr=0.1]  42%|████▏     | 33/78 [12:10<15:52, 21.17s/epoch, loss=1.15, accuracy=0.754, val_loss=2.49, val_accuracy=0.315, lr=0.0316] 44%|████▎     | 34/78 [12:31<15:31, 21.18s/epoch, loss=1.15, accuracy=0.754, val_loss=2.18, val_accuracy=0.421, lr=0.1]    45%|████▍     | 35/78 [12:52<15:10, 21.17s/epoch, loss=1.15, accuracy=0.753, val_loss=1.62, val_accuracy=0.599, lr=0.1] 46%|████▌     | 36/78 [13:13<14:48, 21.15s/epoch, loss=1.15, accuracy=0.752, val_loss=3.16, val_accuracy=0.315, lr=0.1] 47%|████▋     | 37/78 [13:34<14:26, 21.13s/epoch, loss=1.15, accuracy=0.751, val_loss=3.26, val_accuracy=0.324, lr=0.1] 49%|████▊     | 38/78 [13:55<14:05, 21.14s/epoch, loss=1.15, accuracy=0.753, val_loss=2, val_accuracy=0.506, lr=0.0316] 50%|█████     | 39/78 [14:16<13:44, 21.14s/epoch, loss=1.14, accuracy=0.755, val_loss=3.71, val_accuracy=0.319, lr=0.1] 51%|█████▏    | 40/78 [14:38<13:23, 21.13s/epoch, loss=1.14, accuracy=0.751, val_loss=2.24, val_accuracy=0.415, lr=0.1] 53%|█████▎    | 41/78 [14:59<13:01, 21.13s/epoch, loss=1.14, accuracy=0.754, val_loss=1.51, val_accuracy=0.599, lr=0.1] 54%|█████▍    | 42/78 [15:20<12:42, 21.18s/epoch, loss=1.14, accuracy=0.755, val_loss=2.39, val_accuracy=0.493, lr=0.1] 55%|█████▌    | 43/78 [15:41<12:22, 21.23s/epoch, loss=1.14, accuracy=0.753, val_loss=2.86, val_accuracy=0.386, lr=0.1] 56%|█████▋    | 44/78 [16:03<12:07, 21.38s/epoch, loss=1.14, accuracy=0.757, val_loss=2.23, val_accuracy=0.466, lr=0.1] 58%|█████▊    | 45/78 [16:24<11:44, 21.35s/epoch, loss=1.13, accuracy=0.755, val_loss=1.52, val_accuracy=0.619, lr=0.1] 59%|█████▉    | 46/78 [16:45<11:21, 21.29s/epoch, loss=1.13, accuracy=0.754, val_loss=2.01, val_accuracy=0.47, lr=0.0316] 60%|██████    | 47/78 [17:07<11:02, 21.38s/epoch, loss=1.14, accuracy=0.754, val_loss=2.55, val_accuracy=0.403, lr=0.1]   62%|██████▏   | 48/78 [17:28<10:41, 21.37s/epoch, loss=1.14, accuracy=0.755, val_loss=1.9, val_accuracy=0.52, lr=0.1]   63%|██████▎   | 49/78 [17:50<10:24, 21.54s/epoch, loss=1.14, accuracy=0.754, val_loss=1.52, val_accuracy=0.642, lr=0.1] 64%|██████▍   | 50/78 [18:11<09:59, 21.39s/epoch, loss=1.13, accuracy=0.754, val_loss=3.69, val_accuracy=0.296, lr=0.1] 65%|██████▌   | 51/78 [18:32<09:35, 21.31s/epoch, loss=1.13, accuracy=0.757, val_loss=5.86, val_accuracy=0.286, lr=0.0316] 67%|██████▋   | 52/78 [18:54<09:12, 21.24s/epoch, loss=1.13, accuracy=0.756, val_loss=2.3, val_accuracy=0.467, lr=0.1]     68%|██████▊   | 53/78 [19:15<08:51, 21.27s/epoch, loss=1.13, accuracy=0.758, val_loss=1.63, val_accuracy=0.592, lr=0.1] 69%|██████▉   | 54/78 [19:37<08:33, 21.38s/epoch, loss=1.12, accuracy=0.759, val_loss=2.05, val_accuracy=0.49, lr=0.1]  71%|███████   | 55/78 [19:58<08:09, 21.30s/epoch, loss=1.13, accuracy=0.756, val_loss=1.67, val_accuracy=0.56, lr=0.1] 72%|███████▏  | 56/78 [20:19<07:47, 21.23s/epoch, loss=1.13, accuracy=0.757, val_loss=2.23, val_accuracy=0.501, lr=0.0316] 73%|███████▎  | 57/78 [20:40<07:25, 21.24s/epoch, loss=1.13, accuracy=0.756, val_loss=1.59, val_accuracy=0.564, lr=0.1]    74%|███████▍  | 58/78 [21:01<07:04, 21.24s/epoch, loss=1.13, accuracy=0.756, val_loss=3.17, val_accuracy=0.356, lr=0.1] 76%|███████▌  | 59/78 [21:22<06:42, 21.21s/epoch, loss=1.12, accuracy=0.759, val_loss=1.88, val_accuracy=0.535, lr=0.1] 77%|███████▋  | 60/78 [21:44<06:24, 21.37s/epoch, loss=1.12, accuracy=0.759, val_loss=2.54, val_accuracy=0.495, lr=0.1] 78%|███████▊  | 61/78 [22:05<06:01, 21.29s/epoch, loss=1.13, accuracy=0.755, val_loss=1.71, val_accuracy=0.576, lr=0.0316] 79%|███████▉  | 62/78 [22:26<05:40, 21.25s/epoch, loss=1.12, accuracy=0.76, val_loss=2.47, val_accuracy=0.377, lr=0.1]     81%|████████  | 63/78 [22:47<05:17, 21.20s/epoch, loss=1.13, accuracy=0.756, val_loss=1.57, val_accuracy=0.585, lr=0.1] 82%|████████▏ | 64/78 [23:09<04:57, 21.24s/epoch, loss=1.11, accuracy=0.761, val_loss=1.45, val_accuracy=0.635, lr=0.1] 83%|████████▎ | 65/78 [23:30<04:35, 21.21s/epoch, loss=1.12, accuracy=0.761, val_loss=1.56, val_accuracy=0.635, lr=0.1] 85%|████████▍ | 66/78 [23:51<04:13, 21.14s/epoch, loss=1.12, accuracy=0.758, val_loss=1.42, val_accuracy=0.657, lr=0.1] 86%|████████▌ | 67/78 [24:12<03:52, 21.12s/epoch, loss=1.13, accuracy=0.757, val_loss=2.37, val_accuracy=0.49, lr=0.1]  87%|████████▋ | 68/78 [24:33<03:31, 21.11s/epoch, loss=1.13, accuracy=0.756, val_loss=2.53, val_accuracy=0.442, lr=0.1] 88%|████████▊ | 69/78 [24:54<03:09, 21.08s/epoch, loss=1.12, accuracy=0.757, val_loss=1.8, val_accuracy=0.544, lr=0.1]  90%|████████▉ | 70/78 [25:16<02:49, 21.19s/epoch, loss=1.12, accuracy=0.758, val_loss=3.94, val_accuracy=0.238, lr=0.1] 91%|█████████ | 71/78 [25:37<02:28, 21.17s/epoch, loss=1.12, accuracy=0.755, val_loss=1.99, val_accuracy=0.553, lr=0.0316] 92%|█████████▏| 72/78 [25:58<02:08, 21.34s/epoch, loss=1.12, accuracy=0.757, val_loss=2.08, val_accuracy=0.488, lr=0.1]    94%|█████████▎| 73/78 [26:20<01:46, 21.38s/epoch, loss=1.12, accuracy=0.756, val_loss=2.06, val_accuracy=0.426, lr=0.1] 95%|█████████▍| 74/78 [26:41<01:25, 21.42s/epoch, loss=1.12, accuracy=0.759, val_loss=2.25, val_accuracy=0.491, lr=0.1] 96%|█████████▌| 75/78 [27:03<01:04, 21.36s/epoch, loss=1.12, accuracy=0.758, val_loss=3.18, val_accuracy=0.384, lr=0.1] 97%|█████████▋| 76/78 [27:24<00:42, 21.27s/epoch, loss=1.11, accuracy=0.757, val_loss=2.12, val_accuracy=0.44, lr=0.0316] 99%|█████████▊| 77/78 [27:45<00:21, 21.17s/epoch, loss=1.12, accuracy=0.759, val_loss=2.15, val_accuracy=0.454, lr=0.1]  100%|██████████| 78/78 [28:06<00:00, 21.19s/epoch, loss=1.11, accuracy=0.759, val_loss=1.48, val_accuracy=0.626, lr=0.1]100%|██████████| 78/78 [28:06<00:00, 21.62s/epoch, loss=1.11, accuracy=0.759, val_loss=1.48, val_accuracy=0.626, lr=0.1]
Using real-time data augmentation.
Test score: 1.4845014810562134
Test accuracy: 0.6258000135421753


* * * Run SGD for ID = 19_3. * * *


2024-03-05 11:57:09.491169: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 11:57:13.450058: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 11:57:13.450983: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-05 11:57:13.489712: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-05 11:57:13.489745: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 11:57:13.492521: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 11:57:13.492562: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 11:57:13.494612: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 11:57:13.495998: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 11:57:13.498195: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 11:57:13.504921: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 11:57:13.509371: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 11:57:13.509872: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 11:57:13.509958: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 11:57:14.733738: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-05 11:57:14.734746: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 11:57:14.735531: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-05 11:57:14.735562: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 11:57:14.735599: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 11:57:14.735617: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 11:57:14.735633: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 11:57:14.735649: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 11:57:14.735666: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 11:57:14.735684: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 11:57:14.735703: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 11:57:14.736170: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 11:57:14.736202: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 11:57:15.344451: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-05 11:57:15.344509: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-05 11:57:15.344519: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-05 11:57:15.345363: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:03:00.0, compute capability: 6.1)
{'id': '19_03', 'seed': 3, 'out_folder': 'results/epoch_budget', 'batch_size': 128, 'epochs': 78, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'bootstrapping': False, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/78 [00:00<?, ?epoch/s]2024-03-05 11:57:16.158718: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-05 11:57:16.159160: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199945000 Hz
2024-03-05 11:57:18.098167: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 11:57:18.309209: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 11:57:19.283771: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-05 11:57:19.320709: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|▏         | 1/78 [00:52<1:07:52, 52.89s/epoch, loss=2.9, accuracy=0.376, val_loss=1.89, val_accuracy=0.419, lr=0.1]  3%|▎         | 2/78 [01:14<43:38, 34.45s/epoch, loss=1.52, accuracy=0.565, val_loss=2.11, val_accuracy=0.445, lr=0.1]   4%|▍         | 3/78 [01:35<35:36, 28.49s/epoch, loss=1.33, accuracy=0.658, val_loss=1.89, val_accuracy=0.469, lr=0.1]  5%|▌         | 4/78 [01:57<31:42, 25.71s/epoch, loss=1.27, accuracy=0.692, val_loss=1.64, val_accuracy=0.583, lr=0.1]  6%|▋         | 5/78 [02:18<29:19, 24.10s/epoch, loss=1.25, accuracy=0.709, val_loss=1.78, val_accuracy=0.517, lr=0.1]  8%|▊         | 6/78 [02:39<27:49, 23.18s/epoch, loss=1.22, accuracy=0.718, val_loss=2.83, val_accuracy=0.374, lr=0.1]  9%|▉         | 7/78 [03:01<26:46, 22.62s/epoch, loss=1.21, accuracy=0.725, val_loss=1.63, val_accuracy=0.567, lr=0.1] 10%|█         | 8/78 [03:22<25:57, 22.24s/epoch, loss=1.2, accuracy=0.729, val_loss=1.7, val_accuracy=0.597, lr=0.1]   12%|█▏        | 9/78 [03:44<25:15, 21.96s/epoch, loss=1.2, accuracy=0.735, val_loss=1.99, val_accuracy=0.493, lr=0.1] 13%|█▎        | 10/78 [04:05<24:45, 21.84s/epoch, loss=1.19, accuracy=0.737, val_loss=2.51, val_accuracy=0.4, lr=0.1] 14%|█▍        | 11/78 [04:26<24:11, 21.66s/epoch, loss=1.19, accuracy=0.74, val_loss=2.03, val_accuracy=0.538, lr=0.1] 15%|█▌        | 12/78 [04:48<23:55, 21.74s/epoch, loss=1.18, accuracy=0.74, val_loss=1.62, val_accuracy=0.622, lr=0.1] 17%|█▋        | 13/78 [05:10<23:28, 21.67s/epoch, loss=1.18, accuracy=0.742, val_loss=1.66, val_accuracy=0.597, lr=0.1] 18%|█▊        | 14/78 [05:32<23:10, 21.73s/epoch, loss=1.17, accuracy=0.744, val_loss=1.8, val_accuracy=0.512, lr=0.1]  19%|█▉        | 15/78 [05:53<22:42, 21.62s/epoch, loss=1.17, accuracy=0.743, val_loss=1.78, val_accuracy=0.545, lr=0.1] 21%|██        | 16/78 [06:15<22:15, 21.54s/epoch, loss=1.17, accuracy=0.747, val_loss=1.86, val_accuracy=0.55, lr=0.1]  22%|██▏       | 17/78 [06:36<21:52, 21.51s/epoch, loss=1.16, accuracy=0.744, val_loss=1.59, val_accuracy=0.617, lr=0.1] 23%|██▎       | 18/78 [06:57<21:27, 21.46s/epoch, loss=1.16, accuracy=0.749, val_loss=1.53, val_accuracy=0.609, lr=0.1] 24%|██▍       | 19/78 [07:19<21:04, 21.43s/epoch, loss=1.16, accuracy=0.748, val_loss=1.71, val_accuracy=0.56, lr=0.1]  26%|██▌       | 20/78 [07:40<20:42, 21.41s/epoch, loss=1.16, accuracy=0.75, val_loss=1.68, val_accuracy=0.558, lr=0.1] 27%|██▋       | 21/78 [08:02<20:21, 21.44s/epoch, loss=1.16, accuracy=0.749, val_loss=1.69, val_accuracy=0.601, lr=0.1] 28%|██▊       | 22/78 [08:23<20:02, 21.47s/epoch, loss=1.16, accuracy=0.75, val_loss=1.75, val_accuracy=0.545, lr=0.1]  29%|██▉       | 23/78 [08:45<19:41, 21.49s/epoch, loss=1.15, accuracy=0.752, val_loss=1.61, val_accuracy=0.587, lr=0.0316] 31%|███       | 24/78 [09:06<19:23, 21.55s/epoch, loss=1.15, accuracy=0.754, val_loss=1.98, val_accuracy=0.501, lr=0.1]    32%|███▏      | 25/78 [09:28<19:01, 21.54s/epoch, loss=1.14, accuracy=0.752, val_loss=2.14, val_accuracy=0.523, lr=0.1] 33%|███▎      | 26/78 [09:49<18:38, 21.52s/epoch, loss=1.15, accuracy=0.753, val_loss=1.61, val_accuracy=0.599, lr=0.1] 35%|███▍      | 27/78 [10:11<18:19, 21.55s/epoch, loss=1.14, accuracy=0.755, val_loss=2.83, val_accuracy=0.368, lr=0.1] 36%|███▌      | 28/78 [10:33<18:00, 21.61s/epoch, loss=1.14, accuracy=0.755, val_loss=1.78, val_accuracy=0.556, lr=0.0316] 37%|███▋      | 29/78 [10:55<17:44, 21.73s/epoch, loss=1.14, accuracy=0.752, val_loss=1.9, val_accuracy=0.533, lr=0.1]     38%|███▊      | 30/78 [11:16<17:17, 21.61s/epoch, loss=1.14, accuracy=0.753, val_loss=1.85, val_accuracy=0.536, lr=0.1] 40%|███▉      | 31/78 [11:37<16:50, 21.50s/epoch, loss=1.13, accuracy=0.757, val_loss=1.36, val_accuracy=0.691, lr=0.1] 41%|████      | 32/78 [11:59<16:27, 21.46s/epoch, loss=1.14, accuracy=0.755, val_loss=4.04, val_accuracy=0.313, lr=0.1] 42%|████▏     | 33/78 [12:20<16:04, 21.43s/epoch, loss=1.14, accuracy=0.758, val_loss=2.31, val_accuracy=0.45, lr=0.1]  44%|████▎     | 34/78 [12:41<15:40, 21.37s/epoch, loss=1.13, accuracy=0.756, val_loss=1.5, val_accuracy=0.628, lr=0.1] 45%|████▍     | 35/78 [13:03<15:23, 21.47s/epoch, loss=1.13, accuracy=0.758, val_loss=1.63, val_accuracy=0.547, lr=0.1] 46%|████▌     | 36/78 [13:24<14:59, 21.41s/epoch, loss=1.13, accuracy=0.755, val_loss=1.98, val_accuracy=0.551, lr=0.0316] 47%|████▋     | 37/78 [13:46<14:40, 21.47s/epoch, loss=1.13, accuracy=0.757, val_loss=2.89, val_accuracy=0.322, lr=0.1]    49%|████▊     | 38/78 [14:07<14:18, 21.47s/epoch, loss=1.13, accuracy=0.755, val_loss=2.59, val_accuracy=0.353, lr=0.1] 50%|█████     | 39/78 [14:29<13:54, 21.41s/epoch, loss=1.13, accuracy=0.758, val_loss=1.68, val_accuracy=0.578, lr=0.1] 51%|█████▏    | 40/78 [14:51<13:41, 21.63s/epoch, loss=1.13, accuracy=0.755, val_loss=2.45, val_accuracy=0.434, lr=0.1] 53%|█████▎    | 41/78 [15:12<13:15, 21.50s/epoch, loss=1.12, accuracy=0.757, val_loss=2.41, val_accuracy=0.424, lr=0.0316] 54%|█████▍    | 42/78 [15:33<12:50, 21.41s/epoch, loss=1.13, accuracy=0.756, val_loss=1.62, val_accuracy=0.59, lr=0.1]     55%|█████▌    | 43/78 [15:54<12:29, 21.40s/epoch, loss=1.12, accuracy=0.757, val_loss=1.77, val_accuracy=0.565, lr=0.1] 56%|█████▋    | 44/78 [16:16<12:05, 21.34s/epoch, loss=1.12, accuracy=0.756, val_loss=1.71, val_accuracy=0.529, lr=0.1] 58%|█████▊    | 45/78 [16:37<11:45, 21.37s/epoch, loss=1.12, accuracy=0.761, val_loss=1.76, val_accuracy=0.555, lr=0.1] 59%|█████▉    | 46/78 [16:58<11:23, 21.36s/epoch, loss=1.12, accuracy=0.76, val_loss=1.5, val_accuracy=0.642, lr=0.0316] 60%|██████    | 47/78 [17:20<11:01, 21.33s/epoch, loss=1.12, accuracy=0.757, val_loss=1.91, val_accuracy=0.51, lr=0.1]   62%|██████▏   | 48/78 [17:41<10:41, 21.37s/epoch, loss=1.13, accuracy=0.755, val_loss=2.17, val_accuracy=0.424, lr=0.1] 63%|██████▎   | 49/78 [18:03<10:23, 21.49s/epoch, loss=1.13, accuracy=0.759, val_loss=5.45, val_accuracy=0.272, lr=0.1] 64%|██████▍   | 50/78 [18:24<10:02, 21.52s/epoch, loss=1.12, accuracy=0.76, val_loss=1.86, val_accuracy=0.532, lr=0.1]  65%|██████▌   | 51/78 [18:46<09:40, 21.48s/epoch, loss=1.11, accuracy=0.761, val_loss=1.72, val_accuracy=0.552, lr=0.0316] 67%|██████▋   | 52/78 [19:07<09:16, 21.41s/epoch, loss=1.13, accuracy=0.756, val_loss=3.14, val_accuracy=0.314, lr=0.1]    68%|██████▊   | 53/78 [19:29<08:58, 21.54s/epoch, loss=1.12, accuracy=0.759, val_loss=2.49, val_accuracy=0.48, lr=0.1]  69%|██████▉   | 54/78 [19:50<08:35, 21.49s/epoch, loss=1.12, accuracy=0.758, val_loss=8.33, val_accuracy=0.137, lr=0.1] 71%|███████   | 55/78 [20:12<08:13, 21.47s/epoch, loss=1.12, accuracy=0.759, val_loss=2.34, val_accuracy=0.432, lr=0.1] 72%|███████▏  | 56/78 [20:33<07:51, 21.43s/epoch, loss=1.11, accuracy=0.759, val_loss=1.41, val_accuracy=0.657, lr=0.0316] 73%|███████▎  | 57/78 [20:54<07:29, 21.40s/epoch, loss=1.12, accuracy=0.758, val_loss=3.29, val_accuracy=0.362, lr=0.1]    74%|███████▍  | 58/78 [21:16<07:07, 21.36s/epoch, loss=1.12, accuracy=0.758, val_loss=2.05, val_accuracy=0.531, lr=0.1] 76%|███████▌  | 59/78 [21:37<06:45, 21.32s/epoch, loss=1.12, accuracy=0.758, val_loss=2.2, val_accuracy=0.449, lr=0.1]  77%|███████▋  | 60/78 [21:58<06:23, 21.29s/epoch, loss=1.12, accuracy=0.758, val_loss=1.95, val_accuracy=0.482, lr=0.1] 78%|███████▊  | 61/78 [22:20<06:04, 21.44s/epoch, loss=1.11, accuracy=0.758, val_loss=2.02, val_accuracy=0.508, lr=0.0316] 79%|███████▉  | 62/78 [22:41<05:42, 21.41s/epoch, loss=1.12, accuracy=0.756, val_loss=3.86, val_accuracy=0.333, lr=0.1]    81%|████████  | 63/78 [23:02<05:20, 21.35s/epoch, loss=1.12, accuracy=0.758, val_loss=1.58, val_accuracy=0.603, lr=0.1] 82%|████████▏ | 64/78 [23:24<05:00, 21.47s/epoch, loss=1.12, accuracy=0.76, val_loss=2.23, val_accuracy=0.446, lr=0.1]  83%|████████▎ | 65/78 [23:46<04:40, 21.60s/epoch, loss=1.12, accuracy=0.759, val_loss=2.67, val_accuracy=0.42, lr=0.1] 85%|████████▍ | 66/78 [24:07<04:17, 21.46s/epoch, loss=1.12, accuracy=0.758, val_loss=2.56, val_accuracy=0.462, lr=0.0316] 86%|████████▌ | 67/78 [24:28<03:55, 21.38s/epoch, loss=1.12, accuracy=0.759, val_loss=1.63, val_accuracy=0.613, lr=0.1]    87%|████████▋ | 68/78 [24:50<03:33, 21.35s/epoch, loss=1.12, accuracy=0.758, val_loss=2.29, val_accuracy=0.525, lr=0.1] 88%|████████▊ | 69/78 [25:11<03:11, 21.25s/epoch, loss=1.11, accuracy=0.761, val_loss=2.29, val_accuracy=0.407, lr=0.1] 90%|████████▉ | 70/78 [25:32<02:49, 21.21s/epoch, loss=1.11, accuracy=0.76, val_loss=2.6, val_accuracy=0.438, lr=0.1]   91%|█████████ | 71/78 [25:53<02:28, 21.27s/epoch, loss=1.11, accuracy=0.757, val_loss=2.01, val_accuracy=0.475, lr=0.0316] 92%|█████████▏| 72/78 [26:14<02:07, 21.21s/epoch, loss=1.12, accuracy=0.758, val_loss=3.15, val_accuracy=0.239, lr=0.1]    94%|█████████▎| 73/78 [26:36<01:47, 21.40s/epoch, loss=1.11, accuracy=0.76, val_loss=2.59, val_accuracy=0.415, lr=0.1]  95%|█████████▍| 74/78 [26:57<01:25, 21.33s/epoch, loss=1.11, accuracy=0.758, val_loss=1.96, val_accuracy=0.479, lr=0.1] 96%|█████████▌| 75/78 [27:19<01:04, 21.44s/epoch, loss=1.12, accuracy=0.759, val_loss=1.72, val_accuracy=0.559, lr=0.1] 97%|█████████▋| 76/78 [27:40<00:42, 21.44s/epoch, loss=1.11, accuracy=0.76, val_loss=2.55, val_accuracy=0.365, lr=0.0316] 99%|█████████▊| 77/78 [28:02<00:21, 21.39s/epoch, loss=1.12, accuracy=0.759, val_loss=2.12, val_accuracy=0.469, lr=0.1]  100%|██████████| 78/78 [28:23<00:00, 21.36s/epoch, loss=1.11, accuracy=0.761, val_loss=3.38, val_accuracy=0.36, lr=0.1] 100%|██████████| 78/78 [28:23<00:00, 21.84s/epoch, loss=1.11, accuracy=0.761, val_loss=3.38, val_accuracy=0.36, lr=0.1]
Using real-time data augmentation.
Test score: 3.377183675765991
Test accuracy: 0.36000001430511475


* * * Run SGD for ID = 19_4. * * *


2024-03-05 12:25:43.188066: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 12:25:46.278054: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 12:25:46.278889: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-05 12:25:46.317652: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-05 12:25:46.317683: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 12:25:46.320901: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 12:25:46.320943: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 12:25:46.323090: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 12:25:46.323982: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 12:25:46.326234: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 12:25:46.327671: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 12:25:46.331973: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 12:25:46.332460: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 12:25:46.332544: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 12:25:47.549754: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-05 12:25:47.550346: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 12:25:47.551117: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-05 12:25:47.551163: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 12:25:47.551200: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 12:25:47.551216: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 12:25:47.551232: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 12:25:47.551247: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 12:25:47.551264: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 12:25:47.551280: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 12:25:47.551299: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 12:25:47.551717: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 12:25:47.551757: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 12:25:48.180503: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-05 12:25:48.180562: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-05 12:25:48.180570: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-05 12:25:48.181456: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:03:00.0, compute capability: 6.1)
{'id': '19_04', 'seed': 4, 'out_folder': 'results/epoch_budget', 'batch_size': 128, 'epochs': 78, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'bootstrapping': False, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/78 [00:00<?, ?epoch/s]2024-03-05 12:25:48.996253: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-05 12:25:48.996691: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199945000 Hz
2024-03-05 12:25:50.957174: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 12:25:51.172191: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 12:25:52.043905: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-05 12:25:52.075379: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|▏         | 1/78 [00:45<57:59, 45.19s/epoch, loss=2.83, accuracy=0.397, val_loss=3.19, val_accuracy=0.234, lr=0.1]  3%|▎         | 2/78 [01:06<39:35, 31.26s/epoch, loss=1.46, accuracy=0.595, val_loss=2.61, val_accuracy=0.268, lr=0.1]  4%|▍         | 3/78 [01:28<33:27, 26.76s/epoch, loss=1.27, accuracy=0.673, val_loss=1.51, val_accuracy=0.595, lr=0.1]  5%|▌         | 4/78 [01:49<30:14, 24.52s/epoch, loss=1.23, accuracy=0.701, val_loss=4.41, val_accuracy=0.307, lr=0.1]  6%|▋         | 5/78 [02:10<28:17, 23.25s/epoch, loss=1.22, accuracy=0.71, val_loss=3.39, val_accuracy=0.345, lr=0.1]   8%|▊         | 6/78 [02:31<27:16, 22.74s/epoch, loss=1.2, accuracy=0.723, val_loss=3.34, val_accuracy=0.37, lr=0.1]   9%|▉         | 7/78 [02:53<26:18, 22.23s/epoch, loss=1.2, accuracy=0.725, val_loss=2.05, val_accuracy=0.425, lr=0.1] 10%|█         | 8/78 [03:14<25:36, 21.95s/epoch, loss=1.19, accuracy=0.728, val_loss=2.64, val_accuracy=0.446, lr=0.0316] 12%|█▏        | 9/78 [03:35<24:56, 21.69s/epoch, loss=1.18, accuracy=0.734, val_loss=2.04, val_accuracy=0.496, lr=0.1]    13%|█▎        | 10/78 [03:56<24:21, 21.49s/epoch, loss=1.18, accuracy=0.736, val_loss=1.46, val_accuracy=0.622, lr=0.1] 14%|█▍        | 11/78 [04:18<24:02, 21.52s/epoch, loss=1.17, accuracy=0.74, val_loss=1.81, val_accuracy=0.548, lr=0.1]  15%|█▌        | 12/78 [04:39<23:32, 21.40s/epoch, loss=1.17, accuracy=0.742, val_loss=2.07, val_accuracy=0.47, lr=0.1] 17%|█▋        | 13/78 [05:00<23:03, 21.28s/epoch, loss=1.17, accuracy=0.74, val_loss=1.59, val_accuracy=0.61, lr=0.1]  18%|█▊        | 14/78 [05:21<22:45, 21.34s/epoch, loss=1.16, accuracy=0.744, val_loss=2.52, val_accuracy=0.449, lr=0.1] 19%|█▉        | 15/78 [05:42<22:21, 21.29s/epoch, loss=1.16, accuracy=0.745, val_loss=2.15, val_accuracy=0.458, lr=0.0316] 21%|██        | 16/78 [06:03<21:53, 21.19s/epoch, loss=1.16, accuracy=0.744, val_loss=1.92, val_accuracy=0.471, lr=0.1]    22%|██▏       | 17/78 [06:25<21:31, 21.17s/epoch, loss=1.16, accuracy=0.748, val_loss=1.65, val_accuracy=0.567, lr=0.1] 23%|██▎       | 18/78 [06:46<21:06, 21.11s/epoch, loss=1.15, accuracy=0.748, val_loss=1.91, val_accuracy=0.51, lr=0.1]  24%|██▍       | 19/78 [07:07<20:46, 21.12s/epoch, loss=1.14, accuracy=0.749, val_loss=1.68, val_accuracy=0.58, lr=0.1] 26%|██▌       | 20/78 [07:28<20:31, 21.24s/epoch, loss=1.15, accuracy=0.749, val_loss=3.96, val_accuracy=0.303, lr=0.0316] 27%|██▋       | 21/78 [07:49<20:09, 21.21s/epoch, loss=1.15, accuracy=0.749, val_loss=1.65, val_accuracy=0.575, lr=0.1]    28%|██▊       | 22/78 [08:11<19:46, 21.19s/epoch, loss=1.14, accuracy=0.752, val_loss=1.7, val_accuracy=0.543, lr=0.1]  29%|██▉       | 23/78 [08:32<19:37, 21.41s/epoch, loss=1.15, accuracy=0.75, val_loss=1.5, val_accuracy=0.616, lr=0.1]  31%|███       | 24/78 [08:54<19:12, 21.34s/epoch, loss=1.14, accuracy=0.754, val_loss=1.4, val_accuracy=0.657, lr=0.1] 32%|███▏      | 25/78 [09:15<18:48, 21.28s/epoch, loss=1.15, accuracy=0.753, val_loss=1.64, val_accuracy=0.576, lr=0.1] 33%|███▎      | 26/78 [09:36<18:23, 21.22s/epoch, loss=1.14, accuracy=0.753, val_loss=2.19, val_accuracy=0.419, lr=0.1] 35%|███▍      | 27/78 [09:58<18:14, 21.47s/epoch, loss=1.13, accuracy=0.753, val_loss=1.37, val_accuracy=0.673, lr=0.1] 36%|███▌      | 28/78 [10:19<17:47, 21.35s/epoch, loss=1.13, accuracy=0.755, val_loss=2.06, val_accuracy=0.484, lr=0.1] 37%|███▋      | 29/78 [10:40<17:21, 21.25s/epoch, loss=1.13, accuracy=0.755, val_loss=2.05, val_accuracy=0.493, lr=0.1] 38%|███▊      | 30/78 [11:01<16:56, 21.17s/epoch, loss=1.13, accuracy=0.755, val_loss=1.85, val_accuracy=0.503, lr=0.1] 40%|███▉      | 31/78 [11:22<16:31, 21.09s/epoch, loss=1.13, accuracy=0.755, val_loss=1.63, val_accuracy=0.568, lr=0.1] 41%|████      | 32/78 [11:43<16:07, 21.04s/epoch, loss=1.13, accuracy=0.754, val_loss=3.37, val_accuracy=0.265, lr=0.0316] 42%|████▏     | 33/78 [12:04<15:44, 20.99s/epoch, loss=1.13, accuracy=0.755, val_loss=2.18, val_accuracy=0.517, lr=0.1]    44%|████▎     | 34/78 [12:25<15:29, 21.12s/epoch, loss=1.13, accuracy=0.758, val_loss=2.03, val_accuracy=0.411, lr=0.1] 45%|████▍     | 35/78 [12:46<15:07, 21.10s/epoch, loss=1.12, accuracy=0.756, val_loss=1.95, val_accuracy=0.514, lr=0.1] 46%|████▌     | 36/78 [13:07<14:48, 21.16s/epoch, loss=1.13, accuracy=0.756, val_loss=2.09, val_accuracy=0.431, lr=0.1] 47%|████▋     | 37/78 [13:28<14:24, 21.08s/epoch, loss=1.12, accuracy=0.754, val_loss=3.65, val_accuracy=0.329, lr=0.0316] 49%|████▊     | 38/78 [13:50<14:06, 21.17s/epoch, loss=1.12, accuracy=0.757, val_loss=6.57, val_accuracy=0.158, lr=0.1]    50%|█████     | 39/78 [14:11<13:48, 21.24s/epoch, loss=1.12, accuracy=0.756, val_loss=2.99, val_accuracy=0.232, lr=0.1] 51%|█████▏    | 40/78 [14:32<13:23, 21.15s/epoch, loss=1.12, accuracy=0.758, val_loss=2.17, val_accuracy=0.426, lr=0.1] 53%|█████▎    | 41/78 [14:53<13:01, 21.12s/epoch, loss=1.12, accuracy=0.756, val_loss=3.03, val_accuracy=0.363, lr=0.1] 54%|█████▍    | 42/78 [15:14<12:38, 21.08s/epoch, loss=1.12, accuracy=0.759, val_loss=1.54, val_accuracy=0.609, lr=0.0316] 55%|█████▌    | 43/78 [15:35<12:21, 21.18s/epoch, loss=1.12, accuracy=0.758, val_loss=2.05, val_accuracy=0.491, lr=0.1]    56%|█████▋    | 44/78 [15:56<11:58, 21.12s/epoch, loss=1.12, accuracy=0.756, val_loss=2.56, val_accuracy=0.336, lr=0.1] 58%|█████▊    | 45/78 [16:18<11:40, 21.23s/epoch, loss=1.13, accuracy=0.758, val_loss=2, val_accuracy=0.496, lr=0.1]    59%|█████▉    | 46/78 [16:39<11:17, 21.17s/epoch, loss=1.11, accuracy=0.759, val_loss=1.62, val_accuracy=0.614, lr=0.1] 60%|██████    | 47/78 [17:01<11:05, 21.46s/epoch, loss=1.11, accuracy=0.762, val_loss=1.59, val_accuracy=0.6, lr=0.0316] 62%|██████▏   | 48/78 [17:22<10:40, 21.35s/epoch, loss=1.11, accuracy=0.759, val_loss=1.48, val_accuracy=0.626, lr=0.1]  63%|██████▎   | 49/78 [17:44<10:20, 21.39s/epoch, loss=1.12, accuracy=0.757, val_loss=1.68, val_accuracy=0.589, lr=0.1] 64%|██████▍   | 50/78 [18:05<09:58, 21.37s/epoch, loss=1.11, accuracy=0.757, val_loss=1.82, val_accuracy=0.523, lr=0.1] 65%|██████▌   | 51/78 [18:26<09:33, 21.25s/epoch, loss=1.11, accuracy=0.758, val_loss=1.71, val_accuracy=0.564, lr=0.1] 67%|██████▋   | 52/78 [18:47<09:10, 21.16s/epoch, loss=1.12, accuracy=0.756, val_loss=1.77, val_accuracy=0.566, lr=0.0316] 68%|██████▊   | 53/78 [19:08<08:50, 21.22s/epoch, loss=1.12, accuracy=0.756, val_loss=1.84, val_accuracy=0.554, lr=0.1]    69%|██████▉   | 54/78 [19:29<08:28, 21.18s/epoch, loss=1.11, accuracy=0.759, val_loss=1.76, val_accuracy=0.533, lr=0.1] 71%|███████   | 55/78 [19:50<08:06, 21.16s/epoch, loss=1.11, accuracy=0.758, val_loss=2.83, val_accuracy=0.335, lr=0.1] 72%|███████▏  | 56/78 [20:12<07:46, 21.20s/epoch, loss=1.11, accuracy=0.757, val_loss=2.5, val_accuracy=0.329, lr=0.1]  73%|███████▎  | 57/78 [20:33<07:24, 21.18s/epoch, loss=1.11, accuracy=0.759, val_loss=1.6, val_accuracy=0.59, lr=0.0316] 74%|███████▍  | 58/78 [20:54<07:03, 21.19s/epoch, loss=1.11, accuracy=0.76, val_loss=1.79, val_accuracy=0.54, lr=0.1]    76%|███████▌  | 59/78 [21:16<06:44, 21.28s/epoch, loss=1.11, accuracy=0.761, val_loss=2.61, val_accuracy=0.424, lr=0.1] 77%|███████▋  | 60/78 [21:37<06:25, 21.41s/epoch, loss=1.11, accuracy=0.762, val_loss=2.65, val_accuracy=0.373, lr=0.1] 78%|███████▊  | 61/78 [21:58<06:02, 21.29s/epoch, loss=1.1, accuracy=0.76, val_loss=2.01, val_accuracy=0.477, lr=0.1]   79%|███████▉  | 62/78 [22:19<05:39, 21.23s/epoch, loss=1.11, accuracy=0.757, val_loss=2.36, val_accuracy=0.461, lr=0.0316] 81%|████████  | 63/78 [22:40<05:17, 21.15s/epoch, loss=1.11, accuracy=0.761, val_loss=3.22, val_accuracy=0.369, lr=0.1]    82%|████████▏ | 64/78 [23:02<04:57, 21.26s/epoch, loss=1.11, accuracy=0.76, val_loss=1.42, val_accuracy=0.65, lr=0.1]   83%|████████▎ | 65/78 [23:23<04:35, 21.18s/epoch, loss=1.11, accuracy=0.758, val_loss=2.48, val_accuracy=0.488, lr=0.1] 85%|████████▍ | 66/78 [23:44<04:13, 21.10s/epoch, loss=1.11, accuracy=0.76, val_loss=2.01, val_accuracy=0.461, lr=0.1]  86%|████████▌ | 67/78 [24:05<03:51, 21.07s/epoch, loss=1.1, accuracy=0.76, val_loss=3.59, val_accuracy=0.388, lr=0.0316] 87%|████████▋ | 68/78 [24:26<03:30, 21.01s/epoch, loss=1.1, accuracy=0.76, val_loss=3.56, val_accuracy=0.319, lr=0.1]    88%|████████▊ | 69/78 [24:47<03:09, 21.00s/epoch, loss=1.1, accuracy=0.76, val_loss=2.84, val_accuracy=0.385, lr=0.1] 90%|████████▉ | 70/78 [25:08<02:47, 20.98s/epoch, loss=1.11, accuracy=0.76, val_loss=1.5, val_accuracy=0.616, lr=0.1] 91%|█████████ | 71/78 [25:29<02:26, 21.00s/epoch, loss=1.11, accuracy=0.759, val_loss=2.58, val_accuracy=0.325, lr=0.1] 92%|█████████▏| 72/78 [25:50<02:05, 20.99s/epoch, loss=1.11, accuracy=0.759, val_loss=1.58, val_accuracy=0.597, lr=0.0316] 94%|█████████▎| 73/78 [26:11<01:45, 21.00s/epoch, loss=1.11, accuracy=0.76, val_loss=1.4, val_accuracy=0.662, lr=0.1]      95%|█████████▍| 74/78 [26:32<01:24, 21.03s/epoch, loss=1.1, accuracy=0.759, val_loss=2.51, val_accuracy=0.46, lr=0.1] 96%|█████████▌| 75/78 [26:53<01:03, 21.15s/epoch, loss=1.1, accuracy=0.76, val_loss=1.9, val_accuracy=0.485, lr=0.1]  97%|█████████▋| 76/78 [27:14<00:42, 21.14s/epoch, loss=1.11, accuracy=0.76, val_loss=1.77, val_accuracy=0.547, lr=0.1] 99%|█████████▊| 77/78 [27:36<00:21, 21.17s/epoch, loss=1.1, accuracy=0.76, val_loss=2.26, val_accuracy=0.448, lr=0.0316]100%|██████████| 78/78 [27:57<00:00, 21.33s/epoch, loss=1.11, accuracy=0.758, val_loss=1.9, val_accuracy=0.504, lr=0.1]  100%|██████████| 78/78 [27:57<00:00, 21.51s/epoch, loss=1.11, accuracy=0.758, val_loss=1.9, val_accuracy=0.504, lr=0.1]
Using real-time data augmentation.
Test score: 1.895331621170044
Test accuracy: 0.5037000179290771


* * * Run SGD for ID = 19_5. * * *


2024-03-05 12:53:50.145144: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 12:53:52.840017: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 12:53:52.841003: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-05 12:53:52.878867: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-05 12:53:52.878900: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 12:53:52.881530: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 12:53:52.881570: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 12:53:52.883646: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 12:53:52.884478: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 12:53:52.886813: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 12:53:52.888220: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 12:53:52.892538: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 12:53:52.893047: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 12:53:52.893132: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 12:53:54.102844: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-05 12:53:54.103323: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 12:53:54.104114: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-05 12:53:54.104178: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 12:53:54.104214: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 12:53:54.104231: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 12:53:54.104248: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 12:53:54.104273: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 12:53:54.104290: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 12:53:54.104305: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 12:53:54.104321: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 12:53:54.104742: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 12:53:54.104781: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 12:53:54.732057: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-05 12:53:54.732115: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-05 12:53:54.732124: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-05 12:53:54.732976: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:03:00.0, compute capability: 6.1)
{'id': '19_05', 'seed': 5, 'out_folder': 'results/epoch_budget', 'batch_size': 128, 'epochs': 78, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'bootstrapping': False, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/78 [00:00<?, ?epoch/s]2024-03-05 12:53:55.548450: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-05 12:53:55.548895: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199945000 Hz
2024-03-05 12:53:57.497723: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 12:53:57.710323: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 12:53:58.530009: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-05 12:53:58.571218: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|▏         | 1/78 [00:49<1:03:21, 49.37s/epoch, loss=3, accuracy=0.327, val_loss=2.47, val_accuracy=0.297, lr=0.1]  3%|▎         | 2/78 [01:10<41:35, 32.84s/epoch, loss=1.49, accuracy=0.573, val_loss=2.03, val_accuracy=0.459, lr=0.1]  4%|▍         | 3/78 [01:31<34:26, 27.55s/epoch, loss=1.31, accuracy=0.654, val_loss=1.93, val_accuracy=0.511, lr=0.1]  5%|▌         | 4/78 [01:53<30:54, 25.06s/epoch, loss=1.26, accuracy=0.691, val_loss=1.59, val_accuracy=0.573, lr=0.1]  6%|▋         | 5/78 [02:14<28:47, 23.67s/epoch, loss=1.24, accuracy=0.707, val_loss=1.57, val_accuracy=0.594, lr=0.1]  8%|▊         | 6/78 [02:35<27:17, 22.75s/epoch, loss=1.23, accuracy=0.716, val_loss=2.43, val_accuracy=0.386, lr=0.1]  9%|▉         | 7/78 [02:56<26:23, 22.30s/epoch, loss=1.22, accuracy=0.721, val_loss=1.8, val_accuracy=0.53, lr=0.1]   10%|█         | 8/78 [03:17<25:32, 21.90s/epoch, loss=1.21, accuracy=0.728, val_loss=1.74, val_accuracy=0.535, lr=0.1] 12%|█▏        | 9/78 [03:39<24:58, 21.72s/epoch, loss=1.2, accuracy=0.728, val_loss=2.82, val_accuracy=0.398, lr=0.1]  13%|█▎        | 10/78 [04:00<24:24, 21.53s/epoch, loss=1.2, accuracy=0.73, val_loss=1.78, val_accuracy=0.572, lr=0.0316] 14%|█▍        | 11/78 [04:21<23:52, 21.37s/epoch, loss=1.19, accuracy=0.734, val_loss=1.66, val_accuracy=0.58, lr=0.1]   15%|█▌        | 12/78 [04:42<23:24, 21.29s/epoch, loss=1.19, accuracy=0.735, val_loss=1.91, val_accuracy=0.473, lr=0.1] 17%|█▋        | 13/78 [05:03<22:57, 21.19s/epoch, loss=1.19, accuracy=0.735, val_loss=1.53, val_accuracy=0.614, lr=0.1] 18%|█▊        | 14/78 [05:24<22:36, 21.20s/epoch, loss=1.18, accuracy=0.738, val_loss=3.48, val_accuracy=0.326, lr=0.1] 19%|█▉        | 15/78 [05:45<22:11, 21.14s/epoch, loss=1.18, accuracy=0.741, val_loss=1.44, val_accuracy=0.655, lr=0.1] 21%|██        | 16/78 [06:06<21:50, 21.14s/epoch, loss=1.17, accuracy=0.743, val_loss=1.79, val_accuracy=0.583, lr=0.1] 22%|██▏       | 17/78 [06:27<21:27, 21.10s/epoch, loss=1.17, accuracy=0.744, val_loss=2.92, val_accuracy=0.437, lr=0.1] 23%|██▎       | 18/78 [06:48<21:04, 21.07s/epoch, loss=1.17, accuracy=0.746, val_loss=2.15, val_accuracy=0.453, lr=0.1] 24%|██▍       | 19/78 [07:09<20:42, 21.06s/epoch, loss=1.16, accuracy=0.744, val_loss=2.02, val_accuracy=0.455, lr=0.1] 26%|██▌       | 20/78 [07:30<20:22, 21.08s/epoch, loss=1.17, accuracy=0.745, val_loss=2.16, val_accuracy=0.449, lr=0.0316] 27%|██▋       | 21/78 [07:52<20:04, 21.14s/epoch, loss=1.17, accuracy=0.745, val_loss=1.83, val_accuracy=0.558, lr=0.1]    28%|██▊       | 22/78 [08:13<19:44, 21.15s/epoch, loss=1.17, accuracy=0.746, val_loss=2.53, val_accuracy=0.391, lr=0.1] 29%|██▉       | 23/78 [08:34<19:24, 21.17s/epoch, loss=1.16, accuracy=0.748, val_loss=1.39, val_accuracy=0.672, lr=0.1] 31%|███       | 24/78 [08:56<19:11, 21.33s/epoch, loss=1.16, accuracy=0.748, val_loss=1.94, val_accuracy=0.519, lr=0.1] 32%|███▏      | 25/78 [09:17<18:47, 21.28s/epoch, loss=1.16, accuracy=0.748, val_loss=1.54, val_accuracy=0.635, lr=0.1] 33%|███▎      | 26/78 [09:38<18:25, 21.26s/epoch, loss=1.15, accuracy=0.749, val_loss=1.98, val_accuracy=0.52, lr=0.1]  35%|███▍      | 27/78 [09:59<18:04, 21.27s/epoch, loss=1.15, accuracy=0.749, val_loss=1.81, val_accuracy=0.567, lr=0.1] 36%|███▌      | 28/78 [10:20<17:40, 21.21s/epoch, loss=1.15, accuracy=0.75, val_loss=1.86, val_accuracy=0.529, lr=0.0316] 37%|███▋      | 29/78 [10:42<17:18, 21.19s/epoch, loss=1.14, accuracy=0.751, val_loss=2.19, val_accuracy=0.531, lr=0.1]   38%|███▊      | 30/78 [11:03<16:55, 21.15s/epoch, loss=1.14, accuracy=0.752, val_loss=1.7, val_accuracy=0.549, lr=0.1]  40%|███▉      | 31/78 [11:24<16:32, 21.12s/epoch, loss=1.14, accuracy=0.753, val_loss=2.49, val_accuracy=0.393, lr=0.1] 41%|████      | 32/78 [11:45<16:11, 21.11s/epoch, loss=1.14, accuracy=0.755, val_loss=1.7, val_accuracy=0.57, lr=0.1]   42%|████▏     | 33/78 [12:06<15:54, 21.21s/epoch, loss=1.14, accuracy=0.752, val_loss=2.02, val_accuracy=0.514, lr=0.0316] 44%|████▎     | 34/78 [12:27<15:31, 21.17s/epoch, loss=1.14, accuracy=0.752, val_loss=1.79, val_accuracy=0.52, lr=0.1]     45%|████▍     | 35/78 [12:48<15:07, 21.11s/epoch, loss=1.14, accuracy=0.754, val_loss=2.04, val_accuracy=0.416, lr=0.1] 46%|████▌     | 36/78 [13:09<14:48, 21.16s/epoch, loss=1.13, accuracy=0.753, val_loss=2.47, val_accuracy=0.51, lr=0.1]  47%|████▋     | 37/78 [13:30<14:24, 21.08s/epoch, loss=1.13, accuracy=0.757, val_loss=1.97, val_accuracy=0.486, lr=0.1] 49%|████▊     | 38/78 [13:51<14:01, 21.04s/epoch, loss=1.13, accuracy=0.755, val_loss=2.34, val_accuracy=0.433, lr=0.0316] 50%|█████     | 39/78 [14:12<13:38, 20.99s/epoch, loss=1.13, accuracy=0.756, val_loss=1.8, val_accuracy=0.551, lr=0.1]     51%|█████▏    | 40/78 [14:33<13:17, 20.99s/epoch, loss=1.13, accuracy=0.754, val_loss=1.48, val_accuracy=0.638, lr=0.1] 53%|█████▎    | 41/78 [14:55<13:01, 21.11s/epoch, loss=1.13, accuracy=0.755, val_loss=1.93, val_accuracy=0.495, lr=0.1] 54%|█████▍    | 42/78 [15:16<12:40, 21.12s/epoch, loss=1.13, accuracy=0.755, val_loss=5.99, val_accuracy=0.182, lr=0.1] 55%|█████▌    | 43/78 [15:37<12:17, 21.06s/epoch, loss=1.13, accuracy=0.754, val_loss=1.96, val_accuracy=0.469, lr=0.0316] 56%|█████▋    | 44/78 [15:58<12:02, 21.24s/epoch, loss=1.13, accuracy=0.757, val_loss=1.9, val_accuracy=0.511, lr=0.1]     58%|█████▊    | 45/78 [16:19<11:39, 21.19s/epoch, loss=1.13, accuracy=0.756, val_loss=1.67, val_accuracy=0.564, lr=0.1] 59%|█████▉    | 46/78 [16:41<11:17, 21.17s/epoch, loss=1.12, accuracy=0.759, val_loss=1.49, val_accuracy=0.628, lr=0.1] 60%|██████    | 47/78 [17:02<10:58, 21.24s/epoch, loss=1.12, accuracy=0.757, val_loss=1.72, val_accuracy=0.572, lr=0.1] 62%|██████▏   | 48/78 [17:23<10:34, 21.14s/epoch, loss=1.12, accuracy=0.757, val_loss=1.9, val_accuracy=0.587, lr=0.0316] 63%|██████▎   | 49/78 [17:44<10:11, 21.10s/epoch, loss=1.12, accuracy=0.756, val_loss=1.97, val_accuracy=0.537, lr=0.1]   64%|██████▍   | 50/78 [18:05<09:53, 21.21s/epoch, loss=1.11, accuracy=0.757, val_loss=2.34, val_accuracy=0.441, lr=0.1] 65%|██████▌   | 51/78 [18:26<09:30, 21.11s/epoch, loss=1.11, accuracy=0.759, val_loss=2.1, val_accuracy=0.443, lr=0.1]  67%|██████▋   | 52/78 [18:47<09:05, 20.98s/epoch, loss=1.11, accuracy=0.757, val_loss=1.75, val_accuracy=0.572, lr=0.1] 68%|██████▊   | 53/78 [19:08<08:44, 20.97s/epoch, loss=1.11, accuracy=0.76, val_loss=1.73, val_accuracy=0.553, lr=0.0316] 69%|██████▉   | 54/78 [19:29<08:23, 20.96s/epoch, loss=1.11, accuracy=0.759, val_loss=1.79, val_accuracy=0.578, lr=0.1]   71%|███████   | 55/78 [19:50<08:05, 21.09s/epoch, loss=1.11, accuracy=0.759, val_loss=1.45, val_accuracy=0.641, lr=0.1] 72%|███████▏  | 56/78 [20:11<07:42, 21.03s/epoch, loss=1.11, accuracy=0.759, val_loss=2.42, val_accuracy=0.417, lr=0.1] 73%|███████▎  | 57/78 [20:32<07:21, 21.04s/epoch, loss=1.11, accuracy=0.758, val_loss=1.63, val_accuracy=0.577, lr=0.1] 74%|███████▍  | 58/78 [20:53<07:02, 21.11s/epoch, loss=1.11, accuracy=0.757, val_loss=2.14, val_accuracy=0.441, lr=0.0316] 76%|███████▌  | 59/78 [21:14<06:39, 21.02s/epoch, loss=1.11, accuracy=0.759, val_loss=2.7, val_accuracy=0.401, lr=0.1]     77%|███████▋  | 60/78 [21:35<06:17, 20.98s/epoch, loss=1.11, accuracy=0.76, val_loss=2.5, val_accuracy=0.411, lr=0.1]  78%|███████▊  | 61/78 [21:56<05:57, 21.02s/epoch, loss=1.1, accuracy=0.758, val_loss=1.72, val_accuracy=0.566, lr=0.1] 79%|███████▉  | 62/78 [22:17<05:35, 20.99s/epoch, loss=1.11, accuracy=0.757, val_loss=2.28, val_accuracy=0.461, lr=0.1] 81%|████████  | 63/78 [22:39<05:18, 21.21s/epoch, loss=1.11, accuracy=0.757, val_loss=1.81, val_accuracy=0.534, lr=0.0316] 82%|████████▏ | 64/78 [23:00<04:55, 21.10s/epoch, loss=1.11, accuracy=0.758, val_loss=1.6, val_accuracy=0.585, lr=0.1]     83%|████████▎ | 65/78 [23:20<04:33, 21.01s/epoch, loss=1.1, accuracy=0.759, val_loss=1.62, val_accuracy=0.609, lr=0.1] 85%|████████▍ | 66/78 [23:41<04:11, 20.96s/epoch, loss=1.11, accuracy=0.757, val_loss=2.55, val_accuracy=0.451, lr=0.1] 86%|████████▌ | 67/78 [24:02<03:50, 20.93s/epoch, loss=1.11, accuracy=0.758, val_loss=1.66, val_accuracy=0.559, lr=0.1] 87%|████████▋ | 68/78 [24:23<03:29, 20.91s/epoch, loss=1.1, accuracy=0.761, val_loss=1.69, val_accuracy=0.583, lr=0.0316] 88%|████████▊ | 69/78 [24:44<03:07, 20.87s/epoch, loss=1.1, accuracy=0.759, val_loss=3.29, val_accuracy=0.386, lr=0.1]    90%|████████▉ | 70/78 [25:05<02:47, 20.90s/epoch, loss=1.11, accuracy=0.757, val_loss=2.01, val_accuracy=0.483, lr=0.1] 91%|█████████ | 71/78 [25:26<02:26, 20.97s/epoch, loss=1.1, accuracy=0.76, val_loss=3.51, val_accuracy=0.34, lr=0.1]    92%|█████████▏| 72/78 [25:47<02:06, 21.04s/epoch, loss=1.11, accuracy=0.757, val_loss=3.05, val_accuracy=0.308, lr=0.1] 94%|█████████▎| 73/78 [26:09<01:46, 21.24s/epoch, loss=1.1, accuracy=0.758, val_loss=1.75, val_accuracy=0.591, lr=0.0316] 95%|█████████▍| 74/78 [26:30<01:24, 21.13s/epoch, loss=1.1, accuracy=0.758, val_loss=1.89, val_accuracy=0.518, lr=0.1]    96%|█████████▌| 75/78 [26:51<01:03, 21.09s/epoch, loss=1.11, accuracy=0.759, val_loss=1.94, val_accuracy=0.558, lr=0.1] 97%|█████████▋| 76/78 [27:12<00:42, 21.24s/epoch, loss=1.1, accuracy=0.759, val_loss=3.47, val_accuracy=0.363, lr=0.1]  99%|█████████▊| 77/78 [27:33<00:21, 21.17s/epoch, loss=1.11, accuracy=0.756, val_loss=2.06, val_accuracy=0.508, lr=0.1]100%|██████████| 78/78 [27:55<00:00, 21.27s/epoch, loss=1.11, accuracy=0.759, val_loss=2.15, val_accuracy=0.413, lr=0.0316]100%|██████████| 78/78 [27:55<00:00, 21.48s/epoch, loss=1.11, accuracy=0.759, val_loss=2.15, val_accuracy=0.413, lr=0.0316]
Using real-time data augmentation.
Test score: 2.1503188610076904
Test accuracy: 0.41269999742507935


* * * Run SGD for ID = 19_6. * * *


2024-03-05 13:21:54.520326: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 13:21:57.516056: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 13:21:57.517049: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-05 13:21:57.553852: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-05 13:21:57.553884: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 13:21:57.556530: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 13:21:57.556570: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 13:21:57.558572: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 13:21:57.559228: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 13:21:57.561758: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 13:21:57.563182: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 13:21:57.567552: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 13:21:57.568046: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 13:21:57.568136: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 13:21:58.778372: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-05 13:21:58.779350: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 13:21:58.780094: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-05 13:21:58.780127: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 13:21:58.780163: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 13:21:58.780180: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 13:21:58.780198: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 13:21:58.780216: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 13:21:58.780233: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 13:21:58.780249: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 13:21:58.780265: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 13:21:58.780683: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 13:21:58.780720: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 13:21:59.398318: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-05 13:21:59.398375: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-05 13:21:59.398385: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-05 13:21:59.399247: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:03:00.0, compute capability: 6.1)
{'id': '19_06', 'seed': 6, 'out_folder': 'results/epoch_budget', 'batch_size': 128, 'epochs': 78, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'bootstrapping': False, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/78 [00:00<?, ?epoch/s]2024-03-05 13:22:00.227049: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-05 13:22:00.227549: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199945000 Hz
2024-03-05 13:22:02.203613: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 13:22:02.414942: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 13:22:03.157636: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-05 13:22:03.208421: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|▏         | 1/78 [00:46<59:47, 46.60s/epoch, loss=3.12, accuracy=0.335, val_loss=2.08, val_accuracy=0.323, lr=0.1]  3%|▎         | 2/78 [01:08<40:31, 32.00s/epoch, loss=1.63, accuracy=0.495, val_loss=2.04, val_accuracy=0.368, lr=0.1]  4%|▍         | 3/78 [01:29<34:01, 27.22s/epoch, loss=1.39, accuracy=0.609, val_loss=2.57, val_accuracy=0.285, lr=0.1]  5%|▌         | 4/78 [01:51<30:53, 25.04s/epoch, loss=1.28, accuracy=0.67, val_loss=6.45, val_accuracy=0.278, lr=0.1]   6%|▋         | 5/78 [02:12<28:50, 23.71s/epoch, loss=1.25, accuracy=0.692, val_loss=2.39, val_accuracy=0.354, lr=0.1]  8%|▊         | 6/78 [02:34<27:29, 22.91s/epoch, loss=1.24, accuracy=0.706, val_loss=2.26, val_accuracy=0.389, lr=0.1]  9%|▉         | 7/78 [02:55<26:34, 22.46s/epoch, loss=1.23, accuracy=0.716, val_loss=2.45, val_accuracy=0.247, lr=0.0316] 10%|█         | 8/78 [03:17<25:54, 22.21s/epoch, loss=1.22, accuracy=0.72, val_loss=5.15, val_accuracy=0.197, lr=0.1]     12%|█▏        | 9/78 [03:39<25:18, 22.00s/epoch, loss=1.21, accuracy=0.727, val_loss=2.28, val_accuracy=0.382, lr=0.1] 13%|█▎        | 10/78 [04:00<24:52, 21.95s/epoch, loss=1.21, accuracy=0.728, val_loss=2.84, val_accuracy=0.376, lr=0.1] 14%|█▍        | 11/78 [04:22<24:18, 21.76s/epoch, loss=1.21, accuracy=0.73, val_loss=1.45, val_accuracy=0.65, lr=0.1]   15%|█▌        | 12/78 [04:43<23:46, 21.62s/epoch, loss=1.2, accuracy=0.735, val_loss=1.56, val_accuracy=0.605, lr=0.1] 17%|█▋        | 13/78 [05:04<23:18, 21.52s/epoch, loss=1.2, accuracy=0.736, val_loss=2.15, val_accuracy=0.488, lr=0.1] 18%|█▊        | 14/78 [05:26<22:56, 21.51s/epoch, loss=1.2, accuracy=0.739, val_loss=2.29, val_accuracy=0.392, lr=0.1] 19%|█▉        | 15/78 [05:48<22:43, 21.64s/epoch, loss=1.2, accuracy=0.737, val_loss=1.67, val_accuracy=0.584, lr=0.1] 21%|██        | 16/78 [06:09<22:14, 21.53s/epoch, loss=1.2, accuracy=0.737, val_loss=4.58, val_accuracy=0.21, lr=0.0316] 22%|██▏       | 17/78 [06:30<21:49, 21.46s/epoch, loss=1.19, accuracy=0.738, val_loss=2.38, val_accuracy=0.481, lr=0.1]  23%|██▎       | 18/78 [06:52<21:24, 21.41s/epoch, loss=1.18, accuracy=0.74, val_loss=2.02, val_accuracy=0.466, lr=0.1]  24%|██▍       | 19/78 [07:13<21:02, 21.39s/epoch, loss=1.19, accuracy=0.742, val_loss=1.49, val_accuracy=0.63, lr=0.1] 26%|██▌       | 20/78 [07:35<20:47, 21.51s/epoch, loss=1.19, accuracy=0.742, val_loss=2.25, val_accuracy=0.46, lr=0.1] 27%|██▋       | 21/78 [07:56<20:25, 21.50s/epoch, loss=1.18, accuracy=0.741, val_loss=1.45, val_accuracy=0.654, lr=0.1] 28%|██▊       | 22/78 [08:18<20:03, 21.50s/epoch, loss=1.18, accuracy=0.742, val_loss=3.29, val_accuracy=0.307, lr=0.1] 29%|██▉       | 23/78 [08:39<19:40, 21.47s/epoch, loss=1.19, accuracy=0.743, val_loss=1.79, val_accuracy=0.537, lr=0.1] 31%|███       | 24/78 [09:01<19:20, 21.49s/epoch, loss=1.18, accuracy=0.745, val_loss=1.67, val_accuracy=0.577, lr=0.1] 32%|███▏      | 25/78 [09:22<18:57, 21.47s/epoch, loss=1.18, accuracy=0.743, val_loss=2.34, val_accuracy=0.421, lr=0.1] 33%|███▎      | 26/78 [09:43<18:34, 21.43s/epoch, loss=1.18, accuracy=0.744, val_loss=2.48, val_accuracy=0.385, lr=0.0316] 35%|███▍      | 27/78 [10:05<18:13, 21.44s/epoch, loss=1.17, accuracy=0.746, val_loss=5.4, val_accuracy=0.265, lr=0.1]     36%|███▌      | 28/78 [10:27<17:55, 21.51s/epoch, loss=1.18, accuracy=0.745, val_loss=2.01, val_accuracy=0.55, lr=0.1] 37%|███▋      | 29/78 [10:48<17:31, 21.46s/epoch, loss=1.17, accuracy=0.745, val_loss=1.9, val_accuracy=0.54, lr=0.1]  38%|███▊      | 30/78 [11:09<17:07, 21.41s/epoch, loss=1.17, accuracy=0.744, val_loss=2.29, val_accuracy=0.392, lr=0.1] 40%|███▉      | 31/78 [11:31<16:45, 21.38s/epoch, loss=1.17, accuracy=0.748, val_loss=3.62, val_accuracy=0.267, lr=0.0316] 41%|████      | 32/78 [11:52<16:25, 21.43s/epoch, loss=1.17, accuracy=0.748, val_loss=1.99, val_accuracy=0.508, lr=0.1]    42%|████▏     | 33/78 [12:13<16:04, 21.43s/epoch, loss=1.17, accuracy=0.749, val_loss=2.05, val_accuracy=0.501, lr=0.1] 44%|████▎     | 34/78 [12:35<15:46, 21.51s/epoch, loss=1.17, accuracy=0.749, val_loss=2.09, val_accuracy=0.496, lr=0.1] 45%|████▍     | 35/78 [12:57<15:28, 21.59s/epoch, loss=1.18, accuracy=0.746, val_loss=2.39, val_accuracy=0.425, lr=0.1] 46%|████▌     | 36/78 [13:18<15:03, 21.52s/epoch, loss=1.17, accuracy=0.748, val_loss=1.65, val_accuracy=0.556, lr=0.0316] 47%|████▋     | 37/78 [13:40<14:38, 21.43s/epoch, loss=1.16, accuracy=0.749, val_loss=1.71, val_accuracy=0.586, lr=0.1]    49%|████▊     | 38/78 [14:01<14:20, 21.52s/epoch, loss=1.16, accuracy=0.749, val_loss=2.8, val_accuracy=0.325, lr=0.1]  50%|█████     | 39/78 [14:23<13:59, 21.53s/epoch, loss=1.16, accuracy=0.751, val_loss=1.8, val_accuracy=0.51, lr=0.1]  51%|█████▏    | 40/78 [14:44<13:34, 21.44s/epoch, loss=1.16, accuracy=0.748, val_loss=2.69, val_accuracy=0.384, lr=0.1] 53%|█████▎    | 41/78 [15:05<13:12, 21.41s/epoch, loss=1.16, accuracy=0.751, val_loss=2.05, val_accuracy=0.502, lr=0.0316] 54%|█████▍    | 42/78 [15:27<12:48, 21.33s/epoch, loss=1.16, accuracy=0.75, val_loss=2.04, val_accuracy=0.501, lr=0.1]     55%|█████▌    | 43/78 [15:48<12:28, 21.39s/epoch, loss=1.16, accuracy=0.749, val_loss=2.45, val_accuracy=0.395, lr=0.1] 56%|█████▋    | 44/78 [16:09<12:06, 21.36s/epoch, loss=1.16, accuracy=0.752, val_loss=2.16, val_accuracy=0.422, lr=0.1] 58%|█████▊    | 45/78 [16:31<11:44, 21.34s/epoch, loss=1.17, accuracy=0.752, val_loss=2.17, val_accuracy=0.479, lr=0.1] 59%|█████▉    | 46/78 [16:53<11:28, 21.51s/epoch, loss=1.16, accuracy=0.75, val_loss=1.9, val_accuracy=0.549, lr=0.0316] 60%|██████    | 47/78 [17:14<11:09, 21.61s/epoch, loss=1.16, accuracy=0.753, val_loss=1.86, val_accuracy=0.482, lr=0.1]  62%|██████▏   | 48/78 [17:36<10:50, 21.68s/epoch, loss=1.15, accuracy=0.752, val_loss=1.54, val_accuracy=0.625, lr=0.1] 63%|██████▎   | 49/78 [17:58<10:25, 21.57s/epoch, loss=1.15, accuracy=0.752, val_loss=2.19, val_accuracy=0.465, lr=0.1] 64%|██████▍   | 50/78 [18:19<10:01, 21.50s/epoch, loss=1.16, accuracy=0.75, val_loss=2.06, val_accuracy=0.491, lr=0.1]  65%|██████▌   | 51/78 [18:41<09:42, 21.59s/epoch, loss=1.16, accuracy=0.752, val_loss=2.42, val_accuracy=0.442, lr=0.0316] 67%|██████▋   | 52/78 [19:02<09:18, 21.48s/epoch, loss=1.15, accuracy=0.753, val_loss=2, val_accuracy=0.552, lr=0.1]       68%|██████▊   | 53/78 [19:23<08:55, 21.44s/epoch, loss=1.15, accuracy=0.751, val_loss=1.62, val_accuracy=0.585, lr=0.1] 69%|██████▉   | 54/78 [19:45<08:38, 21.59s/epoch, loss=1.14, accuracy=0.754, val_loss=1.99, val_accuracy=0.5, lr=0.1]   71%|███████   | 55/78 [20:07<08:16, 21.58s/epoch, loss=1.15, accuracy=0.752, val_loss=1.87, val_accuracy=0.518, lr=0.1] 72%|███████▏  | 56/78 [20:28<07:54, 21.55s/epoch, loss=1.15, accuracy=0.753, val_loss=1.63, val_accuracy=0.608, lr=0.0316] 73%|███████▎  | 57/78 [20:50<07:30, 21.47s/epoch, loss=1.15, accuracy=0.754, val_loss=5.41, val_accuracy=0.214, lr=0.1]    74%|███████▍  | 58/78 [21:11<07:09, 21.45s/epoch, loss=1.15, accuracy=0.753, val_loss=3.1, val_accuracy=0.342, lr=0.1]  76%|███████▌  | 59/78 [21:32<06:47, 21.44s/epoch, loss=1.15, accuracy=0.755, val_loss=2.55, val_accuracy=0.479, lr=0.1] 77%|███████▋  | 60/78 [21:54<06:25, 21.42s/epoch, loss=1.15, accuracy=0.751, val_loss=1.63, val_accuracy=0.59, lr=0.1]  78%|███████▊  | 61/78 [22:15<06:04, 21.43s/epoch, loss=1.14, accuracy=0.752, val_loss=1.87, val_accuracy=0.537, lr=0.0316] 79%|███████▉  | 62/78 [22:37<05:44, 21.53s/epoch, loss=1.15, accuracy=0.753, val_loss=1.5, val_accuracy=0.63, lr=0.1]      81%|████████  | 63/78 [22:58<05:22, 21.47s/epoch, loss=1.15, accuracy=0.756, val_loss=2.08, val_accuracy=0.488, lr=0.1] 82%|████████▏ | 64/78 [23:20<04:59, 21.42s/epoch, loss=1.14, accuracy=0.754, val_loss=1.87, val_accuracy=0.54, lr=0.1]  83%|████████▎ | 65/78 [23:41<04:37, 21.38s/epoch, loss=1.14, accuracy=0.752, val_loss=1.55, val_accuracy=0.632, lr=0.1] 85%|████████▍ | 66/78 [24:02<04:15, 21.33s/epoch, loss=1.15, accuracy=0.753, val_loss=2.08, val_accuracy=0.451, lr=0.0316] 86%|████████▌ | 67/78 [24:23<03:54, 21.30s/epoch, loss=1.14, accuracy=0.756, val_loss=2.15, val_accuracy=0.478, lr=0.1]    87%|████████▋ | 68/78 [24:44<03:32, 21.27s/epoch, loss=1.15, accuracy=0.754, val_loss=2.57, val_accuracy=0.449, lr=0.1] 88%|████████▊ | 69/78 [25:06<03:11, 21.29s/epoch, loss=1.14, accuracy=0.756, val_loss=1.84, val_accuracy=0.511, lr=0.1] 90%|████████▉ | 70/78 [25:27<02:50, 21.29s/epoch, loss=1.15, accuracy=0.754, val_loss=1.76, val_accuracy=0.583, lr=0.1] 91%|█████████ | 71/78 [25:48<02:28, 21.23s/epoch, loss=1.15, accuracy=0.756, val_loss=1.86, val_accuracy=0.523, lr=0.0316] 92%|█████████▏| 72/78 [26:10<02:08, 21.36s/epoch, loss=1.14, accuracy=0.756, val_loss=2, val_accuracy=0.518, lr=0.1]       94%|█████████▎| 73/78 [26:31<01:46, 21.30s/epoch, loss=1.14, accuracy=0.756, val_loss=2.06, val_accuracy=0.494, lr=0.1] 95%|█████████▍| 74/78 [26:52<01:25, 21.27s/epoch, loss=1.15, accuracy=0.754, val_loss=2.12, val_accuracy=0.418, lr=0.1] 96%|█████████▌| 75/78 [27:14<01:04, 21.39s/epoch, loss=1.15, accuracy=0.756, val_loss=2.57, val_accuracy=0.362, lr=0.1] 97%|█████████▋| 76/78 [27:35<00:42, 21.44s/epoch, loss=1.14, accuracy=0.756, val_loss=1.72, val_accuracy=0.53, lr=0.0316] 99%|█████████▊| 77/78 [27:57<00:21, 21.38s/epoch, loss=1.14, accuracy=0.753, val_loss=1.66, val_accuracy=0.606, lr=0.1]  100%|██████████| 78/78 [28:19<00:00, 21.58s/epoch, loss=1.14, accuracy=0.753, val_loss=2.18, val_accuracy=0.481, lr=0.1]100%|██████████| 78/78 [28:19<00:00, 21.79s/epoch, loss=1.14, accuracy=0.753, val_loss=2.18, val_accuracy=0.481, lr=0.1]
Using real-time data augmentation.
Test score: 2.1845314502716064
Test accuracy: 0.4805999994277954


* * * Run SGD for ID = 19_7. * * *


2024-03-05 13:50:24.654616: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 13:50:41.414298: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 13:50:41.415282: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-05 13:50:41.455378: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-05 13:50:41.455409: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 13:50:41.460626: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 13:50:41.460667: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 13:50:41.464257: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 13:50:41.466597: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 13:50:41.470317: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 13:50:41.473524: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 13:50:41.479694: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 13:50:41.480212: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 13:50:41.480298: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 13:50:42.680752: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-05 13:50:42.681780: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 13:50:42.682234: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-05 13:50:42.682266: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 13:50:42.682298: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 13:50:42.682314: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 13:50:42.682330: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 13:50:42.682345: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 13:50:42.682361: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 13:50:42.682376: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 13:50:42.682392: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 13:50:42.684319: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 13:50:42.684357: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 13:50:43.316894: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-05 13:50:43.316950: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-05 13:50:43.316959: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-05 13:50:43.317808: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:03:00.0, compute capability: 6.1)
{'id': '19_07', 'seed': 7, 'out_folder': 'results/epoch_budget', 'batch_size': 128, 'epochs': 78, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'bootstrapping': False, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/78 [00:00<?, ?epoch/s]2024-03-05 13:50:44.132789: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-05 13:50:44.133198: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199945000 Hz
2024-03-05 13:50:46.081904: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 13:50:46.301177: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 13:50:47.079925: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-05 13:50:47.121189: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|▏         | 1/78 [00:54<1:09:34, 54.22s/epoch, loss=3.14, accuracy=0.326, val_loss=3.07, val_accuracy=0.181, lr=0.1]  3%|▎         | 2/78 [01:15<44:14, 34.92s/epoch, loss=1.51, accuracy=0.548, val_loss=2.09, val_accuracy=0.373, lr=0.1]    4%|▍         | 3/78 [01:36<35:46, 28.62s/epoch, loss=1.31, accuracy=0.653, val_loss=1.84, val_accuracy=0.495, lr=0.1]  5%|▌         | 4/78 [01:57<31:38, 25.66s/epoch, loss=1.24, accuracy=0.69, val_loss=1.5, val_accuracy=0.618, lr=0.1]    6%|▋         | 5/78 [02:18<29:10, 23.98s/epoch, loss=1.22, accuracy=0.707, val_loss=2.43, val_accuracy=0.414, lr=0.1]  8%|▊         | 6/78 [02:39<27:35, 23.00s/epoch, loss=1.21, accuracy=0.713, val_loss=1.68, val_accuracy=0.553, lr=0.1]  9%|▉         | 7/78 [03:00<26:26, 22.35s/epoch, loss=1.2, accuracy=0.721, val_loss=1.71, val_accuracy=0.54, lr=0.1]   10%|█         | 8/78 [03:21<25:33, 21.90s/epoch, loss=1.19, accuracy=0.728, val_loss=2.13, val_accuracy=0.512, lr=0.1] 12%|█▏        | 9/78 [03:43<24:56, 21.69s/epoch, loss=1.19, accuracy=0.73, val_loss=2.14, val_accuracy=0.387, lr=0.0316] 13%|█▎        | 10/78 [04:04<24:27, 21.58s/epoch, loss=1.18, accuracy=0.73, val_loss=1.71, val_accuracy=0.537, lr=0.1]   14%|█▍        | 11/78 [04:25<23:55, 21.42s/epoch, loss=1.18, accuracy=0.733, val_loss=4.06, val_accuracy=0.325, lr=0.1] 15%|█▌        | 12/78 [04:46<23:25, 21.30s/epoch, loss=1.18, accuracy=0.738, val_loss=4.07, val_accuracy=0.277, lr=0.1] 17%|█▋        | 13/78 [05:08<23:10, 21.40s/epoch, loss=1.17, accuracy=0.736, val_loss=2.25, val_accuracy=0.417, lr=0.1] 18%|█▊        | 14/78 [05:29<22:51, 21.42s/epoch, loss=1.16, accuracy=0.74, val_loss=3.51, val_accuracy=0.328, lr=0.0316] 19%|█▉        | 15/78 [05:50<22:20, 21.29s/epoch, loss=1.16, accuracy=0.741, val_loss=2.28, val_accuracy=0.444, lr=0.1]   21%|██        | 16/78 [06:11<21:56, 21.23s/epoch, loss=1.16, accuracy=0.741, val_loss=4.53, val_accuracy=0.356, lr=0.1] 22%|██▏       | 17/78 [06:32<21:31, 21.17s/epoch, loss=1.16, accuracy=0.743, val_loss=1.83, val_accuracy=0.548, lr=0.1] 23%|██▎       | 18/78 [06:53<21:06, 21.10s/epoch, loss=1.15, accuracy=0.745, val_loss=1.48, val_accuracy=0.639, lr=0.1] 24%|██▍       | 19/78 [07:15<20:49, 21.17s/epoch, loss=1.15, accuracy=0.745, val_loss=2.69, val_accuracy=0.407, lr=0.1] 26%|██▌       | 20/78 [07:36<20:27, 21.17s/epoch, loss=1.15, accuracy=0.745, val_loss=2.28, val_accuracy=0.493, lr=0.1] 27%|██▋       | 21/78 [07:57<20:06, 21.16s/epoch, loss=1.15, accuracy=0.746, val_loss=1.88, val_accuracy=0.478, lr=0.1] 28%|██▊       | 22/78 [08:18<19:45, 21.16s/epoch, loss=1.14, accuracy=0.748, val_loss=1.73, val_accuracy=0.553, lr=0.1] 29%|██▉       | 23/78 [08:39<19:23, 21.16s/epoch, loss=1.14, accuracy=0.748, val_loss=1.76, val_accuracy=0.551, lr=0.0316] 31%|███       | 24/78 [09:01<19:10, 21.30s/epoch, loss=1.14, accuracy=0.748, val_loss=2.03, val_accuracy=0.483, lr=0.1]    32%|███▏      | 25/78 [09:22<18:52, 21.37s/epoch, loss=1.14, accuracy=0.749, val_loss=2.06, val_accuracy=0.477, lr=0.1] 33%|███▎      | 26/78 [09:44<18:28, 21.31s/epoch, loss=1.15, accuracy=0.748, val_loss=3.82, val_accuracy=0.361, lr=0.1] 35%|███▍      | 27/78 [10:05<18:03, 21.25s/epoch, loss=1.13, accuracy=0.75, val_loss=2.47, val_accuracy=0.402, lr=0.1]  36%|███▌      | 28/78 [10:26<17:40, 21.21s/epoch, loss=1.13, accuracy=0.752, val_loss=1.56, val_accuracy=0.611, lr=0.0316] 37%|███▋      | 29/78 [10:47<17:16, 21.16s/epoch, loss=1.13, accuracy=0.751, val_loss=1.48, val_accuracy=0.637, lr=0.1]    38%|███▊      | 30/78 [11:08<16:54, 21.13s/epoch, loss=1.13, accuracy=0.749, val_loss=2.12, val_accuracy=0.526, lr=0.1] 40%|███▉      | 31/78 [11:29<16:31, 21.10s/epoch, loss=1.13, accuracy=0.751, val_loss=2, val_accuracy=0.51, lr=0.1]     41%|████      | 32/78 [11:50<16:09, 21.09s/epoch, loss=1.13, accuracy=0.752, val_loss=2.21, val_accuracy=0.502, lr=0.1] 42%|████▏     | 33/78 [12:12<15:56, 21.25s/epoch, loss=1.12, accuracy=0.752, val_loss=1.79, val_accuracy=0.546, lr=0.1] 44%|████▎     | 34/78 [12:33<15:31, 21.17s/epoch, loss=1.12, accuracy=0.753, val_loss=1.84, val_accuracy=0.547, lr=0.0316] 45%|████▍     | 35/78 [12:54<15:09, 21.15s/epoch, loss=1.12, accuracy=0.754, val_loss=2.22, val_accuracy=0.475, lr=0.1]    46%|████▌     | 36/78 [13:15<14:52, 21.25s/epoch, loss=1.13, accuracy=0.754, val_loss=1.72, val_accuracy=0.53, lr=0.1]  47%|████▋     | 37/78 [13:36<14:29, 21.20s/epoch, loss=1.12, accuracy=0.754, val_loss=2.55, val_accuracy=0.478, lr=0.1] 49%|████▊     | 38/78 [13:57<14:07, 21.19s/epoch, loss=1.12, accuracy=0.755, val_loss=1.86, val_accuracy=0.539, lr=0.1] 50%|█████     | 39/78 [14:18<13:44, 21.13s/epoch, loss=1.12, accuracy=0.752, val_loss=2.01, val_accuracy=0.459, lr=0.0316] 51%|█████▏    | 40/78 [14:39<13:22, 21.12s/epoch, loss=1.11, accuracy=0.757, val_loss=1.75, val_accuracy=0.567, lr=0.1]    53%|█████▎    | 41/78 [15:00<13:00, 21.09s/epoch, loss=1.12, accuracy=0.754, val_loss=1.55, val_accuracy=0.626, lr=0.1] 54%|█████▍    | 42/78 [15:22<12:43, 21.20s/epoch, loss=1.12, accuracy=0.757, val_loss=1.9, val_accuracy=0.505, lr=0.1]  55%|█████▌    | 43/78 [15:43<12:23, 21.23s/epoch, loss=1.11, accuracy=0.757, val_loss=1.58, val_accuracy=0.591, lr=0.1] 56%|█████▋    | 44/78 [16:04<11:58, 21.13s/epoch, loss=1.12, accuracy=0.755, val_loss=2.33, val_accuracy=0.354, lr=0.0316] 58%|█████▊    | 45/78 [16:26<11:40, 21.24s/epoch, loss=1.11, accuracy=0.755, val_loss=1.77, val_accuracy=0.574, lr=0.1]    59%|█████▉    | 46/78 [16:47<11:17, 21.17s/epoch, loss=1.11, accuracy=0.755, val_loss=2.8, val_accuracy=0.409, lr=0.1]  60%|██████    | 47/78 [17:08<10:58, 21.26s/epoch, loss=1.12, accuracy=0.756, val_loss=1.5, val_accuracy=0.628, lr=0.1] 62%|██████▏   | 48/78 [17:29<10:35, 21.18s/epoch, loss=1.11, accuracy=0.757, val_loss=1.67, val_accuracy=0.567, lr=0.1] 63%|██████▎   | 49/78 [17:50<10:12, 21.10s/epoch, loss=1.12, accuracy=0.756, val_loss=2.2, val_accuracy=0.499, lr=0.0316] 64%|██████▍   | 50/78 [18:11<09:50, 21.10s/epoch, loss=1.11, accuracy=0.757, val_loss=2.94, val_accuracy=0.419, lr=0.1]   65%|██████▌   | 51/78 [18:32<09:28, 21.07s/epoch, loss=1.11, accuracy=0.756, val_loss=2.12, val_accuracy=0.534, lr=0.1] 67%|██████▋   | 52/78 [18:53<09:06, 21.03s/epoch, loss=1.12, accuracy=0.756, val_loss=2.53, val_accuracy=0.409, lr=0.1] 68%|██████▊   | 53/78 [19:14<08:45, 21.02s/epoch, loss=1.11, accuracy=0.756, val_loss=2.01, val_accuracy=0.542, lr=0.1] 69%|██████▉   | 54/78 [19:35<08:24, 21.03s/epoch, loss=1.11, accuracy=0.756, val_loss=1.52, val_accuracy=0.603, lr=0.0316] 71%|███████   | 55/78 [19:56<08:03, 21.03s/epoch, loss=1.11, accuracy=0.758, val_loss=3.13, val_accuracy=0.387, lr=0.1]    72%|███████▏  | 56/78 [20:17<07:42, 21.01s/epoch, loss=1.11, accuracy=0.758, val_loss=2.16, val_accuracy=0.47, lr=0.1]  73%|███████▎  | 57/78 [20:38<07:21, 21.04s/epoch, loss=1.11, accuracy=0.759, val_loss=2.05, val_accuracy=0.484, lr=0.1] 74%|███████▍  | 58/78 [21:00<07:03, 21.18s/epoch, loss=1.11, accuracy=0.76, val_loss=2.27, val_accuracy=0.388, lr=0.1]  76%|███████▌  | 59/78 [21:21<06:41, 21.14s/epoch, loss=1.11, accuracy=0.757, val_loss=1.98, val_accuracy=0.497, lr=0.0316] 77%|███████▋  | 60/78 [21:42<06:19, 21.06s/epoch, loss=1.1, accuracy=0.759, val_loss=1.92, val_accuracy=0.538, lr=0.1]     78%|███████▊  | 61/78 [22:03<05:59, 21.14s/epoch, loss=1.11, accuracy=0.755, val_loss=1.57, val_accuracy=0.602, lr=0.1] 79%|███████▉  | 62/78 [22:24<05:36, 21.04s/epoch, loss=1.1, accuracy=0.76, val_loss=2.59, val_accuracy=0.456, lr=0.1]   81%|████████  | 63/78 [22:45<05:17, 21.16s/epoch, loss=1.11, accuracy=0.756, val_loss=2.36, val_accuracy=0.463, lr=0.1] 82%|████████▏ | 64/78 [23:06<04:55, 21.13s/epoch, loss=1.11, accuracy=0.753, val_loss=1.96, val_accuracy=0.508, lr=0.0316] 83%|████████▎ | 65/78 [23:28<04:35, 21.20s/epoch, loss=1.11, accuracy=0.757, val_loss=2.56, val_accuracy=0.421, lr=0.1]    85%|████████▍ | 66/78 [23:49<04:15, 21.26s/epoch, loss=1.1, accuracy=0.758, val_loss=1.94, val_accuracy=0.471, lr=0.1]  86%|████████▌ | 67/78 [24:10<03:54, 21.30s/epoch, loss=1.11, accuracy=0.757, val_loss=1.51, val_accuracy=0.618, lr=0.1] 87%|████████▋ | 68/78 [24:32<03:33, 21.33s/epoch, loss=1.11, accuracy=0.757, val_loss=2.57, val_accuracy=0.358, lr=0.1] 88%|████████▊ | 69/78 [24:53<03:10, 21.22s/epoch, loss=1.11, accuracy=0.759, val_loss=2.28, val_accuracy=0.488, lr=0.0316] 90%|████████▉ | 70/78 [25:14<02:49, 21.15s/epoch, loss=1.11, accuracy=0.755, val_loss=1.92, val_accuracy=0.525, lr=0.1]    91%|█████████ | 71/78 [25:36<02:30, 21.48s/epoch, loss=1.11, accuracy=0.758, val_loss=1.69, val_accuracy=0.577, lr=0.1] 92%|█████████▏| 72/78 [25:57<02:07, 21.31s/epoch, loss=1.11, accuracy=0.757, val_loss=2.37, val_accuracy=0.371, lr=0.1] 94%|█████████▎| 73/78 [26:18<01:45, 21.19s/epoch, loss=1.11, accuracy=0.758, val_loss=2.72, val_accuracy=0.356, lr=0.1] 95%|█████████▍| 74/78 [26:39<01:24, 21.08s/epoch, loss=1.1, accuracy=0.758, val_loss=1.53, val_accuracy=0.612, lr=0.0316] 96%|█████████▌| 75/78 [27:00<01:03, 21.05s/epoch, loss=1.1, accuracy=0.76, val_loss=3.27, val_accuracy=0.352, lr=0.1]     97%|█████████▋| 76/78 [27:21<00:42, 21.05s/epoch, loss=1.11, accuracy=0.759, val_loss=1.94, val_accuracy=0.505, lr=0.1] 99%|█████████▊| 77/78 [27:42<00:21, 21.09s/epoch, loss=1.1, accuracy=0.758, val_loss=2.99, val_accuracy=0.419, lr=0.1] 100%|██████████| 78/78 [28:03<00:00, 21.09s/epoch, loss=1.11, accuracy=0.757, val_loss=2.12, val_accuracy=0.514, lr=0.1]100%|██████████| 78/78 [28:03<00:00, 21.58s/epoch, loss=1.11, accuracy=0.757, val_loss=2.12, val_accuracy=0.514, lr=0.1]
Using real-time data augmentation.
Test score: 2.124976396560669
Test accuracy: 0.5139999985694885


* * * Run SGD for ID = 19_8. * * *


2024-03-05 14:18:50.980427: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 14:18:53.692518: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 14:18:53.693486: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-05 14:18:53.730724: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-05 14:18:53.730753: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 14:18:53.733631: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 14:18:53.733671: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 14:18:53.735571: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 14:18:53.736805: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 14:18:53.738980: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 14:18:53.740373: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 14:18:53.744554: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 14:18:53.745064: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 14:18:53.745147: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 14:18:54.928365: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-05 14:18:54.929244: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 14:18:54.929947: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-05 14:18:54.929981: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 14:18:54.930017: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 14:18:54.930035: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 14:18:54.930052: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 14:18:54.930071: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 14:18:54.930088: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 14:18:54.930104: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 14:18:54.930120: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 14:18:54.930557: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 14:18:54.930590: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 14:18:55.549297: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-05 14:18:55.549353: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-05 14:18:55.549362: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-05 14:18:55.550195: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:03:00.0, compute capability: 6.1)
{'id': '19_08', 'seed': 8, 'out_folder': 'results/epoch_budget', 'batch_size': 128, 'epochs': 78, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'bootstrapping': False, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/78 [00:00<?, ?epoch/s]2024-03-05 14:18:56.357254: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-05 14:18:56.357714: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199945000 Hz
2024-03-05 14:18:58.280289: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 14:18:58.500968: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 14:18:59.243624: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-05 14:18:59.288506: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|▏         | 1/78 [00:50<1:04:51, 50.54s/epoch, loss=2.82, accuracy=0.414, val_loss=3.03, val_accuracy=0.261, lr=0.1]  3%|▎         | 2/78 [01:11<42:08, 33.27s/epoch, loss=1.45, accuracy=0.612, val_loss=3.52, val_accuracy=0.317, lr=0.1]    4%|▍         | 3/78 [01:33<34:44, 27.80s/epoch, loss=1.3, accuracy=0.671, val_loss=2.13, val_accuracy=0.489, lr=0.1]   5%|▌         | 4/78 [01:53<30:57, 25.10s/epoch, loss=1.26, accuracy=0.697, val_loss=1.63, val_accuracy=0.555, lr=0.1]  6%|▋         | 5/78 [02:14<28:44, 23.62s/epoch, loss=1.24, accuracy=0.709, val_loss=1.34, val_accuracy=0.682, lr=0.1]  8%|▊         | 6/78 [02:35<27:14, 22.70s/epoch, loss=1.22, accuracy=0.721, val_loss=2.05, val_accuracy=0.484, lr=0.1]  9%|▉         | 7/78 [02:56<26:12, 22.14s/epoch, loss=1.21, accuracy=0.725, val_loss=1.73, val_accuracy=0.572, lr=0.1] 10%|█         | 8/78 [03:18<25:30, 21.86s/epoch, loss=1.2, accuracy=0.728, val_loss=2.81, val_accuracy=0.308, lr=0.1]  12%|█▏        | 9/78 [03:39<24:52, 21.63s/epoch, loss=1.2, accuracy=0.73, val_loss=1.72, val_accuracy=0.576, lr=0.1]  13%|█▎        | 10/78 [04:00<24:28, 21.60s/epoch, loss=1.19, accuracy=0.733, val_loss=1.76, val_accuracy=0.55, lr=0.0316] 14%|█▍        | 11/78 [04:21<23:53, 21.40s/epoch, loss=1.19, accuracy=0.737, val_loss=2.15, val_accuracy=0.52, lr=0.1]    15%|█▌        | 12/78 [04:42<23:21, 21.23s/epoch, loss=1.18, accuracy=0.737, val_loss=1.49, val_accuracy=0.629, lr=0.1] 17%|█▋        | 13/78 [05:03<22:55, 21.17s/epoch, loss=1.18, accuracy=0.74, val_loss=1.76, val_accuracy=0.55, lr=0.1]   18%|█▊        | 14/78 [05:24<22:33, 21.14s/epoch, loss=1.17, accuracy=0.741, val_loss=2.89, val_accuracy=0.435, lr=0.1] 19%|█▉        | 15/78 [05:45<22:08, 21.08s/epoch, loss=1.18, accuracy=0.744, val_loss=2.37, val_accuracy=0.453, lr=0.0316] 21%|██        | 16/78 [06:06<21:51, 21.15s/epoch, loss=1.17, accuracy=0.746, val_loss=1.87, val_accuracy=0.522, lr=0.1]    22%|██▏       | 17/78 [06:28<21:31, 21.17s/epoch, loss=1.17, accuracy=0.745, val_loss=2.54, val_accuracy=0.433, lr=0.1] 23%|██▎       | 18/78 [06:49<21:05, 21.09s/epoch, loss=1.17, accuracy=0.747, val_loss=1.99, val_accuracy=0.489, lr=0.1] 24%|██▍       | 19/78 [07:10<20:48, 21.15s/epoch, loss=1.16, accuracy=0.744, val_loss=2.54, val_accuracy=0.328, lr=0.1] 26%|██▌       | 20/78 [07:31<20:20, 21.04s/epoch, loss=1.16, accuracy=0.747, val_loss=3.35, val_accuracy=0.367, lr=0.0316] 27%|██▋       | 21/78 [07:52<19:57, 21.01s/epoch, loss=1.16, accuracy=0.749, val_loss=2.06, val_accuracy=0.452, lr=0.1]    28%|██▊       | 22/78 [08:13<19:36, 21.00s/epoch, loss=1.15, accuracy=0.752, val_loss=1.95, val_accuracy=0.486, lr=0.1] 29%|██▉       | 23/78 [08:34<19:21, 21.12s/epoch, loss=1.16, accuracy=0.75, val_loss=5.66, val_accuracy=0.196, lr=0.1]  31%|███       | 24/78 [08:55<18:58, 21.08s/epoch, loss=1.15, accuracy=0.752, val_loss=1.65, val_accuracy=0.598, lr=0.1] 32%|███▏      | 25/78 [09:17<18:48, 21.29s/epoch, loss=1.15, accuracy=0.751, val_loss=2.07, val_accuracy=0.47, lr=0.0316] 33%|███▎      | 26/78 [09:38<18:28, 21.31s/epoch, loss=1.14, accuracy=0.752, val_loss=1.58, val_accuracy=0.622, lr=0.1]   35%|███▍      | 27/78 [09:59<18:01, 21.21s/epoch, loss=1.14, accuracy=0.752, val_loss=2.04, val_accuracy=0.438, lr=0.1] 36%|███▌      | 28/78 [10:20<17:36, 21.13s/epoch, loss=1.15, accuracy=0.752, val_loss=3.68, val_accuracy=0.287, lr=0.1] 37%|███▋      | 29/78 [10:41<17:15, 21.12s/epoch, loss=1.14, accuracy=0.751, val_loss=1.79, val_accuracy=0.591, lr=0.1] 38%|███▊      | 30/78 [11:02<16:50, 21.05s/epoch, loss=1.14, accuracy=0.752, val_loss=1.87, val_accuracy=0.525, lr=0.0316] 40%|███▉      | 31/78 [11:23<16:27, 21.02s/epoch, loss=1.14, accuracy=0.752, val_loss=1.79, val_accuracy=0.539, lr=0.1]    41%|████      | 32/78 [11:44<16:03, 20.96s/epoch, loss=1.13, accuracy=0.755, val_loss=2.34, val_accuracy=0.481, lr=0.1] 42%|████▏     | 33/78 [12:05<15:43, 20.96s/epoch, loss=1.14, accuracy=0.753, val_loss=2.56, val_accuracy=0.368, lr=0.1] 44%|████▎     | 34/78 [12:26<15:20, 20.91s/epoch, loss=1.14, accuracy=0.754, val_loss=1.91, val_accuracy=0.482, lr=0.1] 45%|████▍     | 35/78 [12:46<14:59, 20.92s/epoch, loss=1.13, accuracy=0.756, val_loss=1.76, val_accuracy=0.561, lr=0.0316] 46%|████▌     | 36/78 [13:07<14:37, 20.89s/epoch, loss=1.13, accuracy=0.757, val_loss=2.86, val_accuracy=0.39, lr=0.1]     47%|████▋     | 37/78 [13:28<14:14, 20.84s/epoch, loss=1.13, accuracy=0.757, val_loss=1.73, val_accuracy=0.574, lr=0.1] 49%|████▊     | 38/78 [13:49<13:53, 20.83s/epoch, loss=1.13, accuracy=0.758, val_loss=2.19, val_accuracy=0.477, lr=0.1] 50%|█████     | 39/78 [14:10<13:31, 20.82s/epoch, loss=1.13, accuracy=0.757, val_loss=2.49, val_accuracy=0.454, lr=0.1] 51%|█████▏    | 40/78 [14:31<13:17, 20.99s/epoch, loss=1.13, accuracy=0.757, val_loss=2.62, val_accuracy=0.41, lr=0.0316] 53%|█████▎    | 41/78 [14:52<12:56, 20.98s/epoch, loss=1.12, accuracy=0.757, val_loss=1.44, val_accuracy=0.652, lr=0.1]   54%|█████▍    | 42/78 [15:13<12:34, 20.95s/epoch, loss=1.13, accuracy=0.758, val_loss=2.36, val_accuracy=0.424, lr=0.1] 55%|█████▌    | 43/78 [15:34<12:12, 20.93s/epoch, loss=1.12, accuracy=0.758, val_loss=1.87, val_accuracy=0.548, lr=0.1] 56%|█████▋    | 44/78 [15:55<11:51, 20.92s/epoch, loss=1.13, accuracy=0.756, val_loss=1.37, val_accuracy=0.678, lr=0.1] 58%|█████▊    | 45/78 [16:16<11:30, 20.94s/epoch, loss=1.12, accuracy=0.758, val_loss=1.72, val_accuracy=0.571, lr=0.0316] 59%|█████▉    | 46/78 [16:36<11:09, 20.91s/epoch, loss=1.12, accuracy=0.759, val_loss=2.42, val_accuracy=0.497, lr=0.1]    60%|██████    | 47/78 [16:58<10:51, 21.03s/epoch, loss=1.12, accuracy=0.759, val_loss=2.07, val_accuracy=0.52, lr=0.1]  62%|██████▏   | 48/78 [17:19<10:34, 21.13s/epoch, loss=1.12, accuracy=0.757, val_loss=2.3, val_accuracy=0.475, lr=0.1] 63%|██████▎   | 49/78 [17:41<10:16, 21.25s/epoch, loss=1.12, accuracy=0.759, val_loss=2.15, val_accuracy=0.478, lr=0.1] 64%|██████▍   | 50/78 [18:02<09:52, 21.14s/epoch, loss=1.12, accuracy=0.757, val_loss=2.89, val_accuracy=0.35, lr=0.0316] 65%|██████▌   | 51/78 [18:22<09:29, 21.10s/epoch, loss=1.13, accuracy=0.755, val_loss=2.38, val_accuracy=0.494, lr=0.1]   67%|██████▋   | 52/78 [18:43<09:07, 21.04s/epoch, loss=1.12, accuracy=0.756, val_loss=2.56, val_accuracy=0.421, lr=0.1] 68%|██████▊   | 53/78 [19:04<08:45, 21.01s/epoch, loss=1.12, accuracy=0.758, val_loss=2.5, val_accuracy=0.352, lr=0.1]  69%|██████▉   | 54/78 [19:25<08:24, 21.01s/epoch, loss=1.12, accuracy=0.76, val_loss=2.86, val_accuracy=0.392, lr=0.1] 71%|███████   | 55/78 [19:47<08:04, 21.06s/epoch, loss=1.12, accuracy=0.76, val_loss=2.26, val_accuracy=0.442, lr=0.0316] 72%|███████▏  | 56/78 [20:07<07:42, 21.02s/epoch, loss=1.12, accuracy=0.758, val_loss=1.84, val_accuracy=0.553, lr=0.1]   73%|███████▎  | 57/78 [20:29<07:21, 21.03s/epoch, loss=1.12, accuracy=0.757, val_loss=1.84, val_accuracy=0.57, lr=0.1]  74%|███████▍  | 58/78 [20:49<06:59, 20.98s/epoch, loss=1.11, accuracy=0.759, val_loss=2.57, val_accuracy=0.406, lr=0.1] 76%|███████▌  | 59/78 [21:10<06:38, 20.97s/epoch, loss=1.11, accuracy=0.759, val_loss=1.4, val_accuracy=0.659, lr=0.1]  77%|███████▋  | 60/78 [21:31<06:17, 20.96s/epoch, loss=1.12, accuracy=0.76, val_loss=2.13, val_accuracy=0.462, lr=0.0316] 78%|███████▊  | 61/78 [21:52<05:55, 20.92s/epoch, loss=1.12, accuracy=0.759, val_loss=10, val_accuracy=0.158, lr=0.1]     79%|███████▉  | 62/78 [22:13<05:34, 20.89s/epoch, loss=1.12, accuracy=0.758, val_loss=3, val_accuracy=0.354, lr=0.1]  81%|████████  | 63/78 [22:34<05:13, 20.90s/epoch, loss=1.11, accuracy=0.759, val_loss=1.74, val_accuracy=0.556, lr=0.1] 82%|████████▏ | 64/78 [22:55<04:53, 20.93s/epoch, loss=1.11, accuracy=0.758, val_loss=1.74, val_accuracy=0.55, lr=0.1]  83%|████████▎ | 65/78 [23:16<04:32, 21.00s/epoch, loss=1.12, accuracy=0.759, val_loss=2.27, val_accuracy=0.425, lr=0.0316] 85%|████████▍ | 66/78 [23:38<04:14, 21.18s/epoch, loss=1.11, accuracy=0.759, val_loss=1.6, val_accuracy=0.582, lr=0.1]     86%|████████▌ | 67/78 [23:59<03:53, 21.22s/epoch, loss=1.11, accuracy=0.76, val_loss=2.27, val_accuracy=0.44, lr=0.1]  87%|████████▋ | 68/78 [24:20<03:31, 21.10s/epoch, loss=1.12, accuracy=0.758, val_loss=1.93, val_accuracy=0.551, lr=0.1] 88%|████████▊ | 69/78 [24:41<03:10, 21.15s/epoch, loss=1.12, accuracy=0.759, val_loss=1.69, val_accuracy=0.587, lr=0.1] 90%|████████▉ | 70/78 [25:03<02:50, 21.31s/epoch, loss=1.11, accuracy=0.76, val_loss=2.44, val_accuracy=0.41, lr=0.0316] 91%|█████████ | 71/78 [25:23<02:27, 21.13s/epoch, loss=1.12, accuracy=0.762, val_loss=1.68, val_accuracy=0.58, lr=0.1]   92%|█████████▏| 72/78 [25:44<02:06, 21.10s/epoch, loss=1.12, accuracy=0.758, val_loss=2.22, val_accuracy=0.473, lr=0.1] 94%|█████████▎| 73/78 [26:05<01:44, 21.00s/epoch, loss=1.12, accuracy=0.758, val_loss=5.78, val_accuracy=0.248, lr=0.1] 95%|█████████▍| 74/78 [26:27<01:24, 21.20s/epoch, loss=1.11, accuracy=0.758, val_loss=2.01, val_accuracy=0.448, lr=0.1] 96%|█████████▌| 75/78 [26:48<01:03, 21.08s/epoch, loss=1.1, accuracy=0.762, val_loss=2.33, val_accuracy=0.416, lr=0.0316] 97%|█████████▋| 76/78 [27:09<00:42, 21.03s/epoch, loss=1.11, accuracy=0.759, val_loss=2.26, val_accuracy=0.494, lr=0.1]   99%|█████████▊| 77/78 [27:30<00:21, 21.15s/epoch, loss=1.12, accuracy=0.759, val_loss=2.74, val_accuracy=0.403, lr=0.1]100%|██████████| 78/78 [27:51<00:00, 21.11s/epoch, loss=1.11, accuracy=0.759, val_loss=1.82, val_accuracy=0.541, lr=0.1]100%|██████████| 78/78 [27:51<00:00, 21.43s/epoch, loss=1.11, accuracy=0.759, val_loss=1.82, val_accuracy=0.541, lr=0.1]
Using real-time data augmentation.
Test score: 1.8158576488494873
Test accuracy: 0.5407999753952026


* * * Run SGD for ID = 19_9. * * *


2024-03-05 14:46:52.495742: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 14:47:06.561333: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 14:47:06.562268: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-05 14:47:06.624201: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-05 14:47:06.624233: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 14:47:06.628422: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 14:47:06.628463: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 14:47:06.634091: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 14:47:06.635663: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 14:47:06.640177: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 14:47:06.643103: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 14:47:06.647801: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 14:47:06.648304: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 14:47:06.648392: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 14:47:07.984854: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-05 14:47:07.985302: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 14:47:07.985730: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-05 14:47:07.985761: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 14:47:07.985793: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 14:47:07.985809: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 14:47:07.985824: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 14:47:07.985850: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 14:47:07.985865: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 14:47:07.985879: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 14:47:07.985895: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 14:47:07.986325: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 14:47:07.986358: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 14:47:08.622369: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-05 14:47:08.622438: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-05 14:47:08.622453: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-05 14:47:08.623611: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:03:00.0, compute capability: 6.1)
{'id': '19_09', 'seed': 9, 'out_folder': 'results/epoch_budget', 'batch_size': 128, 'epochs': 78, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'bootstrapping': False, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/78 [00:00<?, ?epoch/s]2024-03-05 14:47:09.465768: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-05 14:47:09.466221: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199945000 Hz
2024-03-05 14:47:11.436973: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 14:47:11.663870: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 14:47:12.425455: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-05 14:47:12.461247: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|▏         | 1/78 [00:47<1:00:42, 47.31s/epoch, loss=3.07, accuracy=0.337, val_loss=2.94, val_accuracy=0.216, lr=0.1]  3%|▎         | 2/78 [01:08<40:34, 32.04s/epoch, loss=1.52, accuracy=0.558, val_loss=1.62, val_accuracy=0.539, lr=0.1]    4%|▍         | 3/78 [01:29<33:46, 27.02s/epoch, loss=1.31, accuracy=0.656, val_loss=1.97, val_accuracy=0.509, lr=0.1]  5%|▌         | 4/78 [01:50<30:24, 24.65s/epoch, loss=1.26, accuracy=0.689, val_loss=1.89, val_accuracy=0.502, lr=0.1]  6%|▋         | 5/78 [02:11<28:20, 23.30s/epoch, loss=1.23, accuracy=0.704, val_loss=3.05, val_accuracy=0.411, lr=0.1]  8%|▊         | 6/78 [02:32<26:57, 22.47s/epoch, loss=1.23, accuracy=0.713, val_loss=1.44, val_accuracy=0.628, lr=0.1]  9%|▉         | 7/78 [02:53<26:00, 21.98s/epoch, loss=1.21, accuracy=0.722, val_loss=1.89, val_accuracy=0.5, lr=0.1]   10%|█         | 8/78 [03:14<25:16, 21.66s/epoch, loss=1.21, accuracy=0.725, val_loss=2.17, val_accuracy=0.47, lr=0.1] 12%|█▏        | 9/78 [03:35<24:37, 21.42s/epoch, loss=1.2, accuracy=0.726, val_loss=2.19, val_accuracy=0.495, lr=0.1] 13%|█▎        | 10/78 [03:56<24:04, 21.25s/epoch, loss=1.19, accuracy=0.731, val_loss=1.63, val_accuracy=0.602, lr=0.1] 14%|█▍        | 11/78 [04:17<23:38, 21.17s/epoch, loss=1.19, accuracy=0.733, val_loss=1.67, val_accuracy=0.573, lr=0.0316] 15%|█▌        | 12/78 [04:38<23:11, 21.09s/epoch, loss=1.18, accuracy=0.736, val_loss=2.55, val_accuracy=0.428, lr=0.1]    17%|█▋        | 13/78 [04:59<22:54, 21.14s/epoch, loss=1.18, accuracy=0.737, val_loss=4.11, val_accuracy=0.217, lr=0.1] 18%|█▊        | 14/78 [05:20<22:28, 21.08s/epoch, loss=1.17, accuracy=0.741, val_loss=3.46, val_accuracy=0.381, lr=0.1] 19%|█▉        | 15/78 [05:41<22:04, 21.03s/epoch, loss=1.17, accuracy=0.744, val_loss=1.68, val_accuracy=0.563, lr=0.1] 21%|██        | 16/78 [06:01<21:38, 20.94s/epoch, loss=1.17, accuracy=0.745, val_loss=1.54, val_accuracy=0.617, lr=0.0316] 22%|██▏       | 17/78 [06:22<21:17, 20.94s/epoch, loss=1.17, accuracy=0.744, val_loss=2.1, val_accuracy=0.486, lr=0.1]     23%|██▎       | 18/78 [06:43<20:57, 20.96s/epoch, loss=1.16, accuracy=0.746, val_loss=1.83, val_accuracy=0.534, lr=0.1] 24%|██▍       | 19/78 [07:05<20:39, 21.01s/epoch, loss=1.17, accuracy=0.749, val_loss=1.99, val_accuracy=0.499, lr=0.1] 26%|██▌       | 20/78 [07:26<20:22, 21.08s/epoch, loss=1.16, accuracy=0.748, val_loss=1.66, val_accuracy=0.596, lr=0.1] 27%|██▋       | 21/78 [07:48<20:15, 21.33s/epoch, loss=1.16, accuracy=0.749, val_loss=1.8, val_accuracy=0.553, lr=0.0316] 28%|██▊       | 22/78 [08:09<19:52, 21.30s/epoch, loss=1.15, accuracy=0.75, val_loss=1.93, val_accuracy=0.516, lr=0.1]    29%|██▉       | 23/78 [08:30<19:28, 21.24s/epoch, loss=1.16, accuracy=0.749, val_loss=1.81, val_accuracy=0.594, lr=0.1] 31%|███       | 24/78 [08:51<19:05, 21.21s/epoch, loss=1.15, accuracy=0.749, val_loss=1.99, val_accuracy=0.494, lr=0.1] 32%|███▏      | 25/78 [09:13<18:49, 21.31s/epoch, loss=1.15, accuracy=0.751, val_loss=1.88, val_accuracy=0.551, lr=0.1] 33%|███▎      | 26/78 [09:34<18:22, 21.21s/epoch, loss=1.15, accuracy=0.753, val_loss=1.61, val_accuracy=0.596, lr=0.0316] 35%|███▍      | 27/78 [09:55<17:58, 21.15s/epoch, loss=1.15, accuracy=0.75, val_loss=2.08, val_accuracy=0.487, lr=0.1]     36%|███▌      | 28/78 [10:16<17:34, 21.09s/epoch, loss=1.14, accuracy=0.751, val_loss=1.87, val_accuracy=0.51, lr=0.1] 37%|███▋      | 29/78 [10:37<17:10, 21.04s/epoch, loss=1.15, accuracy=0.75, val_loss=2.62, val_accuracy=0.408, lr=0.1] 38%|███▊      | 30/78 [10:58<16:51, 21.08s/epoch, loss=1.15, accuracy=0.751, val_loss=1.65, val_accuracy=0.593, lr=0.1] 40%|███▉      | 31/78 [11:19<16:30, 21.07s/epoch, loss=1.14, accuracy=0.756, val_loss=1.78, val_accuracy=0.508, lr=0.0316] 41%|████      | 32/78 [11:40<16:07, 21.04s/epoch, loss=1.15, accuracy=0.751, val_loss=1.71, val_accuracy=0.588, lr=0.1]    42%|████▏     | 33/78 [12:01<15:45, 21.02s/epoch, loss=1.14, accuracy=0.754, val_loss=2.31, val_accuracy=0.484, lr=0.1] 44%|████▎     | 34/78 [12:22<15:23, 20.98s/epoch, loss=1.14, accuracy=0.755, val_loss=1.93, val_accuracy=0.512, lr=0.1] 45%|████▍     | 35/78 [12:42<14:59, 20.93s/epoch, loss=1.14, accuracy=0.752, val_loss=2.2, val_accuracy=0.504, lr=0.1]  46%|████▌     | 36/78 [13:04<14:43, 21.05s/epoch, loss=1.14, accuracy=0.756, val_loss=1.9, val_accuracy=0.51, lr=0.0316] 47%|████▋     | 37/78 [13:25<14:20, 21.00s/epoch, loss=1.14, accuracy=0.756, val_loss=1.68, val_accuracy=0.584, lr=0.1]  49%|████▊     | 38/78 [13:46<14:03, 21.09s/epoch, loss=1.14, accuracy=0.757, val_loss=2.15, val_accuracy=0.551, lr=0.1] 50%|█████     | 39/78 [14:07<13:44, 21.13s/epoch, loss=1.14, accuracy=0.754, val_loss=1.77, val_accuracy=0.519, lr=0.1] 51%|█████▏    | 40/78 [14:28<13:19, 21.04s/epoch, loss=1.13, accuracy=0.754, val_loss=1.44, val_accuracy=0.647, lr=0.1] 53%|█████▎    | 41/78 [14:50<13:05, 21.24s/epoch, loss=1.13, accuracy=0.761, val_loss=2.59, val_accuracy=0.358, lr=0.0316] 54%|█████▍    | 42/78 [15:11<12:40, 21.11s/epoch, loss=1.14, accuracy=0.755, val_loss=4.62, val_accuracy=0.263, lr=0.1]    55%|█████▌    | 43/78 [15:31<12:16, 21.04s/epoch, loss=1.13, accuracy=0.756, val_loss=1.57, val_accuracy=0.623, lr=0.1] 56%|█████▋    | 44/78 [15:52<11:53, 20.99s/epoch, loss=1.14, accuracy=0.756, val_loss=2.14, val_accuracy=0.45, lr=0.1]  58%|█████▊    | 45/78 [16:14<11:36, 21.10s/epoch, loss=1.14, accuracy=0.753, val_loss=2.76, val_accuracy=0.351, lr=0.1] 59%|█████▉    | 46/78 [16:35<11:15, 21.12s/epoch, loss=1.13, accuracy=0.758, val_loss=1.7, val_accuracy=0.552, lr=0.0316] 60%|██████    | 47/78 [16:56<10:52, 21.05s/epoch, loss=1.13, accuracy=0.759, val_loss=1.67, val_accuracy=0.532, lr=0.1]   62%|██████▏   | 48/78 [17:17<10:29, 20.99s/epoch, loss=1.14, accuracy=0.755, val_loss=1.55, val_accuracy=0.634, lr=0.1] 63%|██████▎   | 49/78 [17:37<10:08, 20.98s/epoch, loss=1.13, accuracy=0.756, val_loss=2.24, val_accuracy=0.41, lr=0.1]  64%|██████▍   | 50/78 [17:58<09:45, 20.91s/epoch, loss=1.13, accuracy=0.759, val_loss=2.01, val_accuracy=0.501, lr=0.1] 65%|██████▌   | 51/78 [18:20<09:30, 21.12s/epoch, loss=1.12, accuracy=0.758, val_loss=1.8, val_accuracy=0.523, lr=0.0316] 67%|██████▋   | 52/78 [18:41<09:11, 21.21s/epoch, loss=1.13, accuracy=0.758, val_loss=1.98, val_accuracy=0.513, lr=0.1]   68%|██████▊   | 53/78 [19:02<08:47, 21.09s/epoch, loss=1.12, accuracy=0.759, val_loss=1.81, val_accuracy=0.551, lr=0.1] 69%|██████▉   | 54/78 [19:23<08:24, 21.03s/epoch, loss=1.12, accuracy=0.759, val_loss=2, val_accuracy=0.508, lr=0.1]    71%|███████   | 55/78 [19:44<08:05, 21.10s/epoch, loss=1.12, accuracy=0.758, val_loss=1.73, val_accuracy=0.575, lr=0.1] 72%|███████▏  | 56/78 [20:06<07:46, 21.19s/epoch, loss=1.12, accuracy=0.759, val_loss=1.93, val_accuracy=0.526, lr=0.0316] 73%|███████▎  | 57/78 [20:27<07:24, 21.19s/epoch, loss=1.12, accuracy=0.761, val_loss=1.87, val_accuracy=0.55, lr=0.1]     74%|███████▍  | 58/78 [20:48<07:01, 21.09s/epoch, loss=1.12, accuracy=0.757, val_loss=1.7, val_accuracy=0.568, lr=0.1] 76%|███████▌  | 59/78 [21:09<06:39, 21.05s/epoch, loss=1.12, accuracy=0.759, val_loss=3.16, val_accuracy=0.363, lr=0.1] 77%|███████▋  | 60/78 [21:30<06:18, 21.01s/epoch, loss=1.12, accuracy=0.759, val_loss=2.22, val_accuracy=0.42, lr=0.1]  78%|███████▊  | 61/78 [21:50<05:56, 20.99s/epoch, loss=1.12, accuracy=0.759, val_loss=1.97, val_accuracy=0.519, lr=0.0316] 79%|███████▉  | 62/78 [22:11<05:34, 20.91s/epoch, loss=1.13, accuracy=0.758, val_loss=2.08, val_accuracy=0.46, lr=0.1]     81%|████████  | 63/78 [22:32<05:14, 20.95s/epoch, loss=1.12, accuracy=0.759, val_loss=2.92, val_accuracy=0.384, lr=0.1] 82%|████████▏ | 64/78 [22:54<04:55, 21.14s/epoch, loss=1.12, accuracy=0.757, val_loss=2.7, val_accuracy=0.37, lr=0.1]   83%|████████▎ | 65/78 [23:15<04:35, 21.16s/epoch, loss=1.12, accuracy=0.76, val_loss=2.06, val_accuracy=0.482, lr=0.1] 85%|████████▍ | 66/78 [23:36<04:12, 21.02s/epoch, loss=1.12, accuracy=0.759, val_loss=1.51, val_accuracy=0.606, lr=0.0316] 86%|████████▌ | 67/78 [23:56<03:50, 20.92s/epoch, loss=1.12, accuracy=0.758, val_loss=3.33, val_accuracy=0.347, lr=0.1]    87%|████████▋ | 68/78 [24:17<03:28, 20.81s/epoch, loss=1.12, accuracy=0.757, val_loss=2.65, val_accuracy=0.407, lr=0.1] 88%|████████▊ | 69/78 [24:38<03:06, 20.75s/epoch, loss=1.12, accuracy=0.76, val_loss=1.97, val_accuracy=0.475, lr=0.1]  90%|████████▉ | 70/78 [24:58<02:45, 20.74s/epoch, loss=1.12, accuracy=0.757, val_loss=2.71, val_accuracy=0.314, lr=0.1] 91%|█████████ | 71/78 [25:19<02:24, 20.71s/epoch, loss=1.12, accuracy=0.759, val_loss=2.47, val_accuracy=0.439, lr=0.0316] 92%|█████████▏| 72/78 [25:40<02:05, 20.84s/epoch, loss=1.12, accuracy=0.758, val_loss=2.02, val_accuracy=0.479, lr=0.1]    94%|█████████▎| 73/78 [26:01<01:43, 20.76s/epoch, loss=1.12, accuracy=0.757, val_loss=2.9, val_accuracy=0.376, lr=0.1]  95%|█████████▍| 74/78 [26:22<01:23, 20.81s/epoch, loss=1.12, accuracy=0.759, val_loss=2.44, val_accuracy=0.485, lr=0.1] 96%|█████████▌| 75/78 [26:42<01:02, 20.79s/epoch, loss=1.12, accuracy=0.758, val_loss=2, val_accuracy=0.555, lr=0.1]    97%|█████████▋| 76/78 [27:03<00:41, 20.90s/epoch, loss=1.11, accuracy=0.76, val_loss=1.98, val_accuracy=0.511, lr=0.0316] 99%|█████████▊| 77/78 [27:24<00:20, 20.87s/epoch, loss=1.12, accuracy=0.757, val_loss=1.71, val_accuracy=0.57, lr=0.1]   100%|██████████| 78/78 [27:45<00:00, 20.93s/epoch, loss=1.12, accuracy=0.76, val_loss=1.99, val_accuracy=0.526, lr=0.1]100%|██████████| 78/78 [27:45<00:00, 21.36s/epoch, loss=1.12, accuracy=0.76, val_loss=1.99, val_accuracy=0.526, lr=0.1]
Using real-time data augmentation.
Test score: 1.9854804277420044
Test accuracy: 0.525600016117096


* * * Run SGD for ID = 19_10. * * *


2024-03-05 15:15:00.074640: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 15:15:02.636609: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 15:15:02.637667: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-05 15:15:02.674378: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-05 15:15:02.674410: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 15:15:02.677194: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 15:15:02.677234: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 15:15:02.679248: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 15:15:02.679963: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 15:15:02.682514: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 15:15:02.683970: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 15:15:02.688424: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 15:15:02.688904: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 15:15:02.688994: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 15:15:03.901481: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-05 15:15:03.902561: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 15:15:03.903261: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-05 15:15:03.903295: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 15:15:03.903331: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 15:15:03.903349: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 15:15:03.903366: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 15:15:03.903382: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 15:15:03.903400: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 15:15:03.903425: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 15:15:03.903445: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 15:15:03.903877: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 15:15:03.903912: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 15:15:04.530632: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-05 15:15:04.530691: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-05 15:15:04.530706: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-05 15:15:04.531568: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:03:00.0, compute capability: 6.1)
{'id': '19_10', 'seed': 10, 'out_folder': 'results/epoch_budget', 'batch_size': 128, 'epochs': 78, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'bootstrapping': False, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/78 [00:00<?, ?epoch/s]2024-03-05 15:15:05.362601: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-05 15:15:05.363042: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199945000 Hz
2024-03-05 15:15:07.295945: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 15:15:07.520510: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 15:15:08.250072: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-05 15:15:08.294542: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|▏         | 1/78 [00:52<1:07:13, 52.39s/epoch, loss=2.88, accuracy=0.379, val_loss=4.67, val_accuracy=0.193, lr=0.1]  3%|▎         | 2/78 [01:13<43:10, 34.08s/epoch, loss=1.47, accuracy=0.586, val_loss=2.8, val_accuracy=0.396, lr=0.1]     4%|▍         | 3/78 [01:34<35:12, 28.17s/epoch, loss=1.31, accuracy=0.663, val_loss=1.91, val_accuracy=0.51, lr=0.1]  5%|▌         | 4/78 [01:55<31:15, 25.34s/epoch, loss=1.27, accuracy=0.688, val_loss=1.93, val_accuracy=0.506, lr=0.1]  6%|▋         | 5/78 [02:17<29:13, 24.01s/epoch, loss=1.26, accuracy=0.704, val_loss=2, val_accuracy=0.493, lr=0.1]     8%|▊         | 6/78 [02:38<27:34, 22.98s/epoch, loss=1.23, accuracy=0.717, val_loss=1.89, val_accuracy=0.478, lr=0.1]  9%|▉         | 7/78 [02:59<26:24, 22.31s/epoch, loss=1.21, accuracy=0.724, val_loss=1.65, val_accuracy=0.563, lr=0.1] 10%|█         | 8/78 [03:20<25:32, 21.89s/epoch, loss=1.2, accuracy=0.727, val_loss=1.81, val_accuracy=0.52, lr=0.1]   12%|█▏        | 9/78 [03:41<24:51, 21.61s/epoch, loss=1.2, accuracy=0.731, val_loss=1.55, val_accuracy=0.604, lr=0.1] 13%|█▎        | 10/78 [04:02<24:16, 21.42s/epoch, loss=1.18, accuracy=0.738, val_loss=1.87, val_accuracy=0.562, lr=0.1] 14%|█▍        | 11/78 [04:23<23:58, 21.47s/epoch, loss=1.19, accuracy=0.736, val_loss=3.65, val_accuracy=0.306, lr=0.1] 15%|█▌        | 12/78 [04:44<23:26, 21.32s/epoch, loss=1.17, accuracy=0.741, val_loss=1.54, val_accuracy=0.61, lr=0.1]  17%|█▋        | 13/78 [05:06<23:07, 21.34s/epoch, loss=1.17, accuracy=0.737, val_loss=1.72, val_accuracy=0.539, lr=0.1] 18%|█▊        | 14/78 [05:27<22:45, 21.34s/epoch, loss=1.17, accuracy=0.74, val_loss=2.89, val_accuracy=0.317, lr=0.1]  19%|█▉        | 15/78 [05:48<22:17, 21.23s/epoch, loss=1.16, accuracy=0.745, val_loss=1.47, val_accuracy=0.653, lr=0.1] 21%|██        | 16/78 [06:09<21:52, 21.17s/epoch, loss=1.16, accuracy=0.746, val_loss=1.79, val_accuracy=0.574, lr=0.1] 22%|██▏       | 17/78 [06:30<21:32, 21.18s/epoch, loss=1.15, accuracy=0.749, val_loss=2.79, val_accuracy=0.4, lr=0.1]   23%|██▎       | 18/78 [06:51<21:06, 21.11s/epoch, loss=1.16, accuracy=0.747, val_loss=2.03, val_accuracy=0.534, lr=0.1] 24%|██▍       | 19/78 [07:13<20:49, 21.18s/epoch, loss=1.15, accuracy=0.748, val_loss=1.79, val_accuracy=0.517, lr=0.1] 26%|██▌       | 20/78 [07:34<20:31, 21.24s/epoch, loss=1.15, accuracy=0.747, val_loss=1.62, val_accuracy=0.608, lr=0.0316] 27%|██▋       | 21/78 [07:55<20:08, 21.21s/epoch, loss=1.15, accuracy=0.748, val_loss=1.55, val_accuracy=0.62, lr=0.1]     28%|██▊       | 22/78 [08:16<19:46, 21.18s/epoch, loss=1.14, accuracy=0.751, val_loss=2.52, val_accuracy=0.433, lr=0.1] 29%|██▉       | 23/78 [08:37<19:22, 21.13s/epoch, loss=1.14, accuracy=0.752, val_loss=1.78, val_accuracy=0.541, lr=0.1] 31%|███       | 24/78 [08:58<18:59, 21.10s/epoch, loss=1.14, accuracy=0.751, val_loss=1.56, val_accuracy=0.591, lr=0.1] 32%|███▏      | 25/78 [09:19<18:37, 21.08s/epoch, loss=1.14, accuracy=0.753, val_loss=1.96, val_accuracy=0.55, lr=0.0316] 33%|███▎      | 26/78 [09:40<18:14, 21.05s/epoch, loss=1.14, accuracy=0.75, val_loss=1.64, val_accuracy=0.573, lr=0.1]    35%|███▍      | 27/78 [10:02<17:56, 21.11s/epoch, loss=1.13, accuracy=0.754, val_loss=2.71, val_accuracy=0.453, lr=0.1] 36%|███▌      | 28/78 [10:23<17:41, 21.24s/epoch, loss=1.13, accuracy=0.751, val_loss=2.09, val_accuracy=0.485, lr=0.1] 37%|███▋      | 29/78 [10:44<17:15, 21.13s/epoch, loss=1.13, accuracy=0.753, val_loss=2.87, val_accuracy=0.423, lr=0.1] 38%|███▊      | 30/78 [11:05<16:52, 21.10s/epoch, loss=1.13, accuracy=0.753, val_loss=2.8, val_accuracy=0.429, lr=0.0316] 40%|███▉      | 31/78 [11:26<16:32, 21.12s/epoch, loss=1.13, accuracy=0.755, val_loss=2.13, val_accuracy=0.488, lr=0.1]   41%|████      | 32/78 [11:47<16:13, 21.17s/epoch, loss=1.13, accuracy=0.754, val_loss=1.85, val_accuracy=0.518, lr=0.1] 42%|████▏     | 33/78 [12:08<15:49, 21.10s/epoch, loss=1.14, accuracy=0.755, val_loss=1.69, val_accuracy=0.585, lr=0.1] 44%|████▎     | 34/78 [12:29<15:25, 21.03s/epoch, loss=1.13, accuracy=0.754, val_loss=1.75, val_accuracy=0.539, lr=0.1] 45%|████▍     | 35/78 [12:50<15:05, 21.05s/epoch, loss=1.12, accuracy=0.756, val_loss=2.88, val_accuracy=0.38, lr=0.0316] 46%|████▌     | 36/78 [13:11<14:41, 21.00s/epoch, loss=1.13, accuracy=0.758, val_loss=2.64, val_accuracy=0.334, lr=0.1]   47%|████▋     | 37/78 [13:32<14:21, 21.00s/epoch, loss=1.12, accuracy=0.756, val_loss=2.1, val_accuracy=0.5, lr=0.1]    49%|████▊     | 38/78 [13:53<13:59, 21.00s/epoch, loss=1.13, accuracy=0.758, val_loss=1.55, val_accuracy=0.619, lr=0.1] 50%|█████     | 39/78 [14:15<13:43, 21.11s/epoch, loss=1.13, accuracy=0.756, val_loss=1.84, val_accuracy=0.572, lr=0.1] 51%|█████▏    | 40/78 [14:36<13:25, 21.19s/epoch, loss=1.13, accuracy=0.755, val_loss=1.83, val_accuracy=0.573, lr=0.0316] 53%|█████▎    | 41/78 [14:57<13:06, 21.25s/epoch, loss=1.12, accuracy=0.757, val_loss=2.59, val_accuracy=0.423, lr=0.1]    54%|█████▍    | 42/78 [15:20<12:59, 21.64s/epoch, loss=1.12, accuracy=0.761, val_loss=1.77, val_accuracy=0.547, lr=0.1] 55%|█████▌    | 43/78 [15:41<12:31, 21.47s/epoch, loss=1.12, accuracy=0.758, val_loss=1.59, val_accuracy=0.604, lr=0.1] 56%|█████▋    | 44/78 [16:02<12:06, 21.36s/epoch, loss=1.13, accuracy=0.754, val_loss=1.83, val_accuracy=0.544, lr=0.1] 58%|█████▊    | 45/78 [16:24<11:47, 21.45s/epoch, loss=1.13, accuracy=0.757, val_loss=2.4, val_accuracy=0.437, lr=0.0316] 59%|█████▉    | 46/78 [16:45<11:21, 21.29s/epoch, loss=1.13, accuracy=0.757, val_loss=3.02, val_accuracy=0.425, lr=0.1]   60%|██████    | 47/78 [17:06<10:59, 21.27s/epoch, loss=1.13, accuracy=0.757, val_loss=2.34, val_accuracy=0.423, lr=0.1] 62%|██████▏   | 48/78 [17:27<10:35, 21.19s/epoch, loss=1.12, accuracy=0.76, val_loss=1.5, val_accuracy=0.617, lr=0.1]   63%|██████▎   | 49/78 [17:48<10:12, 21.13s/epoch, loss=1.13, accuracy=0.754, val_loss=1.86, val_accuracy=0.551, lr=0.1] 64%|██████▍   | 50/78 [18:10<09:55, 21.28s/epoch, loss=1.12, accuracy=0.758, val_loss=3.41, val_accuracy=0.332, lr=0.0316] 65%|██████▌   | 51/78 [18:30<09:31, 21.15s/epoch, loss=1.12, accuracy=0.757, val_loss=1.53, val_accuracy=0.614, lr=0.1]    67%|██████▋   | 52/78 [18:51<09:07, 21.05s/epoch, loss=1.12, accuracy=0.758, val_loss=3.43, val_accuracy=0.319, lr=0.1] 68%|██████▊   | 53/78 [19:12<08:47, 21.09s/epoch, loss=1.12, accuracy=0.76, val_loss=1.61, val_accuracy=0.612, lr=0.1]  69%|██████▉   | 54/78 [19:34<08:27, 21.15s/epoch, loss=1.12, accuracy=0.757, val_loss=2.78, val_accuracy=0.444, lr=0.1] 71%|███████   | 55/78 [19:55<08:09, 21.29s/epoch, loss=1.13, accuracy=0.755, val_loss=1.78, val_accuracy=0.545, lr=0.0316] 72%|███████▏  | 56/78 [20:16<07:46, 21.21s/epoch, loss=1.12, accuracy=0.758, val_loss=1.85, val_accuracy=0.548, lr=0.1]    73%|███████▎  | 57/78 [20:38<07:27, 21.33s/epoch, loss=1.13, accuracy=0.756, val_loss=3.12, val_accuracy=0.354, lr=0.1] 74%|███████▍  | 58/78 [20:59<07:05, 21.27s/epoch, loss=1.13, accuracy=0.756, val_loss=2.11, val_accuracy=0.477, lr=0.1] 76%|███████▌  | 59/78 [21:20<06:44, 21.27s/epoch, loss=1.13, accuracy=0.756, val_loss=1.56, val_accuracy=0.602, lr=0.1] 77%|███████▋  | 60/78 [21:41<06:22, 21.23s/epoch, loss=1.12, accuracy=0.757, val_loss=3.35, val_accuracy=0.352, lr=0.0316] 78%|███████▊  | 61/78 [22:03<05:59, 21.18s/epoch, loss=1.12, accuracy=0.754, val_loss=6.02, val_accuracy=0.304, lr=0.1]    79%|███████▉  | 62/78 [22:24<05:38, 21.19s/epoch, loss=1.13, accuracy=0.757, val_loss=1.96, val_accuracy=0.455, lr=0.1] 81%|████████  | 63/78 [22:45<05:16, 21.12s/epoch, loss=1.12, accuracy=0.757, val_loss=2.47, val_accuracy=0.469, lr=0.1] 82%|████████▏ | 64/78 [23:06<04:54, 21.07s/epoch, loss=1.12, accuracy=0.756, val_loss=1.76, val_accuracy=0.545, lr=0.1] 83%|████████▎ | 65/78 [23:27<04:33, 21.05s/epoch, loss=1.12, accuracy=0.759, val_loss=1.53, val_accuracy=0.62, lr=0.0316] 85%|████████▍ | 66/78 [23:48<04:12, 21.05s/epoch, loss=1.12, accuracy=0.755, val_loss=2.4, val_accuracy=0.371, lr=0.1]    86%|████████▌ | 67/78 [24:09<03:51, 21.03s/epoch, loss=1.12, accuracy=0.757, val_loss=1.44, val_accuracy=0.648, lr=0.1] 87%|████████▋ | 68/78 [24:30<03:30, 21.01s/epoch, loss=1.12, accuracy=0.757, val_loss=1.63, val_accuracy=0.598, lr=0.1] 88%|████████▊ | 69/78 [24:51<03:08, 20.99s/epoch, loss=1.12, accuracy=0.756, val_loss=1.77, val_accuracy=0.564, lr=0.1] 90%|████████▉ | 70/78 [25:11<02:47, 20.93s/epoch, loss=1.13, accuracy=0.757, val_loss=1.96, val_accuracy=0.501, lr=0.1] 91%|█████████ | 71/78 [25:33<02:27, 21.03s/epoch, loss=1.12, accuracy=0.755, val_loss=4.42, val_accuracy=0.311, lr=0.1] 92%|█████████▏| 72/78 [25:53<02:05, 20.96s/epoch, loss=1.12, accuracy=0.755, val_loss=3.38, val_accuracy=0.362, lr=0.0316] 94%|█████████▎| 73/78 [26:14<01:44, 20.90s/epoch, loss=1.13, accuracy=0.757, val_loss=1.64, val_accuracy=0.599, lr=0.1]    95%|█████████▍| 74/78 [26:35<01:23, 20.92s/epoch, loss=1.12, accuracy=0.758, val_loss=1.66, val_accuracy=0.586, lr=0.1] 96%|█████████▌| 75/78 [26:56<01:02, 20.91s/epoch, loss=1.13, accuracy=0.756, val_loss=2.47, val_accuracy=0.428, lr=0.1] 97%|█████████▋| 76/78 [27:17<00:41, 20.93s/epoch, loss=1.12, accuracy=0.757, val_loss=2.57, val_accuracy=0.355, lr=0.1] 99%|█████████▊| 77/78 [27:38<00:20, 20.92s/epoch, loss=1.12, accuracy=0.758, val_loss=1.91, val_accuracy=0.514, lr=0.0316]100%|██████████| 78/78 [27:59<00:00, 20.94s/epoch, loss=1.12, accuracy=0.757, val_loss=2.13, val_accuracy=0.46, lr=0.1]    100%|██████████| 78/78 [27:59<00:00, 21.53s/epoch, loss=1.12, accuracy=0.757, val_loss=2.13, val_accuracy=0.46, lr=0.1]
Using real-time data augmentation.
Test score: 2.1315231323242188
Test accuracy: 0.4602000117301941


* * * Run SGD for ID = 19_11. * * *


2024-03-05 15:43:08.491366: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 15:43:11.217229: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 15:43:11.218070: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-05 15:43:11.254251: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-05 15:43:11.254284: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 15:43:11.257136: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 15:43:11.257177: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 15:43:11.259375: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 15:43:11.260096: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 15:43:11.262611: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 15:43:11.264013: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 15:43:11.268505: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 15:43:11.269009: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 15:43:11.269099: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 15:43:12.458977: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-05 15:43:12.460003: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 15:43:12.460766: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-05 15:43:12.460799: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 15:43:12.460868: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 15:43:12.460889: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 15:43:12.460905: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 15:43:12.460923: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 15:43:12.460939: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 15:43:12.460955: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 15:43:12.460972: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 15:43:12.461394: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 15:43:12.461430: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 15:43:13.081363: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-05 15:43:13.081421: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-05 15:43:13.081430: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-05 15:43:13.082286: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:03:00.0, compute capability: 6.1)
{'id': '19_11', 'seed': 11, 'out_folder': 'results/epoch_budget', 'batch_size': 128, 'epochs': 78, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'bootstrapping': False, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/78 [00:00<?, ?epoch/s]2024-03-05 15:43:13.901798: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-05 15:43:13.902239: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199945000 Hz
2024-03-05 15:43:15.835160: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 15:43:16.048083: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 15:43:16.808186: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-05 15:43:16.845325: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|▏         | 1/78 [00:51<1:05:56, 51.38s/epoch, loss=2.67, accuracy=0.472, val_loss=3.58, val_accuracy=0.193, lr=0.1]  3%|▎         | 2/78 [01:12<42:40, 33.69s/epoch, loss=1.41, accuracy=0.634, val_loss=2.61, val_accuracy=0.374, lr=0.1]    4%|▍         | 3/78 [01:33<34:58, 27.98s/epoch, loss=1.3, accuracy=0.678, val_loss=2.34, val_accuracy=0.453, lr=0.1]   5%|▌         | 4/78 [01:54<31:09, 25.27s/epoch, loss=1.26, accuracy=0.697, val_loss=1.74, val_accuracy=0.547, lr=0.1]  6%|▋         | 5/78 [02:16<28:54, 23.77s/epoch, loss=1.24, accuracy=0.713, val_loss=1.96, val_accuracy=0.523, lr=0.1]  8%|▊         | 6/78 [02:37<27:32, 22.95s/epoch, loss=1.22, accuracy=0.718, val_loss=1.86, val_accuracy=0.491, lr=0.1]  9%|▉         | 7/78 [02:58<26:26, 22.35s/epoch, loss=1.21, accuracy=0.724, val_loss=2.21, val_accuracy=0.467, lr=0.1] 10%|█         | 8/78 [03:19<25:35, 21.93s/epoch, loss=1.2, accuracy=0.73, val_loss=2.46, val_accuracy=0.44, lr=0.1]    12%|█▏        | 9/78 [03:40<24:55, 21.67s/epoch, loss=1.19, accuracy=0.732, val_loss=3.69, val_accuracy=0.368, lr=0.0316] 13%|█▎        | 10/78 [04:02<24:40, 21.77s/epoch, loss=1.19, accuracy=0.737, val_loss=2.19, val_accuracy=0.361, lr=0.1]   14%|█▍        | 11/78 [04:23<24:05, 21.57s/epoch, loss=1.19, accuracy=0.737, val_loss=1.87, val_accuracy=0.505, lr=0.1] 15%|█▌        | 12/78 [04:45<23:38, 21.49s/epoch, loss=1.18, accuracy=0.739, val_loss=1.68, val_accuracy=0.561, lr=0.1] 17%|█▋        | 13/78 [05:06<23:10, 21.39s/epoch, loss=1.18, accuracy=0.739, val_loss=2.15, val_accuracy=0.431, lr=0.1] 18%|█▊        | 14/78 [05:27<22:46, 21.35s/epoch, loss=1.17, accuracy=0.742, val_loss=1.86, val_accuracy=0.532, lr=0.1] 19%|█▉        | 15/78 [05:48<22:21, 21.29s/epoch, loss=1.17, accuracy=0.744, val_loss=1.55, val_accuracy=0.606, lr=0.1] 21%|██        | 16/78 [06:09<21:53, 21.19s/epoch, loss=1.16, accuracy=0.745, val_loss=2.15, val_accuracy=0.515, lr=0.1] 22%|██▏       | 17/78 [06:30<21:33, 21.20s/epoch, loss=1.17, accuracy=0.745, val_loss=3.01, val_accuracy=0.458, lr=0.1] 23%|██▎       | 18/78 [06:51<21:10, 21.17s/epoch, loss=1.16, accuracy=0.747, val_loss=2.67, val_accuracy=0.417, lr=0.1] 24%|██▍       | 19/78 [07:13<20:48, 21.17s/epoch, loss=1.16, accuracy=0.748, val_loss=2.21, val_accuracy=0.454, lr=0.1] 26%|██▌       | 20/78 [07:34<20:36, 21.32s/epoch, loss=1.15, accuracy=0.749, val_loss=1.82, val_accuracy=0.534, lr=0.0316] 27%|██▋       | 21/78 [07:56<20:17, 21.35s/epoch, loss=1.16, accuracy=0.747, val_loss=2.4, val_accuracy=0.47, lr=0.1]      28%|██▊       | 22/78 [08:17<19:53, 21.32s/epoch, loss=1.15, accuracy=0.748, val_loss=2.06, val_accuracy=0.527, lr=0.1] 29%|██▉       | 23/78 [08:39<19:42, 21.50s/epoch, loss=1.15, accuracy=0.75, val_loss=1.65, val_accuracy=0.573, lr=0.1]  31%|███       | 24/78 [09:00<19:18, 21.46s/epoch, loss=1.16, accuracy=0.747, val_loss=3.18, val_accuracy=0.393, lr=0.1] 32%|███▏      | 25/78 [09:22<18:56, 21.43s/epoch, loss=1.15, accuracy=0.75, val_loss=3.77, val_accuracy=0.378, lr=0.0316] 33%|███▎      | 26/78 [09:43<18:30, 21.35s/epoch, loss=1.14, accuracy=0.754, val_loss=1.77, val_accuracy=0.597, lr=0.1]   35%|███▍      | 27/78 [10:04<18:07, 21.32s/epoch, loss=1.15, accuracy=0.75, val_loss=2.88, val_accuracy=0.387, lr=0.1]  36%|███▌      | 28/78 [10:25<17:42, 21.24s/epoch, loss=1.15, accuracy=0.751, val_loss=1.91, val_accuracy=0.515, lr=0.1] 37%|███▋      | 29/78 [10:46<17:20, 21.24s/epoch, loss=1.13, accuracy=0.751, val_loss=1.77, val_accuracy=0.551, lr=0.1] 38%|███▊      | 30/78 [11:07<16:57, 21.20s/epoch, loss=1.14, accuracy=0.752, val_loss=1.95, val_accuracy=0.511, lr=0.0316] 40%|███▉      | 31/78 [11:28<16:32, 21.13s/epoch, loss=1.13, accuracy=0.753, val_loss=3.83, val_accuracy=0.368, lr=0.1]    41%|████      | 32/78 [11:50<16:12, 21.15s/epoch, loss=1.13, accuracy=0.756, val_loss=7.26, val_accuracy=0.213, lr=0.1] 42%|████▏     | 33/78 [12:11<15:50, 21.13s/epoch, loss=1.14, accuracy=0.755, val_loss=1.95, val_accuracy=0.516, lr=0.1] 44%|████▎     | 34/78 [12:32<15:29, 21.12s/epoch, loss=1.14, accuracy=0.753, val_loss=1.89, val_accuracy=0.538, lr=0.1] 45%|████▍     | 35/78 [12:53<15:05, 21.06s/epoch, loss=1.13, accuracy=0.754, val_loss=2.12, val_accuracy=0.476, lr=0.0316] 46%|████▌     | 36/78 [13:14<14:43, 21.03s/epoch, loss=1.12, accuracy=0.756, val_loss=1.47, val_accuracy=0.623, lr=0.1]    47%|████▋     | 37/78 [13:35<14:22, 21.03s/epoch, loss=1.13, accuracy=0.756, val_loss=3, val_accuracy=0.296, lr=0.1]    49%|████▊     | 38/78 [13:56<14:00, 21.01s/epoch, loss=1.13, accuracy=0.757, val_loss=1.92, val_accuracy=0.57, lr=0.1] 50%|█████     | 39/78 [14:17<13:39, 21.02s/epoch, loss=1.13, accuracy=0.753, val_loss=3.48, val_accuracy=0.379, lr=0.1] 51%|█████▏    | 40/78 [14:38<13:17, 21.00s/epoch, loss=1.12, accuracy=0.757, val_loss=1.9, val_accuracy=0.498, lr=0.1]  53%|█████▎    | 41/78 [14:59<12:55, 20.97s/epoch, loss=1.13, accuracy=0.756, val_loss=1.98, val_accuracy=0.462, lr=0.0316] 54%|█████▍    | 42/78 [15:20<12:38, 21.06s/epoch, loss=1.12, accuracy=0.759, val_loss=1.98, val_accuracy=0.509, lr=0.1]    55%|█████▌    | 43/78 [15:41<12:15, 21.01s/epoch, loss=1.12, accuracy=0.757, val_loss=1.91, val_accuracy=0.542, lr=0.1] 56%|█████▋    | 44/78 [16:02<11:52, 20.95s/epoch, loss=1.12, accuracy=0.757, val_loss=2.19, val_accuracy=0.473, lr=0.1] 58%|█████▊    | 45/78 [16:23<11:32, 21.00s/epoch, loss=1.12, accuracy=0.758, val_loss=1.77, val_accuracy=0.566, lr=0.1] 59%|█████▉    | 46/78 [16:44<11:10, 20.97s/epoch, loss=1.12, accuracy=0.756, val_loss=2.5, val_accuracy=0.406, lr=0.0316] 60%|██████    | 47/78 [17:05<10:51, 21.01s/epoch, loss=1.12, accuracy=0.756, val_loss=1.91, val_accuracy=0.535, lr=0.1]   62%|██████▏   | 48/78 [17:26<10:32, 21.09s/epoch, loss=1.12, accuracy=0.757, val_loss=1.79, val_accuracy=0.552, lr=0.1] 63%|██████▎   | 49/78 [17:47<10:10, 21.06s/epoch, loss=1.12, accuracy=0.755, val_loss=1.5, val_accuracy=0.631, lr=0.1]  64%|██████▍   | 50/78 [18:08<09:49, 21.04s/epoch, loss=1.12, accuracy=0.756, val_loss=1.97, val_accuracy=0.543, lr=0.1] 65%|██████▌   | 51/78 [18:29<09:26, 20.98s/epoch, loss=1.12, accuracy=0.758, val_loss=4.68, val_accuracy=0.339, lr=0.0316] 67%|██████▋   | 52/78 [18:50<09:06, 21.01s/epoch, loss=1.12, accuracy=0.757, val_loss=2.33, val_accuracy=0.36, lr=0.1]     68%|██████▊   | 53/78 [19:11<08:50, 21.20s/epoch, loss=1.13, accuracy=0.755, val_loss=2.42, val_accuracy=0.436, lr=0.1] 69%|██████▉   | 54/78 [19:34<08:35, 21.47s/epoch, loss=1.11, accuracy=0.76, val_loss=2.95, val_accuracy=0.394, lr=0.1]  71%|███████   | 55/78 [19:54<08:10, 21.31s/epoch, loss=1.12, accuracy=0.759, val_loss=1.73, val_accuracy=0.562, lr=0.1] 72%|███████▏  | 56/78 [20:15<07:46, 21.22s/epoch, loss=1.12, accuracy=0.759, val_loss=1.9, val_accuracy=0.534, lr=0.0316] 73%|███████▎  | 57/78 [20:36<07:24, 21.16s/epoch, loss=1.12, accuracy=0.759, val_loss=1.66, val_accuracy=0.56, lr=0.1]    74%|███████▍  | 58/78 [20:57<07:02, 21.11s/epoch, loss=1.12, accuracy=0.757, val_loss=1.98, val_accuracy=0.529, lr=0.1] 76%|███████▌  | 59/78 [21:19<06:40, 21.10s/epoch, loss=1.11, accuracy=0.76, val_loss=2.7, val_accuracy=0.327, lr=0.1]   77%|███████▋  | 60/78 [21:39<06:18, 21.01s/epoch, loss=1.11, accuracy=0.76, val_loss=2.75, val_accuracy=0.443, lr=0.1] 78%|███████▊  | 61/78 [22:01<05:58, 21.11s/epoch, loss=1.11, accuracy=0.757, val_loss=1.52, val_accuracy=0.641, lr=0.0316] 79%|███████▉  | 62/78 [22:22<05:37, 21.10s/epoch, loss=1.11, accuracy=0.758, val_loss=1.92, val_accuracy=0.484, lr=0.1]    81%|████████  | 63/78 [22:43<05:15, 21.06s/epoch, loss=1.11, accuracy=0.759, val_loss=3.32, val_accuracy=0.3, lr=0.1]   82%|████████▏ | 64/78 [23:04<04:54, 21.02s/epoch, loss=1.12, accuracy=0.759, val_loss=2.83, val_accuracy=0.458, lr=0.1] 83%|████████▎ | 65/78 [23:25<04:32, 20.98s/epoch, loss=1.11, accuracy=0.759, val_loss=1.97, val_accuracy=0.443, lr=0.1] 85%|████████▍ | 66/78 [23:46<04:11, 20.99s/epoch, loss=1.11, accuracy=0.76, val_loss=2.75, val_accuracy=0.363, lr=0.0316] 86%|████████▌ | 67/78 [24:06<03:50, 20.94s/epoch, loss=1.11, accuracy=0.759, val_loss=1.96, val_accuracy=0.561, lr=0.1]   87%|████████▋ | 68/78 [24:27<03:29, 20.90s/epoch, loss=1.12, accuracy=0.759, val_loss=1.27, val_accuracy=0.712, lr=0.1] 88%|████████▊ | 69/78 [24:49<03:09, 21.01s/epoch, loss=1.11, accuracy=0.758, val_loss=3.03, val_accuracy=0.387, lr=0.1] 90%|████████▉ | 70/78 [25:10<02:48, 21.09s/epoch, loss=1.11, accuracy=0.76, val_loss=3.02, val_accuracy=0.326, lr=0.1]  91%|█████████ | 71/78 [25:31<02:27, 21.03s/epoch, loss=1.11, accuracy=0.756, val_loss=2.15, val_accuracy=0.472, lr=0.1] 92%|█████████▏| 72/78 [25:51<02:05, 20.95s/epoch, loss=1.11, accuracy=0.758, val_loss=2.21, val_accuracy=0.414, lr=0.1] 94%|█████████▎| 73/78 [26:12<01:44, 20.93s/epoch, loss=1.11, accuracy=0.758, val_loss=1.74, val_accuracy=0.567, lr=0.0316] 95%|█████████▍| 74/78 [26:33<01:23, 20.90s/epoch, loss=1.11, accuracy=0.76, val_loss=2.45, val_accuracy=0.426, lr=0.1]     96%|█████████▌| 75/78 [26:54<01:02, 20.95s/epoch, loss=1.12, accuracy=0.758, val_loss=2.19, val_accuracy=0.488, lr=0.1] 97%|█████████▋| 76/78 [27:16<00:42, 21.18s/epoch, loss=1.11, accuracy=0.758, val_loss=1.45, val_accuracy=0.645, lr=0.1] 99%|█████████▊| 77/78 [27:37<00:21, 21.09s/epoch, loss=1.11, accuracy=0.761, val_loss=2.51, val_accuracy=0.42, lr=0.1] 100%|██████████| 78/78 [27:58<00:00, 21.09s/epoch, loss=1.11, accuracy=0.761, val_loss=1.67, val_accuracy=0.583, lr=0.0316]100%|██████████| 78/78 [27:58<00:00, 21.52s/epoch, loss=1.11, accuracy=0.761, val_loss=1.67, val_accuracy=0.583, lr=0.0316]
Using real-time data augmentation.
Test score: 1.6725627183914185
Test accuracy: 0.5831999778747559


* * * Run SGD for ID = 19_12. * * *


2024-03-05 16:11:19.083036: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 16:11:43.473661: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 16:11:43.474657: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-05 16:11:43.513542: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-05 16:11:43.513574: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 16:11:43.520469: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 16:11:43.520508: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 16:11:43.524540: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 16:11:43.527172: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 16:11:43.531207: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 16:11:43.534238: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 16:11:43.541861: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 16:11:43.542364: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 16:11:43.542456: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 16:11:44.758430: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-05 16:11:44.759392: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 16:11:44.759815: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-05 16:11:44.759873: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 16:11:44.759906: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 16:11:44.759923: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 16:11:44.759940: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 16:11:44.759957: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 16:11:44.759973: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 16:11:44.759990: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 16:11:44.760007: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 16:11:44.760458: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 16:11:44.760497: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 16:11:45.404234: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-05 16:11:45.404294: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-05 16:11:45.404304: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-05 16:11:45.405162: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:03:00.0, compute capability: 6.1)
{'id': '19_12', 'seed': 12, 'out_folder': 'results/epoch_budget', 'batch_size': 128, 'epochs': 78, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'bootstrapping': False, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/78 [00:00<?, ?epoch/s]2024-03-05 16:11:46.231204: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-05 16:11:46.231618: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199945000 Hz
2024-03-05 16:11:48.148904: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 16:11:48.366108: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 16:11:49.111245: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-05 16:11:49.148049: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|▏         | 1/78 [00:49<1:03:36, 49.57s/epoch, loss=2.79, accuracy=0.431, val_loss=2.46, val_accuracy=0.343, lr=0.1]  3%|▎         | 2/78 [01:11<42:00, 33.16s/epoch, loss=1.43, accuracy=0.619, val_loss=3.92, val_accuracy=0.274, lr=0.1]    4%|▍         | 3/78 [01:33<35:08, 28.12s/epoch, loss=1.29, accuracy=0.682, val_loss=2.11, val_accuracy=0.457, lr=0.1]  5%|▌         | 4/78 [01:54<31:21, 25.42s/epoch, loss=1.24, accuracy=0.703, val_loss=2.51, val_accuracy=0.387, lr=0.1]  6%|▋         | 5/78 [02:15<29:04, 23.90s/epoch, loss=1.23, accuracy=0.714, val_loss=3.6, val_accuracy=0.302, lr=0.1]   8%|▊         | 6/78 [02:37<27:42, 23.09s/epoch, loss=1.22, accuracy=0.722, val_loss=1.66, val_accuracy=0.552, lr=0.1]  9%|▉         | 7/78 [02:58<26:36, 22.48s/epoch, loss=1.2, accuracy=0.728, val_loss=1.92, val_accuracy=0.498, lr=0.1]  10%|█         | 8/78 [03:19<25:43, 22.05s/epoch, loss=1.19, accuracy=0.732, val_loss=1.6, val_accuracy=0.607, lr=0.1] 12%|█▏        | 9/78 [03:41<25:06, 21.84s/epoch, loss=1.18, accuracy=0.736, val_loss=3.28, val_accuracy=0.352, lr=0.1] 13%|█▎        | 10/78 [04:02<24:42, 21.80s/epoch, loss=1.18, accuracy=0.737, val_loss=1.69, val_accuracy=0.581, lr=0.1] 14%|█▍        | 11/78 [04:24<24:08, 21.63s/epoch, loss=1.16, accuracy=0.738, val_loss=2.35, val_accuracy=0.373, lr=0.1] 15%|█▌        | 12/78 [04:45<23:37, 21.48s/epoch, loss=1.17, accuracy=0.74, val_loss=1.78, val_accuracy=0.526, lr=0.1]  17%|█▋        | 13/78 [05:06<23:06, 21.33s/epoch, loss=1.16, accuracy=0.742, val_loss=1.38, val_accuracy=0.667, lr=0.1] 18%|█▊        | 14/78 [05:27<22:38, 21.23s/epoch, loss=1.16, accuracy=0.746, val_loss=1.71, val_accuracy=0.589, lr=0.1] 19%|█▉        | 15/78 [05:48<22:14, 21.18s/epoch, loss=1.16, accuracy=0.744, val_loss=2.2, val_accuracy=0.471, lr=0.1]  21%|██        | 16/78 [06:09<22:01, 21.31s/epoch, loss=1.15, accuracy=0.751, val_loss=1.87, val_accuracy=0.472, lr=0.1] 22%|██▏       | 17/78 [06:30<21:35, 21.24s/epoch, loss=1.15, accuracy=0.746, val_loss=1.62, val_accuracy=0.62, lr=0.1]  23%|██▎       | 18/78 [06:52<21:12, 21.20s/epoch, loss=1.14, accuracy=0.748, val_loss=2.65, val_accuracy=0.36, lr=0.0316] 24%|██▍       | 19/78 [07:13<21:02, 21.40s/epoch, loss=1.14, accuracy=0.748, val_loss=1.83, val_accuracy=0.472, lr=0.1]   26%|██▌       | 20/78 [07:35<20:36, 21.32s/epoch, loss=1.14, accuracy=0.75, val_loss=1.59, val_accuracy=0.614, lr=0.1]  27%|██▋       | 21/78 [07:56<20:22, 21.44s/epoch, loss=1.13, accuracy=0.751, val_loss=1.78, val_accuracy=0.565, lr=0.1] 28%|██▊       | 22/78 [08:18<19:58, 21.40s/epoch, loss=1.14, accuracy=0.751, val_loss=3.09, val_accuracy=0.2, lr=0.1]   29%|██▉       | 23/78 [08:39<19:44, 21.54s/epoch, loss=1.13, accuracy=0.754, val_loss=2.24, val_accuracy=0.392, lr=0.0316] 31%|███       | 24/78 [09:01<19:17, 21.44s/epoch, loss=1.13, accuracy=0.754, val_loss=4.93, val_accuracy=0.244, lr=0.1]    32%|███▏      | 25/78 [09:22<18:53, 21.39s/epoch, loss=1.13, accuracy=0.754, val_loss=1.54, val_accuracy=0.61, lr=0.1]  33%|███▎      | 26/78 [09:43<18:29, 21.34s/epoch, loss=1.13, accuracy=0.756, val_loss=1.64, val_accuracy=0.569, lr=0.1] 35%|███▍      | 27/78 [10:04<18:05, 21.28s/epoch, loss=1.13, accuracy=0.753, val_loss=2.25, val_accuracy=0.462, lr=0.1] 36%|███▌      | 28/78 [10:25<17:40, 21.21s/epoch, loss=1.13, accuracy=0.754, val_loss=1.57, val_accuracy=0.597, lr=0.0316] 37%|███▋      | 29/78 [10:47<17:24, 21.33s/epoch, loss=1.12, accuracy=0.756, val_loss=2.67, val_accuracy=0.405, lr=0.1]    38%|███▊      | 30/78 [11:08<17:01, 21.28s/epoch, loss=1.12, accuracy=0.756, val_loss=1.7, val_accuracy=0.568, lr=0.1]  40%|███▉      | 31/78 [11:29<16:40, 21.28s/epoch, loss=1.12, accuracy=0.757, val_loss=1.79, val_accuracy=0.52, lr=0.1] 41%|████      | 32/78 [11:50<16:14, 21.19s/epoch, loss=1.12, accuracy=0.756, val_loss=1.6, val_accuracy=0.625, lr=0.1] 42%|████▏     | 33/78 [12:12<15:54, 21.21s/epoch, loss=1.12, accuracy=0.757, val_loss=1.8, val_accuracy=0.581, lr=0.0316] 44%|████▎     | 34/78 [12:33<15:30, 21.15s/epoch, loss=1.12, accuracy=0.756, val_loss=1.84, val_accuracy=0.505, lr=0.1]   45%|████▍     | 35/78 [12:54<15:07, 21.09s/epoch, loss=1.12, accuracy=0.757, val_loss=1.92, val_accuracy=0.512, lr=0.1] 46%|████▌     | 36/78 [13:15<14:54, 21.29s/epoch, loss=1.12, accuracy=0.755, val_loss=2.08, val_accuracy=0.437, lr=0.1] 47%|████▋     | 37/78 [13:37<14:34, 21.34s/epoch, loss=1.12, accuracy=0.757, val_loss=2.82, val_accuracy=0.377, lr=0.1] 49%|████▊     | 38/78 [13:58<14:12, 21.31s/epoch, loss=1.12, accuracy=0.758, val_loss=2.56, val_accuracy=0.344, lr=0.0316] 50%|█████     | 39/78 [14:20<13:53, 21.38s/epoch, loss=1.12, accuracy=0.755, val_loss=2.03, val_accuracy=0.469, lr=0.1]    51%|█████▏    | 40/78 [14:41<13:27, 21.26s/epoch, loss=1.11, accuracy=0.76, val_loss=2.23, val_accuracy=0.465, lr=0.1]  53%|█████▎    | 41/78 [15:02<13:06, 21.25s/epoch, loss=1.11, accuracy=0.76, val_loss=5.52, val_accuracy=0.221, lr=0.1] 54%|█████▍    | 42/78 [15:23<12:45, 21.26s/epoch, loss=1.11, accuracy=0.757, val_loss=2.21, val_accuracy=0.439, lr=0.1] 55%|█████▌    | 43/78 [15:44<12:21, 21.19s/epoch, loss=1.12, accuracy=0.757, val_loss=1.89, val_accuracy=0.518, lr=0.0316] 56%|█████▋    | 44/78 [16:05<11:59, 21.17s/epoch, loss=1.11, accuracy=0.76, val_loss=1.74, val_accuracy=0.555, lr=0.1]     58%|█████▊    | 45/78 [16:27<11:40, 21.22s/epoch, loss=1.11, accuracy=0.757, val_loss=1.73, val_accuracy=0.569, lr=0.1] 59%|█████▉    | 46/78 [16:48<11:17, 21.18s/epoch, loss=1.12, accuracy=0.757, val_loss=1.61, val_accuracy=0.607, lr=0.1] 60%|██████    | 47/78 [17:09<10:57, 21.21s/epoch, loss=1.12, accuracy=0.76, val_loss=3.04, val_accuracy=0.368, lr=0.1]  62%|██████▏   | 48/78 [17:30<10:34, 21.15s/epoch, loss=1.12, accuracy=0.757, val_loss=1.82, val_accuracy=0.554, lr=0.0316] 63%|██████▎   | 49/78 [17:52<10:20, 21.41s/epoch, loss=1.11, accuracy=0.76, val_loss=1.72, val_accuracy=0.594, lr=0.1]     64%|██████▍   | 50/78 [18:13<09:57, 21.34s/epoch, loss=1.11, accuracy=0.76, val_loss=2.07, val_accuracy=0.441, lr=0.1] 65%|██████▌   | 51/78 [18:34<09:35, 21.32s/epoch, loss=1.12, accuracy=0.758, val_loss=1.49, val_accuracy=0.66, lr=0.1] 67%|██████▋   | 52/78 [18:55<09:12, 21.24s/epoch, loss=1.11, accuracy=0.76, val_loss=1.88, val_accuracy=0.534, lr=0.1] 68%|██████▊   | 53/78 [19:17<08:53, 21.36s/epoch, loss=1.11, accuracy=0.759, val_loss=2.14, val_accuracy=0.473, lr=0.0316] 69%|██████▉   | 54/78 [19:39<08:34, 21.44s/epoch, loss=1.11, accuracy=0.76, val_loss=2.15, val_accuracy=0.461, lr=0.1]     71%|███████   | 55/78 [20:00<08:11, 21.37s/epoch, loss=1.11, accuracy=0.762, val_loss=2.08, val_accuracy=0.503, lr=0.1] 72%|███████▏  | 56/78 [20:21<07:48, 21.29s/epoch, loss=1.11, accuracy=0.759, val_loss=1.51, val_accuracy=0.608, lr=0.1] 73%|███████▎  | 57/78 [20:43<07:29, 21.42s/epoch, loss=1.11, accuracy=0.758, val_loss=1.65, val_accuracy=0.541, lr=0.1] 74%|███████▍  | 58/78 [21:04<07:07, 21.39s/epoch, loss=1.1, accuracy=0.761, val_loss=2.67, val_accuracy=0.304, lr=0.0316] 76%|███████▌  | 59/78 [21:25<06:45, 21.32s/epoch, loss=1.11, accuracy=0.76, val_loss=2.54, val_accuracy=0.435, lr=0.1]    77%|███████▋  | 60/78 [21:46<06:22, 21.27s/epoch, loss=1.1, accuracy=0.761, val_loss=2.2, val_accuracy=0.479, lr=0.1]  78%|███████▊  | 61/78 [22:08<06:01, 21.25s/epoch, loss=1.11, accuracy=0.762, val_loss=1.89, val_accuracy=0.532, lr=0.1] 79%|███████▉  | 62/78 [22:29<05:42, 21.39s/epoch, loss=1.11, accuracy=0.759, val_loss=1.77, val_accuracy=0.575, lr=0.1] 81%|████████  | 63/78 [22:50<05:19, 21.28s/epoch, loss=1.1, accuracy=0.759, val_loss=2.27, val_accuracy=0.515, lr=0.0316] 82%|████████▏ | 64/78 [23:12<04:57, 21.27s/epoch, loss=1.1, accuracy=0.761, val_loss=2.06, val_accuracy=0.521, lr=0.1]    83%|████████▎ | 65/78 [23:33<04:36, 21.24s/epoch, loss=1.11, accuracy=0.759, val_loss=1.96, val_accuracy=0.497, lr=0.1] 85%|████████▍ | 66/78 [23:55<04:17, 21.43s/epoch, loss=1.11, accuracy=0.758, val_loss=2.38, val_accuracy=0.421, lr=0.1] 86%|████████▌ | 67/78 [24:16<03:55, 21.38s/epoch, loss=1.11, accuracy=0.758, val_loss=2.09, val_accuracy=0.506, lr=0.1] 87%|████████▋ | 68/78 [24:37<03:32, 21.30s/epoch, loss=1.11, accuracy=0.757, val_loss=1.89, val_accuracy=0.534, lr=0.0316] 88%|████████▊ | 69/78 [24:58<03:11, 21.24s/epoch, loss=1.1, accuracy=0.761, val_loss=5.51, val_accuracy=0.232, lr=0.1]     90%|████████▉ | 70/78 [25:19<02:50, 21.25s/epoch, loss=1.11, accuracy=0.759, val_loss=1.94, val_accuracy=0.512, lr=0.1] 91%|█████████ | 71/78 [25:41<02:28, 21.23s/epoch, loss=1.11, accuracy=0.758, val_loss=1.67, val_accuracy=0.58, lr=0.1]  92%|█████████▏| 72/78 [26:02<02:08, 21.40s/epoch, loss=1.1, accuracy=0.76, val_loss=3.26, val_accuracy=0.271, lr=0.1]  94%|█████████▎| 73/78 [26:24<01:46, 21.33s/epoch, loss=1.1, accuracy=0.76, val_loss=1.86, val_accuracy=0.539, lr=0.0316] 95%|█████████▍| 74/78 [26:45<01:25, 21.40s/epoch, loss=1.11, accuracy=0.76, val_loss=1.97, val_accuracy=0.434, lr=0.1]   96%|█████████▌| 75/78 [27:06<01:03, 21.31s/epoch, loss=1.1, accuracy=0.761, val_loss=1.5, val_accuracy=0.626, lr=0.1]  97%|█████████▋| 76/78 [27:27<00:42, 21.28s/epoch, loss=1.1, accuracy=0.761, val_loss=2, val_accuracy=0.526, lr=0.1]   99%|█████████▊| 77/78 [27:49<00:21, 21.24s/epoch, loss=1.1, accuracy=0.762, val_loss=2.26, val_accuracy=0.425, lr=0.1]100%|██████████| 78/78 [28:10<00:00, 21.38s/epoch, loss=1.1, accuracy=0.758, val_loss=2.18, val_accuracy=0.475, lr=0.0316]100%|██████████| 78/78 [28:10<00:00, 21.68s/epoch, loss=1.1, accuracy=0.758, val_loss=2.18, val_accuracy=0.475, lr=0.0316]
Using real-time data augmentation.
Test score: 2.182157278060913
Test accuracy: 0.47540000081062317


* * * Run SGD for ID = 19_13. * * *


2024-03-05 16:40:00.321608: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 16:40:03.011613: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 16:40:03.012628: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-05 16:40:03.054232: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-05 16:40:03.054260: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 16:40:03.056921: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 16:40:03.056963: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 16:40:03.059028: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 16:40:03.059674: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 16:40:03.061940: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 16:40:03.063274: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 16:40:03.067797: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 16:40:03.068272: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 16:40:03.068359: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 16:40:04.279838: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-05 16:40:04.280361: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 16:40:04.281117: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-05 16:40:04.281150: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 16:40:04.281188: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 16:40:04.281205: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 16:40:04.281222: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 16:40:04.281238: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 16:40:04.281255: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 16:40:04.281274: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 16:40:04.281292: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 16:40:04.281710: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 16:40:04.281744: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 16:40:04.906544: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-05 16:40:04.906600: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-05 16:40:04.906616: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-05 16:40:04.907486: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:03:00.0, compute capability: 6.1)
{'id': '19_13', 'seed': 13, 'out_folder': 'results/epoch_budget', 'batch_size': 128, 'epochs': 78, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'bootstrapping': False, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/78 [00:00<?, ?epoch/s]2024-03-05 16:40:05.722245: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-05 16:40:05.722808: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199945000 Hz
2024-03-05 16:40:07.688521: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 16:40:07.979209: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 16:40:08.733899: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-05 16:40:08.772126: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|▏         | 1/78 [00:47<1:01:21, 47.81s/epoch, loss=2.75, accuracy=0.451, val_loss=2.28, val_accuracy=0.37, lr=0.1]  3%|▎         | 2/78 [01:09<41:03, 32.42s/epoch, loss=1.41, accuracy=0.62, val_loss=1.45, val_accuracy=0.61, lr=0.1]     4%|▍         | 3/78 [01:30<34:16, 27.43s/epoch, loss=1.29, accuracy=0.674, val_loss=2.19, val_accuracy=0.407, lr=0.1]  5%|▌         | 4/78 [01:52<30:53, 25.05s/epoch, loss=1.25, accuracy=0.696, val_loss=2.25, val_accuracy=0.396, lr=0.1]  6%|▋         | 5/78 [02:14<29:00, 23.84s/epoch, loss=1.24, accuracy=0.708, val_loss=1.47, val_accuracy=0.598, lr=0.1]  8%|▊         | 6/78 [02:35<27:35, 23.00s/epoch, loss=1.22, accuracy=0.719, val_loss=2.27, val_accuracy=0.419, lr=0.1]  9%|▉         | 7/78 [02:57<26:40, 22.55s/epoch, loss=1.22, accuracy=0.721, val_loss=2.04, val_accuracy=0.445, lr=0.0316] 10%|█         | 8/78 [03:18<25:56, 22.24s/epoch, loss=1.21, accuracy=0.727, val_loss=1.81, val_accuracy=0.526, lr=0.1]    12%|█▏        | 9/78 [03:39<25:16, 21.98s/epoch, loss=1.2, accuracy=0.729, val_loss=1.91, val_accuracy=0.499, lr=0.1]  13%|█▎        | 10/78 [04:01<24:42, 21.81s/epoch, loss=1.19, accuracy=0.732, val_loss=1.71, val_accuracy=0.553, lr=0.1] 14%|█▍        | 11/78 [04:23<24:21, 21.82s/epoch, loss=1.19, accuracy=0.735, val_loss=2.26, val_accuracy=0.513, lr=0.1] 15%|█▌        | 12/78 [04:45<24:01, 21.84s/epoch, loss=1.19, accuracy=0.737, val_loss=3.73, val_accuracy=0.364, lr=0.0316] 17%|█▋        | 13/78 [05:06<23:30, 21.71s/epoch, loss=1.18, accuracy=0.738, val_loss=1.92, val_accuracy=0.541, lr=0.1]    18%|█▊        | 14/78 [05:27<22:59, 21.55s/epoch, loss=1.17, accuracy=0.74, val_loss=3.48, val_accuracy=0.342, lr=0.1]  19%|█▉        | 15/78 [05:49<22:34, 21.51s/epoch, loss=1.17, accuracy=0.74, val_loss=3.66, val_accuracy=0.304, lr=0.1] 21%|██        | 16/78 [06:10<22:14, 21.52s/epoch, loss=1.17, accuracy=0.742, val_loss=2.41, val_accuracy=0.445, lr=0.1] 22%|██▏       | 17/78 [06:32<21:50, 21.48s/epoch, loss=1.16, accuracy=0.748, val_loss=2.07, val_accuracy=0.495, lr=0.0316] 23%|██▎       | 18/78 [06:53<21:26, 21.44s/epoch, loss=1.15, accuracy=0.748, val_loss=2.04, val_accuracy=0.513, lr=0.1]    24%|██▍       | 19/78 [07:15<21:11, 21.55s/epoch, loss=1.16, accuracy=0.745, val_loss=2.16, val_accuracy=0.494, lr=0.1] 26%|██▌       | 20/78 [07:36<20:48, 21.52s/epoch, loss=1.16, accuracy=0.747, val_loss=2.81, val_accuracy=0.32, lr=0.1]  27%|██▋       | 21/78 [07:58<20:26, 21.52s/epoch, loss=1.15, accuracy=0.749, val_loss=1.65, val_accuracy=0.57, lr=0.1] 28%|██▊       | 22/78 [08:19<20:03, 21.50s/epoch, loss=1.15, accuracy=0.749, val_loss=1.65, val_accuracy=0.574, lr=0.0316] 29%|██▉       | 23/78 [08:41<19:44, 21.54s/epoch, loss=1.14, accuracy=0.751, val_loss=2.85, val_accuracy=0.296, lr=0.1]    31%|███       | 24/78 [09:02<19:23, 21.54s/epoch, loss=1.15, accuracy=0.751, val_loss=2.18, val_accuracy=0.527, lr=0.1] 32%|███▏      | 25/78 [09:24<19:01, 21.54s/epoch, loss=1.14, accuracy=0.752, val_loss=2.49, val_accuracy=0.429, lr=0.1] 33%|███▎      | 26/78 [09:45<18:38, 21.51s/epoch, loss=1.15, accuracy=0.748, val_loss=1.5, val_accuracy=0.614, lr=0.1]  35%|███▍      | 27/78 [10:07<18:21, 21.61s/epoch, loss=1.14, accuracy=0.752, val_loss=1.54, val_accuracy=0.638, lr=0.0316] 36%|███▌      | 28/78 [10:29<18:02, 21.65s/epoch, loss=1.14, accuracy=0.754, val_loss=1.94, val_accuracy=0.476, lr=0.1]    37%|███▋      | 29/78 [10:50<17:39, 21.61s/epoch, loss=1.14, accuracy=0.754, val_loss=1.39, val_accuracy=0.668, lr=0.1] 38%|███▊      | 30/78 [11:12<17:14, 21.54s/epoch, loss=1.14, accuracy=0.753, val_loss=1.54, val_accuracy=0.637, lr=0.1] 40%|███▉      | 31/78 [11:33<16:51, 21.52s/epoch, loss=1.14, accuracy=0.755, val_loss=3, val_accuracy=0.371, lr=0.1]    41%|████      | 32/78 [11:55<16:29, 21.51s/epoch, loss=1.14, accuracy=0.753, val_loss=1.67, val_accuracy=0.578, lr=0.1] 42%|████▏     | 33/78 [12:16<16:06, 21.48s/epoch, loss=1.14, accuracy=0.754, val_loss=1.78, val_accuracy=0.544, lr=0.1] 44%|████▎     | 34/78 [12:37<15:42, 21.42s/epoch, loss=1.14, accuracy=0.753, val_loss=2.58, val_accuracy=0.421, lr=0.0316] 45%|████▍     | 35/78 [12:59<15:22, 21.46s/epoch, loss=1.13, accuracy=0.757, val_loss=3.08, val_accuracy=0.328, lr=0.1]    46%|████▌     | 36/78 [13:20<14:59, 21.40s/epoch, loss=1.14, accuracy=0.755, val_loss=2.23, val_accuracy=0.443, lr=0.1] 47%|████▋     | 37/78 [13:42<14:36, 21.39s/epoch, loss=1.14, accuracy=0.754, val_loss=2.15, val_accuracy=0.473, lr=0.1] 49%|████▊     | 38/78 [14:03<14:16, 21.40s/epoch, loss=1.14, accuracy=0.756, val_loss=2.38, val_accuracy=0.459, lr=0.1] 50%|█████     | 39/78 [14:25<13:59, 21.53s/epoch, loss=1.14, accuracy=0.756, val_loss=2.15, val_accuracy=0.448, lr=0.0316] 51%|█████▏    | 40/78 [14:47<13:44, 21.71s/epoch, loss=1.14, accuracy=0.756, val_loss=1.88, val_accuracy=0.532, lr=0.1]    53%|█████▎    | 41/78 [15:09<13:25, 21.76s/epoch, loss=1.13, accuracy=0.756, val_loss=1.95, val_accuracy=0.509, lr=0.1] 54%|█████▍    | 42/78 [15:30<12:57, 21.61s/epoch, loss=1.13, accuracy=0.759, val_loss=2.89, val_accuracy=0.317, lr=0.1] 55%|█████▌    | 43/78 [15:52<12:42, 21.78s/epoch, loss=1.14, accuracy=0.754, val_loss=1.89, val_accuracy=0.519, lr=0.1] 56%|█████▋    | 44/78 [16:14<12:16, 21.65s/epoch, loss=1.13, accuracy=0.755, val_loss=1.94, val_accuracy=0.486, lr=0.0316] 58%|█████▊    | 45/78 [16:35<11:50, 21.52s/epoch, loss=1.13, accuracy=0.757, val_loss=1.96, val_accuracy=0.46, lr=0.1]     59%|█████▉    | 46/78 [16:56<11:27, 21.49s/epoch, loss=1.13, accuracy=0.757, val_loss=2.8, val_accuracy=0.395, lr=0.1] 60%|██████    | 47/78 [17:18<11:05, 21.47s/epoch, loss=1.13, accuracy=0.757, val_loss=3.53, val_accuracy=0.381, lr=0.1] 62%|██████▏   | 48/78 [17:39<10:42, 21.43s/epoch, loss=1.13, accuracy=0.755, val_loss=2.09, val_accuracy=0.508, lr=0.1] 63%|██████▎   | 49/78 [18:01<10:23, 21.48s/epoch, loss=1.13, accuracy=0.757, val_loss=1.72, val_accuracy=0.566, lr=0.0316] 64%|██████▍   | 50/78 [18:22<10:01, 21.49s/epoch, loss=1.13, accuracy=0.754, val_loss=1.99, val_accuracy=0.468, lr=0.1]    65%|██████▌   | 51/78 [18:44<09:42, 21.57s/epoch, loss=1.13, accuracy=0.754, val_loss=1.74, val_accuracy=0.565, lr=0.1] 67%|██████▋   | 52/78 [19:05<09:19, 21.52s/epoch, loss=1.12, accuracy=0.758, val_loss=4.83, val_accuracy=0.213, lr=0.1] 68%|██████▊   | 53/78 [19:27<08:59, 21.57s/epoch, loss=1.13, accuracy=0.757, val_loss=2.62, val_accuracy=0.361, lr=0.1] 69%|██████▉   | 54/78 [19:49<08:39, 21.66s/epoch, loss=1.13, accuracy=0.757, val_loss=2.84, val_accuracy=0.411, lr=0.0316] 71%|███████   | 55/78 [20:10<08:16, 21.57s/epoch, loss=1.13, accuracy=0.757, val_loss=1.97, val_accuracy=0.546, lr=0.1]    72%|███████▏  | 56/78 [20:32<07:56, 21.66s/epoch, loss=1.13, accuracy=0.755, val_loss=2.6, val_accuracy=0.365, lr=0.1]  73%|███████▎  | 57/78 [20:54<07:36, 21.74s/epoch, loss=1.13, accuracy=0.757, val_loss=2.53, val_accuracy=0.434, lr=0.1] 74%|███████▍  | 58/78 [21:15<07:12, 21.63s/epoch, loss=1.12, accuracy=0.758, val_loss=1.71, val_accuracy=0.543, lr=0.1] 76%|███████▌  | 59/78 [21:37<06:49, 21.57s/epoch, loss=1.12, accuracy=0.758, val_loss=1.49, val_accuracy=0.659, lr=0.0316] 77%|███████▋  | 60/78 [21:59<06:29, 21.64s/epoch, loss=1.13, accuracy=0.756, val_loss=1.71, val_accuracy=0.577, lr=0.1]    78%|███████▊  | 61/78 [22:20<06:06, 21.55s/epoch, loss=1.12, accuracy=0.759, val_loss=2.05, val_accuracy=0.507, lr=0.1] 79%|███████▉  | 62/78 [22:42<05:46, 21.66s/epoch, loss=1.13, accuracy=0.757, val_loss=2.62, val_accuracy=0.486, lr=0.1] 81%|████████  | 63/78 [23:04<05:25, 21.73s/epoch, loss=1.12, accuracy=0.758, val_loss=2.13, val_accuracy=0.436, lr=0.1] 82%|████████▏ | 64/78 [23:25<05:02, 21.60s/epoch, loss=1.12, accuracy=0.759, val_loss=2.53, val_accuracy=0.421, lr=0.0316] 83%|████████▎ | 65/78 [23:46<04:39, 21.47s/epoch, loss=1.12, accuracy=0.756, val_loss=1.84, val_accuracy=0.493, lr=0.1]    85%|████████▍ | 66/78 [24:08<04:18, 21.55s/epoch, loss=1.13, accuracy=0.755, val_loss=1.93, val_accuracy=0.558, lr=0.1] 86%|████████▌ | 67/78 [24:29<03:55, 21.43s/epoch, loss=1.12, accuracy=0.759, val_loss=2.68, val_accuracy=0.46, lr=0.1]  87%|████████▋ | 68/78 [24:50<03:33, 21.36s/epoch, loss=1.12, accuracy=0.761, val_loss=6.32, val_accuracy=0.266, lr=0.1] 88%|████████▊ | 69/78 [25:11<03:11, 21.27s/epoch, loss=1.12, accuracy=0.758, val_loss=1.6, val_accuracy=0.583, lr=0.0316] 90%|████████▉ | 70/78 [25:33<02:51, 21.49s/epoch, loss=1.13, accuracy=0.754, val_loss=3.45, val_accuracy=0.365, lr=0.1]   91%|█████████ | 71/78 [25:55<02:30, 21.45s/epoch, loss=1.12, accuracy=0.758, val_loss=4.07, val_accuracy=0.224, lr=0.1] 92%|█████████▏| 72/78 [26:16<02:08, 21.36s/epoch, loss=1.12, accuracy=0.759, val_loss=1.95, val_accuracy=0.516, lr=0.1] 94%|█████████▎| 73/78 [26:37<01:46, 21.27s/epoch, loss=1.12, accuracy=0.759, val_loss=3.61, val_accuracy=0.312, lr=0.1] 95%|█████████▍| 74/78 [26:58<01:25, 21.25s/epoch, loss=1.12, accuracy=0.759, val_loss=2.47, val_accuracy=0.382, lr=0.0316] 96%|█████████▌| 75/78 [27:19<01:03, 21.23s/epoch, loss=1.12, accuracy=0.759, val_loss=2.04, val_accuracy=0.48, lr=0.1]     97%|█████████▋| 76/78 [27:42<00:43, 21.56s/epoch, loss=1.11, accuracy=0.759, val_loss=3.49, val_accuracy=0.252, lr=0.1] 99%|█████████▊| 77/78 [28:03<00:21, 21.48s/epoch, loss=1.12, accuracy=0.759, val_loss=4.43, val_accuracy=0.278, lr=0.1]100%|██████████| 78/78 [28:25<00:00, 21.69s/epoch, loss=1.12, accuracy=0.76, val_loss=1.84, val_accuracy=0.485, lr=0.1] 100%|██████████| 78/78 [28:25<00:00, 21.87s/epoch, loss=1.12, accuracy=0.76, val_loss=1.84, val_accuracy=0.485, lr=0.1]
Using real-time data augmentation.
Test score: 1.8383500576019287
Test accuracy: 0.4851999878883362


* * * Run SGD for ID = 19_14. * * *


2024-03-05 17:08:34.982118: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 17:08:37.645721: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 17:08:37.646796: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-05 17:08:37.687125: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-05 17:08:37.687162: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 17:08:37.689979: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 17:08:37.690020: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 17:08:37.692062: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 17:08:37.693002: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 17:08:37.695302: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 17:08:37.696933: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 17:08:37.701628: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 17:08:37.702109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 17:08:37.702203: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 17:08:38.924300: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-05 17:08:38.925260: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 17:08:38.926053: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-05 17:08:38.926086: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 17:08:38.926124: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 17:08:38.926143: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 17:08:38.926160: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 17:08:38.926177: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 17:08:38.926196: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 17:08:38.926215: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 17:08:38.926235: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 17:08:38.926663: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 17:08:38.926703: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 17:08:39.551138: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-05 17:08:39.551196: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-05 17:08:39.551206: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-05 17:08:39.552101: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:03:00.0, compute capability: 6.1)
{'id': '19_14', 'seed': 14, 'out_folder': 'results/epoch_budget', 'batch_size': 128, 'epochs': 78, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'bootstrapping': False, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/78 [00:00<?, ?epoch/s]2024-03-05 17:08:40.396694: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-05 17:08:40.397095: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199945000 Hz
2024-03-05 17:08:42.320935: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 17:08:42.543538: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 17:08:43.289762: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-05 17:08:43.327748: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|▏         | 1/78 [00:48<1:02:06, 48.40s/epoch, loss=3.28, accuracy=0.284, val_loss=2.16, val_accuracy=0.315, lr=0.1]  3%|▎         | 2/78 [01:10<41:37, 32.86s/epoch, loss=1.58, accuracy=0.528, val_loss=2.4, val_accuracy=0.403, lr=0.1]     4%|▍         | 3/78 [01:32<34:42, 27.76s/epoch, loss=1.36, accuracy=0.639, val_loss=2.3, val_accuracy=0.429, lr=0.1]  5%|▌         | 4/78 [01:53<31:15, 25.34s/epoch, loss=1.28, accuracy=0.68, val_loss=2.49, val_accuracy=0.337, lr=0.1]  6%|▋         | 5/78 [02:15<29:27, 24.21s/epoch, loss=1.26, accuracy=0.7, val_loss=1.88, val_accuracy=0.522, lr=0.1]   8%|▊         | 6/78 [02:37<28:02, 23.36s/epoch, loss=1.24, accuracy=0.711, val_loss=2.08, val_accuracy=0.408, lr=0.1]  9%|▉         | 7/78 [02:59<27:01, 22.83s/epoch, loss=1.24, accuracy=0.715, val_loss=2.32, val_accuracy=0.465, lr=0.1] 10%|█         | 8/78 [03:21<26:12, 22.46s/epoch, loss=1.23, accuracy=0.722, val_loss=2.55, val_accuracy=0.447, lr=0.1] 12%|█▏        | 9/78 [03:42<25:33, 22.22s/epoch, loss=1.22, accuracy=0.726, val_loss=2.37, val_accuracy=0.463, lr=0.1] 13%|█▎        | 10/78 [04:04<24:57, 22.01s/epoch, loss=1.22, accuracy=0.727, val_loss=1.6, val_accuracy=0.586, lr=0.1] 14%|█▍        | 11/78 [04:26<24:36, 22.04s/epoch, loss=1.21, accuracy=0.731, val_loss=1.49, val_accuracy=0.631, lr=0.1] 15%|█▌        | 12/78 [04:48<24:13, 22.03s/epoch, loss=1.2, accuracy=0.732, val_loss=2.96, val_accuracy=0.376, lr=0.1]  17%|█▋        | 13/78 [05:09<23:43, 21.89s/epoch, loss=1.2, accuracy=0.732, val_loss=1.64, val_accuracy=0.566, lr=0.1] 18%|█▊        | 14/78 [05:31<23:15, 21.81s/epoch, loss=1.19, accuracy=0.736, val_loss=1.77, val_accuracy=0.559, lr=0.1] 19%|█▉        | 15/78 [05:53<22:48, 21.72s/epoch, loss=1.2, accuracy=0.736, val_loss=2.11, val_accuracy=0.48, lr=0.1]   21%|██        | 16/78 [06:14<22:22, 21.66s/epoch, loss=1.19, accuracy=0.74, val_loss=1.97, val_accuracy=0.496, lr=0.0316] 22%|██▏       | 17/78 [06:36<22:03, 21.69s/epoch, loss=1.19, accuracy=0.737, val_loss=2.8, val_accuracy=0.404, lr=0.1]    23%|██▎       | 18/78 [06:57<21:38, 21.65s/epoch, loss=1.19, accuracy=0.742, val_loss=1.56, val_accuracy=0.592, lr=0.1] 24%|██▍       | 19/78 [07:19<21:17, 21.65s/epoch, loss=1.18, accuracy=0.742, val_loss=1.53, val_accuracy=0.594, lr=0.1] 26%|██▌       | 20/78 [07:41<20:59, 21.71s/epoch, loss=1.18, accuracy=0.743, val_loss=2.18, val_accuracy=0.48, lr=0.1]  27%|██▋       | 21/78 [08:03<20:48, 21.90s/epoch, loss=1.18, accuracy=0.741, val_loss=2.2, val_accuracy=0.419, lr=0.0316] 28%|██▊       | 22/78 [08:25<20:20, 21.80s/epoch, loss=1.18, accuracy=0.744, val_loss=1.76, val_accuracy=0.576, lr=0.1]   29%|██▉       | 23/78 [08:47<19:58, 21.78s/epoch, loss=1.18, accuracy=0.746, val_loss=2.32, val_accuracy=0.334, lr=0.1] 31%|███       | 24/78 [09:08<19:33, 21.74s/epoch, loss=1.18, accuracy=0.745, val_loss=2.2, val_accuracy=0.435, lr=0.1]  32%|███▏      | 25/78 [09:30<19:16, 21.82s/epoch, loss=1.18, accuracy=0.744, val_loss=1.54, val_accuracy=0.613, lr=0.1] 33%|███▎      | 26/78 [09:52<18:52, 21.78s/epoch, loss=1.17, accuracy=0.745, val_loss=7.13, val_accuracy=0.181, lr=0.0316] 35%|███▍      | 27/78 [10:14<18:34, 21.85s/epoch, loss=1.17, accuracy=0.748, val_loss=3.21, val_accuracy=0.378, lr=0.1]    36%|███▌      | 28/78 [10:36<18:14, 21.89s/epoch, loss=1.17, accuracy=0.748, val_loss=2.17, val_accuracy=0.491, lr=0.1] 37%|███▋      | 29/78 [10:58<17:48, 21.81s/epoch, loss=1.16, accuracy=0.747, val_loss=1.77, val_accuracy=0.523, lr=0.1] 38%|███▊      | 30/78 [11:19<17:24, 21.75s/epoch, loss=1.16, accuracy=0.75, val_loss=1.74, val_accuracy=0.566, lr=0.1]  40%|███▉      | 31/78 [11:42<17:12, 21.96s/epoch, loss=1.17, accuracy=0.748, val_loss=1.95, val_accuracy=0.512, lr=0.0316] 41%|████      | 32/78 [12:03<16:46, 21.87s/epoch, loss=1.17, accuracy=0.747, val_loss=2.87, val_accuracy=0.469, lr=0.1]    42%|████▏     | 33/78 [12:25<16:26, 21.93s/epoch, loss=1.16, accuracy=0.749, val_loss=3.69, val_accuracy=0.343, lr=0.1] 44%|████▎     | 34/78 [12:47<15:59, 21.80s/epoch, loss=1.16, accuracy=0.749, val_loss=1.67, val_accuracy=0.588, lr=0.1] 45%|████▍     | 35/78 [13:09<15:38, 21.83s/epoch, loss=1.16, accuracy=0.748, val_loss=2.08, val_accuracy=0.486, lr=0.1] 46%|████▌     | 36/78 [13:30<15:13, 21.74s/epoch, loss=1.16, accuracy=0.751, val_loss=3.44, val_accuracy=0.431, lr=0.0316] 47%|████▋     | 37/78 [13:52<14:48, 21.68s/epoch, loss=1.16, accuracy=0.749, val_loss=1.79, val_accuracy=0.547, lr=0.1]    49%|████▊     | 38/78 [14:14<14:31, 21.78s/epoch, loss=1.16, accuracy=0.748, val_loss=1.92, val_accuracy=0.509, lr=0.1] 50%|█████     | 39/78 [14:36<14:10, 21.82s/epoch, loss=1.15, accuracy=0.75, val_loss=2.27, val_accuracy=0.479, lr=0.1]  51%|█████▏    | 40/78 [14:57<13:46, 21.75s/epoch, loss=1.15, accuracy=0.753, val_loss=1.37, val_accuracy=0.674, lr=0.1] 53%|█████▎    | 41/78 [15:19<13:21, 21.67s/epoch, loss=1.16, accuracy=0.751, val_loss=2.55, val_accuracy=0.356, lr=0.1] 54%|█████▍    | 42/78 [15:41<13:01, 21.70s/epoch, loss=1.15, accuracy=0.753, val_loss=2.12, val_accuracy=0.442, lr=0.1] 55%|█████▌    | 43/78 [16:02<12:41, 21.74s/epoch, loss=1.16, accuracy=0.751, val_loss=1.53, val_accuracy=0.635, lr=0.1] 56%|█████▋    | 44/78 [16:24<12:16, 21.67s/epoch, loss=1.14, accuracy=0.753, val_loss=2.59, val_accuracy=0.417, lr=0.1] 58%|█████▊    | 45/78 [16:45<11:53, 21.62s/epoch, loss=1.15, accuracy=0.75, val_loss=1.6, val_accuracy=0.605, lr=0.0316] 59%|█████▉    | 46/78 [17:07<11:35, 21.74s/epoch, loss=1.14, accuracy=0.754, val_loss=1.6, val_accuracy=0.613, lr=0.1]   60%|██████    | 47/78 [17:29<11:13, 21.72s/epoch, loss=1.14, accuracy=0.753, val_loss=1.85, val_accuracy=0.5, lr=0.1]  62%|██████▏   | 48/78 [17:51<10:57, 21.91s/epoch, loss=1.14, accuracy=0.753, val_loss=2.19, val_accuracy=0.454, lr=0.1] 63%|██████▎   | 49/78 [18:14<10:36, 21.95s/epoch, loss=1.15, accuracy=0.752, val_loss=4.9, val_accuracy=0.278, lr=0.1]  64%|██████▍   | 50/78 [18:35<10:10, 21.81s/epoch, loss=1.14, accuracy=0.753, val_loss=1.55, val_accuracy=0.623, lr=0.0316] 65%|██████▌   | 51/78 [18:57<09:47, 21.76s/epoch, loss=1.15, accuracy=0.75, val_loss=2.52, val_accuracy=0.448, lr=0.1]     67%|██████▋   | 52/78 [19:18<09:24, 21.72s/epoch, loss=1.14, accuracy=0.755, val_loss=1.59, val_accuracy=0.605, lr=0.1] 68%|██████▊   | 53/78 [19:40<09:00, 21.64s/epoch, loss=1.14, accuracy=0.757, val_loss=1.8, val_accuracy=0.512, lr=0.1]  69%|██████▉   | 54/78 [20:01<08:37, 21.57s/epoch, loss=1.14, accuracy=0.753, val_loss=2.57, val_accuracy=0.34, lr=0.1] 71%|███████   | 55/78 [20:23<08:15, 21.56s/epoch, loss=1.14, accuracy=0.755, val_loss=2.33, val_accuracy=0.454, lr=0.0316] 72%|███████▏  | 56/78 [20:44<07:53, 21.50s/epoch, loss=1.14, accuracy=0.755, val_loss=3.14, val_accuracy=0.31, lr=0.1]     73%|███████▎  | 57/78 [21:06<07:34, 21.62s/epoch, loss=1.14, accuracy=0.756, val_loss=1.61, val_accuracy=0.596, lr=0.1] 74%|███████▍  | 58/78 [21:27<07:11, 21.60s/epoch, loss=1.14, accuracy=0.753, val_loss=1.56, val_accuracy=0.601, lr=0.1] 76%|███████▌  | 59/78 [21:49<06:48, 21.51s/epoch, loss=1.14, accuracy=0.755, val_loss=1.98, val_accuracy=0.492, lr=0.1] 77%|███████▋  | 60/78 [22:10<06:27, 21.54s/epoch, loss=1.13, accuracy=0.757, val_loss=2.3, val_accuracy=0.449, lr=0.0316] 78%|███████▊  | 61/78 [22:32<06:06, 21.55s/epoch, loss=1.14, accuracy=0.755, val_loss=1.75, val_accuracy=0.538, lr=0.1]   79%|███████▉  | 62/78 [22:53<05:44, 21.56s/epoch, loss=1.14, accuracy=0.755, val_loss=1.77, val_accuracy=0.533, lr=0.1] 81%|████████  | 63/78 [23:15<05:22, 21.52s/epoch, loss=1.14, accuracy=0.754, val_loss=5.13, val_accuracy=0.315, lr=0.1] 82%|████████▏ | 64/78 [23:37<05:02, 21.58s/epoch, loss=1.14, accuracy=0.753, val_loss=2.21, val_accuracy=0.468, lr=0.1] 83%|████████▎ | 65/78 [23:59<04:42, 21.72s/epoch, loss=1.14, accuracy=0.753, val_loss=3.89, val_accuracy=0.289, lr=0.0316] 85%|████████▍ | 66/78 [24:20<04:19, 21.64s/epoch, loss=1.14, accuracy=0.756, val_loss=3.47, val_accuracy=0.319, lr=0.1]    86%|████████▌ | 67/78 [24:41<03:57, 21.55s/epoch, loss=1.14, accuracy=0.753, val_loss=2.27, val_accuracy=0.469, lr=0.1] 87%|████████▋ | 68/78 [25:03<03:35, 21.50s/epoch, loss=1.14, accuracy=0.754, val_loss=2.82, val_accuracy=0.312, lr=0.1] 88%|████████▊ | 69/78 [25:24<03:13, 21.53s/epoch, loss=1.13, accuracy=0.76, val_loss=2.29, val_accuracy=0.447, lr=0.1]  90%|████████▉ | 70/78 [25:46<02:52, 21.61s/epoch, loss=1.14, accuracy=0.755, val_loss=1.66, val_accuracy=0.595, lr=0.0316] 91%|█████████ | 71/78 [26:08<02:30, 21.50s/epoch, loss=1.13, accuracy=0.757, val_loss=3.18, val_accuracy=0.366, lr=0.1]    92%|█████████▏| 72/78 [26:29<02:09, 21.64s/epoch, loss=1.14, accuracy=0.755, val_loss=2.31, val_accuracy=0.441, lr=0.1] 94%|█████████▎| 73/78 [26:52<01:49, 21.88s/epoch, loss=1.13, accuracy=0.754, val_loss=2.76, val_accuracy=0.374, lr=0.1] 95%|█████████▍| 74/78 [27:13<01:26, 21.74s/epoch, loss=1.14, accuracy=0.757, val_loss=2.14, val_accuracy=0.518, lr=0.1] 96%|█████████▌| 75/78 [27:35<01:05, 21.72s/epoch, loss=1.14, accuracy=0.755, val_loss=3.91, val_accuracy=0.372, lr=0.0316] 97%|█████████▋| 76/78 [27:57<00:43, 21.77s/epoch, loss=1.14, accuracy=0.756, val_loss=3.18, val_accuracy=0.405, lr=0.1]    99%|█████████▊| 77/78 [28:18<00:21, 21.68s/epoch, loss=1.14, accuracy=0.755, val_loss=2.01, val_accuracy=0.51, lr=0.1] 100%|██████████| 78/78 [28:40<00:00, 21.67s/epoch, loss=1.13, accuracy=0.757, val_loss=1.86, val_accuracy=0.547, lr=0.1]100%|██████████| 78/78 [28:40<00:00, 22.06s/epoch, loss=1.13, accuracy=0.757, val_loss=1.86, val_accuracy=0.547, lr=0.1]
Using real-time data augmentation.
Test score: 1.8608471155166626
Test accuracy: 0.546500027179718


* * * Run SGD for ID = 19_15. * * *


2024-03-05 17:37:25.882619: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 17:37:38.734854: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 17:37:38.735815: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-05 17:37:38.775003: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-05 17:37:38.775039: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 17:37:38.780727: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 17:37:38.780769: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 17:37:38.784601: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 17:37:38.786717: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 17:37:38.790217: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 17:37:38.793323: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 17:37:38.799358: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 17:37:38.799893: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 17:37:38.799986: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 17:37:40.018206: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-05 17:37:40.019131: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 17:37:40.019599: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-05 17:37:40.019632: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 17:37:40.019665: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 17:37:40.019683: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 17:37:40.019700: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 17:37:40.019717: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 17:37:40.019734: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 17:37:40.019751: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 17:37:40.019768: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 17:37:40.020264: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 17:37:40.020300: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 17:37:40.662350: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-05 17:37:40.662401: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-05 17:37:40.662410: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-05 17:37:40.663267: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:03:00.0, compute capability: 6.1)
{'id': '19_15', 'seed': 15, 'out_folder': 'results/epoch_budget', 'batch_size': 128, 'epochs': 78, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'bootstrapping': False, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/78 [00:00<?, ?epoch/s]2024-03-05 17:37:41.500561: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-05 17:37:41.500998: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199945000 Hz
2024-03-05 17:37:43.433416: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 17:37:43.669030: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 17:37:44.427957: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-05 17:37:44.467370: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|▏         | 1/78 [00:45<58:52, 45.87s/epoch, loss=3.17, accuracy=0.272, val_loss=2.86, val_accuracy=0.188, lr=0.1]  3%|▎         | 2/78 [01:07<39:55, 31.52s/epoch, loss=1.57, accuracy=0.519, val_loss=2.35, val_accuracy=0.357, lr=0.1]  4%|▍         | 3/78 [01:28<33:30, 26.81s/epoch, loss=1.34, accuracy=0.636, val_loss=1.67, val_accuracy=0.545, lr=0.1]  5%|▌         | 4/78 [01:49<30:23, 24.65s/epoch, loss=1.28, accuracy=0.682, val_loss=1.8, val_accuracy=0.534, lr=0.1]   6%|▋         | 5/78 [02:11<28:29, 23.41s/epoch, loss=1.25, accuracy=0.701, val_loss=1.9, val_accuracy=0.475, lr=0.1]  8%|▊         | 6/78 [02:32<27:12, 22.67s/epoch, loss=1.23, accuracy=0.712, val_loss=2.83, val_accuracy=0.402, lr=0.1]  9%|▉         | 7/78 [02:53<26:18, 22.23s/epoch, loss=1.22, accuracy=0.719, val_loss=1.71, val_accuracy=0.557, lr=0.1] 10%|█         | 8/78 [03:15<25:37, 21.97s/epoch, loss=1.21, accuracy=0.723, val_loss=1.97, val_accuracy=0.506, lr=0.0316] 12%|█▏        | 9/78 [03:36<25:07, 21.85s/epoch, loss=1.2, accuracy=0.729, val_loss=1.95, val_accuracy=0.486, lr=0.1]     13%|█▎        | 10/78 [03:57<24:30, 21.62s/epoch, loss=1.19, accuracy=0.73, val_loss=1.7, val_accuracy=0.549, lr=0.1] 14%|█▍        | 11/78 [04:19<24:03, 21.55s/epoch, loss=1.19, accuracy=0.732, val_loss=1.91, val_accuracy=0.489, lr=0.1] 15%|█▌        | 12/78 [04:40<23:33, 21.41s/epoch, loss=1.18, accuracy=0.734, val_loss=2.01, val_accuracy=0.51, lr=0.1]  17%|█▋        | 13/78 [05:01<23:07, 21.34s/epoch, loss=1.17, accuracy=0.737, val_loss=1.61, val_accuracy=0.608, lr=0.1] 18%|█▊        | 14/78 [05:22<22:44, 21.32s/epoch, loss=1.18, accuracy=0.739, val_loss=2.98, val_accuracy=0.267, lr=0.1] 19%|█▉        | 15/78 [05:43<22:20, 21.27s/epoch, loss=1.17, accuracy=0.739, val_loss=3.35, val_accuracy=0.258, lr=0.1] 21%|██        | 16/78 [06:05<21:59, 21.28s/epoch, loss=1.16, accuracy=0.743, val_loss=2.33, val_accuracy=0.417, lr=0.1] 22%|██▏       | 17/78 [06:26<21:39, 21.30s/epoch, loss=1.17, accuracy=0.741, val_loss=1.89, val_accuracy=0.534, lr=0.1] 23%|██▎       | 18/78 [06:47<21:19, 21.32s/epoch, loss=1.16, accuracy=0.743, val_loss=1.81, val_accuracy=0.595, lr=0.0316] 24%|██▍       | 19/78 [07:09<21:01, 21.39s/epoch, loss=1.16, accuracy=0.745, val_loss=2.08, val_accuracy=0.44, lr=0.1]     26%|██▌       | 20/78 [07:31<20:46, 21.49s/epoch, loss=1.16, accuracy=0.741, val_loss=4.25, val_accuracy=0.305, lr=0.1] 27%|██▋       | 21/78 [07:52<20:20, 21.42s/epoch, loss=1.16, accuracy=0.746, val_loss=3.07, val_accuracy=0.341, lr=0.1] 28%|██▊       | 22/78 [08:13<19:56, 21.37s/epoch, loss=1.16, accuracy=0.745, val_loss=1.94, val_accuracy=0.526, lr=0.1] 29%|██▉       | 23/78 [08:35<19:36, 21.39s/epoch, loss=1.16, accuracy=0.745, val_loss=1.95, val_accuracy=0.519, lr=0.0316] 31%|███       | 24/78 [08:56<19:16, 21.42s/epoch, loss=1.15, accuracy=0.746, val_loss=2.01, val_accuracy=0.519, lr=0.1]    32%|███▏      | 25/78 [09:17<18:53, 21.39s/epoch, loss=1.15, accuracy=0.747, val_loss=1.59, val_accuracy=0.578, lr=0.1] 33%|███▎      | 26/78 [09:39<18:30, 21.36s/epoch, loss=1.16, accuracy=0.746, val_loss=1.94, val_accuracy=0.478, lr=0.1] 35%|███▍      | 27/78 [10:00<18:15, 21.48s/epoch, loss=1.14, accuracy=0.748, val_loss=2.08, val_accuracy=0.511, lr=0.1] 36%|███▌      | 28/78 [10:22<17:55, 21.51s/epoch, loss=1.15, accuracy=0.747, val_loss=1.81, val_accuracy=0.531, lr=0.1] 37%|███▋      | 29/78 [10:43<17:29, 21.42s/epoch, loss=1.15, accuracy=0.75, val_loss=2.02, val_accuracy=0.538, lr=0.1]  38%|███▊      | 30/78 [11:05<17:11, 21.49s/epoch, loss=1.15, accuracy=0.752, val_loss=1.97, val_accuracy=0.499, lr=0.0316] 40%|███▉      | 31/78 [11:26<16:45, 21.40s/epoch, loss=1.15, accuracy=0.749, val_loss=1.79, val_accuracy=0.548, lr=0.1]    41%|████      | 32/78 [11:47<16:21, 21.33s/epoch, loss=1.14, accuracy=0.75, val_loss=2.66, val_accuracy=0.396, lr=0.1]  42%|████▏     | 33/78 [12:09<15:59, 21.33s/epoch, loss=1.14, accuracy=0.751, val_loss=1.32, val_accuracy=0.678, lr=0.1] 44%|████▎     | 34/78 [12:30<15:42, 21.43s/epoch, loss=1.15, accuracy=0.749, val_loss=1.58, val_accuracy=0.597, lr=0.1] 45%|████▍     | 35/78 [12:52<15:23, 21.47s/epoch, loss=1.14, accuracy=0.75, val_loss=2.28, val_accuracy=0.465, lr=0.1]  46%|████▌     | 36/78 [13:13<14:57, 21.36s/epoch, loss=1.14, accuracy=0.753, val_loss=1.9, val_accuracy=0.533, lr=0.1] 47%|████▋     | 37/78 [13:34<14:32, 21.29s/epoch, loss=1.14, accuracy=0.751, val_loss=1.43, val_accuracy=0.64, lr=0.1] 49%|████▊     | 38/78 [13:56<14:15, 21.38s/epoch, loss=1.14, accuracy=0.752, val_loss=2.54, val_accuracy=0.445, lr=0.0316] 50%|█████     | 39/78 [14:17<13:59, 21.52s/epoch, loss=1.14, accuracy=0.752, val_loss=1.48, val_accuracy=0.643, lr=0.1]    51%|█████▏    | 40/78 [14:39<13:35, 21.45s/epoch, loss=1.14, accuracy=0.751, val_loss=2.77, val_accuracy=0.29, lr=0.1]  53%|█████▎    | 41/78 [15:00<13:10, 21.35s/epoch, loss=1.14, accuracy=0.753, val_loss=1.3, val_accuracy=0.704, lr=0.1] 54%|█████▍    | 42/78 [15:21<12:45, 21.27s/epoch, loss=1.14, accuracy=0.753, val_loss=2.17, val_accuracy=0.346, lr=0.1] 55%|█████▌    | 43/78 [15:42<12:24, 21.27s/epoch, loss=1.13, accuracy=0.751, val_loss=1.82, val_accuracy=0.54, lr=0.1]  56%|█████▋    | 44/78 [16:03<12:01, 21.22s/epoch, loss=1.14, accuracy=0.749, val_loss=1.76, val_accuracy=0.532, lr=0.1] 58%|█████▊    | 45/78 [16:25<11:41, 21.24s/epoch, loss=1.13, accuracy=0.752, val_loss=1.9, val_accuracy=0.504, lr=0.1]  59%|█████▉    | 46/78 [16:46<11:18, 21.19s/epoch, loss=1.13, accuracy=0.753, val_loss=1.72, val_accuracy=0.562, lr=0.0316] 60%|██████    | 47/78 [17:07<10:57, 21.20s/epoch, loss=1.14, accuracy=0.753, val_loss=1.74, val_accuracy=0.554, lr=0.1]    62%|██████▏   | 48/78 [17:28<10:35, 21.19s/epoch, loss=1.14, accuracy=0.753, val_loss=1.94, val_accuracy=0.478, lr=0.1] 63%|██████▎   | 49/78 [17:49<10:15, 21.21s/epoch, loss=1.13, accuracy=0.752, val_loss=1.89, val_accuracy=0.525, lr=0.1] 64%|██████▍   | 50/78 [18:11<09:54, 21.24s/epoch, loss=1.14, accuracy=0.751, val_loss=10.8, val_accuracy=0.176, lr=0.1] 65%|██████▌   | 51/78 [18:32<09:32, 21.21s/epoch, loss=1.13, accuracy=0.754, val_loss=1.6, val_accuracy=0.585, lr=0.0316] 67%|██████▋   | 52/78 [18:53<09:10, 21.18s/epoch, loss=1.14, accuracy=0.752, val_loss=1.62, val_accuracy=0.596, lr=0.1]   68%|██████▊   | 53/78 [19:14<08:49, 21.18s/epoch, loss=1.13, accuracy=0.751, val_loss=4.22, val_accuracy=0.371, lr=0.1] 69%|██████▉   | 54/78 [19:35<08:29, 21.23s/epoch, loss=1.13, accuracy=0.755, val_loss=2.43, val_accuracy=0.422, lr=0.1] 71%|███████   | 55/78 [19:57<08:14, 21.48s/epoch, loss=1.13, accuracy=0.753, val_loss=1.61, val_accuracy=0.612, lr=0.1] 72%|███████▏  | 56/78 [20:19<07:51, 21.42s/epoch, loss=1.14, accuracy=0.753, val_loss=1.73, val_accuracy=0.573, lr=0.0316] 73%|███████▎  | 57/78 [20:40<07:28, 21.34s/epoch, loss=1.13, accuracy=0.755, val_loss=2.7, val_accuracy=0.412, lr=0.1]     74%|███████▍  | 58/78 [21:01<07:07, 21.37s/epoch, loss=1.13, accuracy=0.751, val_loss=1.3, val_accuracy=0.688, lr=0.1] 76%|███████▌  | 59/78 [21:23<06:47, 21.44s/epoch, loss=1.13, accuracy=0.753, val_loss=1.84, val_accuracy=0.536, lr=0.1] 77%|███████▋  | 60/78 [21:44<06:24, 21.38s/epoch, loss=1.13, accuracy=0.755, val_loss=2.59, val_accuracy=0.288, lr=0.1] 78%|███████▊  | 61/78 [22:06<06:04, 21.42s/epoch, loss=1.13, accuracy=0.753, val_loss=1.81, val_accuracy=0.568, lr=0.1] 79%|███████▉  | 62/78 [22:27<05:41, 21.34s/epoch, loss=1.12, accuracy=0.755, val_loss=2.31, val_accuracy=0.425, lr=0.1] 81%|████████  | 63/78 [22:48<05:20, 21.37s/epoch, loss=1.13, accuracy=0.752, val_loss=1.73, val_accuracy=0.573, lr=0.0316] 82%|████████▏ | 64/78 [23:10<04:58, 21.32s/epoch, loss=1.13, accuracy=0.755, val_loss=1.9, val_accuracy=0.493, lr=0.1]     83%|████████▎ | 65/78 [23:31<04:36, 21.23s/epoch, loss=1.13, accuracy=0.753, val_loss=1.84, val_accuracy=0.491, lr=0.1] 85%|████████▍ | 66/78 [23:52<04:14, 21.19s/epoch, loss=1.13, accuracy=0.754, val_loss=1.49, val_accuracy=0.628, lr=0.1] 86%|████████▌ | 67/78 [24:13<03:52, 21.13s/epoch, loss=1.12, accuracy=0.754, val_loss=2.35, val_accuracy=0.475, lr=0.1] 87%|████████▋ | 68/78 [24:34<03:31, 21.18s/epoch, loss=1.13, accuracy=0.754, val_loss=1.76, val_accuracy=0.531, lr=0.0316] 88%|████████▊ | 69/78 [24:55<03:10, 21.21s/epoch, loss=1.12, accuracy=0.754, val_loss=2.03, val_accuracy=0.452, lr=0.1]    90%|████████▉ | 70/78 [25:16<02:49, 21.15s/epoch, loss=1.13, accuracy=0.753, val_loss=1.7, val_accuracy=0.599, lr=0.1]  91%|█████████ | 71/78 [25:37<02:27, 21.09s/epoch, loss=1.13, accuracy=0.753, val_loss=3, val_accuracy=0.251, lr=0.1]   92%|█████████▏| 72/78 [25:58<02:06, 21.06s/epoch, loss=1.13, accuracy=0.756, val_loss=1.67, val_accuracy=0.559, lr=0.1] 94%|█████████▎| 73/78 [26:19<01:45, 21.09s/epoch, loss=1.12, accuracy=0.755, val_loss=2.1, val_accuracy=0.494, lr=0.0316] 95%|█████████▍| 74/78 [26:41<01:24, 21.21s/epoch, loss=1.12, accuracy=0.756, val_loss=2.06, val_accuracy=0.506, lr=0.1]   96%|█████████▌| 75/78 [27:03<01:04, 21.45s/epoch, loss=1.12, accuracy=0.757, val_loss=1.74, val_accuracy=0.555, lr=0.1] 97%|█████████▋| 76/78 [27:25<00:43, 21.66s/epoch, loss=1.12, accuracy=0.755, val_loss=3.34, val_accuracy=0.334, lr=0.1] 99%|█████████▊| 77/78 [27:46<00:21, 21.56s/epoch, loss=1.13, accuracy=0.754, val_loss=2.34, val_accuracy=0.425, lr=0.1]100%|██████████| 78/78 [28:07<00:00, 21.44s/epoch, loss=1.12, accuracy=0.754, val_loss=3.86, val_accuracy=0.301, lr=0.0316]100%|██████████| 78/78 [28:07<00:00, 21.64s/epoch, loss=1.12, accuracy=0.754, val_loss=3.86, val_accuracy=0.301, lr=0.0316]
Using real-time data augmentation.
Test score: 3.856389045715332
Test accuracy: 0.3005000054836273


* * * Run SGD for ID = 19_16. * * *


2024-03-05 18:05:52.909980: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 18:05:55.869605: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 18:05:55.870634: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-05 18:05:55.909707: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-05 18:05:55.909739: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 18:05:55.912229: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 18:05:55.912269: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 18:05:55.914404: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 18:05:55.915488: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 18:05:55.917664: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 18:05:55.919113: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 18:05:55.923381: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 18:05:55.923887: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 18:05:55.923973: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 18:05:57.128898: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-05 18:05:57.129895: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 18:05:57.131989: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-05 18:05:57.132026: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 18:05:57.132061: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 18:05:57.132078: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 18:05:57.132103: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 18:05:57.132121: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 18:05:57.132136: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 18:05:57.132151: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 18:05:57.132166: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 18:05:57.132588: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 18:05:57.132622: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 18:05:57.748506: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-05 18:05:57.748563: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-05 18:05:57.748579: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-05 18:05:57.749420: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:03:00.0, compute capability: 6.1)
{'id': '19_16', 'seed': 16, 'out_folder': 'results/epoch_budget', 'batch_size': 128, 'epochs': 78, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'bootstrapping': False, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/78 [00:00<?, ?epoch/s]2024-03-05 18:05:58.570012: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-05 18:05:58.570566: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199945000 Hz
2024-03-05 18:06:00.530762: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 18:06:00.790290: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 18:06:01.537988: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-05 18:06:01.577603: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|▏         | 1/78 [00:59<1:16:14, 59.40s/epoch, loss=3.12, accuracy=0.29, val_loss=2.06, val_accuracy=0.33, lr=0.1]  3%|▎         | 2/78 [01:20<46:56, 37.06s/epoch, loss=1.57, accuracy=0.53, val_loss=1.89, val_accuracy=0.465, lr=0.1]   4%|▍         | 3/78 [01:41<37:15, 29.81s/epoch, loss=1.34, accuracy=0.644, val_loss=2.43, val_accuracy=0.316, lr=0.1]  5%|▌         | 4/78 [02:03<32:32, 26.38s/epoch, loss=1.28, accuracy=0.679, val_loss=2.37, val_accuracy=0.475, lr=0.1]  6%|▋         | 5/78 [02:24<29:43, 24.43s/epoch, loss=1.24, accuracy=0.7, val_loss=1.88, val_accuracy=0.524, lr=0.1]    8%|▊         | 6/78 [02:45<27:58, 23.31s/epoch, loss=1.23, accuracy=0.707, val_loss=1.9, val_accuracy=0.473, lr=0.1]  9%|▉         | 7/78 [03:06<26:40, 22.55s/epoch, loss=1.21, accuracy=0.717, val_loss=1.81, val_accuracy=0.544, lr=0.1] 10%|█         | 8/78 [03:27<25:42, 22.04s/epoch, loss=1.2, accuracy=0.722, val_loss=2.1, val_accuracy=0.491, lr=0.1]   12%|█▏        | 9/78 [03:48<25:02, 21.78s/epoch, loss=1.2, accuracy=0.724, val_loss=1.66, val_accuracy=0.581, lr=0.1] 13%|█▎        | 10/78 [04:09<24:26, 21.56s/epoch, loss=1.2, accuracy=0.727, val_loss=2.2, val_accuracy=0.438, lr=0.1] 14%|█▍        | 11/78 [04:30<24:01, 21.51s/epoch, loss=1.19, accuracy=0.732, val_loss=2.24, val_accuracy=0.462, lr=0.1] 15%|█▌        | 12/78 [04:51<23:29, 21.36s/epoch, loss=1.19, accuracy=0.732, val_loss=1.51, val_accuracy=0.638, lr=0.1] 17%|█▋        | 13/78 [05:12<22:59, 21.22s/epoch, loss=1.19, accuracy=0.733, val_loss=3.79, val_accuracy=0.309, lr=0.1] 18%|█▊        | 14/78 [05:34<22:41, 21.28s/epoch, loss=1.18, accuracy=0.737, val_loss=2.62, val_accuracy=0.397, lr=0.1] 19%|█▉        | 15/78 [05:55<22:15, 21.21s/epoch, loss=1.18, accuracy=0.737, val_loss=2.74, val_accuracy=0.426, lr=0.1] 21%|██        | 16/78 [06:16<21:50, 21.13s/epoch, loss=1.18, accuracy=0.737, val_loss=2.17, val_accuracy=0.501, lr=0.1] 22%|██▏       | 17/78 [06:37<21:33, 21.20s/epoch, loss=1.18, accuracy=0.739, val_loss=1.63, val_accuracy=0.589, lr=0.0316] 23%|██▎       | 18/78 [06:58<21:12, 21.21s/epoch, loss=1.17, accuracy=0.741, val_loss=3.95, val_accuracy=0.217, lr=0.1]    24%|██▍       | 19/78 [07:19<20:48, 21.17s/epoch, loss=1.17, accuracy=0.742, val_loss=1.68, val_accuracy=0.581, lr=0.1] 26%|██▌       | 20/78 [07:40<20:23, 21.10s/epoch, loss=1.17, accuracy=0.744, val_loss=2.48, val_accuracy=0.45, lr=0.1]  27%|██▋       | 21/78 [08:01<20:04, 21.12s/epoch, loss=1.17, accuracy=0.742, val_loss=2.01, val_accuracy=0.463, lr=0.1] 28%|██▊       | 22/78 [08:22<19:41, 21.09s/epoch, loss=1.16, accuracy=0.745, val_loss=1.69, val_accuracy=0.594, lr=0.0316] 29%|██▉       | 23/78 [08:44<19:19, 21.09s/epoch, loss=1.16, accuracy=0.746, val_loss=3.77, val_accuracy=0.347, lr=0.1]    31%|███       | 24/78 [09:05<18:59, 21.10s/epoch, loss=1.16, accuracy=0.746, val_loss=1.81, val_accuracy=0.529, lr=0.1] 32%|███▏      | 25/78 [09:26<18:38, 21.10s/epoch, loss=1.16, accuracy=0.748, val_loss=1.83, val_accuracy=0.609, lr=0.1] 33%|███▎      | 26/78 [09:47<18:16, 21.09s/epoch, loss=1.16, accuracy=0.746, val_loss=2.97, val_accuracy=0.292, lr=0.1] 35%|███▍      | 27/78 [10:08<17:54, 21.08s/epoch, loss=1.16, accuracy=0.748, val_loss=1.85, val_accuracy=0.545, lr=0.0316] 36%|███▌      | 28/78 [10:29<17:36, 21.13s/epoch, loss=1.15, accuracy=0.748, val_loss=1.79, val_accuracy=0.563, lr=0.1]    37%|███▋      | 29/78 [10:50<17:18, 21.20s/epoch, loss=1.15, accuracy=0.749, val_loss=1.87, val_accuracy=0.512, lr=0.1] 38%|███▊      | 30/78 [11:12<17:02, 21.30s/epoch, loss=1.15, accuracy=0.749, val_loss=2.19, val_accuracy=0.457, lr=0.1] 40%|███▉      | 31/78 [11:33<16:37, 21.22s/epoch, loss=1.15, accuracy=0.748, val_loss=1.72, val_accuracy=0.614, lr=0.1] 41%|████      | 32/78 [11:54<16:15, 21.21s/epoch, loss=1.15, accuracy=0.749, val_loss=2.33, val_accuracy=0.398, lr=0.0316] 42%|████▏     | 33/78 [12:15<15:51, 21.14s/epoch, loss=1.15, accuracy=0.749, val_loss=2.91, val_accuracy=0.391, lr=0.1]    44%|████▎     | 34/78 [12:36<15:27, 21.08s/epoch, loss=1.14, accuracy=0.751, val_loss=2.35, val_accuracy=0.471, lr=0.1] 45%|████▍     | 35/78 [12:57<15:05, 21.06s/epoch, loss=1.14, accuracy=0.751, val_loss=4.77, val_accuracy=0.369, lr=0.1] 46%|████▌     | 36/78 [13:19<14:49, 21.19s/epoch, loss=1.14, accuracy=0.751, val_loss=1.92, val_accuracy=0.541, lr=0.1] 47%|████▋     | 37/78 [13:40<14:31, 21.24s/epoch, loss=1.14, accuracy=0.752, val_loss=1.84, val_accuracy=0.528, lr=0.0316] 49%|████▊     | 38/78 [14:01<14:08, 21.22s/epoch, loss=1.14, accuracy=0.751, val_loss=2.7, val_accuracy=0.371, lr=0.1]     50%|█████     | 39/78 [14:22<13:46, 21.20s/epoch, loss=1.14, accuracy=0.753, val_loss=1.94, val_accuracy=0.555, lr=0.1] 51%|█████▏    | 40/78 [14:43<13:24, 21.17s/epoch, loss=1.13, accuracy=0.753, val_loss=1.58, val_accuracy=0.611, lr=0.1] 53%|█████▎    | 41/78 [15:05<13:06, 21.25s/epoch, loss=1.14, accuracy=0.753, val_loss=1.7, val_accuracy=0.551, lr=0.1]  54%|█████▍    | 42/78 [15:26<12:41, 21.15s/epoch, loss=1.13, accuracy=0.755, val_loss=1.99, val_accuracy=0.459, lr=0.0316] 55%|█████▌    | 43/78 [15:47<12:19, 21.12s/epoch, loss=1.13, accuracy=0.754, val_loss=1.96, val_accuracy=0.482, lr=0.1]    56%|█████▋    | 44/78 [16:08<11:55, 21.06s/epoch, loss=1.14, accuracy=0.752, val_loss=2.84, val_accuracy=0.423, lr=0.1] 58%|█████▊    | 45/78 [16:29<11:34, 21.04s/epoch, loss=1.13, accuracy=0.758, val_loss=1.87, val_accuracy=0.525, lr=0.1] 59%|█████▉    | 46/78 [16:50<11:14, 21.09s/epoch, loss=1.14, accuracy=0.752, val_loss=1.73, val_accuracy=0.531, lr=0.1] 60%|██████    | 47/78 [17:12<10:58, 21.24s/epoch, loss=1.13, accuracy=0.755, val_loss=2.42, val_accuracy=0.426, lr=0.0316] 62%|██████▏   | 48/78 [17:33<10:38, 21.30s/epoch, loss=1.12, accuracy=0.755, val_loss=1.84, val_accuracy=0.49, lr=0.1]     63%|██████▎   | 49/78 [17:54<10:15, 21.23s/epoch, loss=1.12, accuracy=0.756, val_loss=1.8, val_accuracy=0.595, lr=0.1] 64%|██████▍   | 50/78 [18:16<09:56, 21.32s/epoch, loss=1.13, accuracy=0.755, val_loss=3.2, val_accuracy=0.389, lr=0.1] 65%|██████▌   | 51/78 [18:37<09:34, 21.29s/epoch, loss=1.12, accuracy=0.757, val_loss=1.8, val_accuracy=0.509, lr=0.1] 67%|██████▋   | 52/78 [18:58<09:11, 21.22s/epoch, loss=1.12, accuracy=0.755, val_loss=2.03, val_accuracy=0.412, lr=0.0316] 68%|██████▊   | 53/78 [19:19<08:49, 21.16s/epoch, loss=1.12, accuracy=0.756, val_loss=1.55, val_accuracy=0.606, lr=0.1]    69%|██████▉   | 54/78 [19:40<08:28, 21.17s/epoch, loss=1.13, accuracy=0.755, val_loss=1.66, val_accuracy=0.587, lr=0.1] 71%|███████   | 55/78 [20:01<08:08, 21.22s/epoch, loss=1.11, accuracy=0.757, val_loss=1.63, val_accuracy=0.567, lr=0.1] 72%|███████▏  | 56/78 [20:22<07:45, 21.15s/epoch, loss=1.12, accuracy=0.759, val_loss=1.61, val_accuracy=0.617, lr=0.1] 73%|███████▎  | 57/78 [20:43<07:23, 21.13s/epoch, loss=1.12, accuracy=0.756, val_loss=1.64, val_accuracy=0.602, lr=0.0316] 74%|███████▍  | 58/78 [21:05<07:04, 21.25s/epoch, loss=1.12, accuracy=0.756, val_loss=2.45, val_accuracy=0.457, lr=0.1]    76%|███████▌  | 59/78 [21:26<06:42, 21.20s/epoch, loss=1.11, accuracy=0.759, val_loss=2.59, val_accuracy=0.392, lr=0.1] 77%|███████▋  | 60/78 [21:48<06:23, 21.32s/epoch, loss=1.11, accuracy=0.755, val_loss=1.97, val_accuracy=0.543, lr=0.1] 78%|███████▊  | 61/78 [22:09<06:01, 21.24s/epoch, loss=1.11, accuracy=0.755, val_loss=3.04, val_accuracy=0.318, lr=0.1] 79%|███████▉  | 62/78 [22:30<05:38, 21.18s/epoch, loss=1.11, accuracy=0.758, val_loss=1.76, val_accuracy=0.564, lr=0.0316] 81%|████████  | 63/78 [22:51<05:18, 21.25s/epoch, loss=1.11, accuracy=0.76, val_loss=1.67, val_accuracy=0.556, lr=0.1]     82%|████████▏ | 64/78 [23:12<04:56, 21.19s/epoch, loss=1.12, accuracy=0.757, val_loss=1.43, val_accuracy=0.643, lr=0.1] 83%|████████▎ | 65/78 [23:33<04:34, 21.12s/epoch, loss=1.11, accuracy=0.758, val_loss=1.77, val_accuracy=0.556, lr=0.1] 85%|████████▍ | 66/78 [23:55<04:14, 21.21s/epoch, loss=1.12, accuracy=0.757, val_loss=1.79, val_accuracy=0.544, lr=0.1] 86%|████████▌ | 67/78 [24:16<03:52, 21.12s/epoch, loss=1.12, accuracy=0.757, val_loss=2.67, val_accuracy=0.421, lr=0.1] 87%|████████▋ | 68/78 [24:36<03:30, 21.07s/epoch, loss=1.11, accuracy=0.758, val_loss=2.65, val_accuracy=0.417, lr=0.1] 88%|████████▊ | 69/78 [24:57<03:09, 21.03s/epoch, loss=1.11, accuracy=0.757, val_loss=2.58, val_accuracy=0.35, lr=0.0316] 90%|████████▉ | 70/78 [25:20<02:51, 21.42s/epoch, loss=1.11, accuracy=0.758, val_loss=2.27, val_accuracy=0.473, lr=0.1]   91%|█████████ | 71/78 [25:41<02:29, 21.36s/epoch, loss=1.11, accuracy=0.759, val_loss=2.71, val_accuracy=0.409, lr=0.1] 92%|█████████▏| 72/78 [26:02<02:07, 21.28s/epoch, loss=1.11, accuracy=0.759, val_loss=2.78, val_accuracy=0.348, lr=0.1] 94%|█████████▎| 73/78 [26:23<01:45, 21.14s/epoch, loss=1.11, accuracy=0.759, val_loss=2.55, val_accuracy=0.462, lr=0.1] 95%|█████████▍| 74/78 [26:44<01:24, 21.05s/epoch, loss=1.1, accuracy=0.762, val_loss=1.73, val_accuracy=0.522, lr=0.0316] 96%|█████████▌| 75/78 [27:05<01:03, 21.11s/epoch, loss=1.11, accuracy=0.757, val_loss=1.59, val_accuracy=0.612, lr=0.1]   97%|█████████▋| 76/78 [27:26<00:42, 21.09s/epoch, loss=1.11, accuracy=0.758, val_loss=1.48, val_accuracy=0.639, lr=0.1] 99%|█████████▊| 77/78 [27:47<00:21, 21.02s/epoch, loss=1.11, accuracy=0.759, val_loss=3.78, val_accuracy=0.284, lr=0.1]100%|██████████| 78/78 [28:08<00:00, 21.05s/epoch, loss=1.1, accuracy=0.762, val_loss=2.06, val_accuracy=0.442, lr=0.1] 100%|██████████| 78/78 [28:08<00:00, 21.65s/epoch, loss=1.1, accuracy=0.762, val_loss=2.06, val_accuracy=0.442, lr=0.1]
Using real-time data augmentation.
Test score: 2.0646862983703613
Test accuracy: 0.44179999828338623


* * * Run SGD for ID = 19_17. * * *


2024-03-05 18:34:10.883842: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 18:34:13.902609: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 18:34:13.903513: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-05 18:34:13.940891: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-05 18:34:13.940924: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 18:34:13.946245: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 18:34:13.946286: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 18:34:13.949397: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 18:34:13.951470: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 18:34:13.954702: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 18:34:13.957671: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 18:34:13.963133: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 18:34:13.963753: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 18:34:13.963854: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 18:34:15.159723: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-05 18:34:15.160296: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 18:34:15.161101: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-05 18:34:15.161153: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 18:34:15.161188: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 18:34:15.161206: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 18:34:15.161223: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 18:34:15.161241: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 18:34:15.161257: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 18:34:15.161272: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 18:34:15.161288: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 18:34:15.161722: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 18:34:15.161755: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 18:34:15.784167: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-05 18:34:15.784224: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-05 18:34:15.784239: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-05 18:34:15.785136: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:03:00.0, compute capability: 6.1)
{'id': '19_17', 'seed': 17, 'out_folder': 'results/epoch_budget', 'batch_size': 128, 'epochs': 78, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'bootstrapping': False, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/78 [00:00<?, ?epoch/s]2024-03-05 18:34:16.660634: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-05 18:34:16.661094: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199945000 Hz
2024-03-05 18:34:18.602866: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 18:34:18.820554: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 18:34:19.574278: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-05 18:34:19.611234: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|▏         | 1/78 [00:55<1:11:03, 55.36s/epoch, loss=3.42, accuracy=0.323, val_loss=2.3, val_accuracy=0.322, lr=0.1]  3%|▎         | 2/78 [01:16<44:47, 35.36s/epoch, loss=1.6, accuracy=0.518, val_loss=2.64, val_accuracy=0.338, lr=0.1]    4%|▍         | 3/78 [01:37<35:59, 28.80s/epoch, loss=1.38, accuracy=0.622, val_loss=1.89, val_accuracy=0.496, lr=0.1]  5%|▌         | 4/78 [01:58<31:45, 25.75s/epoch, loss=1.3, accuracy=0.67, val_loss=2.14, val_accuracy=0.469, lr=0.1]    6%|▋         | 5/78 [02:19<29:14, 24.04s/epoch, loss=1.26, accuracy=0.695, val_loss=1.86, val_accuracy=0.526, lr=0.1]  8%|▊         | 6/78 [02:40<27:40, 23.07s/epoch, loss=1.24, accuracy=0.709, val_loss=2.42, val_accuracy=0.455, lr=0.1]  9%|▉         | 7/78 [03:02<26:32, 22.43s/epoch, loss=1.23, accuracy=0.716, val_loss=2.29, val_accuracy=0.476, lr=0.1] 10%|█         | 8/78 [03:23<25:39, 21.99s/epoch, loss=1.21, accuracy=0.724, val_loss=2.32, val_accuracy=0.393, lr=0.1] 12%|█▏        | 9/78 [03:44<25:03, 21.78s/epoch, loss=1.21, accuracy=0.727, val_loss=1.93, val_accuracy=0.5, lr=0.1]   13%|█▎        | 10/78 [04:05<24:25, 21.55s/epoch, loss=1.2, accuracy=0.731, val_loss=1.55, val_accuracy=0.606, lr=0.1] 14%|█▍        | 11/78 [04:27<24:02, 21.54s/epoch, loss=1.21, accuracy=0.732, val_loss=2.54, val_accuracy=0.376, lr=0.1] 15%|█▌        | 12/78 [04:48<23:31, 21.38s/epoch, loss=1.21, accuracy=0.734, val_loss=1.86, val_accuracy=0.551, lr=0.1] 17%|█▋        | 13/78 [05:09<23:04, 21.30s/epoch, loss=1.2, accuracy=0.735, val_loss=2.85, val_accuracy=0.388, lr=0.1]  18%|█▊        | 14/78 [05:31<23:05, 21.65s/epoch, loss=1.19, accuracy=0.739, val_loss=2.34, val_accuracy=0.44, lr=0.1] 19%|█▉        | 15/78 [05:52<22:34, 21.51s/epoch, loss=1.19, accuracy=0.739, val_loss=1.48, val_accuracy=0.627, lr=0.1] 21%|██        | 16/78 [06:13<22:03, 21.35s/epoch, loss=1.19, accuracy=0.741, val_loss=1.86, val_accuracy=0.522, lr=0.1] 22%|██▏       | 17/78 [06:34<21:35, 21.24s/epoch, loss=1.18, accuracy=0.743, val_loss=2.5, val_accuracy=0.476, lr=0.1]  23%|██▎       | 18/78 [06:55<21:11, 21.20s/epoch, loss=1.18, accuracy=0.744, val_loss=1.53, val_accuracy=0.614, lr=0.1] 24%|██▍       | 19/78 [07:16<20:45, 21.12s/epoch, loss=1.18, accuracy=0.742, val_loss=1.81, val_accuracy=0.575, lr=0.1] 26%|██▌       | 20/78 [07:37<20:23, 21.09s/epoch, loss=1.17, accuracy=0.743, val_loss=2.31, val_accuracy=0.456, lr=0.0316] 27%|██▋       | 21/78 [07:58<20:02, 21.09s/epoch, loss=1.18, accuracy=0.744, val_loss=2.23, val_accuracy=0.46, lr=0.1]     28%|██▊       | 22/78 [08:20<19:42, 21.11s/epoch, loss=1.17, accuracy=0.746, val_loss=1.74, val_accuracy=0.552, lr=0.1] 29%|██▉       | 23/78 [08:42<19:43, 21.52s/epoch, loss=1.17, accuracy=0.746, val_loss=2.6, val_accuracy=0.361, lr=0.1]  31%|███       | 24/78 [09:03<19:15, 21.40s/epoch, loss=1.17, accuracy=0.746, val_loss=2.13, val_accuracy=0.459, lr=0.1] 32%|███▏      | 25/78 [09:25<18:55, 21.42s/epoch, loss=1.16, accuracy=0.748, val_loss=3.52, val_accuracy=0.349, lr=0.0316] 33%|███▎      | 26/78 [09:46<18:27, 21.31s/epoch, loss=1.16, accuracy=0.746, val_loss=1.5, val_accuracy=0.612, lr=0.1]     35%|███▍      | 27/78 [10:07<18:05, 21.28s/epoch, loss=1.16, accuracy=0.749, val_loss=1.55, val_accuracy=0.615, lr=0.1] 36%|███▌      | 28/78 [10:28<17:40, 21.20s/epoch, loss=1.16, accuracy=0.751, val_loss=2.13, val_accuracy=0.466, lr=0.1] 37%|███▋      | 29/78 [10:49<17:21, 21.26s/epoch, loss=1.16, accuracy=0.748, val_loss=1.91, val_accuracy=0.502, lr=0.1] 38%|███▊      | 30/78 [11:10<16:56, 21.18s/epoch, loss=1.16, accuracy=0.751, val_loss=2.22, val_accuracy=0.542, lr=0.0316] 40%|███▉      | 31/78 [11:32<16:39, 21.26s/epoch, loss=1.16, accuracy=0.752, val_loss=2.57, val_accuracy=0.407, lr=0.1]    41%|████      | 32/78 [11:53<16:14, 21.18s/epoch, loss=1.16, accuracy=0.749, val_loss=1.92, val_accuracy=0.475, lr=0.1] 42%|████▏     | 33/78 [12:14<15:57, 21.27s/epoch, loss=1.16, accuracy=0.751, val_loss=4.17, val_accuracy=0.291, lr=0.1] 44%|████▎     | 34/78 [12:35<15:32, 21.20s/epoch, loss=1.16, accuracy=0.75, val_loss=1.53, val_accuracy=0.648, lr=0.1]  45%|████▍     | 35/78 [12:56<15:09, 21.15s/epoch, loss=1.15, accuracy=0.751, val_loss=2.68, val_accuracy=0.357, lr=0.0316] 46%|████▌     | 36/78 [13:18<14:51, 21.24s/epoch, loss=1.15, accuracy=0.753, val_loss=1.71, val_accuracy=0.584, lr=0.1]    47%|████▋     | 37/78 [13:39<14:29, 21.22s/epoch, loss=1.15, accuracy=0.75, val_loss=1.86, val_accuracy=0.506, lr=0.1]  49%|████▊     | 38/78 [14:00<14:09, 21.24s/epoch, loss=1.15, accuracy=0.754, val_loss=2.38, val_accuracy=0.478, lr=0.1] 50%|█████     | 39/78 [14:21<13:45, 21.17s/epoch, loss=1.14, accuracy=0.753, val_loss=4.4, val_accuracy=0.146, lr=0.1]  51%|█████▏    | 40/78 [14:42<13:21, 21.10s/epoch, loss=1.15, accuracy=0.752, val_loss=2.19, val_accuracy=0.495, lr=0.0316] 53%|█████▎    | 41/78 [15:03<13:02, 21.16s/epoch, loss=1.15, accuracy=0.753, val_loss=2, val_accuracy=0.452, lr=0.1]       54%|█████▍    | 42/78 [15:24<12:38, 21.08s/epoch, loss=1.14, accuracy=0.755, val_loss=1.95, val_accuracy=0.497, lr=0.1] 55%|█████▌    | 43/78 [15:45<12:14, 21.00s/epoch, loss=1.15, accuracy=0.751, val_loss=3.97, val_accuracy=0.258, lr=0.1] 56%|█████▋    | 44/78 [16:06<11:51, 20.94s/epoch, loss=1.14, accuracy=0.752, val_loss=2.07, val_accuracy=0.53, lr=0.1]  58%|█████▊    | 45/78 [16:27<11:29, 20.90s/epoch, loss=1.15, accuracy=0.751, val_loss=1.82, val_accuracy=0.525, lr=0.0316] 59%|█████▉    | 46/78 [16:48<11:10, 20.95s/epoch, loss=1.14, accuracy=0.756, val_loss=3.05, val_accuracy=0.383, lr=0.1]    60%|██████    | 47/78 [17:09<10:49, 20.94s/epoch, loss=1.13, accuracy=0.756, val_loss=2.14, val_accuracy=0.494, lr=0.1] 62%|██████▏   | 48/78 [17:30<10:30, 21.01s/epoch, loss=1.14, accuracy=0.754, val_loss=1.56, val_accuracy=0.618, lr=0.1] 63%|██████▎   | 49/78 [17:51<10:08, 20.99s/epoch, loss=1.14, accuracy=0.752, val_loss=1.63, val_accuracy=0.593, lr=0.1] 64%|██████▍   | 50/78 [18:12<09:46, 20.96s/epoch, loss=1.14, accuracy=0.756, val_loss=1.9, val_accuracy=0.475, lr=0.0316] 65%|██████▌   | 51/78 [18:33<09:25, 20.94s/epoch, loss=1.15, accuracy=0.754, val_loss=2.57, val_accuracy=0.371, lr=0.1]   67%|██████▋   | 52/78 [18:54<09:04, 20.93s/epoch, loss=1.13, accuracy=0.753, val_loss=1.71, val_accuracy=0.542, lr=0.1] 68%|██████▊   | 53/78 [19:15<08:47, 21.11s/epoch, loss=1.14, accuracy=0.754, val_loss=2.48, val_accuracy=0.435, lr=0.1] 69%|██████▉   | 54/78 [19:36<08:25, 21.06s/epoch, loss=1.13, accuracy=0.756, val_loss=2.26, val_accuracy=0.398, lr=0.1] 71%|███████   | 55/78 [19:57<08:05, 21.12s/epoch, loss=1.14, accuracy=0.758, val_loss=2.76, val_accuracy=0.388, lr=0.0316] 72%|███████▏  | 56/78 [20:18<07:44, 21.10s/epoch, loss=1.13, accuracy=0.755, val_loss=1.91, val_accuracy=0.531, lr=0.1]    73%|███████▎  | 57/78 [20:39<07:22, 21.06s/epoch, loss=1.14, accuracy=0.756, val_loss=2.67, val_accuracy=0.31, lr=0.1]  74%|███████▍  | 58/78 [21:00<07:00, 21.03s/epoch, loss=1.13, accuracy=0.755, val_loss=1.9, val_accuracy=0.483, lr=0.1] 76%|███████▌  | 59/78 [21:21<06:39, 21.03s/epoch, loss=1.13, accuracy=0.755, val_loss=1.92, val_accuracy=0.463, lr=0.1] 77%|███████▋  | 60/78 [21:42<06:18, 21.04s/epoch, loss=1.13, accuracy=0.755, val_loss=2.13, val_accuracy=0.563, lr=0.0316] 78%|███████▊  | 61/78 [22:03<05:55, 20.94s/epoch, loss=1.13, accuracy=0.752, val_loss=2.24, val_accuracy=0.418, lr=0.1]    79%|███████▉  | 62/78 [22:24<05:34, 20.93s/epoch, loss=1.13, accuracy=0.755, val_loss=3.16, val_accuracy=0.322, lr=0.1] 81%|████████  | 63/78 [22:45<05:13, 20.91s/epoch, loss=1.14, accuracy=0.754, val_loss=2.29, val_accuracy=0.527, lr=0.1] 82%|████████▏ | 64/78 [23:06<04:52, 20.88s/epoch, loss=1.13, accuracy=0.757, val_loss=2.17, val_accuracy=0.451, lr=0.1] 83%|████████▎ | 65/78 [23:26<04:31, 20.86s/epoch, loss=1.13, accuracy=0.756, val_loss=1.64, val_accuracy=0.631, lr=0.0316] 85%|████████▍ | 66/78 [23:47<04:10, 20.88s/epoch, loss=1.13, accuracy=0.755, val_loss=2.38, val_accuracy=0.326, lr=0.1]    86%|████████▌ | 67/78 [24:08<03:50, 20.94s/epoch, loss=1.13, accuracy=0.755, val_loss=2.13, val_accuracy=0.512, lr=0.1] 87%|████████▋ | 68/78 [24:30<03:30, 21.06s/epoch, loss=1.13, accuracy=0.757, val_loss=1.95, val_accuracy=0.458, lr=0.1] 88%|████████▊ | 69/78 [24:51<03:08, 20.96s/epoch, loss=1.13, accuracy=0.754, val_loss=1.77, val_accuracy=0.547, lr=0.1] 90%|████████▉ | 70/78 [25:11<02:47, 20.92s/epoch, loss=1.13, accuracy=0.756, val_loss=2.25, val_accuracy=0.426, lr=0.0316] 91%|█████████ | 71/78 [25:32<02:26, 20.92s/epoch, loss=1.13, accuracy=0.755, val_loss=1.84, val_accuracy=0.513, lr=0.1]    92%|█████████▏| 72/78 [25:53<02:05, 20.93s/epoch, loss=1.12, accuracy=0.759, val_loss=1.7, val_accuracy=0.562, lr=0.1]  94%|█████████▎| 73/78 [26:14<01:44, 20.94s/epoch, loss=1.12, accuracy=0.757, val_loss=1.73, val_accuracy=0.539, lr=0.1] 95%|█████████▍| 74/78 [26:35<01:23, 20.96s/epoch, loss=1.12, accuracy=0.756, val_loss=2.19, val_accuracy=0.457, lr=0.1] 96%|█████████▌| 75/78 [26:56<01:03, 21.03s/epoch, loss=1.12, accuracy=0.756, val_loss=1.7, val_accuracy=0.561, lr=0.0316] 97%|█████████▋| 76/78 [27:17<00:41, 20.98s/epoch, loss=1.12, accuracy=0.754, val_loss=1.72, val_accuracy=0.62, lr=0.1]    99%|█████████▊| 77/78 [27:38<00:20, 20.92s/epoch, loss=1.12, accuracy=0.756, val_loss=1.94, val_accuracy=0.49, lr=0.1]100%|██████████| 78/78 [27:59<00:00, 20.97s/epoch, loss=1.13, accuracy=0.757, val_loss=1.84, val_accuracy=0.541, lr=0.1]100%|██████████| 78/78 [27:59<00:00, 21.53s/epoch, loss=1.13, accuracy=0.757, val_loss=1.84, val_accuracy=0.541, lr=0.1]
Using real-time data augmentation.
Test score: 1.8447397947311401
Test accuracy: 0.541100025177002


* * * Run SGD for ID = 19_18. * * *


2024-03-05 19:02:19.952528: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 19:02:22.638086: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 19:02:22.638954: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-05 19:02:22.676067: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-05 19:02:22.676099: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 19:02:22.678630: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 19:02:22.678669: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 19:02:22.680623: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 19:02:22.681240: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 19:02:22.683356: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 19:02:22.684782: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 19:02:22.689025: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 19:02:22.689488: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 19:02:22.689578: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 19:02:23.917191: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-05 19:02:23.917687: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 19:02:23.918459: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-05 19:02:23.918490: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 19:02:23.918526: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 19:02:23.918542: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 19:02:23.918557: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 19:02:23.918572: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 19:02:23.918589: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 19:02:23.918606: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 19:02:23.918623: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 19:02:23.919098: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 19:02:23.919135: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 19:02:24.544738: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-05 19:02:24.544793: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-05 19:02:24.544802: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-05 19:02:24.545697: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:03:00.0, compute capability: 6.1)
{'id': '19_18', 'seed': 18, 'out_folder': 'results/epoch_budget', 'batch_size': 128, 'epochs': 78, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'bootstrapping': False, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/78 [00:00<?, ?epoch/s]2024-03-05 19:02:25.360993: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-05 19:02:25.361566: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199945000 Hz
2024-03-05 19:02:27.402585: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 19:02:27.661936: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 19:02:28.433785: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-05 19:02:28.476287: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|▏         | 1/78 [00:48<1:02:45, 48.91s/epoch, loss=3.05, accuracy=0.339, val_loss=2.64, val_accuracy=0.235, lr=0.1]  3%|▎         | 2/78 [01:10<41:31, 32.78s/epoch, loss=1.48, accuracy=0.576, val_loss=2.8, val_accuracy=0.283, lr=0.1]     4%|▍         | 3/78 [01:31<34:18, 27.44s/epoch, loss=1.3, accuracy=0.66, val_loss=1.88, val_accuracy=0.463, lr=0.1]   5%|▌         | 4/78 [01:52<30:50, 25.01s/epoch, loss=1.26, accuracy=0.691, val_loss=1.64, val_accuracy=0.564, lr=0.1]  6%|▋         | 5/78 [02:13<28:45, 23.64s/epoch, loss=1.24, accuracy=0.706, val_loss=2.91, val_accuracy=0.37, lr=0.1]   8%|▊         | 6/78 [02:35<27:21, 22.79s/epoch, loss=1.22, accuracy=0.716, val_loss=1.85, val_accuracy=0.533, lr=0.1]  9%|▉         | 7/78 [02:56<26:19, 22.25s/epoch, loss=1.21, accuracy=0.723, val_loss=2.67, val_accuracy=0.445, lr=0.1] 10%|█         | 8/78 [03:17<25:32, 21.89s/epoch, loss=1.2, accuracy=0.728, val_loss=1.95, val_accuracy=0.478, lr=0.1]  12%|█▏        | 9/78 [03:38<24:55, 21.67s/epoch, loss=1.19, accuracy=0.732, val_loss=4.9, val_accuracy=0.185, lr=0.0316] 13%|█▎        | 10/78 [04:00<24:29, 21.62s/epoch, loss=1.2, accuracy=0.731, val_loss=2.77, val_accuracy=0.417, lr=0.1]   14%|█▍        | 11/78 [04:21<24:00, 21.50s/epoch, loss=1.19, accuracy=0.733, val_loss=1.85, val_accuracy=0.508, lr=0.1] 15%|█▌        | 12/78 [04:42<23:30, 21.37s/epoch, loss=1.17, accuracy=0.74, val_loss=2.49, val_accuracy=0.456, lr=0.1]  17%|█▋        | 13/78 [05:03<23:03, 21.28s/epoch, loss=1.18, accuracy=0.739, val_loss=1.81, val_accuracy=0.58, lr=0.1] 18%|█▊        | 14/78 [05:25<22:48, 21.39s/epoch, loss=1.17, accuracy=0.743, val_loss=3.31, val_accuracy=0.355, lr=0.0316] 19%|█▉        | 15/78 [05:46<22:22, 21.30s/epoch, loss=1.17, accuracy=0.74, val_loss=2.22, val_accuracy=0.393, lr=0.1]     21%|██        | 16/78 [06:07<21:57, 21.25s/epoch, loss=1.17, accuracy=0.741, val_loss=2.71, val_accuracy=0.359, lr=0.1] 22%|██▏       | 17/78 [06:28<21:42, 21.35s/epoch, loss=1.16, accuracy=0.742, val_loss=1.69, val_accuracy=0.603, lr=0.1] 23%|██▎       | 18/78 [06:50<21:18, 21.30s/epoch, loss=1.16, accuracy=0.744, val_loss=1.71, val_accuracy=0.571, lr=0.1] 24%|██▍       | 19/78 [07:11<20:52, 21.22s/epoch, loss=1.16, accuracy=0.744, val_loss=1.85, val_accuracy=0.535, lr=0.0316] 26%|██▌       | 20/78 [07:32<20:28, 21.19s/epoch, loss=1.16, accuracy=0.748, val_loss=1.85, val_accuracy=0.543, lr=0.1]    27%|██▋       | 21/78 [07:53<20:14, 21.31s/epoch, loss=1.16, accuracy=0.745, val_loss=2.22, val_accuracy=0.494, lr=0.1] 28%|██▊       | 22/78 [08:15<19:57, 21.38s/epoch, loss=1.15, accuracy=0.745, val_loss=4.21, val_accuracy=0.3, lr=0.1]   29%|██▉       | 23/78 [08:37<19:40, 21.46s/epoch, loss=1.15, accuracy=0.749, val_loss=1.53, val_accuracy=0.618, lr=0.1] 31%|███       | 24/78 [08:58<19:15, 21.40s/epoch, loss=1.15, accuracy=0.748, val_loss=1.49, val_accuracy=0.628, lr=0.1] 32%|███▏      | 25/78 [09:19<18:50, 21.34s/epoch, loss=1.15, accuracy=0.748, val_loss=2.33, val_accuracy=0.396, lr=0.1] 33%|███▎      | 26/78 [09:40<18:30, 21.36s/epoch, loss=1.14, accuracy=0.75, val_loss=3.9, val_accuracy=0.322, lr=0.1]   35%|███▍      | 27/78 [10:02<18:10, 21.38s/epoch, loss=1.14, accuracy=0.751, val_loss=1.99, val_accuracy=0.506, lr=0.1] 36%|███▌      | 28/78 [10:23<17:46, 21.33s/epoch, loss=1.14, accuracy=0.752, val_loss=1.55, val_accuracy=0.633, lr=0.1] 37%|███▋      | 29/78 [10:44<17:22, 21.27s/epoch, loss=1.14, accuracy=0.753, val_loss=1.61, val_accuracy=0.576, lr=0.0316] 38%|███▊      | 30/78 [11:06<17:02, 21.30s/epoch, loss=1.13, accuracy=0.754, val_loss=2.27, val_accuracy=0.527, lr=0.1]    40%|███▉      | 31/78 [11:27<16:38, 21.25s/epoch, loss=1.12, accuracy=0.755, val_loss=2.23, val_accuracy=0.429, lr=0.1] 41%|████      | 32/78 [11:48<16:22, 21.36s/epoch, loss=1.13, accuracy=0.752, val_loss=1.98, val_accuracy=0.488, lr=0.1] 42%|████▏     | 33/78 [12:09<15:56, 21.26s/epoch, loss=1.13, accuracy=0.755, val_loss=2.56, val_accuracy=0.403, lr=0.1] 44%|████▎     | 34/78 [12:30<15:32, 21.19s/epoch, loss=1.13, accuracy=0.752, val_loss=2.6, val_accuracy=0.335, lr=0.0316] 45%|████▍     | 35/78 [12:51<15:09, 21.16s/epoch, loss=1.12, accuracy=0.754, val_loss=2.92, val_accuracy=0.417, lr=0.1]   46%|████▌     | 36/78 [13:13<14:48, 21.15s/epoch, loss=1.13, accuracy=0.752, val_loss=2.3, val_accuracy=0.446, lr=0.1]  47%|████▋     | 37/78 [13:34<14:29, 21.20s/epoch, loss=1.12, accuracy=0.756, val_loss=3.28, val_accuracy=0.366, lr=0.1] 49%|████▊     | 38/78 [13:55<14:06, 21.16s/epoch, loss=1.12, accuracy=0.754, val_loss=1.98, val_accuracy=0.491, lr=0.1] 50%|█████     | 39/78 [14:16<13:42, 21.10s/epoch, loss=1.12, accuracy=0.755, val_loss=2.38, val_accuracy=0.338, lr=0.0316] 51%|█████▏    | 40/78 [14:37<13:22, 21.13s/epoch, loss=1.12, accuracy=0.754, val_loss=2.23, val_accuracy=0.393, lr=0.1]    53%|█████▎    | 41/78 [14:58<13:00, 21.09s/epoch, loss=1.12, accuracy=0.755, val_loss=1.89, val_accuracy=0.501, lr=0.1] 54%|█████▍    | 42/78 [15:19<12:39, 21.10s/epoch, loss=1.12, accuracy=0.756, val_loss=3.48, val_accuracy=0.245, lr=0.1] 55%|█████▌    | 43/78 [15:41<12:22, 21.22s/epoch, loss=1.12, accuracy=0.757, val_loss=1.95, val_accuracy=0.475, lr=0.1] 56%|█████▋    | 44/78 [16:02<11:59, 21.15s/epoch, loss=1.12, accuracy=0.756, val_loss=1.57, val_accuracy=0.587, lr=0.0316] 58%|█████▊    | 45/78 [16:23<11:38, 21.15s/epoch, loss=1.13, accuracy=0.754, val_loss=1.8, val_accuracy=0.534, lr=0.1]     59%|█████▉    | 46/78 [16:44<11:15, 21.12s/epoch, loss=1.11, accuracy=0.756, val_loss=1.71, val_accuracy=0.537, lr=0.1] 60%|██████    | 47/78 [17:05<10:54, 21.12s/epoch, loss=1.12, accuracy=0.754, val_loss=2.23, val_accuracy=0.45, lr=0.1]  62%|██████▏   | 48/78 [17:27<10:38, 21.28s/epoch, loss=1.12, accuracy=0.755, val_loss=4.15, val_accuracy=0.306, lr=0.1] 63%|██████▎   | 49/78 [17:48<10:15, 21.23s/epoch, loss=1.1, accuracy=0.759, val_loss=2.24, val_accuracy=0.485, lr=0.0316] 64%|██████▍   | 50/78 [18:09<09:55, 21.27s/epoch, loss=1.11, accuracy=0.756, val_loss=2.45, val_accuracy=0.438, lr=0.1]   65%|██████▌   | 51/78 [18:30<09:32, 21.20s/epoch, loss=1.11, accuracy=0.76, val_loss=7.06, val_accuracy=0.143, lr=0.1]  67%|██████▋   | 52/78 [18:51<09:10, 21.16s/epoch, loss=1.11, accuracy=0.757, val_loss=1.75, val_accuracy=0.536, lr=0.1] 68%|██████▊   | 53/78 [19:12<08:48, 21.15s/epoch, loss=1.11, accuracy=0.757, val_loss=3.29, val_accuracy=0.318, lr=0.1] 69%|██████▉   | 54/78 [19:34<08:31, 21.30s/epoch, loss=1.11, accuracy=0.756, val_loss=1.84, val_accuracy=0.523, lr=0.0316] 71%|███████   | 55/78 [19:55<08:08, 21.24s/epoch, loss=1.11, accuracy=0.759, val_loss=2.88, val_accuracy=0.367, lr=0.1]    72%|███████▏  | 56/78 [20:16<07:46, 21.20s/epoch, loss=1.12, accuracy=0.756, val_loss=2.15, val_accuracy=0.458, lr=0.1] 73%|███████▎  | 57/78 [20:37<07:24, 21.14s/epoch, loss=1.12, accuracy=0.756, val_loss=2.33, val_accuracy=0.454, lr=0.1] 74%|███████▍  | 58/78 [20:58<07:03, 21.18s/epoch, loss=1.11, accuracy=0.757, val_loss=2.75, val_accuracy=0.372, lr=0.1] 76%|███████▌  | 59/78 [21:20<06:43, 21.24s/epoch, loss=1.11, accuracy=0.759, val_loss=3.36, val_accuracy=0.293, lr=0.0316] 77%|███████▋  | 60/78 [21:41<06:22, 21.25s/epoch, loss=1.11, accuracy=0.755, val_loss=2.82, val_accuracy=0.378, lr=0.1]    78%|███████▊  | 61/78 [22:03<06:03, 21.36s/epoch, loss=1.11, accuracy=0.756, val_loss=1.7, val_accuracy=0.54, lr=0.1]   79%|███████▉  | 62/78 [22:24<05:40, 21.29s/epoch, loss=1.11, accuracy=0.756, val_loss=2.12, val_accuracy=0.471, lr=0.1] 81%|████████  | 63/78 [22:45<05:18, 21.21s/epoch, loss=1.11, accuracy=0.757, val_loss=1.95, val_accuracy=0.521, lr=0.1] 82%|████████▏ | 64/78 [23:06<04:56, 21.21s/epoch, loss=1.12, accuracy=0.759, val_loss=1.72, val_accuracy=0.589, lr=0.0316] 83%|████████▎ | 65/78 [23:27<04:35, 21.18s/epoch, loss=1.11, accuracy=0.757, val_loss=1.89, val_accuracy=0.514, lr=0.1]    85%|████████▍ | 66/78 [23:48<04:13, 21.11s/epoch, loss=1.11, accuracy=0.757, val_loss=2.94, val_accuracy=0.345, lr=0.1] 86%|████████▌ | 67/78 [24:09<03:51, 21.06s/epoch, loss=1.11, accuracy=0.761, val_loss=1.68, val_accuracy=0.585, lr=0.1] 87%|████████▋ | 68/78 [24:30<03:30, 21.05s/epoch, loss=1.11, accuracy=0.758, val_loss=3.41, val_accuracy=0.21, lr=0.1]  88%|████████▊ | 69/78 [24:51<03:09, 21.01s/epoch, loss=1.1, accuracy=0.758, val_loss=3.43, val_accuracy=0.379, lr=0.0316] 90%|████████▉ | 70/78 [25:12<02:47, 20.96s/epoch, loss=1.11, accuracy=0.758, val_loss=2.07, val_accuracy=0.473, lr=0.1]   91%|█████████ | 71/78 [25:33<02:26, 20.97s/epoch, loss=1.1, accuracy=0.758, val_loss=2.6, val_accuracy=0.471, lr=0.1]   92%|█████████▏| 72/78 [25:54<02:05, 20.95s/epoch, loss=1.1, accuracy=0.76, val_loss=1.96, val_accuracy=0.481, lr=0.1] 94%|█████████▎| 73/78 [26:15<01:45, 21.04s/epoch, loss=1.1, accuracy=0.757, val_loss=2.28, val_accuracy=0.383, lr=0.1] 95%|█████████▍| 74/78 [26:36<01:23, 20.99s/epoch, loss=1.1, accuracy=0.758, val_loss=2.28, val_accuracy=0.394, lr=0.0316] 96%|█████████▌| 75/78 [26:57<01:02, 21.00s/epoch, loss=1.12, accuracy=0.756, val_loss=4.81, val_accuracy=0.254, lr=0.1]   97%|█████████▋| 76/78 [27:18<00:42, 21.10s/epoch, loss=1.11, accuracy=0.758, val_loss=1.95, val_accuracy=0.552, lr=0.1] 99%|█████████▊| 77/78 [27:40<00:21, 21.22s/epoch, loss=1.11, accuracy=0.758, val_loss=2.13, val_accuracy=0.5, lr=0.1]  100%|██████████| 78/78 [28:01<00:00, 21.17s/epoch, loss=1.11, accuracy=0.758, val_loss=4.78, val_accuracy=0.276, lr=0.1]100%|██████████| 78/78 [28:01<00:00, 21.56s/epoch, loss=1.11, accuracy=0.758, val_loss=4.78, val_accuracy=0.276, lr=0.1]
Using real-time data augmentation.
Test score: 4.775252819061279
Test accuracy: 0.2759000062942505


* * * Run SGD for ID = 19_19. * * *


2024-03-05 19:30:31.454685: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 19:30:41.320187: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 19:30:41.321160: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-05 19:30:41.361993: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-05 19:30:41.362025: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 19:30:41.366211: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 19:30:41.366258: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 19:30:41.368724: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 19:30:41.370113: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 19:30:41.372745: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 19:30:41.374937: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 19:30:41.380162: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 19:30:41.380642: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 19:30:41.380728: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 19:30:42.643231: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-05 19:30:42.644248: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 19:30:42.644706: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-05 19:30:42.644737: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 19:30:42.644768: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 19:30:42.644783: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 19:30:42.644798: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 19:30:42.644812: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 19:30:42.644833: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 19:30:42.644866: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 19:30:42.644882: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 19:30:42.645332: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 19:30:42.645369: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 19:30:43.296749: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-05 19:30:43.296814: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-05 19:30:43.296823: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-05 19:30:43.298021: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:03:00.0, compute capability: 6.1)
{'id': '19_19', 'seed': 19, 'out_folder': 'results/epoch_budget', 'batch_size': 128, 'epochs': 78, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'bootstrapping': False, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/78 [00:00<?, ?epoch/s]2024-03-05 19:30:44.136973: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-05 19:30:44.137392: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199945000 Hz
2024-03-05 19:30:46.085969: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 19:30:46.335756: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 19:30:47.165963: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-05 19:30:47.223347: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|▏         | 1/78 [00:53<1:08:12, 53.15s/epoch, loss=2.95, accuracy=0.346, val_loss=2.08, val_accuracy=0.34, lr=0.1]  3%|▎         | 2/78 [01:14<43:25, 34.29s/epoch, loss=1.54, accuracy=0.543, val_loss=1.75, val_accuracy=0.466, lr=0.1]   4%|▍         | 3/78 [01:35<35:15, 28.21s/epoch, loss=1.36, accuracy=0.631, val_loss=2.45, val_accuracy=0.365, lr=0.1]  5%|▌         | 4/78 [01:55<31:10, 25.28s/epoch, loss=1.3, accuracy=0.672, val_loss=2.29, val_accuracy=0.4, lr=0.1]     6%|▋         | 5/78 [02:16<28:45, 23.64s/epoch, loss=1.27, accuracy=0.688, val_loss=1.83, val_accuracy=0.531, lr=0.1]  8%|▊         | 6/78 [02:37<27:10, 22.65s/epoch, loss=1.24, accuracy=0.709, val_loss=1.89, val_accuracy=0.566, lr=0.1]  9%|▉         | 7/78 [02:58<26:12, 22.15s/epoch, loss=1.23, accuracy=0.718, val_loss=2.08, val_accuracy=0.452, lr=0.0316] 10%|█         | 8/78 [03:19<25:20, 21.73s/epoch, loss=1.22, accuracy=0.721, val_loss=1.96, val_accuracy=0.447, lr=0.1]    12%|█▏        | 9/78 [03:40<24:35, 21.38s/epoch, loss=1.2, accuracy=0.729, val_loss=1.85, val_accuracy=0.573, lr=0.1]  13%|█▎        | 10/78 [04:00<24:00, 21.18s/epoch, loss=1.2, accuracy=0.731, val_loss=1.92, val_accuracy=0.529, lr=0.1] 14%|█▍        | 11/78 [04:21<23:30, 21.05s/epoch, loss=1.19, accuracy=0.733, val_loss=2.76, val_accuracy=0.432, lr=0.1] 15%|█▌        | 12/78 [04:42<23:07, 21.02s/epoch, loss=1.18, accuracy=0.736, val_loss=1.57, val_accuracy=0.618, lr=0.1] 17%|█▋        | 13/78 [05:03<22:49, 21.06s/epoch, loss=1.18, accuracy=0.741, val_loss=2.62, val_accuracy=0.429, lr=0.1] 18%|█▊        | 14/78 [05:24<22:21, 20.96s/epoch, loss=1.17, accuracy=0.741, val_loss=2.14, val_accuracy=0.449, lr=0.1] 19%|█▉        | 15/78 [05:45<21:57, 20.91s/epoch, loss=1.17, accuracy=0.743, val_loss=2.07, val_accuracy=0.467, lr=0.1] 21%|██        | 16/78 [06:06<21:36, 20.92s/epoch, loss=1.17, accuracy=0.743, val_loss=1.57, val_accuracy=0.6, lr=0.1]   22%|██▏       | 17/78 [06:26<21:12, 20.86s/epoch, loss=1.16, accuracy=0.745, val_loss=4.49, val_accuracy=0.228, lr=0.1] 23%|██▎       | 18/78 [06:47<20:49, 20.82s/epoch, loss=1.16, accuracy=0.742, val_loss=1.87, val_accuracy=0.562, lr=0.1] 24%|██▍       | 19/78 [07:08<20:26, 20.79s/epoch, loss=1.16, accuracy=0.746, val_loss=1.34, val_accuracy=0.689, lr=0.1] 26%|██▌       | 20/78 [07:29<20:05, 20.79s/epoch, loss=1.15, accuracy=0.751, val_loss=1.8, val_accuracy=0.57, lr=0.1]   27%|██▋       | 21/78 [07:49<19:44, 20.78s/epoch, loss=1.15, accuracy=0.75, val_loss=1.87, val_accuracy=0.514, lr=0.1] 28%|██▊       | 22/78 [08:11<19:40, 21.08s/epoch, loss=1.15, accuracy=0.752, val_loss=4, val_accuracy=0.251, lr=0.1]   29%|██▉       | 23/78 [08:32<19:16, 21.03s/epoch, loss=1.14, accuracy=0.751, val_loss=2.1, val_accuracy=0.46, lr=0.1] 31%|███       | 24/78 [08:53<18:52, 20.98s/epoch, loss=1.14, accuracy=0.75, val_loss=1.58, val_accuracy=0.603, lr=0.0316] 32%|███▏      | 25/78 [09:14<18:29, 20.94s/epoch, loss=1.14, accuracy=0.751, val_loss=1.65, val_accuracy=0.595, lr=0.1]   33%|███▎      | 26/78 [09:34<18:05, 20.88s/epoch, loss=1.14, accuracy=0.75, val_loss=2.34, val_accuracy=0.445, lr=0.1]  35%|███▍      | 27/78 [09:56<17:51, 21.01s/epoch, loss=1.13, accuracy=0.755, val_loss=1.93, val_accuracy=0.491, lr=0.1] 36%|███▌      | 28/78 [10:17<17:34, 21.09s/epoch, loss=1.13, accuracy=0.752, val_loss=2.25, val_accuracy=0.484, lr=0.1] 37%|███▋      | 29/78 [10:38<17:11, 21.05s/epoch, loss=1.13, accuracy=0.754, val_loss=1.43, val_accuracy=0.646, lr=0.0316] 38%|███▊      | 30/78 [10:59<16:44, 20.93s/epoch, loss=1.13, accuracy=0.753, val_loss=1.86, val_accuracy=0.54, lr=0.1]     40%|███▉      | 31/78 [11:19<16:19, 20.85s/epoch, loss=1.13, accuracy=0.756, val_loss=1.31, val_accuracy=0.688, lr=0.1] 41%|████      | 32/78 [11:41<16:09, 21.07s/epoch, loss=1.12, accuracy=0.758, val_loss=1.72, val_accuracy=0.549, lr=0.1] 42%|████▏     | 33/78 [12:02<15:46, 21.03s/epoch, loss=1.13, accuracy=0.756, val_loss=1.51, val_accuracy=0.639, lr=0.1] 44%|████▎     | 34/78 [12:22<15:20, 20.92s/epoch, loss=1.13, accuracy=0.755, val_loss=1.66, val_accuracy=0.581, lr=0.1] 45%|████▍     | 35/78 [12:43<14:55, 20.83s/epoch, loss=1.12, accuracy=0.757, val_loss=2.8, val_accuracy=0.466, lr=0.1]  46%|████▌     | 36/78 [13:05<14:42, 21.01s/epoch, loss=1.12, accuracy=0.756, val_loss=3.29, val_accuracy=0.32, lr=0.0316] 47%|████▋     | 37/78 [13:25<14:16, 20.90s/epoch, loss=1.12, accuracy=0.754, val_loss=1.79, val_accuracy=0.522, lr=0.1]   49%|████▊     | 38/78 [13:46<13:52, 20.82s/epoch, loss=1.12, accuracy=0.756, val_loss=1.7, val_accuracy=0.578, lr=0.1]  50%|█████     | 39/78 [14:06<13:29, 20.76s/epoch, loss=1.12, accuracy=0.756, val_loss=2.17, val_accuracy=0.516, lr=0.1] 51%|█████▏    | 40/78 [14:27<13:06, 20.69s/epoch, loss=1.12, accuracy=0.758, val_loss=3.09, val_accuracy=0.384, lr=0.1] 53%|█████▎    | 41/78 [14:48<12:52, 20.87s/epoch, loss=1.11, accuracy=0.76, val_loss=1.31, val_accuracy=0.702, lr=0.0316] 54%|█████▍    | 42/78 [15:10<12:35, 21.00s/epoch, loss=1.12, accuracy=0.758, val_loss=2.21, val_accuracy=0.457, lr=0.1]   55%|█████▌    | 43/78 [15:31<12:16, 21.04s/epoch, loss=1.11, accuracy=0.759, val_loss=1.98, val_accuracy=0.453, lr=0.1] 56%|█████▋    | 44/78 [15:52<11:55, 21.03s/epoch, loss=1.12, accuracy=0.758, val_loss=3.79, val_accuracy=0.293, lr=0.1] 58%|█████▊    | 45/78 [16:12<11:31, 20.95s/epoch, loss=1.11, accuracy=0.758, val_loss=2.33, val_accuracy=0.37, lr=0.1]  59%|█████▉    | 46/78 [16:33<11:09, 20.92s/epoch, loss=1.11, accuracy=0.758, val_loss=1.65, val_accuracy=0.615, lr=0.0316] 60%|██████    | 47/78 [16:54<10:46, 20.87s/epoch, loss=1.12, accuracy=0.759, val_loss=2.18, val_accuracy=0.466, lr=0.1]    62%|██████▏   | 48/78 [17:15<10:25, 20.86s/epoch, loss=1.12, accuracy=0.756, val_loss=1.86, val_accuracy=0.472, lr=0.1] 63%|██████▎   | 49/78 [17:36<10:03, 20.81s/epoch, loss=1.11, accuracy=0.763, val_loss=2.09, val_accuracy=0.49, lr=0.1]  64%|██████▍   | 50/78 [17:56<09:40, 20.72s/epoch, loss=1.11, accuracy=0.759, val_loss=1.7, val_accuracy=0.553, lr=0.1] 65%|██████▌   | 51/78 [18:17<09:18, 20.68s/epoch, loss=1.11, accuracy=0.757, val_loss=1.73, val_accuracy=0.576, lr=0.0316] 67%|██████▋   | 52/78 [18:37<08:56, 20.64s/epoch, loss=1.11, accuracy=0.759, val_loss=2.08, val_accuracy=0.475, lr=0.1]    68%|██████▊   | 53/78 [18:59<08:42, 20.89s/epoch, loss=1.11, accuracy=0.76, val_loss=2.25, val_accuracy=0.418, lr=0.1]  69%|██████▉   | 54/78 [19:20<08:23, 21.00s/epoch, loss=1.11, accuracy=0.759, val_loss=1.63, val_accuracy=0.586, lr=0.1] 71%|███████   | 55/78 [19:41<08:04, 21.06s/epoch, loss=1.11, accuracy=0.759, val_loss=4.28, val_accuracy=0.164, lr=0.1] 72%|███████▏  | 56/78 [20:02<07:45, 21.15s/epoch, loss=1.11, accuracy=0.76, val_loss=1.63, val_accuracy=0.59, lr=0.0316] 73%|███████▎  | 57/78 [20:23<07:22, 21.06s/epoch, loss=1.11, accuracy=0.759, val_loss=1.55, val_accuracy=0.626, lr=0.1]  74%|███████▍  | 58/78 [20:44<06:58, 20.90s/epoch, loss=1.1, accuracy=0.762, val_loss=2.74, val_accuracy=0.374, lr=0.1]  76%|███████▌  | 59/78 [21:05<06:38, 21.00s/epoch, loss=1.11, accuracy=0.761, val_loss=2.36, val_accuracy=0.388, lr=0.1] 77%|███████▋  | 60/78 [21:26<06:15, 20.89s/epoch, loss=1.1, accuracy=0.762, val_loss=1.64, val_accuracy=0.592, lr=0.1]  78%|███████▊  | 61/78 [21:46<05:53, 20.80s/epoch, loss=1.11, accuracy=0.759, val_loss=2.35, val_accuracy=0.445, lr=0.0316] 79%|███████▉  | 62/78 [22:08<05:34, 20.92s/epoch, loss=1.1, accuracy=0.762, val_loss=2.27, val_accuracy=0.454, lr=0.1]     81%|████████  | 63/78 [22:28<05:11, 20.79s/epoch, loss=1.1, accuracy=0.759, val_loss=5.37, val_accuracy=0.27, lr=0.1]  82%|████████▏ | 64/78 [22:49<04:49, 20.71s/epoch, loss=1.1, accuracy=0.758, val_loss=3.2, val_accuracy=0.368, lr=0.1] 83%|████████▎ | 65/78 [23:10<04:30, 20.80s/epoch, loss=1.1, accuracy=0.761, val_loss=2.12, val_accuracy=0.398, lr=0.1] 85%|████████▍ | 66/78 [23:30<04:09, 20.77s/epoch, loss=1.11, accuracy=0.759, val_loss=1.99, val_accuracy=0.484, lr=0.0316] 86%|████████▌ | 67/78 [23:51<03:48, 20.74s/epoch, loss=1.11, accuracy=0.759, val_loss=1.61, val_accuracy=0.58, lr=0.1]     87%|████████▋ | 68/78 [24:12<03:29, 20.92s/epoch, loss=1.11, accuracy=0.759, val_loss=1.8, val_accuracy=0.53, lr=0.1]  88%|████████▊ | 69/78 [24:33<03:07, 20.83s/epoch, loss=1.1, accuracy=0.761, val_loss=3.11, val_accuracy=0.236, lr=0.1] 90%|████████▉ | 70/78 [24:54<02:46, 20.84s/epoch, loss=1.1, accuracy=0.762, val_loss=2.57, val_accuracy=0.424, lr=0.1] 91%|█████████ | 71/78 [25:14<02:25, 20.77s/epoch, loss=1.1, accuracy=0.757, val_loss=3.3, val_accuracy=0.308, lr=0.0316] 92%|█████████▏| 72/78 [25:35<02:04, 20.74s/epoch, loss=1.1, accuracy=0.761, val_loss=4.71, val_accuracy=0.211, lr=0.1]   94%|█████████▎| 73/78 [25:56<01:43, 20.69s/epoch, loss=1.1, accuracy=0.76, val_loss=2.48, val_accuracy=0.433, lr=0.1]  95%|█████████▍| 74/78 [26:16<01:22, 20.63s/epoch, loss=1.1, accuracy=0.76, val_loss=1.82, val_accuracy=0.563, lr=0.1] 96%|█████████▌| 75/78 [26:37<01:02, 20.68s/epoch, loss=1.1, accuracy=0.76, val_loss=2.72, val_accuracy=0.407, lr=0.1] 97%|█████████▋| 76/78 [26:58<00:41, 20.93s/epoch, loss=1.09, accuracy=0.764, val_loss=1.7, val_accuracy=0.562, lr=0.0316] 99%|█████████▊| 77/78 [27:19<00:20, 20.90s/epoch, loss=1.1, accuracy=0.758, val_loss=1.7, val_accuracy=0.54, lr=0.1]     100%|██████████| 78/78 [27:41<00:00, 21.08s/epoch, loss=1.1, accuracy=0.76, val_loss=2.48, val_accuracy=0.367, lr=0.1]100%|██████████| 78/78 [27:41<00:00, 21.30s/epoch, loss=1.1, accuracy=0.76, val_loss=2.48, val_accuracy=0.367, lr=0.1]
Using real-time data augmentation.
Test score: 2.4804749488830566
Test accuracy: 0.3671000003814697
