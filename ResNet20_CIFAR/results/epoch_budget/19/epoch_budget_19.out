Thu Feb 15 15:13:54 2024       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA TITAN Xp                Off | 00000000:86:00.0 Off |                  N/A |
| 50%   74C    P0              92W / 250W |      0MiB / 12288MiB |      2%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|  No running processes found                                                           |
+---------------------------------------------------------------------------------------+


* * * Run SGD for cluster size = 19. * * *


Budget: 78


* * * Run SGD for ID = 19_1. * * *


2024-02-15 15:13:55.444748: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 15:14:02.943307: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 15:14:02.945200: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-15 15:14:02.976593: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:86:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 15:14:02.976637: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 15:14:03.034976: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 15:14:03.035082: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 15:14:03.065236: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 15:14:03.142447: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 15:14:03.205714: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 15:14:03.244903: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 15:14:03.292136: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 15:14:03.293797: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 15:14:03.293892: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 15:14:05.618715: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-15 15:14:05.619626: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 15:14:05.620120: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:86:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 15:14:05.620154: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 15:14:05.620190: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 15:14:05.620206: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 15:14:05.620222: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 15:14:05.620237: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 15:14:05.620253: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 15:14:05.620268: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 15:14:05.620284: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 15:14:05.620849: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 15:14:05.620892: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 15:14:07.490275: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-15 15:14:07.490359: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-15 15:14:07.490371: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-15 15:14:07.492137: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:86:00.0, compute capability: 6.1)
{'id': 191, 'batch_size': 128, 'epochs': 78, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/78 [00:00<?, ?epoch/s]2024-02-15 15:14:08.270770: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-15 15:14:08.271284: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2100000000 Hz
2024-02-15 15:14:10.116202: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 15:14:10.522819: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 15:14:11.867477: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-15 15:14:11.914547: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|▏         | 1/78 [01:00<1:17:33, 60.44s/epoch, loss=3.22, accuracy=0.253, val_loss=2.38, val_accuracy=0.277, lr=0.1]  3%|▎         | 2/78 [01:26<50:35, 39.94s/epoch, loss=1.64, accuracy=0.481, val_loss=2.13, val_accuracy=0.392, lr=0.1]    4%|▍         | 3/78 [01:50<41:17, 33.03s/epoch, loss=1.41, accuracy=0.596, val_loss=1.64, val_accuracy=0.541, lr=0.1]  5%|▌         | 4/78 [02:16<37:15, 30.21s/epoch, loss=1.29, accuracy=0.664, val_loss=2.16, val_accuracy=0.43, lr=0.1]   6%|▋         | 5/78 [02:41<34:25, 28.29s/epoch, loss=1.26, accuracy=0.692, val_loss=2.07, val_accuracy=0.444, lr=0.1]  8%|▊         | 6/78 [03:07<32:53, 27.41s/epoch, loss=1.23, accuracy=0.705, val_loss=2.72, val_accuracy=0.363, lr=0.1]  9%|▉         | 7/78 [03:32<31:37, 26.72s/epoch, loss=1.22, accuracy=0.714, val_loss=1.96, val_accuracy=0.45, lr=0.1]  10%|█         | 8/78 [03:57<30:37, 26.25s/epoch, loss=1.21, accuracy=0.721, val_loss=1.72, val_accuracy=0.56, lr=0.0316] 12%|█▏        | 9/78 [04:23<29:51, 25.96s/epoch, loss=1.2, accuracy=0.723, val_loss=1.91, val_accuracy=0.46, lr=0.1]     13%|█▎        | 10/78 [04:48<29:12, 25.77s/epoch, loss=1.2, accuracy=0.726, val_loss=2.03, val_accuracy=0.529, lr=0.1] 14%|█▍        | 11/78 [05:13<28:25, 25.45s/epoch, loss=1.2, accuracy=0.732, val_loss=1.79, val_accuracy=0.561, lr=0.1] 15%|█▌        | 12/78 [05:38<27:53, 25.35s/epoch, loss=1.18, accuracy=0.734, val_loss=1.69, val_accuracy=0.577, lr=0.1] 17%|█▋        | 13/78 [06:03<27:24, 25.31s/epoch, loss=1.18, accuracy=0.735, val_loss=2.18, val_accuracy=0.502, lr=0.0316] 18%|█▊        | 14/78 [06:28<26:54, 25.23s/epoch, loss=1.18, accuracy=0.737, val_loss=2.53, val_accuracy=0.448, lr=0.1]    19%|█▉        | 15/78 [06:54<26:34, 25.31s/epoch, loss=1.18, accuracy=0.737, val_loss=2.7, val_accuracy=0.463, lr=0.1]  21%|██        | 16/78 [07:19<26:16, 25.43s/epoch, loss=1.18, accuracy=0.74, val_loss=1.47, val_accuracy=0.65, lr=0.1]  22%|██▏       | 17/78 [07:45<25:47, 25.36s/epoch, loss=1.17, accuracy=0.741, val_loss=2, val_accuracy=0.521, lr=0.1]  23%|██▎       | 18/78 [08:09<25:11, 25.20s/epoch, loss=1.17, accuracy=0.744, val_loss=2.28, val_accuracy=0.382, lr=0.1] 24%|██▍       | 19/78 [08:34<24:40, 25.09s/epoch, loss=1.17, accuracy=0.742, val_loss=1.57, val_accuracy=0.611, lr=0.1] 26%|██▌       | 20/78 [08:59<24:13, 25.05s/epoch, loss=1.17, accuracy=0.744, val_loss=4.84, val_accuracy=0.295, lr=0.1] 27%|██▋       | 21/78 [09:24<23:49, 25.07s/epoch, loss=1.16, accuracy=0.743, val_loss=1.79, val_accuracy=0.564, lr=0.0316] 28%|██▊       | 22/78 [09:49<23:20, 25.01s/epoch, loss=1.16, accuracy=0.747, val_loss=4.13, val_accuracy=0.18, lr=0.1]     29%|██▉       | 23/78 [10:14<22:55, 25.01s/epoch, loss=1.16, accuracy=0.747, val_loss=3.96, val_accuracy=0.328, lr=0.1] 31%|███       | 24/78 [10:39<22:34, 25.09s/epoch, loss=1.16, accuracy=0.748, val_loss=1.72, val_accuracy=0.562, lr=0.1] 32%|███▏      | 25/78 [11:05<22:10, 25.10s/epoch, loss=1.15, accuracy=0.746, val_loss=1.61, val_accuracy=0.577, lr=0.1] 33%|███▎      | 26/78 [11:30<21:52, 25.25s/epoch, loss=1.16, accuracy=0.75, val_loss=1.85, val_accuracy=0.548, lr=0.0316] 35%|███▍      | 27/78 [11:55<21:18, 25.07s/epoch, loss=1.15, accuracy=0.749, val_loss=2.28, val_accuracy=0.547, lr=0.1]   36%|███▌      | 28/78 [12:21<21:12, 25.45s/epoch, loss=1.16, accuracy=0.751, val_loss=3.76, val_accuracy=0.401, lr=0.1] 37%|███▋      | 29/78 [12:47<20:52, 25.55s/epoch, loss=1.16, accuracy=0.751, val_loss=1.62, val_accuracy=0.605, lr=0.1] 38%|███▊      | 30/78 [13:12<20:21, 25.45s/epoch, loss=1.15, accuracy=0.751, val_loss=2.77, val_accuracy=0.445, lr=0.1] 40%|███▉      | 31/78 [13:37<19:49, 25.32s/epoch, loss=1.15, accuracy=0.752, val_loss=2.62, val_accuracy=0.404, lr=0.0316] 41%|████      | 32/78 [14:02<19:23, 25.29s/epoch, loss=1.15, accuracy=0.75, val_loss=2.14, val_accuracy=0.43, lr=0.1]      42%|████▏     | 33/78 [14:28<18:59, 25.32s/epoch, loss=1.15, accuracy=0.752, val_loss=2.1, val_accuracy=0.412, lr=0.1] 44%|████▎     | 34/78 [14:53<18:36, 25.39s/epoch, loss=1.15, accuracy=0.751, val_loss=3.73, val_accuracy=0.31, lr=0.1] 45%|████▍     | 35/78 [15:18<18:05, 25.24s/epoch, loss=1.15, accuracy=0.752, val_loss=3.27, val_accuracy=0.392, lr=0.1] 46%|████▌     | 36/78 [15:44<17:44, 25.34s/epoch, loss=1.15, accuracy=0.749, val_loss=2.75, val_accuracy=0.46, lr=0.0316] 47%|████▋     | 37/78 [16:09<17:13, 25.21s/epoch, loss=1.14, accuracy=0.752, val_loss=1.96, val_accuracy=0.556, lr=0.1]   49%|████▊     | 38/78 [16:34<16:49, 25.25s/epoch, loss=1.14, accuracy=0.751, val_loss=1.46, val_accuracy=0.632, lr=0.1] 50%|█████     | 39/78 [16:59<16:25, 25.28s/epoch, loss=1.14, accuracy=0.753, val_loss=1.99, val_accuracy=0.549, lr=0.1] 51%|█████▏    | 40/78 [17:25<16:03, 25.36s/epoch, loss=1.14, accuracy=0.754, val_loss=2.68, val_accuracy=0.48, lr=0.1]  53%|█████▎    | 41/78 [17:49<15:22, 24.94s/epoch, loss=1.14, accuracy=0.755, val_loss=2.54, val_accuracy=0.284, lr=0.1] 54%|█████▍    | 42/78 [18:14<15:03, 25.11s/epoch, loss=1.14, accuracy=0.753, val_loss=1.42, val_accuracy=0.657, lr=0.1] 55%|█████▌    | 43/78 [18:41<14:51, 25.46s/epoch, loss=1.15, accuracy=0.75, val_loss=1.74, val_accuracy=0.58, lr=0.1]   56%|█████▋    | 44/78 [19:06<14:21, 25.33s/epoch, loss=1.14, accuracy=0.751, val_loss=1.81, val_accuracy=0.589, lr=0.1] 58%|█████▊    | 45/78 [19:30<13:48, 25.10s/epoch, loss=1.14, accuracy=0.754, val_loss=1.53, val_accuracy=0.62, lr=0.1]  59%|█████▉    | 46/78 [19:55<13:23, 25.11s/epoch, loss=1.14, accuracy=0.753, val_loss=1.88, val_accuracy=0.475, lr=0.1] 60%|██████    | 47/78 [20:20<12:57, 25.07s/epoch, loss=1.14, accuracy=0.755, val_loss=1.68, val_accuracy=0.559, lr=0.0316] 62%|██████▏   | 48/78 [20:45<12:32, 25.07s/epoch, loss=1.14, accuracy=0.753, val_loss=1.5, val_accuracy=0.604, lr=0.1]     63%|██████▎   | 49/78 [21:11<12:11, 25.23s/epoch, loss=1.13, accuracy=0.757, val_loss=2.04, val_accuracy=0.463, lr=0.1] 64%|██████▍   | 50/78 [21:36<11:46, 25.23s/epoch, loss=1.15, accuracy=0.753, val_loss=1.96, val_accuracy=0.533, lr=0.1] 65%|██████▌   | 51/78 [22:02<11:24, 25.36s/epoch, loss=1.13, accuracy=0.755, val_loss=1.95, val_accuracy=0.522, lr=0.1] 67%|██████▋   | 52/78 [22:28<11:05, 25.61s/epoch, loss=1.14, accuracy=0.754, val_loss=1.78, val_accuracy=0.523, lr=0.0316] 68%|██████▊   | 53/78 [22:55<10:46, 25.87s/epoch, loss=1.13, accuracy=0.757, val_loss=2.32, val_accuracy=0.464, lr=0.1]    69%|██████▉   | 54/78 [23:21<10:21, 25.91s/epoch, loss=1.13, accuracy=0.754, val_loss=1.83, val_accuracy=0.548, lr=0.1] 71%|███████   | 55/78 [23:46<09:52, 25.75s/epoch, loss=1.13, accuracy=0.755, val_loss=2.47, val_accuracy=0.45, lr=0.1]  72%|███████▏  | 56/78 [24:12<09:28, 25.86s/epoch, loss=1.13, accuracy=0.755, val_loss=1.96, val_accuracy=0.545, lr=0.1] 73%|███████▎  | 57/78 [24:38<09:05, 25.98s/epoch, loss=1.13, accuracy=0.756, val_loss=2.09, val_accuracy=0.423, lr=0.0316] 74%|███████▍  | 58/78 [25:03<08:33, 25.67s/epoch, loss=1.12, accuracy=0.756, val_loss=1.95, val_accuracy=0.518, lr=0.1]    76%|███████▌  | 59/78 [25:28<08:00, 25.29s/epoch, loss=1.14, accuracy=0.754, val_loss=2.09, val_accuracy=0.479, lr=0.1] 77%|███████▋  | 60/78 [25:53<07:35, 25.31s/epoch, loss=1.13, accuracy=0.756, val_loss=2.59, val_accuracy=0.423, lr=0.1] 78%|███████▊  | 61/78 [26:18<07:10, 25.35s/epoch, loss=1.12, accuracy=0.759, val_loss=1.76, val_accuracy=0.578, lr=0.1] 79%|███████▉  | 62/78 [26:44<06:45, 25.36s/epoch, loss=1.12, accuracy=0.758, val_loss=3.31, val_accuracy=0.348, lr=0.0316] 81%|████████  | 63/78 [27:09<06:20, 25.38s/epoch, loss=1.12, accuracy=0.756, val_loss=1.52, val_accuracy=0.619, lr=0.1]    82%|████████▏ | 64/78 [27:34<05:54, 25.30s/epoch, loss=1.13, accuracy=0.756, val_loss=2.19, val_accuracy=0.433, lr=0.1] 83%|████████▎ | 65/78 [28:00<05:29, 25.34s/epoch, loss=1.13, accuracy=0.756, val_loss=2.62, val_accuracy=0.333, lr=0.1] 85%|████████▍ | 66/78 [28:25<05:04, 25.37s/epoch, loss=1.12, accuracy=0.755, val_loss=1.52, val_accuracy=0.625, lr=0.1] 86%|████████▌ | 67/78 [28:51<04:39, 25.40s/epoch, loss=1.12, accuracy=0.755, val_loss=2.59, val_accuracy=0.448, lr=0.0316] 87%|████████▋ | 68/78 [29:16<04:13, 25.35s/epoch, loss=1.13, accuracy=0.757, val_loss=2.77, val_accuracy=0.348, lr=0.1]    88%|████████▊ | 69/78 [29:41<03:47, 25.31s/epoch, loss=1.13, accuracy=0.756, val_loss=1.88, val_accuracy=0.482, lr=0.1] 90%|████████▉ | 70/78 [30:06<03:21, 25.22s/epoch, loss=1.12, accuracy=0.757, val_loss=1.6, val_accuracy=0.565, lr=0.1]  91%|█████████ | 71/78 [30:33<02:58, 25.55s/epoch, loss=1.12, accuracy=0.756, val_loss=1.94, val_accuracy=0.549, lr=0.1] 92%|█████████▏| 72/78 [30:58<02:32, 25.50s/epoch, loss=1.12, accuracy=0.757, val_loss=4.79, val_accuracy=0.242, lr=0.0316] 94%|█████████▎| 73/78 [31:23<02:07, 25.43s/epoch, loss=1.12, accuracy=0.755, val_loss=1.63, val_accuracy=0.566, lr=0.1]    95%|█████████▍| 74/78 [31:49<01:42, 25.60s/epoch, loss=1.13, accuracy=0.755, val_loss=2.36, val_accuracy=0.465, lr=0.1] 96%|█████████▌| 75/78 [32:15<01:17, 25.71s/epoch, loss=1.12, accuracy=0.757, val_loss=2.53, val_accuracy=0.373, lr=0.1] 97%|█████████▋| 76/78 [32:40<00:50, 25.50s/epoch, loss=1.13, accuracy=0.757, val_loss=2.15, val_accuracy=0.417, lr=0.1] 99%|█████████▊| 77/78 [33:06<00:25, 25.54s/epoch, loss=1.12, accuracy=0.757, val_loss=1.66, val_accuracy=0.607, lr=0.0316]100%|██████████| 78/78 [33:31<00:00, 25.33s/epoch, loss=1.13, accuracy=0.757, val_loss=3.69, val_accuracy=0.371, lr=0.1]   100%|██████████| 78/78 [33:31<00:00, 25.78s/epoch, loss=1.13, accuracy=0.757, val_loss=3.69, val_accuracy=0.371, lr=0.1]
Using real-time data augmentation.
Test loss: 3.693331241607666
Test accuracy: 0.37139999866485596


* * * Run SGD for ID = 19_2. * * *


2024-02-15 15:47:42.143077: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 15:47:44.711705: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 15:47:44.713009: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-15 15:47:44.752500: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:86:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 15:47:44.752542: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 15:47:44.755895: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 15:47:44.755960: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 15:47:44.758223: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 15:47:44.758938: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 15:47:44.761455: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 15:47:44.763160: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 15:47:44.768769: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 15:47:44.769411: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 15:47:44.769488: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 15:47:45.972082: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-15 15:47:45.972695: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 15:47:45.973634: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:86:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 15:47:45.973675: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 15:47:45.973748: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 15:47:45.973774: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 15:47:45.973798: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 15:47:45.973820: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 15:47:45.973840: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 15:47:45.973861: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 15:47:45.973884: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 15:47:45.974511: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 15:47:45.974568: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 15:47:46.594883: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-15 15:47:46.594938: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-15 15:47:46.594949: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-15 15:47:46.595985: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:86:00.0, compute capability: 6.1)
{'id': 192, 'batch_size': 128, 'epochs': 78, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/78 [00:00<?, ?epoch/s]2024-02-15 15:47:47.357668: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-15 15:47:47.369707: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2100000000 Hz
2024-02-15 15:47:49.174594: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 15:47:49.421351: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 15:47:50.276580: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-15 15:47:50.319893: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|▏         | 1/78 [00:57<1:14:20, 57.92s/epoch, loss=3.13, accuracy=0.297, val_loss=2.58, val_accuracy=0.188, lr=0.1]  3%|▎         | 2/78 [01:23<49:23, 38.99s/epoch, loss=1.59, accuracy=0.509, val_loss=1.98, val_accuracy=0.39, lr=0.1]     4%|▍         | 3/78 [01:49<41:23, 33.11s/epoch, loss=1.37, accuracy=0.622, val_loss=1.57, val_accuracy=0.576, lr=0.1]  5%|▌         | 4/78 [02:15<37:06, 30.09s/epoch, loss=1.27, accuracy=0.677, val_loss=1.9, val_accuracy=0.523, lr=0.1]   6%|▋         | 5/78 [02:40<34:24, 28.28s/epoch, loss=1.23, accuracy=0.703, val_loss=1.68, val_accuracy=0.529, lr=0.1]  8%|▊         | 6/78 [03:05<32:51, 27.38s/epoch, loss=1.21, accuracy=0.714, val_loss=1.83, val_accuracy=0.53, lr=0.1]   9%|▉         | 7/78 [03:31<31:32, 26.66s/epoch, loss=1.2, accuracy=0.72, val_loss=1.58, val_accuracy=0.592, lr=0.1]  10%|█         | 8/78 [03:56<30:28, 26.12s/epoch, loss=1.19, accuracy=0.725, val_loss=1.86, val_accuracy=0.543, lr=0.0316] 12%|█▏        | 9/78 [04:21<29:56, 26.03s/epoch, loss=1.17, accuracy=0.732, val_loss=1.74, val_accuracy=0.554, lr=0.1]    13%|█▎        | 10/78 [04:47<29:21, 25.90s/epoch, loss=1.17, accuracy=0.733, val_loss=1.58, val_accuracy=0.597, lr=0.1] 14%|█▍        | 11/78 [05:13<28:47, 25.78s/epoch, loss=1.16, accuracy=0.735, val_loss=1.47, val_accuracy=0.616, lr=0.1] 15%|█▌        | 12/78 [05:38<28:10, 25.61s/epoch, loss=1.16, accuracy=0.738, val_loss=1.74, val_accuracy=0.531, lr=0.1] 17%|█▋        | 13/78 [06:04<27:58, 25.82s/epoch, loss=1.16, accuracy=0.738, val_loss=2.84, val_accuracy=0.369, lr=0.1] 18%|█▊        | 14/78 [06:30<27:39, 25.94s/epoch, loss=1.15, accuracy=0.742, val_loss=2.3, val_accuracy=0.429, lr=0.1]  19%|█▉        | 15/78 [06:56<27:11, 25.90s/epoch, loss=1.15, accuracy=0.744, val_loss=2.3, val_accuracy=0.483, lr=0.1] 21%|██        | 16/78 [07:22<26:42, 25.85s/epoch, loss=1.14, accuracy=0.744, val_loss=1.75, val_accuracy=0.552, lr=0.0316] 22%|██▏       | 17/78 [07:47<26:05, 25.66s/epoch, loss=1.14, accuracy=0.742, val_loss=1.93, val_accuracy=0.43, lr=0.1]     23%|██▎       | 18/78 [08:13<25:41, 25.69s/epoch, loss=1.15, accuracy=0.745, val_loss=1.42, val_accuracy=0.661, lr=0.1] 24%|██▍       | 19/78 [08:39<25:21, 25.79s/epoch, loss=1.14, accuracy=0.746, val_loss=2.6, val_accuracy=0.385, lr=0.1]  26%|██▌       | 20/78 [09:05<24:54, 25.76s/epoch, loss=1.14, accuracy=0.749, val_loss=1.91, val_accuracy=0.56, lr=0.1] 27%|██▋       | 21/78 [09:31<24:35, 25.89s/epoch, loss=1.14, accuracy=0.746, val_loss=2.04, val_accuracy=0.46, lr=0.1] 28%|██▊       | 22/78 [09:56<23:54, 25.62s/epoch, loss=1.13, accuracy=0.748, val_loss=1.63, val_accuracy=0.59, lr=0.1] 29%|██▉       | 23/78 [10:21<23:29, 25.63s/epoch, loss=1.13, accuracy=0.749, val_loss=1.96, val_accuracy=0.477, lr=0.0316] 31%|███       | 24/78 [10:46<22:52, 25.42s/epoch, loss=1.13, accuracy=0.749, val_loss=2.17, val_accuracy=0.475, lr=0.1]    32%|███▏      | 25/78 [11:12<22:31, 25.50s/epoch, loss=1.12, accuracy=0.75, val_loss=2.64, val_accuracy=0.415, lr=0.1]  33%|███▎      | 26/78 [11:38<22:13, 25.65s/epoch, loss=1.13, accuracy=0.751, val_loss=2.39, val_accuracy=0.366, lr=0.1] 35%|███▍      | 27/78 [12:04<21:52, 25.74s/epoch, loss=1.13, accuracy=0.748, val_loss=3.88, val_accuracy=0.359, lr=0.1] 36%|███▌      | 28/78 [12:29<21:23, 25.67s/epoch, loss=1.12, accuracy=0.753, val_loss=1.82, val_accuracy=0.595, lr=0.0316] 37%|███▋      | 29/78 [12:55<21:00, 25.73s/epoch, loss=1.13, accuracy=0.75, val_loss=2.79, val_accuracy=0.486, lr=0.1]     38%|███▊      | 30/78 [13:22<20:46, 25.96s/epoch, loss=1.12, accuracy=0.752, val_loss=4.52, val_accuracy=0.229, lr=0.1] 40%|███▉      | 31/78 [13:48<20:22, 26.00s/epoch, loss=1.13, accuracy=0.753, val_loss=1.91, val_accuracy=0.532, lr=0.1] 41%|████      | 32/78 [14:14<19:52, 25.91s/epoch, loss=1.13, accuracy=0.754, val_loss=3.37, val_accuracy=0.372, lr=0.1] 42%|████▏     | 33/78 [14:39<19:13, 25.63s/epoch, loss=1.12, accuracy=0.756, val_loss=1.98, val_accuracy=0.488, lr=0.0316] 44%|████▎     | 34/78 [15:04<18:45, 25.58s/epoch, loss=1.12, accuracy=0.753, val_loss=2, val_accuracy=0.539, lr=0.1]       45%|████▍     | 35/78 [15:30<18:28, 25.77s/epoch, loss=1.12, accuracy=0.756, val_loss=2.15, val_accuracy=0.534, lr=0.1] 46%|████▌     | 36/78 [15:57<18:09, 25.94s/epoch, loss=1.12, accuracy=0.755, val_loss=1.76, val_accuracy=0.512, lr=0.1] 47%|████▋     | 37/78 [16:22<17:36, 25.76s/epoch, loss=1.11, accuracy=0.755, val_loss=3.13, val_accuracy=0.34, lr=0.1]  49%|████▊     | 38/78 [16:47<17:06, 25.67s/epoch, loss=1.12, accuracy=0.752, val_loss=1.97, val_accuracy=0.479, lr=0.0316] 50%|█████     | 39/78 [17:13<16:43, 25.74s/epoch, loss=1.11, accuracy=0.756, val_loss=3.17, val_accuracy=0.394, lr=0.1]    51%|█████▏    | 40/78 [17:38<16:10, 25.54s/epoch, loss=1.12, accuracy=0.754, val_loss=2.16, val_accuracy=0.527, lr=0.1] 53%|█████▎    | 41/78 [18:03<15:37, 25.34s/epoch, loss=1.12, accuracy=0.755, val_loss=5.08, val_accuracy=0.292, lr=0.1] 54%|█████▍    | 42/78 [18:29<15:12, 25.36s/epoch, loss=1.11, accuracy=0.756, val_loss=2.51, val_accuracy=0.29, lr=0.1]  55%|█████▌    | 43/78 [18:54<14:51, 25.48s/epoch, loss=1.11, accuracy=0.76, val_loss=1.41, val_accuracy=0.643, lr=0.1] 56%|█████▋    | 44/78 [19:21<14:35, 25.74s/epoch, loss=1.11, accuracy=0.754, val_loss=2.07, val_accuracy=0.482, lr=0.1] 58%|█████▊    | 45/78 [19:46<14:09, 25.74s/epoch, loss=1.11, accuracy=0.757, val_loss=2.1, val_accuracy=0.487, lr=0.1]  59%|█████▉    | 46/78 [20:13<13:46, 25.83s/epoch, loss=1.11, accuracy=0.759, val_loss=1.95, val_accuracy=0.546, lr=0.1] 60%|██████    | 47/78 [20:39<13:23, 25.91s/epoch, loss=1.11, accuracy=0.756, val_loss=1.87, val_accuracy=0.534, lr=0.1] 62%|██████▏   | 48/78 [21:04<12:54, 25.81s/epoch, loss=1.11, accuracy=0.755, val_loss=1.35, val_accuracy=0.678, lr=0.1] 63%|██████▎   | 49/78 [21:29<12:20, 25.52s/epoch, loss=1.11, accuracy=0.756, val_loss=2.26, val_accuracy=0.416, lr=0.1] 64%|██████▍   | 50/78 [21:55<12:01, 25.77s/epoch, loss=1.11, accuracy=0.755, val_loss=1.94, val_accuracy=0.492, lr=0.1] 65%|██████▌   | 51/78 [22:21<11:37, 25.83s/epoch, loss=1.1, accuracy=0.76, val_loss=2.85, val_accuracy=0.46, lr=0.1]    67%|██████▋   | 52/78 [22:47<11:06, 25.65s/epoch, loss=1.12, accuracy=0.757, val_loss=1.92, val_accuracy=0.568, lr=0.1] 68%|██████▊   | 53/78 [23:12<10:39, 25.58s/epoch, loss=1.11, accuracy=0.756, val_loss=1.71, val_accuracy=0.548, lr=0.0316] 69%|██████▉   | 54/78 [23:38<10:13, 25.56s/epoch, loss=1.11, accuracy=0.755, val_loss=2.34, val_accuracy=0.422, lr=0.1]    71%|███████   | 55/78 [24:03<09:49, 25.63s/epoch, loss=1.11, accuracy=0.757, val_loss=1.98, val_accuracy=0.559, lr=0.1] 72%|███████▏  | 56/78 [24:29<09:21, 25.53s/epoch, loss=1.11, accuracy=0.756, val_loss=1.62, val_accuracy=0.563, lr=0.1] 73%|███████▎  | 57/78 [24:55<08:58, 25.64s/epoch, loss=1.11, accuracy=0.757, val_loss=1.76, val_accuracy=0.548, lr=0.1] 74%|███████▍  | 58/78 [25:19<08:27, 25.38s/epoch, loss=1.1, accuracy=0.759, val_loss=1.63, val_accuracy=0.595, lr=0.0316] 76%|███████▌  | 59/78 [25:45<08:03, 25.45s/epoch, loss=1.1, accuracy=0.76, val_loss=1.34, val_accuracy=0.69, lr=0.1]      77%|███████▋  | 60/78 [26:10<07:35, 25.30s/epoch, loss=1.11, accuracy=0.756, val_loss=1.9, val_accuracy=0.56, lr=0.1] 78%|███████▊  | 61/78 [26:34<07:06, 25.09s/epoch, loss=1.11, accuracy=0.758, val_loss=2.12, val_accuracy=0.409, lr=0.1] 79%|███████▉  | 62/78 [26:59<06:40, 25.05s/epoch, loss=1.11, accuracy=0.758, val_loss=1.38, val_accuracy=0.679, lr=0.1] 81%|████████  | 63/78 [27:25<06:17, 25.15s/epoch, loss=1.11, accuracy=0.755, val_loss=2.45, val_accuracy=0.406, lr=0.1] 82%|████████▏ | 64/78 [27:50<05:51, 25.13s/epoch, loss=1.11, accuracy=0.757, val_loss=2.12, val_accuracy=0.504, lr=0.0316] 83%|████████▎ | 65/78 [28:15<05:25, 25.03s/epoch, loss=1.11, accuracy=0.758, val_loss=1.98, val_accuracy=0.495, lr=0.1]    85%|████████▍ | 66/78 [28:40<05:00, 25.00s/epoch, loss=1.11, accuracy=0.758, val_loss=2.36, val_accuracy=0.348, lr=0.1] 86%|████████▌ | 67/78 [29:05<04:36, 25.18s/epoch, loss=1.11, accuracy=0.757, val_loss=2.97, val_accuracy=0.405, lr=0.1] 87%|████████▋ | 68/78 [29:32<04:15, 25.55s/epoch, loss=1.11, accuracy=0.759, val_loss=1.74, val_accuracy=0.538, lr=0.1] 88%|████████▊ | 69/78 [29:58<03:51, 25.76s/epoch, loss=1.11, accuracy=0.757, val_loss=4.06, val_accuracy=0.347, lr=0.0316] 90%|████████▉ | 70/78 [30:24<03:27, 25.92s/epoch, loss=1.11, accuracy=0.758, val_loss=1.6, val_accuracy=0.576, lr=0.1]     91%|█████████ | 71/78 [30:51<03:03, 26.19s/epoch, loss=1.11, accuracy=0.754, val_loss=2.04, val_accuracy=0.483, lr=0.1] 92%|█████████▏| 72/78 [31:17<02:37, 26.29s/epoch, loss=1.11, accuracy=0.756, val_loss=1.95, val_accuracy=0.562, lr=0.1] 94%|█████████▎| 73/78 [31:44<02:11, 26.33s/epoch, loss=1.11, accuracy=0.757, val_loss=2.13, val_accuracy=0.478, lr=0.1] 95%|█████████▍| 74/78 [32:10<01:45, 26.35s/epoch, loss=1.1, accuracy=0.758, val_loss=1.91, val_accuracy=0.564, lr=0.0316] 96%|█████████▌| 75/78 [32:36<01:18, 26.29s/epoch, loss=1.1, accuracy=0.759, val_loss=1.99, val_accuracy=0.484, lr=0.1]    97%|█████████▋| 76/78 [33:03<00:52, 26.36s/epoch, loss=1.1, accuracy=0.761, val_loss=2.54, val_accuracy=0.34, lr=0.1]  99%|█████████▊| 77/78 [33:29<00:26, 26.33s/epoch, loss=1.1, accuracy=0.758, val_loss=2.18, val_accuracy=0.503, lr=0.1]100%|██████████| 78/78 [33:56<00:00, 26.32s/epoch, loss=1.1, accuracy=0.756, val_loss=2.02, val_accuracy=0.495, lr=0.1]100%|██████████| 78/78 [33:56<00:00, 26.10s/epoch, loss=1.1, accuracy=0.756, val_loss=2.02, val_accuracy=0.495, lr=0.1]
Using real-time data augmentation.
Test loss: 2.017465353012085
Test accuracy: 0.4950000047683716


* * * Run SGD for ID = 19_3. * * *


2024-02-15 16:21:46.169604: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 16:21:49.199999: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 16:21:49.201340: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-15 16:21:49.241212: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:86:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 16:21:49.241253: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 16:21:49.244751: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 16:21:49.244823: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 16:21:49.247202: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 16:21:49.248031: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 16:21:49.250667: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 16:21:49.252442: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 16:21:49.258142: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 16:21:49.258793: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 16:21:49.258876: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 16:21:50.535438: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-15 16:21:50.536015: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 16:21:50.536522: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:86:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 16:21:50.536567: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 16:21:50.536605: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 16:21:50.536627: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 16:21:50.536646: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 16:21:50.536660: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 16:21:50.536674: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 16:21:50.536689: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 16:21:50.536703: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 16:21:50.537268: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 16:21:50.537311: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 16:21:51.186997: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-15 16:21:51.187047: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-15 16:21:51.187058: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-15 16:21:51.188144: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:86:00.0, compute capability: 6.1)
{'id': 193, 'batch_size': 128, 'epochs': 78, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/78 [00:00<?, ?epoch/s]2024-02-15 16:21:51.978783: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-15 16:21:51.990767: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2100000000 Hz
2024-02-15 16:21:54.081789: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 16:21:54.407762: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 16:21:55.372661: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-15 16:21:55.414079: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|▏         | 1/78 [00:53<1:08:48, 53.62s/epoch, loss=3.36, accuracy=0.303, val_loss=2.15, val_accuracy=0.319, lr=0.1]  3%|▎         | 2/78 [01:20<47:38, 37.61s/epoch, loss=1.68, accuracy=0.467, val_loss=2.02, val_accuracy=0.389, lr=0.1]    4%|▍         | 3/78 [01:45<40:18, 32.25s/epoch, loss=1.49, accuracy=0.57, val_loss=1.92, val_accuracy=0.475, lr=0.1]   5%|▌         | 4/78 [02:10<36:04, 29.25s/epoch, loss=1.36, accuracy=0.647, val_loss=1.76, val_accuracy=0.541, lr=0.1]  6%|▋         | 5/78 [02:36<34:01, 27.97s/epoch, loss=1.31, accuracy=0.679, val_loss=2.07, val_accuracy=0.454, lr=0.1]  8%|▊         | 6/78 [03:00<32:09, 26.80s/epoch, loss=1.28, accuracy=0.699, val_loss=2.04, val_accuracy=0.534, lr=0.1]  9%|▉         | 7/78 [03:26<31:10, 26.35s/epoch, loss=1.26, accuracy=0.707, val_loss=2.01, val_accuracy=0.469, lr=0.1] 10%|█         | 8/78 [03:52<30:50, 26.44s/epoch, loss=1.25, accuracy=0.715, val_loss=3.43, val_accuracy=0.321, lr=0.1] 12%|█▏        | 9/78 [04:19<30:20, 26.38s/epoch, loss=1.23, accuracy=0.723, val_loss=1.88, val_accuracy=0.526, lr=0.0316] 13%|█▎        | 10/78 [04:45<29:53, 26.38s/epoch, loss=1.23, accuracy=0.727, val_loss=1.71, val_accuracy=0.554, lr=0.1]   14%|█▍        | 11/78 [05:12<29:32, 26.46s/epoch, loss=1.22, accuracy=0.731, val_loss=1.74, val_accuracy=0.565, lr=0.1] 15%|█▌        | 12/78 [05:38<29:05, 26.45s/epoch, loss=1.22, accuracy=0.731, val_loss=1.47, val_accuracy=0.658, lr=0.1] 17%|█▋        | 13/78 [06:04<28:39, 26.46s/epoch, loss=1.22, accuracy=0.732, val_loss=2.86, val_accuracy=0.351, lr=0.1] 18%|█▊        | 14/78 [06:30<27:55, 26.18s/epoch, loss=1.22, accuracy=0.734, val_loss=2.14, val_accuracy=0.412, lr=0.1] 19%|█▉        | 15/78 [06:57<27:37, 26.31s/epoch, loss=1.22, accuracy=0.735, val_loss=1.75, val_accuracy=0.58, lr=0.1]  21%|██        | 16/78 [07:23<27:14, 26.36s/epoch, loss=1.21, accuracy=0.735, val_loss=5, val_accuracy=0.254, lr=0.1]   22%|██▏       | 17/78 [07:50<26:48, 26.37s/epoch, loss=1.21, accuracy=0.738, val_loss=3.48, val_accuracy=0.375, lr=0.0316] 23%|██▎       | 18/78 [08:15<26:01, 26.03s/epoch, loss=1.2, accuracy=0.74, val_loss=1.53, val_accuracy=0.625, lr=0.1]      24%|██▍       | 19/78 [08:41<25:33, 25.99s/epoch, loss=1.2, accuracy=0.743, val_loss=1.55, val_accuracy=0.633, lr=0.1] 26%|██▌       | 20/78 [09:06<25:04, 25.94s/epoch, loss=1.19, accuracy=0.744, val_loss=1.59, val_accuracy=0.606, lr=0.1] 27%|██▋       | 21/78 [09:32<24:31, 25.81s/epoch, loss=1.2, accuracy=0.745, val_loss=1.69, val_accuracy=0.6, lr=0.1]    28%|██▊       | 22/78 [09:57<23:50, 25.55s/epoch, loss=1.19, accuracy=0.747, val_loss=3.02, val_accuracy=0.371, lr=0.0316] 29%|██▉       | 23/78 [10:22<23:24, 25.54s/epoch, loss=1.18, accuracy=0.747, val_loss=2.96, val_accuracy=0.405, lr=0.1]    31%|███       | 24/78 [10:48<22:52, 25.42s/epoch, loss=1.18, accuracy=0.747, val_loss=1.5, val_accuracy=0.636, lr=0.1]  32%|███▏      | 25/78 [11:14<22:35, 25.58s/epoch, loss=1.18, accuracy=0.747, val_loss=1.84, val_accuracy=0.519, lr=0.1] 33%|███▎      | 26/78 [11:40<22:17, 25.72s/epoch, loss=1.18, accuracy=0.748, val_loss=1.83, val_accuracy=0.547, lr=0.1] 35%|███▍      | 27/78 [12:05<21:51, 25.71s/epoch, loss=1.18, accuracy=0.746, val_loss=2.53, val_accuracy=0.458, lr=0.0316] 36%|███▌      | 28/78 [12:31<21:29, 25.80s/epoch, loss=1.18, accuracy=0.749, val_loss=1.57, val_accuracy=0.619, lr=0.1]    37%|███▋      | 29/78 [12:57<21:08, 25.88s/epoch, loss=1.18, accuracy=0.748, val_loss=1.72, val_accuracy=0.56, lr=0.1]  38%|███▊      | 30/78 [13:23<20:45, 25.94s/epoch, loss=1.18, accuracy=0.747, val_loss=1.44, val_accuracy=0.656, lr=0.1] 40%|███▉      | 31/78 [13:50<20:32, 26.22s/epoch, loss=1.16, accuracy=0.751, val_loss=1.67, val_accuracy=0.585, lr=0.1] 41%|████      | 32/78 [14:17<20:09, 26.30s/epoch, loss=1.17, accuracy=0.748, val_loss=1.96, val_accuracy=0.532, lr=0.1] 42%|████▏     | 33/78 [14:43<19:48, 26.41s/epoch, loss=1.17, accuracy=0.751, val_loss=1.7, val_accuracy=0.606, lr=0.1]  44%|████▎     | 34/78 [15:10<19:19, 26.36s/epoch, loss=1.16, accuracy=0.749, val_loss=1.48, val_accuracy=0.643, lr=0.1] 45%|████▍     | 35/78 [15:37<18:59, 26.50s/epoch, loss=1.16, accuracy=0.75, val_loss=1.47, val_accuracy=0.674, lr=0.0316] 46%|████▌     | 36/78 [16:03<18:32, 26.49s/epoch, loss=1.16, accuracy=0.751, val_loss=1.49, val_accuracy=0.642, lr=0.1]   47%|████▋     | 37/78 [16:29<18:03, 26.42s/epoch, loss=1.17, accuracy=0.749, val_loss=2.01, val_accuracy=0.471, lr=0.1] 49%|████▊     | 38/78 [16:56<17:40, 26.52s/epoch, loss=1.16, accuracy=0.751, val_loss=1.58, val_accuracy=0.606, lr=0.1] 50%|█████     | 39/78 [17:23<17:16, 26.57s/epoch, loss=1.16, accuracy=0.747, val_loss=1.75, val_accuracy=0.594, lr=0.1] 51%|█████▏    | 40/78 [17:48<16:40, 26.32s/epoch, loss=1.16, accuracy=0.75, val_loss=1.42, val_accuracy=0.659, lr=0.1]  53%|█████▎    | 41/78 [18:15<16:17, 26.41s/epoch, loss=1.16, accuracy=0.749, val_loss=2.42, val_accuracy=0.445, lr=0.1] 54%|█████▍    | 42/78 [18:41<15:48, 26.36s/epoch, loss=1.16, accuracy=0.751, val_loss=1.89, val_accuracy=0.521, lr=0.1] 55%|█████▌    | 43/78 [19:08<15:26, 26.46s/epoch, loss=1.16, accuracy=0.752, val_loss=2.4, val_accuracy=0.441, lr=0.1]  56%|█████▋    | 44/78 [19:34<14:58, 26.42s/epoch, loss=1.16, accuracy=0.753, val_loss=1.76, val_accuracy=0.604, lr=0.1] 58%|█████▊    | 45/78 [20:01<14:31, 26.42s/epoch, loss=1.15, accuracy=0.752, val_loss=1.44, val_accuracy=0.642, lr=0.0316] 59%|█████▉    | 46/78 [20:27<14:07, 26.47s/epoch, loss=1.15, accuracy=0.752, val_loss=1.87, val_accuracy=0.502, lr=0.1]    60%|██████    | 47/78 [20:54<13:39, 26.44s/epoch, loss=1.16, accuracy=0.752, val_loss=2.74, val_accuracy=0.426, lr=0.1] 62%|██████▏   | 48/78 [21:20<13:14, 26.48s/epoch, loss=1.16, accuracy=0.753, val_loss=2.08, val_accuracy=0.513, lr=0.1] 63%|██████▎   | 49/78 [21:47<12:49, 26.53s/epoch, loss=1.16, accuracy=0.753, val_loss=1.92, val_accuracy=0.558, lr=0.1] 64%|██████▍   | 50/78 [22:14<12:23, 26.57s/epoch, loss=1.15, accuracy=0.749, val_loss=2.16, val_accuracy=0.466, lr=0.0316] 65%|██████▌   | 51/78 [22:40<11:59, 26.64s/epoch, loss=1.15, accuracy=0.753, val_loss=2.42, val_accuracy=0.474, lr=0.1]    67%|██████▋   | 52/78 [23:07<11:29, 26.53s/epoch, loss=1.15, accuracy=0.752, val_loss=2.39, val_accuracy=0.461, lr=0.1] 68%|██████▊   | 53/78 [23:33<11:02, 26.50s/epoch, loss=1.15, accuracy=0.754, val_loss=2.06, val_accuracy=0.477, lr=0.1] 69%|██████▉   | 54/78 [24:00<10:38, 26.59s/epoch, loss=1.15, accuracy=0.753, val_loss=2.07, val_accuracy=0.495, lr=0.1] 71%|███████   | 55/78 [24:27<10:14, 26.72s/epoch, loss=1.15, accuracy=0.753, val_loss=1.6, val_accuracy=0.614, lr=0.0316] 72%|███████▏  | 56/78 [24:53<09:46, 26.65s/epoch, loss=1.14, accuracy=0.755, val_loss=2.17, val_accuracy=0.484, lr=0.1]   73%|███████▎  | 57/78 [25:20<09:19, 26.63s/epoch, loss=1.15, accuracy=0.755, val_loss=2.31, val_accuracy=0.465, lr=0.1] 74%|███████▍  | 58/78 [25:47<08:53, 26.67s/epoch, loss=1.15, accuracy=0.752, val_loss=1.84, val_accuracy=0.488, lr=0.1] 76%|███████▌  | 59/78 [26:14<08:28, 26.75s/epoch, loss=1.14, accuracy=0.755, val_loss=1.81, val_accuracy=0.572, lr=0.1] 77%|███████▋  | 60/78 [26:40<08:01, 26.74s/epoch, loss=1.15, accuracy=0.751, val_loss=1.91, val_accuracy=0.486, lr=0.0316] 78%|███████▊  | 61/78 [27:07<07:34, 26.71s/epoch, loss=1.15, accuracy=0.753, val_loss=1.97, val_accuracy=0.532, lr=0.1]    79%|███████▉  | 62/78 [27:34<07:07, 26.75s/epoch, loss=1.15, accuracy=0.754, val_loss=1.49, val_accuracy=0.634, lr=0.1] 81%|████████  | 63/78 [28:00<06:39, 26.61s/epoch, loss=1.14, accuracy=0.756, val_loss=1.44, val_accuracy=0.654, lr=0.1] 82%|████████▏ | 64/78 [28:27<06:12, 26.62s/epoch, loss=1.15, accuracy=0.753, val_loss=2.51, val_accuracy=0.449, lr=0.1] 83%|████████▎ | 65/78 [28:53<05:45, 26.57s/epoch, loss=1.15, accuracy=0.754, val_loss=2.12, val_accuracy=0.451, lr=0.0316] 85%|████████▍ | 66/78 [29:20<05:18, 26.58s/epoch, loss=1.14, accuracy=0.752, val_loss=3.96, val_accuracy=0.345, lr=0.1]    86%|████████▌ | 67/78 [29:47<04:52, 26.63s/epoch, loss=1.15, accuracy=0.753, val_loss=1.6, val_accuracy=0.609, lr=0.1]  87%|████████▋ | 68/78 [30:13<04:26, 26.64s/epoch, loss=1.14, accuracy=0.754, val_loss=2.31, val_accuracy=0.497, lr=0.1] 88%|████████▊ | 69/78 [30:39<03:57, 26.43s/epoch, loss=1.14, accuracy=0.754, val_loss=1.86, val_accuracy=0.49, lr=0.1]  90%|████████▉ | 70/78 [31:06<03:31, 26.43s/epoch, loss=1.14, accuracy=0.755, val_loss=1.81, val_accuracy=0.548, lr=0.0316] 91%|█████████ | 71/78 [31:33<03:05, 26.56s/epoch, loss=1.14, accuracy=0.754, val_loss=1.59, val_accuracy=0.625, lr=0.1]    92%|█████████▏| 72/78 [31:59<02:39, 26.66s/epoch, loss=1.13, accuracy=0.755, val_loss=1.98, val_accuracy=0.486, lr=0.1] 94%|█████████▎| 73/78 [32:26<02:13, 26.72s/epoch, loss=1.14, accuracy=0.758, val_loss=2.07, val_accuracy=0.442, lr=0.1] 95%|█████████▍| 74/78 [32:53<01:46, 26.74s/epoch, loss=1.14, accuracy=0.755, val_loss=1.77, val_accuracy=0.54, lr=0.1]  96%|█████████▌| 75/78 [33:20<01:20, 26.78s/epoch, loss=1.14, accuracy=0.754, val_loss=1.48, val_accuracy=0.639, lr=0.0316] 97%|█████████▋| 76/78 [33:46<00:53, 26.66s/epoch, loss=1.13, accuracy=0.757, val_loss=1.8, val_accuracy=0.502, lr=0.1]     99%|█████████▊| 77/78 [34:13<00:26, 26.69s/epoch, loss=1.14, accuracy=0.756, val_loss=2.27, val_accuracy=0.405, lr=0.1]100%|██████████| 78/78 [34:40<00:00, 26.66s/epoch, loss=1.14, accuracy=0.756, val_loss=1.98, val_accuracy=0.501, lr=0.1]100%|██████████| 78/78 [34:40<00:00, 26.67s/epoch, loss=1.14, accuracy=0.756, val_loss=1.98, val_accuracy=0.501, lr=0.1]
Using real-time data augmentation.
Test loss: 1.9786386489868164
Test accuracy: 0.5005999803543091


* * * Run SGD for ID = 19_4. * * *


2024-02-15 16:56:35.005739: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 16:56:37.951397: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 16:56:37.952823: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-15 16:56:37.993726: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:86:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 16:56:37.993772: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 16:56:37.997351: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 16:56:37.997422: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 16:56:37.999986: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 16:56:38.000746: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 16:56:38.003545: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 16:56:38.005322: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 16:56:38.011732: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 16:56:38.012467: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 16:56:38.012565: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 16:56:39.265659: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-15 16:56:39.266704: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 16:56:39.267230: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:86:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 16:56:39.267265: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 16:56:39.267302: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 16:56:39.267317: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 16:56:39.267332: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 16:56:39.267347: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 16:56:39.267361: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 16:56:39.267376: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 16:56:39.267391: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 16:56:39.267970: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 16:56:39.268013: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 16:56:39.905486: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-15 16:56:39.905541: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-15 16:56:39.905553: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-15 16:56:39.906666: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:86:00.0, compute capability: 6.1)
{'id': 194, 'batch_size': 128, 'epochs': 78, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/78 [00:00<?, ?epoch/s]2024-02-15 16:56:40.689328: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-15 16:56:40.701740: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2100000000 Hz
2024-02-15 16:56:42.605222: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 16:56:42.909368: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 16:56:43.851953: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-15 16:56:43.895911: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|▏         | 1/78 [00:57<1:14:12, 57.83s/epoch, loss=3.19, accuracy=0.329, val_loss=3.88, val_accuracy=0.131, lr=0.1]  3%|▎         | 2/78 [01:24<50:17, 39.71s/epoch, loss=1.52, accuracy=0.551, val_loss=1.78, val_accuracy=0.47, lr=0.1]     4%|▍         | 3/78 [01:52<42:29, 34.00s/epoch, loss=1.32, accuracy=0.655, val_loss=2.06, val_accuracy=0.48, lr=0.1]  5%|▌         | 4/78 [02:19<38:32, 31.25s/epoch, loss=1.28, accuracy=0.685, val_loss=2.59, val_accuracy=0.397, lr=0.1]  6%|▋         | 5/78 [02:45<36:06, 29.68s/epoch, loss=1.25, accuracy=0.702, val_loss=2.34, val_accuracy=0.393, lr=0.1]  8%|▊         | 6/78 [03:13<34:34, 28.81s/epoch, loss=1.23, accuracy=0.712, val_loss=2.3, val_accuracy=0.44, lr=0.1]    9%|▉         | 7/78 [03:40<33:21, 28.19s/epoch, loss=1.22, accuracy=0.72, val_loss=2.58, val_accuracy=0.408, lr=0.0316] 10%|█         | 8/78 [04:06<32:25, 27.80s/epoch, loss=1.21, accuracy=0.727, val_loss=1.76, val_accuracy=0.541, lr=0.1]   12%|█▏        | 9/78 [04:33<31:39, 27.53s/epoch, loss=1.2, accuracy=0.73, val_loss=1.67, val_accuracy=0.558, lr=0.1]   13%|█▎        | 10/78 [05:00<30:56, 27.30s/epoch, loss=1.2, accuracy=0.732, val_loss=1.33, val_accuracy=0.685, lr=0.1] 14%|█▍        | 11/78 [05:27<30:19, 27.16s/epoch, loss=1.19, accuracy=0.734, val_loss=2.35, val_accuracy=0.41, lr=0.1] 15%|█▌        | 12/78 [05:54<29:47, 27.08s/epoch, loss=1.18, accuracy=0.735, val_loss=1.94, val_accuracy=0.525, lr=0.1] 17%|█▋        | 13/78 [06:21<29:11, 26.95s/epoch, loss=1.18, accuracy=0.738, val_loss=2.12, val_accuracy=0.448, lr=0.1] 18%|█▊        | 14/78 [06:47<28:37, 26.84s/epoch, loss=1.18, accuracy=0.741, val_loss=1.89, val_accuracy=0.497, lr=0.1] 19%|█▉        | 15/78 [07:14<28:15, 26.91s/epoch, loss=1.17, accuracy=0.739, val_loss=2.76, val_accuracy=0.43, lr=0.0316] 21%|██        | 16/78 [07:41<27:53, 26.99s/epoch, loss=1.17, accuracy=0.739, val_loss=1.54, val_accuracy=0.627, lr=0.1]   22%|██▏       | 17/78 [08:08<27:26, 27.00s/epoch, loss=1.16, accuracy=0.741, val_loss=1.98, val_accuracy=0.535, lr=0.1] 23%|██▎       | 18/78 [08:36<27:04, 27.08s/epoch, loss=1.16, accuracy=0.744, val_loss=1.32, val_accuracy=0.679, lr=0.1] 24%|██▍       | 19/78 [09:03<26:36, 27.06s/epoch, loss=1.16, accuracy=0.746, val_loss=2.3, val_accuracy=0.45, lr=0.1]   26%|██▌       | 20/78 [09:29<26:02, 26.94s/epoch, loss=1.16, accuracy=0.745, val_loss=2.4, val_accuracy=0.401, lr=0.1] 27%|██▋       | 21/78 [09:56<25:33, 26.90s/epoch, loss=1.16, accuracy=0.747, val_loss=2.65, val_accuracy=0.314, lr=0.1] 28%|██▊       | 22/78 [10:23<25:02, 26.84s/epoch, loss=1.15, accuracy=0.747, val_loss=1.85, val_accuracy=0.566, lr=0.1] 29%|██▉       | 23/78 [10:50<24:33, 26.79s/epoch, loss=1.15, accuracy=0.746, val_loss=4.49, val_accuracy=0.216, lr=0.0316] 31%|███       | 24/78 [11:16<23:56, 26.61s/epoch, loss=1.15, accuracy=0.747, val_loss=1.8, val_accuracy=0.588, lr=0.1]     32%|███▏      | 25/78 [11:43<23:33, 26.67s/epoch, loss=1.15, accuracy=0.748, val_loss=1.47, val_accuracy=0.657, lr=0.1] 33%|███▎      | 26/78 [12:09<23:01, 26.56s/epoch, loss=1.15, accuracy=0.749, val_loss=5.27, val_accuracy=0.183, lr=0.1] 35%|███▍      | 27/78 [12:35<22:33, 26.54s/epoch, loss=1.15, accuracy=0.748, val_loss=2.04, val_accuracy=0.486, lr=0.1] 36%|███▌      | 28/78 [13:02<22:10, 26.62s/epoch, loss=1.14, accuracy=0.75, val_loss=1.98, val_accuracy=0.498, lr=0.0316] 37%|███▋      | 29/78 [13:29<21:46, 26.67s/epoch, loss=1.15, accuracy=0.748, val_loss=1.69, val_accuracy=0.576, lr=0.1]   38%|███▊      | 30/78 [13:56<21:18, 26.64s/epoch, loss=1.13, accuracy=0.753, val_loss=1.86, val_accuracy=0.489, lr=0.1] 40%|███▉      | 31/78 [14:22<20:56, 26.74s/epoch, loss=1.14, accuracy=0.749, val_loss=2.11, val_accuracy=0.533, lr=0.1] 41%|████      | 32/78 [14:49<20:26, 26.67s/epoch, loss=1.14, accuracy=0.753, val_loss=1.94, val_accuracy=0.554, lr=0.1] 42%|████▏     | 33/78 [15:16<19:59, 26.64s/epoch, loss=1.14, accuracy=0.751, val_loss=1.82, val_accuracy=0.535, lr=0.0316] 44%|████▎     | 34/78 [15:42<19:35, 26.72s/epoch, loss=1.13, accuracy=0.754, val_loss=1.54, val_accuracy=0.608, lr=0.1]    45%|████▍     | 35/78 [16:09<19:08, 26.70s/epoch, loss=1.13, accuracy=0.752, val_loss=2.19, val_accuracy=0.522, lr=0.1] 46%|████▌     | 36/78 [16:36<18:49, 26.89s/epoch, loss=1.13, accuracy=0.753, val_loss=1.82, val_accuracy=0.557, lr=0.1] 47%|████▋     | 37/78 [17:03<18:18, 26.80s/epoch, loss=1.13, accuracy=0.756, val_loss=2.49, val_accuracy=0.41, lr=0.1]  49%|████▊     | 38/78 [17:30<17:57, 26.94s/epoch, loss=1.13, accuracy=0.754, val_loss=1.69, val_accuracy=0.582, lr=0.0316] 50%|█████     | 39/78 [17:57<17:33, 27.00s/epoch, loss=1.13, accuracy=0.752, val_loss=1.92, val_accuracy=0.55, lr=0.1]     51%|█████▏    | 40/78 [18:24<17:01, 26.88s/epoch, loss=1.12, accuracy=0.753, val_loss=7.12, val_accuracy=0.291, lr=0.1] 53%|█████▎    | 41/78 [18:51<16:32, 26.81s/epoch, loss=1.12, accuracy=0.755, val_loss=3.24, val_accuracy=0.393, lr=0.1] 54%|█████▍    | 42/78 [19:18<16:05, 26.81s/epoch, loss=1.13, accuracy=0.753, val_loss=1.68, val_accuracy=0.561, lr=0.1] 55%|█████▌    | 43/78 [19:44<15:39, 26.84s/epoch, loss=1.13, accuracy=0.755, val_loss=2.64, val_accuracy=0.418, lr=0.0316] 56%|█████▋    | 44/78 [20:10<15:03, 26.58s/epoch, loss=1.13, accuracy=0.755, val_loss=1.76, val_accuracy=0.556, lr=0.1]    58%|█████▊    | 45/78 [20:36<14:24, 26.19s/epoch, loss=1.12, accuracy=0.758, val_loss=1.67, val_accuracy=0.599, lr=0.1] 59%|█████▉    | 46/78 [21:01<13:50, 25.94s/epoch, loss=1.12, accuracy=0.757, val_loss=1.58, val_accuracy=0.595, lr=0.1] 60%|██████    | 47/78 [21:26<13:17, 25.72s/epoch, loss=1.12, accuracy=0.754, val_loss=2.17, val_accuracy=0.448, lr=0.1] 62%|██████▏   | 48/78 [21:52<12:48, 25.62s/epoch, loss=1.12, accuracy=0.757, val_loss=1.9, val_accuracy=0.55, lr=0.0316] 63%|██████▎   | 49/78 [22:17<12:19, 25.50s/epoch, loss=1.13, accuracy=0.755, val_loss=2.64, val_accuracy=0.377, lr=0.1]  64%|██████▍   | 50/78 [22:42<11:53, 25.47s/epoch, loss=1.12, accuracy=0.755, val_loss=2.21, val_accuracy=0.493, lr=0.1] 65%|██████▌   | 51/78 [23:08<11:27, 25.45s/epoch, loss=1.13, accuracy=0.756, val_loss=1.93, val_accuracy=0.535, lr=0.1] 67%|██████▋   | 52/78 [23:34<11:08, 25.72s/epoch, loss=1.12, accuracy=0.756, val_loss=2.18, val_accuracy=0.499, lr=0.1] 68%|██████▊   | 53/78 [23:59<10:40, 25.64s/epoch, loss=1.12, accuracy=0.757, val_loss=1.77, val_accuracy=0.538, lr=0.0316] 69%|██████▉   | 54/78 [24:25<10:11, 25.47s/epoch, loss=1.11, accuracy=0.761, val_loss=1.82, val_accuracy=0.559, lr=0.1]    71%|███████   | 55/78 [24:50<09:47, 25.54s/epoch, loss=1.12, accuracy=0.756, val_loss=2.93, val_accuracy=0.31, lr=0.1]  72%|███████▏  | 56/78 [25:16<09:22, 25.57s/epoch, loss=1.12, accuracy=0.758, val_loss=4.83, val_accuracy=0.254, lr=0.1] 73%|███████▎  | 57/78 [25:42<09:01, 25.78s/epoch, loss=1.12, accuracy=0.755, val_loss=2.09, val_accuracy=0.488, lr=0.1] 74%|███████▍  | 58/78 [26:08<08:33, 25.70s/epoch, loss=1.12, accuracy=0.756, val_loss=2.04, val_accuracy=0.466, lr=0.0316] 76%|███████▌  | 59/78 [26:33<08:07, 25.67s/epoch, loss=1.11, accuracy=0.76, val_loss=2.71, val_accuracy=0.412, lr=0.1]     77%|███████▋  | 60/78 [26:59<07:43, 25.75s/epoch, loss=1.12, accuracy=0.754, val_loss=2.37, val_accuracy=0.384, lr=0.1] 78%|███████▊  | 61/78 [27:24<07:14, 25.56s/epoch, loss=1.11, accuracy=0.758, val_loss=2.19, val_accuracy=0.458, lr=0.1] 79%|███████▉  | 62/78 [27:50<06:48, 25.54s/epoch, loss=1.12, accuracy=0.758, val_loss=2.04, val_accuracy=0.481, lr=0.1] 81%|████████  | 63/78 [28:15<06:22, 25.48s/epoch, loss=1.11, accuracy=0.757, val_loss=2.03, val_accuracy=0.478, lr=0.0316] 82%|████████▏ | 64/78 [28:41<05:56, 25.47s/epoch, loss=1.11, accuracy=0.758, val_loss=1.73, val_accuracy=0.534, lr=0.1]    83%|████████▎ | 65/78 [29:07<05:33, 25.62s/epoch, loss=1.11, accuracy=0.757, val_loss=1.93, val_accuracy=0.515, lr=0.1] 85%|████████▍ | 66/78 [29:32<05:05, 25.49s/epoch, loss=1.11, accuracy=0.756, val_loss=1.83, val_accuracy=0.494, lr=0.1] 86%|████████▌ | 67/78 [29:57<04:40, 25.52s/epoch, loss=1.11, accuracy=0.759, val_loss=3.47, val_accuracy=0.322, lr=0.1] 87%|████████▋ | 68/78 [30:23<04:14, 25.49s/epoch, loss=1.11, accuracy=0.756, val_loss=3.01, val_accuracy=0.389, lr=0.0316] 88%|████████▊ | 69/78 [30:48<03:48, 25.44s/epoch, loss=1.11, accuracy=0.757, val_loss=2.61, val_accuracy=0.375, lr=0.1]    90%|████████▉ | 70/78 [31:13<03:23, 25.38s/epoch, loss=1.1, accuracy=0.761, val_loss=1.78, val_accuracy=0.562, lr=0.1]  91%|█████████ | 71/78 [31:39<02:57, 25.35s/epoch, loss=1.11, accuracy=0.76, val_loss=1.51, val_accuracy=0.612, lr=0.1] 92%|█████████▏| 72/78 [32:04<02:32, 25.43s/epoch, loss=1.1, accuracy=0.758, val_loss=3.12, val_accuracy=0.378, lr=0.1] 94%|█████████▎| 73/78 [32:30<02:07, 25.48s/epoch, loss=1.1, accuracy=0.759, val_loss=2.05, val_accuracy=0.511, lr=0.0316] 95%|█████████▍| 74/78 [32:55<01:40, 25.25s/epoch, loss=1.11, accuracy=0.758, val_loss=3.17, val_accuracy=0.361, lr=0.1]   96%|█████████▌| 75/78 [33:20<01:16, 25.38s/epoch, loss=1.1, accuracy=0.758, val_loss=2.7, val_accuracy=0.408, lr=0.1]   97%|█████████▋| 76/78 [33:46<00:50, 25.41s/epoch, loss=1.11, accuracy=0.76, val_loss=2.2, val_accuracy=0.514, lr=0.1] 99%|█████████▊| 77/78 [34:11<00:25, 25.44s/epoch, loss=1.11, accuracy=0.759, val_loss=1.38, val_accuracy=0.665, lr=0.1]100%|██████████| 78/78 [34:37<00:00, 25.45s/epoch, loss=1.11, accuracy=0.757, val_loss=1.72, val_accuracy=0.564, lr=0.0316]100%|██████████| 78/78 [34:37<00:00, 26.63s/epoch, loss=1.11, accuracy=0.757, val_loss=1.72, val_accuracy=0.564, lr=0.0316]
Using real-time data augmentation.
Test loss: 1.7225611209869385
Test accuracy: 0.5638999938964844


* * * Run SGD for ID = 19_5. * * *


2024-02-15 17:31:20.624757: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 17:31:23.409753: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 17:31:23.411099: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-15 17:31:23.454239: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:86:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 17:31:23.454288: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 17:31:23.457950: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 17:31:23.458018: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 17:31:23.460491: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 17:31:23.461268: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 17:31:23.464084: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 17:31:23.465836: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 17:31:23.471514: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 17:31:23.472179: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 17:31:23.472586: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 17:31:24.689962: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-15 17:31:24.690538: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 17:31:24.691061: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:86:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 17:31:24.691096: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 17:31:24.691133: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 17:31:24.691150: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 17:31:24.691165: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 17:31:24.691181: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 17:31:24.691205: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 17:31:24.691221: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 17:31:24.691237: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 17:31:24.691896: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 17:31:24.691938: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 17:31:25.307819: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-15 17:31:25.307876: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-15 17:31:25.307901: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-15 17:31:25.308929: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:86:00.0, compute capability: 6.1)
{'id': 195, 'batch_size': 128, 'epochs': 78, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/78 [00:00<?, ?epoch/s]2024-02-15 17:31:26.063727: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-15 17:31:26.075713: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2100000000 Hz
2024-02-15 17:31:27.824289: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 17:31:28.103402: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 17:31:29.087660: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-15 17:31:29.195657: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|▏         | 1/78 [01:08<1:27:50, 68.45s/epoch, loss=3.16, accuracy=0.274, val_loss=3.23, val_accuracy=0.132, lr=0.1]  3%|▎         | 2/78 [01:34<54:57, 43.38s/epoch, loss=1.56, accuracy=0.533, val_loss=1.82, val_accuracy=0.494, lr=0.1]    4%|▍         | 3/78 [01:59<43:47, 35.03s/epoch, loss=1.34, accuracy=0.647, val_loss=1.74, val_accuracy=0.524, lr=0.1]  5%|▌         | 4/78 [02:23<38:01, 30.83s/epoch, loss=1.28, accuracy=0.683, val_loss=1.68, val_accuracy=0.546, lr=0.1]  6%|▋         | 5/78 [02:49<35:14, 28.97s/epoch, loss=1.25, accuracy=0.698, val_loss=1.56, val_accuracy=0.592, lr=0.1]  8%|▊         | 6/78 [03:14<33:17, 27.74s/epoch, loss=1.22, accuracy=0.711, val_loss=1.93, val_accuracy=0.484, lr=0.1]  9%|▉         | 7/78 [03:40<32:00, 27.05s/epoch, loss=1.22, accuracy=0.718, val_loss=3.54, val_accuracy=0.314, lr=0.1] 10%|█         | 8/78 [04:05<30:57, 26.53s/epoch, loss=1.21, accuracy=0.721, val_loss=1.55, val_accuracy=0.604, lr=0.1] 12%|█▏        | 9/78 [04:30<29:57, 26.06s/epoch, loss=1.2, accuracy=0.726, val_loss=2.5, val_accuracy=0.419, lr=0.1]   13%|█▎        | 10/78 [04:56<29:25, 25.96s/epoch, loss=1.2, accuracy=0.727, val_loss=2.13, val_accuracy=0.461, lr=0.1] 14%|█▍        | 11/78 [05:21<28:45, 25.75s/epoch, loss=1.2, accuracy=0.728, val_loss=2.86, val_accuracy=0.457, lr=0.1] 15%|█▌        | 12/78 [05:47<28:21, 25.78s/epoch, loss=1.19, accuracy=0.733, val_loss=1.38, val_accuracy=0.676, lr=0.1] 17%|█▋        | 13/78 [06:13<27:54, 25.77s/epoch, loss=1.19, accuracy=0.732, val_loss=2.05, val_accuracy=0.516, lr=0.1] 18%|█▊        | 14/78 [06:39<27:35, 25.86s/epoch, loss=1.18, accuracy=0.737, val_loss=1.76, val_accuracy=0.556, lr=0.1] 19%|█▉        | 15/78 [07:05<27:09, 25.87s/epoch, loss=1.18, accuracy=0.734, val_loss=2.41, val_accuracy=0.46, lr=0.1]  21%|██        | 16/78 [07:31<26:42, 25.85s/epoch, loss=1.18, accuracy=0.736, val_loss=1.48, val_accuracy=0.641, lr=0.1] 22%|██▏       | 17/78 [07:56<26:03, 25.63s/epoch, loss=1.17, accuracy=0.743, val_loss=1.63, val_accuracy=0.603, lr=0.0316] 23%|██▎       | 18/78 [08:22<25:39, 25.67s/epoch, loss=1.18, accuracy=0.74, val_loss=1.71, val_accuracy=0.575, lr=0.1]     24%|██▍       | 19/78 [08:47<25:15, 25.68s/epoch, loss=1.17, accuracy=0.742, val_loss=1.51, val_accuracy=0.639, lr=0.1] 26%|██▌       | 20/78 [09:13<24:48, 25.67s/epoch, loss=1.17, accuracy=0.74, val_loss=1.86, val_accuracy=0.55, lr=0.1]   27%|██▋       | 21/78 [09:39<24:24, 25.69s/epoch, loss=1.17, accuracy=0.741, val_loss=1.52, val_accuracy=0.626, lr=0.1] 28%|██▊       | 22/78 [10:04<23:57, 25.66s/epoch, loss=1.16, accuracy=0.744, val_loss=2.14, val_accuracy=0.52, lr=0.0316] 29%|██▉       | 23/78 [10:31<23:47, 25.95s/epoch, loss=1.16, accuracy=0.742, val_loss=1.69, val_accuracy=0.579, lr=0.1]   31%|███       | 24/78 [10:57<23:20, 25.94s/epoch, loss=1.16, accuracy=0.743, val_loss=5.22, val_accuracy=0.286, lr=0.1] 32%|███▏      | 25/78 [11:22<22:43, 25.73s/epoch, loss=1.15, accuracy=0.744, val_loss=1.43, val_accuracy=0.635, lr=0.1] 33%|███▎      | 26/78 [11:48<22:15, 25.69s/epoch, loss=1.15, accuracy=0.746, val_loss=3.09, val_accuracy=0.419, lr=0.1] 35%|███▍      | 27/78 [12:14<22:03, 25.95s/epoch, loss=1.15, accuracy=0.745, val_loss=1.59, val_accuracy=0.597, lr=0.0316] 36%|███▌      | 28/78 [12:40<21:37, 25.95s/epoch, loss=1.15, accuracy=0.747, val_loss=2.35, val_accuracy=0.49, lr=0.1]     37%|███▋      | 29/78 [13:06<21:10, 25.93s/epoch, loss=1.15, accuracy=0.748, val_loss=2.16, val_accuracy=0.521, lr=0.1] 38%|███▊      | 30/78 [13:31<20:35, 25.75s/epoch, loss=1.15, accuracy=0.745, val_loss=1.69, val_accuracy=0.576, lr=0.1] 40%|███▉      | 31/78 [13:57<20:03, 25.62s/epoch, loss=1.15, accuracy=0.748, val_loss=1.99, val_accuracy=0.484, lr=0.1] 41%|████      | 32/78 [14:22<19:36, 25.57s/epoch, loss=1.15, accuracy=0.75, val_loss=2.02, val_accuracy=0.528, lr=0.0316] 42%|████▏     | 33/78 [14:48<19:09, 25.55s/epoch, loss=1.14, accuracy=0.75, val_loss=1.66, val_accuracy=0.599, lr=0.1]    44%|████▎     | 34/78 [15:13<18:36, 25.38s/epoch, loss=1.15, accuracy=0.748, val_loss=2.44, val_accuracy=0.379, lr=0.1] 45%|████▍     | 35/78 [15:38<18:06, 25.28s/epoch, loss=1.14, accuracy=0.751, val_loss=2.21, val_accuracy=0.461, lr=0.1] 46%|████▌     | 36/78 [16:03<17:41, 25.28s/epoch, loss=1.13, accuracy=0.751, val_loss=2.16, val_accuracy=0.505, lr=0.1] 47%|████▋     | 37/78 [16:29<17:24, 25.48s/epoch, loss=1.14, accuracy=0.751, val_loss=2.93, val_accuracy=0.347, lr=0.0316] 49%|████▊     | 38/78 [16:54<16:59, 25.49s/epoch, loss=1.14, accuracy=0.749, val_loss=2.23, val_accuracy=0.451, lr=0.1]    50%|█████     | 39/78 [17:20<16:35, 25.52s/epoch, loss=1.14, accuracy=0.749, val_loss=2.9, val_accuracy=0.342, lr=0.1]  51%|█████▏    | 40/78 [17:46<16:14, 25.64s/epoch, loss=1.14, accuracy=0.749, val_loss=1.99, val_accuracy=0.459, lr=0.1] 53%|█████▎    | 41/78 [18:11<15:46, 25.57s/epoch, loss=1.13, accuracy=0.751, val_loss=1.77, val_accuracy=0.574, lr=0.1] 54%|█████▍    | 42/78 [18:38<15:27, 25.77s/epoch, loss=1.14, accuracy=0.749, val_loss=2.12, val_accuracy=0.405, lr=0.0316] 55%|█████▌    | 43/78 [19:04<15:04, 25.83s/epoch, loss=1.13, accuracy=0.753, val_loss=1.84, val_accuracy=0.547, lr=0.1]    56%|█████▋    | 44/78 [19:29<14:36, 25.79s/epoch, loss=1.14, accuracy=0.748, val_loss=1.68, val_accuracy=0.581, lr=0.1] 58%|█████▊    | 45/78 [19:55<14:08, 25.72s/epoch, loss=1.14, accuracy=0.748, val_loss=1.79, val_accuracy=0.541, lr=0.1] 59%|█████▉    | 46/78 [20:20<13:39, 25.61s/epoch, loss=1.13, accuracy=0.752, val_loss=2.01, val_accuracy=0.528, lr=0.1] 60%|██████    | 47/78 [20:47<13:26, 26.03s/epoch, loss=1.13, accuracy=0.751, val_loss=1.65, val_accuracy=0.579, lr=0.0316] 62%|██████▏   | 48/78 [21:13<12:55, 25.85s/epoch, loss=1.13, accuracy=0.751, val_loss=1.51, val_accuracy=0.634, lr=0.1]    63%|██████▎   | 49/78 [21:39<12:37, 26.13s/epoch, loss=1.13, accuracy=0.754, val_loss=2.61, val_accuracy=0.466, lr=0.1] 64%|██████▍   | 50/78 [22:05<12:10, 26.09s/epoch, loss=1.13, accuracy=0.753, val_loss=1.94, val_accuracy=0.542, lr=0.1] 65%|██████▌   | 51/78 [22:32<11:47, 26.19s/epoch, loss=1.12, accuracy=0.754, val_loss=1.6, val_accuracy=0.595, lr=0.1]  67%|██████▋   | 52/78 [22:59<11:25, 26.38s/epoch, loss=1.13, accuracy=0.753, val_loss=1.6, val_accuracy=0.616, lr=0.0316] 68%|██████▊   | 53/78 [23:25<10:58, 26.34s/epoch, loss=1.13, accuracy=0.75, val_loss=4.22, val_accuracy=0.297, lr=0.1]    69%|██████▉   | 54/78 [23:52<10:39, 26.65s/epoch, loss=1.13, accuracy=0.752, val_loss=1.82, val_accuracy=0.518, lr=0.1] 71%|███████   | 55/78 [24:19<10:14, 26.74s/epoch, loss=1.14, accuracy=0.753, val_loss=1.45, val_accuracy=0.654, lr=0.1] 72%|███████▏  | 56/78 [24:46<09:47, 26.72s/epoch, loss=1.13, accuracy=0.754, val_loss=2.96, val_accuracy=0.344, lr=0.1] 73%|███████▎  | 57/78 [25:13<09:21, 26.76s/epoch, loss=1.13, accuracy=0.753, val_loss=5, val_accuracy=0.299, lr=0.0316] 74%|███████▍  | 58/78 [25:40<08:55, 26.78s/epoch, loss=1.13, accuracy=0.755, val_loss=1.92, val_accuracy=0.506, lr=0.1] 76%|███████▌  | 59/78 [26:06<08:27, 26.73s/epoch, loss=1.13, accuracy=0.753, val_loss=1.98, val_accuracy=0.541, lr=0.1] 77%|███████▋  | 60/78 [26:33<08:00, 26.67s/epoch, loss=1.13, accuracy=0.754, val_loss=1.87, val_accuracy=0.533, lr=0.1] 78%|███████▊  | 61/78 [27:00<07:34, 26.71s/epoch, loss=1.13, accuracy=0.753, val_loss=1.89, val_accuracy=0.552, lr=0.1] 79%|███████▉  | 62/78 [27:26<07:04, 26.54s/epoch, loss=1.13, accuracy=0.753, val_loss=1.38, val_accuracy=0.672, lr=0.1] 81%|████████  | 63/78 [27:52<06:35, 26.37s/epoch, loss=1.13, accuracy=0.754, val_loss=3.67, val_accuracy=0.396, lr=0.1] 82%|████████▏ | 64/78 [28:17<06:06, 26.20s/epoch, loss=1.13, accuracy=0.753, val_loss=2.3, val_accuracy=0.428, lr=0.1]  83%|████████▎ | 65/78 [28:43<05:37, 25.97s/epoch, loss=1.13, accuracy=0.754, val_loss=2.4, val_accuracy=0.474, lr=0.1] 85%|████████▍ | 66/78 [29:09<05:10, 25.88s/epoch, loss=1.14, accuracy=0.752, val_loss=2.12, val_accuracy=0.507, lr=0.1] 86%|████████▌ | 67/78 [29:34<04:43, 25.76s/epoch, loss=1.13, accuracy=0.755, val_loss=2.11, val_accuracy=0.45, lr=0.0316] 87%|████████▋ | 68/78 [30:00<04:17, 25.72s/epoch, loss=1.13, accuracy=0.753, val_loss=4.26, val_accuracy=0.225, lr=0.1]   88%|████████▊ | 69/78 [30:27<03:54, 26.10s/epoch, loss=1.13, accuracy=0.754, val_loss=1.9, val_accuracy=0.495, lr=0.1]  90%|████████▉ | 70/78 [30:54<03:30, 26.35s/epoch, loss=1.13, accuracy=0.756, val_loss=2.09, val_accuracy=0.47, lr=0.1] 91%|█████████ | 71/78 [31:20<03:05, 26.51s/epoch, loss=1.13, accuracy=0.755, val_loss=1.81, val_accuracy=0.524, lr=0.1] 92%|█████████▏| 72/78 [31:47<02:39, 26.60s/epoch, loss=1.13, accuracy=0.752, val_loss=3.39, val_accuracy=0.398, lr=0.0316] 94%|█████████▎| 73/78 [32:14<02:13, 26.61s/epoch, loss=1.13, accuracy=0.755, val_loss=1.73, val_accuracy=0.588, lr=0.1]    95%|█████████▍| 74/78 [32:40<01:46, 26.54s/epoch, loss=1.13, accuracy=0.752, val_loss=2.34, val_accuracy=0.435, lr=0.1] 96%|█████████▌| 75/78 [33:07<01:19, 26.63s/epoch, loss=1.13, accuracy=0.755, val_loss=2.71, val_accuracy=0.433, lr=0.1] 97%|█████████▋| 76/78 [33:34<00:53, 26.60s/epoch, loss=1.13, accuracy=0.753, val_loss=1.78, val_accuracy=0.561, lr=0.1] 99%|█████████▊| 77/78 [34:00<00:26, 26.40s/epoch, loss=1.13, accuracy=0.752, val_loss=1.79, val_accuracy=0.527, lr=0.0316]100%|██████████| 78/78 [34:25<00:00, 26.17s/epoch, loss=1.12, accuracy=0.754, val_loss=1.93, val_accuracy=0.468, lr=0.1]   100%|██████████| 78/78 [34:25<00:00, 26.48s/epoch, loss=1.12, accuracy=0.754, val_loss=1.93, val_accuracy=0.468, lr=0.1]
Using real-time data augmentation.
Test loss: 1.934939980506897
Test accuracy: 0.4683000147342682


* * * Run SGD for ID = 19_6. * * *


2024-02-15 18:05:54.518702: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 18:05:57.362216: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 18:05:57.363618: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-15 18:05:57.409375: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:86:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 18:05:57.409424: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 18:05:57.413040: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 18:05:57.413110: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 18:05:57.415567: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 18:05:57.416354: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 18:05:57.418968: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 18:05:57.420721: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 18:05:57.426341: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 18:05:57.427017: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 18:05:57.427410: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 18:05:58.622719: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-15 18:05:58.623755: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 18:05:58.624268: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:86:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 18:05:58.624304: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 18:05:58.624348: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 18:05:58.624364: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 18:05:58.624378: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 18:05:58.624393: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 18:05:58.624408: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 18:05:58.624423: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 18:05:58.624438: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 18:05:58.625004: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 18:05:58.625041: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 18:05:59.256547: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-15 18:05:59.256614: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-15 18:05:59.256626: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-15 18:05:59.257733: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:86:00.0, compute capability: 6.1)
{'id': 196, 'batch_size': 128, 'epochs': 78, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/78 [00:00<?, ?epoch/s]2024-02-15 18:06:00.019617: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-15 18:06:00.020126: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2100000000 Hz
2024-02-15 18:06:01.831962: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 18:06:02.109498: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 18:06:02.897301: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-15 18:06:02.941533: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|▏         | 1/78 [00:56<1:12:33, 56.54s/epoch, loss=3.06, accuracy=0.323, val_loss=2.71, val_accuracy=0.242, lr=0.1]  3%|▎         | 2/78 [01:22<48:50, 38.57s/epoch, loss=1.48, accuracy=0.578, val_loss=2.45, val_accuracy=0.408, lr=0.1]    4%|▍         | 3/78 [01:47<40:16, 32.22s/epoch, loss=1.31, accuracy=0.664, val_loss=2.09, val_accuracy=0.467, lr=0.1]  5%|▌         | 4/78 [02:11<36:07, 29.29s/epoch, loss=1.27, accuracy=0.693, val_loss=1.66, val_accuracy=0.563, lr=0.1]  6%|▋         | 5/78 [02:36<33:29, 27.53s/epoch, loss=1.24, accuracy=0.707, val_loss=2.43, val_accuracy=0.315, lr=0.1]  8%|▊         | 6/78 [03:02<32:22, 26.98s/epoch, loss=1.23, accuracy=0.717, val_loss=1.81, val_accuracy=0.558, lr=0.1]  9%|▉         | 7/78 [03:27<31:16, 26.43s/epoch, loss=1.22, accuracy=0.723, val_loss=1.94, val_accuracy=0.53, lr=0.1]  10%|█         | 8/78 [03:52<30:24, 26.06s/epoch, loss=1.2, accuracy=0.729, val_loss=2.1, val_accuracy=0.505, lr=0.1]  12%|█▏        | 9/78 [04:18<29:55, 26.02s/epoch, loss=1.2, accuracy=0.733, val_loss=1.72, val_accuracy=0.562, lr=0.0316] 13%|█▎        | 10/78 [04:44<29:29, 26.02s/epoch, loss=1.19, accuracy=0.734, val_loss=1.58, val_accuracy=0.607, lr=0.1]  14%|█▍        | 11/78 [05:10<28:51, 25.85s/epoch, loss=1.19, accuracy=0.737, val_loss=1.99, val_accuracy=0.505, lr=0.1] 15%|█▌        | 12/78 [05:36<28:33, 25.97s/epoch, loss=1.18, accuracy=0.74, val_loss=1.45, val_accuracy=0.648, lr=0.1]  17%|█▋        | 13/78 [06:02<28:11, 26.03s/epoch, loss=1.17, accuracy=0.739, val_loss=1.89, val_accuracy=0.497, lr=0.1] 18%|█▊        | 14/78 [06:28<27:37, 25.89s/epoch, loss=1.17, accuracy=0.74, val_loss=1.91, val_accuracy=0.552, lr=0.1]  19%|█▉        | 15/78 [06:53<26:55, 25.65s/epoch, loss=1.17, accuracy=0.746, val_loss=3.78, val_accuracy=0.275, lr=0.1] 21%|██        | 16/78 [07:19<26:33, 25.69s/epoch, loss=1.18, accuracy=0.744, val_loss=1.58, val_accuracy=0.598, lr=0.1] 22%|██▏       | 17/78 [07:45<26:18, 25.88s/epoch, loss=1.16, accuracy=0.748, val_loss=1.84, val_accuracy=0.544, lr=0.0316] 23%|██▎       | 18/78 [08:10<25:41, 25.70s/epoch, loss=1.16, accuracy=0.747, val_loss=2.07, val_accuracy=0.458, lr=0.1]    24%|██▍       | 19/78 [08:36<25:16, 25.70s/epoch, loss=1.17, accuracy=0.745, val_loss=1.88, val_accuracy=0.489, lr=0.1] 26%|██▌       | 20/78 [09:02<24:51, 25.72s/epoch, loss=1.16, accuracy=0.751, val_loss=2.41, val_accuracy=0.458, lr=0.1] 27%|██▋       | 21/78 [09:26<24:03, 25.32s/epoch, loss=1.15, accuracy=0.752, val_loss=1.67, val_accuracy=0.56, lr=0.1]  28%|██▊       | 22/78 [09:52<23:43, 25.42s/epoch, loss=1.16, accuracy=0.75, val_loss=1.53, val_accuracy=0.627, lr=0.0316] 29%|██▉       | 23/78 [10:16<23:01, 25.12s/epoch, loss=1.16, accuracy=0.75, val_loss=2.33, val_accuracy=0.37, lr=0.1]     31%|███       | 24/78 [10:41<22:36, 25.13s/epoch, loss=1.15, accuracy=0.754, val_loss=1.57, val_accuracy=0.594, lr=0.1] 32%|███▏      | 25/78 [11:06<22:10, 25.11s/epoch, loss=1.14, accuracy=0.755, val_loss=1.45, val_accuracy=0.646, lr=0.1] 33%|███▎      | 26/78 [11:32<21:50, 25.19s/epoch, loss=1.15, accuracy=0.752, val_loss=2.26, val_accuracy=0.428, lr=0.1] 35%|███▍      | 27/78 [11:57<21:22, 25.15s/epoch, loss=1.15, accuracy=0.754, val_loss=1.7, val_accuracy=0.582, lr=0.1]  36%|███▌      | 28/78 [12:22<20:57, 25.16s/epoch, loss=1.14, accuracy=0.752, val_loss=1.72, val_accuracy=0.585, lr=0.1] 37%|███▋      | 29/78 [12:47<20:30, 25.12s/epoch, loss=1.14, accuracy=0.753, val_loss=1.95, val_accuracy=0.487, lr=0.1] 38%|███▊      | 30/78 [13:13<20:17, 25.37s/epoch, loss=1.14, accuracy=0.753, val_loss=1.56, val_accuracy=0.623, lr=0.0316] 40%|███▉      | 31/78 [13:39<20:02, 25.59s/epoch, loss=1.14, accuracy=0.753, val_loss=2.82, val_accuracy=0.328, lr=0.1]    41%|████      | 32/78 [14:05<19:35, 25.55s/epoch, loss=1.13, accuracy=0.756, val_loss=1.89, val_accuracy=0.477, lr=0.1] 42%|████▏     | 33/78 [14:29<18:58, 25.31s/epoch, loss=1.13, accuracy=0.756, val_loss=1.5, val_accuracy=0.643, lr=0.1]  44%|████▎     | 34/78 [14:55<18:43, 25.53s/epoch, loss=1.13, accuracy=0.755, val_loss=1.84, val_accuracy=0.501, lr=0.1] 45%|████▍     | 35/78 [15:20<18:12, 25.41s/epoch, loss=1.14, accuracy=0.754, val_loss=1.63, val_accuracy=0.594, lr=0.0316] 46%|████▌     | 36/78 [15:45<17:38, 25.21s/epoch, loss=1.13, accuracy=0.757, val_loss=2.16, val_accuracy=0.453, lr=0.1]    47%|████▋     | 37/78 [16:11<17:19, 25.35s/epoch, loss=1.13, accuracy=0.754, val_loss=1.83, val_accuracy=0.527, lr=0.1] 49%|████▊     | 38/78 [16:36<16:53, 25.34s/epoch, loss=1.13, accuracy=0.757, val_loss=1.84, val_accuracy=0.536, lr=0.1] 50%|█████     | 39/78 [17:02<16:35, 25.52s/epoch, loss=1.13, accuracy=0.755, val_loss=1.83, val_accuracy=0.532, lr=0.1] 51%|█████▏    | 40/78 [17:29<16:19, 25.79s/epoch, loss=1.13, accuracy=0.755, val_loss=1.73, val_accuracy=0.56, lr=0.0316] 53%|█████▎    | 41/78 [17:53<15:39, 25.39s/epoch, loss=1.14, accuracy=0.755, val_loss=1.56, val_accuracy=0.623, lr=0.1]   54%|█████▍    | 42/78 [18:18<15:11, 25.31s/epoch, loss=1.12, accuracy=0.758, val_loss=2.34, val_accuracy=0.469, lr=0.1] 55%|█████▌    | 43/78 [18:44<14:51, 25.47s/epoch, loss=1.13, accuracy=0.756, val_loss=1.46, val_accuracy=0.627, lr=0.1] 56%|█████▋    | 44/78 [19:09<14:21, 25.34s/epoch, loss=1.13, accuracy=0.758, val_loss=4.56, val_accuracy=0.264, lr=0.1] 58%|█████▊    | 45/78 [19:34<13:52, 25.22s/epoch, loss=1.13, accuracy=0.758, val_loss=3.29, val_accuracy=0.309, lr=0.0316] 59%|█████▉    | 46/78 [19:59<13:28, 25.26s/epoch, loss=1.12, accuracy=0.757, val_loss=2.39, val_accuracy=0.421, lr=0.1]    60%|██████    | 47/78 [20:25<13:04, 25.29s/epoch, loss=1.13, accuracy=0.756, val_loss=2.41, val_accuracy=0.442, lr=0.1] 62%|██████▏   | 48/78 [20:50<12:43, 25.45s/epoch, loss=1.12, accuracy=0.761, val_loss=4.62, val_accuracy=0.246, lr=0.1] 63%|██████▎   | 49/78 [21:16<12:22, 25.60s/epoch, loss=1.13, accuracy=0.758, val_loss=1.7, val_accuracy=0.581, lr=0.1]  64%|██████▍   | 50/78 [21:42<11:56, 25.58s/epoch, loss=1.13, accuracy=0.755, val_loss=1.46, val_accuracy=0.635, lr=0.0316] 65%|██████▌   | 51/78 [22:08<11:31, 25.61s/epoch, loss=1.12, accuracy=0.755, val_loss=4.33, val_accuracy=0.231, lr=0.1]    67%|██████▋   | 52/78 [22:33<11:03, 25.53s/epoch, loss=1.12, accuracy=0.759, val_loss=2.68, val_accuracy=0.403, lr=0.1] 68%|██████▊   | 53/78 [22:59<10:38, 25.53s/epoch, loss=1.12, accuracy=0.758, val_loss=1.71, val_accuracy=0.589, lr=0.1] 69%|██████▉   | 54/78 [23:24<10:08, 25.36s/epoch, loss=1.12, accuracy=0.758, val_loss=3.03, val_accuracy=0.346, lr=0.1] 71%|███████   | 55/78 [23:48<09:38, 25.17s/epoch, loss=1.12, accuracy=0.757, val_loss=1.97, val_accuracy=0.484, lr=0.0316] 72%|███████▏  | 56/78 [24:14<09:15, 25.26s/epoch, loss=1.12, accuracy=0.756, val_loss=1.59, val_accuracy=0.595, lr=0.1]    73%|███████▎  | 57/78 [24:39<08:52, 25.34s/epoch, loss=1.12, accuracy=0.758, val_loss=1.76, val_accuracy=0.575, lr=0.1] 74%|███████▍  | 58/78 [25:04<08:20, 25.05s/epoch, loss=1.12, accuracy=0.757, val_loss=1.66, val_accuracy=0.561, lr=0.1] 76%|███████▌  | 59/78 [25:29<07:56, 25.08s/epoch, loss=1.11, accuracy=0.76, val_loss=1.95, val_accuracy=0.486, lr=0.1]  77%|███████▋  | 60/78 [25:54<07:30, 25.01s/epoch, loss=1.12, accuracy=0.757, val_loss=2.36, val_accuracy=0.39, lr=0.0316] 78%|███████▊  | 61/78 [26:19<07:06, 25.11s/epoch, loss=1.12, accuracy=0.759, val_loss=1.47, val_accuracy=0.632, lr=0.1]   79%|███████▉  | 62/78 [26:44<06:43, 25.23s/epoch, loss=1.11, accuracy=0.758, val_loss=1.73, val_accuracy=0.573, lr=0.1] 81%|████████  | 63/78 [27:10<06:18, 25.25s/epoch, loss=1.12, accuracy=0.76, val_loss=2.25, val_accuracy=0.474, lr=0.1]  82%|████████▏ | 64/78 [27:35<05:51, 25.13s/epoch, loss=1.12, accuracy=0.758, val_loss=2.74, val_accuracy=0.41, lr=0.1] 83%|████████▎ | 65/78 [28:01<05:29, 25.38s/epoch, loss=1.12, accuracy=0.756, val_loss=7.72, val_accuracy=0.21, lr=0.0316] 85%|████████▍ | 66/78 [28:25<05:02, 25.21s/epoch, loss=1.12, accuracy=0.758, val_loss=1.73, val_accuracy=0.6, lr=0.1]     86%|████████▌ | 67/78 [28:51<04:37, 25.27s/epoch, loss=1.12, accuracy=0.757, val_loss=1.37, val_accuracy=0.667, lr=0.1] 87%|████████▋ | 68/78 [29:16<04:12, 25.27s/epoch, loss=1.12, accuracy=0.758, val_loss=5.97, val_accuracy=0.198, lr=0.1] 88%|████████▊ | 69/78 [29:42<03:48, 25.40s/epoch, loss=1.11, accuracy=0.758, val_loss=5.57, val_accuracy=0.254, lr=0.1] 90%|████████▉ | 70/78 [30:07<03:22, 25.37s/epoch, loss=1.12, accuracy=0.757, val_loss=1.7, val_accuracy=0.578, lr=0.1]  91%|█████████ | 71/78 [30:32<02:56, 25.20s/epoch, loss=1.11, accuracy=0.76, val_loss=2.1, val_accuracy=0.453, lr=0.1]  92%|█████████▏| 72/78 [30:57<02:30, 25.15s/epoch, loss=1.12, accuracy=0.758, val_loss=2.53, val_accuracy=0.42, lr=0.0316] 94%|█████████▎| 73/78 [31:23<02:06, 25.36s/epoch, loss=1.12, accuracy=0.76, val_loss=1.76, val_accuracy=0.566, lr=0.1]    95%|█████████▍| 74/78 [31:47<01:40, 25.12s/epoch, loss=1.12, accuracy=0.759, val_loss=2.79, val_accuracy=0.402, lr=0.1] 96%|█████████▌| 75/78 [32:12<01:15, 25.10s/epoch, loss=1.12, accuracy=0.757, val_loss=2.02, val_accuracy=0.486, lr=0.1] 97%|█████████▋| 76/78 [32:37<00:49, 24.99s/epoch, loss=1.12, accuracy=0.757, val_loss=4.21, val_accuracy=0.301, lr=0.1] 99%|█████████▊| 77/78 [33:01<00:24, 24.79s/epoch, loss=1.12, accuracy=0.757, val_loss=2.07, val_accuracy=0.546, lr=0.0316]100%|██████████| 78/78 [33:26<00:00, 24.70s/epoch, loss=1.12, accuracy=0.757, val_loss=2.28, val_accuracy=0.459, lr=0.1]   100%|██████████| 78/78 [33:26<00:00, 25.72s/epoch, loss=1.12, accuracy=0.757, val_loss=2.28, val_accuracy=0.459, lr=0.1]
Using real-time data augmentation.
Test loss: 2.2829976081848145
Test accuracy: 0.45879998803138733


* * * Run SGD for ID = 19_7. * * *


2024-02-15 18:39:28.950733: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 18:39:31.655281: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 18:39:31.656464: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-15 18:39:31.696962: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:86:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 18:39:31.697006: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 18:39:31.700607: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 18:39:31.700692: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 18:39:31.703292: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 18:39:31.704206: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 18:39:31.707080: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 18:39:31.708849: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 18:39:31.714674: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 18:39:31.715322: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 18:39:31.715402: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 18:39:32.905740: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-15 18:39:32.906375: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 18:39:32.907236: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:86:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 18:39:32.907272: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 18:39:32.907335: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 18:39:32.907353: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 18:39:32.907371: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 18:39:32.907388: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 18:39:32.907406: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 18:39:32.907423: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 18:39:32.907443: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 18:39:32.907989: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 18:39:32.908029: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 18:39:33.521379: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-15 18:39:33.521432: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-15 18:39:33.521442: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-15 18:39:33.522439: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:86:00.0, compute capability: 6.1)
{'id': 197, 'batch_size': 128, 'epochs': 78, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/78 [00:00<?, ?epoch/s]2024-02-15 18:39:34.276917: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-15 18:39:34.288723: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2100000000 Hz
2024-02-15 18:39:36.071377: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 18:39:36.320359: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 18:39:37.143982: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-15 18:39:37.224548: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|▏         | 1/78 [00:56<1:12:23, 56.41s/epoch, loss=3.3, accuracy=0.201, val_loss=2.39, val_accuracy=0.223, lr=0.1]  3%|▎         | 2/78 [01:22<48:40, 38.43s/epoch, loss=1.67, accuracy=0.456, val_loss=3.16, val_accuracy=0.323, lr=0.1]   4%|▍         | 3/78 [01:47<40:23, 32.31s/epoch, loss=1.36, accuracy=0.609, val_loss=2.17, val_accuracy=0.416, lr=0.1]  5%|▌         | 4/78 [02:12<36:34, 29.66s/epoch, loss=1.26, accuracy=0.668, val_loss=4.32, val_accuracy=0.279, lr=0.1]  6%|▋         | 5/78 [02:38<34:29, 28.35s/epoch, loss=1.22, accuracy=0.697, val_loss=1.61, val_accuracy=0.562, lr=0.1]  8%|▊         | 6/78 [03:03<32:37, 27.18s/epoch, loss=1.21, accuracy=0.707, val_loss=1.92, val_accuracy=0.512, lr=0.1]  9%|▉         | 7/78 [03:28<31:20, 26.48s/epoch, loss=1.2, accuracy=0.718, val_loss=2.38, val_accuracy=0.417, lr=0.1]  10%|█         | 8/78 [03:54<30:24, 26.07s/epoch, loss=1.19, accuracy=0.723, val_loss=2.42, val_accuracy=0.474, lr=0.1] 12%|█▏        | 9/78 [04:19<29:49, 25.94s/epoch, loss=1.19, accuracy=0.726, val_loss=2.76, val_accuracy=0.411, lr=0.1] 13%|█▎        | 10/78 [04:45<29:23, 25.93s/epoch, loss=1.19, accuracy=0.73, val_loss=3.66, val_accuracy=0.342, lr=0.0316] 14%|█▍        | 11/78 [05:11<28:52, 25.86s/epoch, loss=1.19, accuracy=0.732, val_loss=2.54, val_accuracy=0.429, lr=0.1]   15%|█▌        | 12/78 [05:36<28:22, 25.80s/epoch, loss=1.18, accuracy=0.733, val_loss=2.22, val_accuracy=0.459, lr=0.1] 17%|█▋        | 13/78 [06:01<27:40, 25.55s/epoch, loss=1.18, accuracy=0.736, val_loss=2.3, val_accuracy=0.458, lr=0.1]  18%|█▊        | 14/78 [06:27<27:14, 25.54s/epoch, loss=1.17, accuracy=0.738, val_loss=2.6, val_accuracy=0.41, lr=0.1]  19%|█▉        | 15/78 [06:53<26:50, 25.56s/epoch, loss=1.18, accuracy=0.74, val_loss=2.43, val_accuracy=0.401, lr=0.0316] 21%|██        | 16/78 [07:18<26:19, 25.48s/epoch, loss=1.16, accuracy=0.743, val_loss=1.95, val_accuracy=0.545, lr=0.1]   22%|██▏       | 17/78 [07:43<25:55, 25.50s/epoch, loss=1.16, accuracy=0.74, val_loss=2.2, val_accuracy=0.507, lr=0.1]   23%|██▎       | 18/78 [08:09<25:37, 25.63s/epoch, loss=1.15, accuracy=0.745, val_loss=1.79, val_accuracy=0.544, lr=0.1] 24%|██▍       | 19/78 [08:35<25:04, 25.50s/epoch, loss=1.15, accuracy=0.742, val_loss=1.87, val_accuracy=0.547, lr=0.1] 26%|██▌       | 20/78 [09:00<24:44, 25.60s/epoch, loss=1.15, accuracy=0.745, val_loss=3.31, val_accuracy=0.31, lr=0.0316] 27%|██▋       | 21/78 [09:26<24:26, 25.73s/epoch, loss=1.16, accuracy=0.745, val_loss=2.19, val_accuracy=0.436, lr=0.1]   28%|██▊       | 22/78 [09:51<23:44, 25.44s/epoch, loss=1.15, accuracy=0.746, val_loss=1.99, val_accuracy=0.524, lr=0.1] 29%|██▉       | 23/78 [10:17<23:29, 25.63s/epoch, loss=1.15, accuracy=0.747, val_loss=2.19, val_accuracy=0.502, lr=0.1] 31%|███       | 24/78 [10:42<22:53, 25.43s/epoch, loss=1.15, accuracy=0.744, val_loss=2.39, val_accuracy=0.361, lr=0.1] 32%|███▏      | 25/78 [11:08<22:31, 25.49s/epoch, loss=1.14, accuracy=0.745, val_loss=3.43, val_accuracy=0.384, lr=0.0316] 33%|███▎      | 26/78 [11:32<21:51, 25.22s/epoch, loss=1.13, accuracy=0.75, val_loss=1.92, val_accuracy=0.523, lr=0.1]     35%|███▍      | 27/78 [11:58<21:28, 25.26s/epoch, loss=1.14, accuracy=0.747, val_loss=1.97, val_accuracy=0.504, lr=0.1] 36%|███▌      | 28/78 [12:22<20:53, 25.08s/epoch, loss=1.14, accuracy=0.748, val_loss=2.03, val_accuracy=0.497, lr=0.1] 37%|███▋      | 29/78 [12:48<20:37, 25.25s/epoch, loss=1.14, accuracy=0.75, val_loss=2.86, val_accuracy=0.257, lr=0.1]  38%|███▊      | 30/78 [13:13<20:09, 25.20s/epoch, loss=1.14, accuracy=0.748, val_loss=2.19, val_accuracy=0.399, lr=0.0316] 40%|███▉      | 31/78 [13:38<19:37, 25.06s/epoch, loss=1.13, accuracy=0.751, val_loss=2.19, val_accuracy=0.456, lr=0.1]    41%|████      | 32/78 [14:04<19:22, 25.28s/epoch, loss=1.12, accuracy=0.751, val_loss=1.71, val_accuracy=0.556, lr=0.1] 42%|████▏     | 33/78 [14:29<18:55, 25.24s/epoch, loss=1.13, accuracy=0.75, val_loss=2.62, val_accuracy=0.316, lr=0.1]  44%|████▎     | 34/78 [14:54<18:32, 25.29s/epoch, loss=1.12, accuracy=0.753, val_loss=4.7, val_accuracy=0.268, lr=0.1] 45%|████▍     | 35/78 [15:19<18:02, 25.17s/epoch, loss=1.13, accuracy=0.75, val_loss=2.4, val_accuracy=0.439, lr=0.0316] 46%|████▌     | 36/78 [15:44<17:32, 25.06s/epoch, loss=1.12, accuracy=0.752, val_loss=1.82, val_accuracy=0.506, lr=0.1]  47%|████▋     | 37/78 [16:09<17:08, 25.08s/epoch, loss=1.13, accuracy=0.751, val_loss=1.58, val_accuracy=0.608, lr=0.1] 49%|████▊     | 38/78 [16:35<16:59, 25.48s/epoch, loss=1.13, accuracy=0.751, val_loss=2.17, val_accuracy=0.475, lr=0.1] 50%|█████     | 39/78 [17:01<16:34, 25.51s/epoch, loss=1.12, accuracy=0.753, val_loss=1.61, val_accuracy=0.618, lr=0.1] 51%|█████▏    | 40/78 [17:27<16:10, 25.55s/epoch, loss=1.12, accuracy=0.752, val_loss=2.03, val_accuracy=0.489, lr=0.1] 53%|█████▎    | 41/78 [17:51<15:33, 25.24s/epoch, loss=1.13, accuracy=0.75, val_loss=3.59, val_accuracy=0.241, lr=0.1]  54%|█████▍    | 42/78 [18:17<15:16, 25.47s/epoch, loss=1.12, accuracy=0.755, val_loss=1.56, val_accuracy=0.601, lr=0.1] 55%|█████▌    | 43/78 [18:42<14:44, 25.27s/epoch, loss=1.12, accuracy=0.752, val_loss=1.93, val_accuracy=0.503, lr=0.1] 56%|█████▋    | 44/78 [19:08<14:23, 25.40s/epoch, loss=1.12, accuracy=0.754, val_loss=2.29, val_accuracy=0.451, lr=0.1] 58%|█████▊    | 45/78 [19:33<13:58, 25.42s/epoch, loss=1.11, accuracy=0.756, val_loss=3.81, val_accuracy=0.37, lr=0.1]  59%|█████▉    | 46/78 [19:59<13:41, 25.67s/epoch, loss=1.11, accuracy=0.756, val_loss=2.68, val_accuracy=0.364, lr=0.1] 60%|██████    | 47/78 [20:25<13:11, 25.52s/epoch, loss=1.12, accuracy=0.754, val_loss=1.59, val_accuracy=0.619, lr=0.0316] 62%|██████▏   | 48/78 [20:50<12:40, 25.36s/epoch, loss=1.11, accuracy=0.755, val_loss=2.44, val_accuracy=0.402, lr=0.1]    63%|██████▎   | 49/78 [21:15<12:12, 25.27s/epoch, loss=1.12, accuracy=0.752, val_loss=3.36, val_accuracy=0.26, lr=0.1]  64%|██████▍   | 50/78 [21:40<11:47, 25.26s/epoch, loss=1.11, accuracy=0.754, val_loss=1.56, val_accuracy=0.611, lr=0.1] 65%|██████▌   | 51/78 [22:06<11:28, 25.51s/epoch, loss=1.11, accuracy=0.754, val_loss=2.07, val_accuracy=0.416, lr=0.1] 67%|██████▋   | 52/78 [22:32<11:08, 25.71s/epoch, loss=1.12, accuracy=0.753, val_loss=1.39, val_accuracy=0.669, lr=0.1] 68%|██████▊   | 53/78 [22:57<10:39, 25.59s/epoch, loss=1.11, accuracy=0.755, val_loss=2.28, val_accuracy=0.322, lr=0.1] 69%|██████▉   | 54/78 [23:23<10:13, 25.56s/epoch, loss=1.11, accuracy=0.756, val_loss=1.46, val_accuracy=0.645, lr=0.1] 71%|███████   | 55/78 [23:49<09:47, 25.56s/epoch, loss=1.11, accuracy=0.756, val_loss=5.76, val_accuracy=0.214, lr=0.1] 72%|███████▏  | 56/78 [24:14<09:22, 25.58s/epoch, loss=1.11, accuracy=0.755, val_loss=1.65, val_accuracy=0.562, lr=0.1] 73%|███████▎  | 57/78 [24:39<08:52, 25.34s/epoch, loss=1.11, accuracy=0.757, val_loss=1.69, val_accuracy=0.576, lr=0.0316] 74%|███████▍  | 58/78 [25:03<08:20, 25.02s/epoch, loss=1.11, accuracy=0.757, val_loss=3.22, val_accuracy=0.355, lr=0.1]    76%|███████▌  | 59/78 [25:29<07:58, 25.17s/epoch, loss=1.11, accuracy=0.756, val_loss=1.83, val_accuracy=0.501, lr=0.1] 77%|███████▋  | 60/78 [25:54<07:33, 25.19s/epoch, loss=1.11, accuracy=0.755, val_loss=1.96, val_accuracy=0.528, lr=0.1] 78%|███████▊  | 61/78 [26:20<07:12, 25.45s/epoch, loss=1.11, accuracy=0.758, val_loss=2.06, val_accuracy=0.502, lr=0.1] 79%|███████▉  | 62/78 [26:46<06:50, 25.66s/epoch, loss=1.11, accuracy=0.757, val_loss=2.31, val_accuracy=0.431, lr=0.0316] 81%|████████  | 63/78 [27:11<06:21, 25.43s/epoch, loss=1.11, accuracy=0.756, val_loss=2.64, val_accuracy=0.22, lr=0.1]     82%|████████▏ | 64/78 [27:37<05:58, 25.59s/epoch, loss=1.11, accuracy=0.758, val_loss=2.33, val_accuracy=0.387, lr=0.1] 83%|████████▎ | 65/78 [28:03<05:32, 25.56s/epoch, loss=1.11, accuracy=0.755, val_loss=2.68, val_accuracy=0.378, lr=0.1] 85%|████████▍ | 66/78 [28:28<05:08, 25.67s/epoch, loss=1.11, accuracy=0.757, val_loss=2.44, val_accuracy=0.417, lr=0.1] 86%|████████▌ | 67/78 [28:54<04:41, 25.61s/epoch, loss=1.11, accuracy=0.757, val_loss=1.69, val_accuracy=0.54, lr=0.0316] 87%|████████▋ | 68/78 [29:20<04:16, 25.67s/epoch, loss=1.11, accuracy=0.757, val_loss=2.13, val_accuracy=0.456, lr=0.1]   88%|████████▊ | 69/78 [29:45<03:50, 25.61s/epoch, loss=1.11, accuracy=0.758, val_loss=2.89, val_accuracy=0.385, lr=0.1] 90%|████████▉ | 70/78 [30:11<03:24, 25.53s/epoch, loss=1.12, accuracy=0.752, val_loss=1.72, val_accuracy=0.558, lr=0.1] 91%|█████████ | 71/78 [30:35<02:56, 25.27s/epoch, loss=1.12, accuracy=0.757, val_loss=2.21, val_accuracy=0.455, lr=0.1] 92%|█████████▏| 72/78 [31:01<02:32, 25.39s/epoch, loss=1.11, accuracy=0.756, val_loss=1.97, val_accuracy=0.464, lr=0.0316] 94%|█████████▎| 73/78 [31:26<02:06, 25.29s/epoch, loss=1.11, accuracy=0.757, val_loss=4.13, val_accuracy=0.294, lr=0.1]    95%|█████████▍| 74/78 [31:51<01:41, 25.33s/epoch, loss=1.11, accuracy=0.757, val_loss=1.65, val_accuracy=0.559, lr=0.1] 96%|█████████▌| 75/78 [32:17<01:16, 25.35s/epoch, loss=1.11, accuracy=0.753, val_loss=2.61, val_accuracy=0.346, lr=0.1] 97%|█████████▋| 76/78 [32:43<00:51, 25.65s/epoch, loss=1.11, accuracy=0.757, val_loss=5.76, val_accuracy=0.225, lr=0.1] 99%|█████████▊| 77/78 [33:08<00:25, 25.39s/epoch, loss=1.11, accuracy=0.758, val_loss=3.65, val_accuracy=0.279, lr=0.0316]100%|██████████| 78/78 [33:34<00:00, 25.51s/epoch, loss=1.11, accuracy=0.76, val_loss=1.81, val_accuracy=0.564, lr=0.1]    100%|██████████| 78/78 [33:34<00:00, 25.82s/epoch, loss=1.11, accuracy=0.76, val_loss=1.81, val_accuracy=0.564, lr=0.1]
Using real-time data augmentation.
Test loss: 1.8145577907562256
Test accuracy: 0.564300000667572


* * * Run SGD for ID = 19_8. * * *


2024-02-15 19:13:11.936227: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 19:13:19.364622: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 19:13:19.365911: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-15 19:13:19.404462: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:86:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 19:13:19.404502: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 19:13:19.412482: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 19:13:19.412550: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 19:13:19.416733: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 19:13:19.418929: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 19:13:19.422661: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 19:13:19.425915: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 19:13:19.433338: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 19:13:19.434001: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 19:13:19.434087: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 19:13:20.595644: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-15 19:13:20.596749: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 19:13:20.597611: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:86:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 19:13:20.597649: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 19:13:20.597713: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 19:13:20.597732: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 19:13:20.597749: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 19:13:20.597766: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 19:13:20.597784: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 19:13:20.597812: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 19:13:20.597829: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 19:13:20.598336: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 19:13:20.598376: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 19:13:21.212408: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-15 19:13:21.212460: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-15 19:13:21.212470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-15 19:13:21.214191: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:86:00.0, compute capability: 6.1)
{'id': 198, 'batch_size': 128, 'epochs': 78, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/78 [00:00<?, ?epoch/s]2024-02-15 19:13:21.951713: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-15 19:13:21.963709: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2100000000 Hz
2024-02-15 19:13:23.721355: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 19:13:23.973509: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 19:13:24.944609: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-15 19:13:24.989865: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|▏         | 1/78 [01:01<1:18:59, 61.56s/epoch, loss=3.24, accuracy=0.266, val_loss=2.45, val_accuracy=0.16, lr=0.1]  3%|▎         | 2/78 [01:26<50:42, 40.04s/epoch, loss=1.6, accuracy=0.513, val_loss=1.75, val_accuracy=0.488, lr=0.1]    4%|▍         | 3/78 [01:52<41:46, 33.42s/epoch, loss=1.38, accuracy=0.628, val_loss=1.58, val_accuracy=0.571, lr=0.1]  5%|▌         | 4/78 [02:17<37:27, 30.37s/epoch, loss=1.29, accuracy=0.679, val_loss=2, val_accuracy=0.467, lr=0.1]     6%|▋         | 5/78 [02:43<34:44, 28.56s/epoch, loss=1.26, accuracy=0.696, val_loss=2.51, val_accuracy=0.35, lr=0.1]  8%|▊         | 6/78 [03:08<32:50, 27.37s/epoch, loss=1.23, accuracy=0.712, val_loss=1.81, val_accuracy=0.589, lr=0.1]  9%|▉         | 7/78 [03:33<31:30, 26.62s/epoch, loss=1.22, accuracy=0.719, val_loss=2.34, val_accuracy=0.364, lr=0.1] 10%|█         | 8/78 [03:58<30:36, 26.23s/epoch, loss=1.21, accuracy=0.724, val_loss=2.14, val_accuracy=0.434, lr=0.0316] 12%|█▏        | 9/78 [04:24<29:51, 25.97s/epoch, loss=1.21, accuracy=0.724, val_loss=1.46, val_accuracy=0.63, lr=0.1]     13%|█▎        | 10/78 [04:49<29:21, 25.90s/epoch, loss=1.19, accuracy=0.732, val_loss=1.53, val_accuracy=0.641, lr=0.1] 14%|█▍        | 11/78 [05:15<28:54, 25.89s/epoch, loss=1.2, accuracy=0.732, val_loss=1.87, val_accuracy=0.526, lr=0.1]  15%|█▌        | 12/78 [05:41<28:19, 25.76s/epoch, loss=1.19, accuracy=0.734, val_loss=2.03, val_accuracy=0.493, lr=0.1] 17%|█▋        | 13/78 [06:06<27:48, 25.67s/epoch, loss=1.2, accuracy=0.732, val_loss=1.73, val_accuracy=0.571, lr=0.1]  18%|█▊        | 14/78 [06:31<27:17, 25.58s/epoch, loss=1.19, accuracy=0.74, val_loss=1.76, val_accuracy=0.532, lr=0.0316] 19%|█▉        | 15/78 [06:57<26:50, 25.56s/epoch, loss=1.2, accuracy=0.737, val_loss=2.46, val_accuracy=0.442, lr=0.1]    21%|██        | 16/78 [07:23<26:25, 25.58s/epoch, loss=1.17, accuracy=0.741, val_loss=2.16, val_accuracy=0.396, lr=0.1] 22%|██▏       | 17/78 [07:48<26:01, 25.59s/epoch, loss=1.18, accuracy=0.74, val_loss=2.55, val_accuracy=0.448, lr=0.1]  23%|██▎       | 18/78 [08:14<25:44, 25.74s/epoch, loss=1.17, accuracy=0.743, val_loss=2.89, val_accuracy=0.265, lr=0.1] 24%|██▍       | 19/78 [08:40<25:10, 25.59s/epoch, loss=1.15, accuracy=0.746, val_loss=2.04, val_accuracy=0.439, lr=0.0316] 26%|██▌       | 20/78 [09:05<24:38, 25.49s/epoch, loss=1.17, accuracy=0.743, val_loss=1.78, val_accuracy=0.591, lr=0.1]    27%|██▋       | 21/78 [09:30<24:03, 25.33s/epoch, loss=1.16, accuracy=0.745, val_loss=1.71, val_accuracy=0.564, lr=0.1] 28%|██▊       | 22/78 [09:55<23:42, 25.40s/epoch, loss=1.16, accuracy=0.748, val_loss=1.82, val_accuracy=0.534, lr=0.1] 29%|██▉       | 23/78 [10:21<23:22, 25.49s/epoch, loss=1.15, accuracy=0.749, val_loss=1.45, val_accuracy=0.631, lr=0.1] 31%|███       | 24/78 [10:46<22:56, 25.49s/epoch, loss=1.16, accuracy=0.748, val_loss=1.57, val_accuracy=0.611, lr=0.1] 32%|███▏      | 25/78 [11:13<22:39, 25.66s/epoch, loss=1.15, accuracy=0.746, val_loss=1.72, val_accuracy=0.591, lr=0.1] 33%|███▎      | 26/78 [11:38<22:08, 25.56s/epoch, loss=1.15, accuracy=0.748, val_loss=3.16, val_accuracy=0.37, lr=0.1]  35%|███▍      | 27/78 [12:02<21:26, 25.23s/epoch, loss=1.14, accuracy=0.748, val_loss=2.17, val_accuracy=0.441, lr=0.1] 36%|███▌      | 28/78 [12:28<21:05, 25.32s/epoch, loss=1.14, accuracy=0.749, val_loss=3.86, val_accuracy=0.372, lr=0.0316] 37%|███▋      | 29/78 [12:53<20:43, 25.39s/epoch, loss=1.15, accuracy=0.749, val_loss=2.56, val_accuracy=0.426, lr=0.1]    38%|███▊      | 30/78 [13:19<20:24, 25.50s/epoch, loss=1.14, accuracy=0.75, val_loss=1.73, val_accuracy=0.579, lr=0.1]  40%|███▉      | 31/78 [13:45<19:56, 25.45s/epoch, loss=1.15, accuracy=0.749, val_loss=1.96, val_accuracy=0.499, lr=0.1] 41%|████      | 32/78 [14:10<19:30, 25.44s/epoch, loss=1.14, accuracy=0.75, val_loss=1.42, val_accuracy=0.653, lr=0.1]  42%|████▏     | 33/78 [14:36<19:14, 25.66s/epoch, loss=1.14, accuracy=0.751, val_loss=3.96, val_accuracy=0.262, lr=0.1] 44%|████▎     | 34/78 [15:01<18:40, 25.47s/epoch, loss=1.14, accuracy=0.75, val_loss=1.71, val_accuracy=0.561, lr=0.1]  45%|████▍     | 35/78 [15:27<18:17, 25.53s/epoch, loss=1.14, accuracy=0.752, val_loss=2.39, val_accuracy=0.434, lr=0.1] 46%|████▌     | 36/78 [15:52<17:53, 25.57s/epoch, loss=1.13, accuracy=0.753, val_loss=1.51, val_accuracy=0.613, lr=0.1] 47%|████▋     | 37/78 [16:18<17:31, 25.63s/epoch, loss=1.14, accuracy=0.752, val_loss=3.35, val_accuracy=0.282, lr=0.0316] 49%|████▊     | 38/78 [16:44<17:08, 25.70s/epoch, loss=1.13, accuracy=0.752, val_loss=3.9, val_accuracy=0.271, lr=0.1]     50%|█████     | 39/78 [17:10<16:42, 25.70s/epoch, loss=1.14, accuracy=0.752, val_loss=3.89, val_accuracy=0.356, lr=0.1] 51%|█████▏    | 40/78 [17:36<16:18, 25.76s/epoch, loss=1.13, accuracy=0.752, val_loss=1.74, val_accuracy=0.518, lr=0.1] 53%|█████▎    | 41/78 [18:01<15:53, 25.76s/epoch, loss=1.13, accuracy=0.752, val_loss=2.03, val_accuracy=0.451, lr=0.1] 54%|█████▍    | 42/78 [18:26<15:15, 25.42s/epoch, loss=1.13, accuracy=0.754, val_loss=2.38, val_accuracy=0.422, lr=0.0316] 55%|█████▌    | 43/78 [18:52<14:52, 25.49s/epoch, loss=1.13, accuracy=0.753, val_loss=2.48, val_accuracy=0.438, lr=0.1]    56%|█████▋    | 44/78 [19:18<14:31, 25.64s/epoch, loss=1.13, accuracy=0.757, val_loss=1.74, val_accuracy=0.532, lr=0.1] 58%|█████▊    | 45/78 [19:43<14:02, 25.54s/epoch, loss=1.14, accuracy=0.753, val_loss=2.47, val_accuracy=0.416, lr=0.1] 59%|█████▉    | 46/78 [20:09<13:44, 25.78s/epoch, loss=1.13, accuracy=0.755, val_loss=2.06, val_accuracy=0.452, lr=0.1] 60%|██████    | 47/78 [20:34<13:09, 25.48s/epoch, loss=1.13, accuracy=0.754, val_loss=3.12, val_accuracy=0.415, lr=0.0316] 62%|██████▏   | 48/78 [20:59<12:40, 25.35s/epoch, loss=1.13, accuracy=0.756, val_loss=6.15, val_accuracy=0.241, lr=0.1]    63%|██████▎   | 49/78 [21:25<12:16, 25.39s/epoch, loss=1.13, accuracy=0.755, val_loss=3.31, val_accuracy=0.328, lr=0.1] 64%|██████▍   | 50/78 [21:51<11:55, 25.54s/epoch, loss=1.13, accuracy=0.755, val_loss=1.79, val_accuracy=0.54, lr=0.1]  65%|██████▌   | 51/78 [22:15<11:22, 25.26s/epoch, loss=1.13, accuracy=0.755, val_loss=2.71, val_accuracy=0.463, lr=0.1] 67%|██████▋   | 52/78 [22:41<10:57, 25.30s/epoch, loss=1.12, accuracy=0.756, val_loss=2.71, val_accuracy=0.399, lr=0.0316] 68%|██████▊   | 53/78 [23:06<10:31, 25.25s/epoch, loss=1.13, accuracy=0.755, val_loss=1.7, val_accuracy=0.608, lr=0.1]     69%|██████▉   | 54/78 [23:31<10:07, 25.32s/epoch, loss=1.13, accuracy=0.755, val_loss=1.89, val_accuracy=0.502, lr=0.1] 71%|███████   | 55/78 [23:57<09:45, 25.47s/epoch, loss=1.12, accuracy=0.755, val_loss=3.85, val_accuracy=0.292, lr=0.1] 72%|███████▏  | 56/78 [24:22<09:19, 25.44s/epoch, loss=1.13, accuracy=0.754, val_loss=2.59, val_accuracy=0.405, lr=0.1] 73%|███████▎  | 57/78 [24:48<08:54, 25.43s/epoch, loss=1.13, accuracy=0.756, val_loss=1.64, val_accuracy=0.581, lr=0.0316] 74%|███████▍  | 58/78 [25:12<08:22, 25.14s/epoch, loss=1.13, accuracy=0.755, val_loss=2.26, val_accuracy=0.422, lr=0.1]    76%|███████▌  | 59/78 [25:38<07:59, 25.26s/epoch, loss=1.13, accuracy=0.755, val_loss=2.33, val_accuracy=0.477, lr=0.1] 77%|███████▋  | 60/78 [26:03<07:32, 25.13s/epoch, loss=1.12, accuracy=0.755, val_loss=2.1, val_accuracy=0.391, lr=0.1]  78%|███████▊  | 61/78 [26:28<07:07, 25.17s/epoch, loss=1.13, accuracy=0.753, val_loss=3.63, val_accuracy=0.374, lr=0.1] 79%|███████▉  | 62/78 [26:53<06:41, 25.12s/epoch, loss=1.12, accuracy=0.756, val_loss=1.69, val_accuracy=0.561, lr=0.0316] 81%|████████  | 63/78 [27:18<06:15, 25.06s/epoch, loss=1.12, accuracy=0.757, val_loss=1.96, val_accuracy=0.445, lr=0.1]    82%|████████▏ | 64/78 [27:43<05:50, 25.03s/epoch, loss=1.13, accuracy=0.756, val_loss=1.99, val_accuracy=0.523, lr=0.1] 83%|████████▎ | 65/78 [28:08<05:26, 25.12s/epoch, loss=1.12, accuracy=0.756, val_loss=1.9, val_accuracy=0.473, lr=0.1]  85%|████████▍ | 66/78 [28:34<05:03, 25.29s/epoch, loss=1.12, accuracy=0.757, val_loss=1.82, val_accuracy=0.503, lr=0.1] 86%|████████▌ | 67/78 [28:59<04:36, 25.13s/epoch, loss=1.12, accuracy=0.756, val_loss=2.52, val_accuracy=0.453, lr=0.0316] 87%|████████▋ | 68/78 [29:25<04:14, 25.46s/epoch, loss=1.12, accuracy=0.754, val_loss=2.28, val_accuracy=0.483, lr=0.1]    88%|████████▊ | 69/78 [29:49<03:46, 25.22s/epoch, loss=1.12, accuracy=0.755, val_loss=2.29, val_accuracy=0.452, lr=0.1] 90%|████████▉ | 70/78 [30:14<03:20, 25.10s/epoch, loss=1.12, accuracy=0.755, val_loss=2.16, val_accuracy=0.431, lr=0.1] 91%|█████████ | 71/78 [30:39<02:55, 25.01s/epoch, loss=1.12, accuracy=0.758, val_loss=2.12, val_accuracy=0.457, lr=0.1] 92%|█████████▏| 72/78 [31:03<02:28, 24.80s/epoch, loss=1.12, accuracy=0.755, val_loss=3.71, val_accuracy=0.399, lr=0.0316] 94%|█████████▎| 73/78 [31:28<02:04, 24.90s/epoch, loss=1.12, accuracy=0.754, val_loss=2.45, val_accuracy=0.396, lr=0.1]    95%|█████████▍| 74/78 [31:54<01:39, 24.98s/epoch, loss=1.11, accuracy=0.758, val_loss=1.68, val_accuracy=0.556, lr=0.1] 96%|█████████▌| 75/78 [32:19<01:14, 24.95s/epoch, loss=1.12, accuracy=0.753, val_loss=1.58, val_accuracy=0.592, lr=0.1] 97%|█████████▋| 76/78 [32:43<00:49, 24.95s/epoch, loss=1.12, accuracy=0.755, val_loss=3.88, val_accuracy=0.373, lr=0.1] 99%|█████████▊| 77/78 [33:09<00:25, 25.02s/epoch, loss=1.12, accuracy=0.758, val_loss=6.11, val_accuracy=0.236, lr=0.0316]100%|██████████| 78/78 [33:34<00:00, 25.04s/epoch, loss=1.11, accuracy=0.758, val_loss=4.23, val_accuracy=0.236, lr=0.1]   100%|██████████| 78/78 [33:34<00:00, 25.82s/epoch, loss=1.11, accuracy=0.758, val_loss=4.23, val_accuracy=0.236, lr=0.1]
Using real-time data augmentation.
Test loss: 4.2305684089660645
Test accuracy: 0.2361000031232834


* * * Run SGD for ID = 19_9. * * *


2024-02-15 19:46:58.797552: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 19:47:01.366763: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 19:47:01.368156: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-15 19:47:01.408603: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:86:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 19:47:01.408648: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 19:47:01.412154: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 19:47:01.412228: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 19:47:01.414700: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 19:47:01.415485: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 19:47:01.418059: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 19:47:01.419841: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 19:47:01.425433: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 19:47:01.426063: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 19:47:01.426144: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 19:47:02.729575: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-15 19:47:02.730632: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 19:47:02.731544: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:86:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 19:47:02.731599: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 19:47:02.731667: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 19:47:02.731688: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 19:47:02.731709: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 19:47:02.731729: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 19:47:02.731749: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 19:47:02.731769: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 19:47:02.731789: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 19:47:02.732407: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 19:47:02.732451: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 19:47:03.361847: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-15 19:47:03.361900: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-15 19:47:03.361912: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-15 19:47:03.363014: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:86:00.0, compute capability: 6.1)
{'id': 199, 'batch_size': 128, 'epochs': 78, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/78 [00:00<?, ?epoch/s]2024-02-15 19:47:04.119286: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-15 19:47:04.131720: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2100000000 Hz
2024-02-15 19:47:05.992605: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 19:47:06.340161: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 19:47:07.198991: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-15 19:47:07.245595: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|▏         | 1/78 [00:55<1:11:24, 55.65s/epoch, loss=6.53, accuracy=0.17, val_loss=3.88, val_accuracy=0.107, lr=0.1]  3%|▎         | 2/78 [01:20<47:36, 37.58s/epoch, loss=1.93, accuracy=0.406, val_loss=3.66, val_accuracy=0.125, lr=0.1]   4%|▍         | 3/78 [01:45<39:38, 31.71s/epoch, loss=1.47, accuracy=0.558, val_loss=5.61, val_accuracy=0.13, lr=0.1]   5%|▌         | 4/78 [02:10<35:57, 29.16s/epoch, loss=1.32, accuracy=0.646, val_loss=3.39, val_accuracy=0.286, lr=0.1]  6%|▋         | 5/78 [02:35<33:29, 27.52s/epoch, loss=1.27, accuracy=0.681, val_loss=1.93, val_accuracy=0.507, lr=0.1]  8%|▊         | 6/78 [03:01<32:20, 26.95s/epoch, loss=1.24, accuracy=0.697, val_loss=2.07, val_accuracy=0.444, lr=0.1]  9%|▉         | 7/78 [03:26<31:12, 26.37s/epoch, loss=1.24, accuracy=0.707, val_loss=1.86, val_accuracy=0.486, lr=0.1] 10%|█         | 8/78 [03:52<30:40, 26.29s/epoch, loss=1.22, accuracy=0.718, val_loss=3.11, val_accuracy=0.339, lr=0.1] 12%|█▏        | 9/78 [04:17<29:40, 25.81s/epoch, loss=1.22, accuracy=0.722, val_loss=1.74, val_accuracy=0.533, lr=0.1] 13%|█▎        | 10/78 [04:42<29:02, 25.63s/epoch, loss=1.21, accuracy=0.725, val_loss=1.59, val_accuracy=0.57, lr=0.1] 14%|█▍        | 11/78 [05:07<28:27, 25.48s/epoch, loss=1.21, accuracy=0.727, val_loss=2.81, val_accuracy=0.417, lr=0.1] 15%|█▌        | 12/78 [05:32<27:45, 25.24s/epoch, loss=1.2, accuracy=0.73, val_loss=1.71, val_accuracy=0.592, lr=0.1]   17%|█▋        | 13/78 [05:57<27:15, 25.16s/epoch, loss=1.19, accuracy=0.737, val_loss=4.75, val_accuracy=0.208, lr=0.1] 18%|█▊        | 14/78 [06:22<26:47, 25.12s/epoch, loss=1.2, accuracy=0.732, val_loss=2.97, val_accuracy=0.402, lr=0.1]  19%|█▉        | 15/78 [06:46<26:14, 25.00s/epoch, loss=1.19, accuracy=0.737, val_loss=2.58, val_accuracy=0.338, lr=0.0316] 21%|██        | 16/78 [07:12<26:04, 25.24s/epoch, loss=1.19, accuracy=0.737, val_loss=2.54, val_accuracy=0.417, lr=0.1]    22%|██▏       | 17/78 [07:38<25:49, 25.40s/epoch, loss=1.19, accuracy=0.737, val_loss=1.89, val_accuracy=0.493, lr=0.1] 23%|██▎       | 18/78 [08:03<25:15, 25.26s/epoch, loss=1.19, accuracy=0.735, val_loss=1.8, val_accuracy=0.545, lr=0.1]  24%|██▍       | 19/78 [08:28<24:40, 25.09s/epoch, loss=1.18, accuracy=0.738, val_loss=1.86, val_accuracy=0.508, lr=0.1] 26%|██▌       | 20/78 [08:53<24:24, 25.26s/epoch, loss=1.19, accuracy=0.739, val_loss=3.21, val_accuracy=0.297, lr=0.0316] 27%|██▋       | 21/78 [09:18<24:00, 25.26s/epoch, loss=1.18, accuracy=0.742, val_loss=1.81, val_accuracy=0.531, lr=0.1]    28%|██▊       | 22/78 [09:44<23:43, 25.42s/epoch, loss=1.18, accuracy=0.742, val_loss=1.63, val_accuracy=0.589, lr=0.1] 29%|██▉       | 23/78 [10:09<23:12, 25.32s/epoch, loss=1.17, accuracy=0.741, val_loss=3.27, val_accuracy=0.393, lr=0.1] 31%|███       | 24/78 [10:34<22:38, 25.15s/epoch, loss=1.18, accuracy=0.743, val_loss=2.27, val_accuracy=0.417, lr=0.1] 32%|███▏      | 25/78 [10:59<22:10, 25.09s/epoch, loss=1.16, accuracy=0.747, val_loss=2.56, val_accuracy=0.373, lr=0.0316] 33%|███▎      | 26/78 [11:24<21:49, 25.19s/epoch, loss=1.17, accuracy=0.745, val_loss=1.82, val_accuracy=0.533, lr=0.1]    35%|███▍      | 27/78 [11:50<21:37, 25.44s/epoch, loss=1.18, accuracy=0.745, val_loss=2.55, val_accuracy=0.354, lr=0.1] 36%|███▌      | 28/78 [12:16<21:20, 25.61s/epoch, loss=1.16, accuracy=0.747, val_loss=2.71, val_accuracy=0.358, lr=0.1] 37%|███▋      | 29/78 [12:41<20:43, 25.38s/epoch, loss=1.16, accuracy=0.747, val_loss=1.77, val_accuracy=0.531, lr=0.1] 38%|███▊      | 30/78 [13:06<20:11, 25.24s/epoch, loss=1.16, accuracy=0.747, val_loss=1.88, val_accuracy=0.534, lr=0.0316] 40%|███▉      | 31/78 [13:32<19:47, 25.26s/epoch, loss=1.16, accuracy=0.747, val_loss=1.71, val_accuracy=0.563, lr=0.1]    41%|████      | 32/78 [13:57<19:18, 25.18s/epoch, loss=1.17, accuracy=0.745, val_loss=2.81, val_accuracy=0.37, lr=0.1]  42%|████▏     | 33/78 [14:22<18:55, 25.24s/epoch, loss=1.16, accuracy=0.749, val_loss=2.47, val_accuracy=0.425, lr=0.1] 44%|████▎     | 34/78 [14:47<18:33, 25.31s/epoch, loss=1.16, accuracy=0.75, val_loss=1.94, val_accuracy=0.476, lr=0.1]  45%|████▍     | 35/78 [15:12<18:02, 25.16s/epoch, loss=1.15, accuracy=0.749, val_loss=3.17, val_accuracy=0.252, lr=0.0316] 46%|████▌     | 36/78 [15:37<17:36, 25.14s/epoch, loss=1.16, accuracy=0.748, val_loss=2.35, val_accuracy=0.433, lr=0.1]    47%|████▋     | 37/78 [16:03<17:17, 25.29s/epoch, loss=1.15, accuracy=0.751, val_loss=1.68, val_accuracy=0.56, lr=0.1]  49%|████▊     | 38/78 [16:28<16:43, 25.09s/epoch, loss=1.15, accuracy=0.747, val_loss=2.31, val_accuracy=0.458, lr=0.1] 50%|█████     | 39/78 [16:52<16:14, 24.99s/epoch, loss=1.15, accuracy=0.749, val_loss=1.82, val_accuracy=0.553, lr=0.1] 51%|█████▏    | 40/78 [17:18<15:58, 25.23s/epoch, loss=1.15, accuracy=0.751, val_loss=1.78, val_accuracy=0.509, lr=0.0316] 53%|█████▎    | 41/78 [17:44<15:45, 25.55s/epoch, loss=1.14, accuracy=0.749, val_loss=2.1, val_accuracy=0.473, lr=0.1]     54%|█████▍    | 42/78 [18:09<15:12, 25.36s/epoch, loss=1.15, accuracy=0.749, val_loss=1.75, val_accuracy=0.57, lr=0.1] 55%|█████▌    | 43/78 [18:35<14:49, 25.40s/epoch, loss=1.14, accuracy=0.75, val_loss=1.55, val_accuracy=0.608, lr=0.1] 56%|█████▋    | 44/78 [19:01<14:31, 25.64s/epoch, loss=1.13, accuracy=0.752, val_loss=1.87, val_accuracy=0.57, lr=0.1] 58%|█████▊    | 45/78 [19:27<14:10, 25.78s/epoch, loss=1.14, accuracy=0.751, val_loss=1.57, val_accuracy=0.612, lr=0.1] 59%|█████▉    | 46/78 [19:53<13:44, 25.77s/epoch, loss=1.14, accuracy=0.753, val_loss=2.86, val_accuracy=0.291, lr=0.1] 60%|██████    | 47/78 [20:18<13:09, 25.46s/epoch, loss=1.14, accuracy=0.75, val_loss=2.35, val_accuracy=0.412, lr=0.1]  62%|██████▏   | 48/78 [20:43<12:44, 25.47s/epoch, loss=1.14, accuracy=0.752, val_loss=2.03, val_accuracy=0.501, lr=0.0316] 63%|██████▎   | 49/78 [21:09<12:21, 25.56s/epoch, loss=1.13, accuracy=0.754, val_loss=3.97, val_accuracy=0.296, lr=0.1]    64%|██████▍   | 50/78 [21:34<11:52, 25.46s/epoch, loss=1.13, accuracy=0.75, val_loss=1.94, val_accuracy=0.471, lr=0.1]  65%|██████▌   | 51/78 [21:59<11:21, 25.25s/epoch, loss=1.13, accuracy=0.753, val_loss=2.55, val_accuracy=0.357, lr=0.1] 67%|██████▋   | 52/78 [22:24<10:58, 25.32s/epoch, loss=1.14, accuracy=0.753, val_loss=1.87, val_accuracy=0.53, lr=0.1]  68%|██████▊   | 53/78 [22:50<10:35, 25.43s/epoch, loss=1.14, accuracy=0.754, val_loss=4.98, val_accuracy=0.235, lr=0.0316] 69%|██████▉   | 54/78 [23:16<10:12, 25.52s/epoch, loss=1.14, accuracy=0.754, val_loss=3.73, val_accuracy=0.336, lr=0.1]    71%|███████   | 55/78 [23:41<09:47, 25.56s/epoch, loss=1.13, accuracy=0.753, val_loss=2.63, val_accuracy=0.289, lr=0.1] 72%|███████▏  | 56/78 [24:07<09:21, 25.53s/epoch, loss=1.13, accuracy=0.754, val_loss=2.13, val_accuracy=0.507, lr=0.1] 73%|███████▎  | 57/78 [24:33<08:56, 25.57s/epoch, loss=1.13, accuracy=0.752, val_loss=2.13, val_accuracy=0.427, lr=0.1] 74%|███████▍  | 58/78 [24:57<08:25, 25.27s/epoch, loss=1.12, accuracy=0.755, val_loss=2.32, val_accuracy=0.43, lr=0.0316] 76%|███████▌  | 59/78 [25:22<07:59, 25.22s/epoch, loss=1.13, accuracy=0.752, val_loss=1.97, val_accuracy=0.514, lr=0.1]   77%|███████▋  | 60/78 [25:46<07:28, 24.89s/epoch, loss=1.13, accuracy=0.753, val_loss=2.65, val_accuracy=0.367, lr=0.1] 78%|███████▊  | 61/78 [26:11<07:02, 24.83s/epoch, loss=1.13, accuracy=0.753, val_loss=2.13, val_accuracy=0.423, lr=0.1] 79%|███████▉  | 62/78 [26:36<06:37, 24.82s/epoch, loss=1.13, accuracy=0.754, val_loss=2.02, val_accuracy=0.498, lr=0.1] 81%|████████  | 63/78 [27:01<06:13, 24.88s/epoch, loss=1.14, accuracy=0.751, val_loss=11.2, val_accuracy=0.104, lr=0.0316] 82%|████████▏ | 64/78 [27:26<05:49, 24.94s/epoch, loss=1.13, accuracy=0.755, val_loss=2.12, val_accuracy=0.485, lr=0.1]    83%|████████▎ | 65/78 [27:50<05:20, 24.66s/epoch, loss=1.12, accuracy=0.756, val_loss=2.18, val_accuracy=0.527, lr=0.1] 85%|████████▍ | 66/78 [28:15<04:56, 24.73s/epoch, loss=1.12, accuracy=0.755, val_loss=2.16, val_accuracy=0.498, lr=0.1] 86%|████████▌ | 67/78 [28:41<04:35, 25.04s/epoch, loss=1.12, accuracy=0.754, val_loss=2.45, val_accuracy=0.348, lr=0.1] 87%|████████▋ | 68/78 [29:05<04:09, 25.00s/epoch, loss=1.13, accuracy=0.755, val_loss=1.57, val_accuracy=0.591, lr=0.0316] 88%|████████▊ | 69/78 [29:30<03:44, 24.93s/epoch, loss=1.13, accuracy=0.755, val_loss=3.66, val_accuracy=0.307, lr=0.1]    90%|████████▉ | 70/78 [29:55<03:19, 24.99s/epoch, loss=1.12, accuracy=0.754, val_loss=1.94, val_accuracy=0.542, lr=0.1] 91%|█████████ | 71/78 [30:20<02:54, 24.89s/epoch, loss=1.12, accuracy=0.755, val_loss=2.41, val_accuracy=0.354, lr=0.1] 92%|█████████▏| 72/78 [30:45<02:29, 24.95s/epoch, loss=1.12, accuracy=0.755, val_loss=2.23, val_accuracy=0.454, lr=0.1] 94%|█████████▎| 73/78 [31:11<02:06, 25.23s/epoch, loss=1.12, accuracy=0.756, val_loss=2.08, val_accuracy=0.503, lr=0.0316] 95%|█████████▍| 74/78 [31:35<01:40, 25.01s/epoch, loss=1.12, accuracy=0.755, val_loss=3.49, val_accuracy=0.311, lr=0.1]    96%|█████████▌| 75/78 [32:01<01:15, 25.12s/epoch, loss=1.11, accuracy=0.757, val_loss=2.44, val_accuracy=0.463, lr=0.1] 97%|█████████▋| 76/78 [32:26<00:50, 25.13s/epoch, loss=1.13, accuracy=0.754, val_loss=2.71, val_accuracy=0.382, lr=0.1] 99%|█████████▊| 77/78 [32:50<00:24, 24.81s/epoch, loss=1.12, accuracy=0.757, val_loss=1.94, val_accuracy=0.503, lr=0.1]100%|██████████| 78/78 [33:15<00:00, 24.81s/epoch, loss=1.11, accuracy=0.757, val_loss=1.74, val_accuracy=0.562, lr=0.0316]100%|██████████| 78/78 [33:15<00:00, 25.58s/epoch, loss=1.11, accuracy=0.757, val_loss=1.74, val_accuracy=0.562, lr=0.0316]
Using real-time data augmentation.
Test loss: 1.7386455535888672
Test accuracy: 0.5615000128746033


* * * Run SGD for ID = 19_10. * * *


2024-02-15 20:20:22.154752: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 20:20:24.875645: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 20:20:24.877012: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-15 20:20:24.917031: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:86:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 20:20:24.917069: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 20:20:24.923642: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 20:20:24.924398: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 20:20:24.926867: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 20:20:24.927668: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 20:20:24.930291: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 20:20:24.932099: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 20:20:24.937774: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 20:20:24.938489: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 20:20:24.938884: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 20:20:26.147224: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-15 20:20:26.148231: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 20:20:26.148758: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:86:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 20:20:26.148796: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 20:20:26.148833: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 20:20:26.148848: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 20:20:26.148862: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 20:20:26.148877: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 20:20:26.148891: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 20:20:26.148905: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 20:20:26.148920: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 20:20:26.149497: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 20:20:26.149535: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 20:20:26.768188: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-15 20:20:26.768238: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-15 20:20:26.768248: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-15 20:20:26.769264: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:86:00.0, compute capability: 6.1)
{'id': 1910, 'batch_size': 128, 'epochs': 78, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/78 [00:00<?, ?epoch/s]2024-02-15 20:20:27.532806: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-15 20:20:27.544722: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2100000000 Hz
2024-02-15 20:20:29.417502: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 20:20:29.677120: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 20:20:30.911018: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-15 20:20:30.967981: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|▏         | 1/78 [00:56<1:12:19, 56.36s/epoch, loss=3.15, accuracy=0.268, val_loss=3.31, val_accuracy=0.155, lr=0.1]  3%|▎         | 2/78 [01:22<48:50, 38.56s/epoch, loss=1.6, accuracy=0.508, val_loss=2.28, val_accuracy=0.362, lr=0.1]     4%|▍         | 3/78 [01:48<40:47, 32.64s/epoch, loss=1.4, accuracy=0.613, val_loss=2.52, val_accuracy=0.377, lr=0.1]  5%|▌         | 4/78 [02:13<36:33, 29.64s/epoch, loss=1.31, accuracy=0.665, val_loss=2.35, val_accuracy=0.377, lr=0.1]  6%|▋         | 5/78 [02:38<34:06, 28.04s/epoch, loss=1.27, accuracy=0.688, val_loss=2.01, val_accuracy=0.499, lr=0.1]  8%|▊         | 6/78 [03:04<32:46, 27.31s/epoch, loss=1.25, accuracy=0.705, val_loss=2.32, val_accuracy=0.436, lr=0.1]  9%|▉         | 7/78 [03:29<31:43, 26.81s/epoch, loss=1.23, accuracy=0.711, val_loss=1.64, val_accuracy=0.542, lr=0.1] 10%|█         | 8/78 [03:56<30:59, 26.57s/epoch, loss=1.22, accuracy=0.719, val_loss=1.57, val_accuracy=0.617, lr=0.1] 12%|█▏        | 9/78 [04:21<30:19, 26.37s/epoch, loss=1.22, accuracy=0.723, val_loss=1.69, val_accuracy=0.568, lr=0.1] 13%|█▎        | 10/78 [04:46<29:19, 25.87s/epoch, loss=1.21, accuracy=0.724, val_loss=1.51, val_accuracy=0.626, lr=0.1] 14%|█▍        | 11/78 [05:12<28:59, 25.97s/epoch, loss=1.21, accuracy=0.73, val_loss=3.1, val_accuracy=0.423, lr=0.1]   15%|█▌        | 12/78 [05:38<28:32, 25.95s/epoch, loss=1.19, accuracy=0.733, val_loss=1.46, val_accuracy=0.639, lr=0.1] 17%|█▋        | 13/78 [06:05<28:12, 26.03s/epoch, loss=1.2, accuracy=0.731, val_loss=1.67, val_accuracy=0.558, lr=0.1]  18%|█▊        | 14/78 [06:29<27:18, 25.60s/epoch, loss=1.2, accuracy=0.734, val_loss=1.57, val_accuracy=0.597, lr=0.1] 19%|█▉        | 15/78 [06:53<26:27, 25.19s/epoch, loss=1.2, accuracy=0.735, val_loss=2.03, val_accuracy=0.505, lr=0.1] 21%|██        | 16/78 [07:19<26:06, 25.26s/epoch, loss=1.19, accuracy=0.733, val_loss=2.01, val_accuracy=0.524, lr=0.1] 22%|██▏       | 17/78 [07:44<25:42, 25.28s/epoch, loss=1.18, accuracy=0.74, val_loss=1.85, val_accuracy=0.566, lr=0.0316] 23%|██▎       | 18/78 [08:09<25:07, 25.13s/epoch, loss=1.19, accuracy=0.738, val_loss=1.94, val_accuracy=0.516, lr=0.1]   24%|██▍       | 19/78 [08:35<24:51, 25.29s/epoch, loss=1.18, accuracy=0.741, val_loss=1.43, val_accuracy=0.651, lr=0.1] 26%|██▌       | 20/78 [08:59<24:20, 25.18s/epoch, loss=1.18, accuracy=0.739, val_loss=2.77, val_accuracy=0.369, lr=0.1] 27%|██▋       | 21/78 [09:25<24:07, 25.39s/epoch, loss=1.18, accuracy=0.742, val_loss=1.4, val_accuracy=0.667, lr=0.1]  28%|██▊       | 22/78 [09:51<23:38, 25.34s/epoch, loss=1.17, accuracy=0.743, val_loss=1.65, val_accuracy=0.607, lr=0.1] 29%|██▉       | 23/78 [10:15<23:02, 25.14s/epoch, loss=1.17, accuracy=0.743, val_loss=1.47, val_accuracy=0.655, lr=0.1] 31%|███       | 24/78 [10:40<22:33, 25.06s/epoch, loss=1.16, accuracy=0.745, val_loss=1.78, val_accuracy=0.571, lr=0.1] 32%|███▏      | 25/78 [11:05<22:10, 25.11s/epoch, loss=1.17, accuracy=0.746, val_loss=2.06, val_accuracy=0.502, lr=0.1] 33%|███▎      | 26/78 [11:32<22:06, 25.52s/epoch, loss=1.16, accuracy=0.746, val_loss=1.99, val_accuracy=0.51, lr=0.0316] 35%|███▍      | 27/78 [11:58<21:50, 25.70s/epoch, loss=1.16, accuracy=0.744, val_loss=1.8, val_accuracy=0.551, lr=0.1]    36%|███▌      | 28/78 [12:23<21:21, 25.62s/epoch, loss=1.17, accuracy=0.745, val_loss=2.95, val_accuracy=0.253, lr=0.1] 37%|███▋      | 29/78 [12:49<20:53, 25.57s/epoch, loss=1.15, accuracy=0.746, val_loss=1.7, val_accuracy=0.594, lr=0.1]  38%|███▊      | 30/78 [13:15<20:33, 25.70s/epoch, loss=1.16, accuracy=0.745, val_loss=1.66, val_accuracy=0.578, lr=0.1] 40%|███▉      | 31/78 [13:40<20:00, 25.54s/epoch, loss=1.16, accuracy=0.747, val_loss=1.87, val_accuracy=0.506, lr=0.0316] 41%|████      | 32/78 [14:05<19:27, 25.39s/epoch, loss=1.16, accuracy=0.75, val_loss=2.06, val_accuracy=0.49, lr=0.1]      42%|████▏     | 33/78 [14:31<19:13, 25.62s/epoch, loss=1.16, accuracy=0.75, val_loss=1.66, val_accuracy=0.546, lr=0.1] 44%|████▎     | 34/78 [14:58<18:59, 25.89s/epoch, loss=1.15, accuracy=0.748, val_loss=1.68, val_accuracy=0.555, lr=0.1] 45%|████▍     | 35/78 [15:23<18:31, 25.85s/epoch, loss=1.14, accuracy=0.752, val_loss=1.89, val_accuracy=0.511, lr=0.1] 46%|████▌     | 36/78 [15:50<18:09, 25.95s/epoch, loss=1.15, accuracy=0.749, val_loss=2.04, val_accuracy=0.498, lr=0.0316] 47%|████▋     | 37/78 [16:14<17:29, 25.59s/epoch, loss=1.15, accuracy=0.749, val_loss=2.6, val_accuracy=0.344, lr=0.1]     49%|████▊     | 38/78 [16:39<16:49, 25.23s/epoch, loss=1.15, accuracy=0.75, val_loss=1.56, val_accuracy=0.621, lr=0.1] 50%|█████     | 39/78 [17:03<16:15, 25.02s/epoch, loss=1.15, accuracy=0.75, val_loss=1.61, val_accuracy=0.572, lr=0.1] 51%|█████▏    | 40/78 [17:29<16:02, 25.34s/epoch, loss=1.15, accuracy=0.75, val_loss=2.55, val_accuracy=0.422, lr=0.1] 53%|█████▎    | 41/78 [17:55<15:42, 25.48s/epoch, loss=1.15, accuracy=0.752, val_loss=2.66, val_accuracy=0.429, lr=0.0316] 54%|█████▍    | 42/78 [18:20<15:08, 25.23s/epoch, loss=1.14, accuracy=0.75, val_loss=1.81, val_accuracy=0.56, lr=0.1]      55%|█████▌    | 43/78 [18:45<14:38, 25.10s/epoch, loss=1.15, accuracy=0.751, val_loss=3.44, val_accuracy=0.346, lr=0.1] 56%|█████▋    | 44/78 [19:09<14:07, 24.92s/epoch, loss=1.15, accuracy=0.75, val_loss=1.84, val_accuracy=0.51, lr=0.1]   58%|█████▊    | 45/78 [19:35<13:48, 25.10s/epoch, loss=1.14, accuracy=0.753, val_loss=1.89, val_accuracy=0.563, lr=0.1] 59%|█████▉    | 46/78 [20:00<13:28, 25.27s/epoch, loss=1.14, accuracy=0.751, val_loss=1.63, val_accuracy=0.638, lr=0.0316] 60%|██████    | 47/78 [20:25<12:58, 25.12s/epoch, loss=1.14, accuracy=0.751, val_loss=1.88, val_accuracy=0.531, lr=0.1]    62%|██████▏   | 48/78 [20:51<12:36, 25.21s/epoch, loss=1.13, accuracy=0.754, val_loss=1.67, val_accuracy=0.59, lr=0.1]  63%|██████▎   | 49/78 [21:17<12:18, 25.45s/epoch, loss=1.14, accuracy=0.754, val_loss=2.4, val_accuracy=0.4, lr=0.1]   64%|██████▍   | 50/78 [21:43<11:59, 25.70s/epoch, loss=1.14, accuracy=0.753, val_loss=1.56, val_accuracy=0.612, lr=0.1] 65%|██████▌   | 51/78 [22:07<11:24, 25.37s/epoch, loss=1.14, accuracy=0.754, val_loss=2.18, val_accuracy=0.466, lr=0.0316] 67%|██████▋   | 52/78 [22:33<11:04, 25.54s/epoch, loss=1.14, accuracy=0.752, val_loss=2.4, val_accuracy=0.45, lr=0.1]      68%|██████▊   | 53/78 [23:00<10:47, 25.92s/epoch, loss=1.14, accuracy=0.754, val_loss=2.13, val_accuracy=0.505, lr=0.1] 69%|██████▉   | 54/78 [23:26<10:23, 25.97s/epoch, loss=1.14, accuracy=0.753, val_loss=2.9, val_accuracy=0.454, lr=0.1]  71%|███████   | 55/78 [23:53<10:01, 26.16s/epoch, loss=1.13, accuracy=0.753, val_loss=1.79, val_accuracy=0.535, lr=0.1] 72%|███████▏  | 56/78 [24:19<09:37, 26.25s/epoch, loss=1.14, accuracy=0.755, val_loss=1.53, val_accuracy=0.642, lr=0.0316] 73%|███████▎  | 57/78 [24:46<09:11, 26.28s/epoch, loss=1.13, accuracy=0.754, val_loss=3, val_accuracy=0.453, lr=0.1]       74%|███████▍  | 58/78 [25:13<08:49, 26.45s/epoch, loss=1.14, accuracy=0.75, val_loss=2.8, val_accuracy=0.452, lr=0.1] 76%|███████▌  | 59/78 [25:39<08:22, 26.47s/epoch, loss=1.13, accuracy=0.752, val_loss=2.47, val_accuracy=0.449, lr=0.1] 77%|███████▋  | 60/78 [26:06<07:57, 26.51s/epoch, loss=1.13, accuracy=0.753, val_loss=3.5, val_accuracy=0.27, lr=0.1]   78%|███████▊  | 61/78 [26:32<07:32, 26.60s/epoch, loss=1.13, accuracy=0.754, val_loss=1.86, val_accuracy=0.572, lr=0.0316] 79%|███████▉  | 62/78 [26:58<07:01, 26.37s/epoch, loss=1.13, accuracy=0.753, val_loss=1.91, val_accuracy=0.501, lr=0.1]    81%|████████  | 63/78 [27:24<06:33, 26.24s/epoch, loss=1.14, accuracy=0.752, val_loss=4.4, val_accuracy=0.289, lr=0.1]  82%|████████▏ | 64/78 [27:49<06:03, 25.94s/epoch, loss=1.13, accuracy=0.752, val_loss=1.81, val_accuracy=0.576, lr=0.1] 83%|████████▎ | 65/78 [28:15<05:34, 25.69s/epoch, loss=1.13, accuracy=0.755, val_loss=2.74, val_accuracy=0.46, lr=0.1]  85%|████████▍ | 66/78 [28:41<05:09, 25.78s/epoch, loss=1.13, accuracy=0.752, val_loss=1.75, val_accuracy=0.577, lr=0.0316] 86%|████████▌ | 67/78 [29:06<04:43, 25.74s/epoch, loss=1.13, accuracy=0.753, val_loss=1.93, val_accuracy=0.486, lr=0.1]    87%|████████▋ | 68/78 [29:31<04:15, 25.51s/epoch, loss=1.13, accuracy=0.753, val_loss=2.07, val_accuracy=0.521, lr=0.1] 88%|████████▊ | 69/78 [29:56<03:47, 25.25s/epoch, loss=1.13, accuracy=0.752, val_loss=2.58, val_accuracy=0.459, lr=0.1] 90%|████████▉ | 70/78 [30:21<03:21, 25.13s/epoch, loss=1.13, accuracy=0.756, val_loss=1.97, val_accuracy=0.512, lr=0.1] 91%|█████████ | 71/78 [30:46<02:56, 25.16s/epoch, loss=1.13, accuracy=0.753, val_loss=2.52, val_accuracy=0.43, lr=0.0316] 92%|█████████▏| 72/78 [31:11<02:30, 25.13s/epoch, loss=1.13, accuracy=0.752, val_loss=2.02, val_accuracy=0.514, lr=0.1]   94%|█████████▎| 73/78 [31:36<02:04, 24.96s/epoch, loss=1.13, accuracy=0.754, val_loss=1.68, val_accuracy=0.558, lr=0.1] 95%|█████████▍| 74/78 [32:01<01:40, 25.22s/epoch, loss=1.12, accuracy=0.756, val_loss=3.7, val_accuracy=0.336, lr=0.1]  96%|█████████▌| 75/78 [32:26<01:15, 25.13s/epoch, loss=1.12, accuracy=0.756, val_loss=2.25, val_accuracy=0.433, lr=0.1] 97%|█████████▋| 76/78 [32:52<00:50, 25.39s/epoch, loss=1.12, accuracy=0.755, val_loss=2.36, val_accuracy=0.514, lr=0.0316] 99%|█████████▊| 77/78 [33:18<00:25, 25.60s/epoch, loss=1.12, accuracy=0.755, val_loss=2.08, val_accuracy=0.457, lr=0.1]   100%|██████████| 78/78 [33:45<00:00, 25.84s/epoch, loss=1.13, accuracy=0.752, val_loss=2.19, val_accuracy=0.452, lr=0.1]100%|██████████| 78/78 [33:45<00:00, 25.97s/epoch, loss=1.13, accuracy=0.752, val_loss=2.19, val_accuracy=0.452, lr=0.1]
Using real-time data augmentation.
Test loss: 2.1891427040100098
Test accuracy: 0.45210000872612


* * * Run SGD for ID = 19_11. * * *


2024-02-15 20:54:15.435497: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 20:54:18.209937: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 20:54:18.211956: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-15 20:54:18.252626: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:86:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 20:54:18.252672: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 20:54:18.256050: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 20:54:18.256117: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 20:54:18.258578: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 20:54:18.259348: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 20:54:18.261926: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 20:54:18.263663: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 20:54:18.269442: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 20:54:18.270114: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 20:54:18.270240: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 20:54:19.471813: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-15 20:54:19.472409: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 20:54:19.472949: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:86:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 20:54:19.472987: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 20:54:19.473025: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 20:54:19.473041: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 20:54:19.473056: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 20:54:19.473072: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 20:54:19.473096: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 20:54:19.473112: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 20:54:19.473127: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 20:54:19.473720: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 20:54:19.473761: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 20:54:20.113859: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-15 20:54:20.113916: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-15 20:54:20.113928: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-15 20:54:20.115013: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:86:00.0, compute capability: 6.1)
{'id': 1911, 'batch_size': 128, 'epochs': 78, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/78 [00:00<?, ?epoch/s]2024-02-15 20:54:20.892646: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-15 20:54:20.904726: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2100000000 Hz
2024-02-15 20:54:22.872969: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 20:54:23.148951: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 20:54:24.045469: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-15 20:54:24.105674: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|▏         | 1/78 [01:09<1:28:47, 69.19s/epoch, loss=3.95, accuracy=0.299, val_loss=4.34, val_accuracy=0.142, lr=0.1]  3%|▎         | 2/78 [01:35<55:29, 43.80s/epoch, loss=1.63, accuracy=0.509, val_loss=3.23, val_accuracy=0.226, lr=0.1]    4%|▍         | 3/78 [02:01<44:42, 35.77s/epoch, loss=1.41, accuracy=0.612, val_loss=2.3, val_accuracy=0.367, lr=0.1]   5%|▌         | 4/78 [02:27<39:32, 32.07s/epoch, loss=1.33, accuracy=0.664, val_loss=1.7, val_accuracy=0.555, lr=0.1]  6%|▋         | 5/78 [02:53<36:20, 29.87s/epoch, loss=1.29, accuracy=0.692, val_loss=1.95, val_accuracy=0.469, lr=0.1]  8%|▊         | 6/78 [03:20<34:21, 28.63s/epoch, loss=1.25, accuracy=0.705, val_loss=1.85, val_accuracy=0.547, lr=0.1]  9%|▉         | 7/78 [03:44<32:23, 27.38s/epoch, loss=1.26, accuracy=0.71, val_loss=2.64, val_accuracy=0.408, lr=0.1]  10%|█         | 8/78 [04:10<31:19, 26.85s/epoch, loss=1.23, accuracy=0.719, val_loss=1.61, val_accuracy=0.581, lr=0.1] 12%|█▏        | 9/78 [04:36<30:25, 26.45s/epoch, loss=1.22, accuracy=0.725, val_loss=1.92, val_accuracy=0.537, lr=0.1] 13%|█▎        | 10/78 [05:01<29:29, 26.02s/epoch, loss=1.22, accuracy=0.727, val_loss=2.57, val_accuracy=0.465, lr=0.1] 14%|█▍        | 11/78 [05:26<28:39, 25.66s/epoch, loss=1.21, accuracy=0.73, val_loss=2.81, val_accuracy=0.392, lr=0.1]  15%|█▌        | 12/78 [05:51<28:17, 25.72s/epoch, loss=1.21, accuracy=0.731, val_loss=1.84, val_accuracy=0.497, lr=0.1] 17%|█▋        | 13/78 [06:17<27:47, 25.65s/epoch, loss=1.2, accuracy=0.734, val_loss=1.72, val_accuracy=0.547, lr=0.0316] 18%|█▊        | 14/78 [06:42<27:06, 25.41s/epoch, loss=1.2, accuracy=0.736, val_loss=2.61, val_accuracy=0.395, lr=0.1]    19%|█▉        | 15/78 [07:07<26:34, 25.31s/epoch, loss=1.2, accuracy=0.735, val_loss=3.38, val_accuracy=0.286, lr=0.1] 21%|██        | 16/78 [07:33<26:25, 25.57s/epoch, loss=1.19, accuracy=0.739, val_loss=2.13, val_accuracy=0.492, lr=0.1] 22%|██▏       | 17/78 [07:59<26:16, 25.85s/epoch, loss=1.19, accuracy=0.738, val_loss=2.15, val_accuracy=0.525, lr=0.1] 23%|██▎       | 18/78 [08:26<26:03, 26.06s/epoch, loss=1.18, accuracy=0.741, val_loss=2.23, val_accuracy=0.486, lr=0.0316] 24%|██▍       | 19/78 [08:53<25:46, 26.20s/epoch, loss=1.19, accuracy=0.741, val_loss=1.5, val_accuracy=0.637, lr=0.1]     26%|██▌       | 20/78 [09:19<25:23, 26.26s/epoch, loss=1.19, accuracy=0.742, val_loss=2.3, val_accuracy=0.482, lr=0.1] 27%|██▋       | 21/78 [09:45<24:53, 26.20s/epoch, loss=1.18, accuracy=0.743, val_loss=2.52, val_accuracy=0.466, lr=0.1] 28%|██▊       | 22/78 [10:11<24:26, 26.19s/epoch, loss=1.18, accuracy=0.744, val_loss=1.37, val_accuracy=0.672, lr=0.1] 29%|██▉       | 23/78 [10:38<24:05, 26.29s/epoch, loss=1.17, accuracy=0.745, val_loss=2.16, val_accuracy=0.493, lr=0.1] 31%|███       | 24/78 [11:04<23:43, 26.35s/epoch, loss=1.18, accuracy=0.744, val_loss=2.82, val_accuracy=0.407, lr=0.1] 32%|███▏      | 25/78 [11:31<23:16, 26.34s/epoch, loss=1.18, accuracy=0.744, val_loss=1.95, val_accuracy=0.464, lr=0.1] 33%|███▎      | 26/78 [11:57<22:47, 26.30s/epoch, loss=1.18, accuracy=0.743, val_loss=1.68, val_accuracy=0.579, lr=0.1] 35%|███▍      | 27/78 [12:22<22:08, 26.04s/epoch, loss=1.17, accuracy=0.745, val_loss=3.06, val_accuracy=0.434, lr=0.0316] 36%|███▌      | 28/78 [12:47<21:27, 25.75s/epoch, loss=1.17, accuracy=0.747, val_loss=1.45, val_accuracy=0.638, lr=0.1]    37%|███▋      | 29/78 [13:13<20:58, 25.68s/epoch, loss=1.17, accuracy=0.747, val_loss=1.99, val_accuracy=0.475, lr=0.1] 38%|███▊      | 30/78 [13:38<20:30, 25.63s/epoch, loss=1.17, accuracy=0.744, val_loss=2.13, val_accuracy=0.502, lr=0.1] 40%|███▉      | 31/78 [14:03<19:52, 25.37s/epoch, loss=1.17, accuracy=0.747, val_loss=1.32, val_accuracy=0.683, lr=0.1] 41%|████      | 32/78 [14:28<19:26, 25.36s/epoch, loss=1.17, accuracy=0.748, val_loss=2.22, val_accuracy=0.446, lr=0.1] 42%|████▏     | 33/78 [14:53<18:51, 25.15s/epoch, loss=1.16, accuracy=0.75, val_loss=2.36, val_accuracy=0.47, lr=0.1]   44%|████▎     | 34/78 [15:18<18:21, 25.03s/epoch, loss=1.17, accuracy=0.75, val_loss=1.84, val_accuracy=0.595, lr=0.1] 45%|████▍     | 35/78 [15:42<17:50, 24.90s/epoch, loss=1.16, accuracy=0.749, val_loss=1.71, val_accuracy=0.578, lr=0.1] 46%|████▌     | 36/78 [16:08<17:35, 25.12s/epoch, loss=1.17, accuracy=0.746, val_loss=2.12, val_accuracy=0.436, lr=0.0316] 47%|████▋     | 37/78 [16:33<17:08, 25.09s/epoch, loss=1.16, accuracy=0.75, val_loss=1.99, val_accuracy=0.507, lr=0.1]     49%|████▊     | 38/78 [16:58<16:43, 25.08s/epoch, loss=1.15, accuracy=0.749, val_loss=2.65, val_accuracy=0.397, lr=0.1] 50%|█████     | 39/78 [17:23<16:19, 25.13s/epoch, loss=1.16, accuracy=0.75, val_loss=1.58, val_accuracy=0.623, lr=0.1]  51%|█████▏    | 40/78 [17:49<15:56, 25.18s/epoch, loss=1.16, accuracy=0.749, val_loss=3.91, val_accuracy=0.229, lr=0.1] 53%|█████▎    | 41/78 [18:14<15:30, 25.15s/epoch, loss=1.16, accuracy=0.751, val_loss=1.72, val_accuracy=0.573, lr=0.0316] 54%|█████▍    | 42/78 [18:38<14:57, 24.93s/epoch, loss=1.15, accuracy=0.752, val_loss=2.99, val_accuracy=0.441, lr=0.1]    55%|█████▌    | 43/78 [19:04<14:46, 25.31s/epoch, loss=1.16, accuracy=0.75, val_loss=1.93, val_accuracy=0.482, lr=0.1]  56%|█████▋    | 44/78 [19:31<14:36, 25.79s/epoch, loss=1.15, accuracy=0.748, val_loss=2.16, val_accuracy=0.463, lr=0.1] 58%|█████▊    | 45/78 [19:58<14:20, 26.08s/epoch, loss=1.16, accuracy=0.75, val_loss=3.28, val_accuracy=0.291, lr=0.1]  59%|█████▉    | 46/78 [20:25<13:59, 26.24s/epoch, loss=1.15, accuracy=0.751, val_loss=2.18, val_accuracy=0.475, lr=0.0316] 60%|██████    | 47/78 [20:51<13:33, 26.25s/epoch, loss=1.15, accuracy=0.751, val_loss=1.56, val_accuracy=0.615, lr=0.1]    62%|██████▏   | 48/78 [21:17<13:09, 26.31s/epoch, loss=1.15, accuracy=0.755, val_loss=2.79, val_accuracy=0.303, lr=0.1] 63%|██████▎   | 49/78 [21:44<12:44, 26.38s/epoch, loss=1.15, accuracy=0.75, val_loss=1.86, val_accuracy=0.554, lr=0.1]  64%|██████▍   | 50/78 [22:11<12:20, 26.46s/epoch, loss=1.15, accuracy=0.751, val_loss=1.84, val_accuracy=0.523, lr=0.1] 65%|██████▌   | 51/78 [22:37<11:56, 26.54s/epoch, loss=1.15, accuracy=0.752, val_loss=2.03, val_accuracy=0.466, lr=0.0316] 67%|██████▋   | 52/78 [23:04<11:29, 26.51s/epoch, loss=1.14, accuracy=0.753, val_loss=1.99, val_accuracy=0.534, lr=0.1]    68%|██████▊   | 53/78 [23:29<10:55, 26.23s/epoch, loss=1.15, accuracy=0.752, val_loss=2.05, val_accuracy=0.496, lr=0.1] 69%|██████▉   | 54/78 [23:55<10:24, 26.02s/epoch, loss=1.15, accuracy=0.753, val_loss=2.17, val_accuracy=0.52, lr=0.1]  71%|███████   | 55/78 [24:21<10:02, 26.19s/epoch, loss=1.15, accuracy=0.754, val_loss=1.91, val_accuracy=0.535, lr=0.1] 72%|███████▏  | 56/78 [24:48<09:37, 26.27s/epoch, loss=1.14, accuracy=0.756, val_loss=1.74, val_accuracy=0.538, lr=0.0316] 73%|███████▎  | 57/78 [25:14<09:13, 26.36s/epoch, loss=1.15, accuracy=0.752, val_loss=2.76, val_accuracy=0.421, lr=0.1]    74%|███████▍  | 58/78 [25:41<08:49, 26.47s/epoch, loss=1.15, accuracy=0.755, val_loss=4.06, val_accuracy=0.28, lr=0.1]  76%|███████▌  | 59/78 [26:07<08:19, 26.26s/epoch, loss=1.15, accuracy=0.751, val_loss=1.9, val_accuracy=0.531, lr=0.1] 77%|███████▋  | 60/78 [26:34<07:55, 26.40s/epoch, loss=1.14, accuracy=0.755, val_loss=1.36, val_accuracy=0.684, lr=0.1] 78%|███████▊  | 61/78 [27:00<07:29, 26.44s/epoch, loss=1.14, accuracy=0.754, val_loss=1.94, val_accuracy=0.538, lr=0.0316] 79%|███████▉  | 62/78 [27:27<07:03, 26.48s/epoch, loss=1.14, accuracy=0.756, val_loss=2.34, val_accuracy=0.344, lr=0.1]    81%|████████  | 63/78 [27:53<06:36, 26.45s/epoch, loss=1.16, accuracy=0.749, val_loss=1.94, val_accuracy=0.521, lr=0.1] 82%|████████▏ | 64/78 [28:18<06:02, 25.92s/epoch, loss=1.14, accuracy=0.756, val_loss=1.43, val_accuracy=0.648, lr=0.1] 83%|████████▎ | 65/78 [28:43<05:32, 25.59s/epoch, loss=1.14, accuracy=0.755, val_loss=1.81, val_accuracy=0.567, lr=0.1] 85%|████████▍ | 66/78 [29:08<05:05, 25.49s/epoch, loss=1.14, accuracy=0.754, val_loss=2.79, val_accuracy=0.414, lr=0.0316] 86%|████████▌ | 67/78 [29:33<04:38, 25.27s/epoch, loss=1.15, accuracy=0.755, val_loss=4.79, val_accuracy=0.163, lr=0.1]    87%|████████▋ | 68/78 [29:57<04:10, 25.10s/epoch, loss=1.14, accuracy=0.754, val_loss=1.6, val_accuracy=0.608, lr=0.1]  88%|████████▊ | 69/78 [30:22<03:45, 25.01s/epoch, loss=1.14, accuracy=0.756, val_loss=1.69, val_accuracy=0.571, lr=0.1] 90%|████████▉ | 70/78 [30:47<03:19, 24.95s/epoch, loss=1.14, accuracy=0.755, val_loss=3.07, val_accuracy=0.327, lr=0.1] 91%|█████████ | 71/78 [31:12<02:55, 25.00s/epoch, loss=1.15, accuracy=0.752, val_loss=2.04, val_accuracy=0.497, lr=0.0316] 92%|█████████▏| 72/78 [31:37<02:30, 25.02s/epoch, loss=1.14, accuracy=0.757, val_loss=2.1, val_accuracy=0.553, lr=0.1]     94%|█████████▎| 73/78 [32:02<02:04, 24.92s/epoch, loss=1.15, accuracy=0.753, val_loss=2.16, val_accuracy=0.502, lr=0.1] 95%|█████████▍| 74/78 [32:27<01:40, 25.12s/epoch, loss=1.14, accuracy=0.756, val_loss=2, val_accuracy=0.523, lr=0.1]    96%|█████████▌| 75/78 [32:52<01:14, 24.95s/epoch, loss=1.15, accuracy=0.754, val_loss=2.42, val_accuracy=0.371, lr=0.1] 97%|█████████▋| 76/78 [33:17<00:49, 24.98s/epoch, loss=1.14, accuracy=0.756, val_loss=2.58, val_accuracy=0.377, lr=0.0316] 99%|█████████▊| 77/78 [33:42<00:25, 25.04s/epoch, loss=1.15, accuracy=0.753, val_loss=2.37, val_accuracy=0.49, lr=0.1]    100%|██████████| 78/78 [34:08<00:00, 25.16s/epoch, loss=1.14, accuracy=0.755, val_loss=3.31, val_accuracy=0.321, lr=0.1]100%|██████████| 78/78 [34:08<00:00, 26.26s/epoch, loss=1.14, accuracy=0.755, val_loss=3.31, val_accuracy=0.321, lr=0.1]
Using real-time data augmentation.
Test loss: 3.312594175338745
Test accuracy: 0.321399986743927


* * * Run SGD for ID = 19_12. * * *


2024-02-15 21:28:31.558742: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 21:28:34.264427: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 21:28:34.265720: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-15 21:28:34.310108: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:86:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 21:28:34.310151: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 21:28:34.313877: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 21:28:34.313945: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 21:28:34.316443: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 21:28:34.317185: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 21:28:34.319929: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 21:28:34.321730: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 21:28:34.327739: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 21:28:34.328389: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 21:28:34.328789: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 21:28:35.521365: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-15 21:28:35.522358: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 21:28:35.522884: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:86:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 21:28:35.522930: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 21:28:35.522967: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 21:28:35.522982: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 21:28:35.522997: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 21:28:35.523011: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 21:28:35.523026: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 21:28:35.523040: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 21:28:35.523055: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 21:28:35.523625: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 21:28:35.523669: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 21:28:36.145835: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-15 21:28:36.145890: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-15 21:28:36.145902: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-15 21:28:36.147021: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:86:00.0, compute capability: 6.1)
{'id': 1912, 'batch_size': 128, 'epochs': 78, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/78 [00:00<?, ?epoch/s]2024-02-15 21:28:36.910808: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-15 21:28:36.922720: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2100000000 Hz
2024-02-15 21:28:38.778387: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 21:28:39.066021: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 21:28:39.937815: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-15 21:28:39.983892: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|▏         | 1/78 [01:03<1:21:20, 63.38s/epoch, loss=3.14, accuracy=0.322, val_loss=2.04, val_accuracy=0.362, lr=0.1]  3%|▎         | 2/78 [01:29<52:20, 41.32s/epoch, loss=1.58, accuracy=0.519, val_loss=2.04, val_accuracy=0.451, lr=0.1]    4%|▍         | 3/78 [01:55<43:06, 34.48s/epoch, loss=1.35, accuracy=0.635, val_loss=1.73, val_accuracy=0.524, lr=0.1]  5%|▌         | 4/78 [02:21<38:35, 31.29s/epoch, loss=1.27, accuracy=0.683, val_loss=1.6, val_accuracy=0.588, lr=0.1]   6%|▋         | 5/78 [02:48<35:52, 29.49s/epoch, loss=1.23, accuracy=0.705, val_loss=1.61, val_accuracy=0.572, lr=0.1]  8%|▊         | 6/78 [03:14<34:02, 28.37s/epoch, loss=1.22, accuracy=0.717, val_loss=1.56, val_accuracy=0.576, lr=0.1]  9%|▉         | 7/78 [03:41<32:54, 27.81s/epoch, loss=1.21, accuracy=0.724, val_loss=2.06, val_accuracy=0.506, lr=0.1] 10%|█         | 8/78 [04:07<32:00, 27.44s/epoch, loss=1.2, accuracy=0.728, val_loss=1.43, val_accuracy=0.649, lr=0.1]  12%|█▏        | 9/78 [04:34<31:15, 27.19s/epoch, loss=1.19, accuracy=0.732, val_loss=1.59, val_accuracy=0.575, lr=0.1] 13%|█▎        | 10/78 [05:00<30:24, 26.84s/epoch, loss=1.2, accuracy=0.736, val_loss=2.1, val_accuracy=0.539, lr=0.1]  14%|█▍        | 11/78 [05:27<29:52, 26.75s/epoch, loss=1.19, accuracy=0.738, val_loss=8.26, val_accuracy=0.157, lr=0.1] 15%|█▌        | 12/78 [05:53<29:22, 26.70s/epoch, loss=1.17, accuracy=0.739, val_loss=1.62, val_accuracy=0.578, lr=0.1] 17%|█▋        | 13/78 [06:18<28:26, 26.25s/epoch, loss=1.18, accuracy=0.742, val_loss=2.13, val_accuracy=0.52, lr=0.0316] 18%|█▊        | 14/78 [06:43<27:36, 25.88s/epoch, loss=1.18, accuracy=0.741, val_loss=1.91, val_accuracy=0.53, lr=0.1]    19%|█▉        | 15/78 [07:10<27:19, 26.03s/epoch, loss=1.16, accuracy=0.746, val_loss=2.43, val_accuracy=0.337, lr=0.1] 21%|██        | 16/78 [07:35<26:41, 25.83s/epoch, loss=1.17, accuracy=0.744, val_loss=3.17, val_accuracy=0.361, lr=0.1] 22%|██▏       | 17/78 [08:01<26:24, 25.97s/epoch, loss=1.17, accuracy=0.744, val_loss=1.89, val_accuracy=0.502, lr=0.1] 23%|██▎       | 18/78 [08:28<26:06, 26.11s/epoch, loss=1.17, accuracy=0.745, val_loss=2.03, val_accuracy=0.469, lr=0.0316] 24%|██▍       | 19/78 [08:54<25:42, 26.14s/epoch, loss=1.16, accuracy=0.744, val_loss=1.96, val_accuracy=0.53, lr=0.1]     26%|██▌       | 20/78 [09:20<25:14, 26.10s/epoch, loss=1.16, accuracy=0.746, val_loss=1.64, val_accuracy=0.606, lr=0.1] 27%|██▋       | 21/78 [09:47<24:56, 26.26s/epoch, loss=1.17, accuracy=0.745, val_loss=1.81, val_accuracy=0.573, lr=0.1] 28%|██▊       | 22/78 [10:13<24:27, 26.20s/epoch, loss=1.15, accuracy=0.747, val_loss=2.88, val_accuracy=0.462, lr=0.1] 29%|██▉       | 23/78 [10:38<23:51, 26.03s/epoch, loss=1.15, accuracy=0.747, val_loss=2.1, val_accuracy=0.489, lr=0.0316] 31%|███       | 24/78 [11:04<23:25, 26.03s/epoch, loss=1.16, accuracy=0.748, val_loss=1.81, val_accuracy=0.518, lr=0.1]   32%|███▏      | 25/78 [11:31<23:06, 26.17s/epoch, loss=1.16, accuracy=0.749, val_loss=5.26, val_accuracy=0.2, lr=0.1]   33%|███▎      | 26/78 [11:57<22:43, 26.21s/epoch, loss=1.15, accuracy=0.751, val_loss=1.99, val_accuracy=0.502, lr=0.1] 35%|███▍      | 27/78 [12:23<22:13, 26.14s/epoch, loss=1.15, accuracy=0.75, val_loss=1.93, val_accuracy=0.543, lr=0.1]  36%|███▌      | 28/78 [12:49<21:41, 26.03s/epoch, loss=1.15, accuracy=0.751, val_loss=2.73, val_accuracy=0.338, lr=0.0316] 37%|███▋      | 29/78 [13:15<21:11, 25.95s/epoch, loss=1.15, accuracy=0.751, val_loss=1.93, val_accuracy=0.555, lr=0.1]    38%|███▊      | 30/78 [13:41<20:50, 26.05s/epoch, loss=1.15, accuracy=0.752, val_loss=2.3, val_accuracy=0.456, lr=0.1]  40%|███▉      | 31/78 [14:06<20:13, 25.83s/epoch, loss=1.14, accuracy=0.752, val_loss=3.59, val_accuracy=0.262, lr=0.1] 41%|████      | 32/78 [14:31<19:35, 25.55s/epoch, loss=1.14, accuracy=0.754, val_loss=5.59, val_accuracy=0.198, lr=0.1] 42%|████▏     | 33/78 [14:57<19:12, 25.62s/epoch, loss=1.15, accuracy=0.752, val_loss=2.2, val_accuracy=0.498, lr=0.0316] 44%|████▎     | 34/78 [15:23<18:48, 25.64s/epoch, loss=1.15, accuracy=0.752, val_loss=8.19, val_accuracy=0.126, lr=0.1]   45%|████▍     | 35/78 [15:48<18:20, 25.60s/epoch, loss=1.14, accuracy=0.753, val_loss=3.3, val_accuracy=0.184, lr=0.1]  46%|████▌     | 36/78 [16:14<17:55, 25.60s/epoch, loss=1.15, accuracy=0.751, val_loss=3.49, val_accuracy=0.3, lr=0.1]  47%|████▋     | 37/78 [16:40<17:32, 25.68s/epoch, loss=1.14, accuracy=0.752, val_loss=1.89, val_accuracy=0.574, lr=0.1] 49%|████▊     | 38/78 [17:06<17:20, 26.00s/epoch, loss=1.14, accuracy=0.754, val_loss=4.57, val_accuracy=0.244, lr=0.0316] 50%|█████     | 39/78 [17:33<17:01, 26.20s/epoch, loss=1.14, accuracy=0.752, val_loss=3.34, val_accuracy=0.367, lr=0.1]    51%|█████▏    | 40/78 [18:00<16:39, 26.32s/epoch, loss=1.14, accuracy=0.754, val_loss=3.93, val_accuracy=0.327, lr=0.1] 53%|█████▎    | 41/78 [18:26<16:15, 26.35s/epoch, loss=1.14, accuracy=0.752, val_loss=4.57, val_accuracy=0.324, lr=0.1] 54%|█████▍    | 42/78 [18:53<15:49, 26.38s/epoch, loss=1.14, accuracy=0.753, val_loss=1.58, val_accuracy=0.6, lr=0.1]   55%|█████▌    | 43/78 [19:19<15:25, 26.45s/epoch, loss=1.14, accuracy=0.753, val_loss=2.21, val_accuracy=0.42, lr=0.0316] 56%|█████▋    | 44/78 [19:45<14:58, 26.41s/epoch, loss=1.14, accuracy=0.756, val_loss=2.45, val_accuracy=0.441, lr=0.1]   58%|█████▊    | 45/78 [20:12<14:30, 26.37s/epoch, loss=1.13, accuracy=0.754, val_loss=1.56, val_accuracy=0.608, lr=0.1] 59%|█████▉    | 46/78 [20:38<14:01, 26.30s/epoch, loss=1.14, accuracy=0.755, val_loss=3.03, val_accuracy=0.388, lr=0.1] 60%|██████    | 47/78 [21:04<13:33, 26.25s/epoch, loss=1.13, accuracy=0.753, val_loss=1.54, val_accuracy=0.644, lr=0.1] 62%|██████▏   | 48/78 [21:31<13:10, 26.35s/epoch, loss=1.13, accuracy=0.755, val_loss=3.54, val_accuracy=0.24, lr=0.0316] 63%|██████▎   | 49/78 [21:58<12:50, 26.58s/epoch, loss=1.14, accuracy=0.754, val_loss=2.03, val_accuracy=0.484, lr=0.1]   64%|██████▍   | 50/78 [22:25<12:26, 26.65s/epoch, loss=1.13, accuracy=0.755, val_loss=2.47, val_accuracy=0.342, lr=0.1] 65%|██████▌   | 51/78 [22:51<12:01, 26.74s/epoch, loss=1.13, accuracy=0.758, val_loss=2.42, val_accuracy=0.425, lr=0.1] 67%|██████▋   | 52/78 [23:19<11:37, 26.85s/epoch, loss=1.13, accuracy=0.754, val_loss=2.57, val_accuracy=0.391, lr=0.1] 68%|██████▊   | 53/78 [23:45<11:08, 26.75s/epoch, loss=1.14, accuracy=0.756, val_loss=1.67, val_accuracy=0.567, lr=0.0316] 69%|██████▉   | 54/78 [24:11<10:37, 26.57s/epoch, loss=1.13, accuracy=0.754, val_loss=2.3, val_accuracy=0.485, lr=0.1]     71%|███████   | 55/78 [24:38<10:13, 26.69s/epoch, loss=1.13, accuracy=0.755, val_loss=2.04, val_accuracy=0.536, lr=0.1] 72%|███████▏  | 56/78 [25:05<09:46, 26.67s/epoch, loss=1.13, accuracy=0.758, val_loss=1.7, val_accuracy=0.559, lr=0.1]  73%|███████▎  | 57/78 [25:31<09:16, 26.51s/epoch, loss=1.13, accuracy=0.756, val_loss=3.12, val_accuracy=0.37, lr=0.1] 74%|███████▍  | 58/78 [25:57<08:49, 26.48s/epoch, loss=1.13, accuracy=0.756, val_loss=2.17, val_accuracy=0.495, lr=0.0316] 76%|███████▌  | 59/78 [26:24<08:24, 26.53s/epoch, loss=1.12, accuracy=0.756, val_loss=2.1, val_accuracy=0.507, lr=0.1]     77%|███████▋  | 60/78 [26:51<08:01, 26.73s/epoch, loss=1.13, accuracy=0.755, val_loss=1.77, val_accuracy=0.58, lr=0.1] 78%|███████▊  | 61/78 [27:18<07:33, 26.70s/epoch, loss=1.13, accuracy=0.755, val_loss=1.49, val_accuracy=0.625, lr=0.1] 79%|███████▉  | 62/78 [27:44<07:06, 26.63s/epoch, loss=1.13, accuracy=0.755, val_loss=2.36, val_accuracy=0.459, lr=0.1] 81%|████████  | 63/78 [28:11<06:37, 26.53s/epoch, loss=1.12, accuracy=0.756, val_loss=1.83, val_accuracy=0.583, lr=0.0316] 82%|████████▏ | 64/78 [28:37<06:12, 26.60s/epoch, loss=1.12, accuracy=0.757, val_loss=2.49, val_accuracy=0.36, lr=0.1]     83%|████████▎ | 65/78 [29:04<05:45, 26.60s/epoch, loss=1.13, accuracy=0.758, val_loss=1.85, val_accuracy=0.514, lr=0.1] 85%|████████▍ | 66/78 [29:30<05:18, 26.56s/epoch, loss=1.12, accuracy=0.757, val_loss=3.09, val_accuracy=0.438, lr=0.1] 86%|████████▌ | 67/78 [29:57<04:51, 26.51s/epoch, loss=1.13, accuracy=0.756, val_loss=2.55, val_accuracy=0.43, lr=0.1]  87%|████████▋ | 68/78 [30:23<04:24, 26.50s/epoch, loss=1.12, accuracy=0.759, val_loss=1.93, val_accuracy=0.512, lr=0.0316] 88%|████████▊ | 69/78 [30:49<03:57, 26.38s/epoch, loss=1.12, accuracy=0.759, val_loss=3.15, val_accuracy=0.36, lr=0.1]     90%|████████▉ | 70/78 [31:16<03:31, 26.39s/epoch, loss=1.12, accuracy=0.757, val_loss=2.11, val_accuracy=0.5, lr=0.1]  91%|█████████ | 71/78 [31:43<03:05, 26.53s/epoch, loss=1.12, accuracy=0.759, val_loss=3.25, val_accuracy=0.314, lr=0.1] 92%|█████████▏| 72/78 [32:09<02:38, 26.46s/epoch, loss=1.12, accuracy=0.757, val_loss=3.17, val_accuracy=0.336, lr=0.1] 94%|█████████▎| 73/78 [32:35<02:12, 26.43s/epoch, loss=1.12, accuracy=0.758, val_loss=3.08, val_accuracy=0.273, lr=0.0316] 95%|█████████▍| 74/78 [33:02<01:45, 26.44s/epoch, loss=1.13, accuracy=0.759, val_loss=2.13, val_accuracy=0.465, lr=0.1]    96%|█████████▌| 75/78 [33:28<01:19, 26.51s/epoch, loss=1.12, accuracy=0.759, val_loss=4.04, val_accuracy=0.209, lr=0.1] 97%|█████████▋| 76/78 [33:55<00:53, 26.61s/epoch, loss=1.13, accuracy=0.757, val_loss=3.14, val_accuracy=0.3, lr=0.1]   99%|█████████▊| 77/78 [34:22<00:26, 26.69s/epoch, loss=1.12, accuracy=0.759, val_loss=1.99, val_accuracy=0.471, lr=0.1]100%|██████████| 78/78 [34:49<00:00, 26.62s/epoch, loss=1.11, accuracy=0.761, val_loss=3.93, val_accuracy=0.271, lr=0.0316]100%|██████████| 78/78 [34:49<00:00, 26.78s/epoch, loss=1.11, accuracy=0.761, val_loss=3.93, val_accuracy=0.271, lr=0.0316]
Using real-time data augmentation.
Test loss: 3.9285266399383545
Test accuracy: 0.27090001106262207


* * * Run SGD for ID = 19_13. * * *


2024-02-15 22:03:28.796639: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 22:03:31.731076: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 22:03:31.732728: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-15 22:03:31.773277: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:86:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 22:03:31.773325: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 22:03:31.777074: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 22:03:31.777144: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 22:03:31.779708: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 22:03:31.780586: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 22:03:31.783376: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 22:03:31.785310: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 22:03:31.791292: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 22:03:31.791988: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 22:03:31.792090: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 22:03:33.078796: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-15 22:03:33.079392: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 22:03:33.079918: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:86:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 22:03:33.079955: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 22:03:33.079993: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 22:03:33.080009: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 22:03:33.080024: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 22:03:33.080040: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 22:03:33.080055: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 22:03:33.080071: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 22:03:33.080087: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 22:03:33.080651: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 22:03:33.080695: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 22:03:33.742030: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-15 22:03:33.742090: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-15 22:03:33.742103: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-15 22:03:33.743221: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:86:00.0, compute capability: 6.1)
{'id': 1913, 'batch_size': 128, 'epochs': 78, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/78 [00:00<?, ?epoch/s]2024-02-15 22:03:34.548060: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-15 22:03:34.559732: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2100000000 Hz
2024-02-15 22:03:36.423855: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 22:03:36.668504: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 22:03:37.519257: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-15 22:03:37.564974: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|▏         | 1/78 [00:59<1:15:51, 59.11s/epoch, loss=3.27, accuracy=0.318, val_loss=2.57, val_accuracy=0.186, lr=0.1]  3%|▎         | 2/78 [01:25<50:48, 40.11s/epoch, loss=1.61, accuracy=0.518, val_loss=2.33, val_accuracy=0.394, lr=0.1]    4%|▍         | 3/78 [01:52<42:31, 34.02s/epoch, loss=1.43, accuracy=0.607, val_loss=2.21, val_accuracy=0.42, lr=0.1]   5%|▌         | 4/78 [02:19<38:31, 31.23s/epoch, loss=1.34, accuracy=0.661, val_loss=1.76, val_accuracy=0.545, lr=0.1]  6%|▋         | 5/78 [02:46<36:01, 29.60s/epoch, loss=1.29, accuracy=0.687, val_loss=1.89, val_accuracy=0.54, lr=0.1]   8%|▊         | 6/78 [03:12<34:10, 28.47s/epoch, loss=1.27, accuracy=0.7, val_loss=1.86, val_accuracy=0.47, lr=0.1]    9%|▉         | 7/78 [03:39<32:59, 27.88s/epoch, loss=1.25, accuracy=0.712, val_loss=1.58, val_accuracy=0.602, lr=0.1] 10%|█         | 8/78 [04:05<31:54, 27.35s/epoch, loss=1.25, accuracy=0.717, val_loss=1.82, val_accuracy=0.532, lr=0.1] 12%|█▏        | 9/78 [04:32<31:18, 27.22s/epoch, loss=1.23, accuracy=0.723, val_loss=2.14, val_accuracy=0.505, lr=0.1] 13%|█▎        | 10/78 [04:59<30:39, 27.05s/epoch, loss=1.22, accuracy=0.727, val_loss=1.8, val_accuracy=0.541, lr=0.1] 14%|█▍        | 11/78 [05:26<30:09, 27.00s/epoch, loss=1.22, accuracy=0.728, val_loss=1.5, val_accuracy=0.655, lr=0.1] 15%|█▌        | 12/78 [05:52<29:38, 26.95s/epoch, loss=1.21, accuracy=0.734, val_loss=2.05, val_accuracy=0.447, lr=0.1] 17%|█▋        | 13/78 [06:19<29:13, 26.97s/epoch, loss=1.21, accuracy=0.736, val_loss=1.59, val_accuracy=0.628, lr=0.1] 18%|█▊        | 14/78 [06:46<28:46, 26.97s/epoch, loss=1.21, accuracy=0.734, val_loss=2.01, val_accuracy=0.544, lr=0.1] 19%|█▉        | 15/78 [07:14<28:24, 27.05s/epoch, loss=1.19, accuracy=0.739, val_loss=1.65, val_accuracy=0.587, lr=0.1] 21%|██        | 16/78 [07:41<28:01, 27.12s/epoch, loss=1.2, accuracy=0.74, val_loss=1.81, val_accuracy=0.569, lr=0.0316] 22%|██▏       | 17/78 [08:08<27:25, 26.98s/epoch, loss=1.19, accuracy=0.74, val_loss=1.62, val_accuracy=0.573, lr=0.1]   23%|██▎       | 18/78 [08:34<26:54, 26.90s/epoch, loss=1.2, accuracy=0.739, val_loss=2.09, val_accuracy=0.553, lr=0.1] 24%|██▍       | 19/78 [09:01<26:29, 26.95s/epoch, loss=1.19, accuracy=0.743, val_loss=1.51, val_accuracy=0.63, lr=0.1] 26%|██▌       | 20/78 [09:28<25:55, 26.82s/epoch, loss=1.19, accuracy=0.743, val_loss=2.88, val_accuracy=0.359, lr=0.1] 27%|██▋       | 21/78 [09:53<25:09, 26.48s/epoch, loss=1.18, accuracy=0.745, val_loss=1.51, val_accuracy=0.632, lr=0.0316] 28%|██▊       | 22/78 [10:20<24:41, 26.46s/epoch, loss=1.19, accuracy=0.743, val_loss=1.79, val_accuracy=0.554, lr=0.1]    29%|██▉       | 23/78 [10:47<24:18, 26.51s/epoch, loss=1.18, accuracy=0.746, val_loss=1.5, val_accuracy=0.642, lr=0.1]  31%|███       | 24/78 [11:13<23:52, 26.53s/epoch, loss=1.18, accuracy=0.746, val_loss=2.31, val_accuracy=0.414, lr=0.1] 32%|███▏      | 25/78 [11:40<23:29, 26.59s/epoch, loss=1.18, accuracy=0.745, val_loss=2.26, val_accuracy=0.482, lr=0.1] 33%|███▎      | 26/78 [12:07<23:09, 26.73s/epoch, loss=1.17, accuracy=0.747, val_loss=2.32, val_accuracy=0.408, lr=0.1] 35%|███▍      | 27/78 [12:33<22:39, 26.66s/epoch, loss=1.17, accuracy=0.748, val_loss=2.53, val_accuracy=0.441, lr=0.1] 36%|███▌      | 28/78 [13:00<22:07, 26.56s/epoch, loss=1.17, accuracy=0.747, val_loss=1.81, val_accuracy=0.571, lr=0.0316] 37%|███▋      | 29/78 [13:26<21:37, 26.49s/epoch, loss=1.17, accuracy=0.747, val_loss=1.99, val_accuracy=0.516, lr=0.1]    38%|███▊      | 30/78 [13:53<21:11, 26.49s/epoch, loss=1.17, accuracy=0.747, val_loss=1.85, val_accuracy=0.51, lr=0.1]  40%|███▉      | 31/78 [14:19<20:48, 26.56s/epoch, loss=1.16, accuracy=0.75, val_loss=1.64, val_accuracy=0.586, lr=0.1] 41%|████      | 32/78 [14:46<20:25, 26.63s/epoch, loss=1.16, accuracy=0.749, val_loss=2.31, val_accuracy=0.415, lr=0.1] 42%|████▏     | 33/78 [15:13<19:59, 26.65s/epoch, loss=1.16, accuracy=0.75, val_loss=1.7, val_accuracy=0.558, lr=0.0316] 44%|████▎     | 34/78 [15:40<19:37, 26.76s/epoch, loss=1.15, accuracy=0.75, val_loss=1.66, val_accuracy=0.58, lr=0.1]    45%|████▍     | 35/78 [16:07<19:11, 26.78s/epoch, loss=1.15, accuracy=0.752, val_loss=2.16, val_accuracy=0.512, lr=0.1] 46%|████▌     | 36/78 [16:33<18:45, 26.80s/epoch, loss=1.15, accuracy=0.751, val_loss=2.15, val_accuracy=0.488, lr=0.1] 47%|████▋     | 37/78 [17:00<18:15, 26.73s/epoch, loss=1.16, accuracy=0.751, val_loss=2.94, val_accuracy=0.419, lr=0.1] 49%|████▊     | 38/78 [17:26<17:36, 26.40s/epoch, loss=1.16, accuracy=0.75, val_loss=1.72, val_accuracy=0.566, lr=0.0316] 50%|█████     | 39/78 [17:52<17:08, 26.38s/epoch, loss=1.15, accuracy=0.756, val_loss=2.74, val_accuracy=0.346, lr=0.1]   51%|█████▏    | 40/78 [18:17<16:30, 26.07s/epoch, loss=1.15, accuracy=0.754, val_loss=1.65, val_accuracy=0.587, lr=0.1] 53%|█████▎    | 41/78 [18:42<15:50, 25.70s/epoch, loss=1.15, accuracy=0.754, val_loss=1.51, val_accuracy=0.633, lr=0.1] 54%|█████▍    | 42/78 [19:07<15:17, 25.49s/epoch, loss=1.15, accuracy=0.753, val_loss=2.7, val_accuracy=0.359, lr=0.1]  55%|█████▌    | 43/78 [19:33<14:53, 25.54s/epoch, loss=1.15, accuracy=0.754, val_loss=1.72, val_accuracy=0.577, lr=0.0316] 56%|█████▋    | 44/78 [19:57<14:16, 25.20s/epoch, loss=1.14, accuracy=0.754, val_loss=1.73, val_accuracy=0.555, lr=0.1]    58%|█████▊    | 45/78 [20:23<13:54, 25.27s/epoch, loss=1.15, accuracy=0.751, val_loss=3.82, val_accuracy=0.324, lr=0.1] 59%|█████▉    | 46/78 [20:47<13:17, 24.92s/epoch, loss=1.14, accuracy=0.753, val_loss=1.73, val_accuracy=0.564, lr=0.1] 60%|██████    | 47/78 [21:12<12:53, 24.95s/epoch, loss=1.14, accuracy=0.755, val_loss=1.92, val_accuracy=0.536, lr=0.1] 62%|██████▏   | 48/78 [21:37<12:31, 25.06s/epoch, loss=1.14, accuracy=0.752, val_loss=2.52, val_accuracy=0.481, lr=0.0316] 63%|██████▎   | 49/78 [22:02<12:04, 25.00s/epoch, loss=1.14, accuracy=0.757, val_loss=1.7, val_accuracy=0.567, lr=0.1]     64%|██████▍   | 50/78 [22:28<11:47, 25.25s/epoch, loss=1.14, accuracy=0.752, val_loss=3.43, val_accuracy=0.369, lr=0.1] 65%|██████▌   | 51/78 [22:55<11:35, 25.75s/epoch, loss=1.13, accuracy=0.755, val_loss=1.79, val_accuracy=0.544, lr=0.1] 67%|██████▋   | 52/78 [23:20<11:07, 25.69s/epoch, loss=1.14, accuracy=0.752, val_loss=2.75, val_accuracy=0.421, lr=0.1] 68%|██████▊   | 53/78 [23:46<10:42, 25.68s/epoch, loss=1.14, accuracy=0.755, val_loss=2.42, val_accuracy=0.447, lr=0.0316] 69%|██████▉   | 54/78 [24:12<10:19, 25.80s/epoch, loss=1.13, accuracy=0.754, val_loss=5.45, val_accuracy=0.292, lr=0.1]    71%|███████   | 55/78 [24:38<09:55, 25.91s/epoch, loss=1.14, accuracy=0.756, val_loss=1.55, val_accuracy=0.611, lr=0.1] 72%|███████▏  | 56/78 [25:05<09:35, 26.14s/epoch, loss=1.14, accuracy=0.755, val_loss=1.67, val_accuracy=0.554, lr=0.1] 73%|███████▎  | 57/78 [25:31<09:06, 26.02s/epoch, loss=1.14, accuracy=0.756, val_loss=2, val_accuracy=0.455, lr=0.1]    74%|███████▍  | 58/78 [25:57<08:42, 26.10s/epoch, loss=1.13, accuracy=0.757, val_loss=2.59, val_accuracy=0.435, lr=0.0316] 76%|███████▌  | 59/78 [26:24<08:19, 26.30s/epoch, loss=1.13, accuracy=0.755, val_loss=2.08, val_accuracy=0.443, lr=0.1]    77%|███████▋  | 60/78 [26:51<07:57, 26.51s/epoch, loss=1.14, accuracy=0.757, val_loss=2.14, val_accuracy=0.442, lr=0.1] 78%|███████▊  | 61/78 [27:17<07:28, 26.41s/epoch, loss=1.14, accuracy=0.753, val_loss=2.77, val_accuracy=0.42, lr=0.1]  79%|███████▉  | 62/78 [27:43<07:01, 26.34s/epoch, loss=1.13, accuracy=0.754, val_loss=1.78, val_accuracy=0.531, lr=0.1] 81%|████████  | 63/78 [28:09<06:35, 26.38s/epoch, loss=1.13, accuracy=0.757, val_loss=1.97, val_accuracy=0.511, lr=0.0316] 82%|████████▏ | 64/78 [28:36<06:10, 26.45s/epoch, loss=1.13, accuracy=0.754, val_loss=3.49, val_accuracy=0.268, lr=0.1]    83%|████████▎ | 65/78 [29:02<05:41, 26.24s/epoch, loss=1.13, accuracy=0.756, val_loss=1.48, val_accuracy=0.621, lr=0.1] 85%|████████▍ | 66/78 [29:28<05:16, 26.33s/epoch, loss=1.14, accuracy=0.755, val_loss=2.3, val_accuracy=0.476, lr=0.1]  86%|████████▌ | 67/78 [29:54<04:48, 26.19s/epoch, loss=1.13, accuracy=0.758, val_loss=5.14, val_accuracy=0.183, lr=0.1] 87%|████████▋ | 68/78 [30:20<04:21, 26.17s/epoch, loss=1.13, accuracy=0.757, val_loss=1.51, val_accuracy=0.619, lr=0.1] 88%|████████▊ | 69/78 [30:47<03:56, 26.23s/epoch, loss=1.13, accuracy=0.758, val_loss=1.91, val_accuracy=0.504, lr=0.1] 90%|████████▉ | 70/78 [31:13<03:30, 26.32s/epoch, loss=1.13, accuracy=0.756, val_loss=2.28, val_accuracy=0.491, lr=0.0316] 91%|█████████ | 71/78 [31:40<03:04, 26.37s/epoch, loss=1.13, accuracy=0.757, val_loss=2.87, val_accuracy=0.336, lr=0.1]    92%|█████████▏| 72/78 [32:06<02:38, 26.43s/epoch, loss=1.13, accuracy=0.754, val_loss=1.76, val_accuracy=0.532, lr=0.1] 94%|█████████▎| 73/78 [32:33<02:12, 26.51s/epoch, loss=1.12, accuracy=0.758, val_loss=1.41, val_accuracy=0.656, lr=0.1] 95%|█████████▍| 74/78 [33:00<01:46, 26.62s/epoch, loss=1.13, accuracy=0.757, val_loss=1.77, val_accuracy=0.54, lr=0.1]  96%|█████████▌| 75/78 [33:26<01:19, 26.52s/epoch, loss=1.12, accuracy=0.756, val_loss=1.63, val_accuracy=0.636, lr=0.1] 97%|█████████▋| 76/78 [33:53<00:53, 26.52s/epoch, loss=1.12, accuracy=0.76, val_loss=1.94, val_accuracy=0.537, lr=0.1]  99%|█████████▊| 77/78 [34:19<00:26, 26.47s/epoch, loss=1.13, accuracy=0.757, val_loss=4.75, val_accuracy=0.249, lr=0.1]100%|██████████| 78/78 [34:45<00:00, 26.41s/epoch, loss=1.12, accuracy=0.757, val_loss=4.47, val_accuracy=0.237, lr=0.0316]100%|██████████| 78/78 [34:45<00:00, 26.74s/epoch, loss=1.12, accuracy=0.757, val_loss=4.47, val_accuracy=0.237, lr=0.0316]
Using real-time data augmentation.
Test loss: 4.471940040588379
Test accuracy: 0.23720000684261322


* * * Run SGD for ID = 19_14. * * *


2024-02-15 22:38:23.134189: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 22:38:25.931145: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 22:38:25.932633: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-15 22:38:25.973523: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:86:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 22:38:25.973577: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 22:38:25.976953: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 22:38:25.977017: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 22:38:25.979253: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 22:38:25.979970: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 22:38:25.982662: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 22:38:25.984247: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 22:38:25.989801: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 22:38:25.990470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 22:38:25.990566: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 22:38:27.202181: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-15 22:38:27.202811: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 22:38:27.203325: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:86:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 22:38:27.203359: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 22:38:27.203395: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 22:38:27.203410: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 22:38:27.203425: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 22:38:27.203439: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 22:38:27.203454: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 22:38:27.203469: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 22:38:27.203483: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 22:38:27.204059: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 22:38:27.204101: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 22:38:27.832949: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-15 22:38:27.833001: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-15 22:38:27.833012: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-15 22:38:27.834085: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:86:00.0, compute capability: 6.1)
{'id': 1914, 'batch_size': 128, 'epochs': 78, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/78 [00:00<?, ?epoch/s]2024-02-15 22:38:28.600600: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-15 22:38:28.612730: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2100000000 Hz
2024-02-15 22:38:30.530755: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 22:38:30.895997: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 22:38:31.737448: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-15 22:38:31.783390: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|▏         | 1/78 [01:12<1:33:27, 72.83s/epoch, loss=3.47, accuracy=0.327, val_loss=2.34, val_accuracy=0.261, lr=0.1]  3%|▎         | 2/78 [01:39<58:04, 45.84s/epoch, loss=1.59, accuracy=0.526, val_loss=3.33, val_accuracy=0.264, lr=0.1]    4%|▍         | 3/78 [02:06<46:34, 37.25s/epoch, loss=1.35, accuracy=0.642, val_loss=1.85, val_accuracy=0.534, lr=0.1]  5%|▌         | 4/78 [02:33<40:56, 33.20s/epoch, loss=1.29, accuracy=0.686, val_loss=2.27, val_accuracy=0.355, lr=0.1]  6%|▋         | 5/78 [03:00<37:30, 30.83s/epoch, loss=1.26, accuracy=0.703, val_loss=2.23, val_accuracy=0.419, lr=0.1]  8%|▊         | 6/78 [03:27<35:21, 29.47s/epoch, loss=1.24, accuracy=0.712, val_loss=2.63, val_accuracy=0.451, lr=0.1]  9%|▉         | 7/78 [03:54<33:52, 28.63s/epoch, loss=1.22, accuracy=0.72, val_loss=2.43, val_accuracy=0.438, lr=0.1]  10%|█         | 8/78 [04:20<32:36, 27.95s/epoch, loss=1.22, accuracy=0.72, val_loss=1.7, val_accuracy=0.559, lr=0.1]  12%|█▏        | 9/78 [04:47<31:44, 27.60s/epoch, loss=1.21, accuracy=0.728, val_loss=1.8, val_accuracy=0.523, lr=0.1] 13%|█▎        | 10/78 [05:14<31:09, 27.49s/epoch, loss=1.2, accuracy=0.731, val_loss=1.94, val_accuracy=0.523, lr=0.1] 14%|█▍        | 11/78 [05:41<30:23, 27.21s/epoch, loss=1.2, accuracy=0.733, val_loss=1.85, val_accuracy=0.558, lr=0.1] 15%|█▌        | 12/78 [06:08<29:47, 27.09s/epoch, loss=1.2, accuracy=0.735, val_loss=1.54, val_accuracy=0.622, lr=0.1] 17%|█▋        | 13/78 [06:34<29:15, 27.01s/epoch, loss=1.2, accuracy=0.735, val_loss=2.83, val_accuracy=0.389, lr=0.1] 18%|█▊        | 14/78 [07:01<28:38, 26.85s/epoch, loss=1.19, accuracy=0.738, val_loss=2.87, val_accuracy=0.363, lr=0.1] 19%|█▉        | 15/78 [07:28<28:15, 26.91s/epoch, loss=1.18, accuracy=0.738, val_loss=1.39, val_accuracy=0.668, lr=0.1] 21%|██        | 16/78 [07:55<27:48, 26.91s/epoch, loss=1.18, accuracy=0.742, val_loss=2.28, val_accuracy=0.457, lr=0.1] 22%|██▏       | 17/78 [08:22<27:26, 26.99s/epoch, loss=1.18, accuracy=0.743, val_loss=2.43, val_accuracy=0.398, lr=0.1] 23%|██▎       | 18/78 [08:48<26:48, 26.82s/epoch, loss=1.18, accuracy=0.742, val_loss=1.46, val_accuracy=0.644, lr=0.1] 24%|██▍       | 19/78 [09:16<26:28, 26.92s/epoch, loss=1.17, accuracy=0.744, val_loss=1.67, val_accuracy=0.571, lr=0.1] 26%|██▌       | 20/78 [09:43<26:01, 26.92s/epoch, loss=1.18, accuracy=0.747, val_loss=3.19, val_accuracy=0.394, lr=0.0316] 27%|██▋       | 21/78 [10:09<25:30, 26.85s/epoch, loss=1.18, accuracy=0.745, val_loss=1.78, val_accuracy=0.53, lr=0.1]     28%|██▊       | 22/78 [10:36<24:57, 26.75s/epoch, loss=1.17, accuracy=0.746, val_loss=1.62, val_accuracy=0.622, lr=0.1] 29%|██▉       | 23/78 [11:03<24:36, 26.85s/epoch, loss=1.17, accuracy=0.748, val_loss=1.7, val_accuracy=0.55, lr=0.1]   31%|███       | 24/78 [11:30<24:07, 26.81s/epoch, loss=1.17, accuracy=0.747, val_loss=1.83, val_accuracy=0.546, lr=0.1] 32%|███▏      | 25/78 [11:56<23:42, 26.84s/epoch, loss=1.17, accuracy=0.746, val_loss=2.14, val_accuracy=0.45, lr=0.0316] 33%|███▎      | 26/78 [12:23<23:16, 26.86s/epoch, loss=1.17, accuracy=0.75, val_loss=1.64, val_accuracy=0.596, lr=0.1]    35%|███▍      | 27/78 [12:50<22:51, 26.89s/epoch, loss=1.17, accuracy=0.749, val_loss=1.57, val_accuracy=0.614, lr=0.1] 36%|███▌      | 28/78 [13:17<22:21, 26.82s/epoch, loss=1.16, accuracy=0.748, val_loss=1.82, val_accuracy=0.568, lr=0.1] 37%|███▋      | 29/78 [13:44<22:01, 26.98s/epoch, loss=1.17, accuracy=0.75, val_loss=2.39, val_accuracy=0.414, lr=0.1]  38%|███▊      | 30/78 [14:11<21:27, 26.82s/epoch, loss=1.16, accuracy=0.748, val_loss=1.92, val_accuracy=0.533, lr=0.0316] 40%|███▉      | 31/78 [14:38<21:01, 26.85s/epoch, loss=1.16, accuracy=0.751, val_loss=2.91, val_accuracy=0.276, lr=0.1]    41%|████      | 32/78 [15:05<20:37, 26.90s/epoch, loss=1.16, accuracy=0.749, val_loss=2.85, val_accuracy=0.35, lr=0.1]  42%|████▏     | 33/78 [15:31<20:08, 26.85s/epoch, loss=1.15, accuracy=0.749, val_loss=1.86, val_accuracy=0.541, lr=0.1] 44%|████▎     | 34/78 [15:58<19:39, 26.82s/epoch, loss=1.16, accuracy=0.753, val_loss=1.77, val_accuracy=0.537, lr=0.1] 45%|████▍     | 35/78 [16:25<19:12, 26.81s/epoch, loss=1.16, accuracy=0.752, val_loss=2.01, val_accuracy=0.546, lr=0.0316] 46%|████▌     | 36/78 [16:52<18:51, 26.93s/epoch, loss=1.15, accuracy=0.752, val_loss=2.21, val_accuracy=0.476, lr=0.1]    47%|████▋     | 37/78 [17:19<18:25, 26.96s/epoch, loss=1.16, accuracy=0.755, val_loss=2.39, val_accuracy=0.434, lr=0.1] 49%|████▊     | 38/78 [17:46<18:02, 27.06s/epoch, loss=1.16, accuracy=0.751, val_loss=1.92, val_accuracy=0.459, lr=0.1] 50%|█████     | 39/78 [18:14<17:37, 27.11s/epoch, loss=1.16, accuracy=0.75, val_loss=2.29, val_accuracy=0.432, lr=0.1]  51%|█████▏    | 40/78 [18:41<17:11, 27.14s/epoch, loss=1.16, accuracy=0.753, val_loss=1.61, val_accuracy=0.593, lr=0.0316] 53%|█████▎    | 41/78 [19:08<16:42, 27.11s/epoch, loss=1.15, accuracy=0.753, val_loss=1.92, val_accuracy=0.54, lr=0.1]     54%|█████▍    | 42/78 [19:35<16:14, 27.07s/epoch, loss=1.15, accuracy=0.751, val_loss=1.61, val_accuracy=0.596, lr=0.1] 55%|█████▌    | 43/78 [20:02<15:49, 27.14s/epoch, loss=1.16, accuracy=0.75, val_loss=1.9, val_accuracy=0.483, lr=0.1]   56%|█████▋    | 44/78 [20:30<15:24, 27.20s/epoch, loss=1.15, accuracy=0.756, val_loss=1.53, val_accuracy=0.633, lr=0.1] 58%|█████▊    | 45/78 [20:57<14:55, 27.12s/epoch, loss=1.15, accuracy=0.755, val_loss=1.65, val_accuracy=0.567, lr=0.0316] 59%|█████▉    | 46/78 [21:23<14:24, 27.02s/epoch, loss=1.15, accuracy=0.753, val_loss=1.79, val_accuracy=0.546, lr=0.1]    60%|██████    | 47/78 [21:50<13:57, 27.01s/epoch, loss=1.15, accuracy=0.752, val_loss=2.02, val_accuracy=0.476, lr=0.1] 62%|██████▏   | 48/78 [22:17<13:24, 26.81s/epoch, loss=1.16, accuracy=0.754, val_loss=2.97, val_accuracy=0.392, lr=0.1] 63%|██████▎   | 49/78 [22:43<12:54, 26.72s/epoch, loss=1.14, accuracy=0.754, val_loss=1.72, val_accuracy=0.568, lr=0.1] 64%|██████▍   | 50/78 [23:10<12:26, 26.66s/epoch, loss=1.15, accuracy=0.753, val_loss=1.64, val_accuracy=0.575, lr=0.0316] 65%|██████▌   | 51/78 [23:36<12:00, 26.70s/epoch, loss=1.16, accuracy=0.753, val_loss=1.84, val_accuracy=0.566, lr=0.1]    67%|██████▋   | 52/78 [24:03<11:35, 26.75s/epoch, loss=1.15, accuracy=0.754, val_loss=2.05, val_accuracy=0.481, lr=0.1] 68%|██████▊   | 53/78 [24:30<11:06, 26.68s/epoch, loss=1.15, accuracy=0.756, val_loss=2.05, val_accuracy=0.489, lr=0.1] 69%|██████▉   | 54/78 [24:56<10:37, 26.56s/epoch, loss=1.15, accuracy=0.753, val_loss=1.74, val_accuracy=0.597, lr=0.1] 71%|███████   | 55/78 [25:22<10:05, 26.33s/epoch, loss=1.15, accuracy=0.754, val_loss=2.28, val_accuracy=0.488, lr=0.0316] 72%|███████▏  | 56/78 [25:48<09:34, 26.13s/epoch, loss=1.14, accuracy=0.752, val_loss=1.76, val_accuracy=0.533, lr=0.1]    73%|███████▎  | 57/78 [26:14<09:08, 26.11s/epoch, loss=1.14, accuracy=0.754, val_loss=2.15, val_accuracy=0.492, lr=0.1] 74%|███████▍  | 58/78 [26:40<08:42, 26.11s/epoch, loss=1.15, accuracy=0.755, val_loss=1.71, val_accuracy=0.557, lr=0.1] 76%|███████▌  | 59/78 [27:05<08:13, 25.96s/epoch, loss=1.15, accuracy=0.754, val_loss=1.67, val_accuracy=0.573, lr=0.1] 77%|███████▋  | 60/78 [27:31<07:45, 25.85s/epoch, loss=1.15, accuracy=0.755, val_loss=1.98, val_accuracy=0.481, lr=0.0316] 78%|███████▊  | 61/78 [27:56<07:14, 25.58s/epoch, loss=1.15, accuracy=0.755, val_loss=13.7, val_accuracy=0.123, lr=0.1]    79%|███████▉  | 62/78 [28:21<06:48, 25.52s/epoch, loss=1.15, accuracy=0.753, val_loss=1.84, val_accuracy=0.591, lr=0.1] 81%|████████  | 63/78 [28:47<06:24, 25.60s/epoch, loss=1.15, accuracy=0.753, val_loss=2.6, val_accuracy=0.369, lr=0.1]  82%|████████▏ | 64/78 [29:13<05:59, 25.71s/epoch, loss=1.14, accuracy=0.756, val_loss=1.53, val_accuracy=0.652, lr=0.1] 83%|████████▎ | 65/78 [29:39<05:36, 25.86s/epoch, loss=1.14, accuracy=0.754, val_loss=3.1, val_accuracy=0.341, lr=0.0316] 85%|████████▍ | 66/78 [30:04<05:07, 25.62s/epoch, loss=1.14, accuracy=0.756, val_loss=1.79, val_accuracy=0.538, lr=0.1]   86%|████████▌ | 67/78 [30:29<04:39, 25.41s/epoch, loss=1.15, accuracy=0.755, val_loss=5.94, val_accuracy=0.139, lr=0.1] 87%|████████▋ | 68/78 [30:54<04:12, 25.28s/epoch, loss=1.14, accuracy=0.754, val_loss=2, val_accuracy=0.508, lr=0.1]    88%|████████▊ | 69/78 [31:19<03:45, 25.11s/epoch, loss=1.14, accuracy=0.757, val_loss=1.97, val_accuracy=0.492, lr=0.1] 90%|████████▉ | 70/78 [31:44<03:20, 25.12s/epoch, loss=1.14, accuracy=0.753, val_loss=1.77, val_accuracy=0.544, lr=0.0316] 91%|█████████ | 71/78 [32:09<02:55, 25.04s/epoch, loss=1.14, accuracy=0.756, val_loss=3.64, val_accuracy=0.284, lr=0.1]    92%|█████████▏| 72/78 [32:34<02:30, 25.05s/epoch, loss=1.13, accuracy=0.757, val_loss=5.25, val_accuracy=0.236, lr=0.1] 94%|█████████▎| 73/78 [32:59<02:05, 25.05s/epoch, loss=1.14, accuracy=0.756, val_loss=1.56, val_accuracy=0.603, lr=0.1] 95%|█████████▍| 74/78 [33:24<01:40, 25.00s/epoch, loss=1.14, accuracy=0.754, val_loss=2.01, val_accuracy=0.571, lr=0.1] 96%|█████████▌| 75/78 [33:50<01:15, 25.20s/epoch, loss=1.13, accuracy=0.756, val_loss=3.19, val_accuracy=0.365, lr=0.0316] 97%|█████████▋| 76/78 [34:15<00:50, 25.35s/epoch, loss=1.13, accuracy=0.757, val_loss=1.86, val_accuracy=0.47, lr=0.1]     99%|█████████▊| 77/78 [34:42<00:25, 25.67s/epoch, loss=1.13, accuracy=0.756, val_loss=1.79, val_accuracy=0.549, lr=0.1]100%|██████████| 78/78 [35:07<00:00, 25.57s/epoch, loss=1.13, accuracy=0.757, val_loss=2.23, val_accuracy=0.494, lr=0.1]100%|██████████| 78/78 [35:07<00:00, 27.02s/epoch, loss=1.13, accuracy=0.757, val_loss=2.23, val_accuracy=0.494, lr=0.1]
Using real-time data augmentation.
Test loss: 2.234140396118164
Test accuracy: 0.49390000104904175


* * * Run SGD for ID = 19_15. * * *


2024-02-15 23:13:40.807430: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 23:13:52.765003: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 23:13:52.766267: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-15 23:13:52.812404: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:86:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 23:13:52.812452: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 23:13:52.816051: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 23:13:52.816119: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 23:13:52.818492: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 23:13:52.819157: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 23:13:52.821868: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 23:13:52.823484: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 23:13:52.829123: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 23:13:52.829870: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 23:13:52.830276: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 23:13:54.065949: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-15 23:13:54.066541: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 23:13:54.067065: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:86:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 23:13:54.067100: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 23:13:54.067136: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 23:13:54.067151: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 23:13:54.067166: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 23:13:54.067180: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 23:13:54.067195: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 23:13:54.067209: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 23:13:54.067224: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 23:13:54.067807: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 23:13:54.067844: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 23:13:54.716439: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-15 23:13:54.716492: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-15 23:13:54.716504: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-15 23:13:54.717620: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:86:00.0, compute capability: 6.1)
{'id': 1915, 'batch_size': 128, 'epochs': 78, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/78 [00:00<?, ?epoch/s]2024-02-15 23:13:55.486924: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-15 23:13:55.498726: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2100000000 Hz
2024-02-15 23:13:57.349402: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 23:13:57.619951: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 23:13:58.730791: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-15 23:13:58.795173: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|▏         | 1/78 [00:59<1:16:41, 59.76s/epoch, loss=3.19, accuracy=0.303, val_loss=3.17, val_accuracy=0.138, lr=0.1]  3%|▎         | 2/78 [01:25<50:06, 39.55s/epoch, loss=1.55, accuracy=0.539, val_loss=2.04, val_accuracy=0.406, lr=0.1]    4%|▍         | 3/78 [01:49<40:59, 32.80s/epoch, loss=1.33, accuracy=0.647, val_loss=1.94, val_accuracy=0.456, lr=0.1]  5%|▌         | 4/78 [02:15<36:45, 29.81s/epoch, loss=1.28, accuracy=0.683, val_loss=4.43, val_accuracy=0.283, lr=0.1]  6%|▋         | 5/78 [02:40<34:13, 28.14s/epoch, loss=1.25, accuracy=0.702, val_loss=1.56, val_accuracy=0.59, lr=0.1]   8%|▊         | 6/78 [03:04<32:18, 26.92s/epoch, loss=1.23, accuracy=0.712, val_loss=2.72, val_accuracy=0.396, lr=0.1]  9%|▉         | 7/78 [03:29<31:04, 26.26s/epoch, loss=1.22, accuracy=0.72, val_loss=1.8, val_accuracy=0.535, lr=0.1]   10%|█         | 8/78 [03:54<30:03, 25.77s/epoch, loss=1.21, accuracy=0.723, val_loss=2.23, val_accuracy=0.442, lr=0.1] 12%|█▏        | 9/78 [04:20<29:47, 25.91s/epoch, loss=1.2, accuracy=0.731, val_loss=3.2, val_accuracy=0.343, lr=0.1]   13%|█▎        | 10/78 [04:46<29:12, 25.77s/epoch, loss=1.21, accuracy=0.729, val_loss=2.69, val_accuracy=0.443, lr=0.0316] 14%|█▍        | 11/78 [05:11<28:40, 25.68s/epoch, loss=1.19, accuracy=0.736, val_loss=2.11, val_accuracy=0.471, lr=0.1]    15%|█▌        | 12/78 [05:36<28:00, 25.46s/epoch, loss=1.19, accuracy=0.735, val_loss=1.6, val_accuracy=0.581, lr=0.1]  17%|█▋        | 13/78 [06:01<27:18, 25.21s/epoch, loss=1.19, accuracy=0.734, val_loss=2.92, val_accuracy=0.34, lr=0.1] 18%|█▊        | 14/78 [06:27<27:07, 25.42s/epoch, loss=1.18, accuracy=0.738, val_loss=1.95, val_accuracy=0.515, lr=0.1] 19%|█▉        | 15/78 [06:52<26:40, 25.41s/epoch, loss=1.19, accuracy=0.74, val_loss=1.91, val_accuracy=0.516, lr=0.0316] 21%|██        | 16/78 [07:18<26:17, 25.45s/epoch, loss=1.18, accuracy=0.74, val_loss=1.68, val_accuracy=0.588, lr=0.1]    22%|██▏       | 17/78 [07:43<25:48, 25.38s/epoch, loss=1.18, accuracy=0.743, val_loss=2.31, val_accuracy=0.498, lr=0.1] 23%|██▎       | 18/78 [08:08<25:24, 25.41s/epoch, loss=1.18, accuracy=0.743, val_loss=2.11, val_accuracy=0.412, lr=0.1] 24%|██▍       | 19/78 [08:33<24:45, 25.18s/epoch, loss=1.18, accuracy=0.743, val_loss=1.99, val_accuracy=0.543, lr=0.1] 26%|██▌       | 20/78 [08:58<24:25, 25.26s/epoch, loss=1.17, accuracy=0.744, val_loss=2.57, val_accuracy=0.429, lr=0.0316] 27%|██▋       | 21/78 [09:24<23:58, 25.23s/epoch, loss=1.17, accuracy=0.745, val_loss=2.2, val_accuracy=0.47, lr=0.1]      28%|██▊       | 22/78 [09:49<23:32, 25.23s/epoch, loss=1.17, accuracy=0.745, val_loss=1.6, val_accuracy=0.619, lr=0.1] 29%|██▉       | 23/78 [10:14<23:12, 25.32s/epoch, loss=1.17, accuracy=0.746, val_loss=2.84, val_accuracy=0.335, lr=0.1] 31%|███       | 24/78 [10:39<22:40, 25.20s/epoch, loss=1.16, accuracy=0.749, val_loss=1.66, val_accuracy=0.574, lr=0.1] 32%|███▏      | 25/78 [11:04<22:15, 25.19s/epoch, loss=1.16, accuracy=0.749, val_loss=1.9, val_accuracy=0.548, lr=0.0316] 33%|███▎      | 26/78 [11:30<21:59, 25.37s/epoch, loss=1.16, accuracy=0.746, val_loss=4.02, val_accuracy=0.29, lr=0.1]    35%|███▍      | 27/78 [11:55<21:29, 25.29s/epoch, loss=1.16, accuracy=0.749, val_loss=1.88, val_accuracy=0.525, lr=0.1] 36%|███▌      | 28/78 [12:20<20:51, 25.03s/epoch, loss=1.16, accuracy=0.75, val_loss=3.69, val_accuracy=0.336, lr=0.1]  37%|███▋      | 29/78 [12:46<20:41, 25.35s/epoch, loss=1.16, accuracy=0.747, val_loss=2.17, val_accuracy=0.544, lr=0.1] 38%|███▊      | 30/78 [13:11<20:19, 25.40s/epoch, loss=1.15, accuracy=0.753, val_loss=2.09, val_accuracy=0.456, lr=0.0316] 40%|███▉      | 31/78 [13:36<19:43, 25.17s/epoch, loss=1.16, accuracy=0.753, val_loss=3.8, val_accuracy=0.301, lr=0.1]     41%|████      | 32/78 [14:02<19:23, 25.29s/epoch, loss=1.16, accuracy=0.75, val_loss=3.05, val_accuracy=0.368, lr=0.1] 42%|████▏     | 33/78 [14:27<19:05, 25.45s/epoch, loss=1.15, accuracy=0.752, val_loss=3.55, val_accuracy=0.319, lr=0.1] 44%|████▎     | 34/78 [14:53<18:36, 25.37s/epoch, loss=1.16, accuracy=0.75, val_loss=1.79, val_accuracy=0.537, lr=0.1]  45%|████▍     | 35/78 [15:17<18:05, 25.24s/epoch, loss=1.15, accuracy=0.752, val_loss=3.36, val_accuracy=0.354, lr=0.0316] 46%|████▌     | 36/78 [15:43<17:47, 25.42s/epoch, loss=1.15, accuracy=0.75, val_loss=2.42, val_accuracy=0.428, lr=0.1]     47%|████▋     | 37/78 [16:09<17:20, 25.39s/epoch, loss=1.15, accuracy=0.752, val_loss=1.75, val_accuracy=0.576, lr=0.1] 49%|████▊     | 38/78 [16:34<16:52, 25.31s/epoch, loss=1.15, accuracy=0.752, val_loss=1.85, val_accuracy=0.55, lr=0.1]  50%|█████     | 39/78 [17:00<16:33, 25.47s/epoch, loss=1.15, accuracy=0.753, val_loss=2.01, val_accuracy=0.433, lr=0.1] 51%|█████▏    | 40/78 [17:25<16:04, 25.37s/epoch, loss=1.14, accuracy=0.754, val_loss=2.34, val_accuracy=0.465, lr=0.0316] 53%|█████▎    | 41/78 [17:51<15:43, 25.51s/epoch, loss=1.15, accuracy=0.751, val_loss=1.77, val_accuracy=0.546, lr=0.1]    54%|█████▍    | 42/78 [18:15<15:11, 25.32s/epoch, loss=1.15, accuracy=0.751, val_loss=2.04, val_accuracy=0.477, lr=0.1] 55%|█████▌    | 43/78 [18:41<14:50, 25.44s/epoch, loss=1.14, accuracy=0.755, val_loss=2.09, val_accuracy=0.458, lr=0.1] 56%|█████▋    | 44/78 [19:06<14:21, 25.32s/epoch, loss=1.15, accuracy=0.753, val_loss=3.64, val_accuracy=0.268, lr=0.1] 58%|█████▊    | 45/78 [19:31<13:54, 25.29s/epoch, loss=1.15, accuracy=0.753, val_loss=2.31, val_accuracy=0.435, lr=0.0316] 59%|█████▉    | 46/78 [19:56<13:21, 25.06s/epoch, loss=1.14, accuracy=0.755, val_loss=3.24, val_accuracy=0.392, lr=0.1]    60%|██████    | 47/78 [20:22<13:01, 25.21s/epoch, loss=1.14, accuracy=0.753, val_loss=2.25, val_accuracy=0.461, lr=0.1] 62%|██████▏   | 48/78 [20:47<12:39, 25.33s/epoch, loss=1.14, accuracy=0.756, val_loss=2.14, val_accuracy=0.499, lr=0.1] 63%|██████▎   | 49/78 [21:13<12:16, 25.38s/epoch, loss=1.15, accuracy=0.754, val_loss=2.07, val_accuracy=0.492, lr=0.1] 64%|██████▍   | 50/78 [21:37<11:46, 25.22s/epoch, loss=1.15, accuracy=0.755, val_loss=1.74, val_accuracy=0.592, lr=0.0316] 65%|██████▌   | 51/78 [22:02<11:18, 25.13s/epoch, loss=1.15, accuracy=0.751, val_loss=2.59, val_accuracy=0.429, lr=0.1]    67%|██████▋   | 52/78 [22:28<11:00, 25.39s/epoch, loss=1.14, accuracy=0.756, val_loss=1.89, val_accuracy=0.548, lr=0.1] 68%|██████▊   | 53/78 [22:54<10:36, 25.47s/epoch, loss=1.15, accuracy=0.75, val_loss=3.59, val_accuracy=0.346, lr=0.1]  69%|██████▉   | 54/78 [23:20<10:14, 25.61s/epoch, loss=1.14, accuracy=0.755, val_loss=1.57, val_accuracy=0.648, lr=0.1] 71%|███████   | 55/78 [23:46<09:53, 25.82s/epoch, loss=1.14, accuracy=0.753, val_loss=2.01, val_accuracy=0.534, lr=0.0316] 72%|███████▏  | 56/78 [24:11<09:20, 25.48s/epoch, loss=1.13, accuracy=0.755, val_loss=1.7, val_accuracy=0.574, lr=0.1]     73%|███████▎  | 57/78 [24:36<08:52, 25.33s/epoch, loss=1.14, accuracy=0.755, val_loss=1.89, val_accuracy=0.499, lr=0.1] 74%|███████▍  | 58/78 [25:01<08:27, 25.39s/epoch, loss=1.14, accuracy=0.755, val_loss=2.11, val_accuracy=0.483, lr=0.1] 76%|███████▌  | 59/78 [25:26<07:59, 25.22s/epoch, loss=1.13, accuracy=0.756, val_loss=2.02, val_accuracy=0.47, lr=0.1]  77%|███████▋  | 60/78 [25:52<07:37, 25.42s/epoch, loss=1.14, accuracy=0.757, val_loss=1.87, val_accuracy=0.522, lr=0.0316] 78%|███████▊  | 61/78 [26:17<07:10, 25.32s/epoch, loss=1.14, accuracy=0.753, val_loss=2.46, val_accuracy=0.46, lr=0.1]     79%|███████▉  | 62/78 [26:42<06:43, 25.20s/epoch, loss=1.14, accuracy=0.756, val_loss=1.77, val_accuracy=0.579, lr=0.1] 81%|████████  | 63/78 [27:08<06:19, 25.32s/epoch, loss=1.14, accuracy=0.756, val_loss=1.71, val_accuracy=0.591, lr=0.1] 82%|████████▏ | 64/78 [27:32<05:51, 25.12s/epoch, loss=1.13, accuracy=0.756, val_loss=1.48, val_accuracy=0.637, lr=0.1] 83%|████████▎ | 65/78 [27:57<05:25, 25.05s/epoch, loss=1.14, accuracy=0.756, val_loss=1.72, val_accuracy=0.54, lr=0.1]  85%|████████▍ | 66/78 [28:23<05:01, 25.11s/epoch, loss=1.14, accuracy=0.756, val_loss=1.7, val_accuracy=0.604, lr=0.1] 86%|████████▌ | 67/78 [28:48<04:36, 25.16s/epoch, loss=1.13, accuracy=0.757, val_loss=1.88, val_accuracy=0.553, lr=0.1] 87%|████████▋ | 68/78 [29:14<04:13, 25.34s/epoch, loss=1.14, accuracy=0.758, val_loss=2.22, val_accuracy=0.484, lr=0.1] 88%|████████▊ | 69/78 [29:39<03:47, 25.24s/epoch, loss=1.14, accuracy=0.756, val_loss=1.73, val_accuracy=0.583, lr=0.0316] 90%|████████▉ | 70/78 [30:03<03:21, 25.13s/epoch, loss=1.14, accuracy=0.753, val_loss=3.31, val_accuracy=0.242, lr=0.1]    91%|█████████ | 71/78 [30:29<02:56, 25.17s/epoch, loss=1.14, accuracy=0.756, val_loss=2.38, val_accuracy=0.425, lr=0.1] 92%|█████████▏| 72/78 [30:54<02:30, 25.04s/epoch, loss=1.13, accuracy=0.755, val_loss=2.08, val_accuracy=0.423, lr=0.1] 94%|█████████▎| 73/78 [31:19<02:05, 25.17s/epoch, loss=1.13, accuracy=0.759, val_loss=3.32, val_accuracy=0.316, lr=0.1] 95%|█████████▍| 74/78 [31:44<01:40, 25.09s/epoch, loss=1.13, accuracy=0.755, val_loss=2.67, val_accuracy=0.406, lr=0.0316] 96%|█████████▌| 75/78 [32:09<01:15, 25.02s/epoch, loss=1.13, accuracy=0.757, val_loss=1.87, val_accuracy=0.504, lr=0.1]    97%|█████████▋| 76/78 [32:34<00:49, 24.98s/epoch, loss=1.14, accuracy=0.754, val_loss=1.89, val_accuracy=0.523, lr=0.1] 99%|█████████▊| 77/78 [32:58<00:24, 24.79s/epoch, loss=1.13, accuracy=0.755, val_loss=1.85, val_accuracy=0.526, lr=0.1]100%|██████████| 78/78 [33:24<00:00, 25.09s/epoch, loss=1.13, accuracy=0.756, val_loss=2.59, val_accuracy=0.492, lr=0.1]100%|██████████| 78/78 [33:24<00:00, 25.70s/epoch, loss=1.13, accuracy=0.756, val_loss=2.59, val_accuracy=0.492, lr=0.1]
Using real-time data augmentation.
Test loss: 2.5927369594573975
Test accuracy: 0.4921000003814697


* * * Run SGD for ID = 19_16. * * *


2024-02-15 23:47:22.440297: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 23:47:25.432791: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 23:47:25.434382: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-15 23:47:25.477730: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:86:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 23:47:25.477772: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 23:47:25.481055: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 23:47:25.481116: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 23:47:25.484499: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 23:47:25.485944: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 23:47:25.489515: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 23:47:25.491311: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 23:47:25.497847: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 23:47:25.498488: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 23:47:25.498581: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 23:47:26.718330: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-15 23:47:26.718926: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 23:47:26.721091: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:86:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 23:47:26.721123: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 23:47:26.721158: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 23:47:26.721171: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 23:47:26.721184: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 23:47:26.721197: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 23:47:26.721209: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 23:47:26.721222: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 23:47:26.721235: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 23:47:26.721818: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 23:47:26.721865: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 23:47:27.358023: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-15 23:47:27.358074: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-15 23:47:27.358084: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-15 23:47:27.359080: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:86:00.0, compute capability: 6.1)
{'id': 1916, 'batch_size': 128, 'epochs': 78, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/78 [00:00<?, ?epoch/s]2024-02-15 23:47:28.121977: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-15 23:47:28.133714: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2100000000 Hz
2024-02-15 23:47:29.915173: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 23:47:30.172503: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 23:47:31.201285: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-15 23:47:31.250635: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|▏         | 1/78 [00:59<1:16:02, 59.26s/epoch, loss=3.13, accuracy=0.301, val_loss=2.33, val_accuracy=0.269, lr=0.1]  3%|▎         | 2/78 [01:24<49:43, 39.26s/epoch, loss=1.65, accuracy=0.483, val_loss=2.01, val_accuracy=0.369, lr=0.1]    4%|▍         | 3/78 [01:49<40:52, 32.70s/epoch, loss=1.43, accuracy=0.594, val_loss=1.8, val_accuracy=0.485, lr=0.1]   5%|▌         | 4/78 [02:14<36:31, 29.61s/epoch, loss=1.31, accuracy=0.657, val_loss=1.93, val_accuracy=0.514, lr=0.1]  6%|▋         | 5/78 [02:40<34:37, 28.45s/epoch, loss=1.26, accuracy=0.689, val_loss=2.35, val_accuracy=0.427, lr=0.1]  8%|▊         | 6/78 [03:06<32:53, 27.42s/epoch, loss=1.25, accuracy=0.704, val_loss=2.43, val_accuracy=0.398, lr=0.1]  9%|▉         | 7/78 [03:32<31:55, 26.98s/epoch, loss=1.22, accuracy=0.713, val_loss=5.59, val_accuracy=0.255, lr=0.1] 10%|█         | 8/78 [03:58<31:06, 26.66s/epoch, loss=1.22, accuracy=0.721, val_loss=2.06, val_accuracy=0.432, lr=0.0316] 12%|█▏        | 9/78 [04:23<30:18, 26.35s/epoch, loss=1.21, accuracy=0.724, val_loss=3.52, val_accuracy=0.401, lr=0.1]    13%|█▎        | 10/78 [04:49<29:47, 26.28s/epoch, loss=1.2, accuracy=0.729, val_loss=2.24, val_accuracy=0.477, lr=0.1] 14%|█▍        | 11/78 [05:15<29:11, 26.14s/epoch, loss=1.19, accuracy=0.735, val_loss=1.63, val_accuracy=0.584, lr=0.1] 15%|█▌        | 12/78 [05:42<28:47, 26.17s/epoch, loss=1.19, accuracy=0.735, val_loss=3.67, val_accuracy=0.296, lr=0.1] 17%|█▋        | 13/78 [06:07<28:07, 25.96s/epoch, loss=1.19, accuracy=0.736, val_loss=2.11, val_accuracy=0.472, lr=0.1] 18%|█▊        | 14/78 [06:33<27:40, 25.95s/epoch, loss=1.18, accuracy=0.738, val_loss=2.06, val_accuracy=0.428, lr=0.1] 19%|█▉        | 15/78 [06:59<27:21, 26.05s/epoch, loss=1.17, accuracy=0.741, val_loss=2.53, val_accuracy=0.465, lr=0.1] 21%|██        | 16/78 [07:25<26:55, 26.06s/epoch, loss=1.19, accuracy=0.74, val_loss=1.86, val_accuracy=0.55, lr=0.0316] 22%|██▏       | 17/78 [07:51<26:17, 25.87s/epoch, loss=1.17, accuracy=0.745, val_loss=1.76, val_accuracy=0.557, lr=0.1]  23%|██▎       | 18/78 [08:16<25:34, 25.57s/epoch, loss=1.18, accuracy=0.746, val_loss=1.96, val_accuracy=0.527, lr=0.1] 24%|██▍       | 19/78 [08:42<25:20, 25.78s/epoch, loss=1.17, accuracy=0.743, val_loss=1.49, val_accuracy=0.638, lr=0.1] 26%|██▌       | 20/78 [09:07<24:39, 25.50s/epoch, loss=1.16, accuracy=0.747, val_loss=1.47, val_accuracy=0.631, lr=0.1] 27%|██▋       | 21/78 [09:34<24:36, 25.90s/epoch, loss=1.16, accuracy=0.748, val_loss=1.59, val_accuracy=0.588, lr=0.1] 28%|██▊       | 22/78 [09:59<23:59, 25.71s/epoch, loss=1.16, accuracy=0.748, val_loss=1.7, val_accuracy=0.598, lr=0.1]  29%|██▉       | 23/78 [10:24<23:22, 25.49s/epoch, loss=1.16, accuracy=0.747, val_loss=1.73, val_accuracy=0.559, lr=0.1] 31%|███       | 24/78 [10:49<22:50, 25.39s/epoch, loss=1.16, accuracy=0.747, val_loss=2.08, val_accuracy=0.509, lr=0.1] 32%|███▏      | 25/78 [11:15<22:35, 25.58s/epoch, loss=1.17, accuracy=0.747, val_loss=1.44, val_accuracy=0.646, lr=0.1] 33%|███▎      | 26/78 [11:41<22:16, 25.69s/epoch, loss=1.15, accuracy=0.752, val_loss=1.56, val_accuracy=0.613, lr=0.1] 35%|███▍      | 27/78 [12:07<21:55, 25.79s/epoch, loss=1.16, accuracy=0.748, val_loss=2.02, val_accuracy=0.518, lr=0.1] 36%|███▌      | 28/78 [12:32<21:21, 25.63s/epoch, loss=1.15, accuracy=0.751, val_loss=1.62, val_accuracy=0.601, lr=0.1] 37%|███▋      | 29/78 [12:58<20:57, 25.67s/epoch, loss=1.16, accuracy=0.751, val_loss=1.86, val_accuracy=0.516, lr=0.1] 38%|███▊      | 30/78 [13:24<20:40, 25.85s/epoch, loss=1.15, accuracy=0.752, val_loss=2.28, val_accuracy=0.391, lr=0.0316] 40%|███▉      | 31/78 [13:50<20:19, 25.95s/epoch, loss=1.15, accuracy=0.753, val_loss=3.91, val_accuracy=0.238, lr=0.1]    41%|████      | 32/78 [14:16<19:54, 25.96s/epoch, loss=1.15, accuracy=0.753, val_loss=1.93, val_accuracy=0.499, lr=0.1] 42%|████▏     | 33/78 [14:42<19:20, 25.79s/epoch, loss=1.15, accuracy=0.752, val_loss=1.57, val_accuracy=0.611, lr=0.1] 44%|████▎     | 34/78 [15:07<18:44, 25.57s/epoch, loss=1.14, accuracy=0.757, val_loss=2.07, val_accuracy=0.484, lr=0.1] 45%|████▍     | 35/78 [15:32<18:08, 25.32s/epoch, loss=1.14, accuracy=0.752, val_loss=3.1, val_accuracy=0.351, lr=0.0316] 46%|████▌     | 36/78 [15:57<17:51, 25.51s/epoch, loss=1.14, accuracy=0.754, val_loss=1.77, val_accuracy=0.579, lr=0.1]   47%|████▋     | 37/78 [16:24<17:35, 25.75s/epoch, loss=1.14, accuracy=0.755, val_loss=1.82, val_accuracy=0.528, lr=0.1] 49%|████▊     | 38/78 [16:49<17:05, 25.64s/epoch, loss=1.14, accuracy=0.753, val_loss=1.78, val_accuracy=0.533, lr=0.1] 50%|█████     | 39/78 [17:15<16:46, 25.80s/epoch, loss=1.14, accuracy=0.755, val_loss=2.35, val_accuracy=0.316, lr=0.1] 51%|█████▏    | 40/78 [17:41<16:15, 25.67s/epoch, loss=1.14, accuracy=0.753, val_loss=1.67, val_accuracy=0.586, lr=0.0316] 53%|█████▎    | 41/78 [18:07<15:57, 25.89s/epoch, loss=1.14, accuracy=0.754, val_loss=2.52, val_accuracy=0.279, lr=0.1]    54%|█████▍    | 42/78 [18:33<15:36, 26.02s/epoch, loss=1.14, accuracy=0.754, val_loss=2.19, val_accuracy=0.462, lr=0.1] 55%|█████▌    | 43/78 [18:59<15:08, 25.97s/epoch, loss=1.14, accuracy=0.756, val_loss=2.47, val_accuracy=0.366, lr=0.1] 56%|█████▋    | 44/78 [19:25<14:37, 25.81s/epoch, loss=1.14, accuracy=0.756, val_loss=1.73, val_accuracy=0.594, lr=0.1] 58%|█████▊    | 45/78 [19:51<14:12, 25.83s/epoch, loss=1.14, accuracy=0.756, val_loss=1.8, val_accuracy=0.576, lr=0.0316] 59%|█████▉    | 46/78 [20:16<13:45, 25.78s/epoch, loss=1.13, accuracy=0.756, val_loss=2.72, val_accuracy=0.261, lr=0.1]   60%|██████    | 47/78 [20:42<13:15, 25.65s/epoch, loss=1.13, accuracy=0.757, val_loss=1.82, val_accuracy=0.509, lr=0.1] 62%|██████▏   | 48/78 [21:08<12:57, 25.90s/epoch, loss=1.13, accuracy=0.756, val_loss=1.83, val_accuracy=0.54, lr=0.1]  63%|██████▎   | 49/78 [21:33<12:26, 25.74s/epoch, loss=1.13, accuracy=0.756, val_loss=1.76, val_accuracy=0.537, lr=0.1] 64%|██████▍   | 50/78 [21:59<12:02, 25.81s/epoch, loss=1.13, accuracy=0.76, val_loss=2.29, val_accuracy=0.418, lr=0.0316] 65%|██████▌   | 51/78 [22:26<11:40, 25.94s/epoch, loss=1.13, accuracy=0.756, val_loss=2.2, val_accuracy=0.48, lr=0.1]     67%|██████▋   | 52/78 [22:52<11:14, 25.96s/epoch, loss=1.13, accuracy=0.756, val_loss=1.99, val_accuracy=0.549, lr=0.1] 68%|██████▊   | 53/78 [23:16<10:38, 25.56s/epoch, loss=1.13, accuracy=0.757, val_loss=2.2, val_accuracy=0.409, lr=0.1]  69%|██████▉   | 54/78 [23:42<10:17, 25.74s/epoch, loss=1.12, accuracy=0.758, val_loss=4.32, val_accuracy=0.38, lr=0.1] 71%|███████   | 55/78 [24:08<09:52, 25.74s/epoch, loss=1.13, accuracy=0.758, val_loss=1.42, val_accuracy=0.661, lr=0.1] 72%|███████▏  | 56/78 [24:34<09:29, 25.89s/epoch, loss=1.13, accuracy=0.757, val_loss=1.94, val_accuracy=0.522, lr=0.1] 73%|███████▎  | 57/78 [25:01<09:07, 26.09s/epoch, loss=1.12, accuracy=0.755, val_loss=2.28, val_accuracy=0.45, lr=0.1]  74%|███████▍  | 58/78 [25:27<08:41, 26.06s/epoch, loss=1.13, accuracy=0.754, val_loss=1.58, val_accuracy=0.61, lr=0.1] 76%|███████▌  | 59/78 [25:53<08:12, 25.90s/epoch, loss=1.12, accuracy=0.76, val_loss=1.59, val_accuracy=0.598, lr=0.1] 77%|███████▋  | 60/78 [26:18<07:43, 25.77s/epoch, loss=1.12, accuracy=0.757, val_loss=7.09, val_accuracy=0.16, lr=0.0316] 78%|███████▊  | 61/78 [26:44<07:19, 25.88s/epoch, loss=1.12, accuracy=0.755, val_loss=1.63, val_accuracy=0.592, lr=0.1]   79%|███████▉  | 62/78 [27:10<06:52, 25.80s/epoch, loss=1.12, accuracy=0.758, val_loss=1.53, val_accuracy=0.635, lr=0.1] 81%|████████  | 63/78 [27:36<06:27, 25.81s/epoch, loss=1.12, accuracy=0.755, val_loss=1.94, val_accuracy=0.508, lr=0.1] 82%|████████▏ | 64/78 [28:02<06:03, 25.94s/epoch, loss=1.12, accuracy=0.758, val_loss=4.38, val_accuracy=0.312, lr=0.1] 83%|████████▎ | 65/78 [28:28<05:36, 25.88s/epoch, loss=1.12, accuracy=0.757, val_loss=1.39, val_accuracy=0.661, lr=0.1] 85%|████████▍ | 66/78 [28:53<05:09, 25.78s/epoch, loss=1.12, accuracy=0.758, val_loss=2.37, val_accuracy=0.416, lr=0.1] 86%|████████▌ | 67/78 [29:18<04:41, 25.58s/epoch, loss=1.12, accuracy=0.758, val_loss=1.63, val_accuracy=0.585, lr=0.1] 87%|████████▋ | 68/78 [29:43<04:13, 25.38s/epoch, loss=1.11, accuracy=0.76, val_loss=2.11, val_accuracy=0.432, lr=0.1]  88%|████████▊ | 69/78 [30:08<03:47, 25.30s/epoch, loss=1.12, accuracy=0.757, val_loss=3.19, val_accuracy=0.241, lr=0.1] 90%|████████▉ | 70/78 [30:33<03:22, 25.28s/epoch, loss=1.12, accuracy=0.757, val_loss=1.47, val_accuracy=0.656, lr=0.0316] 91%|█████████ | 71/78 [30:59<02:57, 25.30s/epoch, loss=1.12, accuracy=0.758, val_loss=2, val_accuracy=0.499, lr=0.1]       92%|█████████▏| 72/78 [31:24<02:32, 25.34s/epoch, loss=1.12, accuracy=0.756, val_loss=1.96, val_accuracy=0.484, lr=0.1] 94%|█████████▎| 73/78 [31:50<02:06, 25.37s/epoch, loss=1.12, accuracy=0.755, val_loss=2.65, val_accuracy=0.455, lr=0.1] 95%|█████████▍| 74/78 [32:15<01:41, 25.49s/epoch, loss=1.11, accuracy=0.759, val_loss=2.22, val_accuracy=0.409, lr=0.1] 96%|█████████▌| 75/78 [32:41<01:16, 25.38s/epoch, loss=1.13, accuracy=0.757, val_loss=1.83, val_accuracy=0.557, lr=0.0316] 97%|█████████▋| 76/78 [33:07<00:51, 25.60s/epoch, loss=1.11, accuracy=0.76, val_loss=2, val_accuracy=0.522, lr=0.1]        99%|█████████▊| 77/78 [33:32<00:25, 25.44s/epoch, loss=1.12, accuracy=0.756, val_loss=1.67, val_accuracy=0.572, lr=0.1]100%|██████████| 78/78 [33:58<00:00, 25.52s/epoch, loss=1.12, accuracy=0.756, val_loss=1.65, val_accuracy=0.599, lr=0.1]100%|██████████| 78/78 [33:58<00:00, 26.13s/epoch, loss=1.12, accuracy=0.756, val_loss=1.65, val_accuracy=0.599, lr=0.1]
Using real-time data augmentation.
Test loss: 1.6493054628372192
Test accuracy: 0.5985999703407288


* * * Run SGD for ID = 19_17. * * *


2024-02-16 00:21:28.862707: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-16 00:21:31.515377: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-16 00:21:31.516698: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-16 00:21:31.557320: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:86:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-16 00:21:31.557364: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-16 00:21:31.560697: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-16 00:21:31.560764: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-16 00:21:31.562999: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-16 00:21:31.563626: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-16 00:21:31.566239: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-16 00:21:31.567818: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-16 00:21:31.576521: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-16 00:21:31.577948: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-16 00:21:31.578346: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-16 00:21:32.808198: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-16 00:21:32.809197: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-16 00:21:32.809737: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:86:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-16 00:21:32.809776: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-16 00:21:32.809841: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-16 00:21:32.809860: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-16 00:21:32.809880: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-16 00:21:32.809899: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-16 00:21:32.809926: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-16 00:21:32.809944: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-16 00:21:32.809963: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-16 00:21:32.810522: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-16 00:21:32.810572: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-16 00:21:33.465866: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-16 00:21:33.465925: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-16 00:21:33.465937: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-16 00:21:33.467049: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:86:00.0, compute capability: 6.1)
{'id': 1917, 'batch_size': 128, 'epochs': 78, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/78 [00:00<?, ?epoch/s]2024-02-16 00:21:34.246743: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-16 00:21:34.258723: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2100000000 Hz
2024-02-16 00:21:36.103844: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-16 00:21:36.383241: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-16 00:21:37.346357: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-16 00:21:37.394047: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|▏         | 1/78 [00:58<1:14:36, 58.13s/epoch, loss=3.68, accuracy=0.286, val_loss=2.25, val_accuracy=0.293, lr=0.1]  3%|▎         | 2/78 [01:23<49:08, 38.80s/epoch, loss=1.64, accuracy=0.498, val_loss=1.88, val_accuracy=0.423, lr=0.1]    4%|▍         | 3/78 [01:49<41:01, 32.82s/epoch, loss=1.37, accuracy=0.62, val_loss=4.73, val_accuracy=0.201, lr=0.1]   5%|▌         | 4/78 [02:14<37:02, 30.04s/epoch, loss=1.27, accuracy=0.675, val_loss=2.45, val_accuracy=0.351, lr=0.1]  6%|▋         | 5/78 [02:41<34:52, 28.66s/epoch, loss=1.24, accuracy=0.697, val_loss=1.96, val_accuracy=0.53, lr=0.1]   8%|▊         | 6/78 [03:05<32:49, 27.36s/epoch, loss=1.23, accuracy=0.707, val_loss=3.99, val_accuracy=0.316, lr=0.1]  9%|▉         | 7/78 [03:31<31:35, 26.69s/epoch, loss=1.22, accuracy=0.716, val_loss=2.61, val_accuracy=0.411, lr=0.0316] 10%|█         | 8/78 [03:55<30:25, 26.07s/epoch, loss=1.2, accuracy=0.723, val_loss=1.88, val_accuracy=0.515, lr=0.1]     12%|█▏        | 9/78 [04:20<29:28, 25.63s/epoch, loss=1.19, accuracy=0.729, val_loss=1.94, val_accuracy=0.488, lr=0.1] 13%|█▎        | 10/78 [04:45<28:45, 25.38s/epoch, loss=1.19, accuracy=0.729, val_loss=1.79, val_accuracy=0.537, lr=0.1] 14%|█▍        | 11/78 [05:11<28:30, 25.52s/epoch, loss=1.19, accuracy=0.732, val_loss=1.49, val_accuracy=0.618, lr=0.1] 15%|█▌        | 12/78 [05:36<28:06, 25.55s/epoch, loss=1.18, accuracy=0.735, val_loss=2.23, val_accuracy=0.399, lr=0.1] 17%|█▋        | 13/78 [06:02<27:33, 25.43s/epoch, loss=1.18, accuracy=0.738, val_loss=3, val_accuracy=0.453, lr=0.1]    18%|█▊        | 14/78 [06:26<26:53, 25.21s/epoch, loss=1.19, accuracy=0.736, val_loss=1.65, val_accuracy=0.585, lr=0.1] 19%|█▉        | 15/78 [06:52<26:35, 25.33s/epoch, loss=1.18, accuracy=0.737, val_loss=1.69, val_accuracy=0.551, lr=0.1] 21%|██        | 16/78 [07:17<26:13, 25.38s/epoch, loss=1.18, accuracy=0.739, val_loss=2.35, val_accuracy=0.458, lr=0.0316] 22%|██▏       | 17/78 [07:43<25:46, 25.36s/epoch, loss=1.16, accuracy=0.744, val_loss=2.69, val_accuracy=0.326, lr=0.1]    23%|██▎       | 18/78 [08:08<25:29, 25.49s/epoch, loss=1.16, accuracy=0.743, val_loss=1.69, val_accuracy=0.577, lr=0.1] 24%|██▍       | 19/78 [08:34<24:58, 25.39s/epoch, loss=1.16, accuracy=0.742, val_loss=1.55, val_accuracy=0.609, lr=0.1] 26%|██▌       | 20/78 [08:59<24:34, 25.43s/epoch, loss=1.16, accuracy=0.742, val_loss=2.04, val_accuracy=0.457, lr=0.1] 27%|██▋       | 21/78 [09:24<24:03, 25.32s/epoch, loss=1.16, accuracy=0.745, val_loss=1.73, val_accuracy=0.539, lr=0.0316] 28%|██▊       | 22/78 [09:49<23:36, 25.30s/epoch, loss=1.16, accuracy=0.745, val_loss=1.92, val_accuracy=0.548, lr=0.1]    29%|██▉       | 23/78 [10:14<23:04, 25.18s/epoch, loss=1.16, accuracy=0.744, val_loss=2.72, val_accuracy=0.391, lr=0.1] 31%|███       | 24/78 [10:40<22:43, 25.24s/epoch, loss=1.16, accuracy=0.744, val_loss=2.67, val_accuracy=0.394, lr=0.1] 32%|███▏      | 25/78 [11:05<22:11, 25.13s/epoch, loss=1.16, accuracy=0.745, val_loss=2.34, val_accuracy=0.492, lr=0.1] 33%|███▎      | 26/78 [11:30<21:53, 25.26s/epoch, loss=1.15, accuracy=0.752, val_loss=1.76, val_accuracy=0.58, lr=0.0316] 35%|███▍      | 27/78 [11:56<21:37, 25.45s/epoch, loss=1.15, accuracy=0.746, val_loss=1.46, val_accuracy=0.636, lr=0.1]   36%|███▌      | 28/78 [12:22<21:20, 25.62s/epoch, loss=1.14, accuracy=0.75, val_loss=2.02, val_accuracy=0.476, lr=0.1]  37%|███▋      | 29/78 [12:47<20:50, 25.51s/epoch, loss=1.15, accuracy=0.751, val_loss=1.42, val_accuracy=0.653, lr=0.1] 38%|███▊      | 30/78 [13:13<20:19, 25.42s/epoch, loss=1.14, accuracy=0.752, val_loss=1.84, val_accuracy=0.578, lr=0.1] 40%|███▉      | 31/78 [13:39<20:03, 25.62s/epoch, loss=1.15, accuracy=0.749, val_loss=3.35, val_accuracy=0.299, lr=0.1] 41%|████      | 32/78 [14:04<19:33, 25.51s/epoch, loss=1.14, accuracy=0.751, val_loss=2.34, val_accuracy=0.426, lr=0.1] 42%|████▏     | 33/78 [14:29<19:06, 25.49s/epoch, loss=1.14, accuracy=0.751, val_loss=2.92, val_accuracy=0.357, lr=0.1] 44%|████▎     | 34/78 [14:55<18:41, 25.48s/epoch, loss=1.15, accuracy=0.749, val_loss=2.15, val_accuracy=0.486, lr=0.0316] 45%|████▍     | 35/78 [15:20<18:15, 25.47s/epoch, loss=1.14, accuracy=0.752, val_loss=2, val_accuracy=0.448, lr=0.1]       46%|████▌     | 36/78 [15:46<17:54, 25.59s/epoch, loss=1.14, accuracy=0.752, val_loss=1.74, val_accuracy=0.57, lr=0.1] 47%|████▋     | 37/78 [16:11<17:20, 25.38s/epoch, loss=1.14, accuracy=0.753, val_loss=1.92, val_accuracy=0.516, lr=0.1] 49%|████▊     | 38/78 [16:37<16:59, 25.48s/epoch, loss=1.14, accuracy=0.751, val_loss=1.56, val_accuracy=0.606, lr=0.1] 50%|█████     | 39/78 [17:01<16:17, 25.07s/epoch, loss=1.13, accuracy=0.754, val_loss=1.65, val_accuracy=0.597, lr=0.0316] 51%|█████▏    | 40/78 [17:26<15:55, 25.14s/epoch, loss=1.13, accuracy=0.754, val_loss=1.87, val_accuracy=0.515, lr=0.1]    53%|█████▎    | 41/78 [17:52<15:39, 25.40s/epoch, loss=1.14, accuracy=0.749, val_loss=2.17, val_accuracy=0.511, lr=0.1] 54%|█████▍    | 42/78 [18:18<15:20, 25.57s/epoch, loss=1.13, accuracy=0.751, val_loss=2.35, val_accuracy=0.432, lr=0.1] 55%|█████▌    | 43/78 [18:43<14:44, 25.26s/epoch, loss=1.14, accuracy=0.751, val_loss=2.61, val_accuracy=0.368, lr=0.1] 56%|█████▋    | 44/78 [19:09<14:30, 25.60s/epoch, loss=1.13, accuracy=0.753, val_loss=2.06, val_accuracy=0.559, lr=0.0316] 58%|█████▊    | 45/78 [19:35<14:07, 25.67s/epoch, loss=1.12, accuracy=0.755, val_loss=1.47, val_accuracy=0.637, lr=0.1]    59%|█████▉    | 46/78 [20:00<13:31, 25.37s/epoch, loss=1.12, accuracy=0.756, val_loss=2.03, val_accuracy=0.462, lr=0.1] 60%|██████    | 47/78 [20:25<13:08, 25.43s/epoch, loss=1.13, accuracy=0.757, val_loss=1.65, val_accuracy=0.591, lr=0.1] 62%|██████▏   | 48/78 [20:50<12:38, 25.29s/epoch, loss=1.12, accuracy=0.754, val_loss=2.92, val_accuracy=0.372, lr=0.1] 63%|██████▎   | 49/78 [21:15<12:11, 25.24s/epoch, loss=1.12, accuracy=0.757, val_loss=1.99, val_accuracy=0.431, lr=0.0316] 64%|██████▍   | 50/78 [21:41<11:48, 25.29s/epoch, loss=1.12, accuracy=0.756, val_loss=2.11, val_accuracy=0.454, lr=0.1]    65%|██████▌   | 51/78 [22:06<11:25, 25.38s/epoch, loss=1.12, accuracy=0.754, val_loss=1.92, val_accuracy=0.493, lr=0.1] 67%|██████▋   | 52/78 [22:32<11:00, 25.40s/epoch, loss=1.12, accuracy=0.756, val_loss=1.49, val_accuracy=0.642, lr=0.1] 68%|██████▊   | 53/78 [22:58<10:39, 25.56s/epoch, loss=1.11, accuracy=0.756, val_loss=2.23, val_accuracy=0.448, lr=0.1] 69%|██████▉   | 54/78 [23:22<10:08, 25.36s/epoch, loss=1.13, accuracy=0.755, val_loss=1.87, val_accuracy=0.571, lr=0.0316] 71%|███████   | 55/78 [23:48<09:40, 25.26s/epoch, loss=1.12, accuracy=0.755, val_loss=1.83, val_accuracy=0.506, lr=0.1]    72%|███████▏  | 56/78 [24:12<09:12, 25.12s/epoch, loss=1.11, accuracy=0.755, val_loss=2.42, val_accuracy=0.468, lr=0.1] 73%|███████▎  | 57/78 [24:38<08:48, 25.18s/epoch, loss=1.12, accuracy=0.756, val_loss=2.22, val_accuracy=0.426, lr=0.1] 74%|███████▍  | 58/78 [25:02<08:18, 24.90s/epoch, loss=1.12, accuracy=0.753, val_loss=3.42, val_accuracy=0.382, lr=0.1] 76%|███████▌  | 59/78 [25:27<07:53, 24.90s/epoch, loss=1.12, accuracy=0.755, val_loss=2.34, val_accuracy=0.504, lr=0.0316] 77%|███████▋  | 60/78 [25:52<07:30, 25.00s/epoch, loss=1.12, accuracy=0.757, val_loss=2.02, val_accuracy=0.517, lr=0.1]    78%|███████▊  | 61/78 [26:17<07:04, 24.94s/epoch, loss=1.11, accuracy=0.758, val_loss=1.92, val_accuracy=0.504, lr=0.1] 79%|███████▉  | 62/78 [26:42<06:39, 25.00s/epoch, loss=1.11, accuracy=0.758, val_loss=2.27, val_accuracy=0.433, lr=0.1] 81%|████████  | 63/78 [27:07<06:17, 25.16s/epoch, loss=1.11, accuracy=0.759, val_loss=1.64, val_accuracy=0.602, lr=0.1] 82%|████████▏ | 64/78 [27:34<05:56, 25.47s/epoch, loss=1.12, accuracy=0.755, val_loss=2.95, val_accuracy=0.316, lr=0.0316] 83%|████████▎ | 65/78 [27:59<05:28, 25.30s/epoch, loss=1.11, accuracy=0.758, val_loss=3.63, val_accuracy=0.255, lr=0.1]    85%|████████▍ | 66/78 [28:24<05:03, 25.32s/epoch, loss=1.11, accuracy=0.758, val_loss=1.89, val_accuracy=0.495, lr=0.1] 86%|████████▌ | 67/78 [28:49<04:38, 25.36s/epoch, loss=1.11, accuracy=0.76, val_loss=3.65, val_accuracy=0.361, lr=0.1]  87%|████████▋ | 68/78 [29:14<04:11, 25.17s/epoch, loss=1.11, accuracy=0.757, val_loss=1.72, val_accuracy=0.555, lr=0.1] 88%|████████▊ | 69/78 [29:40<03:47, 25.27s/epoch, loss=1.11, accuracy=0.758, val_loss=2.31, val_accuracy=0.324, lr=0.0316] 90%|████████▉ | 70/78 [30:05<03:21, 25.16s/epoch, loss=1.12, accuracy=0.758, val_loss=1.93, val_accuracy=0.561, lr=0.1]    91%|█████████ | 71/78 [30:30<02:56, 25.16s/epoch, loss=1.12, accuracy=0.756, val_loss=4.05, val_accuracy=0.235, lr=0.1] 92%|█████████▏| 72/78 [30:54<02:29, 24.96s/epoch, loss=1.11, accuracy=0.758, val_loss=2.53, val_accuracy=0.459, lr=0.1] 94%|█████████▎| 73/78 [31:20<02:06, 25.23s/epoch, loss=1.11, accuracy=0.759, val_loss=1.69, val_accuracy=0.567, lr=0.1] 95%|█████████▍| 74/78 [31:46<01:41, 25.32s/epoch, loss=1.11, accuracy=0.757, val_loss=1.94, val_accuracy=0.526, lr=0.0316] 96%|█████████▌| 75/78 [32:11<01:16, 25.38s/epoch, loss=1.11, accuracy=0.759, val_loss=1.51, val_accuracy=0.621, lr=0.1]    97%|█████████▋| 76/78 [32:36<00:50, 25.29s/epoch, loss=1.11, accuracy=0.758, val_loss=2.19, val_accuracy=0.439, lr=0.1] 99%|█████████▊| 77/78 [33:01<00:25, 25.22s/epoch, loss=1.11, accuracy=0.757, val_loss=2.61, val_accuracy=0.441, lr=0.1]100%|██████████| 78/78 [33:26<00:00, 25.12s/epoch, loss=1.11, accuracy=0.757, val_loss=3.16, val_accuracy=0.321, lr=0.1]100%|██████████| 78/78 [33:26<00:00, 25.73s/epoch, loss=1.11, accuracy=0.757, val_loss=3.16, val_accuracy=0.321, lr=0.1]
Using real-time data augmentation.
Test loss: 3.156689167022705
Test accuracy: 0.3206000030040741


* * * Run SGD for ID = 19_18. * * *


2024-02-16 00:55:03.658398: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-16 00:55:06.365613: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-16 00:55:06.366859: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-16 00:55:06.413496: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:86:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-16 00:55:06.413534: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-16 00:55:06.416913: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-16 00:55:06.416981: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-16 00:55:06.419394: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-16 00:55:06.420151: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-16 00:55:06.422751: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-16 00:55:06.424392: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-16 00:55:06.429507: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-16 00:55:06.430139: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-16 00:55:06.430498: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-16 00:55:07.580170: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-16 00:55:07.580802: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-16 00:55:07.581344: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:86:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-16 00:55:07.581390: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-16 00:55:07.581429: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-16 00:55:07.581446: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-16 00:55:07.581462: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-16 00:55:07.581479: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-16 00:55:07.581495: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-16 00:55:07.581511: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-16 00:55:07.581528: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-16 00:55:07.582157: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-16 00:55:07.582205: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-16 00:55:08.204239: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-16 00:55:08.204290: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-16 00:55:08.204300: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-16 00:55:08.205376: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:86:00.0, compute capability: 6.1)
{'id': 1918, 'batch_size': 128, 'epochs': 78, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/78 [00:00<?, ?epoch/s]2024-02-16 00:55:08.937798: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-16 00:55:08.949758: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2100000000 Hz
2024-02-16 00:55:10.847551: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-16 00:55:11.093959: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-16 00:55:12.190717: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-16 00:55:12.256352: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|▏         | 1/78 [00:58<1:14:37, 58.14s/epoch, loss=3.38, accuracy=0.242, val_loss=2.81, val_accuracy=0.219, lr=0.1]  3%|▎         | 2/78 [01:24<49:38, 39.19s/epoch, loss=1.71, accuracy=0.451, val_loss=2, val_accuracy=0.372, lr=0.1]       4%|▍         | 3/78 [01:49<41:23, 33.12s/epoch, loss=1.48, accuracy=0.565, val_loss=2.01, val_accuracy=0.42, lr=0.1]  5%|▌         | 4/78 [02:15<36:55, 29.94s/epoch, loss=1.35, accuracy=0.643, val_loss=1.65, val_accuracy=0.551, lr=0.1]  6%|▋         | 5/78 [02:39<34:14, 28.14s/epoch, loss=1.29, accuracy=0.679, val_loss=3.19, val_accuracy=0.245, lr=0.1]  8%|▊         | 6/78 [03:06<32:55, 27.43s/epoch, loss=1.27, accuracy=0.697, val_loss=2.54, val_accuracy=0.324, lr=0.1]  9%|▉         | 7/78 [03:31<31:31, 26.64s/epoch, loss=1.25, accuracy=0.706, val_loss=2.08, val_accuracy=0.423, lr=0.1] 10%|█         | 8/78 [03:55<30:23, 26.04s/epoch, loss=1.24, accuracy=0.713, val_loss=1.87, val_accuracy=0.578, lr=0.1] 12%|█▏        | 9/78 [04:21<29:38, 25.78s/epoch, loss=1.23, accuracy=0.721, val_loss=2.16, val_accuracy=0.452, lr=0.0316] 13%|█▎        | 10/78 [04:46<29:12, 25.78s/epoch, loss=1.23, accuracy=0.723, val_loss=2.09, val_accuracy=0.48, lr=0.1]    14%|█▍        | 11/78 [05:12<28:53, 25.87s/epoch, loss=1.22, accuracy=0.728, val_loss=2.15, val_accuracy=0.5, lr=0.1]  15%|█▌        | 12/78 [05:38<28:13, 25.66s/epoch, loss=1.21, accuracy=0.731, val_loss=2.86, val_accuracy=0.325, lr=0.1] 17%|█▋        | 13/78 [06:03<27:38, 25.52s/epoch, loss=1.21, accuracy=0.734, val_loss=1.67, val_accuracy=0.552, lr=0.1] 18%|█▊        | 14/78 [06:28<27:09, 25.46s/epoch, loss=1.21, accuracy=0.734, val_loss=1.64, val_accuracy=0.606, lr=0.1] 19%|█▉        | 15/78 [06:53<26:34, 25.31s/epoch, loss=1.2, accuracy=0.735, val_loss=2.12, val_accuracy=0.489, lr=0.1]  21%|██        | 16/78 [07:19<26:21, 25.51s/epoch, loss=1.2, accuracy=0.739, val_loss=2.13, val_accuracy=0.466, lr=0.1] 22%|██▏       | 17/78 [07:44<25:51, 25.44s/epoch, loss=1.19, accuracy=0.741, val_loss=2.04, val_accuracy=0.52, lr=0.1] 23%|██▎       | 18/78 [08:10<25:25, 25.42s/epoch, loss=1.19, accuracy=0.739, val_loss=2.02, val_accuracy=0.545, lr=0.1] 24%|██▍       | 19/78 [08:36<25:08, 25.57s/epoch, loss=1.19, accuracy=0.743, val_loss=2.08, val_accuracy=0.458, lr=0.0316] 26%|██▌       | 20/78 [09:01<24:45, 25.62s/epoch, loss=1.19, accuracy=0.74, val_loss=1.98, val_accuracy=0.494, lr=0.1]     27%|██▋       | 21/78 [09:27<24:28, 25.77s/epoch, loss=1.19, accuracy=0.743, val_loss=3.08, val_accuracy=0.389, lr=0.1] 28%|██▊       | 22/78 [09:54<24:16, 26.01s/epoch, loss=1.19, accuracy=0.742, val_loss=1.61, val_accuracy=0.612, lr=0.1] 29%|██▉       | 23/78 [10:19<23:38, 25.80s/epoch, loss=1.18, accuracy=0.745, val_loss=1.7, val_accuracy=0.597, lr=0.1]  31%|███       | 24/78 [10:45<23:13, 25.80s/epoch, loss=1.18, accuracy=0.742, val_loss=2.44, val_accuracy=0.474, lr=0.1] 32%|███▏      | 25/78 [11:11<22:49, 25.85s/epoch, loss=1.18, accuracy=0.744, val_loss=1.58, val_accuracy=0.607, lr=0.1] 33%|███▎      | 26/78 [11:37<22:19, 25.76s/epoch, loss=1.18, accuracy=0.745, val_loss=3.01, val_accuracy=0.361, lr=0.1] 35%|███▍      | 27/78 [12:01<21:37, 25.43s/epoch, loss=1.17, accuracy=0.745, val_loss=2.21, val_accuracy=0.414, lr=0.1] 36%|███▌      | 28/78 [12:26<21:06, 25.33s/epoch, loss=1.17, accuracy=0.745, val_loss=1.67, val_accuracy=0.606, lr=0.1] 37%|███▋      | 29/78 [12:52<20:51, 25.55s/epoch, loss=1.17, accuracy=0.746, val_loss=1.67, val_accuracy=0.587, lr=0.1] 38%|███▊      | 30/78 [13:18<20:28, 25.59s/epoch, loss=1.17, accuracy=0.749, val_loss=1.72, val_accuracy=0.563, lr=0.0316] 40%|███▉      | 31/78 [13:44<20:02, 25.59s/epoch, loss=1.17, accuracy=0.751, val_loss=2.41, val_accuracy=0.485, lr=0.1]    41%|████      | 32/78 [14:09<19:35, 25.56s/epoch, loss=1.17, accuracy=0.747, val_loss=1.82, val_accuracy=0.515, lr=0.1] 42%|████▏     | 33/78 [14:35<19:10, 25.57s/epoch, loss=1.16, accuracy=0.749, val_loss=1.56, val_accuracy=0.609, lr=0.1] 44%|████▎     | 34/78 [15:01<18:52, 25.74s/epoch, loss=1.17, accuracy=0.747, val_loss=1.63, val_accuracy=0.596, lr=0.1] 45%|████▍     | 35/78 [15:26<18:22, 25.65s/epoch, loss=1.16, accuracy=0.75, val_loss=2.23, val_accuracy=0.423, lr=0.1]  46%|████▌     | 36/78 [15:52<17:51, 25.50s/epoch, loss=1.16, accuracy=0.751, val_loss=1.96, val_accuracy=0.484, lr=0.1] 47%|████▋     | 37/78 [16:18<17:32, 25.66s/epoch, loss=1.16, accuracy=0.751, val_loss=1.43, val_accuracy=0.642, lr=0.1] 49%|████▊     | 38/78 [16:43<17:09, 25.73s/epoch, loss=1.16, accuracy=0.752, val_loss=1.79, val_accuracy=0.549, lr=0.1] 50%|█████     | 39/78 [17:09<16:43, 25.73s/epoch, loss=1.16, accuracy=0.75, val_loss=1.8, val_accuracy=0.567, lr=0.1]   51%|█████▏    | 40/78 [17:35<16:22, 25.86s/epoch, loss=1.15, accuracy=0.752, val_loss=2.41, val_accuracy=0.382, lr=0.1] 53%|█████▎    | 41/78 [18:01<15:56, 25.84s/epoch, loss=1.15, accuracy=0.753, val_loss=1.75, val_accuracy=0.566, lr=0.1] 54%|█████▍    | 42/78 [18:26<15:22, 25.63s/epoch, loss=1.16, accuracy=0.752, val_loss=1.66, val_accuracy=0.59, lr=0.0316] 55%|█████▌    | 43/78 [18:52<14:54, 25.56s/epoch, loss=1.16, accuracy=0.752, val_loss=1.38, val_accuracy=0.683, lr=0.1]   56%|█████▋    | 44/78 [19:17<14:23, 25.40s/epoch, loss=1.15, accuracy=0.753, val_loss=2.37, val_accuracy=0.451, lr=0.1] 58%|█████▊    | 45/78 [19:43<14:04, 25.60s/epoch, loss=1.15, accuracy=0.753, val_loss=1.39, val_accuracy=0.677, lr=0.1] 59%|█████▉    | 46/78 [20:09<13:47, 25.86s/epoch, loss=1.15, accuracy=0.754, val_loss=2.52, val_accuracy=0.451, lr=0.1] 60%|██████    | 47/78 [20:35<13:20, 25.82s/epoch, loss=1.15, accuracy=0.754, val_loss=3.21, val_accuracy=0.31, lr=0.1]  62%|██████▏   | 48/78 [21:01<12:54, 25.80s/epoch, loss=1.15, accuracy=0.756, val_loss=2.38, val_accuracy=0.397, lr=0.0316] 63%|██████▎   | 49/78 [21:26<12:26, 25.73s/epoch, loss=1.15, accuracy=0.75, val_loss=2.61, val_accuracy=0.37, lr=0.1]      64%|██████▍   | 50/78 [21:52<11:58, 25.65s/epoch, loss=1.14, accuracy=0.753, val_loss=2.04, val_accuracy=0.504, lr=0.1] 65%|██████▌   | 51/78 [22:17<11:29, 25.55s/epoch, loss=1.14, accuracy=0.754, val_loss=1.75, val_accuracy=0.548, lr=0.1] 67%|██████▋   | 52/78 [22:43<11:08, 25.70s/epoch, loss=1.14, accuracy=0.753, val_loss=5.64, val_accuracy=0.217, lr=0.1] 68%|██████▊   | 53/78 [23:08<10:36, 25.47s/epoch, loss=1.14, accuracy=0.755, val_loss=1.5, val_accuracy=0.647, lr=0.0316] 69%|██████▉   | 54/78 [23:34<10:11, 25.48s/epoch, loss=1.14, accuracy=0.754, val_loss=2.58, val_accuracy=0.39, lr=0.1]    71%|███████   | 55/78 [24:00<09:49, 25.63s/epoch, loss=1.14, accuracy=0.755, val_loss=2.14, val_accuracy=0.375, lr=0.1] 72%|███████▏  | 56/78 [24:25<09:24, 25.66s/epoch, loss=1.14, accuracy=0.755, val_loss=1.66, val_accuracy=0.574, lr=0.1] 73%|███████▎  | 57/78 [24:51<08:59, 25.70s/epoch, loss=1.13, accuracy=0.757, val_loss=2.05, val_accuracy=0.52, lr=0.1]  74%|███████▍  | 58/78 [25:17<08:33, 25.70s/epoch, loss=1.14, accuracy=0.755, val_loss=1.48, val_accuracy=0.63, lr=0.0316] 76%|███████▌  | 59/78 [25:43<08:09, 25.77s/epoch, loss=1.13, accuracy=0.755, val_loss=2.46, val_accuracy=0.391, lr=0.1]   77%|███████▋  | 60/78 [26:09<07:44, 25.82s/epoch, loss=1.14, accuracy=0.756, val_loss=2.05, val_accuracy=0.5, lr=0.1]   78%|███████▊  | 61/78 [26:34<07:17, 25.75s/epoch, loss=1.13, accuracy=0.759, val_loss=1.89, val_accuracy=0.493, lr=0.1] 79%|███████▉  | 62/78 [27:01<06:55, 25.96s/epoch, loss=1.13, accuracy=0.758, val_loss=1.82, val_accuracy=0.548, lr=0.1] 81%|████████  | 63/78 [27:26<06:27, 25.81s/epoch, loss=1.13, accuracy=0.756, val_loss=1.62, val_accuracy=0.608, lr=0.0316] 82%|████████▏ | 64/78 [27:52<06:02, 25.90s/epoch, loss=1.13, accuracy=0.757, val_loss=2.64, val_accuracy=0.435, lr=0.1]    83%|████████▎ | 65/78 [28:18<05:35, 25.83s/epoch, loss=1.14, accuracy=0.757, val_loss=2.15, val_accuracy=0.47, lr=0.1]  85%|████████▍ | 66/78 [28:43<05:08, 25.71s/epoch, loss=1.13, accuracy=0.757, val_loss=1.9, val_accuracy=0.525, lr=0.1] 86%|████████▌ | 67/78 [29:09<04:41, 25.61s/epoch, loss=1.12, accuracy=0.758, val_loss=1.74, val_accuracy=0.603, lr=0.1] 87%|████████▋ | 68/78 [29:33<04:13, 25.35s/epoch, loss=1.13, accuracy=0.755, val_loss=2.12, val_accuracy=0.459, lr=0.0316] 88%|████████▊ | 69/78 [29:58<03:47, 25.23s/epoch, loss=1.12, accuracy=0.757, val_loss=3.11, val_accuracy=0.195, lr=0.1]    90%|████████▉ | 70/78 [30:24<03:23, 25.38s/epoch, loss=1.12, accuracy=0.758, val_loss=1.9, val_accuracy=0.49, lr=0.1]   91%|█████████ | 71/78 [30:50<02:58, 25.55s/epoch, loss=1.13, accuracy=0.757, val_loss=2.04, val_accuracy=0.567, lr=0.1] 92%|█████████▏| 72/78 [31:15<02:32, 25.47s/epoch, loss=1.12, accuracy=0.757, val_loss=1.31, val_accuracy=0.694, lr=0.1] 94%|█████████▎| 73/78 [31:40<02:06, 25.36s/epoch, loss=1.13, accuracy=0.755, val_loss=2.2, val_accuracy=0.424, lr=0.1]  95%|█████████▍| 74/78 [32:06<01:42, 25.52s/epoch, loss=1.12, accuracy=0.759, val_loss=2.33, val_accuracy=0.35, lr=0.1] 96%|█████████▌| 75/78 [32:32<01:16, 25.49s/epoch, loss=1.11, accuracy=0.757, val_loss=3, val_accuracy=0.442, lr=0.1]   97%|█████████▋| 76/78 [32:57<00:50, 25.37s/epoch, loss=1.12, accuracy=0.757, val_loss=1.53, val_accuracy=0.616, lr=0.1] 99%|█████████▊| 77/78 [33:22<00:25, 25.43s/epoch, loss=1.12, accuracy=0.756, val_loss=2.92, val_accuracy=0.461, lr=0.0316]100%|██████████| 78/78 [33:48<00:00, 25.35s/epoch, loss=1.11, accuracy=0.76, val_loss=1.36, val_accuracy=0.687, lr=0.1]    100%|██████████| 78/78 [33:48<00:00, 26.00s/epoch, loss=1.11, accuracy=0.76, val_loss=1.36, val_accuracy=0.687, lr=0.1]
Using real-time data augmentation.
Test loss: 1.3593231439590454
Test accuracy: 0.6866999864578247


* * * Run SGD for ID = 19_19. * * *


2024-02-16 01:28:59.763221: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-16 01:29:04.865842: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-16 01:29:04.867074: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-16 01:29:04.919380: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:86:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-16 01:29:04.919425: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-16 01:29:04.923317: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-16 01:29:04.923384: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-16 01:29:04.925853: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-16 01:29:04.926908: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-16 01:29:04.929626: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-16 01:29:04.931521: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-16 01:29:04.936818: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-16 01:29:04.937476: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-16 01:29:04.937877: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-16 01:29:06.145041: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-16 01:29:06.145627: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-16 01:29:06.146132: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:86:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-16 01:29:06.146166: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-16 01:29:06.146203: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-16 01:29:06.146218: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-16 01:29:06.146233: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-16 01:29:06.146248: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-16 01:29:06.146262: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-16 01:29:06.146277: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-16 01:29:06.146292: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-16 01:29:06.146857: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-16 01:29:06.146891: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-16 01:29:06.787248: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-16 01:29:06.787298: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-16 01:29:06.787308: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-16 01:29:06.788386: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:86:00.0, compute capability: 6.1)
{'id': 1919, 'batch_size': 128, 'epochs': 78, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/78 [00:00<?, ?epoch/s]2024-02-16 01:29:07.560953: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-16 01:29:07.572710: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2100000000 Hz
2024-02-16 01:29:09.338174: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-16 01:29:09.608083: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-16 01:29:10.610926: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-16 01:29:10.660963: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|▏         | 1/78 [01:02<1:20:42, 62.89s/epoch, loss=3.45, accuracy=0.324, val_loss=2.33, val_accuracy=0.26, lr=0.1]  3%|▎         | 2/78 [01:29<52:23, 41.37s/epoch, loss=1.59, accuracy=0.531, val_loss=2.48, val_accuracy=0.377, lr=0.1]   4%|▍         | 3/78 [01:54<42:41, 34.15s/epoch, loss=1.38, accuracy=0.629, val_loss=2.06, val_accuracy=0.429, lr=0.1]  5%|▌         | 4/78 [02:19<37:45, 30.61s/epoch, loss=1.3, accuracy=0.671, val_loss=1.88, val_accuracy=0.48, lr=0.1]    6%|▋         | 5/78 [02:44<34:42, 28.53s/epoch, loss=1.28, accuracy=0.692, val_loss=1.85, val_accuracy=0.482, lr=0.1]  8%|▊         | 6/78 [03:09<32:50, 27.37s/epoch, loss=1.26, accuracy=0.704, val_loss=1.69, val_accuracy=0.567, lr=0.1]  9%|▉         | 7/78 [03:35<31:48, 26.89s/epoch, loss=1.23, accuracy=0.714, val_loss=2.22, val_accuracy=0.481, lr=0.1] 10%|█         | 8/78 [04:01<30:47, 26.39s/epoch, loss=1.22, accuracy=0.719, val_loss=5.36, val_accuracy=0.283, lr=0.1] 12%|█▏        | 9/78 [04:27<30:10, 26.24s/epoch, loss=1.22, accuracy=0.727, val_loss=3.05, val_accuracy=0.336, lr=0.1] 13%|█▎        | 10/78 [04:51<29:08, 25.72s/epoch, loss=1.2, accuracy=0.73, val_loss=4.41, val_accuracy=0.266, lr=0.1]  14%|█▍        | 11/78 [05:17<28:40, 25.68s/epoch, loss=1.21, accuracy=0.728, val_loss=1.4, val_accuracy=0.665, lr=0.1] 15%|█▌        | 12/78 [05:42<28:09, 25.60s/epoch, loss=1.19, accuracy=0.734, val_loss=2.01, val_accuracy=0.505, lr=0.1] 17%|█▋        | 13/78 [06:07<27:38, 25.52s/epoch, loss=1.2, accuracy=0.734, val_loss=2.23, val_accuracy=0.479, lr=0.1]  18%|█▊        | 14/78 [06:33<27:10, 25.48s/epoch, loss=1.18, accuracy=0.739, val_loss=3.04, val_accuracy=0.377, lr=0.1] 19%|█▉        | 15/78 [06:59<26:50, 25.56s/epoch, loss=1.18, accuracy=0.737, val_loss=1.75, val_accuracy=0.525, lr=0.1] 21%|██        | 16/78 [07:24<26:22, 25.52s/epoch, loss=1.18, accuracy=0.74, val_loss=2.6, val_accuracy=0.405, lr=0.0316] 22%|██▏       | 17/78 [07:50<26:03, 25.63s/epoch, loss=1.17, accuracy=0.742, val_loss=1.84, val_accuracy=0.577, lr=0.1]  23%|██▎       | 18/78 [08:16<25:52, 25.88s/epoch, loss=1.17, accuracy=0.742, val_loss=1.7, val_accuracy=0.564, lr=0.1]  24%|██▍       | 19/78 [08:42<25:20, 25.76s/epoch, loss=1.17, accuracy=0.744, val_loss=1.52, val_accuracy=0.635, lr=0.1] 26%|██▌       | 20/78 [09:08<24:54, 25.76s/epoch, loss=1.17, accuracy=0.744, val_loss=1.92, val_accuracy=0.505, lr=0.1] 27%|██▋       | 21/78 [09:33<24:27, 25.75s/epoch, loss=1.16, accuracy=0.746, val_loss=1.96, val_accuracy=0.5, lr=0.0316] 28%|██▊       | 22/78 [09:58<23:51, 25.56s/epoch, loss=1.17, accuracy=0.744, val_loss=1.59, val_accuracy=0.598, lr=0.1]  29%|██▉       | 23/78 [10:24<23:18, 25.42s/epoch, loss=1.16, accuracy=0.744, val_loss=1.58, val_accuracy=0.596, lr=0.1] 31%|███       | 24/78 [10:48<22:37, 25.13s/epoch, loss=1.16, accuracy=0.747, val_loss=2.32, val_accuracy=0.407, lr=0.1] 32%|███▏      | 25/78 [11:13<22:12, 25.14s/epoch, loss=1.15, accuracy=0.747, val_loss=2.14, val_accuracy=0.507, lr=0.1] 33%|███▎      | 26/78 [11:39<21:51, 25.22s/epoch, loss=1.15, accuracy=0.75, val_loss=1.65, val_accuracy=0.61, lr=0.0316] 35%|███▍      | 27/78 [12:04<21:36, 25.43s/epoch, loss=1.16, accuracy=0.749, val_loss=6.56, val_accuracy=0.204, lr=0.1]  36%|███▌      | 28/78 [12:31<21:22, 25.65s/epoch, loss=1.16, accuracy=0.747, val_loss=1.36, val_accuracy=0.686, lr=0.1] 37%|███▋      | 29/78 [12:56<20:59, 25.70s/epoch, loss=1.14, accuracy=0.753, val_loss=2.52, val_accuracy=0.301, lr=0.1] 38%|███▊      | 30/78 [13:22<20:26, 25.55s/epoch, loss=1.15, accuracy=0.75, val_loss=2.31, val_accuracy=0.412, lr=0.1]  40%|███▉      | 31/78 [13:47<19:57, 25.47s/epoch, loss=1.15, accuracy=0.748, val_loss=1.66, val_accuracy=0.602, lr=0.1] 41%|████      | 32/78 [14:13<19:33, 25.51s/epoch, loss=1.14, accuracy=0.75, val_loss=1.62, val_accuracy=0.576, lr=0.1]  42%|████▏     | 33/78 [14:39<19:15, 25.68s/epoch, loss=1.14, accuracy=0.751, val_loss=3.11, val_accuracy=0.404, lr=0.0316] 44%|████▎     | 34/78 [15:04<18:47, 25.63s/epoch, loss=1.14, accuracy=0.752, val_loss=1.54, val_accuracy=0.597, lr=0.1]    45%|████▍     | 35/78 [15:30<18:22, 25.64s/epoch, loss=1.14, accuracy=0.753, val_loss=1.85, val_accuracy=0.53, lr=0.1]  46%|████▌     | 36/78 [15:55<17:48, 25.45s/epoch, loss=1.14, accuracy=0.75, val_loss=3.27, val_accuracy=0.352, lr=0.1] 47%|████▋     | 37/78 [16:20<17:24, 25.48s/epoch, loss=1.14, accuracy=0.752, val_loss=1.62, val_accuracy=0.605, lr=0.1] 49%|████▊     | 38/78 [16:46<17:04, 25.62s/epoch, loss=1.14, accuracy=0.753, val_loss=2.03, val_accuracy=0.468, lr=0.0316] 50%|█████     | 39/78 [17:12<16:40, 25.65s/epoch, loss=1.14, accuracy=0.754, val_loss=2.27, val_accuracy=0.42, lr=0.1]     51%|█████▏    | 40/78 [17:36<15:57, 25.19s/epoch, loss=1.13, accuracy=0.753, val_loss=1.68, val_accuracy=0.57, lr=0.1] 53%|█████▎    | 41/78 [18:02<15:40, 25.42s/epoch, loss=1.14, accuracy=0.753, val_loss=2.05, val_accuracy=0.447, lr=0.1] 54%|█████▍    | 42/78 [18:28<15:18, 25.52s/epoch, loss=1.14, accuracy=0.752, val_loss=1.72, val_accuracy=0.596, lr=0.1] 55%|█████▌    | 43/78 [18:53<14:54, 25.55s/epoch, loss=1.13, accuracy=0.752, val_loss=4.23, val_accuracy=0.328, lr=0.0316] 56%|█████▋    | 44/78 [19:19<14:26, 25.50s/epoch, loss=1.14, accuracy=0.752, val_loss=4.83, val_accuracy=0.261, lr=0.1]    58%|█████▊    | 45/78 [19:43<13:52, 25.24s/epoch, loss=1.13, accuracy=0.754, val_loss=1.9, val_accuracy=0.545, lr=0.1]  59%|█████▉    | 46/78 [20:08<13:24, 25.15s/epoch, loss=1.14, accuracy=0.753, val_loss=2.41, val_accuracy=0.357, lr=0.1] 60%|██████    | 47/78 [20:34<12:59, 25.16s/epoch, loss=1.13, accuracy=0.753, val_loss=2.69, val_accuracy=0.469, lr=0.1] 62%|██████▏   | 48/78 [20:59<12:36, 25.20s/epoch, loss=1.14, accuracy=0.754, val_loss=1.87, val_accuracy=0.547, lr=0.0316] 63%|██████▎   | 49/78 [21:24<12:11, 25.23s/epoch, loss=1.13, accuracy=0.754, val_loss=2.58, val_accuracy=0.502, lr=0.1]    64%|██████▍   | 50/78 [21:50<11:48, 25.32s/epoch, loss=1.14, accuracy=0.752, val_loss=2.65, val_accuracy=0.364, lr=0.1] 65%|██████▌   | 51/78 [22:16<11:31, 25.60s/epoch, loss=1.13, accuracy=0.755, val_loss=2.21, val_accuracy=0.488, lr=0.1] 67%|██████▋   | 52/78 [22:42<11:08, 25.72s/epoch, loss=1.12, accuracy=0.754, val_loss=2.24, val_accuracy=0.441, lr=0.1] 68%|██████▊   | 53/78 [23:07<10:34, 25.38s/epoch, loss=1.13, accuracy=0.753, val_loss=2.26, val_accuracy=0.497, lr=0.0316] 69%|██████▉   | 54/78 [23:32<10:06, 25.26s/epoch, loss=1.14, accuracy=0.752, val_loss=2.15, val_accuracy=0.493, lr=0.1]    71%|███████   | 55/78 [23:58<09:46, 25.50s/epoch, loss=1.13, accuracy=0.754, val_loss=5.9, val_accuracy=0.189, lr=0.1]  72%|███████▏  | 56/78 [24:24<09:25, 25.71s/epoch, loss=1.14, accuracy=0.752, val_loss=4.01, val_accuracy=0.272, lr=0.1] 73%|███████▎  | 57/78 [24:50<09:01, 25.78s/epoch, loss=1.12, accuracy=0.757, val_loss=2, val_accuracy=0.536, lr=0.1]    74%|███████▍  | 58/78 [25:15<08:33, 25.67s/epoch, loss=1.13, accuracy=0.755, val_loss=1.99, val_accuracy=0.51, lr=0.0316] 76%|███████▌  | 59/78 [25:41<08:11, 25.85s/epoch, loss=1.13, accuracy=0.754, val_loss=1.91, val_accuracy=0.549, lr=0.1]   77%|███████▋  | 60/78 [26:07<07:43, 25.78s/epoch, loss=1.13, accuracy=0.756, val_loss=1.78, val_accuracy=0.539, lr=0.1] 78%|███████▊  | 61/78 [26:32<07:13, 25.52s/epoch, loss=1.13, accuracy=0.756, val_loss=2.49, val_accuracy=0.465, lr=0.1] 79%|███████▉  | 62/78 [26:57<06:45, 25.36s/epoch, loss=1.14, accuracy=0.75, val_loss=1.89, val_accuracy=0.534, lr=0.1]  81%|████████  | 63/78 [27:23<06:24, 25.62s/epoch, loss=1.14, accuracy=0.751, val_loss=1.99, val_accuracy=0.458, lr=0.0316] 82%|████████▏ | 64/78 [27:49<06:01, 25.83s/epoch, loss=1.12, accuracy=0.758, val_loss=1.73, val_accuracy=0.536, lr=0.1]    83%|████████▎ | 65/78 [28:16<05:36, 25.90s/epoch, loss=1.13, accuracy=0.752, val_loss=2.04, val_accuracy=0.518, lr=0.1] 85%|████████▍ | 66/78 [28:41<05:08, 25.70s/epoch, loss=1.13, accuracy=0.755, val_loss=3.13, val_accuracy=0.349, lr=0.1] 86%|████████▌ | 67/78 [29:06<04:41, 25.59s/epoch, loss=1.13, accuracy=0.757, val_loss=1.75, val_accuracy=0.54, lr=0.1]  87%|████████▋ | 68/78 [29:32<04:16, 25.66s/epoch, loss=1.13, accuracy=0.756, val_loss=1.77, val_accuracy=0.523, lr=0.0316] 88%|████████▊ | 69/78 [29:58<03:51, 25.75s/epoch, loss=1.13, accuracy=0.756, val_loss=2.45, val_accuracy=0.4, lr=0.1]      90%|████████▉ | 70/78 [30:24<03:26, 25.76s/epoch, loss=1.13, accuracy=0.756, val_loss=2.77, val_accuracy=0.401, lr=0.1] 91%|█████████ | 71/78 [30:50<03:00, 25.78s/epoch, loss=1.13, accuracy=0.754, val_loss=3.26, val_accuracy=0.382, lr=0.1] 92%|█████████▏| 72/78 [31:16<02:35, 25.86s/epoch, loss=1.13, accuracy=0.756, val_loss=2.33, val_accuracy=0.449, lr=0.1] 94%|█████████▎| 73/78 [31:41<02:09, 25.84s/epoch, loss=1.13, accuracy=0.755, val_loss=3.08, val_accuracy=0.35, lr=0.0316] 95%|█████████▍| 74/78 [32:07<01:43, 25.81s/epoch, loss=1.13, accuracy=0.757, val_loss=2.34, val_accuracy=0.391, lr=0.1]   96%|█████████▌| 75/78 [32:33<01:17, 25.75s/epoch, loss=1.13, accuracy=0.754, val_loss=1.7, val_accuracy=0.568, lr=0.1]  97%|█████████▋| 76/78 [32:59<00:51, 25.84s/epoch, loss=1.12, accuracy=0.757, val_loss=2.35, val_accuracy=0.361, lr=0.1] 99%|█████████▊| 77/78 [33:25<00:25, 25.88s/epoch, loss=1.13, accuracy=0.751, val_loss=1.83, val_accuracy=0.527, lr=0.1]100%|██████████| 78/78 [33:49<00:00, 25.49s/epoch, loss=1.13, accuracy=0.755, val_loss=1.73, val_accuracy=0.575, lr=0.0316]100%|██████████| 78/78 [33:49<00:00, 26.02s/epoch, loss=1.13, accuracy=0.755, val_loss=1.73, val_accuracy=0.575, lr=0.0316]
Using real-time data augmentation.
Test loss: 1.7303701639175415
Test accuracy: 0.5752000212669373
