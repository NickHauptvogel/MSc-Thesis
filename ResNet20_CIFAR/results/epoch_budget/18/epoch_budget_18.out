Tue Mar  5 09:53:42 2024       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 545.23.08              Driver Version: 545.23.08    CUDA Version: 12.3     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA TITAN X (Pascal)        Off | 00000000:83:00.0 Off |                  N/A |
| 41%   58C    P8              13W / 250W |      0MiB / 12288MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|  No running processes found                                                           |
+---------------------------------------------------------------------------------------+


* * * Run SGD for cluster size = 18. * * *


Budget: 83


* * * Run SGD for ID = 18_1. * * *


2024-03-05 09:53:42.918599: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 09:53:47.989132: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 09:53:47.990231: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-05 09:53:48.028605: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-03-05 09:53:48.028649: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 09:53:48.048317: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 09:53:48.048440: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 09:53:48.070859: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 09:53:48.129237: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 09:53:48.169617: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 09:53:48.193240: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 09:53:48.219758: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 09:53:48.220398: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 09:53:48.220479: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 09:53:49.551208: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-05 09:53:49.552188: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 09:53:49.552629: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-03-05 09:53:49.552662: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 09:53:49.552695: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 09:53:49.552711: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 09:53:49.552726: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 09:53:49.552741: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 09:53:49.552756: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 09:53:49.552771: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 09:53:49.552786: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 09:53:49.553228: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 09:53:49.553264: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 09:53:50.358895: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-05 09:53:50.358942: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-05 09:53:50.358950: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-05 09:53:50.359845: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': '18_01', 'seed': 1, 'out_folder': 'results/epoch_budget', 'batch_size': 128, 'epochs': 83, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'bootstrapping': False, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/83 [00:00<?, ?epoch/s]2024-03-05 09:53:51.238420: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-05 09:53:51.238850: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600020000 Hz
2024-03-05 09:53:53.274036: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 09:53:53.506673: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 09:53:54.319269: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-05 09:53:54.374077: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/83 [01:05<1:28:54, 65.05s/epoch, loss=3.51, accuracy=0.305, val_loss=2.8, val_accuracy=0.132, lr=0.1]  2%|▏         | 2/83 [01:25<52:31, 38.90s/epoch, loss=1.62, accuracy=0.509, val_loss=2.71, val_accuracy=0.341, lr=0.1]   4%|▎         | 3/83 [01:45<40:21, 30.26s/epoch, loss=1.41, accuracy=0.613, val_loss=1.94, val_accuracy=0.498, lr=0.1]  5%|▍         | 4/83 [02:06<34:46, 26.42s/epoch, loss=1.31, accuracy=0.668, val_loss=1.56, val_accuracy=0.589, lr=0.1]  6%|▌         | 5/83 [02:26<31:19, 24.10s/epoch, loss=1.26, accuracy=0.693, val_loss=1.6, val_accuracy=0.591, lr=0.1]   7%|▋         | 6/83 [02:46<29:05, 22.67s/epoch, loss=1.25, accuracy=0.706, val_loss=1.99, val_accuracy=0.446, lr=0.1]  8%|▊         | 7/83 [03:06<27:41, 21.86s/epoch, loss=1.24, accuracy=0.711, val_loss=1.73, val_accuracy=0.543, lr=0.1] 10%|▉         | 8/83 [03:26<26:33, 21.25s/epoch, loss=1.22, accuracy=0.72, val_loss=2.42, val_accuracy=0.428, lr=0.1]  11%|█         | 9/83 [03:46<25:40, 20.81s/epoch, loss=1.22, accuracy=0.725, val_loss=1.91, val_accuracy=0.526, lr=0.0316] 12%|█▏        | 10/83 [04:05<24:56, 20.50s/epoch, loss=1.21, accuracy=0.726, val_loss=2.61, val_accuracy=0.376, lr=0.1]   13%|█▎        | 11/83 [04:25<24:21, 20.29s/epoch, loss=1.2, accuracy=0.729, val_loss=2.05, val_accuracy=0.5, lr=0.1]    14%|█▍        | 12/83 [04:45<23:51, 20.16s/epoch, loss=1.2, accuracy=0.735, val_loss=2.18, val_accuracy=0.45, lr=0.1] 16%|█▌        | 13/83 [05:05<23:31, 20.16s/epoch, loss=1.19, accuracy=0.735, val_loss=2.13, val_accuracy=0.468, lr=0.1] 17%|█▋        | 14/83 [05:25<22:59, 19.99s/epoch, loss=1.19, accuracy=0.737, val_loss=1.64, val_accuracy=0.583, lr=0.0316] 18%|█▊        | 15/83 [05:45<22:35, 19.94s/epoch, loss=1.19, accuracy=0.739, val_loss=1.87, val_accuracy=0.578, lr=0.1]    19%|█▉        | 16/83 [06:04<22:13, 19.90s/epoch, loss=1.19, accuracy=0.74, val_loss=1.41, val_accuracy=0.656, lr=0.1]  20%|██        | 17/83 [06:24<21:48, 19.82s/epoch, loss=1.2, accuracy=0.74, val_loss=1.73, val_accuracy=0.564, lr=0.1]  22%|██▏       | 18/83 [06:44<21:25, 19.77s/epoch, loss=1.18, accuracy=0.74, val_loss=1.94, val_accuracy=0.534, lr=0.1] 23%|██▎       | 19/83 [07:03<21:05, 19.78s/epoch, loss=1.18, accuracy=0.742, val_loss=3.71, val_accuracy=0.156, lr=0.1] 24%|██▍       | 20/83 [07:23<20:46, 19.78s/epoch, loss=1.18, accuracy=0.743, val_loss=1.97, val_accuracy=0.543, lr=0.1] 25%|██▌       | 21/83 [07:43<20:29, 19.82s/epoch, loss=1.18, accuracy=0.745, val_loss=2.17, val_accuracy=0.419, lr=0.0316] 27%|██▋       | 22/83 [08:03<20:12, 19.88s/epoch, loss=1.18, accuracy=0.746, val_loss=1.84, val_accuracy=0.55, lr=0.1]     28%|██▊       | 23/83 [08:23<19:56, 19.94s/epoch, loss=1.18, accuracy=0.745, val_loss=1.93, val_accuracy=0.548, lr=0.1] 29%|██▉       | 24/83 [08:43<19:40, 20.00s/epoch, loss=1.18, accuracy=0.744, val_loss=2.05, val_accuracy=0.482, lr=0.1] 30%|███       | 25/83 [09:04<19:23, 20.06s/epoch, loss=1.18, accuracy=0.744, val_loss=2.7, val_accuracy=0.421, lr=0.1]  31%|███▏      | 26/83 [09:24<19:01, 20.03s/epoch, loss=1.18, accuracy=0.743, val_loss=5.18, val_accuracy=0.249, lr=0.0316] 33%|███▎      | 27/83 [09:44<18:49, 20.16s/epoch, loss=1.17, accuracy=0.745, val_loss=1.81, val_accuracy=0.547, lr=0.1]    34%|███▎      | 28/83 [10:04<18:25, 20.10s/epoch, loss=1.17, accuracy=0.749, val_loss=3, val_accuracy=0.353, lr=0.1]    35%|███▍      | 29/83 [10:24<18:01, 20.03s/epoch, loss=1.18, accuracy=0.745, val_loss=1.48, val_accuracy=0.633, lr=0.1] 36%|███▌      | 30/83 [10:44<17:45, 20.11s/epoch, loss=1.18, accuracy=0.746, val_loss=1.82, val_accuracy=0.542, lr=0.1] 37%|███▋      | 31/83 [11:04<17:24, 20.08s/epoch, loss=1.16, accuracy=0.748, val_loss=1.98, val_accuracy=0.493, lr=0.0316] 39%|███▊      | 32/83 [11:24<16:59, 20.00s/epoch, loss=1.17, accuracy=0.746, val_loss=2.22, val_accuracy=0.432, lr=0.1]    40%|███▉      | 33/83 [11:44<16:38, 19.98s/epoch, loss=1.16, accuracy=0.748, val_loss=1.45, val_accuracy=0.653, lr=0.1] 41%|████      | 34/83 [12:04<16:21, 20.02s/epoch, loss=1.16, accuracy=0.749, val_loss=2.09, val_accuracy=0.519, lr=0.1] 42%|████▏     | 35/83 [12:24<16:02, 20.05s/epoch, loss=1.16, accuracy=0.748, val_loss=1.84, val_accuracy=0.539, lr=0.1] 43%|████▎     | 36/83 [12:44<15:43, 20.08s/epoch, loss=1.16, accuracy=0.746, val_loss=1.84, val_accuracy=0.558, lr=0.0316] 45%|████▍     | 37/83 [13:04<15:21, 20.04s/epoch, loss=1.16, accuracy=0.749, val_loss=2.22, val_accuracy=0.486, lr=0.1]    46%|████▌     | 38/83 [13:24<15:00, 20.00s/epoch, loss=1.16, accuracy=0.749, val_loss=1.73, val_accuracy=0.565, lr=0.1] 47%|████▋     | 39/83 [13:44<14:38, 19.96s/epoch, loss=1.16, accuracy=0.749, val_loss=1.78, val_accuracy=0.56, lr=0.1]  48%|████▊     | 40/83 [14:04<14:19, 19.99s/epoch, loss=1.15, accuracy=0.749, val_loss=3.11, val_accuracy=0.382, lr=0.1] 49%|████▉     | 41/83 [14:24<13:58, 19.97s/epoch, loss=1.15, accuracy=0.747, val_loss=4.43, val_accuracy=0.294, lr=0.0316] 51%|█████     | 42/83 [14:44<13:44, 20.10s/epoch, loss=1.15, accuracy=0.748, val_loss=1.7, val_accuracy=0.558, lr=0.1]     52%|█████▏    | 43/83 [15:05<13:23, 20.10s/epoch, loss=1.15, accuracy=0.75, val_loss=1.96, val_accuracy=0.505, lr=0.1] 53%|█████▎    | 44/83 [15:24<12:57, 19.94s/epoch, loss=1.16, accuracy=0.748, val_loss=1.61, val_accuracy=0.607, lr=0.1] 54%|█████▍    | 45/83 [15:44<12:38, 19.95s/epoch, loss=1.15, accuracy=0.75, val_loss=1.71, val_accuracy=0.56, lr=0.1]   55%|█████▌    | 46/83 [16:04<12:16, 19.92s/epoch, loss=1.14, accuracy=0.752, val_loss=1.95, val_accuracy=0.574, lr=0.0316] 57%|█████▋    | 47/83 [16:24<11:57, 19.92s/epoch, loss=1.15, accuracy=0.75, val_loss=2.03, val_accuracy=0.493, lr=0.1]     58%|█████▊    | 48/83 [16:44<11:36, 19.91s/epoch, loss=1.15, accuracy=0.751, val_loss=2.36, val_accuracy=0.42, lr=0.1] 59%|█████▉    | 49/83 [17:04<11:17, 19.93s/epoch, loss=1.14, accuracy=0.754, val_loss=4.21, val_accuracy=0.232, lr=0.1] 60%|██████    | 50/83 [17:24<10:57, 19.92s/epoch, loss=1.15, accuracy=0.752, val_loss=4.97, val_accuracy=0.258, lr=0.1] 61%|██████▏   | 51/83 [17:44<10:38, 19.94s/epoch, loss=1.15, accuracy=0.752, val_loss=2.35, val_accuracy=0.363, lr=0.0316] 63%|██████▎   | 52/83 [18:04<10:19, 19.99s/epoch, loss=1.14, accuracy=0.751, val_loss=2.03, val_accuracy=0.503, lr=0.1]    64%|██████▍   | 53/83 [18:24<10:01, 20.04s/epoch, loss=1.14, accuracy=0.753, val_loss=1.98, val_accuracy=0.541, lr=0.1] 65%|██████▌   | 54/83 [18:44<09:42, 20.08s/epoch, loss=1.15, accuracy=0.752, val_loss=1.58, val_accuracy=0.638, lr=0.1] 66%|██████▋   | 55/83 [19:04<09:21, 20.07s/epoch, loss=1.14, accuracy=0.752, val_loss=1.83, val_accuracy=0.521, lr=0.1] 67%|██████▋   | 56/83 [19:24<09:01, 20.04s/epoch, loss=1.14, accuracy=0.753, val_loss=3.76, val_accuracy=0.381, lr=0.0316] 69%|██████▊   | 57/83 [19:44<08:39, 19.99s/epoch, loss=1.14, accuracy=0.75, val_loss=1.87, val_accuracy=0.527, lr=0.1]     70%|██████▉   | 58/83 [20:04<08:19, 19.99s/epoch, loss=1.14, accuracy=0.753, val_loss=2.07, val_accuracy=0.511, lr=0.1] 71%|███████   | 59/83 [20:24<07:59, 19.99s/epoch, loss=1.14, accuracy=0.751, val_loss=1.81, val_accuracy=0.543, lr=0.1] 72%|███████▏  | 60/83 [20:44<07:40, 20.01s/epoch, loss=1.14, accuracy=0.753, val_loss=2.17, val_accuracy=0.469, lr=0.1] 73%|███████▎  | 61/83 [21:04<07:18, 19.94s/epoch, loss=1.14, accuracy=0.753, val_loss=2.77, val_accuracy=0.371, lr=0.0316] 75%|███████▍  | 62/83 [21:24<06:58, 19.93s/epoch, loss=1.14, accuracy=0.752, val_loss=2.13, val_accuracy=0.446, lr=0.1]    76%|███████▌  | 63/83 [21:43<06:38, 19.90s/epoch, loss=1.14, accuracy=0.75, val_loss=1.97, val_accuracy=0.49, lr=0.1]   77%|███████▋  | 64/83 [22:03<06:16, 19.82s/epoch, loss=1.14, accuracy=0.753, val_loss=2.1, val_accuracy=0.452, lr=0.1] 78%|███████▊  | 65/83 [22:23<05:56, 19.78s/epoch, loss=1.14, accuracy=0.753, val_loss=1.75, val_accuracy=0.593, lr=0.1] 80%|███████▉  | 66/83 [22:42<05:35, 19.74s/epoch, loss=1.14, accuracy=0.753, val_loss=1.9, val_accuracy=0.534, lr=0.0316] 81%|████████  | 67/83 [23:02<05:15, 19.73s/epoch, loss=1.15, accuracy=0.753, val_loss=1.82, val_accuracy=0.57, lr=0.1]    82%|████████▏ | 68/83 [23:22<04:56, 19.77s/epoch, loss=1.13, accuracy=0.754, val_loss=2.1, val_accuracy=0.47, lr=0.1]  83%|████████▎ | 69/83 [23:42<04:35, 19.71s/epoch, loss=1.13, accuracy=0.753, val_loss=2.76, val_accuracy=0.397, lr=0.1] 84%|████████▍ | 70/83 [24:01<04:15, 19.68s/epoch, loss=1.13, accuracy=0.752, val_loss=3.34, val_accuracy=0.393, lr=0.1] 86%|████████▌ | 71/83 [24:21<03:55, 19.65s/epoch, loss=1.14, accuracy=0.751, val_loss=1.8, val_accuracy=0.545, lr=0.0316] 87%|████████▋ | 72/83 [24:41<03:36, 19.69s/epoch, loss=1.13, accuracy=0.753, val_loss=1.95, val_accuracy=0.524, lr=0.1]   88%|████████▊ | 73/83 [25:00<03:16, 19.68s/epoch, loss=1.13, accuracy=0.757, val_loss=1.99, val_accuracy=0.461, lr=0.1] 89%|████████▉ | 74/83 [25:20<02:57, 19.75s/epoch, loss=1.13, accuracy=0.753, val_loss=1.56, val_accuracy=0.608, lr=0.1] 90%|█████████ | 75/83 [25:40<02:38, 19.75s/epoch, loss=1.13, accuracy=0.753, val_loss=1.71, val_accuracy=0.542, lr=0.1] 92%|█████████▏| 76/83 [26:00<02:18, 19.80s/epoch, loss=1.12, accuracy=0.756, val_loss=2.42, val_accuracy=0.404, lr=0.0316] 93%|█████████▎| 77/83 [26:20<01:58, 19.82s/epoch, loss=1.13, accuracy=0.753, val_loss=2.06, val_accuracy=0.512, lr=0.1]    94%|█████████▍| 78/83 [26:39<01:38, 19.79s/epoch, loss=1.13, accuracy=0.754, val_loss=2.52, val_accuracy=0.373, lr=0.1] 95%|█████████▌| 79/83 [26:59<01:18, 19.75s/epoch, loss=1.12, accuracy=0.757, val_loss=2.27, val_accuracy=0.438, lr=0.1] 96%|█████████▋| 80/83 [27:19<00:59, 19.70s/epoch, loss=1.13, accuracy=0.754, val_loss=1.71, val_accuracy=0.533, lr=0.1] 98%|█████████▊| 81/83 [27:38<00:39, 19.68s/epoch, loss=1.13, accuracy=0.754, val_loss=1.49, val_accuracy=0.63, lr=0.0316] 99%|█████████▉| 82/83 [27:58<00:19, 19.72s/epoch, loss=0.916, accuracy=0.815, val_loss=0.919, val_accuracy=0.797, lr=0.01]100%|██████████| 83/83 [28:18<00:00, 19.67s/epoch, loss=0.736, accuracy=0.845, val_loss=0.846, val_accuracy=0.796, lr=0.01]100%|██████████| 83/83 [28:18<00:00, 20.46s/epoch, loss=0.736, accuracy=0.845, val_loss=0.846, val_accuracy=0.796, lr=0.01]
Using real-time data augmentation.
Test score: 0.8457629680633545
Test accuracy: 0.7961999773979187


* * * Run SGD for ID = 18_2. * * *


2024-03-05 10:22:13.233410: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 10:22:16.784134: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 10:22:16.785286: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-05 10:22:16.822844: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-03-05 10:22:16.822892: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 10:22:16.825851: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 10:22:16.825902: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 10:22:16.828029: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 10:22:16.828695: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 10:22:16.831051: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 10:22:16.832490: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 10:22:16.837093: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 10:22:16.837725: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 10:22:16.837824: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 10:22:18.077525: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-05 10:22:18.078199: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 10:22:18.079467: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-03-05 10:22:18.079502: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 10:22:18.079549: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 10:22:18.079567: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 10:22:18.079582: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 10:22:18.079598: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 10:22:18.079613: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 10:22:18.079628: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 10:22:18.079643: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 10:22:18.080090: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 10:22:18.080126: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 10:22:18.751079: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-05 10:22:18.751135: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-05 10:22:18.751144: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-05 10:22:18.752089: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': '18_02', 'seed': 2, 'out_folder': 'results/epoch_budget', 'batch_size': 128, 'epochs': 83, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'bootstrapping': False, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/83 [00:00<?, ?epoch/s]2024-03-05 10:22:19.646552: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-05 10:22:19.658120: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600020000 Hz
2024-03-05 10:22:21.677523: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 10:22:21.890721: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 10:22:22.629854: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-05 10:22:22.680695: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/83 [01:05<1:29:48, 65.72s/epoch, loss=2.91, accuracy=0.371, val_loss=2.25, val_accuracy=0.369, lr=0.1]  2%|▏         | 2/83 [01:26<52:46, 39.09s/epoch, loss=1.43, accuracy=0.603, val_loss=2.46, val_accuracy=0.326, lr=0.1]    4%|▎         | 3/83 [01:46<40:44, 30.55s/epoch, loss=1.3, accuracy=0.666, val_loss=3.01, val_accuracy=0.366, lr=0.1]   5%|▍         | 4/83 [02:06<34:49, 26.45s/epoch, loss=1.24, accuracy=0.693, val_loss=1.76, val_accuracy=0.527, lr=0.1]  6%|▌         | 5/83 [02:26<31:23, 24.15s/epoch, loss=1.23, accuracy=0.707, val_loss=2.22, val_accuracy=0.419, lr=0.1]  7%|▋         | 6/83 [02:46<29:14, 22.78s/epoch, loss=1.22, accuracy=0.714, val_loss=1.6, val_accuracy=0.579, lr=0.1]   8%|▊         | 7/83 [03:06<27:42, 21.88s/epoch, loss=1.21, accuracy=0.722, val_loss=1.5, val_accuracy=0.608, lr=0.1] 10%|▉         | 8/83 [03:27<26:37, 21.31s/epoch, loss=1.2, accuracy=0.725, val_loss=1.8, val_accuracy=0.532, lr=0.1]  11%|█         | 9/83 [03:46<25:43, 20.85s/epoch, loss=1.2, accuracy=0.727, val_loss=2.83, val_accuracy=0.324, lr=0.1] 12%|█▏        | 10/83 [04:06<25:01, 20.56s/epoch, loss=1.2, accuracy=0.727, val_loss=2.57, val_accuracy=0.414, lr=0.1] 13%|█▎        | 11/83 [04:26<24:23, 20.32s/epoch, loss=1.19, accuracy=0.731, val_loss=3.25, val_accuracy=0.396, lr=0.1] 14%|█▍        | 12/83 [04:46<23:52, 20.18s/epoch, loss=1.2, accuracy=0.734, val_loss=1.8, val_accuracy=0.554, lr=0.0316] 16%|█▌        | 13/83 [05:06<23:28, 20.12s/epoch, loss=1.18, accuracy=0.735, val_loss=1.93, val_accuracy=0.485, lr=0.1]  17%|█▋        | 14/83 [05:26<23:06, 20.09s/epoch, loss=1.18, accuracy=0.736, val_loss=1.96, val_accuracy=0.507, lr=0.1] 18%|█▊        | 15/83 [05:46<22:43, 20.05s/epoch, loss=1.19, accuracy=0.735, val_loss=1.55, val_accuracy=0.614, lr=0.1] 19%|█▉        | 16/83 [06:06<22:18, 19.99s/epoch, loss=1.18, accuracy=0.738, val_loss=2.04, val_accuracy=0.503, lr=0.1] 20%|██        | 17/83 [06:26<21:57, 19.96s/epoch, loss=1.17, accuracy=0.741, val_loss=1.75, val_accuracy=0.562, lr=0.0316] 22%|██▏       | 18/83 [06:46<21:44, 20.07s/epoch, loss=1.17, accuracy=0.739, val_loss=2.1, val_accuracy=0.453, lr=0.1]     23%|██▎       | 19/83 [07:06<21:27, 20.11s/epoch, loss=1.17, accuracy=0.74, val_loss=2.94, val_accuracy=0.419, lr=0.1] 24%|██▍       | 20/83 [07:26<21:02, 20.04s/epoch, loss=1.17, accuracy=0.743, val_loss=1.76, val_accuracy=0.559, lr=0.1] 25%|██▌       | 21/83 [07:46<20:37, 19.97s/epoch, loss=1.19, accuracy=0.74, val_loss=2.15, val_accuracy=0.425, lr=0.1]  27%|██▋       | 22/83 [08:06<20:17, 19.96s/epoch, loss=1.17, accuracy=0.746, val_loss=3.07, val_accuracy=0.428, lr=0.0316] 28%|██▊       | 23/83 [08:26<19:54, 19.90s/epoch, loss=1.16, accuracy=0.745, val_loss=3.62, val_accuracy=0.334, lr=0.1]    29%|██▉       | 24/83 [08:45<19:29, 19.83s/epoch, loss=1.16, accuracy=0.747, val_loss=1.8, val_accuracy=0.573, lr=0.1]  30%|███       | 25/83 [09:05<19:13, 19.89s/epoch, loss=1.16, accuracy=0.748, val_loss=1.8, val_accuracy=0.539, lr=0.1] 31%|███▏      | 26/83 [09:25<18:56, 19.94s/epoch, loss=1.17, accuracy=0.744, val_loss=1.53, val_accuracy=0.647, lr=0.1] 33%|███▎      | 27/83 [09:46<18:43, 20.06s/epoch, loss=1.16, accuracy=0.749, val_loss=1.78, val_accuracy=0.536, lr=0.0316] 34%|███▎      | 28/83 [10:06<18:25, 20.09s/epoch, loss=1.15, accuracy=0.748, val_loss=2.67, val_accuracy=0.416, lr=0.1]    35%|███▍      | 29/83 [10:26<18:07, 20.13s/epoch, loss=1.16, accuracy=0.749, val_loss=3.1, val_accuracy=0.397, lr=0.1]  36%|███▌      | 30/83 [10:46<17:46, 20.12s/epoch, loss=1.16, accuracy=0.749, val_loss=2.23, val_accuracy=0.429, lr=0.1] 37%|███▋      | 31/83 [11:06<17:22, 20.04s/epoch, loss=1.15, accuracy=0.747, val_loss=2.03, val_accuracy=0.46, lr=0.1]  39%|███▊      | 32/83 [11:26<17:02, 20.06s/epoch, loss=1.16, accuracy=0.747, val_loss=1.61, val_accuracy=0.586, lr=0.0316] 40%|███▉      | 33/83 [11:46<16:41, 20.03s/epoch, loss=1.14, accuracy=0.75, val_loss=2.44, val_accuracy=0.425, lr=0.1]     41%|████      | 34/83 [12:06<16:24, 20.10s/epoch, loss=1.15, accuracy=0.752, val_loss=1.69, val_accuracy=0.582, lr=0.1] 42%|████▏     | 35/83 [12:26<16:02, 20.05s/epoch, loss=1.14, accuracy=0.749, val_loss=2.12, val_accuracy=0.457, lr=0.1] 43%|████▎     | 36/83 [12:46<15:41, 20.04s/epoch, loss=1.14, accuracy=0.75, val_loss=1.68, val_accuracy=0.598, lr=0.1]  45%|████▍     | 37/83 [13:06<15:24, 20.09s/epoch, loss=1.14, accuracy=0.75, val_loss=3.43, val_accuracy=0.296, lr=0.0316] 46%|████▌     | 38/83 [13:27<15:04, 20.10s/epoch, loss=1.15, accuracy=0.749, val_loss=2.1, val_accuracy=0.473, lr=0.1]    47%|████▋     | 39/83 [13:46<14:41, 20.04s/epoch, loss=1.14, accuracy=0.75, val_loss=2.66, val_accuracy=0.353, lr=0.1] 48%|████▊     | 40/83 [14:06<14:20, 20.00s/epoch, loss=1.15, accuracy=0.753, val_loss=1.75, val_accuracy=0.553, lr=0.1] 49%|████▉     | 41/83 [14:26<13:58, 19.96s/epoch, loss=1.14, accuracy=0.751, val_loss=1.63, val_accuracy=0.619, lr=0.1] 51%|█████     | 42/83 [14:46<13:38, 19.97s/epoch, loss=1.14, accuracy=0.75, val_loss=2.35, val_accuracy=0.433, lr=0.0316] 52%|█████▏    | 43/83 [15:06<13:17, 19.93s/epoch, loss=1.14, accuracy=0.752, val_loss=2.73, val_accuracy=0.423, lr=0.1]   53%|█████▎    | 44/83 [15:26<12:56, 19.90s/epoch, loss=1.15, accuracy=0.75, val_loss=1.94, val_accuracy=0.462, lr=0.1]  54%|█████▍    | 45/83 [15:46<12:36, 19.90s/epoch, loss=1.15, accuracy=0.751, val_loss=1.93, val_accuracy=0.531, lr=0.1] 55%|█████▌    | 46/83 [16:06<12:15, 19.89s/epoch, loss=1.14, accuracy=0.752, val_loss=2.85, val_accuracy=0.348, lr=0.1] 57%|█████▋    | 47/83 [16:25<11:55, 19.86s/epoch, loss=1.14, accuracy=0.752, val_loss=3.61, val_accuracy=0.323, lr=0.0316] 58%|█████▊    | 48/83 [16:45<11:35, 19.86s/epoch, loss=1.13, accuracy=0.754, val_loss=2.19, val_accuracy=0.463, lr=0.1]    59%|█████▉    | 49/83 [17:05<11:15, 19.88s/epoch, loss=1.14, accuracy=0.752, val_loss=2.25, val_accuracy=0.439, lr=0.1] 60%|██████    | 50/83 [17:25<10:56, 19.88s/epoch, loss=1.14, accuracy=0.752, val_loss=2.73, val_accuracy=0.335, lr=0.1] 61%|██████▏   | 51/83 [17:45<10:36, 19.88s/epoch, loss=1.13, accuracy=0.753, val_loss=5.91, val_accuracy=0.137, lr=0.1] 63%|██████▎   | 52/83 [18:05<10:15, 19.85s/epoch, loss=1.13, accuracy=0.752, val_loss=1.87, val_accuracy=0.539, lr=0.0316] 64%|██████▍   | 53/83 [18:25<09:54, 19.83s/epoch, loss=1.14, accuracy=0.755, val_loss=2.58, val_accuracy=0.375, lr=0.1]    65%|██████▌   | 54/83 [18:45<09:36, 19.87s/epoch, loss=1.14, accuracy=0.752, val_loss=2.9, val_accuracy=0.27, lr=0.1]   66%|██████▋   | 55/83 [19:05<09:18, 19.94s/epoch, loss=1.13, accuracy=0.752, val_loss=2.65, val_accuracy=0.415, lr=0.1] 67%|██████▋   | 56/83 [19:24<08:56, 19.89s/epoch, loss=1.14, accuracy=0.753, val_loss=2.16, val_accuracy=0.513, lr=0.1] 69%|██████▊   | 57/83 [19:44<08:34, 19.80s/epoch, loss=1.13, accuracy=0.756, val_loss=1.59, val_accuracy=0.605, lr=0.0316] 70%|██████▉   | 58/83 [20:04<08:15, 19.80s/epoch, loss=1.14, accuracy=0.752, val_loss=1.6, val_accuracy=0.585, lr=0.1]     71%|███████   | 59/83 [20:24<07:55, 19.80s/epoch, loss=1.14, accuracy=0.754, val_loss=3.03, val_accuracy=0.392, lr=0.1] 72%|███████▏  | 60/83 [20:43<07:35, 19.80s/epoch, loss=1.14, accuracy=0.752, val_loss=2.2, val_accuracy=0.411, lr=0.1]  73%|███████▎  | 61/83 [21:03<07:14, 19.75s/epoch, loss=1.14, accuracy=0.752, val_loss=2.96, val_accuracy=0.363, lr=0.1] 75%|███████▍  | 62/83 [21:23<06:54, 19.73s/epoch, loss=1.13, accuracy=0.756, val_loss=4.17, val_accuracy=0.26, lr=0.0316] 76%|███████▌  | 63/83 [21:42<06:33, 19.68s/epoch, loss=1.14, accuracy=0.752, val_loss=2.53, val_accuracy=0.368, lr=0.1]   77%|███████▋  | 64/83 [22:02<06:13, 19.67s/epoch, loss=1.14, accuracy=0.752, val_loss=2.71, val_accuracy=0.327, lr=0.1] 78%|███████▊  | 65/83 [22:22<05:53, 19.65s/epoch, loss=1.14, accuracy=0.752, val_loss=1.88, val_accuracy=0.568, lr=0.1] 80%|███████▉  | 66/83 [22:41<05:34, 19.65s/epoch, loss=1.13, accuracy=0.754, val_loss=2.67, val_accuracy=0.438, lr=0.1] 81%|████████  | 67/83 [23:01<05:13, 19.60s/epoch, loss=1.13, accuracy=0.755, val_loss=2.49, val_accuracy=0.35, lr=0.0316] 82%|████████▏ | 68/83 [23:20<04:53, 19.60s/epoch, loss=1.14, accuracy=0.754, val_loss=1.92, val_accuracy=0.537, lr=0.1]   83%|████████▎ | 69/83 [23:40<04:34, 19.62s/epoch, loss=1.14, accuracy=0.754, val_loss=3.34, val_accuracy=0.381, lr=0.1] 84%|████████▍ | 70/83 [24:00<04:14, 19.61s/epoch, loss=1.14, accuracy=0.755, val_loss=2.26, val_accuracy=0.439, lr=0.1] 86%|████████▌ | 71/83 [24:19<03:55, 19.63s/epoch, loss=1.13, accuracy=0.755, val_loss=3.04, val_accuracy=0.346, lr=0.1] 87%|████████▋ | 72/83 [24:39<03:35, 19.64s/epoch, loss=1.13, accuracy=0.754, val_loss=1.43, val_accuracy=0.641, lr=0.1] 88%|████████▊ | 73/83 [24:58<03:16, 19.64s/epoch, loss=1.14, accuracy=0.751, val_loss=1.42, val_accuracy=0.658, lr=0.1] 89%|████████▉ | 74/83 [25:18<02:56, 19.62s/epoch, loss=1.14, accuracy=0.752, val_loss=1.74, val_accuracy=0.599, lr=0.1] 90%|█████████ | 75/83 [25:38<02:37, 19.68s/epoch, loss=1.12, accuracy=0.758, val_loss=1.71, val_accuracy=0.554, lr=0.1] 92%|█████████▏| 76/83 [25:58<02:17, 19.68s/epoch, loss=1.13, accuracy=0.754, val_loss=1.49, val_accuracy=0.616, lr=0.1] 93%|█████████▎| 77/83 [26:17<01:58, 19.74s/epoch, loss=1.13, accuracy=0.755, val_loss=1.91, val_accuracy=0.533, lr=0.1] 94%|█████████▍| 78/83 [26:38<01:39, 19.83s/epoch, loss=1.12, accuracy=0.757, val_loss=1.42, val_accuracy=0.646, lr=0.0316] 95%|█████████▌| 79/83 [26:58<01:19, 19.89s/epoch, loss=1.14, accuracy=0.755, val_loss=1.67, val_accuracy=0.576, lr=0.1]    96%|█████████▋| 80/83 [27:17<00:59, 19.86s/epoch, loss=1.13, accuracy=0.755, val_loss=1.67, val_accuracy=0.576, lr=0.1] 98%|█████████▊| 81/83 [27:37<00:39, 19.84s/epoch, loss=1.13, accuracy=0.757, val_loss=1.78, val_accuracy=0.571, lr=0.1] 99%|█████████▉| 82/83 [27:57<00:19, 19.87s/epoch, loss=0.914, accuracy=0.816, val_loss=0.946, val_accuracy=0.788, lr=0.01]100%|██████████| 83/83 [28:17<00:00, 19.87s/epoch, loss=0.74, accuracy=0.845, val_loss=0.75, val_accuracy=0.834, lr=0.01]  100%|██████████| 83/83 [28:17<00:00, 20.45s/epoch, loss=0.74, accuracy=0.845, val_loss=0.75, val_accuracy=0.834, lr=0.01]
Using real-time data augmentation.
Test score: 0.7502254843711853
Test accuracy: 0.8337000012397766


* * * Run SGD for ID = 18_3. * * *


2024-03-05 10:50:40.734117: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 10:50:43.245449: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 10:50:43.246577: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-05 10:50:43.283319: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-03-05 10:50:43.283369: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 10:50:43.286134: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 10:50:43.286175: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 10:50:43.288498: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 10:50:43.289165: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 10:50:43.291549: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 10:50:43.292922: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 10:50:43.297547: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 10:50:43.298139: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 10:50:43.298221: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 10:50:44.525747: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-05 10:50:44.526326: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 10:50:44.527109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-03-05 10:50:44.527139: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 10:50:44.527176: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 10:50:44.527192: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 10:50:44.527207: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 10:50:44.527229: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 10:50:44.527246: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 10:50:44.527262: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 10:50:44.527278: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 10:50:44.527708: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 10:50:44.527744: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 10:50:45.234794: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-05 10:50:45.234848: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-05 10:50:45.234857: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-05 10:50:45.235756: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': '18_03', 'seed': 3, 'out_folder': 'results/epoch_budget', 'batch_size': 128, 'epochs': 83, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'bootstrapping': False, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/83 [00:00<?, ?epoch/s]2024-03-05 10:50:46.076028: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-05 10:50:46.088152: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600020000 Hz
2024-03-05 10:50:48.044508: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 10:50:48.265011: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 10:50:48.998010: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-05 10:50:49.061853: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/83 [01:05<1:28:52, 65.04s/epoch, loss=2.87, accuracy=0.397, val_loss=2.37, val_accuracy=0.318, lr=0.1]  2%|▏         | 2/83 [01:25<52:23, 38.80s/epoch, loss=1.47, accuracy=0.586, val_loss=2.36, val_accuracy=0.36, lr=0.1]     4%|▎         | 3/83 [01:45<40:21, 30.26s/epoch, loss=1.3, accuracy=0.667, val_loss=1.58, val_accuracy=0.571, lr=0.1]  5%|▍         | 4/83 [02:05<34:37, 26.30s/epoch, loss=1.25, accuracy=0.696, val_loss=2.06, val_accuracy=0.457, lr=0.1]  6%|▌         | 5/83 [02:25<31:13, 24.02s/epoch, loss=1.23, accuracy=0.709, val_loss=1.59, val_accuracy=0.604, lr=0.1]  7%|▋         | 6/83 [02:45<29:08, 22.71s/epoch, loss=1.22, accuracy=0.717, val_loss=1.91, val_accuracy=0.495, lr=0.1]  8%|▊         | 7/83 [03:06<27:43, 21.89s/epoch, loss=1.21, accuracy=0.725, val_loss=2.41, val_accuracy=0.411, lr=0.1] 10%|▉         | 8/83 [03:26<26:35, 21.27s/epoch, loss=1.21, accuracy=0.726, val_loss=1.38, val_accuracy=0.665, lr=0.1] 11%|█         | 9/83 [03:46<25:46, 20.89s/epoch, loss=1.2, accuracy=0.731, val_loss=1.93, val_accuracy=0.516, lr=0.1]  12%|█▏        | 10/83 [04:05<25:00, 20.56s/epoch, loss=1.21, accuracy=0.733, val_loss=3.17, val_accuracy=0.292, lr=0.1] 13%|█▎        | 11/83 [04:26<24:31, 20.43s/epoch, loss=1.2, accuracy=0.735, val_loss=1.96, val_accuracy=0.499, lr=0.1]  14%|█▍        | 12/83 [04:45<23:56, 20.23s/epoch, loss=1.19, accuracy=0.74, val_loss=1.63, val_accuracy=0.603, lr=0.1] 16%|█▌        | 13/83 [05:05<23:30, 20.15s/epoch, loss=1.19, accuracy=0.736, val_loss=2.46, val_accuracy=0.355, lr=0.0316] 17%|█▋        | 14/83 [05:25<23:00, 20.01s/epoch, loss=1.18, accuracy=0.74, val_loss=1.87, val_accuracy=0.525, lr=0.1]     18%|█▊        | 15/83 [05:45<22:38, 19.98s/epoch, loss=1.19, accuracy=0.74, val_loss=1.61, val_accuracy=0.601, lr=0.1] 19%|█▉        | 16/83 [06:05<22:18, 19.98s/epoch, loss=1.18, accuracy=0.741, val_loss=2.67, val_accuracy=0.382, lr=0.1] 20%|██        | 17/83 [06:25<21:56, 19.95s/epoch, loss=1.17, accuracy=0.745, val_loss=1.89, val_accuracy=0.505, lr=0.1] 22%|██▏       | 18/83 [06:45<21:37, 19.95s/epoch, loss=1.18, accuracy=0.745, val_loss=2.32, val_accuracy=0.459, lr=0.0316] 23%|██▎       | 19/83 [07:05<21:17, 19.96s/epoch, loss=1.17, accuracy=0.746, val_loss=2.5, val_accuracy=0.378, lr=0.1]     24%|██▍       | 20/83 [07:25<21:06, 20.10s/epoch, loss=1.17, accuracy=0.746, val_loss=1.41, val_accuracy=0.659, lr=0.1] 25%|██▌       | 21/83 [07:45<20:41, 20.02s/epoch, loss=1.17, accuracy=0.747, val_loss=3.25, val_accuracy=0.202, lr=0.1] 27%|██▋       | 22/83 [08:05<20:17, 19.95s/epoch, loss=1.17, accuracy=0.748, val_loss=1.95, val_accuracy=0.472, lr=0.1] 28%|██▊       | 23/83 [08:25<19:56, 19.94s/epoch, loss=1.17, accuracy=0.745, val_loss=2.54, val_accuracy=0.477, lr=0.0316] 29%|██▉       | 24/83 [08:45<19:36, 19.95s/epoch, loss=1.17, accuracy=0.748, val_loss=2.04, val_accuracy=0.532, lr=0.1]    30%|███       | 25/83 [09:05<19:17, 19.95s/epoch, loss=1.17, accuracy=0.747, val_loss=3.1, val_accuracy=0.301, lr=0.1]  31%|███▏      | 26/83 [09:25<18:59, 19.99s/epoch, loss=1.16, accuracy=0.75, val_loss=2.24, val_accuracy=0.451, lr=0.1] 33%|███▎      | 27/83 [09:45<18:36, 19.94s/epoch, loss=1.16, accuracy=0.75, val_loss=1.65, val_accuracy=0.612, lr=0.1] 34%|███▎      | 28/83 [10:04<18:12, 19.87s/epoch, loss=1.16, accuracy=0.752, val_loss=2.45, val_accuracy=0.488, lr=0.0316] 35%|███▍      | 29/83 [10:24<17:47, 19.77s/epoch, loss=1.16, accuracy=0.749, val_loss=1.7, val_accuracy=0.535, lr=0.1]     36%|███▌      | 30/83 [10:43<17:25, 19.73s/epoch, loss=1.16, accuracy=0.75, val_loss=2.07, val_accuracy=0.495, lr=0.1] 37%|███▋      | 31/83 [11:03<17:03, 19.69s/epoch, loss=1.16, accuracy=0.752, val_loss=1.58, val_accuracy=0.612, lr=0.1] 39%|███▊      | 32/83 [11:23<16:45, 19.72s/epoch, loss=1.16, accuracy=0.75, val_loss=1.29, val_accuracy=0.709, lr=0.1]  40%|███▉      | 33/83 [11:42<16:25, 19.71s/epoch, loss=1.15, accuracy=0.752, val_loss=2.33, val_accuracy=0.425, lr=0.1] 41%|████      | 34/83 [12:02<16:05, 19.71s/epoch, loss=1.16, accuracy=0.752, val_loss=2.08, val_accuracy=0.514, lr=0.1] 42%|████▏     | 35/83 [12:22<15:46, 19.71s/epoch, loss=1.16, accuracy=0.752, val_loss=1.95, val_accuracy=0.545, lr=0.1] 43%|████▎     | 36/83 [12:42<15:29, 19.79s/epoch, loss=1.15, accuracy=0.753, val_loss=1.96, val_accuracy=0.479, lr=0.1] 45%|████▍     | 37/83 [13:01<15:07, 19.72s/epoch, loss=1.16, accuracy=0.749, val_loss=2.4, val_accuracy=0.378, lr=0.0316] 46%|████▌     | 38/83 [13:21<14:49, 19.76s/epoch, loss=1.14, accuracy=0.753, val_loss=1.86, val_accuracy=0.499, lr=0.1]   47%|████▋     | 39/83 [13:41<14:30, 19.78s/epoch, loss=1.15, accuracy=0.752, val_loss=1.58, val_accuracy=0.607, lr=0.1] 48%|████▊     | 40/83 [14:01<14:09, 19.76s/epoch, loss=1.16, accuracy=0.752, val_loss=2.43, val_accuracy=0.377, lr=0.1] 49%|████▉     | 41/83 [14:20<13:48, 19.73s/epoch, loss=1.15, accuracy=0.754, val_loss=1.81, val_accuracy=0.538, lr=0.1] 51%|█████     | 42/83 [14:40<13:29, 19.73s/epoch, loss=1.15, accuracy=0.752, val_loss=2.66, val_accuracy=0.328, lr=0.0316] 52%|█████▏    | 43/83 [15:00<13:10, 19.77s/epoch, loss=1.14, accuracy=0.755, val_loss=1.79, val_accuracy=0.496, lr=0.1]    53%|█████▎    | 44/83 [15:20<12:51, 19.77s/epoch, loss=1.15, accuracy=0.755, val_loss=2.75, val_accuracy=0.375, lr=0.1] 54%|█████▍    | 45/83 [15:40<12:31, 19.78s/epoch, loss=1.14, accuracy=0.757, val_loss=1.91, val_accuracy=0.498, lr=0.1] 55%|█████▌    | 46/83 [15:59<12:11, 19.77s/epoch, loss=1.15, accuracy=0.754, val_loss=2.09, val_accuracy=0.51, lr=0.1]  57%|█████▋    | 47/83 [16:19<11:53, 19.81s/epoch, loss=1.14, accuracy=0.754, val_loss=1.72, val_accuracy=0.594, lr=0.0316] 58%|█████▊    | 48/83 [16:39<11:35, 19.87s/epoch, loss=1.14, accuracy=0.752, val_loss=2.45, val_accuracy=0.442, lr=0.1]    59%|█████▉    | 49/83 [16:59<11:16, 19.88s/epoch, loss=1.13, accuracy=0.756, val_loss=1.33, val_accuracy=0.679, lr=0.1] 60%|██████    | 50/83 [17:19<10:56, 19.88s/epoch, loss=1.15, accuracy=0.754, val_loss=3.12, val_accuracy=0.377, lr=0.1] 61%|██████▏   | 51/83 [17:39<10:34, 19.84s/epoch, loss=1.14, accuracy=0.755, val_loss=1.52, val_accuracy=0.632, lr=0.1] 63%|██████▎   | 52/83 [17:59<10:16, 19.88s/epoch, loss=1.14, accuracy=0.756, val_loss=1.76, val_accuracy=0.582, lr=0.0316] 64%|██████▍   | 53/83 [18:19<09:57, 19.91s/epoch, loss=1.14, accuracy=0.753, val_loss=1.54, val_accuracy=0.615, lr=0.1]    65%|██████▌   | 54/83 [18:39<09:40, 20.00s/epoch, loss=1.13, accuracy=0.757, val_loss=1.39, val_accuracy=0.663, lr=0.1] 66%|██████▋   | 55/83 [19:00<09:26, 20.23s/epoch, loss=1.14, accuracy=0.755, val_loss=1.85, val_accuracy=0.533, lr=0.1] 67%|██████▋   | 56/83 [19:20<09:07, 20.27s/epoch, loss=1.14, accuracy=0.754, val_loss=2, val_accuracy=0.546, lr=0.1]    69%|██████▊   | 57/83 [19:40<08:46, 20.25s/epoch, loss=1.14, accuracy=0.754, val_loss=1.63, val_accuracy=0.581, lr=0.0316] 70%|██████▉   | 58/83 [20:00<08:24, 20.20s/epoch, loss=1.13, accuracy=0.756, val_loss=1.73, val_accuracy=0.588, lr=0.1]    71%|███████   | 59/83 [20:20<08:02, 20.09s/epoch, loss=1.14, accuracy=0.755, val_loss=1.59, val_accuracy=0.611, lr=0.1] 72%|███████▏  | 60/83 [20:40<07:42, 20.09s/epoch, loss=1.14, accuracy=0.753, val_loss=1.71, val_accuracy=0.564, lr=0.1] 73%|███████▎  | 61/83 [21:00<07:21, 20.07s/epoch, loss=1.13, accuracy=0.755, val_loss=2.74, val_accuracy=0.4, lr=0.1]   75%|███████▍  | 62/83 [21:20<07:01, 20.06s/epoch, loss=1.14, accuracy=0.758, val_loss=1.96, val_accuracy=0.503, lr=0.0316] 76%|███████▌  | 63/83 [21:40<06:39, 19.98s/epoch, loss=1.13, accuracy=0.758, val_loss=2.85, val_accuracy=0.324, lr=0.1]    77%|███████▋  | 64/83 [22:00<06:19, 19.96s/epoch, loss=1.14, accuracy=0.757, val_loss=2.05, val_accuracy=0.451, lr=0.1] 78%|███████▊  | 65/83 [22:20<05:58, 19.93s/epoch, loss=1.14, accuracy=0.756, val_loss=2.05, val_accuracy=0.527, lr=0.1] 80%|███████▉  | 66/83 [22:40<05:38, 19.92s/epoch, loss=1.13, accuracy=0.757, val_loss=2.16, val_accuracy=0.429, lr=0.1] 81%|████████  | 67/83 [23:00<05:18, 19.93s/epoch, loss=1.13, accuracy=0.756, val_loss=1.61, val_accuracy=0.597, lr=0.0316] 82%|████████▏ | 68/83 [23:20<04:58, 19.90s/epoch, loss=1.13, accuracy=0.76, val_loss=1.74, val_accuracy=0.602, lr=0.1]     83%|████████▎ | 69/83 [23:40<04:38, 19.91s/epoch, loss=1.13, accuracy=0.759, val_loss=1.54, val_accuracy=0.626, lr=0.1] 84%|████████▍ | 70/83 [24:00<04:19, 19.98s/epoch, loss=1.13, accuracy=0.757, val_loss=1.49, val_accuracy=0.647, lr=0.1] 86%|████████▌ | 71/83 [24:20<03:59, 19.98s/epoch, loss=1.14, accuracy=0.759, val_loss=1.68, val_accuracy=0.603, lr=0.1] 87%|████████▋ | 72/83 [24:40<03:39, 19.92s/epoch, loss=1.13, accuracy=0.758, val_loss=1.92, val_accuracy=0.51, lr=0.0316] 88%|████████▊ | 73/83 [24:59<03:19, 19.91s/epoch, loss=1.13, accuracy=0.758, val_loss=1.71, val_accuracy=0.586, lr=0.1]   89%|████████▉ | 74/83 [25:19<02:59, 19.89s/epoch, loss=1.13, accuracy=0.758, val_loss=1.54, val_accuracy=0.606, lr=0.1] 90%|█████████ | 75/83 [25:39<02:38, 19.86s/epoch, loss=1.12, accuracy=0.757, val_loss=1.47, val_accuracy=0.649, lr=0.1] 92%|█████████▏| 76/83 [25:59<02:19, 19.87s/epoch, loss=1.13, accuracy=0.758, val_loss=1.55, val_accuracy=0.615, lr=0.1] 93%|█████████▎| 77/83 [26:19<01:59, 19.92s/epoch, loss=1.12, accuracy=0.759, val_loss=1.59, val_accuracy=0.601, lr=0.0316] 94%|█████████▍| 78/83 [26:39<01:39, 19.92s/epoch, loss=1.13, accuracy=0.755, val_loss=4.12, val_accuracy=0.339, lr=0.1]    95%|█████████▌| 79/83 [26:59<01:19, 19.91s/epoch, loss=1.13, accuracy=0.755, val_loss=1.72, val_accuracy=0.553, lr=0.1] 96%|█████████▋| 80/83 [27:19<00:59, 19.89s/epoch, loss=1.13, accuracy=0.758, val_loss=1.98, val_accuracy=0.548, lr=0.1] 98%|█████████▊| 81/83 [27:38<00:39, 19.85s/epoch, loss=1.13, accuracy=0.758, val_loss=1.74, val_accuracy=0.566, lr=0.1] 99%|█████████▉| 82/83 [27:58<00:19, 19.85s/epoch, loss=0.913, accuracy=0.82, val_loss=0.866, val_accuracy=0.817, lr=0.01]100%|██████████| 83/83 [28:18<00:00, 19.81s/epoch, loss=0.735, accuracy=0.85, val_loss=0.761, val_accuracy=0.83, lr=0.01] 100%|██████████| 83/83 [28:18<00:00, 20.46s/epoch, loss=0.735, accuracy=0.85, val_loss=0.761, val_accuracy=0.83, lr=0.01]
Using real-time data augmentation.
Test score: 0.7612981796264648
Test accuracy: 0.8299999833106995


* * * Run SGD for ID = 18_4. * * *


2024-03-05 11:19:08.169703: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 11:19:10.785700: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 11:19:10.786954: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-05 11:19:10.824837: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-03-05 11:19:10.824881: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 11:19:10.827915: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 11:19:10.827982: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 11:19:10.830099: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 11:19:10.830729: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 11:19:10.833046: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 11:19:10.834432: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 11:19:10.839118: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 11:19:10.839803: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 11:19:10.839924: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 11:19:12.134555: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-05 11:19:12.135664: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 11:19:12.136390: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-03-05 11:19:12.136423: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 11:19:12.136462: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 11:19:12.136488: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 11:19:12.136504: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 11:19:12.136522: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 11:19:12.136538: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 11:19:12.136555: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 11:19:12.136571: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 11:19:12.137014: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 11:19:12.137061: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 11:19:12.850140: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-05 11:19:12.850196: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-05 11:19:12.850205: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-05 11:19:12.851095: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': '18_04', 'seed': 4, 'out_folder': 'results/epoch_budget', 'batch_size': 128, 'epochs': 83, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'bootstrapping': False, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/83 [00:00<?, ?epoch/s]2024-03-05 11:19:13.717180: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-05 11:19:13.729118: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600020000 Hz
2024-03-05 11:19:15.731594: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 11:19:15.944704: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 11:19:16.752492: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-05 11:19:16.819922: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/83 [01:06<1:31:17, 66.79s/epoch, loss=2.83, accuracy=0.404, val_loss=2.35, val_accuracy=0.297, lr=0.1]  2%|▏         | 2/83 [01:27<53:21, 39.53s/epoch, loss=1.47, accuracy=0.592, val_loss=1.96, val_accuracy=0.464, lr=0.1]    4%|▎         | 3/83 [01:47<40:51, 30.65s/epoch, loss=1.3, accuracy=0.671, val_loss=2.2, val_accuracy=0.486, lr=0.1]    5%|▍         | 4/83 [02:07<34:55, 26.53s/epoch, loss=1.25, accuracy=0.7, val_loss=3.82, val_accuracy=0.267, lr=0.1]  6%|▌         | 5/83 [02:27<31:27, 24.20s/epoch, loss=1.23, accuracy=0.715, val_loss=3.12, val_accuracy=0.383, lr=0.1]  7%|▋         | 6/83 [02:47<29:18, 22.83s/epoch, loss=1.21, accuracy=0.723, val_loss=1.66, val_accuracy=0.585, lr=0.1]  8%|▊         | 7/83 [03:07<27:48, 21.96s/epoch, loss=1.2, accuracy=0.729, val_loss=1.82, val_accuracy=0.505, lr=0.1]  10%|▉         | 8/83 [03:27<26:39, 21.32s/epoch, loss=1.2, accuracy=0.734, val_loss=3.55, val_accuracy=0.14, lr=0.1]  11%|█         | 9/83 [03:47<25:47, 20.91s/epoch, loss=1.19, accuracy=0.731, val_loss=2.18, val_accuracy=0.449, lr=0.1] 12%|█▏        | 10/83 [04:08<25:12, 20.72s/epoch, loss=1.18, accuracy=0.738, val_loss=2.5, val_accuracy=0.476, lr=0.1] 13%|█▎        | 11/83 [04:28<24:32, 20.45s/epoch, loss=1.18, accuracy=0.739, val_loss=1.55, val_accuracy=0.617, lr=0.1] 14%|█▍        | 12/83 [04:48<24:02, 20.31s/epoch, loss=1.18, accuracy=0.742, val_loss=2.1, val_accuracy=0.493, lr=0.1]  16%|█▌        | 13/83 [05:08<23:35, 20.22s/epoch, loss=1.18, accuracy=0.743, val_loss=1.67, val_accuracy=0.573, lr=0.1] 17%|█▋        | 14/83 [05:28<23:14, 20.21s/epoch, loss=1.17, accuracy=0.744, val_loss=2.64, val_accuracy=0.313, lr=0.1] 18%|█▊        | 15/83 [05:48<22:45, 20.09s/epoch, loss=1.16, accuracy=0.745, val_loss=2.21, val_accuracy=0.45, lr=0.1]  19%|█▉        | 16/83 [06:07<22:22, 20.04s/epoch, loss=1.17, accuracy=0.744, val_loss=2.71, val_accuracy=0.448, lr=0.0316] 20%|██        | 17/83 [06:28<22:03, 20.05s/epoch, loss=1.15, accuracy=0.747, val_loss=2.34, val_accuracy=0.39, lr=0.1]     22%|██▏       | 18/83 [06:48<21:45, 20.08s/epoch, loss=1.16, accuracy=0.747, val_loss=1.84, val_accuracy=0.54, lr=0.1] 23%|██▎       | 19/83 [07:08<21:29, 20.15s/epoch, loss=1.16, accuracy=0.748, val_loss=1.62, val_accuracy=0.578, lr=0.1] 24%|██▍       | 20/83 [07:28<21:10, 20.17s/epoch, loss=1.15, accuracy=0.75, val_loss=2.12, val_accuracy=0.479, lr=0.1]  25%|██▌       | 21/83 [07:49<20:53, 20.22s/epoch, loss=1.15, accuracy=0.749, val_loss=2.95, val_accuracy=0.41, lr=0.0316] 27%|██▋       | 22/83 [08:09<20:32, 20.21s/epoch, loss=1.16, accuracy=0.753, val_loss=1.71, val_accuracy=0.529, lr=0.1]   28%|██▊       | 23/83 [08:29<20:14, 20.23s/epoch, loss=1.15, accuracy=0.75, val_loss=1.77, val_accuracy=0.562, lr=0.1]  29%|██▉       | 24/83 [08:49<19:57, 20.29s/epoch, loss=1.15, accuracy=0.749, val_loss=2.13, val_accuracy=0.426, lr=0.1] 30%|███       | 25/83 [09:10<19:40, 20.35s/epoch, loss=1.15, accuracy=0.75, val_loss=2.2, val_accuracy=0.458, lr=0.1]   31%|███▏      | 26/83 [09:30<19:21, 20.37s/epoch, loss=1.15, accuracy=0.754, val_loss=2.49, val_accuracy=0.34, lr=0.0316] 33%|███▎      | 27/83 [09:51<18:58, 20.33s/epoch, loss=1.14, accuracy=0.755, val_loss=2.8, val_accuracy=0.351, lr=0.1]    34%|███▎      | 28/83 [10:11<18:37, 20.32s/epoch, loss=1.14, accuracy=0.755, val_loss=1.75, val_accuracy=0.554, lr=0.1] 35%|███▍      | 29/83 [10:31<18:18, 20.34s/epoch, loss=1.14, accuracy=0.754, val_loss=5.1, val_accuracy=0.253, lr=0.1]  36%|███▌      | 30/83 [10:51<17:55, 20.30s/epoch, loss=1.14, accuracy=0.755, val_loss=4.03, val_accuracy=0.321, lr=0.1] 37%|███▋      | 31/83 [11:12<17:36, 20.31s/epoch, loss=1.14, accuracy=0.753, val_loss=4.01, val_accuracy=0.171, lr=0.0316] 39%|███▊      | 32/83 [11:32<17:17, 20.34s/epoch, loss=1.13, accuracy=0.755, val_loss=2.82, val_accuracy=0.284, lr=0.1]    40%|███▉      | 33/83 [11:53<16:56, 20.34s/epoch, loss=1.14, accuracy=0.754, val_loss=1.67, val_accuracy=0.576, lr=0.1] 41%|████      | 34/83 [12:13<16:34, 20.30s/epoch, loss=1.14, accuracy=0.753, val_loss=2.05, val_accuracy=0.467, lr=0.1] 42%|████▏     | 35/83 [12:33<16:12, 20.26s/epoch, loss=1.14, accuracy=0.754, val_loss=1.6, val_accuracy=0.598, lr=0.1]  43%|████▎     | 36/83 [12:53<15:50, 20.23s/epoch, loss=1.14, accuracy=0.757, val_loss=2.62, val_accuracy=0.487, lr=0.0316] 45%|████▍     | 37/83 [13:13<15:30, 20.23s/epoch, loss=1.13, accuracy=0.755, val_loss=1.74, val_accuracy=0.554, lr=0.1]    46%|████▌     | 38/83 [13:34<15:14, 20.32s/epoch, loss=1.13, accuracy=0.758, val_loss=1.86, val_accuracy=0.557, lr=0.1] 47%|████▋     | 39/83 [13:54<14:54, 20.34s/epoch, loss=1.13, accuracy=0.756, val_loss=1.5, val_accuracy=0.645, lr=0.1]  48%|████▊     | 40/83 [14:15<14:34, 20.33s/epoch, loss=1.13, accuracy=0.756, val_loss=1.82, val_accuracy=0.58, lr=0.1] 49%|████▉     | 41/83 [14:35<14:13, 20.31s/epoch, loss=1.13, accuracy=0.757, val_loss=2.11, val_accuracy=0.404, lr=0.1] 51%|█████     | 42/83 [14:55<13:50, 20.26s/epoch, loss=1.13, accuracy=0.758, val_loss=2.6, val_accuracy=0.28, lr=0.1]   52%|█████▏    | 43/83 [15:15<13:30, 20.25s/epoch, loss=1.13, accuracy=0.758, val_loss=2.28, val_accuracy=0.383, lr=0.1] 53%|█████▎    | 44/83 [15:36<13:12, 20.33s/epoch, loss=1.13, accuracy=0.757, val_loss=2.69, val_accuracy=0.389, lr=0.0316] 54%|█████▍    | 45/83 [15:56<12:52, 20.32s/epoch, loss=1.13, accuracy=0.756, val_loss=3.1, val_accuracy=0.216, lr=0.1]     55%|█████▌    | 46/83 [16:16<12:30, 20.28s/epoch, loss=1.12, accuracy=0.756, val_loss=2.11, val_accuracy=0.46, lr=0.1] 57%|█████▋    | 47/83 [16:36<12:09, 20.25s/epoch, loss=1.12, accuracy=0.758, val_loss=2.61, val_accuracy=0.414, lr=0.1] 58%|█████▊    | 48/83 [16:57<11:48, 20.25s/epoch, loss=1.13, accuracy=0.757, val_loss=2.76, val_accuracy=0.359, lr=0.1] 59%|█████▉    | 49/83 [17:17<11:27, 20.22s/epoch, loss=1.12, accuracy=0.76, val_loss=1.7, val_accuracy=0.568, lr=0.0316] 60%|██████    | 50/83 [17:37<11:06, 20.21s/epoch, loss=1.12, accuracy=0.757, val_loss=1.95, val_accuracy=0.536, lr=0.1]  61%|██████▏   | 51/83 [17:57<10:44, 20.13s/epoch, loss=1.13, accuracy=0.756, val_loss=1.94, val_accuracy=0.476, lr=0.1] 63%|██████▎   | 52/83 [18:17<10:24, 20.15s/epoch, loss=1.12, accuracy=0.758, val_loss=2.03, val_accuracy=0.507, lr=0.1] 64%|██████▍   | 53/83 [18:37<10:05, 20.20s/epoch, loss=1.12, accuracy=0.759, val_loss=3.03, val_accuracy=0.29, lr=0.1]  65%|██████▌   | 54/83 [18:58<09:46, 20.21s/epoch, loss=1.12, accuracy=0.757, val_loss=1.89, val_accuracy=0.539, lr=0.0316] 66%|██████▋   | 55/83 [19:18<09:25, 20.18s/epoch, loss=1.12, accuracy=0.757, val_loss=1.95, val_accuracy=0.454, lr=0.1]    67%|██████▋   | 56/83 [19:38<09:03, 20.14s/epoch, loss=1.12, accuracy=0.758, val_loss=1.67, val_accuracy=0.552, lr=0.1] 69%|██████▊   | 57/83 [19:58<08:43, 20.13s/epoch, loss=1.12, accuracy=0.761, val_loss=2.34, val_accuracy=0.433, lr=0.1] 70%|██████▉   | 58/83 [20:18<08:22, 20.11s/epoch, loss=1.12, accuracy=0.761, val_loss=1.95, val_accuracy=0.511, lr=0.1] 71%|███████   | 59/83 [20:38<08:02, 20.10s/epoch, loss=1.12, accuracy=0.759, val_loss=1.8, val_accuracy=0.582, lr=0.0316] 72%|███████▏  | 60/83 [20:58<07:42, 20.09s/epoch, loss=1.11, accuracy=0.76, val_loss=2.43, val_accuracy=0.326, lr=0.1]    73%|███████▎  | 61/83 [21:18<07:22, 20.10s/epoch, loss=1.12, accuracy=0.76, val_loss=1.86, val_accuracy=0.521, lr=0.1] 75%|███████▍  | 62/83 [21:38<07:01, 20.09s/epoch, loss=1.12, accuracy=0.758, val_loss=1.98, val_accuracy=0.526, lr=0.1] 76%|███████▌  | 63/83 [21:58<06:41, 20.07s/epoch, loss=1.12, accuracy=0.758, val_loss=1.98, val_accuracy=0.514, lr=0.1] 77%|███████▋  | 64/83 [22:18<06:21, 20.06s/epoch, loss=1.13, accuracy=0.757, val_loss=1.63, val_accuracy=0.59, lr=0.0316] 78%|███████▊  | 65/83 [22:38<06:01, 20.07s/epoch, loss=1.11, accuracy=0.759, val_loss=1.77, val_accuracy=0.549, lr=0.1]   80%|███████▉  | 66/83 [22:58<05:40, 20.05s/epoch, loss=1.12, accuracy=0.761, val_loss=2.07, val_accuracy=0.497, lr=0.1] 81%|████████  | 67/83 [23:18<05:20, 20.02s/epoch, loss=1.12, accuracy=0.76, val_loss=2.08, val_accuracy=0.497, lr=0.1]  82%|████████▏ | 68/83 [23:38<05:00, 20.01s/epoch, loss=1.12, accuracy=0.759, val_loss=1.5, val_accuracy=0.627, lr=0.1] 83%|████████▎ | 69/83 [23:58<04:40, 20.00s/epoch, loss=1.11, accuracy=0.761, val_loss=1.52, val_accuracy=0.624, lr=0.0316] 84%|████████▍ | 70/83 [24:18<04:20, 20.02s/epoch, loss=1.11, accuracy=0.76, val_loss=2.03, val_accuracy=0.53, lr=0.1]      86%|████████▌ | 71/83 [24:38<03:59, 19.99s/epoch, loss=1.11, accuracy=0.759, val_loss=1.64, val_accuracy=0.559, lr=0.1] 87%|████████▋ | 72/83 [24:58<03:39, 20.00s/epoch, loss=1.11, accuracy=0.759, val_loss=2.48, val_accuracy=0.47, lr=0.1]  88%|████████▊ | 73/83 [25:18<03:20, 20.00s/epoch, loss=1.11, accuracy=0.761, val_loss=2.15, val_accuracy=0.42, lr=0.1] 89%|████████▉ | 74/83 [25:38<02:59, 19.92s/epoch, loss=1.11, accuracy=0.758, val_loss=2.58, val_accuracy=0.416, lr=0.0316] 90%|█████████ | 75/83 [25:58<02:40, 20.04s/epoch, loss=1.11, accuracy=0.761, val_loss=2.13, val_accuracy=0.504, lr=0.1]    92%|█████████▏| 76/83 [26:19<02:20, 20.07s/epoch, loss=1.11, accuracy=0.758, val_loss=2.85, val_accuracy=0.403, lr=0.1] 93%|█████████▎| 77/83 [26:39<02:00, 20.07s/epoch, loss=1.11, accuracy=0.761, val_loss=2.12, val_accuracy=0.398, lr=0.1] 94%|█████████▍| 78/83 [26:59<01:40, 20.18s/epoch, loss=1.12, accuracy=0.76, val_loss=2.17, val_accuracy=0.413, lr=0.1]  95%|█████████▌| 79/83 [27:19<01:20, 20.17s/epoch, loss=1.11, accuracy=0.761, val_loss=4.38, val_accuracy=0.269, lr=0.0316] 96%|█████████▋| 80/83 [27:39<01:00, 20.15s/epoch, loss=1.12, accuracy=0.761, val_loss=1.92, val_accuracy=0.581, lr=0.1]    98%|█████████▊| 81/83 [28:00<00:40, 20.16s/epoch, loss=1.11, accuracy=0.761, val_loss=1.83, val_accuracy=0.502, lr=0.1] 99%|█████████▉| 82/83 [28:20<00:20, 20.16s/epoch, loss=0.899, accuracy=0.818, val_loss=0.882, val_accuracy=0.812, lr=0.01]100%|██████████| 83/83 [28:40<00:00, 20.13s/epoch, loss=0.719, accuracy=0.851, val_loss=0.817, val_accuracy=0.808, lr=0.01]100%|██████████| 83/83 [28:40<00:00, 20.73s/epoch, loss=0.719, accuracy=0.851, val_loss=0.817, val_accuracy=0.808, lr=0.01]
Using real-time data augmentation.
Test score: 0.8169727325439453
Test accuracy: 0.8082000017166138


* * * Run SGD for ID = 18_5. * * *


2024-03-05 11:47:57.548780: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 11:48:00.313603: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 11:48:00.314798: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-05 11:48:00.355573: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-03-05 11:48:00.355630: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 11:48:00.358762: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 11:48:00.358823: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 11:48:00.361205: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 11:48:00.362484: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 11:48:00.365040: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 11:48:00.366595: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 11:48:00.371479: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 11:48:00.372194: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 11:48:00.372305: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 11:48:01.675783: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-05 11:48:01.676810: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 11:48:01.678295: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-03-05 11:48:01.678329: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 11:48:01.678364: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 11:48:01.678389: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 11:48:01.678406: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 11:48:01.678423: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 11:48:01.678438: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 11:48:01.678454: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 11:48:01.678469: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 11:48:01.678892: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 11:48:01.678938: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 11:48:02.425057: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-05 11:48:02.425119: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-05 11:48:02.425128: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-05 11:48:02.426092: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': '18_05', 'seed': 5, 'out_folder': 'results/epoch_budget', 'batch_size': 128, 'epochs': 83, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'bootstrapping': False, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/83 [00:00<?, ?epoch/s]2024-03-05 11:48:03.342713: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-05 11:48:03.355155: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600020000 Hz
2024-03-05 11:48:05.461030: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 11:48:05.680700: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 11:48:06.419282: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-05 11:48:06.471291: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/83 [01:07<1:31:41, 67.09s/epoch, loss=2.88, accuracy=0.353, val_loss=1.95, val_accuracy=0.411, lr=0.1]  2%|▏         | 2/83 [01:27<53:48, 39.86s/epoch, loss=1.49, accuracy=0.567, val_loss=2, val_accuracy=0.444, lr=0.1]       4%|▎         | 3/83 [01:48<41:12, 30.91s/epoch, loss=1.31, accuracy=0.644, val_loss=2.23, val_accuracy=0.426, lr=0.1]  5%|▍         | 4/83 [02:08<35:07, 26.67s/epoch, loss=1.24, accuracy=0.688, val_loss=3.21, val_accuracy=0.217, lr=0.1]  6%|▌         | 5/83 [02:28<31:29, 24.22s/epoch, loss=1.22, accuracy=0.707, val_loss=3.48, val_accuracy=0.305, lr=0.1]  7%|▋         | 6/83 [02:48<29:22, 22.89s/epoch, loss=1.2, accuracy=0.716, val_loss=2.71, val_accuracy=0.406, lr=0.0316]  8%|▊         | 7/83 [03:08<27:50, 21.99s/epoch, loss=1.19, accuracy=0.725, val_loss=1.89, val_accuracy=0.582, lr=0.1]   10%|▉         | 8/83 [03:29<26:56, 21.55s/epoch, loss=1.19, accuracy=0.728, val_loss=2.17, val_accuracy=0.476, lr=0.1] 11%|█         | 9/83 [03:49<26:03, 21.13s/epoch, loss=1.18, accuracy=0.735, val_loss=2.04, val_accuracy=0.465, lr=0.1] 12%|█▏        | 10/83 [04:09<25:21, 20.85s/epoch, loss=1.18, accuracy=0.733, val_loss=2.03, val_accuracy=0.517, lr=0.1] 13%|█▎        | 11/83 [04:29<24:45, 20.63s/epoch, loss=1.17, accuracy=0.735, val_loss=1.59, val_accuracy=0.611, lr=0.1] 14%|█▍        | 12/83 [04:49<24:11, 20.45s/epoch, loss=1.18, accuracy=0.738, val_loss=1.53, val_accuracy=0.608, lr=0.1] 16%|█▌        | 13/83 [05:10<23:46, 20.38s/epoch, loss=1.17, accuracy=0.74, val_loss=2.27, val_accuracy=0.457, lr=0.1]  17%|█▋        | 14/83 [05:30<23:18, 20.27s/epoch, loss=1.16, accuracy=0.74, val_loss=1.59, val_accuracy=0.576, lr=0.1] 18%|█▊        | 15/83 [05:50<22:52, 20.19s/epoch, loss=1.16, accuracy=0.743, val_loss=2.24, val_accuracy=0.478, lr=0.1] 19%|█▉        | 16/83 [06:10<22:35, 20.23s/epoch, loss=1.16, accuracy=0.742, val_loss=3.71, val_accuracy=0.213, lr=0.1] 20%|██        | 17/83 [06:30<22:10, 20.16s/epoch, loss=1.16, accuracy=0.746, val_loss=1.9, val_accuracy=0.553, lr=0.0316] 22%|██▏       | 18/83 [06:50<21:44, 20.07s/epoch, loss=1.16, accuracy=0.745, val_loss=1.84, val_accuracy=0.536, lr=0.1]   23%|██▎       | 19/83 [07:10<21:25, 20.09s/epoch, loss=1.15, accuracy=0.745, val_loss=2.1, val_accuracy=0.505, lr=0.1]  24%|██▍       | 20/83 [07:30<21:04, 20.07s/epoch, loss=1.14, accuracy=0.747, val_loss=3.07, val_accuracy=0.352, lr=0.1] 25%|██▌       | 21/83 [07:50<20:43, 20.06s/epoch, loss=1.15, accuracy=0.747, val_loss=1.82, val_accuracy=0.569, lr=0.1] 27%|██▋       | 22/83 [08:10<20:22, 20.04s/epoch, loss=1.14, accuracy=0.748, val_loss=2.29, val_accuracy=0.469, lr=0.0316] 28%|██▊       | 23/83 [08:30<20:00, 20.01s/epoch, loss=1.15, accuracy=0.747, val_loss=2.64, val_accuracy=0.366, lr=0.1]    29%|██▉       | 24/83 [08:50<19:42, 20.04s/epoch, loss=1.14, accuracy=0.747, val_loss=2.64, val_accuracy=0.415, lr=0.1] 30%|███       | 25/83 [09:10<19:21, 20.03s/epoch, loss=1.14, accuracy=0.75, val_loss=2.68, val_accuracy=0.339, lr=0.1]  31%|███▏      | 26/83 [09:30<19:01, 20.02s/epoch, loss=1.13, accuracy=0.752, val_loss=1.61, val_accuracy=0.595, lr=0.1] 33%|███▎      | 27/83 [09:50<18:48, 20.14s/epoch, loss=1.13, accuracy=0.754, val_loss=1.99, val_accuracy=0.558, lr=0.0316] 34%|███▎      | 28/83 [10:10<18:26, 20.11s/epoch, loss=1.14, accuracy=0.751, val_loss=2.22, val_accuracy=0.463, lr=0.1]    35%|███▍      | 29/83 [10:31<18:06, 20.12s/epoch, loss=1.14, accuracy=0.752, val_loss=1.54, val_accuracy=0.605, lr=0.1] 36%|███▌      | 30/83 [10:51<17:43, 20.06s/epoch, loss=1.13, accuracy=0.751, val_loss=1.77, val_accuracy=0.542, lr=0.1] 37%|███▋      | 31/83 [11:10<17:19, 20.00s/epoch, loss=1.13, accuracy=0.754, val_loss=3.78, val_accuracy=0.382, lr=0.1] 39%|███▊      | 32/83 [11:30<17:00, 20.02s/epoch, loss=1.13, accuracy=0.753, val_loss=2.4, val_accuracy=0.46, lr=0.0316] 40%|███▉      | 33/83 [11:50<16:39, 19.98s/epoch, loss=1.13, accuracy=0.756, val_loss=2.6, val_accuracy=0.326, lr=0.1]   41%|████      | 34/83 [12:10<16:17, 19.95s/epoch, loss=1.12, accuracy=0.753, val_loss=1.92, val_accuracy=0.479, lr=0.1] 42%|████▏     | 35/83 [12:30<15:57, 19.94s/epoch, loss=1.12, accuracy=0.755, val_loss=1.79, val_accuracy=0.544, lr=0.1] 43%|████▎     | 36/83 [12:50<15:41, 20.03s/epoch, loss=1.12, accuracy=0.754, val_loss=3.77, val_accuracy=0.358, lr=0.1] 45%|████▍     | 37/83 [13:10<15:19, 19.98s/epoch, loss=1.12, accuracy=0.754, val_loss=3.78, val_accuracy=0.328, lr=0.0316] 46%|████▌     | 38/83 [13:30<14:55, 19.90s/epoch, loss=1.12, accuracy=0.756, val_loss=1.73, val_accuracy=0.573, lr=0.1]    47%|████▋     | 39/83 [13:50<14:34, 19.87s/epoch, loss=1.12, accuracy=0.755, val_loss=1.82, val_accuracy=0.552, lr=0.1] 48%|████▊     | 40/83 [14:09<14:11, 19.80s/epoch, loss=1.11, accuracy=0.755, val_loss=2.23, val_accuracy=0.421, lr=0.1] 49%|████▉     | 41/83 [14:29<13:52, 19.82s/epoch, loss=1.12, accuracy=0.754, val_loss=2.09, val_accuracy=0.533, lr=0.1] 51%|█████     | 42/83 [14:49<13:34, 19.87s/epoch, loss=1.12, accuracy=0.755, val_loss=1.92, val_accuracy=0.493, lr=0.0316] 52%|█████▏    | 43/83 [15:09<13:16, 19.92s/epoch, loss=1.12, accuracy=0.757, val_loss=2.55, val_accuracy=0.435, lr=0.1]    53%|█████▎    | 44/83 [15:29<12:57, 19.93s/epoch, loss=1.12, accuracy=0.756, val_loss=2.08, val_accuracy=0.512, lr=0.1] 54%|█████▍    | 45/83 [15:50<12:41, 20.05s/epoch, loss=1.11, accuracy=0.758, val_loss=2.14, val_accuracy=0.436, lr=0.1] 55%|█████▌    | 46/83 [16:10<12:21, 20.05s/epoch, loss=1.12, accuracy=0.756, val_loss=1.94, val_accuracy=0.512, lr=0.1] 57%|█████▋    | 47/83 [16:30<12:01, 20.05s/epoch, loss=1.12, accuracy=0.758, val_loss=1.96, val_accuracy=0.517, lr=0.0316] 58%|█████▊    | 48/83 [16:50<11:44, 20.14s/epoch, loss=1.11, accuracy=0.759, val_loss=1.93, val_accuracy=0.488, lr=0.1]    59%|█████▉    | 49/83 [17:10<11:23, 20.11s/epoch, loss=1.1, accuracy=0.758, val_loss=2.09, val_accuracy=0.42, lr=0.1]   60%|██████    | 50/83 [17:30<11:03, 20.12s/epoch, loss=1.11, accuracy=0.756, val_loss=2.06, val_accuracy=0.491, lr=0.1] 61%|██████▏   | 51/83 [17:50<10:42, 20.09s/epoch, loss=1.11, accuracy=0.759, val_loss=1.91, val_accuracy=0.482, lr=0.1] 63%|██████▎   | 52/83 [18:10<10:21, 20.04s/epoch, loss=1.11, accuracy=0.759, val_loss=1.64, val_accuracy=0.57, lr=0.0316] 64%|██████▍   | 53/83 [18:30<10:01, 20.05s/epoch, loss=1.11, accuracy=0.757, val_loss=3.29, val_accuracy=0.386, lr=0.1]   65%|██████▌   | 54/83 [18:51<09:44, 20.17s/epoch, loss=1.11, accuracy=0.758, val_loss=3.53, val_accuracy=0.316, lr=0.1] 66%|██████▋   | 55/83 [19:11<09:25, 20.19s/epoch, loss=1.11, accuracy=0.76, val_loss=3.22, val_accuracy=0.371, lr=0.1]  67%|██████▋   | 56/83 [19:31<09:05, 20.21s/epoch, loss=1.1, accuracy=0.76, val_loss=2.64, val_accuracy=0.405, lr=0.1]  69%|██████▊   | 57/83 [19:52<08:46, 20.26s/epoch, loss=1.11, accuracy=0.757, val_loss=1.69, val_accuracy=0.561, lr=0.0316] 70%|██████▉   | 58/83 [20:12<08:25, 20.21s/epoch, loss=1.1, accuracy=0.76, val_loss=1.59, val_accuracy=0.598, lr=0.1]      71%|███████   | 59/83 [20:32<08:04, 20.19s/epoch, loss=1.11, accuracy=0.757, val_loss=1.95, val_accuracy=0.448, lr=0.1] 72%|███████▏  | 60/83 [20:52<07:44, 20.17s/epoch, loss=1.1, accuracy=0.758, val_loss=2.59, val_accuracy=0.41, lr=0.1]   73%|███████▎  | 61/83 [21:12<07:23, 20.14s/epoch, loss=1.1, accuracy=0.761, val_loss=1.87, val_accuracy=0.507, lr=0.1] 75%|███████▍  | 62/83 [21:32<07:02, 20.13s/epoch, loss=1.11, accuracy=0.757, val_loss=1.5, val_accuracy=0.62, lr=0.1]  76%|███████▌  | 63/83 [21:52<06:41, 20.08s/epoch, loss=1.1, accuracy=0.759, val_loss=1.86, val_accuracy=0.517, lr=0.1] 77%|███████▋  | 64/83 [22:12<06:22, 20.11s/epoch, loss=1.1, accuracy=0.762, val_loss=1.85, val_accuracy=0.502, lr=0.1] 78%|███████▊  | 65/83 [22:32<06:01, 20.08s/epoch, loss=1.1, accuracy=0.76, val_loss=2.25, val_accuracy=0.423, lr=0.1]  80%|███████▉  | 66/83 [22:52<05:41, 20.09s/epoch, loss=1.11, accuracy=0.758, val_loss=2.31, val_accuracy=0.348, lr=0.1] 81%|████████  | 67/83 [23:12<05:21, 20.09s/epoch, loss=1.1, accuracy=0.759, val_loss=2.61, val_accuracy=0.389, lr=0.0316] 82%|████████▏ | 68/83 [23:33<05:01, 20.10s/epoch, loss=1.1, accuracy=0.759, val_loss=1.48, val_accuracy=0.621, lr=0.1]    83%|████████▎ | 69/83 [23:53<04:41, 20.11s/epoch, loss=1.1, accuracy=0.758, val_loss=1.56, val_accuracy=0.605, lr=0.1] 84%|████████▍ | 70/83 [24:13<04:20, 20.06s/epoch, loss=1.1, accuracy=0.76, val_loss=1.63, val_accuracy=0.596, lr=0.1]  86%|████████▌ | 71/83 [24:33<04:00, 20.03s/epoch, loss=1.1, accuracy=0.759, val_loss=2.21, val_accuracy=0.39, lr=0.1] 87%|████████▋ | 72/83 [24:53<03:40, 20.07s/epoch, loss=1.11, accuracy=0.758, val_loss=3.24, val_accuracy=0.37, lr=0.1] 88%|████████▊ | 73/83 [25:13<03:20, 20.01s/epoch, loss=1.1, accuracy=0.758, val_loss=2.67, val_accuracy=0.311, lr=0.0316] 89%|████████▉ | 74/83 [25:32<02:59, 19.91s/epoch, loss=1.1, accuracy=0.762, val_loss=1.58, val_accuracy=0.597, lr=0.1]    90%|█████████ | 75/83 [25:52<02:39, 19.92s/epoch, loss=1.1, accuracy=0.758, val_loss=2.2, val_accuracy=0.46, lr=0.1]   92%|█████████▏| 76/83 [26:12<02:19, 19.98s/epoch, loss=1.11, accuracy=0.759, val_loss=2.02, val_accuracy=0.508, lr=0.1] 93%|█████████▎| 77/83 [26:32<01:59, 19.99s/epoch, loss=1.1, accuracy=0.76, val_loss=2.87, val_accuracy=0.373, lr=0.1]   94%|█████████▍| 78/83 [26:52<01:39, 20.00s/epoch, loss=1.11, accuracy=0.76, val_loss=1.4, val_accuracy=0.66, lr=0.1]  95%|█████████▌| 79/83 [27:12<01:19, 19.97s/epoch, loss=1.1, accuracy=0.761, val_loss=2.09, val_accuracy=0.512, lr=0.1] 96%|█████████▋| 80/83 [27:32<00:59, 19.97s/epoch, loss=1.1, accuracy=0.761, val_loss=2.04, val_accuracy=0.488, lr=0.1] 98%|█████████▊| 81/83 [27:52<00:39, 20.00s/epoch, loss=1.11, accuracy=0.761, val_loss=1.66, val_accuracy=0.585, lr=0.1] 99%|█████████▉| 82/83 [28:13<00:20, 20.10s/epoch, loss=0.893, accuracy=0.818, val_loss=0.896, val_accuracy=0.805, lr=0.01]100%|██████████| 83/83 [28:32<00:00, 20.02s/epoch, loss=0.721, accuracy=0.85, val_loss=0.75, val_accuracy=0.832, lr=0.01]  100%|██████████| 83/83 [28:32<00:00, 20.64s/epoch, loss=0.721, accuracy=0.85, val_loss=0.75, val_accuracy=0.832, lr=0.01]
Using real-time data augmentation.
Test score: 0.7502060532569885
Test accuracy: 0.8321999907493591


* * * Run SGD for ID = 18_6. * * *


2024-03-05 12:16:40.082510: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 12:16:42.666962: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 12:16:42.667948: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-05 12:16:42.707759: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-03-05 12:16:42.707873: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 12:16:42.710668: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 12:16:42.710713: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 12:16:42.712759: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 12:16:42.713358: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 12:16:42.715659: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 12:16:42.717104: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 12:16:42.721527: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 12:16:42.722135: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 12:16:42.722229: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 12:16:43.974329: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-05 12:16:43.974914: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 12:16:43.975637: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-03-05 12:16:43.975669: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 12:16:43.975707: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 12:16:43.975734: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 12:16:43.975750: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 12:16:43.975765: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 12:16:43.975782: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 12:16:43.975799: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 12:16:43.975816: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 12:16:43.977183: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 12:16:43.977217: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 12:16:44.654612: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-05 12:16:44.654667: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-05 12:16:44.654675: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-05 12:16:44.655571: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': '18_06', 'seed': 6, 'out_folder': 'results/epoch_budget', 'batch_size': 128, 'epochs': 83, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'bootstrapping': False, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/83 [00:00<?, ?epoch/s]2024-03-05 12:16:45.539046: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-05 12:16:45.539597: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600020000 Hz
2024-03-05 12:16:47.555362: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 12:16:47.761773: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 12:16:48.549314: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-05 12:16:48.612219: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/83 [01:02<1:25:30, 62.57s/epoch, loss=3.29, accuracy=0.316, val_loss=2.21, val_accuracy=0.291, lr=0.1]  2%|▏         | 2/83 [01:22<50:47, 37.62s/epoch, loss=1.6, accuracy=0.516, val_loss=2.22, val_accuracy=0.336, lr=0.1]     4%|▎         | 3/83 [01:42<39:24, 29.55s/epoch, loss=1.37, accuracy=0.624, val_loss=1.63, val_accuracy=0.549, lr=0.1]  5%|▍         | 4/83 [02:02<33:55, 25.76s/epoch, loss=1.29, accuracy=0.672, val_loss=1.96, val_accuracy=0.498, lr=0.1]  6%|▌         | 5/83 [02:22<30:43, 23.64s/epoch, loss=1.26, accuracy=0.692, val_loss=1.98, val_accuracy=0.457, lr=0.1]  7%|▋         | 6/83 [02:42<28:39, 22.33s/epoch, loss=1.23, accuracy=0.705, val_loss=1.51, val_accuracy=0.621, lr=0.1]  8%|▊         | 7/83 [03:02<27:18, 21.56s/epoch, loss=1.22, accuracy=0.712, val_loss=1.46, val_accuracy=0.653, lr=0.1] 10%|▉         | 8/83 [03:22<26:20, 21.07s/epoch, loss=1.22, accuracy=0.719, val_loss=2.32, val_accuracy=0.441, lr=0.1] 11%|█         | 9/83 [03:42<25:32, 20.71s/epoch, loss=1.21, accuracy=0.726, val_loss=2.36, val_accuracy=0.439, lr=0.1] 12%|█▏        | 10/83 [04:02<25:00, 20.56s/epoch, loss=1.2, accuracy=0.728, val_loss=1.71, val_accuracy=0.532, lr=0.1] 13%|█▎        | 11/83 [04:22<24:29, 20.40s/epoch, loss=1.2, accuracy=0.733, val_loss=1.68, val_accuracy=0.564, lr=0.1] 14%|█▍        | 12/83 [04:42<24:00, 20.29s/epoch, loss=1.19, accuracy=0.732, val_loss=1.87, val_accuracy=0.538, lr=0.0316] 16%|█▌        | 13/83 [05:02<23:36, 20.24s/epoch, loss=1.19, accuracy=0.735, val_loss=1.57, val_accuracy=0.583, lr=0.1]    17%|█▋        | 14/83 [05:22<23:13, 20.20s/epoch, loss=1.18, accuracy=0.737, val_loss=2.13, val_accuracy=0.422, lr=0.1] 18%|█▊        | 15/83 [05:42<22:49, 20.13s/epoch, loss=1.18, accuracy=0.738, val_loss=2.12, val_accuracy=0.466, lr=0.1] 19%|█▉        | 16/83 [06:02<22:26, 20.09s/epoch, loss=1.18, accuracy=0.74, val_loss=1.8, val_accuracy=0.57, lr=0.1]    20%|██        | 17/83 [06:22<22:03, 20.05s/epoch, loss=1.18, accuracy=0.739, val_loss=1.65, val_accuracy=0.584, lr=0.0316] 22%|██▏       | 18/83 [06:42<21:41, 20.03s/epoch, loss=1.17, accuracy=0.743, val_loss=1.49, val_accuracy=0.628, lr=0.1]    23%|██▎       | 19/83 [07:02<21:19, 20.00s/epoch, loss=1.16, accuracy=0.744, val_loss=1.56, val_accuracy=0.612, lr=0.1] 24%|██▍       | 20/83 [07:22<20:59, 20.00s/epoch, loss=1.17, accuracy=0.744, val_loss=1.79, val_accuracy=0.602, lr=0.1] 25%|██▌       | 21/83 [07:42<20:40, 20.00s/epoch, loss=1.16, accuracy=0.746, val_loss=1.73, val_accuracy=0.56, lr=0.1]  27%|██▋       | 22/83 [08:02<20:18, 19.98s/epoch, loss=1.16, accuracy=0.745, val_loss=2.67, val_accuracy=0.463, lr=0.0316] 28%|██▊       | 23/83 [08:22<19:59, 20.00s/epoch, loss=1.16, accuracy=0.747, val_loss=2.06, val_accuracy=0.461, lr=0.1]    29%|██▉       | 24/83 [08:42<19:39, 19.98s/epoch, loss=1.15, accuracy=0.75, val_loss=1.57, val_accuracy=0.608, lr=0.1]  30%|███       | 25/83 [09:02<19:15, 19.92s/epoch, loss=1.15, accuracy=0.75, val_loss=2.01, val_accuracy=0.503, lr=0.1] 31%|███▏      | 26/83 [09:21<18:51, 19.86s/epoch, loss=1.15, accuracy=0.75, val_loss=5.03, val_accuracy=0.211, lr=0.1] 33%|███▎      | 27/83 [09:41<18:30, 19.83s/epoch, loss=1.15, accuracy=0.751, val_loss=1.81, val_accuracy=0.552, lr=0.0316] 34%|███▎      | 28/83 [10:01<18:09, 19.81s/epoch, loss=1.14, accuracy=0.749, val_loss=2.36, val_accuracy=0.434, lr=0.1]    35%|███▍      | 29/83 [10:21<17:56, 19.93s/epoch, loss=1.15, accuracy=0.749, val_loss=1.67, val_accuracy=0.612, lr=0.1] 36%|███▌      | 30/83 [10:41<17:36, 19.93s/epoch, loss=1.15, accuracy=0.751, val_loss=2.01, val_accuracy=0.445, lr=0.1] 37%|███▋      | 31/83 [11:01<17:14, 19.90s/epoch, loss=1.14, accuracy=0.754, val_loss=2.26, val_accuracy=0.45, lr=0.1]  39%|███▊      | 32/83 [11:21<16:52, 19.86s/epoch, loss=1.14, accuracy=0.751, val_loss=1.81, val_accuracy=0.515, lr=0.0316] 40%|███▉      | 33/83 [11:40<16:29, 19.79s/epoch, loss=1.13, accuracy=0.753, val_loss=3.08, val_accuracy=0.306, lr=0.1]    41%|████      | 34/83 [12:00<16:09, 19.79s/epoch, loss=1.15, accuracy=0.75, val_loss=2.21, val_accuracy=0.44, lr=0.1]   42%|████▏     | 35/83 [12:20<15:47, 19.73s/epoch, loss=1.14, accuracy=0.754, val_loss=1.73, val_accuracy=0.566, lr=0.1] 43%|████▎     | 36/83 [12:39<15:27, 19.72s/epoch, loss=1.14, accuracy=0.751, val_loss=1.69, val_accuracy=0.589, lr=0.1] 45%|████▍     | 37/83 [12:59<15:10, 19.79s/epoch, loss=1.13, accuracy=0.754, val_loss=2.15, val_accuracy=0.525, lr=0.0316] 46%|████▌     | 38/83 [13:19<14:50, 19.78s/epoch, loss=1.13, accuracy=0.753, val_loss=2.27, val_accuracy=0.523, lr=0.1]    47%|████▋     | 39/83 [13:39<14:27, 19.72s/epoch, loss=1.13, accuracy=0.755, val_loss=1.95, val_accuracy=0.503, lr=0.1] 48%|████▊     | 40/83 [13:59<14:10, 19.79s/epoch, loss=1.14, accuracy=0.752, val_loss=2.01, val_accuracy=0.481, lr=0.1] 49%|████▉     | 41/83 [14:19<13:53, 19.85s/epoch, loss=1.13, accuracy=0.752, val_loss=1.53, val_accuracy=0.621, lr=0.1] 51%|█████     | 42/83 [14:39<13:35, 19.89s/epoch, loss=1.13, accuracy=0.756, val_loss=2.33, val_accuracy=0.338, lr=0.0316] 52%|█████▏    | 43/83 [14:59<13:15, 19.89s/epoch, loss=1.13, accuracy=0.755, val_loss=1.83, val_accuracy=0.566, lr=0.1]    53%|█████▎    | 44/83 [15:19<12:56, 19.91s/epoch, loss=1.13, accuracy=0.756, val_loss=3.01, val_accuracy=0.463, lr=0.1] 54%|█████▍    | 45/83 [15:39<12:37, 19.95s/epoch, loss=1.13, accuracy=0.756, val_loss=1.73, val_accuracy=0.591, lr=0.1] 55%|█████▌    | 46/83 [15:59<12:19, 19.99s/epoch, loss=1.13, accuracy=0.756, val_loss=3.14, val_accuracy=0.29, lr=0.1]  57%|█████▋    | 47/83 [16:18<11:54, 19.86s/epoch, loss=1.12, accuracy=0.756, val_loss=2.98, val_accuracy=0.352, lr=0.0316] 58%|█████▊    | 48/83 [16:38<11:37, 19.94s/epoch, loss=1.13, accuracy=0.757, val_loss=3.52, val_accuracy=0.371, lr=0.1]    59%|█████▉    | 49/83 [16:58<11:16, 19.90s/epoch, loss=1.12, accuracy=0.757, val_loss=3.02, val_accuracy=0.377, lr=0.1] 60%|██████    | 50/83 [17:18<10:56, 19.90s/epoch, loss=1.13, accuracy=0.752, val_loss=1.95, val_accuracy=0.496, lr=0.1] 61%|██████▏   | 51/83 [17:38<10:37, 19.93s/epoch, loss=1.12, accuracy=0.757, val_loss=1.58, val_accuracy=0.625, lr=0.1] 63%|██████▎   | 52/83 [17:58<10:16, 19.87s/epoch, loss=1.13, accuracy=0.756, val_loss=1.85, val_accuracy=0.519, lr=0.0316] 64%|██████▍   | 53/83 [18:18<09:56, 19.87s/epoch, loss=1.12, accuracy=0.756, val_loss=1.96, val_accuracy=0.529, lr=0.1]    65%|██████▌   | 54/83 [18:37<09:36, 19.86s/epoch, loss=1.12, accuracy=0.755, val_loss=1.36, val_accuracy=0.671, lr=0.1] 66%|██████▋   | 55/83 [18:58<09:17, 19.92s/epoch, loss=1.12, accuracy=0.756, val_loss=1.69, val_accuracy=0.602, lr=0.1] 67%|██████▋   | 56/83 [19:18<08:58, 19.94s/epoch, loss=1.12, accuracy=0.757, val_loss=2.12, val_accuracy=0.394, lr=0.1] 69%|██████▊   | 57/83 [19:37<08:37, 19.89s/epoch, loss=1.12, accuracy=0.755, val_loss=1.76, val_accuracy=0.561, lr=0.1] 70%|██████▉   | 58/83 [19:57<08:18, 19.92s/epoch, loss=1.12, accuracy=0.757, val_loss=1.67, val_accuracy=0.589, lr=0.1] 71%|███████   | 59/83 [20:17<07:57, 19.90s/epoch, loss=1.12, accuracy=0.755, val_loss=1.7, val_accuracy=0.589, lr=0.0316] 72%|███████▏  | 60/83 [20:37<07:38, 19.94s/epoch, loss=1.12, accuracy=0.756, val_loss=1.61, val_accuracy=0.58, lr=0.1]    73%|███████▎  | 61/83 [20:57<07:18, 19.95s/epoch, loss=1.12, accuracy=0.758, val_loss=2.33, val_accuracy=0.481, lr=0.1] 75%|███████▍  | 62/83 [21:17<07:00, 20.04s/epoch, loss=1.12, accuracy=0.757, val_loss=1.63, val_accuracy=0.604, lr=0.1] 76%|███████▌  | 63/83 [21:37<06:39, 19.97s/epoch, loss=1.11, accuracy=0.758, val_loss=1.83, val_accuracy=0.553, lr=0.1] 77%|███████▋  | 64/83 [21:57<06:17, 19.88s/epoch, loss=1.12, accuracy=0.755, val_loss=3.27, val_accuracy=0.251, lr=0.0316] 78%|███████▊  | 65/83 [22:16<05:55, 19.74s/epoch, loss=1.12, accuracy=0.758, val_loss=1.9, val_accuracy=0.521, lr=0.1]     80%|███████▉  | 66/83 [22:36<05:35, 19.74s/epoch, loss=1.12, accuracy=0.756, val_loss=4.7, val_accuracy=0.324, lr=0.1] 81%|████████  | 67/83 [22:56<05:15, 19.74s/epoch, loss=1.12, accuracy=0.756, val_loss=1.84, val_accuracy=0.549, lr=0.1] 82%|████████▏ | 68/83 [23:15<04:55, 19.71s/epoch, loss=1.12, accuracy=0.756, val_loss=1.36, val_accuracy=0.675, lr=0.1] 83%|████████▎ | 69/83 [23:35<04:35, 19.70s/epoch, loss=1.12, accuracy=0.756, val_loss=1.63, val_accuracy=0.577, lr=0.0316] 84%|████████▍ | 70/83 [23:55<04:16, 19.70s/epoch, loss=1.12, accuracy=0.757, val_loss=2.09, val_accuracy=0.472, lr=0.1]    86%|████████▌ | 71/83 [24:14<03:56, 19.68s/epoch, loss=1.12, accuracy=0.757, val_loss=1.77, val_accuracy=0.545, lr=0.1] 87%|████████▋ | 72/83 [24:34<03:36, 19.68s/epoch, loss=1.12, accuracy=0.755, val_loss=1.49, val_accuracy=0.647, lr=0.1] 88%|████████▊ | 73/83 [24:54<03:17, 19.73s/epoch, loss=1.11, accuracy=0.757, val_loss=2.63, val_accuracy=0.442, lr=0.1] 89%|████████▉ | 74/83 [25:14<02:57, 19.73s/epoch, loss=1.11, accuracy=0.757, val_loss=1.67, val_accuracy=0.585, lr=0.0316] 90%|█████████ | 75/83 [25:33<02:38, 19.77s/epoch, loss=1.12, accuracy=0.76, val_loss=2.07, val_accuracy=0.504, lr=0.1]     92%|█████████▏| 76/83 [25:53<02:18, 19.81s/epoch, loss=1.11, accuracy=0.759, val_loss=2.17, val_accuracy=0.534, lr=0.1] 93%|█████████▎| 77/83 [26:14<01:59, 19.92s/epoch, loss=1.13, accuracy=0.755, val_loss=2.51, val_accuracy=0.465, lr=0.1] 94%|█████████▍| 78/83 [26:33<01:39, 19.90s/epoch, loss=1.12, accuracy=0.756, val_loss=3.35, val_accuracy=0.3, lr=0.1]   95%|█████████▌| 79/83 [26:53<01:19, 19.85s/epoch, loss=1.12, accuracy=0.756, val_loss=1.56, val_accuracy=0.602, lr=0.0316] 96%|█████████▋| 80/83 [27:13<00:59, 19.81s/epoch, loss=1.11, accuracy=0.757, val_loss=2.37, val_accuracy=0.469, lr=0.1]    98%|█████████▊| 81/83 [27:33<00:39, 19.76s/epoch, loss=1.11, accuracy=0.759, val_loss=2.43, val_accuracy=0.424, lr=0.1] 99%|█████████▉| 82/83 [27:52<00:19, 19.79s/epoch, loss=0.885, accuracy=0.818, val_loss=0.894, val_accuracy=0.803, lr=0.01]100%|██████████| 83/83 [28:12<00:00, 19.75s/epoch, loss=0.721, accuracy=0.847, val_loss=0.797, val_accuracy=0.816, lr=0.01]100%|██████████| 83/83 [28:12<00:00, 20.39s/epoch, loss=0.721, accuracy=0.847, val_loss=0.797, val_accuracy=0.816, lr=0.01]
Using real-time data augmentation.
Test score: 0.7965090274810791
Test accuracy: 0.8163999915122986


* * * Run SGD for ID = 18_7. * * *


2024-03-05 12:45:02.854184: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 12:45:05.459874: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 12:45:05.461026: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-05 12:45:05.497551: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-03-05 12:45:05.497596: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 12:45:05.500534: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 12:45:05.500571: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 12:45:05.502843: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 12:45:05.503536: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 12:45:05.506014: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 12:45:05.507367: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 12:45:05.512115: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 12:45:05.512775: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 12:45:05.512878: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 12:45:06.834761: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-05 12:45:06.835399: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 12:45:06.836202: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-03-05 12:45:06.836234: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 12:45:06.836287: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 12:45:06.836304: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 12:45:06.836319: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 12:45:06.836335: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 12:45:06.836349: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 12:45:06.836363: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 12:45:06.836378: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 12:45:06.836798: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 12:45:06.836836: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 12:45:07.472269: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-05 12:45:07.472315: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-05 12:45:07.472323: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-05 12:45:07.473256: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': '18_07', 'seed': 7, 'out_folder': 'results/epoch_budget', 'batch_size': 128, 'epochs': 83, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'bootstrapping': False, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/83 [00:00<?, ?epoch/s]2024-03-05 12:45:08.325403: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-05 12:45:08.337146: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600020000 Hz
2024-03-05 12:45:10.359239: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 12:45:10.593571: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 12:45:11.408008: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-05 12:45:11.455408: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/83 [01:01<1:24:04, 61.51s/epoch, loss=3.2, accuracy=0.307, val_loss=2.84, val_accuracy=0.209, lr=0.1]  2%|▏         | 2/83 [01:22<50:45, 37.60s/epoch, loss=1.53, accuracy=0.549, val_loss=2.09, val_accuracy=0.464, lr=0.1]   4%|▎         | 3/83 [01:43<39:51, 29.89s/epoch, loss=1.31, accuracy=0.655, val_loss=1.87, val_accuracy=0.475, lr=0.1]  5%|▍         | 4/83 [02:03<34:20, 26.08s/epoch, loss=1.25, accuracy=0.688, val_loss=2.09, val_accuracy=0.462, lr=0.1]  6%|▌         | 5/83 [02:23<31:17, 24.07s/epoch, loss=1.24, accuracy=0.705, val_loss=2.21, val_accuracy=0.451, lr=0.1]  7%|▋         | 6/83 [02:44<29:25, 22.92s/epoch, loss=1.22, accuracy=0.716, val_loss=2.94, val_accuracy=0.414, lr=0.1]  8%|▊         | 7/83 [03:05<28:04, 22.16s/epoch, loss=1.22, accuracy=0.72, val_loss=4.54, val_accuracy=0.256, lr=0.1]  10%|▉         | 8/83 [03:25<27:06, 21.68s/epoch, loss=1.21, accuracy=0.724, val_loss=1.74, val_accuracy=0.542, lr=0.1] 11%|█         | 9/83 [03:46<26:21, 21.38s/epoch, loss=1.2, accuracy=0.728, val_loss=2.03, val_accuracy=0.514, lr=0.1]  12%|█▏        | 10/83 [04:07<25:42, 21.13s/epoch, loss=1.2, accuracy=0.731, val_loss=2.23, val_accuracy=0.441, lr=0.1] 13%|█▎        | 11/83 [04:27<25:07, 20.93s/epoch, loss=1.19, accuracy=0.735, val_loss=2.66, val_accuracy=0.29, lr=0.1] 14%|█▍        | 12/83 [04:48<24:37, 20.81s/epoch, loss=1.19, accuracy=0.736, val_loss=2.02, val_accuracy=0.518, lr=0.1] 16%|█▌        | 13/83 [05:08<24:13, 20.76s/epoch, loss=1.18, accuracy=0.739, val_loss=1.76, val_accuracy=0.531, lr=0.0316] 17%|█▋        | 14/83 [05:29<23:47, 20.69s/epoch, loss=1.18, accuracy=0.741, val_loss=1.6, val_accuracy=0.623, lr=0.1]     18%|█▊        | 15/83 [05:49<23:26, 20.68s/epoch, loss=1.18, accuracy=0.74, val_loss=1.63, val_accuracy=0.575, lr=0.1] 19%|█▉        | 16/83 [06:10<23:02, 20.64s/epoch, loss=1.17, accuracy=0.741, val_loss=2.42, val_accuracy=0.433, lr=0.1] 20%|██        | 17/83 [06:30<22:39, 20.59s/epoch, loss=1.17, accuracy=0.744, val_loss=1.77, val_accuracy=0.565, lr=0.1] 22%|██▏       | 18/83 [06:51<22:17, 20.57s/epoch, loss=1.17, accuracy=0.743, val_loss=3.17, val_accuracy=0.355, lr=0.1] 23%|██▎       | 19/83 [07:12<21:55, 20.56s/epoch, loss=1.17, accuracy=0.746, val_loss=1.6, val_accuracy=0.59, lr=0.0316] 24%|██▍       | 20/83 [07:32<21:33, 20.53s/epoch, loss=1.16, accuracy=0.746, val_loss=1.75, val_accuracy=0.56, lr=0.1]   25%|██▌       | 21/83 [07:52<21:12, 20.52s/epoch, loss=1.16, accuracy=0.746, val_loss=1.7, val_accuracy=0.567, lr=0.1] 27%|██▋       | 22/83 [08:13<20:53, 20.55s/epoch, loss=1.16, accuracy=0.747, val_loss=1.46, val_accuracy=0.63, lr=0.1] 28%|██▊       | 23/83 [08:34<20:32, 20.55s/epoch, loss=1.16, accuracy=0.752, val_loss=1.78, val_accuracy=0.544, lr=0.1] 29%|██▉       | 24/83 [08:54<20:11, 20.53s/epoch, loss=1.15, accuracy=0.75, val_loss=1.88, val_accuracy=0.528, lr=0.1]  30%|███       | 25/83 [09:15<19:51, 20.54s/epoch, loss=1.15, accuracy=0.75, val_loss=1.6, val_accuracy=0.601, lr=0.1]  31%|███▏      | 26/83 [09:35<19:31, 20.55s/epoch, loss=1.15, accuracy=0.749, val_loss=1.9, val_accuracy=0.524, lr=0.1] 33%|███▎      | 27/83 [09:56<19:12, 20.57s/epoch, loss=1.14, accuracy=0.752, val_loss=2.01, val_accuracy=0.561, lr=0.0316] 34%|███▎      | 28/83 [10:16<18:42, 20.42s/epoch, loss=1.15, accuracy=0.75, val_loss=1.81, val_accuracy=0.523, lr=0.1]     35%|███▍      | 29/83 [10:36<18:21, 20.40s/epoch, loss=1.14, accuracy=0.754, val_loss=4.38, val_accuracy=0.274, lr=0.1] 36%|███▌      | 30/83 [10:57<17:58, 20.36s/epoch, loss=1.14, accuracy=0.753, val_loss=2.12, val_accuracy=0.417, lr=0.1] 37%|███▋      | 31/83 [11:17<17:38, 20.35s/epoch, loss=1.14, accuracy=0.752, val_loss=1.78, val_accuracy=0.529, lr=0.1] 39%|███▊      | 32/83 [11:37<17:18, 20.37s/epoch, loss=1.14, accuracy=0.753, val_loss=1.99, val_accuracy=0.475, lr=0.0316] 40%|███▉      | 33/83 [11:58<17:02, 20.45s/epoch, loss=1.14, accuracy=0.756, val_loss=2.46, val_accuracy=0.406, lr=0.1]    41%|████      | 34/83 [12:18<16:39, 20.40s/epoch, loss=1.14, accuracy=0.753, val_loss=1.62, val_accuracy=0.591, lr=0.1] 42%|████▏     | 35/83 [12:39<16:21, 20.45s/epoch, loss=1.14, accuracy=0.753, val_loss=4.47, val_accuracy=0.351, lr=0.1] 43%|████▎     | 36/83 [12:59<16:00, 20.44s/epoch, loss=1.14, accuracy=0.752, val_loss=2.29, val_accuracy=0.404, lr=0.1] 45%|████▍     | 37/83 [13:20<15:39, 20.42s/epoch, loss=1.14, accuracy=0.752, val_loss=1.96, val_accuracy=0.551, lr=0.0316] 46%|████▌     | 38/83 [13:40<15:16, 20.37s/epoch, loss=1.13, accuracy=0.754, val_loss=1.88, val_accuracy=0.536, lr=0.1]    47%|████▋     | 39/83 [14:00<14:55, 20.35s/epoch, loss=1.13, accuracy=0.756, val_loss=2.37, val_accuracy=0.345, lr=0.1] 48%|████▊     | 40/83 [14:20<14:33, 20.31s/epoch, loss=1.14, accuracy=0.755, val_loss=2.78, val_accuracy=0.424, lr=0.1] 49%|████▉     | 41/83 [14:41<14:15, 20.37s/epoch, loss=1.14, accuracy=0.752, val_loss=1.97, val_accuracy=0.5, lr=0.1]   51%|█████     | 42/83 [15:01<13:54, 20.36s/epoch, loss=1.13, accuracy=0.755, val_loss=2.52, val_accuracy=0.431, lr=0.0316] 52%|█████▏    | 43/83 [15:22<13:36, 20.41s/epoch, loss=1.13, accuracy=0.753, val_loss=2.87, val_accuracy=0.347, lr=0.1]    53%|█████▎    | 44/83 [15:42<13:17, 20.45s/epoch, loss=1.13, accuracy=0.756, val_loss=2.47, val_accuracy=0.34, lr=0.1]  54%|█████▍    | 45/83 [16:03<12:56, 20.43s/epoch, loss=1.13, accuracy=0.757, val_loss=2.6, val_accuracy=0.419, lr=0.1] 55%|█████▌    | 46/83 [16:23<12:38, 20.50s/epoch, loss=1.13, accuracy=0.754, val_loss=2.07, val_accuracy=0.501, lr=0.1] 57%|█████▋    | 47/83 [16:44<12:18, 20.52s/epoch, loss=1.13, accuracy=0.752, val_loss=5.51, val_accuracy=0.137, lr=0.0316] 58%|█████▊    | 48/83 [17:05<11:59, 20.56s/epoch, loss=1.12, accuracy=0.754, val_loss=1.56, val_accuracy=0.604, lr=0.1]    59%|█████▉    | 49/83 [17:25<11:41, 20.62s/epoch, loss=1.13, accuracy=0.754, val_loss=1.73, val_accuracy=0.56, lr=0.1]  60%|██████    | 50/83 [17:46<11:18, 20.55s/epoch, loss=1.13, accuracy=0.754, val_loss=2.81, val_accuracy=0.471, lr=0.1] 61%|██████▏   | 51/83 [18:06<10:54, 20.46s/epoch, loss=1.12, accuracy=0.755, val_loss=2.63, val_accuracy=0.404, lr=0.1] 63%|██████▎   | 52/83 [18:26<10:33, 20.44s/epoch, loss=1.12, accuracy=0.754, val_loss=2.31, val_accuracy=0.392, lr=0.0316] 64%|██████▍   | 53/83 [18:47<10:13, 20.46s/epoch, loss=1.12, accuracy=0.755, val_loss=2, val_accuracy=0.509, lr=0.1]       65%|██████▌   | 54/83 [19:07<09:54, 20.49s/epoch, loss=1.12, accuracy=0.758, val_loss=1.52, val_accuracy=0.61, lr=0.1] 66%|██████▋   | 55/83 [19:28<09:31, 20.41s/epoch, loss=1.12, accuracy=0.755, val_loss=2.1, val_accuracy=0.465, lr=0.1] 67%|██████▋   | 56/83 [19:48<09:08, 20.32s/epoch, loss=1.12, accuracy=0.757, val_loss=1.93, val_accuracy=0.519, lr=0.1] 69%|██████▊   | 57/83 [20:08<08:48, 20.32s/epoch, loss=1.12, accuracy=0.755, val_loss=3.98, val_accuracy=0.257, lr=0.0316] 70%|██████▉   | 58/83 [20:29<08:29, 20.39s/epoch, loss=1.12, accuracy=0.756, val_loss=2.68, val_accuracy=0.35, lr=0.1]     71%|███████   | 59/83 [20:49<08:08, 20.34s/epoch, loss=1.12, accuracy=0.757, val_loss=3.14, val_accuracy=0.329, lr=0.1] 72%|███████▏  | 60/83 [21:09<07:46, 20.30s/epoch, loss=1.11, accuracy=0.759, val_loss=4.43, val_accuracy=0.28, lr=0.1]  73%|███████▎  | 61/83 [21:29<07:26, 20.29s/epoch, loss=1.12, accuracy=0.755, val_loss=2.07, val_accuracy=0.434, lr=0.1] 75%|███████▍  | 62/83 [21:50<07:06, 20.32s/epoch, loss=1.12, accuracy=0.753, val_loss=2.5, val_accuracy=0.396, lr=0.0316] 76%|███████▌  | 63/83 [22:10<06:45, 20.26s/epoch, loss=1.11, accuracy=0.757, val_loss=1.51, val_accuracy=0.615, lr=0.1]   77%|███████▋  | 64/83 [22:30<06:25, 20.27s/epoch, loss=1.11, accuracy=0.757, val_loss=3.26, val_accuracy=0.247, lr=0.1] 78%|███████▊  | 65/83 [22:50<06:05, 20.29s/epoch, loss=1.11, accuracy=0.758, val_loss=3.47, val_accuracy=0.389, lr=0.1] 80%|███████▉  | 66/83 [23:11<05:48, 20.52s/epoch, loss=1.11, accuracy=0.756, val_loss=2.68, val_accuracy=0.409, lr=0.1] 81%|████████  | 67/83 [23:32<05:28, 20.51s/epoch, loss=1.11, accuracy=0.758, val_loss=1.31, val_accuracy=0.685, lr=0.1] 82%|████████▏ | 68/83 [23:53<05:08, 20.53s/epoch, loss=1.11, accuracy=0.757, val_loss=2.74, val_accuracy=0.343, lr=0.1] 83%|████████▎ | 69/83 [24:13<04:47, 20.50s/epoch, loss=1.11, accuracy=0.759, val_loss=3.28, val_accuracy=0.325, lr=0.1] 84%|████████▍ | 70/83 [24:33<04:26, 20.47s/epoch, loss=1.11, accuracy=0.757, val_loss=2.3, val_accuracy=0.373, lr=0.1]  86%|████████▌ | 71/83 [24:54<04:05, 20.44s/epoch, loss=1.12, accuracy=0.756, val_loss=2.94, val_accuracy=0.327, lr=0.1] 87%|████████▋ | 72/83 [25:14<03:44, 20.45s/epoch, loss=1.11, accuracy=0.756, val_loss=2.17, val_accuracy=0.523, lr=0.0316] 88%|████████▊ | 73/83 [25:35<03:24, 20.43s/epoch, loss=1.11, accuracy=0.757, val_loss=5.89, val_accuracy=0.258, lr=0.1]    89%|████████▉ | 74/83 [25:55<03:03, 20.44s/epoch, loss=1.11, accuracy=0.757, val_loss=1.57, val_accuracy=0.599, lr=0.1] 90%|█████████ | 75/83 [26:16<02:43, 20.44s/epoch, loss=1.11, accuracy=0.759, val_loss=1.78, val_accuracy=0.533, lr=0.1] 92%|█████████▏| 76/83 [26:36<02:23, 20.45s/epoch, loss=1.12, accuracy=0.755, val_loss=2.7, val_accuracy=0.317, lr=0.1]  93%|█████████▎| 77/83 [26:56<02:02, 20.45s/epoch, loss=1.11, accuracy=0.757, val_loss=2.52, val_accuracy=0.449, lr=0.0316] 94%|█████████▍| 78/83 [27:17<01:42, 20.44s/epoch, loss=1.11, accuracy=0.758, val_loss=1.48, val_accuracy=0.649, lr=0.1]    95%|█████████▌| 79/83 [27:37<01:21, 20.42s/epoch, loss=1.11, accuracy=0.756, val_loss=1.53, val_accuracy=0.613, lr=0.1] 96%|█████████▋| 80/83 [27:58<01:01, 20.38s/epoch, loss=1.11, accuracy=0.754, val_loss=2.72, val_accuracy=0.475, lr=0.1] 98%|█████████▊| 81/83 [28:18<00:40, 20.36s/epoch, loss=1.11, accuracy=0.758, val_loss=2.58, val_accuracy=0.308, lr=0.1] 99%|█████████▉| 82/83 [28:38<00:20, 20.35s/epoch, loss=0.897, accuracy=0.817, val_loss=0.916, val_accuracy=0.796, lr=0.01]100%|██████████| 83/83 [28:58<00:00, 20.32s/epoch, loss=0.724, accuracy=0.848, val_loss=0.803, val_accuracy=0.814, lr=0.01]100%|██████████| 83/83 [28:58<00:00, 20.95s/epoch, loss=0.724, accuracy=0.848, val_loss=0.803, val_accuracy=0.814, lr=0.01]
Using real-time data augmentation.
Test score: 0.8030015230178833
Test accuracy: 0.8137000203132629


* * * Run SGD for ID = 18_8. * * *


2024-03-05 13:14:11.038400: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 13:14:13.633087: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 13:14:13.634199: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-05 13:14:13.682599: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-03-05 13:14:13.682641: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 13:14:13.685794: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 13:14:13.685830: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 13:14:13.688128: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 13:14:13.688782: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 13:14:13.691152: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 13:14:13.692522: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 13:14:13.697237: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 13:14:13.697860: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 13:14:13.697973: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 13:14:14.935481: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-05 13:14:14.936071: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 13:14:14.936810: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-03-05 13:14:14.936840: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 13:14:14.936877: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 13:14:14.936895: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 13:14:14.936910: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 13:14:14.936926: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 13:14:14.936941: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 13:14:14.936963: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 13:14:14.936996: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 13:14:14.937429: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 13:14:14.937460: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 13:14:15.618840: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-05 13:14:15.618899: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-05 13:14:15.618908: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-05 13:14:15.619930: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': '18_08', 'seed': 8, 'out_folder': 'results/epoch_budget', 'batch_size': 128, 'epochs': 83, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'bootstrapping': False, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/83 [00:00<?, ?epoch/s]2024-03-05 13:14:16.472757: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-05 13:14:16.485134: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600020000 Hz
2024-03-05 13:14:18.548224: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 13:14:18.759969: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 13:14:19.590185: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-05 13:14:19.655374: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/83 [01:04<1:28:26, 64.72s/epoch, loss=2.92, accuracy=0.369, val_loss=2.28, val_accuracy=0.341, lr=0.1]  2%|▏         | 2/83 [01:24<52:00, 38.52s/epoch, loss=1.46, accuracy=0.585, val_loss=3.53, val_accuracy=0.299, lr=0.1]    4%|▎         | 3/83 [01:45<40:11, 30.14s/epoch, loss=1.3, accuracy=0.665, val_loss=1.55, val_accuracy=0.593, lr=0.1]   5%|▍         | 4/83 [02:05<34:24, 26.13s/epoch, loss=1.25, accuracy=0.696, val_loss=1.62, val_accuracy=0.573, lr=0.1]  6%|▌         | 5/83 [02:24<31:01, 23.86s/epoch, loss=1.22, accuracy=0.711, val_loss=5.3, val_accuracy=0.232, lr=0.1]   7%|▋         | 6/83 [02:45<28:59, 22.60s/epoch, loss=1.21, accuracy=0.719, val_loss=6.68, val_accuracy=0.163, lr=0.1]  8%|▊         | 7/83 [03:04<27:30, 21.72s/epoch, loss=1.21, accuracy=0.725, val_loss=1.75, val_accuracy=0.542, lr=0.1] 10%|▉         | 8/83 [03:24<26:28, 21.19s/epoch, loss=1.19, accuracy=0.73, val_loss=1.67, val_accuracy=0.578, lr=0.0316] 11%|█         | 9/83 [03:45<25:42, 20.84s/epoch, loss=1.19, accuracy=0.729, val_loss=2.24, val_accuracy=0.452, lr=0.1]   12%|█▏        | 10/83 [04:05<25:03, 20.60s/epoch, loss=1.19, accuracy=0.736, val_loss=2.37, val_accuracy=0.415, lr=0.1] 13%|█▎        | 11/83 [04:24<24:25, 20.35s/epoch, loss=1.18, accuracy=0.738, val_loss=3.85, val_accuracy=0.345, lr=0.1] 14%|█▍        | 12/83 [04:44<23:56, 20.23s/epoch, loss=1.18, accuracy=0.743, val_loss=1.57, val_accuracy=0.627, lr=0.1] 16%|█▌        | 13/83 [05:04<23:29, 20.14s/epoch, loss=1.17, accuracy=0.743, val_loss=2.32, val_accuracy=0.471, lr=0.0316] 17%|█▋        | 14/83 [05:24<23:07, 20.11s/epoch, loss=1.17, accuracy=0.742, val_loss=1.95, val_accuracy=0.451, lr=0.1]    18%|█▊        | 15/83 [05:44<22:44, 20.07s/epoch, loss=1.17, accuracy=0.746, val_loss=1.45, val_accuracy=0.659, lr=0.1] 19%|█▉        | 16/83 [06:04<22:25, 20.09s/epoch, loss=1.16, accuracy=0.747, val_loss=1.91, val_accuracy=0.536, lr=0.1] 20%|██        | 17/83 [06:25<22:05, 20.08s/epoch, loss=1.16, accuracy=0.745, val_loss=2.16, val_accuracy=0.541, lr=0.1] 22%|██▏       | 18/83 [06:45<21:45, 20.08s/epoch, loss=1.16, accuracy=0.75, val_loss=1.4, val_accuracy=0.656, lr=0.1]   23%|██▎       | 19/83 [07:05<21:26, 20.10s/epoch, loss=1.15, accuracy=0.75, val_loss=2.58, val_accuracy=0.384, lr=0.1] 24%|██▍       | 20/83 [07:25<21:10, 20.17s/epoch, loss=1.15, accuracy=0.749, val_loss=2.65, val_accuracy=0.346, lr=0.1] 25%|██▌       | 21/83 [07:45<20:51, 20.18s/epoch, loss=1.15, accuracy=0.75, val_loss=1.8, val_accuracy=0.554, lr=0.1]   27%|██▋       | 22/83 [08:05<20:30, 20.17s/epoch, loss=1.15, accuracy=0.752, val_loss=1.75, val_accuracy=0.577, lr=0.1] 28%|██▊       | 23/83 [08:26<20:11, 20.20s/epoch, loss=1.15, accuracy=0.751, val_loss=1.64, val_accuracy=0.614, lr=0.0316] 29%|██▉       | 24/83 [08:46<19:49, 20.16s/epoch, loss=1.15, accuracy=0.749, val_loss=2.2, val_accuracy=0.422, lr=0.1]     30%|███       | 25/83 [09:06<19:31, 20.20s/epoch, loss=1.15, accuracy=0.749, val_loss=1.44, val_accuracy=0.643, lr=0.1] 31%|███▏      | 26/83 [09:26<19:14, 20.26s/epoch, loss=1.14, accuracy=0.753, val_loss=1.55, val_accuracy=0.601, lr=0.1] 33%|███▎      | 27/83 [09:47<18:54, 20.27s/epoch, loss=1.14, accuracy=0.753, val_loss=2.56, val_accuracy=0.323, lr=0.1] 34%|███▎      | 28/83 [10:07<18:33, 20.24s/epoch, loss=1.14, accuracy=0.754, val_loss=1.52, val_accuracy=0.624, lr=0.0316] 35%|███▍      | 29/83 [10:27<18:17, 20.33s/epoch, loss=1.13, accuracy=0.753, val_loss=1.74, val_accuracy=0.543, lr=0.1]    36%|███▌      | 30/83 [10:48<17:55, 20.28s/epoch, loss=1.13, accuracy=0.757, val_loss=2.1, val_accuracy=0.505, lr=0.1]  37%|███▋      | 31/83 [11:08<17:30, 20.20s/epoch, loss=1.13, accuracy=0.756, val_loss=1.8, val_accuracy=0.503, lr=0.1] 39%|███▊      | 32/83 [11:28<17:10, 20.20s/epoch, loss=1.13, accuracy=0.757, val_loss=6.01, val_accuracy=0.203, lr=0.1] 40%|███▉      | 33/83 [11:48<16:50, 20.22s/epoch, loss=1.14, accuracy=0.754, val_loss=5.78, val_accuracy=0.22, lr=0.0316] 41%|████      | 34/83 [12:08<16:32, 20.26s/epoch, loss=1.13, accuracy=0.753, val_loss=1.48, val_accuracy=0.632, lr=0.1]   42%|████▏     | 35/83 [12:29<16:09, 20.21s/epoch, loss=1.13, accuracy=0.754, val_loss=2.44, val_accuracy=0.4, lr=0.1]   43%|████▎     | 36/83 [12:49<15:48, 20.19s/epoch, loss=1.14, accuracy=0.752, val_loss=1.64, val_accuracy=0.568, lr=0.1] 45%|████▍     | 37/83 [13:09<15:27, 20.16s/epoch, loss=1.13, accuracy=0.757, val_loss=1.74, val_accuracy=0.554, lr=0.1] 46%|████▌     | 38/83 [13:29<15:07, 20.17s/epoch, loss=1.12, accuracy=0.757, val_loss=4.81, val_accuracy=0.315, lr=0.0316] 47%|████▋     | 39/83 [13:49<14:49, 20.21s/epoch, loss=1.13, accuracy=0.759, val_loss=2, val_accuracy=0.552, lr=0.1]       48%|████▊     | 40/83 [14:09<14:26, 20.16s/epoch, loss=1.13, accuracy=0.754, val_loss=2.34, val_accuracy=0.445, lr=0.1] 49%|████▉     | 41/83 [14:29<14:04, 20.10s/epoch, loss=1.13, accuracy=0.754, val_loss=1.93, val_accuracy=0.52, lr=0.1]  51%|█████     | 42/83 [14:50<13:47, 20.19s/epoch, loss=1.13, accuracy=0.756, val_loss=1.73, val_accuracy=0.579, lr=0.1] 52%|█████▏    | 43/83 [15:09<13:23, 20.08s/epoch, loss=1.12, accuracy=0.757, val_loss=1.72, val_accuracy=0.533, lr=0.0316] 53%|█████▎    | 44/83 [15:29<13:02, 20.06s/epoch, loss=1.12, accuracy=0.756, val_loss=2.06, val_accuracy=0.521, lr=0.1]    54%|█████▍    | 45/83 [15:50<12:42, 20.08s/epoch, loss=1.13, accuracy=0.757, val_loss=1.55, val_accuracy=0.608, lr=0.1] 55%|█████▌    | 46/83 [16:10<12:23, 20.08s/epoch, loss=1.12, accuracy=0.757, val_loss=2.19, val_accuracy=0.521, lr=0.1] 57%|█████▋    | 47/83 [16:30<12:03, 20.10s/epoch, loss=1.12, accuracy=0.756, val_loss=2.15, val_accuracy=0.507, lr=0.1] 58%|█████▊    | 48/83 [16:50<11:43, 20.09s/epoch, loss=1.12, accuracy=0.759, val_loss=1.87, val_accuracy=0.563, lr=0.0316] 59%|█████▉    | 49/83 [17:10<11:24, 20.12s/epoch, loss=1.12, accuracy=0.759, val_loss=1.61, val_accuracy=0.61, lr=0.1]     60%|██████    | 50/83 [17:30<11:05, 20.18s/epoch, loss=1.12, accuracy=0.757, val_loss=2.4, val_accuracy=0.429, lr=0.1] 61%|██████▏   | 51/83 [17:51<10:46, 20.19s/epoch, loss=1.12, accuracy=0.757, val_loss=1.74, val_accuracy=0.544, lr=0.1] 63%|██████▎   | 52/83 [18:11<10:26, 20.20s/epoch, loss=1.12, accuracy=0.761, val_loss=2.17, val_accuracy=0.48, lr=0.1]  64%|██████▍   | 53/83 [18:31<10:05, 20.18s/epoch, loss=1.12, accuracy=0.757, val_loss=2.4, val_accuracy=0.483, lr=0.0316] 65%|██████▌   | 54/83 [18:51<09:43, 20.11s/epoch, loss=1.12, accuracy=0.76, val_loss=2.53, val_accuracy=0.359, lr=0.1]    66%|██████▋   | 55/83 [19:11<09:20, 20.01s/epoch, loss=1.11, accuracy=0.759, val_loss=1.79, val_accuracy=0.562, lr=0.1] 67%|██████▋   | 56/83 [19:31<08:58, 19.96s/epoch, loss=1.11, accuracy=0.76, val_loss=2.29, val_accuracy=0.419, lr=0.1]  69%|██████▊   | 57/83 [19:50<08:36, 19.87s/epoch, loss=1.12, accuracy=0.758, val_loss=1.29, val_accuracy=0.69, lr=0.1] 70%|██████▉   | 58/83 [20:10<08:14, 19.80s/epoch, loss=1.11, accuracy=0.759, val_loss=1.88, val_accuracy=0.477, lr=0.1] 71%|███████   | 59/83 [20:29<07:52, 19.71s/epoch, loss=1.12, accuracy=0.756, val_loss=1.57, val_accuracy=0.585, lr=0.1] 72%|███████▏  | 60/83 [20:49<07:32, 19.69s/epoch, loss=1.11, accuracy=0.76, val_loss=1.67, val_accuracy=0.621, lr=0.1]  73%|███████▎  | 61/83 [21:09<07:12, 19.64s/epoch, loss=1.12, accuracy=0.756, val_loss=1.67, val_accuracy=0.588, lr=0.1] 75%|███████▍  | 62/83 [21:28<06:52, 19.66s/epoch, loss=1.11, accuracy=0.761, val_loss=1.94, val_accuracy=0.546, lr=0.0316] 76%|███████▌  | 63/83 [21:48<06:32, 19.61s/epoch, loss=1.12, accuracy=0.757, val_loss=2.72, val_accuracy=0.409, lr=0.1]    77%|███████▋  | 64/83 [22:07<06:12, 19.61s/epoch, loss=1.11, accuracy=0.759, val_loss=1.77, val_accuracy=0.589, lr=0.1] 78%|███████▊  | 65/83 [22:27<05:54, 19.70s/epoch, loss=1.11, accuracy=0.759, val_loss=1.92, val_accuracy=0.493, lr=0.1] 80%|███████▉  | 66/83 [22:47<05:34, 19.68s/epoch, loss=1.12, accuracy=0.757, val_loss=1.58, val_accuracy=0.614, lr=0.1] 81%|████████  | 67/83 [23:06<05:14, 19.64s/epoch, loss=1.11, accuracy=0.759, val_loss=1.78, val_accuracy=0.498, lr=0.0316] 82%|████████▏ | 68/83 [23:26<04:54, 19.63s/epoch, loss=1.11, accuracy=0.759, val_loss=5.11, val_accuracy=0.24, lr=0.1]     83%|████████▎ | 69/83 [23:45<04:34, 19.59s/epoch, loss=1.11, accuracy=0.756, val_loss=2.07, val_accuracy=0.488, lr=0.1] 84%|████████▍ | 70/83 [24:05<04:14, 19.55s/epoch, loss=1.11, accuracy=0.758, val_loss=2.47, val_accuracy=0.447, lr=0.1] 86%|████████▌ | 71/83 [24:25<03:55, 19.61s/epoch, loss=1.11, accuracy=0.761, val_loss=4.16, val_accuracy=0.326, lr=0.1] 87%|████████▋ | 72/83 [24:45<03:36, 19.70s/epoch, loss=1.11, accuracy=0.759, val_loss=1.41, val_accuracy=0.661, lr=0.0316] 88%|████████▊ | 73/83 [25:04<03:17, 19.72s/epoch, loss=1.11, accuracy=0.761, val_loss=7.95, val_accuracy=0.122, lr=0.1]    89%|████████▉ | 74/83 [25:24<02:57, 19.70s/epoch, loss=1.12, accuracy=0.759, val_loss=4.3, val_accuracy=0.319, lr=0.1]  90%|█████████ | 75/83 [25:44<02:37, 19.66s/epoch, loss=1.11, accuracy=0.76, val_loss=4.19, val_accuracy=0.229, lr=0.1] 92%|█████████▏| 76/83 [26:03<02:17, 19.69s/epoch, loss=1.11, accuracy=0.76, val_loss=2.42, val_accuracy=0.449, lr=0.1] 93%|█████████▎| 77/83 [26:23<01:58, 19.70s/epoch, loss=1.11, accuracy=0.761, val_loss=6.32, val_accuracy=0.214, lr=0.0316] 94%|█████████▍| 78/83 [26:43<01:38, 19.69s/epoch, loss=1.11, accuracy=0.759, val_loss=2.25, val_accuracy=0.5, lr=0.1]      95%|█████████▌| 79/83 [27:03<01:18, 19.71s/epoch, loss=1.11, accuracy=0.76, val_loss=2.21, val_accuracy=0.451, lr=0.1] 96%|█████████▋| 80/83 [27:22<00:59, 19.69s/epoch, loss=1.11, accuracy=0.758, val_loss=1.94, val_accuracy=0.485, lr=0.1] 98%|█████████▊| 81/83 [27:42<00:39, 19.70s/epoch, loss=1.11, accuracy=0.76, val_loss=1.46, val_accuracy=0.649, lr=0.1]  99%|█████████▉| 82/83 [28:02<00:19, 19.78s/epoch, loss=0.901, accuracy=0.819, val_loss=0.97, val_accuracy=0.774, lr=0.01]100%|██████████| 83/83 [28:21<00:00, 19.73s/epoch, loss=0.724, accuracy=0.849, val_loss=0.793, val_accuracy=0.816, lr=0.01]100%|██████████| 83/83 [28:21<00:00, 20.51s/epoch, loss=0.724, accuracy=0.849, val_loss=0.793, val_accuracy=0.816, lr=0.01]
Using real-time data augmentation.
Test score: 0.7926732301712036
Test accuracy: 0.8159000277519226


* * * Run SGD for ID = 18_9. * * *


2024-03-05 13:42:42.077964: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 13:42:44.653158: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 13:42:44.654242: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-05 13:42:44.694462: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-03-05 13:42:44.694508: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 13:42:44.697392: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 13:42:44.697442: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 13:42:44.699518: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 13:42:44.700211: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 13:42:44.702556: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 13:42:44.703909: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 13:42:44.708348: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 13:42:44.708947: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 13:42:44.709042: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 13:42:45.937597: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-05 13:42:45.938222: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 13:42:45.938975: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-03-05 13:42:45.939028: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 13:42:45.939065: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 13:42:45.939083: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 13:42:45.939099: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 13:42:45.939115: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 13:42:45.939131: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 13:42:45.939146: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 13:42:45.939162: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 13:42:45.939590: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 13:42:45.939625: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 13:42:46.593354: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-05 13:42:46.593411: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-05 13:42:46.593420: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-05 13:42:46.594335: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': '18_09', 'seed': 9, 'out_folder': 'results/epoch_budget', 'batch_size': 128, 'epochs': 83, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'bootstrapping': False, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/83 [00:00<?, ?epoch/s]2024-03-05 13:42:47.444586: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-05 13:42:47.456115: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600020000 Hz
2024-03-05 13:42:49.470794: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 13:42:49.673002: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 13:42:50.445972: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-05 13:42:50.511670: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/83 [01:11<1:38:18, 71.93s/epoch, loss=2.82, accuracy=0.414, val_loss=2.27, val_accuracy=0.367, lr=0.1]  2%|▏         | 2/83 [01:32<56:22, 41.75s/epoch, loss=1.44, accuracy=0.614, val_loss=1.89, val_accuracy=0.502, lr=0.1]    4%|▎         | 3/83 [01:52<42:35, 31.95s/epoch, loss=1.3, accuracy=0.675, val_loss=1.96, val_accuracy=0.517, lr=0.1]   5%|▍         | 4/83 [02:13<36:01, 27.36s/epoch, loss=1.25, accuracy=0.702, val_loss=2.02, val_accuracy=0.476, lr=0.1]  6%|▌         | 5/83 [02:33<32:11, 24.77s/epoch, loss=1.22, accuracy=0.714, val_loss=2.29, val_accuracy=0.47, lr=0.1]   7%|▋         | 6/83 [02:53<29:54, 23.31s/epoch, loss=1.21, accuracy=0.72, val_loss=1.48, val_accuracy=0.635, lr=0.1]  8%|▊         | 7/83 [03:14<28:16, 22.32s/epoch, loss=1.2, accuracy=0.724, val_loss=1.54, val_accuracy=0.602, lr=0.1] 10%|▉         | 8/83 [03:34<27:08, 21.72s/epoch, loss=1.19, accuracy=0.729, val_loss=3.14, val_accuracy=0.36, lr=0.1] 11%|█         | 9/83 [03:54<26:18, 21.33s/epoch, loss=1.19, accuracy=0.729, val_loss=1.91, val_accuracy=0.524, lr=0.1] 12%|█▏        | 10/83 [04:15<25:37, 21.07s/epoch, loss=1.18, accuracy=0.736, val_loss=1.55, val_accuracy=0.623, lr=0.1] 13%|█▎        | 11/83 [04:35<24:58, 20.81s/epoch, loss=1.17, accuracy=0.737, val_loss=2.84, val_accuracy=0.42, lr=0.0316] 14%|█▍        | 12/83 [04:56<24:26, 20.66s/epoch, loss=1.17, accuracy=0.737, val_loss=2.12, val_accuracy=0.498, lr=0.1]   16%|█▌        | 13/83 [05:16<23:57, 20.53s/epoch, loss=1.16, accuracy=0.74, val_loss=4.2, val_accuracy=0.222, lr=0.1]   17%|█▋        | 14/83 [05:36<23:29, 20.43s/epoch, loss=1.16, accuracy=0.743, val_loss=1.65, val_accuracy=0.594, lr=0.1] 18%|█▊        | 15/83 [05:56<23:04, 20.36s/epoch, loss=1.15, accuracy=0.744, val_loss=2.15, val_accuracy=0.465, lr=0.1] 19%|█▉        | 16/83 [06:17<22:46, 20.39s/epoch, loss=1.15, accuracy=0.744, val_loss=1.99, val_accuracy=0.507, lr=0.0316] 20%|██        | 17/83 [06:37<22:22, 20.35s/epoch, loss=1.15, accuracy=0.745, val_loss=1.71, val_accuracy=0.563, lr=0.1]    22%|██▏       | 18/83 [06:57<22:02, 20.35s/epoch, loss=1.14, accuracy=0.746, val_loss=1.83, val_accuracy=0.568, lr=0.1] 23%|██▎       | 19/83 [07:17<21:39, 20.31s/epoch, loss=1.14, accuracy=0.748, val_loss=1.79, val_accuracy=0.502, lr=0.1] 24%|██▍       | 20/83 [07:38<21:19, 20.32s/epoch, loss=1.14, accuracy=0.746, val_loss=1.77, val_accuracy=0.529, lr=0.1] 25%|██▌       | 21/83 [07:58<21:02, 20.36s/epoch, loss=1.14, accuracy=0.749, val_loss=1.84, val_accuracy=0.547, lr=0.0316] 27%|██▋       | 22/83 [08:18<20:37, 20.29s/epoch, loss=1.14, accuracy=0.751, val_loss=2.13, val_accuracy=0.47, lr=0.1]     28%|██▊       | 23/83 [08:39<20:18, 20.32s/epoch, loss=1.14, accuracy=0.749, val_loss=1.59, val_accuracy=0.609, lr=0.1] 29%|██▉       | 24/83 [08:59<20:01, 20.36s/epoch, loss=1.14, accuracy=0.749, val_loss=2.64, val_accuracy=0.316, lr=0.1] 30%|███       | 25/83 [09:20<19:41, 20.37s/epoch, loss=1.14, accuracy=0.75, val_loss=2.23, val_accuracy=0.522, lr=0.1]  31%|███▏      | 26/83 [09:40<19:21, 20.37s/epoch, loss=1.14, accuracy=0.751, val_loss=2.15, val_accuracy=0.49, lr=0.0316] 33%|███▎      | 27/83 [10:00<18:58, 20.33s/epoch, loss=1.14, accuracy=0.751, val_loss=2.72, val_accuracy=0.37, lr=0.1]    34%|███▎      | 28/83 [10:21<18:38, 20.34s/epoch, loss=1.14, accuracy=0.754, val_loss=2.36, val_accuracy=0.429, lr=0.1] 35%|███▍      | 29/83 [10:41<18:25, 20.46s/epoch, loss=1.14, accuracy=0.75, val_loss=2.67, val_accuracy=0.403, lr=0.1]  36%|███▌      | 30/83 [11:02<18:02, 20.43s/epoch, loss=1.13, accuracy=0.755, val_loss=1.78, val_accuracy=0.511, lr=0.1] 37%|███▋      | 31/83 [11:22<17:43, 20.45s/epoch, loss=1.12, accuracy=0.755, val_loss=2.68, val_accuracy=0.336, lr=0.0316] 39%|███▊      | 32/83 [11:42<17:19, 20.38s/epoch, loss=1.13, accuracy=0.752, val_loss=2.01, val_accuracy=0.521, lr=0.1]    40%|███▉      | 33/83 [12:03<16:56, 20.34s/epoch, loss=1.12, accuracy=0.754, val_loss=2.21, val_accuracy=0.415, lr=0.1] 41%|████      | 34/83 [12:23<16:33, 20.29s/epoch, loss=1.13, accuracy=0.754, val_loss=1.6, val_accuracy=0.634, lr=0.1]  42%|████▏     | 35/83 [12:43<16:12, 20.26s/epoch, loss=1.13, accuracy=0.753, val_loss=2.58, val_accuracy=0.409, lr=0.1] 43%|████▎     | 36/83 [13:03<15:51, 20.25s/epoch, loss=1.13, accuracy=0.753, val_loss=1.64, val_accuracy=0.607, lr=0.0316] 45%|████▍     | 37/83 [13:23<15:31, 20.25s/epoch, loss=1.13, accuracy=0.755, val_loss=4.15, val_accuracy=0.277, lr=0.1]    46%|████▌     | 38/83 [13:44<15:09, 20.20s/epoch, loss=1.12, accuracy=0.756, val_loss=1.7, val_accuracy=0.558, lr=0.1]  47%|████▋     | 39/83 [14:04<14:51, 20.27s/epoch, loss=1.12, accuracy=0.753, val_loss=1.94, val_accuracy=0.439, lr=0.1] 48%|████▊     | 40/83 [14:24<14:30, 20.24s/epoch, loss=1.12, accuracy=0.756, val_loss=2.12, val_accuracy=0.528, lr=0.1] 49%|████▉     | 41/83 [14:45<14:12, 20.29s/epoch, loss=1.12, accuracy=0.755, val_loss=2.53, val_accuracy=0.418, lr=0.0316] 51%|█████     | 42/83 [15:05<13:49, 20.22s/epoch, loss=1.12, accuracy=0.756, val_loss=1.96, val_accuracy=0.521, lr=0.1]    52%|█████▏    | 43/83 [15:25<13:28, 20.22s/epoch, loss=1.11, accuracy=0.76, val_loss=1.58, val_accuracy=0.615, lr=0.1]  53%|█████▎    | 44/83 [15:45<13:09, 20.24s/epoch, loss=1.12, accuracy=0.757, val_loss=1.95, val_accuracy=0.495, lr=0.1] 54%|█████▍    | 45/83 [16:05<12:49, 20.24s/epoch, loss=1.12, accuracy=0.756, val_loss=1.61, val_accuracy=0.59, lr=0.1]  55%|█████▌    | 46/83 [16:26<12:28, 20.22s/epoch, loss=1.12, accuracy=0.755, val_loss=3.16, val_accuracy=0.401, lr=0.0316] 57%|█████▋    | 47/83 [16:46<12:10, 20.29s/epoch, loss=1.12, accuracy=0.756, val_loss=1.48, val_accuracy=0.639, lr=0.1]    58%|█████▊    | 48/83 [17:06<11:50, 20.31s/epoch, loss=1.12, accuracy=0.756, val_loss=2.89, val_accuracy=0.336, lr=0.1] 59%|█████▉    | 49/83 [17:27<11:31, 20.33s/epoch, loss=1.12, accuracy=0.757, val_loss=2.32, val_accuracy=0.389, lr=0.1] 60%|██████    | 50/83 [17:47<11:09, 20.30s/epoch, loss=1.11, accuracy=0.761, val_loss=2.49, val_accuracy=0.421, lr=0.1] 61%|██████▏   | 51/83 [18:07<10:51, 20.34s/epoch, loss=1.12, accuracy=0.757, val_loss=5.74, val_accuracy=0.207, lr=0.1] 63%|██████▎   | 52/83 [18:28<10:34, 20.46s/epoch, loss=1.12, accuracy=0.758, val_loss=2.6, val_accuracy=0.408, lr=0.0316] 64%|██████▍   | 53/83 [18:49<10:13, 20.46s/epoch, loss=1.12, accuracy=0.759, val_loss=2.63, val_accuracy=0.37, lr=0.1]    65%|██████▌   | 54/83 [19:09<09:51, 20.40s/epoch, loss=1.11, accuracy=0.757, val_loss=1.89, val_accuracy=0.559, lr=0.1] 66%|██████▋   | 55/83 [19:29<09:31, 20.42s/epoch, loss=1.12, accuracy=0.756, val_loss=1.9, val_accuracy=0.493, lr=0.1]  67%|██████▋   | 56/83 [19:50<09:12, 20.48s/epoch, loss=1.11, accuracy=0.758, val_loss=2.3, val_accuracy=0.401, lr=0.1] 69%|██████▊   | 57/83 [20:10<08:51, 20.45s/epoch, loss=1.12, accuracy=0.759, val_loss=2.55, val_accuracy=0.377, lr=0.0316] 70%|██████▉   | 58/83 [20:30<08:29, 20.36s/epoch, loss=1.12, accuracy=0.758, val_loss=3.02, val_accuracy=0.331, lr=0.1]    71%|███████   | 59/83 [20:51<08:09, 20.38s/epoch, loss=1.12, accuracy=0.756, val_loss=1.66, val_accuracy=0.613, lr=0.1] 72%|███████▏  | 60/83 [21:11<07:47, 20.33s/epoch, loss=1.12, accuracy=0.757, val_loss=1.99, val_accuracy=0.469, lr=0.1] 73%|███████▎  | 61/83 [21:32<07:27, 20.35s/epoch, loss=1.11, accuracy=0.76, val_loss=1.69, val_accuracy=0.574, lr=0.1]  75%|███████▍  | 62/83 [21:52<07:08, 20.40s/epoch, loss=1.12, accuracy=0.757, val_loss=2.16, val_accuracy=0.445, lr=0.0316] 76%|███████▌  | 63/83 [22:12<06:47, 20.35s/epoch, loss=1.12, accuracy=0.757, val_loss=2.25, val_accuracy=0.411, lr=0.1]    77%|███████▋  | 64/83 [22:33<06:27, 20.39s/epoch, loss=1.11, accuracy=0.758, val_loss=2.91, val_accuracy=0.427, lr=0.1] 78%|███████▊  | 65/83 [22:53<06:07, 20.39s/epoch, loss=1.12, accuracy=0.758, val_loss=2.15, val_accuracy=0.438, lr=0.1] 80%|███████▉  | 66/83 [23:13<05:46, 20.38s/epoch, loss=1.11, accuracy=0.76, val_loss=3, val_accuracy=0.357, lr=0.1]     81%|████████  | 67/83 [23:34<05:25, 20.32s/epoch, loss=1.11, accuracy=0.76, val_loss=2.16, val_accuracy=0.496, lr=0.0316] 82%|████████▏ | 68/83 [23:54<05:04, 20.33s/epoch, loss=1.11, accuracy=0.757, val_loss=2.44, val_accuracy=0.394, lr=0.1]   83%|████████▎ | 69/83 [24:14<04:44, 20.34s/epoch, loss=1.11, accuracy=0.759, val_loss=1.53, val_accuracy=0.613, lr=0.1] 84%|████████▍ | 70/83 [24:35<04:24, 20.37s/epoch, loss=1.12, accuracy=0.757, val_loss=2.49, val_accuracy=0.352, lr=0.1] 86%|████████▌ | 71/83 [24:55<04:03, 20.32s/epoch, loss=1.12, accuracy=0.757, val_loss=2.62, val_accuracy=0.434, lr=0.1] 87%|████████▋ | 72/83 [25:15<03:43, 20.28s/epoch, loss=1.11, accuracy=0.76, val_loss=6.81, val_accuracy=0.204, lr=0.0316] 88%|████████▊ | 73/83 [25:35<03:22, 20.23s/epoch, loss=1.11, accuracy=0.758, val_loss=2.11, val_accuracy=0.488, lr=0.1]   89%|████████▉ | 74/83 [25:56<03:02, 20.23s/epoch, loss=1.12, accuracy=0.757, val_loss=1.86, val_accuracy=0.559, lr=0.1] 90%|█████████ | 75/83 [26:16<02:41, 20.21s/epoch, loss=1.12, accuracy=0.757, val_loss=1.97, val_accuracy=0.557, lr=0.1] 92%|█████████▏| 76/83 [26:36<02:21, 20.26s/epoch, loss=1.11, accuracy=0.76, val_loss=1.62, val_accuracy=0.589, lr=0.1]  93%|█████████▎| 77/83 [26:56<02:01, 20.27s/epoch, loss=1.11, accuracy=0.76, val_loss=2.05, val_accuracy=0.487, lr=0.0316] 94%|█████████▍| 78/83 [27:17<01:41, 20.24s/epoch, loss=1.11, accuracy=0.76, val_loss=2.12, val_accuracy=0.485, lr=0.1]    95%|█████████▌| 79/83 [27:37<01:20, 20.18s/epoch, loss=1.12, accuracy=0.757, val_loss=2.18, val_accuracy=0.456, lr=0.1] 96%|█████████▋| 80/83 [27:57<01:00, 20.16s/epoch, loss=1.11, accuracy=0.759, val_loss=2.62, val_accuracy=0.463, lr=0.1] 98%|█████████▊| 81/83 [28:17<00:40, 20.15s/epoch, loss=1.11, accuracy=0.757, val_loss=2.18, val_accuracy=0.479, lr=0.1] 99%|█████████▉| 82/83 [28:37<00:20, 20.17s/epoch, loss=0.92, accuracy=0.814, val_loss=0.951, val_accuracy=0.782, lr=0.01]100%|██████████| 83/83 [28:57<00:00, 20.16s/epoch, loss=0.733, accuracy=0.849, val_loss=0.776, val_accuracy=0.819, lr=0.01]100%|██████████| 83/83 [28:57<00:00, 20.94s/epoch, loss=0.733, accuracy=0.849, val_loss=0.776, val_accuracy=0.819, lr=0.01]
Using real-time data augmentation.
Test score: 0.775554358959198
Test accuracy: 0.8194000124931335


* * * Run SGD for ID = 18_10. * * *


2024-03-05 14:11:48.859670: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 14:11:51.429546: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 14:11:51.430528: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-05 14:11:51.468039: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-03-05 14:11:51.468080: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 14:11:51.470857: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 14:11:51.470899: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 14:11:51.473167: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 14:11:51.474254: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 14:11:51.476686: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 14:11:51.478129: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 14:11:51.482879: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 14:11:51.483498: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 14:11:51.483589: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 14:11:52.754318: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-05 14:11:52.755401: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 14:11:52.756163: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-03-05 14:11:52.756195: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 14:11:52.756233: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 14:11:52.756250: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 14:11:52.756266: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 14:11:52.756282: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 14:11:52.756297: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 14:11:52.756311: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 14:11:52.756326: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 14:11:52.756746: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 14:11:52.756783: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 14:11:53.400532: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-05 14:11:53.400596: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-05 14:11:53.400605: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-05 14:11:53.401543: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': '18_10', 'seed': 10, 'out_folder': 'results/epoch_budget', 'batch_size': 128, 'epochs': 83, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'bootstrapping': False, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/83 [00:00<?, ?epoch/s]2024-03-05 14:11:54.264319: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-05 14:11:54.276099: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600020000 Hz
2024-03-05 14:11:56.297007: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 14:11:56.533064: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 14:11:57.244290: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-05 14:11:57.316043: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/83 [01:08<1:33:22, 68.33s/epoch, loss=2.86, accuracy=0.389, val_loss=3.07, val_accuracy=0.227, lr=0.1]  2%|▏         | 2/83 [01:28<54:03, 40.04s/epoch, loss=1.48, accuracy=0.586, val_loss=2.21, val_accuracy=0.457, lr=0.1]    4%|▎         | 3/83 [01:48<41:24, 31.05s/epoch, loss=1.32, accuracy=0.666, val_loss=3.03, val_accuracy=0.394, lr=0.1]  5%|▍         | 4/83 [02:09<35:12, 26.74s/epoch, loss=1.27, accuracy=0.694, val_loss=2.31, val_accuracy=0.452, lr=0.1]  6%|▌         | 5/83 [02:29<31:38, 24.34s/epoch, loss=1.25, accuracy=0.704, val_loss=1.82, val_accuracy=0.504, lr=0.1]  7%|▋         | 6/83 [02:49<29:19, 22.84s/epoch, loss=1.23, accuracy=0.716, val_loss=1.86, val_accuracy=0.501, lr=0.1]  8%|▊         | 7/83 [03:09<27:50, 21.99s/epoch, loss=1.22, accuracy=0.721, val_loss=2.28, val_accuracy=0.451, lr=0.1] 10%|▉         | 8/83 [03:29<26:50, 21.47s/epoch, loss=1.21, accuracy=0.726, val_loss=3.74, val_accuracy=0.321, lr=0.1] 11%|█         | 9/83 [03:49<25:55, 21.02s/epoch, loss=1.2, accuracy=0.73, val_loss=1.76, val_accuracy=0.541, lr=0.1]   12%|█▏        | 10/83 [04:09<25:10, 20.69s/epoch, loss=1.19, accuracy=0.734, val_loss=2.98, val_accuracy=0.306, lr=0.1] 13%|█▎        | 11/83 [04:29<24:37, 20.52s/epoch, loss=1.19, accuracy=0.735, val_loss=1.74, val_accuracy=0.582, lr=0.1] 14%|█▍        | 12/83 [04:49<24:05, 20.35s/epoch, loss=1.19, accuracy=0.736, val_loss=1.56, val_accuracy=0.615, lr=0.1] 16%|█▌        | 13/83 [05:09<23:37, 20.25s/epoch, loss=1.18, accuracy=0.739, val_loss=1.76, val_accuracy=0.591, lr=0.1] 17%|█▋        | 14/83 [05:29<23:09, 20.14s/epoch, loss=1.18, accuracy=0.741, val_loss=2.1, val_accuracy=0.536, lr=0.1]  18%|█▊        | 15/83 [05:49<22:45, 20.08s/epoch, loss=1.18, accuracy=0.742, val_loss=1.73, val_accuracy=0.591, lr=0.1] 19%|█▉        | 16/83 [06:09<22:26, 20.10s/epoch, loss=1.17, accuracy=0.745, val_loss=1.44, val_accuracy=0.651, lr=0.1] 20%|██        | 17/83 [06:29<22:02, 20.03s/epoch, loss=1.17, accuracy=0.744, val_loss=1.6, val_accuracy=0.612, lr=0.1]  22%|██▏       | 18/83 [06:49<21:39, 19.99s/epoch, loss=1.17, accuracy=0.744, val_loss=1.7, val_accuracy=0.589, lr=0.1] 23%|██▎       | 19/83 [07:09<21:22, 20.04s/epoch, loss=1.16, accuracy=0.747, val_loss=3.21, val_accuracy=0.253, lr=0.1] 24%|██▍       | 20/83 [07:30<21:10, 20.16s/epoch, loss=1.17, accuracy=0.748, val_loss=2.52, val_accuracy=0.399, lr=0.1] 25%|██▌       | 21/83 [07:50<20:47, 20.13s/epoch, loss=1.16, accuracy=0.747, val_loss=4.1, val_accuracy=0.303, lr=0.0316] 27%|██▋       | 22/83 [08:10<20:27, 20.12s/epoch, loss=1.16, accuracy=0.75, val_loss=1.89, val_accuracy=0.553, lr=0.1]    28%|██▊       | 23/83 [08:30<20:06, 20.11s/epoch, loss=1.16, accuracy=0.751, val_loss=2.16, val_accuracy=0.49, lr=0.1] 29%|██▉       | 24/83 [08:50<19:49, 20.17s/epoch, loss=1.16, accuracy=0.748, val_loss=1.59, val_accuracy=0.592, lr=0.1] 30%|███       | 25/83 [09:10<19:30, 20.19s/epoch, loss=1.15, accuracy=0.751, val_loss=2.7, val_accuracy=0.44, lr=0.1]   31%|███▏      | 26/83 [09:31<19:12, 20.22s/epoch, loss=1.15, accuracy=0.751, val_loss=2.08, val_accuracy=0.48, lr=0.0316] 33%|███▎      | 27/83 [09:51<18:51, 20.20s/epoch, loss=1.15, accuracy=0.753, val_loss=2.63, val_accuracy=0.41, lr=0.1]    34%|███▎      | 28/83 [10:11<18:30, 20.19s/epoch, loss=1.15, accuracy=0.751, val_loss=2.66, val_accuracy=0.389, lr=0.1] 35%|███▍      | 29/83 [10:31<18:09, 20.18s/epoch, loss=1.14, accuracy=0.753, val_loss=1.79, val_accuracy=0.52, lr=0.1]  36%|███▌      | 30/83 [10:51<17:51, 20.21s/epoch, loss=1.15, accuracy=0.751, val_loss=1.76, val_accuracy=0.545, lr=0.1] 37%|███▋      | 31/83 [11:12<17:30, 20.21s/epoch, loss=1.14, accuracy=0.752, val_loss=2.86, val_accuracy=0.408, lr=0.0316] 39%|███▊      | 32/83 [11:32<17:07, 20.14s/epoch, loss=1.14, accuracy=0.753, val_loss=4.67, val_accuracy=0.292, lr=0.1]    40%|███▉      | 33/83 [11:52<16:46, 20.12s/epoch, loss=1.14, accuracy=0.752, val_loss=1.51, val_accuracy=0.616, lr=0.1] 41%|████      | 34/83 [12:12<16:25, 20.12s/epoch, loss=1.13, accuracy=0.753, val_loss=2.05, val_accuracy=0.467, lr=0.1] 42%|████▏     | 35/83 [12:32<16:04, 20.08s/epoch, loss=1.15, accuracy=0.751, val_loss=1.67, val_accuracy=0.563, lr=0.1] 43%|████▎     | 36/83 [12:52<15:47, 20.15s/epoch, loss=1.14, accuracy=0.752, val_loss=2.48, val_accuracy=0.439, lr=0.0316] 45%|████▍     | 37/83 [13:12<15:28, 20.19s/epoch, loss=1.14, accuracy=0.756, val_loss=4.58, val_accuracy=0.321, lr=0.1]    46%|████▌     | 38/83 [13:33<15:10, 20.23s/epoch, loss=1.14, accuracy=0.754, val_loss=1.59, val_accuracy=0.598, lr=0.1] 47%|████▋     | 39/83 [13:53<14:52, 20.28s/epoch, loss=1.13, accuracy=0.754, val_loss=2.15, val_accuracy=0.475, lr=0.1] 48%|████▊     | 40/83 [14:13<14:31, 20.27s/epoch, loss=1.14, accuracy=0.753, val_loss=2.94, val_accuracy=0.321, lr=0.1] 49%|████▉     | 41/83 [14:34<14:13, 20.31s/epoch, loss=1.13, accuracy=0.755, val_loss=1.93, val_accuracy=0.491, lr=0.0316] 51%|█████     | 42/83 [14:54<13:52, 20.31s/epoch, loss=1.13, accuracy=0.757, val_loss=2.32, val_accuracy=0.463, lr=0.1]    52%|█████▏    | 43/83 [15:15<13:34, 20.35s/epoch, loss=1.13, accuracy=0.754, val_loss=2.12, val_accuracy=0.487, lr=0.1] 53%|█████▎    | 44/83 [15:35<13:16, 20.41s/epoch, loss=1.13, accuracy=0.757, val_loss=3.83, val_accuracy=0.362, lr=0.1] 54%|█████▍    | 45/83 [15:55<12:53, 20.36s/epoch, loss=1.13, accuracy=0.754, val_loss=1.51, val_accuracy=0.623, lr=0.1] 55%|█████▌    | 46/83 [16:16<12:34, 20.39s/epoch, loss=1.13, accuracy=0.754, val_loss=2.02, val_accuracy=0.499, lr=0.0316] 57%|█████▋    | 47/83 [16:36<12:11, 20.31s/epoch, loss=1.14, accuracy=0.754, val_loss=1.66, val_accuracy=0.565, lr=0.1]    58%|█████▊    | 48/83 [16:56<11:51, 20.34s/epoch, loss=1.13, accuracy=0.752, val_loss=1.68, val_accuracy=0.545, lr=0.1] 59%|█████▉    | 49/83 [17:17<11:30, 20.32s/epoch, loss=1.14, accuracy=0.753, val_loss=1.65, val_accuracy=0.566, lr=0.1] 60%|██████    | 50/83 [17:37<11:06, 20.21s/epoch, loss=1.13, accuracy=0.756, val_loss=2.11, val_accuracy=0.514, lr=0.1] 61%|██████▏   | 51/83 [17:57<10:46, 20.19s/epoch, loss=1.13, accuracy=0.756, val_loss=1.82, val_accuracy=0.571, lr=0.0316] 63%|██████▎   | 52/83 [18:17<10:25, 20.18s/epoch, loss=1.13, accuracy=0.756, val_loss=1.65, val_accuracy=0.589, lr=0.1]    64%|██████▍   | 53/83 [18:37<10:06, 20.22s/epoch, loss=1.13, accuracy=0.755, val_loss=1.81, val_accuracy=0.579, lr=0.1] 65%|██████▌   | 54/83 [18:58<09:47, 20.26s/epoch, loss=1.12, accuracy=0.757, val_loss=1.9, val_accuracy=0.51, lr=0.1]   66%|██████▋   | 55/83 [19:18<09:28, 20.30s/epoch, loss=1.12, accuracy=0.755, val_loss=1.81, val_accuracy=0.549, lr=0.1] 67%|██████▋   | 56/83 [19:38<09:08, 20.30s/epoch, loss=1.13, accuracy=0.755, val_loss=3.77, val_accuracy=0.35, lr=0.0316] 69%|██████▊   | 57/83 [19:58<08:45, 20.20s/epoch, loss=1.13, accuracy=0.756, val_loss=2.04, val_accuracy=0.537, lr=0.1]   70%|██████▉   | 58/83 [20:18<08:25, 20.22s/epoch, loss=1.12, accuracy=0.756, val_loss=2.16, val_accuracy=0.505, lr=0.1] 71%|███████   | 59/83 [20:38<08:03, 20.17s/epoch, loss=1.12, accuracy=0.758, val_loss=2.08, val_accuracy=0.492, lr=0.1] 72%|███████▏  | 60/83 [20:59<07:43, 20.17s/epoch, loss=1.12, accuracy=0.757, val_loss=2.21, val_accuracy=0.477, lr=0.1] 73%|███████▎  | 61/83 [21:19<07:22, 20.14s/epoch, loss=1.13, accuracy=0.757, val_loss=2.06, val_accuracy=0.419, lr=0.0316] 75%|███████▍  | 62/83 [21:39<07:02, 20.12s/epoch, loss=1.12, accuracy=0.756, val_loss=2.08, val_accuracy=0.485, lr=0.1]    76%|███████▌  | 63/83 [21:59<06:40, 20.03s/epoch, loss=1.12, accuracy=0.757, val_loss=2.05, val_accuracy=0.498, lr=0.1] 77%|███████▋  | 64/83 [22:19<06:20, 20.03s/epoch, loss=1.12, accuracy=0.757, val_loss=1.41, val_accuracy=0.655, lr=0.1] 78%|███████▊  | 65/83 [22:38<05:58, 19.94s/epoch, loss=1.12, accuracy=0.756, val_loss=1.52, val_accuracy=0.626, lr=0.1] 80%|███████▉  | 66/83 [22:58<05:39, 19.99s/epoch, loss=1.12, accuracy=0.758, val_loss=2.92, val_accuracy=0.408, lr=0.1] 81%|████████  | 67/83 [23:18<05:18, 19.88s/epoch, loss=1.12, accuracy=0.758, val_loss=3.4, val_accuracy=0.275, lr=0.1]  82%|████████▏ | 68/83 [23:38<04:58, 19.91s/epoch, loss=1.13, accuracy=0.756, val_loss=1.72, val_accuracy=0.586, lr=0.1] 83%|████████▎ | 69/83 [23:58<04:39, 19.96s/epoch, loss=1.12, accuracy=0.755, val_loss=1.8, val_accuracy=0.57, lr=0.0316] 84%|████████▍ | 70/83 [24:18<04:18, 19.91s/epoch, loss=1.12, accuracy=0.758, val_loss=2.15, val_accuracy=0.498, lr=0.1]  86%|████████▌ | 71/83 [24:38<03:58, 19.90s/epoch, loss=1.12, accuracy=0.754, val_loss=2.4, val_accuracy=0.492, lr=0.1]  87%|████████▋ | 72/83 [24:58<03:39, 19.94s/epoch, loss=1.12, accuracy=0.757, val_loss=1.67, val_accuracy=0.598, lr=0.1] 88%|████████▊ | 73/83 [25:18<03:19, 19.95s/epoch, loss=1.12, accuracy=0.756, val_loss=2.49, val_accuracy=0.476, lr=0.1] 89%|████████▉ | 74/83 [25:38<02:59, 19.99s/epoch, loss=1.12, accuracy=0.756, val_loss=2.27, val_accuracy=0.461, lr=0.0316] 90%|█████████ | 75/83 [25:58<02:39, 19.98s/epoch, loss=1.12, accuracy=0.755, val_loss=1.58, val_accuracy=0.613, lr=0.1]    92%|█████████▏| 76/83 [26:18<02:19, 19.95s/epoch, loss=1.12, accuracy=0.757, val_loss=3.36, val_accuracy=0.378, lr=0.1] 93%|█████████▎| 77/83 [26:38<01:59, 19.96s/epoch, loss=1.12, accuracy=0.757, val_loss=3.29, val_accuracy=0.38, lr=0.1]  94%|█████████▍| 78/83 [26:58<01:39, 19.97s/epoch, loss=1.13, accuracy=0.755, val_loss=1.82, val_accuracy=0.554, lr=0.1] 95%|█████████▌| 79/83 [27:18<01:19, 19.97s/epoch, loss=1.13, accuracy=0.755, val_loss=2.18, val_accuracy=0.475, lr=0.0316] 96%|█████████▋| 80/83 [27:38<00:59, 19.97s/epoch, loss=1.12, accuracy=0.755, val_loss=2.84, val_accuracy=0.468, lr=0.1]    98%|█████████▊| 81/83 [27:58<00:39, 19.93s/epoch, loss=1.12, accuracy=0.758, val_loss=8.87, val_accuracy=0.141, lr=0.1] 99%|█████████▉| 82/83 [28:17<00:19, 19.91s/epoch, loss=0.926, accuracy=0.813, val_loss=0.956, val_accuracy=0.778, lr=0.01]100%|██████████| 83/83 [28:37<00:00, 19.89s/epoch, loss=0.741, accuracy=0.845, val_loss=0.814, val_accuracy=0.805, lr=0.01]100%|██████████| 83/83 [28:37<00:00, 20.70s/epoch, loss=0.741, accuracy=0.845, val_loss=0.814, val_accuracy=0.805, lr=0.01]
Using real-time data augmentation.
Test score: 0.8136487603187561
Test accuracy: 0.8047999739646912


* * * Run SGD for ID = 18_11. * * *


2024-03-05 14:40:35.641154: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 14:40:38.299694: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 14:40:38.300772: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-05 14:40:38.337718: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-03-05 14:40:38.337814: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 14:40:38.340671: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 14:40:38.340714: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 14:40:38.342997: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 14:40:38.343690: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 14:40:38.346113: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 14:40:38.347604: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 14:40:38.352297: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 14:40:38.352927: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 14:40:38.353038: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 14:40:39.628731: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-05 14:40:39.629304: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 14:40:39.630063: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-03-05 14:40:39.630095: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 14:40:39.630132: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 14:40:39.630150: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 14:40:39.630165: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 14:40:39.630181: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 14:40:39.630196: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 14:40:39.630211: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 14:40:39.630225: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 14:40:39.630641: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 14:40:39.630682: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 14:40:40.267218: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-05 14:40:40.267262: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-05 14:40:40.267278: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-05 14:40:40.268186: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': '18_11', 'seed': 11, 'out_folder': 'results/epoch_budget', 'batch_size': 128, 'epochs': 83, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'bootstrapping': False, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/83 [00:00<?, ?epoch/s]2024-03-05 14:40:41.120634: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-05 14:40:41.133163: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600020000 Hz
2024-03-05 14:40:43.163132: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 14:40:43.397232: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 14:40:44.165443: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-05 14:40:44.227571: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/83 [01:05<1:30:02, 65.88s/epoch, loss=2.78, accuracy=0.422, val_loss=2.22, val_accuracy=0.371, lr=0.1]  2%|▏         | 2/83 [01:26<53:18, 39.48s/epoch, loss=1.44, accuracy=0.61, val_loss=2.1, val_accuracy=0.462, lr=0.1]      4%|▎         | 3/83 [01:48<41:29, 31.12s/epoch, loss=1.29, accuracy=0.674, val_loss=1.58, val_accuracy=0.576, lr=0.1]  5%|▍         | 4/83 [02:09<35:44, 27.14s/epoch, loss=1.25, accuracy=0.701, val_loss=2, val_accuracy=0.448, lr=0.1]     6%|▌         | 5/83 [02:30<32:21, 24.89s/epoch, loss=1.23, accuracy=0.713, val_loss=1.69, val_accuracy=0.57, lr=0.1]  7%|▋         | 6/83 [02:50<30:14, 23.56s/epoch, loss=1.22, accuracy=0.724, val_loss=1.84, val_accuracy=0.548, lr=0.1]  8%|▊         | 7/83 [03:11<28:43, 22.68s/epoch, loss=1.21, accuracy=0.729, val_loss=2.34, val_accuracy=0.387, lr=0.1] 10%|▉         | 8/83 [03:32<27:39, 22.13s/epoch, loss=1.2, accuracy=0.734, val_loss=2.54, val_accuracy=0.39, lr=0.0316] 11%|█         | 9/83 [03:53<26:49, 21.74s/epoch, loss=1.2, accuracy=0.733, val_loss=1.82, val_accuracy=0.554, lr=0.1]   12%|█▏        | 10/83 [04:14<26:09, 21.50s/epoch, loss=1.2, accuracy=0.736, val_loss=2.09, val_accuracy=0.478, lr=0.1] 13%|█▎        | 11/83 [04:35<25:40, 21.39s/epoch, loss=1.18, accuracy=0.742, val_loss=2.84, val_accuracy=0.382, lr=0.1] 14%|█▍        | 12/83 [04:56<25:09, 21.26s/epoch, loss=1.18, accuracy=0.742, val_loss=1.66, val_accuracy=0.606, lr=0.1] 16%|█▌        | 13/83 [05:17<24:45, 21.22s/epoch, loss=1.18, accuracy=0.743, val_loss=1.49, val_accuracy=0.634, lr=0.1] 17%|█▋        | 14/83 [05:38<24:17, 21.12s/epoch, loss=1.17, accuracy=0.744, val_loss=2.41, val_accuracy=0.479, lr=0.1] 18%|█▊        | 15/83 [05:59<23:51, 21.06s/epoch, loss=1.17, accuracy=0.745, val_loss=1.93, val_accuracy=0.549, lr=0.1] 19%|█▉        | 16/83 [06:20<23:33, 21.09s/epoch, loss=1.16, accuracy=0.749, val_loss=1.8, val_accuracy=0.567, lr=0.1]  20%|██        | 17/83 [06:41<23:12, 21.10s/epoch, loss=1.16, accuracy=0.749, val_loss=1.54, val_accuracy=0.61, lr=0.1] 22%|██▏       | 18/83 [07:02<22:49, 21.07s/epoch, loss=1.16, accuracy=0.749, val_loss=2.23, val_accuracy=0.458, lr=0.0316] 23%|██▎       | 19/83 [07:23<22:27, 21.05s/epoch, loss=1.16, accuracy=0.75, val_loss=1.78, val_accuracy=0.545, lr=0.1]     24%|██▍       | 20/83 [07:44<22:03, 21.01s/epoch, loss=1.16, accuracy=0.751, val_loss=2.03, val_accuracy=0.486, lr=0.1] 25%|██▌       | 21/83 [08:05<21:42, 21.00s/epoch, loss=1.15, accuracy=0.75, val_loss=2.67, val_accuracy=0.376, lr=0.1]  27%|██▋       | 22/83 [08:26<21:18, 20.97s/epoch, loss=1.14, accuracy=0.753, val_loss=1.96, val_accuracy=0.496, lr=0.1] 28%|██▊       | 23/83 [08:47<20:57, 20.96s/epoch, loss=1.15, accuracy=0.752, val_loss=1.71, val_accuracy=0.558, lr=0.0316] 29%|██▉       | 24/83 [09:09<20:42, 21.07s/epoch, loss=1.14, accuracy=0.754, val_loss=1.9, val_accuracy=0.529, lr=0.1]     30%|███       | 25/83 [09:30<20:24, 21.10s/epoch, loss=1.14, accuracy=0.753, val_loss=2.37, val_accuracy=0.456, lr=0.1] 31%|███▏      | 26/83 [09:51<20:04, 21.14s/epoch, loss=1.14, accuracy=0.752, val_loss=1.93, val_accuracy=0.52, lr=0.1]  33%|███▎      | 27/83 [10:12<19:45, 21.16s/epoch, loss=1.14, accuracy=0.75, val_loss=1.82, val_accuracy=0.511, lr=0.1] 34%|███▎      | 28/83 [10:33<19:22, 21.14s/epoch, loss=1.14, accuracy=0.754, val_loss=1.82, val_accuracy=0.526, lr=0.0316] 35%|███▍      | 29/83 [10:55<19:06, 21.23s/epoch, loss=1.14, accuracy=0.755, val_loss=1.57, val_accuracy=0.599, lr=0.1]    36%|███▌      | 30/83 [11:16<18:41, 21.17s/epoch, loss=1.13, accuracy=0.755, val_loss=1.93, val_accuracy=0.559, lr=0.1] 37%|███▋      | 31/83 [11:37<18:20, 21.17s/epoch, loss=1.13, accuracy=0.756, val_loss=1.84, val_accuracy=0.554, lr=0.1] 39%|███▊      | 32/83 [11:58<17:57, 21.12s/epoch, loss=1.13, accuracy=0.757, val_loss=2.52, val_accuracy=0.441, lr=0.1] 40%|███▉      | 33/83 [12:19<17:33, 21.07s/epoch, loss=1.13, accuracy=0.759, val_loss=2.32, val_accuracy=0.474, lr=0.0316] 41%|████      | 34/83 [12:40<17:11, 21.05s/epoch, loss=1.13, accuracy=0.757, val_loss=1.84, val_accuracy=0.517, lr=0.1]    42%|████▏     | 35/83 [13:01<16:51, 21.07s/epoch, loss=1.14, accuracy=0.756, val_loss=4.1, val_accuracy=0.241, lr=0.1]  43%|████▎     | 36/83 [13:22<16:30, 21.08s/epoch, loss=1.13, accuracy=0.757, val_loss=2.43, val_accuracy=0.468, lr=0.1] 45%|████▍     | 37/83 [13:43<16:10, 21.11s/epoch, loss=1.13, accuracy=0.757, val_loss=1.75, val_accuracy=0.592, lr=0.1] 46%|████▌     | 38/83 [14:04<15:46, 21.04s/epoch, loss=1.13, accuracy=0.756, val_loss=2.34, val_accuracy=0.422, lr=0.0316] 47%|████▋     | 39/83 [14:25<15:26, 21.07s/epoch, loss=1.13, accuracy=0.756, val_loss=3.01, val_accuracy=0.309, lr=0.1]    48%|████▊     | 40/83 [14:46<15:04, 21.04s/epoch, loss=1.13, accuracy=0.757, val_loss=2.18, val_accuracy=0.5, lr=0.1]   49%|████▉     | 41/83 [15:07<14:42, 21.00s/epoch, loss=1.12, accuracy=0.756, val_loss=2.33, val_accuracy=0.348, lr=0.1] 51%|█████     | 42/83 [15:28<14:20, 20.98s/epoch, loss=1.13, accuracy=0.757, val_loss=2.16, val_accuracy=0.448, lr=0.1] 52%|█████▏    | 43/83 [15:49<13:59, 20.99s/epoch, loss=1.13, accuracy=0.759, val_loss=1.52, val_accuracy=0.628, lr=0.0316] 53%|█████▎    | 44/83 [16:10<13:35, 20.92s/epoch, loss=1.13, accuracy=0.758, val_loss=1.54, val_accuracy=0.612, lr=0.1]    54%|█████▍    | 45/83 [16:31<13:15, 20.94s/epoch, loss=1.12, accuracy=0.759, val_loss=2.2, val_accuracy=0.468, lr=0.1]  55%|█████▌    | 46/83 [16:52<12:55, 20.97s/epoch, loss=1.13, accuracy=0.758, val_loss=1.71, val_accuracy=0.522, lr=0.1] 57%|█████▋    | 47/83 [17:13<12:35, 20.99s/epoch, loss=1.12, accuracy=0.758, val_loss=1.85, val_accuracy=0.549, lr=0.1] 58%|█████▊    | 48/83 [17:34<12:16, 21.04s/epoch, loss=1.12, accuracy=0.759, val_loss=1.57, val_accuracy=0.602, lr=0.0316] 59%|█████▉    | 49/83 [17:55<11:57, 21.09s/epoch, loss=1.12, accuracy=0.758, val_loss=1.53, val_accuracy=0.593, lr=0.1]    60%|██████    | 50/83 [18:16<11:34, 21.05s/epoch, loss=1.12, accuracy=0.757, val_loss=3.07, val_accuracy=0.316, lr=0.1] 61%|██████▏   | 51/83 [18:37<11:15, 21.12s/epoch, loss=1.12, accuracy=0.757, val_loss=1.67, val_accuracy=0.559, lr=0.1] 63%|██████▎   | 52/83 [18:58<10:52, 21.05s/epoch, loss=1.11, accuracy=0.76, val_loss=1.68, val_accuracy=0.597, lr=0.1]  64%|██████▍   | 53/83 [19:19<10:30, 21.03s/epoch, loss=1.12, accuracy=0.759, val_loss=2.07, val_accuracy=0.501, lr=0.0316] 65%|██████▌   | 54/83 [19:40<10:09, 21.01s/epoch, loss=1.12, accuracy=0.759, val_loss=1.84, val_accuracy=0.558, lr=0.1]    66%|██████▋   | 55/83 [20:01<09:47, 20.97s/epoch, loss=1.12, accuracy=0.757, val_loss=2.01, val_accuracy=0.508, lr=0.1] 67%|██████▋   | 56/83 [20:22<09:26, 20.99s/epoch, loss=1.11, accuracy=0.76, val_loss=2.05, val_accuracy=0.455, lr=0.1]  69%|██████▊   | 57/83 [20:43<09:06, 21.00s/epoch, loss=1.12, accuracy=0.758, val_loss=1.84, val_accuracy=0.526, lr=0.1] 70%|██████▉   | 58/83 [21:04<08:44, 20.98s/epoch, loss=1.12, accuracy=0.759, val_loss=3.72, val_accuracy=0.305, lr=0.0316] 71%|███████   | 59/83 [21:25<08:22, 20.95s/epoch, loss=1.12, accuracy=0.76, val_loss=1.41, val_accuracy=0.649, lr=0.1]     72%|███████▏  | 60/83 [21:46<08:02, 20.98s/epoch, loss=1.11, accuracy=0.759, val_loss=5.42, val_accuracy=0.161, lr=0.1] 73%|███████▎  | 61/83 [22:07<07:43, 21.05s/epoch, loss=1.11, accuracy=0.758, val_loss=1.89, val_accuracy=0.506, lr=0.1] 75%|███████▍  | 62/83 [22:29<07:23, 21.13s/epoch, loss=1.12, accuracy=0.759, val_loss=5.67, val_accuracy=0.235, lr=0.1] 76%|███████▌  | 63/83 [22:50<07:01, 21.07s/epoch, loss=1.11, accuracy=0.76, val_loss=2.01, val_accuracy=0.534, lr=0.1]  77%|███████▋  | 64/83 [23:11<06:39, 21.04s/epoch, loss=1.11, accuracy=0.758, val_loss=2.51, val_accuracy=0.445, lr=0.0316] 78%|███████▊  | 65/83 [23:32<06:18, 21.05s/epoch, loss=1.12, accuracy=0.758, val_loss=4.07, val_accuracy=0.299, lr=0.1]    80%|███████▉  | 66/83 [23:52<05:56, 20.98s/epoch, loss=1.11, accuracy=0.762, val_loss=2.53, val_accuracy=0.39, lr=0.1]  81%|████████  | 67/83 [24:13<05:34, 20.93s/epoch, loss=1.11, accuracy=0.762, val_loss=2.44, val_accuracy=0.454, lr=0.1] 82%|████████▏ | 68/83 [24:34<05:12, 20.84s/epoch, loss=1.11, accuracy=0.757, val_loss=2.21, val_accuracy=0.377, lr=0.1] 83%|████████▎ | 69/83 [24:55<04:51, 20.83s/epoch, loss=1.11, accuracy=0.76, val_loss=2.59, val_accuracy=0.28, lr=0.0316] 84%|████████▍ | 70/83 [25:16<04:31, 20.85s/epoch, loss=1.11, accuracy=0.76, val_loss=2.46, val_accuracy=0.383, lr=0.1]   86%|████████▌ | 71/83 [25:36<04:10, 20.86s/epoch, loss=1.12, accuracy=0.759, val_loss=1.93, val_accuracy=0.532, lr=0.1] 87%|████████▋ | 72/83 [25:57<03:50, 20.91s/epoch, loss=1.11, accuracy=0.76, val_loss=1.53, val_accuracy=0.606, lr=0.1]  88%|████████▊ | 73/83 [26:18<03:29, 20.91s/epoch, loss=1.11, accuracy=0.759, val_loss=3.06, val_accuracy=0.378, lr=0.1] 89%|████████▉ | 74/83 [26:39<03:08, 20.94s/epoch, loss=1.11, accuracy=0.756, val_loss=1.94, val_accuracy=0.503, lr=0.0316] 90%|█████████ | 75/83 [27:00<02:47, 20.98s/epoch, loss=1.11, accuracy=0.76, val_loss=1.58, val_accuracy=0.587, lr=0.1]     92%|█████████▏| 76/83 [27:21<02:26, 20.98s/epoch, loss=1.1, accuracy=0.761, val_loss=1.61, val_accuracy=0.605, lr=0.1] 93%|█████████▎| 77/83 [27:43<02:06, 21.02s/epoch, loss=1.1, accuracy=0.76, val_loss=2.25, val_accuracy=0.391, lr=0.1]  94%|█████████▍| 78/83 [28:04<01:45, 21.04s/epoch, loss=1.11, accuracy=0.76, val_loss=1.59, val_accuracy=0.611, lr=0.1] 95%|█████████▌| 79/83 [28:25<01:24, 21.04s/epoch, loss=1.11, accuracy=0.757, val_loss=1.71, val_accuracy=0.528, lr=0.0316] 96%|█████████▋| 80/83 [28:46<01:03, 21.04s/epoch, loss=1.11, accuracy=0.757, val_loss=1.88, val_accuracy=0.527, lr=0.1]    98%|█████████▊| 81/83 [29:07<00:41, 20.99s/epoch, loss=1.1, accuracy=0.757, val_loss=2.09, val_accuracy=0.454, lr=0.1]  99%|█████████▉| 82/83 [29:28<00:20, 20.97s/epoch, loss=0.902, accuracy=0.819, val_loss=0.839, val_accuracy=0.826, lr=0.01]100%|██████████| 83/83 [29:48<00:00, 20.94s/epoch, loss=0.721, accuracy=0.852, val_loss=0.791, val_accuracy=0.81, lr=0.01] 100%|██████████| 83/83 [29:48<00:00, 21.55s/epoch, loss=0.721, accuracy=0.852, val_loss=0.791, val_accuracy=0.81, lr=0.01]
Using real-time data augmentation.
Test score: 0.7913020253181458
Test accuracy: 0.8102999925613403


* * * Run SGD for ID = 18_12. * * *


2024-03-05 15:10:33.788025: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 15:10:36.475934: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 15:10:36.477179: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-05 15:10:36.514325: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-03-05 15:10:36.514369: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 15:10:36.517057: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 15:10:36.517116: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 15:10:36.519202: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 15:10:36.519985: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 15:10:36.522254: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 15:10:36.523596: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 15:10:36.527947: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 15:10:36.528561: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 15:10:36.528671: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 15:10:37.776317: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-05 15:10:37.777365: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 15:10:37.778111: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-03-05 15:10:37.778145: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 15:10:37.778180: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 15:10:37.778196: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 15:10:37.778211: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 15:10:37.778228: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 15:10:37.778243: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 15:10:37.778258: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 15:10:37.778274: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 15:10:37.778701: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 15:10:37.778738: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 15:10:38.425255: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-05 15:10:38.425320: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-05 15:10:38.425328: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-05 15:10:38.426281: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': '18_12', 'seed': 12, 'out_folder': 'results/epoch_budget', 'batch_size': 128, 'epochs': 83, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'bootstrapping': False, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/83 [00:00<?, ?epoch/s]2024-03-05 15:10:39.301689: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-05 15:10:39.314121: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600020000 Hz
2024-03-05 15:10:41.312297: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 15:10:41.517004: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 15:10:42.176265: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-05 15:10:42.237532: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/83 [01:04<1:28:35, 64.82s/epoch, loss=3, accuracy=0.349, val_loss=2.4, val_accuracy=0.312, lr=0.1]  2%|▏         | 2/83 [01:25<52:14, 38.70s/epoch, loss=1.51, accuracy=0.559, val_loss=6.09, val_accuracy=0.194, lr=0.1]  4%|▎         | 3/83 [01:45<40:31, 30.39s/epoch, loss=1.35, accuracy=0.634, val_loss=2.63, val_accuracy=0.41, lr=0.1]   5%|▍         | 4/83 [02:06<34:50, 26.46s/epoch, loss=1.28, accuracy=0.677, val_loss=2.22, val_accuracy=0.446, lr=0.1]  6%|▌         | 5/83 [02:26<31:32, 24.27s/epoch, loss=1.25, accuracy=0.698, val_loss=1.93, val_accuracy=0.487, lr=0.1]  7%|▋         | 6/83 [02:47<29:28, 22.97s/epoch, loss=1.23, accuracy=0.71, val_loss=2.14, val_accuracy=0.451, lr=0.1]   8%|▊         | 7/83 [03:07<28:01, 22.13s/epoch, loss=1.22, accuracy=0.72, val_loss=1.9, val_accuracy=0.501, lr=0.1]  10%|▉         | 8/83 [03:27<26:56, 21.56s/epoch, loss=1.21, accuracy=0.721, val_loss=1.77, val_accuracy=0.57, lr=0.1] 11%|█         | 9/83 [03:48<26:08, 21.19s/epoch, loss=1.19, accuracy=0.729, val_loss=1.58, val_accuracy=0.596, lr=0.1] 12%|█▏        | 10/83 [04:08<25:30, 20.97s/epoch, loss=1.19, accuracy=0.732, val_loss=3.17, val_accuracy=0.43, lr=0.1] 13%|█▎        | 11/83 [04:29<25:06, 20.92s/epoch, loss=1.19, accuracy=0.733, val_loss=2.03, val_accuracy=0.486, lr=0.1] 14%|█▍        | 12/83 [04:50<24:46, 20.94s/epoch, loss=1.19, accuracy=0.735, val_loss=2.37, val_accuracy=0.436, lr=0.1] 16%|█▌        | 13/83 [05:10<24:16, 20.81s/epoch, loss=1.17, accuracy=0.74, val_loss=2.09, val_accuracy=0.464, lr=0.1]  17%|█▋        | 14/83 [05:31<23:48, 20.70s/epoch, loss=1.17, accuracy=0.741, val_loss=3.22, val_accuracy=0.362, lr=0.0316] 18%|█▊        | 15/83 [05:51<23:23, 20.64s/epoch, loss=1.17, accuracy=0.743, val_loss=2.21, val_accuracy=0.431, lr=0.1]    19%|█▉        | 16/83 [06:12<22:56, 20.54s/epoch, loss=1.16, accuracy=0.746, val_loss=2.62, val_accuracy=0.438, lr=0.1] 20%|██        | 17/83 [06:32<22:32, 20.49s/epoch, loss=1.16, accuracy=0.745, val_loss=1.5, val_accuracy=0.624, lr=0.1]  22%|██▏       | 18/83 [06:52<22:09, 20.45s/epoch, loss=1.15, accuracy=0.748, val_loss=2.02, val_accuracy=0.53, lr=0.1] 23%|██▎       | 19/83 [07:13<21:45, 20.40s/epoch, loss=1.16, accuracy=0.747, val_loss=2.07, val_accuracy=0.519, lr=0.1] 24%|██▍       | 20/83 [07:33<21:26, 20.42s/epoch, loss=1.16, accuracy=0.748, val_loss=1.63, val_accuracy=0.581, lr=0.1] 25%|██▌       | 21/83 [07:54<21:06, 20.42s/epoch, loss=1.15, accuracy=0.746, val_loss=1.57, val_accuracy=0.598, lr=0.1] 27%|██▋       | 22/83 [08:14<20:43, 20.38s/epoch, loss=1.14, accuracy=0.749, val_loss=4.84, val_accuracy=0.232, lr=0.0316] 28%|██▊       | 23/83 [08:34<20:19, 20.32s/epoch, loss=1.15, accuracy=0.75, val_loss=1.43, val_accuracy=0.651, lr=0.1]     29%|██▉       | 24/83 [08:54<19:58, 20.31s/epoch, loss=1.13, accuracy=0.753, val_loss=1.89, val_accuracy=0.508, lr=0.1] 30%|███       | 25/83 [09:15<19:42, 20.39s/epoch, loss=1.14, accuracy=0.753, val_loss=3.17, val_accuracy=0.34, lr=0.1]  31%|███▏      | 26/83 [09:35<19:21, 20.37s/epoch, loss=1.14, accuracy=0.751, val_loss=1.57, val_accuracy=0.62, lr=0.1] 33%|███▎      | 27/83 [09:56<18:59, 20.35s/epoch, loss=1.13, accuracy=0.754, val_loss=1.7, val_accuracy=0.587, lr=0.1] 34%|███▎      | 28/83 [10:16<18:41, 20.38s/epoch, loss=1.13, accuracy=0.754, val_loss=2.63, val_accuracy=0.299, lr=0.0316] 35%|███▍      | 29/83 [10:36<18:18, 20.34s/epoch, loss=1.14, accuracy=0.756, val_loss=2.42, val_accuracy=0.362, lr=0.1]    36%|███▌      | 30/83 [10:57<18:00, 20.39s/epoch, loss=1.13, accuracy=0.755, val_loss=2.78, val_accuracy=0.403, lr=0.1] 37%|███▋      | 31/83 [11:17<17:42, 20.44s/epoch, loss=1.13, accuracy=0.754, val_loss=2, val_accuracy=0.478, lr=0.1]    39%|███▊      | 32/83 [11:38<17:19, 20.38s/epoch, loss=1.14, accuracy=0.754, val_loss=1.47, val_accuracy=0.637, lr=0.1] 40%|███▉      | 33/83 [11:58<16:57, 20.36s/epoch, loss=1.13, accuracy=0.75, val_loss=2.19, val_accuracy=0.39, lr=0.0316] 41%|████      | 34/83 [12:18<16:36, 20.33s/epoch, loss=1.13, accuracy=0.754, val_loss=1.96, val_accuracy=0.503, lr=0.1]  42%|████▏     | 35/83 [12:38<16:14, 20.30s/epoch, loss=1.13, accuracy=0.753, val_loss=1.6, val_accuracy=0.605, lr=0.1]  43%|████▎     | 36/83 [12:59<15:53, 20.28s/epoch, loss=1.13, accuracy=0.755, val_loss=2.44, val_accuracy=0.266, lr=0.1] 45%|████▍     | 37/83 [13:19<15:32, 20.28s/epoch, loss=1.12, accuracy=0.753, val_loss=1.61, val_accuracy=0.592, lr=0.1] 46%|████▌     | 38/83 [13:39<15:14, 20.32s/epoch, loss=1.12, accuracy=0.756, val_loss=2.17, val_accuracy=0.432, lr=0.0316] 47%|████▋     | 39/83 [14:00<14:56, 20.39s/epoch, loss=1.12, accuracy=0.758, val_loss=2.35, val_accuracy=0.335, lr=0.1]    48%|████▊     | 40/83 [14:20<14:37, 20.40s/epoch, loss=1.13, accuracy=0.755, val_loss=2.48, val_accuracy=0.484, lr=0.1] 49%|████▉     | 41/83 [14:40<14:13, 20.33s/epoch, loss=1.12, accuracy=0.758, val_loss=2.4, val_accuracy=0.468, lr=0.1]  51%|█████     | 42/83 [15:01<13:54, 20.35s/epoch, loss=1.11, accuracy=0.758, val_loss=2.04, val_accuracy=0.419, lr=0.1] 52%|█████▏    | 43/83 [15:21<13:36, 20.41s/epoch, loss=1.13, accuracy=0.757, val_loss=1.67, val_accuracy=0.586, lr=0.0316] 53%|█████▎    | 44/83 [15:42<13:18, 20.46s/epoch, loss=1.12, accuracy=0.758, val_loss=1.91, val_accuracy=0.484, lr=0.1]    54%|█████▍    | 45/83 [16:02<12:58, 20.50s/epoch, loss=1.12, accuracy=0.757, val_loss=3.25, val_accuracy=0.346, lr=0.1] 55%|█████▌    | 46/83 [16:23<12:40, 20.56s/epoch, loss=1.12, accuracy=0.758, val_loss=2.13, val_accuracy=0.507, lr=0.1] 57%|█████▋    | 47/83 [16:44<12:19, 20.54s/epoch, loss=1.11, accuracy=0.759, val_loss=1.92, val_accuracy=0.493, lr=0.1] 58%|█████▊    | 48/83 [17:05<12:02, 20.64s/epoch, loss=1.11, accuracy=0.757, val_loss=1.73, val_accuracy=0.591, lr=0.0316] 59%|█████▉    | 49/83 [17:25<11:39, 20.58s/epoch, loss=1.12, accuracy=0.757, val_loss=1.59, val_accuracy=0.584, lr=0.1]    60%|██████    | 50/83 [17:45<11:16, 20.50s/epoch, loss=1.12, accuracy=0.756, val_loss=2.12, val_accuracy=0.486, lr=0.1] 61%|██████▏   | 51/83 [18:06<10:53, 20.42s/epoch, loss=1.12, accuracy=0.759, val_loss=1.67, val_accuracy=0.563, lr=0.1] 63%|██████▎   | 52/83 [18:26<10:30, 20.33s/epoch, loss=1.12, accuracy=0.756, val_loss=1.51, val_accuracy=0.635, lr=0.1] 64%|██████▍   | 53/83 [18:46<10:10, 20.35s/epoch, loss=1.11, accuracy=0.757, val_loss=2.47, val_accuracy=0.467, lr=0.0316] 65%|██████▌   | 54/83 [19:06<09:50, 20.35s/epoch, loss=1.12, accuracy=0.755, val_loss=1.51, val_accuracy=0.61, lr=0.1]     66%|██████▋   | 55/83 [19:27<09:32, 20.43s/epoch, loss=1.11, accuracy=0.758, val_loss=1.46, val_accuracy=0.661, lr=0.1] 67%|██████▋   | 56/83 [19:48<09:11, 20.44s/epoch, loss=1.12, accuracy=0.757, val_loss=2.77, val_accuracy=0.416, lr=0.1] 69%|██████▊   | 57/83 [20:08<08:49, 20.36s/epoch, loss=1.11, accuracy=0.759, val_loss=1.68, val_accuracy=0.581, lr=0.1] 70%|██████▉   | 58/83 [20:28<08:27, 20.32s/epoch, loss=1.11, accuracy=0.76, val_loss=2.84, val_accuracy=0.439, lr=0.0316] 71%|███████   | 59/83 [20:48<08:07, 20.30s/epoch, loss=1.11, accuracy=0.761, val_loss=2.98, val_accuracy=0.37, lr=0.1]    72%|███████▏  | 60/83 [21:08<07:46, 20.27s/epoch, loss=1.11, accuracy=0.76, val_loss=3.18, val_accuracy=0.427, lr=0.1] 73%|███████▎  | 61/83 [21:28<07:24, 20.23s/epoch, loss=1.12, accuracy=0.757, val_loss=1.79, val_accuracy=0.53, lr=0.1] 75%|███████▍  | 62/83 [21:49<07:05, 20.27s/epoch, loss=1.11, accuracy=0.759, val_loss=2.52, val_accuracy=0.29, lr=0.1] 76%|███████▌  | 63/83 [22:09<06:43, 20.20s/epoch, loss=1.11, accuracy=0.759, val_loss=1.65, val_accuracy=0.57, lr=0.0316] 77%|███████▋  | 64/83 [22:29<06:23, 20.20s/epoch, loss=1.11, accuracy=0.76, val_loss=3.11, val_accuracy=0.346, lr=0.1]    78%|███████▊  | 65/83 [22:49<06:03, 20.19s/epoch, loss=1.11, accuracy=0.76, val_loss=1.69, val_accuracy=0.591, lr=0.1] 80%|███████▉  | 66/83 [23:10<05:44, 20.25s/epoch, loss=1.11, accuracy=0.76, val_loss=2.05, val_accuracy=0.432, lr=0.1] 81%|████████  | 67/83 [23:30<05:22, 20.18s/epoch, loss=1.11, accuracy=0.759, val_loss=2, val_accuracy=0.492, lr=0.1]   82%|████████▏ | 68/83 [23:50<05:04, 20.28s/epoch, loss=1.11, accuracy=0.761, val_loss=4.53, val_accuracy=0.273, lr=0.0316] 83%|████████▎ | 69/83 [24:10<04:43, 20.27s/epoch, loss=1.11, accuracy=0.76, val_loss=1.76, val_accuracy=0.581, lr=0.1]     84%|████████▍ | 70/83 [24:31<04:22, 20.22s/epoch, loss=1.11, accuracy=0.76, val_loss=1.74, val_accuracy=0.564, lr=0.1] 86%|████████▌ | 71/83 [24:51<04:02, 20.17s/epoch, loss=1.11, accuracy=0.759, val_loss=1.84, val_accuracy=0.512, lr=0.1] 87%|████████▋ | 72/83 [25:11<03:41, 20.12s/epoch, loss=1.11, accuracy=0.759, val_loss=2.01, val_accuracy=0.435, lr=0.1] 88%|████████▊ | 73/83 [25:31<03:20, 20.10s/epoch, loss=1.11, accuracy=0.757, val_loss=1.78, val_accuracy=0.528, lr=0.0316] 89%|████████▉ | 74/83 [25:51<03:00, 20.06s/epoch, loss=1.11, accuracy=0.76, val_loss=3.11, val_accuracy=0.372, lr=0.1]     90%|█████████ | 75/83 [26:11<02:40, 20.07s/epoch, loss=1.11, accuracy=0.761, val_loss=1.38, val_accuracy=0.652, lr=0.1] 92%|█████████▏| 76/83 [26:31<02:20, 20.04s/epoch, loss=1.1, accuracy=0.758, val_loss=1.79, val_accuracy=0.571, lr=0.1]  93%|█████████▎| 77/83 [26:51<02:00, 20.06s/epoch, loss=1.11, accuracy=0.757, val_loss=1.88, val_accuracy=0.535, lr=0.1] 94%|█████████▍| 78/83 [27:11<01:40, 20.08s/epoch, loss=1.1, accuracy=0.76, val_loss=1.89, val_accuracy=0.495, lr=0.1]   95%|█████████▌| 79/83 [27:31<01:20, 20.03s/epoch, loss=1.1, accuracy=0.758, val_loss=4.4, val_accuracy=0.218, lr=0.1] 96%|█████████▋| 80/83 [27:51<00:59, 19.98s/epoch, loss=1.11, accuracy=0.758, val_loss=1.61, val_accuracy=0.592, lr=0.0316] 98%|█████████▊| 81/83 [28:11<00:39, 19.95s/epoch, loss=1.1, accuracy=0.758, val_loss=2.52, val_accuracy=0.439, lr=0.1]     99%|█████████▉| 82/83 [28:30<00:19, 19.90s/epoch, loss=0.888, accuracy=0.819, val_loss=0.875, val_accuracy=0.807, lr=0.01]100%|██████████| 83/83 [28:50<00:00, 19.86s/epoch, loss=0.716, accuracy=0.851, val_loss=0.764, val_accuracy=0.824, lr=0.01]100%|██████████| 83/83 [28:50<00:00, 20.85s/epoch, loss=0.716, accuracy=0.851, val_loss=0.764, val_accuracy=0.824, lr=0.01]
Using real-time data augmentation.
Test score: 0.7643089294433594
Test accuracy: 0.8238999843597412


* * * Run SGD for ID = 18_13. * * *


2024-03-05 15:39:33.772840: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 15:39:36.386634: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 15:39:36.387743: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-05 15:39:36.424055: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-03-05 15:39:36.424106: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 15:39:36.426892: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 15:39:36.426961: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 15:39:36.429139: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 15:39:36.429871: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 15:39:36.432175: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 15:39:36.433488: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 15:39:36.437923: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 15:39:36.438552: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 15:39:36.438638: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 15:39:37.670649: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-05 15:39:37.671754: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 15:39:37.672534: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-03-05 15:39:37.672571: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 15:39:37.672615: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 15:39:37.672632: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 15:39:37.672647: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 15:39:37.672664: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 15:39:37.672680: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 15:39:37.672702: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 15:39:37.672720: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 15:39:37.673178: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 15:39:37.673214: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 15:39:38.321976: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-05 15:39:38.322029: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-05 15:39:38.322037: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-05 15:39:38.322930: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': '18_13', 'seed': 13, 'out_folder': 'results/epoch_budget', 'batch_size': 128, 'epochs': 83, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'bootstrapping': False, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/83 [00:00<?, ?epoch/s]2024-03-05 15:39:39.196092: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-05 15:39:39.208125: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600020000 Hz
2024-03-05 15:39:41.263583: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 15:39:41.474410: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 15:39:42.265614: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-05 15:39:42.330072: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/83 [01:06<1:30:27, 66.19s/epoch, loss=2.87, accuracy=0.385, val_loss=4.02, val_accuracy=0.191, lr=0.1]  2%|▏         | 2/83 [01:26<53:12, 39.41s/epoch, loss=1.42, accuracy=0.61, val_loss=1.6, val_accuracy=0.566, lr=0.1]      4%|▎         | 3/83 [01:47<40:50, 30.63s/epoch, loss=1.27, accuracy=0.679, val_loss=2.66, val_accuracy=0.383, lr=0.1]  5%|▍         | 4/83 [02:06<34:44, 26.38s/epoch, loss=1.24, accuracy=0.696, val_loss=2.15, val_accuracy=0.418, lr=0.1]  6%|▌         | 5/83 [02:26<31:10, 23.98s/epoch, loss=1.22, accuracy=0.709, val_loss=2.02, val_accuracy=0.508, lr=0.1]  7%|▋         | 6/83 [02:46<29:07, 22.69s/epoch, loss=1.21, accuracy=0.717, val_loss=3.51, val_accuracy=0.312, lr=0.1]  8%|▊         | 7/83 [03:07<27:45, 21.92s/epoch, loss=1.2, accuracy=0.725, val_loss=1.73, val_accuracy=0.57, lr=0.0316] 10%|▉         | 8/83 [03:27<26:42, 21.36s/epoch, loss=1.19, accuracy=0.728, val_loss=2.7, val_accuracy=0.44, lr=0.1]    11%|█         | 9/83 [03:47<25:56, 21.03s/epoch, loss=1.18, accuracy=0.733, val_loss=1.65, val_accuracy=0.585, lr=0.1] 12%|█▏        | 10/83 [04:07<25:18, 20.80s/epoch, loss=1.19, accuracy=0.734, val_loss=5.7, val_accuracy=0.276, lr=0.1] 13%|█▎        | 11/83 [04:28<24:47, 20.66s/epoch, loss=1.18, accuracy=0.737, val_loss=2.08, val_accuracy=0.508, lr=0.1] 14%|█▍        | 12/83 [04:48<24:19, 20.55s/epoch, loss=1.18, accuracy=0.738, val_loss=1.47, val_accuracy=0.643, lr=0.1] 16%|█▌        | 13/83 [05:08<23:53, 20.49s/epoch, loss=1.17, accuracy=0.739, val_loss=1.71, val_accuracy=0.589, lr=0.1] 17%|█▋        | 14/83 [05:29<23:26, 20.39s/epoch, loss=1.17, accuracy=0.743, val_loss=1.94, val_accuracy=0.487, lr=0.1] 18%|█▊        | 15/83 [05:49<23:03, 20.35s/epoch, loss=1.17, accuracy=0.743, val_loss=1.64, val_accuracy=0.586, lr=0.1] 19%|█▉        | 16/83 [06:09<22:42, 20.34s/epoch, loss=1.16, accuracy=0.744, val_loss=2.76, val_accuracy=0.356, lr=0.1] 20%|██        | 17/83 [06:29<22:18, 20.28s/epoch, loss=1.15, accuracy=0.746, val_loss=1.39, val_accuracy=0.672, lr=0.1] 22%|██▏       | 18/83 [06:49<21:57, 20.26s/epoch, loss=1.15, accuracy=0.744, val_loss=1.87, val_accuracy=0.564, lr=0.1] 23%|██▎       | 19/83 [07:10<21:42, 20.35s/epoch, loss=1.15, accuracy=0.748, val_loss=2.22, val_accuracy=0.482, lr=0.1] 24%|██▍       | 20/83 [07:30<21:20, 20.33s/epoch, loss=1.15, accuracy=0.746, val_loss=1.68, val_accuracy=0.603, lr=0.1] 25%|██▌       | 21/83 [07:51<21:03, 20.37s/epoch, loss=1.15, accuracy=0.748, val_loss=1.61, val_accuracy=0.571, lr=0.1] 27%|██▋       | 22/83 [08:11<20:42, 20.37s/epoch, loss=1.15, accuracy=0.747, val_loss=1.93, val_accuracy=0.541, lr=0.0316] 28%|██▊       | 23/83 [08:32<20:22, 20.38s/epoch, loss=1.15, accuracy=0.749, val_loss=1.96, val_accuracy=0.487, lr=0.1]    29%|██▉       | 24/83 [08:52<20:03, 20.40s/epoch, loss=1.14, accuracy=0.748, val_loss=2.21, val_accuracy=0.402, lr=0.1] 30%|███       | 25/83 [09:12<19:41, 20.38s/epoch, loss=1.13, accuracy=0.752, val_loss=1.97, val_accuracy=0.576, lr=0.1] 31%|███▏      | 26/83 [09:33<19:24, 20.43s/epoch, loss=1.14, accuracy=0.749, val_loss=2.89, val_accuracy=0.382, lr=0.1] 33%|███▎      | 27/83 [09:53<19:02, 20.40s/epoch, loss=1.14, accuracy=0.751, val_loss=1.52, val_accuracy=0.619, lr=0.0316] 34%|███▎      | 28/83 [10:13<18:39, 20.35s/epoch, loss=1.13, accuracy=0.753, val_loss=3.41, val_accuracy=0.339, lr=0.1]    35%|███▍      | 29/83 [10:34<18:20, 20.38s/epoch, loss=1.13, accuracy=0.754, val_loss=1.91, val_accuracy=0.51, lr=0.1]  36%|███▌      | 30/83 [10:54<17:57, 20.33s/epoch, loss=1.13, accuracy=0.749, val_loss=3.2, val_accuracy=0.368, lr=0.1] 37%|███▋      | 31/83 [11:14<17:37, 20.33s/epoch, loss=1.12, accuracy=0.753, val_loss=3.56, val_accuracy=0.354, lr=0.1] 39%|███▊      | 32/83 [11:35<17:15, 20.31s/epoch, loss=1.12, accuracy=0.753, val_loss=1.9, val_accuracy=0.529, lr=0.0316] 40%|███▉      | 33/83 [11:55<16:54, 20.28s/epoch, loss=1.12, accuracy=0.755, val_loss=1.54, val_accuracy=0.597, lr=0.1]   41%|████      | 34/83 [12:15<16:33, 20.27s/epoch, loss=1.12, accuracy=0.757, val_loss=1.83, val_accuracy=0.515, lr=0.1] 42%|████▏     | 35/83 [12:35<16:10, 20.22s/epoch, loss=1.12, accuracy=0.754, val_loss=1.6, val_accuracy=0.587, lr=0.1]  43%|████▎     | 36/83 [12:55<15:49, 20.21s/epoch, loss=1.12, accuracy=0.755, val_loss=1.46, val_accuracy=0.645, lr=0.1] 45%|████▍     | 37/83 [13:16<15:32, 20.27s/epoch, loss=1.11, accuracy=0.754, val_loss=1.75, val_accuracy=0.59, lr=0.0316] 46%|████▌     | 38/83 [13:36<15:13, 20.31s/epoch, loss=1.12, accuracy=0.755, val_loss=3.06, val_accuracy=0.363, lr=0.1]   47%|████▋     | 39/83 [13:56<14:50, 20.25s/epoch, loss=1.12, accuracy=0.755, val_loss=4.18, val_accuracy=0.229, lr=0.1] 48%|████▊     | 40/83 [14:16<14:27, 20.17s/epoch, loss=1.12, accuracy=0.756, val_loss=1.7, val_accuracy=0.605, lr=0.1]  49%|████▉     | 41/83 [14:36<14:06, 20.14s/epoch, loss=1.12, accuracy=0.757, val_loss=1.96, val_accuracy=0.501, lr=0.1] 51%|█████     | 42/83 [14:57<13:45, 20.13s/epoch, loss=1.11, accuracy=0.755, val_loss=2.61, val_accuracy=0.446, lr=0.0316] 52%|█████▏    | 43/83 [15:17<13:24, 20.12s/epoch, loss=1.11, accuracy=0.757, val_loss=1.6, val_accuracy=0.601, lr=0.1]     53%|█████▎    | 44/83 [15:37<13:05, 20.13s/epoch, loss=1.11, accuracy=0.756, val_loss=2.42, val_accuracy=0.474, lr=0.1] 54%|█████▍    | 45/83 [15:57<12:46, 20.17s/epoch, loss=1.11, accuracy=0.755, val_loss=1.57, val_accuracy=0.604, lr=0.1] 55%|█████▌    | 46/83 [16:17<12:26, 20.18s/epoch, loss=1.1, accuracy=0.758, val_loss=2.41, val_accuracy=0.343, lr=0.1]  57%|█████▋    | 47/83 [16:37<12:06, 20.17s/epoch, loss=1.11, accuracy=0.757, val_loss=2.55, val_accuracy=0.441, lr=0.0316] 58%|█████▊    | 48/83 [16:58<11:45, 20.17s/epoch, loss=1.12, accuracy=0.756, val_loss=2.84, val_accuracy=0.351, lr=0.1]    59%|█████▉    | 49/83 [17:18<11:26, 20.19s/epoch, loss=1.11, accuracy=0.755, val_loss=1.49, val_accuracy=0.635, lr=0.1] 60%|██████    | 50/83 [17:38<11:06, 20.20s/epoch, loss=1.1, accuracy=0.756, val_loss=1.89, val_accuracy=0.487, lr=0.1]  61%|██████▏   | 51/83 [17:58<10:46, 20.21s/epoch, loss=1.11, accuracy=0.757, val_loss=6.06, val_accuracy=0.31, lr=0.1] 63%|██████▎   | 52/83 [18:19<10:29, 20.29s/epoch, loss=1.11, accuracy=0.757, val_loss=1.85, val_accuracy=0.535, lr=0.0316] 64%|██████▍   | 53/83 [18:39<10:12, 20.41s/epoch, loss=1.1, accuracy=0.757, val_loss=2.52, val_accuracy=0.404, lr=0.1]     65%|██████▌   | 54/83 [19:00<09:53, 20.45s/epoch, loss=1.11, accuracy=0.759, val_loss=1.69, val_accuracy=0.586, lr=0.1] 66%|██████▋   | 55/83 [19:20<09:32, 20.43s/epoch, loss=1.11, accuracy=0.756, val_loss=11, val_accuracy=0.152, lr=0.1]   67%|██████▋   | 56/83 [19:41<09:10, 20.39s/epoch, loss=1.1, accuracy=0.758, val_loss=3.46, val_accuracy=0.255, lr=0.1] 69%|██████▊   | 57/83 [20:01<08:49, 20.38s/epoch, loss=1.1, accuracy=0.758, val_loss=2.56, val_accuracy=0.416, lr=0.0316] 70%|██████▉   | 58/83 [20:22<08:31, 20.45s/epoch, loss=1.1, accuracy=0.758, val_loss=1.88, val_accuracy=0.527, lr=0.1]    71%|███████   | 59/83 [20:42<08:11, 20.50s/epoch, loss=1.11, accuracy=0.756, val_loss=1.83, val_accuracy=0.541, lr=0.1] 72%|███████▏  | 60/83 [21:02<07:49, 20.40s/epoch, loss=1.11, accuracy=0.757, val_loss=2.79, val_accuracy=0.306, lr=0.1] 73%|███████▎  | 61/83 [21:23<07:29, 20.41s/epoch, loss=1.11, accuracy=0.756, val_loss=2.01, val_accuracy=0.512, lr=0.1] 75%|███████▍  | 62/83 [21:43<07:07, 20.35s/epoch, loss=1.1, accuracy=0.758, val_loss=2.24, val_accuracy=0.438, lr=0.0316] 76%|███████▌  | 63/83 [22:03<06:46, 20.33s/epoch, loss=1.12, accuracy=0.757, val_loss=3.2, val_accuracy=0.304, lr=0.1]    77%|███████▋  | 64/83 [22:24<06:26, 20.33s/epoch, loss=1.1, accuracy=0.759, val_loss=1.48, val_accuracy=0.636, lr=0.1] 78%|███████▊  | 65/83 [22:44<06:06, 20.34s/epoch, loss=1.1, accuracy=0.757, val_loss=2.12, val_accuracy=0.465, lr=0.1] 80%|███████▉  | 66/83 [23:05<05:47, 20.42s/epoch, loss=1.1, accuracy=0.76, val_loss=2.22, val_accuracy=0.486, lr=0.1]  81%|████████  | 67/83 [23:25<05:26, 20.42s/epoch, loss=1.1, accuracy=0.758, val_loss=1.74, val_accuracy=0.563, lr=0.0316] 82%|████████▏ | 68/83 [23:46<05:07, 20.51s/epoch, loss=1.1, accuracy=0.756, val_loss=1.74, val_accuracy=0.547, lr=0.1]    83%|████████▎ | 69/83 [24:06<04:47, 20.52s/epoch, loss=1.1, accuracy=0.759, val_loss=2.02, val_accuracy=0.539, lr=0.1] 84%|████████▍ | 70/83 [24:27<04:25, 20.44s/epoch, loss=1.11, accuracy=0.754, val_loss=2.16, val_accuracy=0.407, lr=0.1] 86%|████████▌ | 71/83 [24:47<04:04, 20.34s/epoch, loss=1.1, accuracy=0.758, val_loss=1.46, val_accuracy=0.642, lr=0.1]  87%|████████▋ | 72/83 [25:07<03:42, 20.25s/epoch, loss=1.1, accuracy=0.757, val_loss=1.47, val_accuracy=0.63, lr=0.0316] 88%|████████▊ | 73/83 [25:27<03:21, 20.18s/epoch, loss=1.09, accuracy=0.759, val_loss=1.69, val_accuracy=0.559, lr=0.1]  89%|████████▉ | 74/83 [25:47<03:02, 20.22s/epoch, loss=1.1, accuracy=0.758, val_loss=1.51, val_accuracy=0.618, lr=0.1]  90%|█████████ | 75/83 [26:07<02:41, 20.22s/epoch, loss=1.1, accuracy=0.757, val_loss=4.1, val_accuracy=0.287, lr=0.1]  92%|█████████▏| 76/83 [26:27<02:21, 20.16s/epoch, loss=1.1, accuracy=0.756, val_loss=1.55, val_accuracy=0.592, lr=0.1] 93%|█████████▎| 77/83 [26:47<02:00, 20.16s/epoch, loss=1.09, accuracy=0.76, val_loss=2.33, val_accuracy=0.427, lr=0.0316] 94%|█████████▍| 78/83 [27:08<01:40, 20.16s/epoch, loss=1.1, accuracy=0.757, val_loss=2.95, val_accuracy=0.324, lr=0.1]    95%|█████████▌| 79/83 [27:28<01:20, 20.21s/epoch, loss=1.1, accuracy=0.758, val_loss=3.65, val_accuracy=0.378, lr=0.1] 96%|█████████▋| 80/83 [27:48<01:00, 20.29s/epoch, loss=1.1, accuracy=0.758, val_loss=1.64, val_accuracy=0.587, lr=0.1] 98%|█████████▊| 81/83 [28:09<00:40, 20.30s/epoch, loss=1.1, accuracy=0.758, val_loss=1.38, val_accuracy=0.669, lr=0.1] 99%|█████████▉| 82/83 [28:29<00:20, 20.33s/epoch, loss=0.897, accuracy=0.815, val_loss=0.899, val_accuracy=0.802, lr=0.01]100%|██████████| 83/83 [28:49<00:00, 20.26s/epoch, loss=0.72, accuracy=0.848, val_loss=0.849, val_accuracy=0.788, lr=0.01] 100%|██████████| 83/83 [28:49<00:00, 20.84s/epoch, loss=0.72, accuracy=0.848, val_loss=0.849, val_accuracy=0.788, lr=0.01]
Using real-time data augmentation.
Test score: 0.8488352298736572
Test accuracy: 0.7883999943733215


* * * Run SGD for ID = 18_14. * * *


2024-03-05 16:08:32.820965: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 16:08:35.504771: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 16:08:35.505979: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-05 16:08:35.543633: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-03-05 16:08:35.543680: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 16:08:35.546454: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 16:08:35.546511: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 16:08:35.548629: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 16:08:35.549687: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 16:08:35.551921: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 16:08:35.553348: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 16:08:35.557828: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 16:08:35.558466: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 16:08:35.558572: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 16:08:36.836999: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-05 16:08:36.838052: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 16:08:36.838815: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-03-05 16:08:36.838850: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 16:08:36.838890: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 16:08:36.838908: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 16:08:36.838923: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 16:08:36.838939: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 16:08:36.838954: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 16:08:36.838982: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 16:08:36.839006: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 16:08:36.839445: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 16:08:36.839484: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 16:08:37.494332: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-05 16:08:37.494381: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-05 16:08:37.494390: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-05 16:08:37.495284: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': '18_14', 'seed': 14, 'out_folder': 'results/epoch_budget', 'batch_size': 128, 'epochs': 83, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'bootstrapping': False, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/83 [00:00<?, ?epoch/s]2024-03-05 16:08:38.373829: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-05 16:08:38.386140: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600020000 Hz
2024-03-05 16:08:40.407485: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 16:08:40.638298: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 16:08:41.314424: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-05 16:08:41.382278: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/83 [01:06<1:31:16, 66.79s/epoch, loss=3.23, accuracy=0.293, val_loss=2.29, val_accuracy=0.228, lr=0.1]  2%|▏         | 2/83 [01:27<53:20, 39.51s/epoch, loss=1.57, accuracy=0.534, val_loss=2.81, val_accuracy=0.329, lr=0.1]    4%|▎         | 3/83 [01:47<40:43, 30.55s/epoch, loss=1.37, accuracy=0.63, val_loss=2.07, val_accuracy=0.424, lr=0.1]   5%|▍         | 4/83 [02:06<34:40, 26.33s/epoch, loss=1.31, accuracy=0.672, val_loss=1.81, val_accuracy=0.508, lr=0.1]  6%|▌         | 5/83 [02:26<31:14, 24.03s/epoch, loss=1.28, accuracy=0.691, val_loss=1.55, val_accuracy=0.607, lr=0.1]  7%|▋         | 6/83 [02:47<29:08, 22.70s/epoch, loss=1.25, accuracy=0.705, val_loss=3.87, val_accuracy=0.293, lr=0.1]  8%|▊         | 7/83 [03:07<27:38, 21.83s/epoch, loss=1.24, accuracy=0.71, val_loss=3.32, val_accuracy=0.251, lr=0.1]  10%|▉         | 8/83 [03:26<26:29, 21.19s/epoch, loss=1.23, accuracy=0.715, val_loss=1.55, val_accuracy=0.609, lr=0.1] 11%|█         | 9/83 [03:46<25:35, 20.74s/epoch, loss=1.23, accuracy=0.72, val_loss=2.37, val_accuracy=0.454, lr=0.1]  12%|█▏        | 10/83 [04:06<24:59, 20.54s/epoch, loss=1.21, accuracy=0.728, val_loss=1.34, val_accuracy=0.684, lr=0.1] 13%|█▎        | 11/83 [04:26<24:23, 20.33s/epoch, loss=1.2, accuracy=0.729, val_loss=1.61, val_accuracy=0.588, lr=0.1]  14%|█▍        | 12/83 [04:46<23:51, 20.17s/epoch, loss=1.2, accuracy=0.731, val_loss=2.48, val_accuracy=0.432, lr=0.1] 16%|█▌        | 13/83 [05:06<23:24, 20.07s/epoch, loss=1.19, accuracy=0.734, val_loss=1.66, val_accuracy=0.561, lr=0.1] 17%|█▋        | 14/83 [05:25<22:57, 19.97s/epoch, loss=1.19, accuracy=0.736, val_loss=2.19, val_accuracy=0.502, lr=0.1] 18%|█▊        | 15/83 [05:46<22:40, 20.00s/epoch, loss=1.19, accuracy=0.737, val_loss=1.92, val_accuracy=0.506, lr=0.0316] 19%|█▉        | 16/83 [06:06<22:22, 20.04s/epoch, loss=1.18, accuracy=0.739, val_loss=1.52, val_accuracy=0.614, lr=0.1]    20%|██        | 17/83 [06:26<22:00, 20.01s/epoch, loss=1.18, accuracy=0.737, val_loss=1.64, val_accuracy=0.598, lr=0.1] 22%|██▏       | 18/83 [06:45<21:37, 19.96s/epoch, loss=1.18, accuracy=0.741, val_loss=2.43, val_accuracy=0.396, lr=0.1] 23%|██▎       | 19/83 [07:05<21:16, 19.95s/epoch, loss=1.17, accuracy=0.741, val_loss=1.46, val_accuracy=0.641, lr=0.1] 24%|██▍       | 20/83 [07:25<20:59, 19.99s/epoch, loss=1.17, accuracy=0.743, val_loss=1.62, val_accuracy=0.59, lr=0.0316] 25%|██▌       | 21/83 [07:46<20:42, 20.04s/epoch, loss=1.17, accuracy=0.743, val_loss=2.73, val_accuracy=0.39, lr=0.1]    27%|██▋       | 22/83 [08:06<20:24, 20.08s/epoch, loss=1.17, accuracy=0.744, val_loss=2.84, val_accuracy=0.292, lr=0.1] 28%|██▊       | 23/83 [08:26<20:06, 20.11s/epoch, loss=1.17, accuracy=0.745, val_loss=2.7, val_accuracy=0.42, lr=0.1]   29%|██▉       | 24/83 [08:46<19:48, 20.14s/epoch, loss=1.17, accuracy=0.746, val_loss=1.94, val_accuracy=0.523, lr=0.1] 30%|███       | 25/83 [09:06<19:27, 20.13s/epoch, loss=1.17, accuracy=0.744, val_loss=1.79, val_accuracy=0.541, lr=0.0316] 31%|███▏      | 26/83 [09:26<19:07, 20.13s/epoch, loss=1.16, accuracy=0.742, val_loss=1.59, val_accuracy=0.57, lr=0.1]     33%|███▎      | 27/83 [09:46<18:46, 20.11s/epoch, loss=1.16, accuracy=0.745, val_loss=1.58, val_accuracy=0.604, lr=0.1] 34%|███▎      | 28/83 [10:07<18:26, 20.12s/epoch, loss=1.16, accuracy=0.748, val_loss=1.57, val_accuracy=0.614, lr=0.1] 35%|███▍      | 29/83 [10:27<18:03, 20.07s/epoch, loss=1.15, accuracy=0.746, val_loss=1.85, val_accuracy=0.524, lr=0.1] 36%|███▌      | 30/83 [10:46<17:40, 20.02s/epoch, loss=1.15, accuracy=0.749, val_loss=1.57, val_accuracy=0.609, lr=0.0316] 37%|███▋      | 31/83 [11:06<17:21, 20.02s/epoch, loss=1.15, accuracy=0.75, val_loss=2.05, val_accuracy=0.497, lr=0.1]     39%|███▊      | 32/83 [11:26<17:00, 20.01s/epoch, loss=1.15, accuracy=0.748, val_loss=2.74, val_accuracy=0.356, lr=0.1] 40%|███▉      | 33/83 [11:46<16:39, 19.99s/epoch, loss=1.15, accuracy=0.749, val_loss=1.68, val_accuracy=0.588, lr=0.1] 41%|████      | 34/83 [12:06<16:18, 19.98s/epoch, loss=1.15, accuracy=0.75, val_loss=1.63, val_accuracy=0.632, lr=0.1]  42%|████▏     | 35/83 [12:26<15:55, 19.91s/epoch, loss=1.14, accuracy=0.75, val_loss=3.7, val_accuracy=0.34, lr=0.0316] 43%|████▎     | 36/83 [12:46<15:38, 19.98s/epoch, loss=1.14, accuracy=0.752, val_loss=1.58, val_accuracy=0.601, lr=0.1] 45%|████▍     | 37/83 [13:06<15:20, 20.02s/epoch, loss=1.15, accuracy=0.751, val_loss=2.1, val_accuracy=0.474, lr=0.1]  46%|████▌     | 38/83 [13:26<15:01, 20.04s/epoch, loss=1.14, accuracy=0.749, val_loss=2.39, val_accuracy=0.306, lr=0.1] 47%|████▋     | 39/83 [13:47<14:42, 20.05s/epoch, loss=1.15, accuracy=0.749, val_loss=2.8, val_accuracy=0.345, lr=0.1]  48%|████▊     | 40/83 [14:07<14:21, 20.04s/epoch, loss=1.14, accuracy=0.751, val_loss=7.54, val_accuracy=0.192, lr=0.0316] 49%|████▉     | 41/83 [14:27<14:00, 20.02s/epoch, loss=1.14, accuracy=0.751, val_loss=2.82, val_accuracy=0.412, lr=0.1]    51%|█████     | 42/83 [14:46<13:40, 20.01s/epoch, loss=1.14, accuracy=0.751, val_loss=3.36, val_accuracy=0.262, lr=0.1] 52%|█████▏    | 43/83 [15:06<13:18, 19.97s/epoch, loss=1.14, accuracy=0.753, val_loss=1.77, val_accuracy=0.551, lr=0.1] 53%|█████▎    | 44/83 [15:26<12:59, 19.98s/epoch, loss=1.13, accuracy=0.753, val_loss=6.9, val_accuracy=0.254, lr=0.1]  54%|█████▍    | 45/83 [15:46<12:39, 20.00s/epoch, loss=1.14, accuracy=0.752, val_loss=3.33, val_accuracy=0.33, lr=0.0316] 55%|█████▌    | 46/83 [16:06<12:19, 19.99s/epoch, loss=1.13, accuracy=0.753, val_loss=2.55, val_accuracy=0.426, lr=0.1]   57%|█████▋    | 47/83 [16:27<12:01, 20.03s/epoch, loss=1.14, accuracy=0.752, val_loss=2.2, val_accuracy=0.485, lr=0.1]  58%|█████▊    | 48/83 [16:47<11:42, 20.06s/epoch, loss=1.13, accuracy=0.752, val_loss=2.23, val_accuracy=0.455, lr=0.1] 59%|█████▉    | 49/83 [17:07<11:22, 20.06s/epoch, loss=1.14, accuracy=0.753, val_loss=1.61, val_accuracy=0.596, lr=0.1] 60%|██████    | 50/83 [17:27<11:02, 20.06s/epoch, loss=1.13, accuracy=0.754, val_loss=2.17, val_accuracy=0.479, lr=0.0316] 61%|██████▏   | 51/83 [17:47<10:41, 20.04s/epoch, loss=1.14, accuracy=0.755, val_loss=5.03, val_accuracy=0.225, lr=0.1]    63%|██████▎   | 52/83 [18:07<10:21, 20.05s/epoch, loss=1.13, accuracy=0.752, val_loss=2.69, val_accuracy=0.418, lr=0.1] 64%|██████▍   | 53/83 [18:27<10:01, 20.06s/epoch, loss=1.13, accuracy=0.755, val_loss=1.82, val_accuracy=0.517, lr=0.1] 65%|██████▌   | 54/83 [18:47<09:41, 20.07s/epoch, loss=1.13, accuracy=0.753, val_loss=2.8, val_accuracy=0.36, lr=0.1]   66%|██████▋   | 55/83 [19:07<09:21, 20.06s/epoch, loss=1.12, accuracy=0.753, val_loss=1.41, val_accuracy=0.643, lr=0.0316] 67%|██████▋   | 56/83 [19:27<09:01, 20.05s/epoch, loss=1.13, accuracy=0.752, val_loss=2.39, val_accuracy=0.486, lr=0.1]    69%|██████▊   | 57/83 [19:47<08:41, 20.06s/epoch, loss=1.13, accuracy=0.752, val_loss=2.63, val_accuracy=0.331, lr=0.1] 70%|██████▉   | 58/83 [20:07<08:22, 20.09s/epoch, loss=1.13, accuracy=0.756, val_loss=1.63, val_accuracy=0.59, lr=0.1]  71%|███████   | 59/83 [20:28<08:04, 20.17s/epoch, loss=1.13, accuracy=0.753, val_loss=2.3, val_accuracy=0.447, lr=0.1] 72%|███████▏  | 60/83 [20:48<07:43, 20.15s/epoch, loss=1.12, accuracy=0.758, val_loss=6.34, val_accuracy=0.236, lr=0.0316] 73%|███████▎  | 61/83 [21:08<07:21, 20.06s/epoch, loss=1.13, accuracy=0.752, val_loss=2.08, val_accuracy=0.45, lr=0.1]     75%|███████▍  | 62/83 [21:28<07:01, 20.07s/epoch, loss=1.12, accuracy=0.755, val_loss=2.06, val_accuracy=0.457, lr=0.1] 76%|███████▌  | 63/83 [21:48<06:41, 20.06s/epoch, loss=1.13, accuracy=0.755, val_loss=1.94, val_accuracy=0.495, lr=0.1] 77%|███████▋  | 64/83 [22:08<06:19, 19.98s/epoch, loss=1.13, accuracy=0.756, val_loss=1.9, val_accuracy=0.554, lr=0.1]  78%|███████▊  | 65/83 [22:28<06:00, 20.03s/epoch, loss=1.12, accuracy=0.757, val_loss=2.27, val_accuracy=0.466, lr=0.0316] 80%|███████▉  | 66/83 [22:48<05:40, 20.05s/epoch, loss=1.13, accuracy=0.756, val_loss=2.42, val_accuracy=0.411, lr=0.1]    81%|████████  | 67/83 [23:08<05:20, 20.05s/epoch, loss=1.13, accuracy=0.755, val_loss=2.48, val_accuracy=0.436, lr=0.1] 82%|████████▏ | 68/83 [23:28<05:00, 20.02s/epoch, loss=1.13, accuracy=0.757, val_loss=2.36, val_accuracy=0.411, lr=0.1] 83%|████████▎ | 69/83 [23:48<04:39, 19.97s/epoch, loss=1.13, accuracy=0.754, val_loss=1.66, val_accuracy=0.566, lr=0.1] 84%|████████▍ | 70/83 [24:07<04:18, 19.88s/epoch, loss=1.13, accuracy=0.753, val_loss=1.56, val_accuracy=0.6, lr=0.0316] 86%|████████▌ | 71/83 [24:27<03:57, 19.76s/epoch, loss=1.12, accuracy=0.757, val_loss=1.87, val_accuracy=0.478, lr=0.1]  87%|████████▋ | 72/83 [24:46<03:37, 19.74s/epoch, loss=1.12, accuracy=0.755, val_loss=2.08, val_accuracy=0.475, lr=0.1] 88%|████████▊ | 73/83 [25:06<03:17, 19.72s/epoch, loss=1.13, accuracy=0.753, val_loss=2.54, val_accuracy=0.406, lr=0.1] 89%|████████▉ | 74/83 [25:26<02:56, 19.67s/epoch, loss=1.13, accuracy=0.757, val_loss=1.96, val_accuracy=0.515, lr=0.1] 90%|█████████ | 75/83 [25:45<02:37, 19.64s/epoch, loss=1.13, accuracy=0.758, val_loss=4.19, val_accuracy=0.29, lr=0.0316] 92%|█████████▏| 76/83 [26:06<02:18, 19.84s/epoch, loss=1.13, accuracy=0.757, val_loss=2.15, val_accuracy=0.391, lr=0.1]   93%|█████████▎| 77/83 [26:26<01:59, 19.87s/epoch, loss=1.13, accuracy=0.753, val_loss=2.72, val_accuracy=0.446, lr=0.1] 94%|█████████▍| 78/83 [26:45<01:39, 19.82s/epoch, loss=1.13, accuracy=0.754, val_loss=3.46, val_accuracy=0.357, lr=0.1] 95%|█████████▌| 79/83 [27:05<01:19, 19.80s/epoch, loss=1.13, accuracy=0.753, val_loss=2.59, val_accuracy=0.401, lr=0.1] 96%|█████████▋| 80/83 [27:25<00:59, 19.78s/epoch, loss=1.13, accuracy=0.754, val_loss=2.71, val_accuracy=0.321, lr=0.0316] 98%|█████████▊| 81/83 [27:44<00:39, 19.70s/epoch, loss=1.12, accuracy=0.757, val_loss=2.35, val_accuracy=0.392, lr=0.1]    99%|█████████▉| 82/83 [28:04<00:19, 19.71s/epoch, loss=0.924, accuracy=0.81, val_loss=1.09, val_accuracy=0.728, lr=0.01]100%|██████████| 83/83 [28:23<00:00, 19.65s/epoch, loss=0.738, accuracy=0.844, val_loss=0.769, val_accuracy=0.828, lr=0.01]100%|██████████| 83/83 [28:23<00:00, 20.53s/epoch, loss=0.738, accuracy=0.844, val_loss=0.769, val_accuracy=0.828, lr=0.01]
Using real-time data augmentation.
Test score: 0.76921147108078
Test accuracy: 0.8281999826431274


* * * Run SGD for ID = 18_15. * * *


2024-03-05 16:37:06.143260: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 16:37:08.764610: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 16:37:08.765733: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-05 16:37:08.801550: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-03-05 16:37:08.801593: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 16:37:08.804423: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 16:37:08.804462: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 16:37:08.806732: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 16:37:08.807365: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 16:37:08.809687: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 16:37:08.811030: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 16:37:08.815569: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 16:37:08.816172: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 16:37:08.816251: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 16:37:10.055538: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-05 16:37:10.056599: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 16:37:10.057397: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-03-05 16:37:10.057430: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 16:37:10.057467: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 16:37:10.057483: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 16:37:10.057505: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 16:37:10.057519: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 16:37:10.057536: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 16:37:10.057553: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 16:37:10.057570: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 16:37:10.058015: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 16:37:10.058047: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 16:37:10.696267: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-05 16:37:10.696314: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-05 16:37:10.696321: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-05 16:37:10.697290: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': '18_15', 'seed': 15, 'out_folder': 'results/epoch_budget', 'batch_size': 128, 'epochs': 83, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'bootstrapping': False, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/83 [00:00<?, ?epoch/s]2024-03-05 16:37:11.546111: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-05 16:37:11.558125: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600020000 Hz
2024-03-05 16:37:13.551120: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 16:37:13.778709: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 16:37:14.495233: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-05 16:37:14.548877: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/83 [01:00<1:22:37, 60.45s/epoch, loss=3.13, accuracy=0.328, val_loss=2.4, val_accuracy=0.259, lr=0.1]  2%|▏         | 2/83 [01:21<50:05, 37.11s/epoch, loss=1.59, accuracy=0.521, val_loss=3.08, val_accuracy=0.264, lr=0.1]   4%|▎         | 3/83 [01:41<39:13, 29.42s/epoch, loss=1.35, accuracy=0.638, val_loss=1.63, val_accuracy=0.562, lr=0.1]  5%|▍         | 4/83 [02:01<34:01, 25.85s/epoch, loss=1.29, accuracy=0.677, val_loss=2.98, val_accuracy=0.263, lr=0.1]  6%|▌         | 5/83 [02:22<31:03, 23.89s/epoch, loss=1.26, accuracy=0.696, val_loss=1.84, val_accuracy=0.475, lr=0.1]  7%|▋         | 6/83 [02:42<29:06, 22.69s/epoch, loss=1.24, accuracy=0.709, val_loss=2.31, val_accuracy=0.393, lr=0.1]  8%|▊         | 7/83 [03:02<27:44, 21.90s/epoch, loss=1.23, accuracy=0.718, val_loss=2.21, val_accuracy=0.488, lr=0.1] 10%|▉         | 8/83 [03:23<26:48, 21.45s/epoch, loss=1.23, accuracy=0.723, val_loss=1.95, val_accuracy=0.494, lr=0.0316] 11%|█         | 9/83 [03:43<25:58, 21.06s/epoch, loss=1.23, accuracy=0.725, val_loss=1.62, val_accuracy=0.585, lr=0.1]    12%|█▏        | 10/83 [04:04<25:23, 20.87s/epoch, loss=1.22, accuracy=0.728, val_loss=2.57, val_accuracy=0.451, lr=0.1] 13%|█▎        | 11/83 [04:24<24:58, 20.81s/epoch, loss=1.21, accuracy=0.731, val_loss=2.17, val_accuracy=0.497, lr=0.1] 14%|█▍        | 12/83 [04:45<24:27, 20.67s/epoch, loss=1.2, accuracy=0.737, val_loss=2.35, val_accuracy=0.502, lr=0.1]  16%|█▌        | 13/83 [05:05<23:57, 20.54s/epoch, loss=1.2, accuracy=0.735, val_loss=2.23, val_accuracy=0.492, lr=0.1] 17%|█▋        | 14/83 [05:25<23:28, 20.41s/epoch, loss=1.2, accuracy=0.736, val_loss=2.04, val_accuracy=0.505, lr=0.0316] 18%|█▊        | 15/83 [05:45<23:06, 20.39s/epoch, loss=1.19, accuracy=0.738, val_loss=2.18, val_accuracy=0.462, lr=0.1]   19%|█▉        | 16/83 [06:06<22:49, 20.44s/epoch, loss=1.19, accuracy=0.74, val_loss=1.79, val_accuracy=0.52, lr=0.1]   20%|██        | 17/83 [06:27<22:35, 20.54s/epoch, loss=1.19, accuracy=0.74, val_loss=1.85, val_accuracy=0.552, lr=0.1] 22%|██▏       | 18/83 [06:47<22:11, 20.49s/epoch, loss=1.19, accuracy=0.743, val_loss=2.32, val_accuracy=0.475, lr=0.1] 23%|██▎       | 19/83 [07:07<21:51, 20.49s/epoch, loss=1.19, accuracy=0.744, val_loss=3.07, val_accuracy=0.327, lr=0.0316] 24%|██▍       | 20/83 [07:28<21:27, 20.44s/epoch, loss=1.2, accuracy=0.739, val_loss=1.9, val_accuracy=0.538, lr=0.1]      25%|██▌       | 21/83 [07:48<21:04, 20.39s/epoch, loss=1.2, accuracy=0.74, val_loss=1.45, val_accuracy=0.637, lr=0.1] 27%|██▋       | 22/83 [08:08<20:44, 20.40s/epoch, loss=1.19, accuracy=0.742, val_loss=2.07, val_accuracy=0.541, lr=0.1] 28%|██▊       | 23/83 [08:29<20:21, 20.35s/epoch, loss=1.19, accuracy=0.742, val_loss=2.19, val_accuracy=0.489, lr=0.1] 29%|██▉       | 24/83 [08:49<19:59, 20.33s/epoch, loss=1.17, accuracy=0.75, val_loss=1.5, val_accuracy=0.645, lr=0.1]   30%|███       | 25/83 [09:09<19:39, 20.33s/epoch, loss=1.18, accuracy=0.745, val_loss=4.66, val_accuracy=0.156, lr=0.1] 31%|███▏      | 26/83 [09:30<19:22, 20.40s/epoch, loss=1.17, accuracy=0.746, val_loss=1.96, val_accuracy=0.51, lr=0.0316] 33%|███▎      | 27/83 [09:50<19:05, 20.46s/epoch, loss=1.18, accuracy=0.744, val_loss=1.73, val_accuracy=0.56, lr=0.1]    34%|███▎      | 28/83 [10:11<18:43, 20.44s/epoch, loss=1.17, accuracy=0.748, val_loss=3.19, val_accuracy=0.355, lr=0.1] 35%|███▍      | 29/83 [10:31<18:25, 20.48s/epoch, loss=1.17, accuracy=0.746, val_loss=2.45, val_accuracy=0.403, lr=0.1] 36%|███▌      | 30/83 [10:52<18:06, 20.50s/epoch, loss=1.17, accuracy=0.75, val_loss=1.94, val_accuracy=0.477, lr=0.1]  37%|███▋      | 31/83 [11:13<17:52, 20.63s/epoch, loss=1.17, accuracy=0.748, val_loss=1.66, val_accuracy=0.578, lr=0.0316] 39%|███▊      | 32/83 [11:34<17:35, 20.69s/epoch, loss=1.16, accuracy=0.746, val_loss=1.77, val_accuracy=0.609, lr=0.1]    40%|███▉      | 33/83 [11:54<17:12, 20.65s/epoch, loss=1.16, accuracy=0.747, val_loss=2.05, val_accuracy=0.47, lr=0.1]  41%|████      | 34/83 [12:15<16:49, 20.60s/epoch, loss=1.16, accuracy=0.75, val_loss=1.79, val_accuracy=0.528, lr=0.1] 42%|████▏     | 35/83 [12:35<16:27, 20.57s/epoch, loss=1.16, accuracy=0.749, val_loss=1.98, val_accuracy=0.468, lr=0.1] 43%|████▎     | 36/83 [12:56<16:06, 20.56s/epoch, loss=1.15, accuracy=0.752, val_loss=1.7, val_accuracy=0.562, lr=0.0316] 45%|████▍     | 37/83 [13:16<15:46, 20.57s/epoch, loss=1.15, accuracy=0.752, val_loss=1.68, val_accuracy=0.571, lr=0.1]   46%|████▌     | 38/83 [13:37<15:23, 20.53s/epoch, loss=1.16, accuracy=0.747, val_loss=1.98, val_accuracy=0.461, lr=0.1] 47%|████▋     | 39/83 [13:57<15:02, 20.51s/epoch, loss=1.15, accuracy=0.752, val_loss=1.56, val_accuracy=0.645, lr=0.1] 48%|████▊     | 40/83 [14:18<14:40, 20.49s/epoch, loss=1.15, accuracy=0.751, val_loss=1.91, val_accuracy=0.512, lr=0.1] 49%|████▉     | 41/83 [14:38<14:22, 20.53s/epoch, loss=1.14, accuracy=0.754, val_loss=2.35, val_accuracy=0.472, lr=0.0316] 51%|█████     | 42/83 [14:59<14:02, 20.54s/epoch, loss=1.16, accuracy=0.751, val_loss=2.04, val_accuracy=0.486, lr=0.1]    52%|█████▏    | 43/83 [15:19<13:41, 20.53s/epoch, loss=1.15, accuracy=0.753, val_loss=4.07, val_accuracy=0.289, lr=0.1] 53%|█████▎    | 44/83 [15:40<13:20, 20.53s/epoch, loss=1.15, accuracy=0.752, val_loss=1.89, val_accuracy=0.512, lr=0.1] 54%|█████▍    | 45/83 [16:00<12:59, 20.52s/epoch, loss=1.15, accuracy=0.753, val_loss=1.89, val_accuracy=0.514, lr=0.1] 55%|█████▌    | 46/83 [16:21<12:39, 20.52s/epoch, loss=1.14, accuracy=0.755, val_loss=2.52, val_accuracy=0.341, lr=0.0316] 57%|█████▋    | 47/83 [16:41<12:17, 20.49s/epoch, loss=1.14, accuracy=0.755, val_loss=2.75, val_accuracy=0.344, lr=0.1]    58%|█████▊    | 48/83 [17:02<11:58, 20.54s/epoch, loss=1.14, accuracy=0.756, val_loss=1.66, val_accuracy=0.569, lr=0.1] 59%|█████▉    | 49/83 [17:23<11:38, 20.55s/epoch, loss=1.14, accuracy=0.752, val_loss=1.86, val_accuracy=0.536, lr=0.1] 60%|██████    | 50/83 [17:43<11:17, 20.52s/epoch, loss=1.14, accuracy=0.756, val_loss=2.22, val_accuracy=0.459, lr=0.1] 61%|██████▏   | 51/83 [18:04<10:58, 20.58s/epoch, loss=1.14, accuracy=0.757, val_loss=2.51, val_accuracy=0.312, lr=0.0316] 63%|██████▎   | 52/83 [18:24<10:36, 20.53s/epoch, loss=1.14, accuracy=0.756, val_loss=2, val_accuracy=0.492, lr=0.1]       64%|██████▍   | 53/83 [18:45<10:18, 20.60s/epoch, loss=1.14, accuracy=0.753, val_loss=1.74, val_accuracy=0.571, lr=0.1] 65%|██████▌   | 54/83 [19:06<09:56, 20.58s/epoch, loss=1.13, accuracy=0.753, val_loss=2.55, val_accuracy=0.426, lr=0.1] 66%|██████▋   | 55/83 [19:26<09:36, 20.57s/epoch, loss=1.14, accuracy=0.754, val_loss=2.27, val_accuracy=0.511, lr=0.1] 67%|██████▋   | 56/83 [19:47<09:16, 20.60s/epoch, loss=1.13, accuracy=0.757, val_loss=1.9, val_accuracy=0.571, lr=0.0316] 69%|██████▊   | 57/83 [20:07<08:55, 20.58s/epoch, loss=1.13, accuracy=0.756, val_loss=2.4, val_accuracy=0.493, lr=0.1]    70%|██████▉   | 58/83 [20:28<08:34, 20.57s/epoch, loss=1.14, accuracy=0.756, val_loss=1.68, val_accuracy=0.532, lr=0.1] 71%|███████   | 59/83 [20:48<08:14, 20.59s/epoch, loss=1.13, accuracy=0.758, val_loss=2.04, val_accuracy=0.473, lr=0.1] 72%|███████▏  | 60/83 [21:09<07:53, 20.57s/epoch, loss=1.13, accuracy=0.757, val_loss=1.71, val_accuracy=0.576, lr=0.1] 73%|███████▎  | 61/83 [21:29<07:31, 20.52s/epoch, loss=1.13, accuracy=0.757, val_loss=2.45, val_accuracy=0.465, lr=0.0316] 75%|███████▍  | 62/83 [21:50<07:10, 20.49s/epoch, loss=1.13, accuracy=0.755, val_loss=2.05, val_accuracy=0.53, lr=0.1]     76%|███████▌  | 63/83 [22:10<06:49, 20.47s/epoch, loss=1.13, accuracy=0.755, val_loss=2.66, val_accuracy=0.399, lr=0.1] 77%|███████▋  | 64/83 [22:31<06:28, 20.45s/epoch, loss=1.13, accuracy=0.754, val_loss=3.68, val_accuracy=0.275, lr=0.1] 78%|███████▊  | 65/83 [22:51<06:08, 20.49s/epoch, loss=1.12, accuracy=0.76, val_loss=1.53, val_accuracy=0.613, lr=0.1]  80%|███████▉  | 66/83 [23:12<05:48, 20.49s/epoch, loss=1.12, accuracy=0.756, val_loss=1.73, val_accuracy=0.578, lr=0.0316] 81%|████████  | 67/83 [23:32<05:28, 20.51s/epoch, loss=1.13, accuracy=0.759, val_loss=1.54, val_accuracy=0.595, lr=0.1]    82%|████████▏ | 68/83 [23:53<05:08, 20.54s/epoch, loss=1.13, accuracy=0.759, val_loss=1.9, val_accuracy=0.537, lr=0.1]  83%|████████▎ | 69/83 [24:14<04:48, 20.60s/epoch, loss=1.12, accuracy=0.758, val_loss=2.39, val_accuracy=0.44, lr=0.1] 84%|████████▍ | 70/83 [24:34<04:27, 20.58s/epoch, loss=1.13, accuracy=0.758, val_loss=1.9, val_accuracy=0.471, lr=0.1] 86%|████████▌ | 71/83 [24:55<04:06, 20.53s/epoch, loss=1.12, accuracy=0.758, val_loss=2.27, val_accuracy=0.475, lr=0.0316] 87%|████████▋ | 72/83 [25:15<03:45, 20.55s/epoch, loss=1.12, accuracy=0.757, val_loss=2, val_accuracy=0.481, lr=0.1]       88%|████████▊ | 73/83 [25:36<03:25, 20.60s/epoch, loss=1.13, accuracy=0.759, val_loss=1.75, val_accuracy=0.551, lr=0.1] 89%|████████▉ | 74/83 [25:56<03:05, 20.57s/epoch, loss=1.12, accuracy=0.757, val_loss=2.18, val_accuracy=0.441, lr=0.1] 90%|█████████ | 75/83 [26:17<02:44, 20.55s/epoch, loss=1.11, accuracy=0.758, val_loss=2.14, val_accuracy=0.435, lr=0.1] 92%|█████████▏| 76/83 [26:38<02:24, 20.58s/epoch, loss=1.12, accuracy=0.757, val_loss=3.5, val_accuracy=0.355, lr=0.0316] 93%|█████████▎| 77/83 [26:58<02:03, 20.59s/epoch, loss=1.11, accuracy=0.762, val_loss=1.55, val_accuracy=0.632, lr=0.1]   94%|█████████▍| 78/83 [27:19<01:42, 20.57s/epoch, loss=1.12, accuracy=0.76, val_loss=1.88, val_accuracy=0.523, lr=0.1]  95%|█████████▌| 79/83 [27:39<01:22, 20.56s/epoch, loss=1.13, accuracy=0.759, val_loss=5.22, val_accuracy=0.306, lr=0.1] 96%|█████████▋| 80/83 [28:00<01:01, 20.50s/epoch, loss=1.12, accuracy=0.76, val_loss=2.28, val_accuracy=0.443, lr=0.1]  98%|█████████▊| 81/83 [28:20<00:40, 20.49s/epoch, loss=1.12, accuracy=0.76, val_loss=2.24, val_accuracy=0.519, lr=0.0316] 99%|█████████▉| 82/83 [28:40<00:20, 20.39s/epoch, loss=0.907, accuracy=0.817, val_loss=0.897, val_accuracy=0.804, lr=0.01]100%|██████████| 83/83 [29:01<00:00, 20.44s/epoch, loss=0.724, accuracy=0.85, val_loss=0.783, val_accuracy=0.813, lr=0.01] 100%|██████████| 83/83 [29:01<00:00, 20.98s/epoch, loss=0.724, accuracy=0.85, val_loss=0.783, val_accuracy=0.813, lr=0.01]
Using real-time data augmentation.
Test score: 0.7833619713783264
Test accuracy: 0.8127999901771545


* * * Run SGD for ID = 18_16. * * *


2024-03-05 17:06:16.771289: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 17:06:19.364377: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 17:06:19.365393: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-05 17:06:19.401829: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-03-05 17:06:19.401872: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 17:06:19.404875: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 17:06:19.404925: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 17:06:19.407352: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 17:06:19.408177: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 17:06:19.410653: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 17:06:19.412092: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 17:06:19.416814: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 17:06:19.417429: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 17:06:19.417522: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 17:06:20.657160: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-05 17:06:20.658261: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 17:06:20.659031: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-03-05 17:06:20.659062: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 17:06:20.659101: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 17:06:20.659117: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 17:06:20.659133: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 17:06:20.659147: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 17:06:20.659163: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 17:06:20.659179: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 17:06:20.659196: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 17:06:20.659623: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 17:06:20.659657: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 17:06:21.307630: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-05 17:06:21.307686: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-05 17:06:21.307694: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-05 17:06:21.308606: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': '18_16', 'seed': 16, 'out_folder': 'results/epoch_budget', 'batch_size': 128, 'epochs': 83, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'bootstrapping': False, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/83 [00:00<?, ?epoch/s]2024-03-05 17:06:22.155283: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-05 17:06:22.167135: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600020000 Hz
2024-03-05 17:06:24.179520: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 17:06:24.416368: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 17:06:25.156542: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-05 17:06:25.205149: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/83 [01:02<1:25:49, 62.80s/epoch, loss=3.07, accuracy=0.325, val_loss=2.78, val_accuracy=0.23, lr=0.1]  2%|▏         | 2/83 [01:23<51:19, 38.02s/epoch, loss=1.48, accuracy=0.578, val_loss=1.85, val_accuracy=0.463, lr=0.1]   4%|▎         | 3/83 [01:43<39:46, 29.83s/epoch, loss=1.31, accuracy=0.653, val_loss=1.75, val_accuracy=0.493, lr=0.1]  5%|▍         | 4/83 [02:03<34:16, 26.03s/epoch, loss=1.27, accuracy=0.685, val_loss=2.21, val_accuracy=0.438, lr=0.1]  6%|▌         | 5/83 [02:24<31:11, 23.99s/epoch, loss=1.23, accuracy=0.704, val_loss=1.73, val_accuracy=0.528, lr=0.1]  7%|▋         | 6/83 [02:44<29:09, 22.72s/epoch, loss=1.23, accuracy=0.714, val_loss=2.21, val_accuracy=0.468, lr=0.1]  8%|▊         | 7/83 [03:04<27:43, 21.89s/epoch, loss=1.22, accuracy=0.72, val_loss=3.1, val_accuracy=0.302, lr=0.1]   10%|▉         | 8/83 [03:24<26:47, 21.43s/epoch, loss=1.2, accuracy=0.727, val_loss=2.41, val_accuracy=0.442, lr=0.1] 11%|█         | 9/83 [03:45<25:57, 21.05s/epoch, loss=1.2, accuracy=0.73, val_loss=1.89, val_accuracy=0.486, lr=0.1]  12%|█▏        | 10/83 [04:05<25:18, 20.80s/epoch, loss=1.19, accuracy=0.734, val_loss=1.8, val_accuracy=0.57, lr=0.0316] 13%|█▎        | 11/83 [04:25<24:44, 20.62s/epoch, loss=1.19, accuracy=0.734, val_loss=3.72, val_accuracy=0.287, lr=0.1]  14%|█▍        | 12/83 [04:45<24:14, 20.49s/epoch, loss=1.18, accuracy=0.738, val_loss=1.71, val_accuracy=0.566, lr=0.1] 16%|█▌        | 13/83 [05:06<23:50, 20.44s/epoch, loss=1.18, accuracy=0.738, val_loss=2.45, val_accuracy=0.461, lr=0.1] 17%|█▋        | 14/83 [05:26<23:24, 20.35s/epoch, loss=1.17, accuracy=0.742, val_loss=3.24, val_accuracy=0.313, lr=0.1] 18%|█▊        | 15/83 [05:46<23:01, 20.31s/epoch, loss=1.16, accuracy=0.746, val_loss=1.8, val_accuracy=0.553, lr=0.1]  19%|█▉        | 16/83 [06:06<22:37, 20.27s/epoch, loss=1.16, accuracy=0.746, val_loss=2.6, val_accuracy=0.408, lr=0.1] 20%|██        | 17/83 [06:26<22:16, 20.25s/epoch, loss=1.15, accuracy=0.746, val_loss=2.93, val_accuracy=0.426, lr=0.0316] 22%|██▏       | 18/83 [06:47<21:52, 20.20s/epoch, loss=1.16, accuracy=0.745, val_loss=1.58, val_accuracy=0.645, lr=0.1]    23%|██▎       | 19/83 [07:07<21:31, 20.18s/epoch, loss=1.15, accuracy=0.747, val_loss=1.76, val_accuracy=0.545, lr=0.1] 24%|██▍       | 20/83 [07:27<21:10, 20.17s/epoch, loss=1.15, accuracy=0.751, val_loss=3.2, val_accuracy=0.394, lr=0.1]  25%|██▌       | 21/83 [07:47<20:49, 20.15s/epoch, loss=1.15, accuracy=0.75, val_loss=2.64, val_accuracy=0.339, lr=0.1] 27%|██▋       | 22/83 [08:07<20:27, 20.12s/epoch, loss=1.15, accuracy=0.748, val_loss=1.47, val_accuracy=0.647, lr=0.1] 28%|██▊       | 23/83 [08:27<20:15, 20.26s/epoch, loss=1.14, accuracy=0.753, val_loss=1.4, val_accuracy=0.671, lr=0.1]  29%|██▉       | 24/83 [08:48<19:55, 20.26s/epoch, loss=1.14, accuracy=0.752, val_loss=1.51, val_accuracy=0.619, lr=0.1] 30%|███       | 25/83 [09:08<19:36, 20.28s/epoch, loss=1.14, accuracy=0.75, val_loss=1.45, val_accuracy=0.639, lr=0.1]  31%|███▏      | 26/83 [09:28<19:13, 20.24s/epoch, loss=1.14, accuracy=0.751, val_loss=4.64, val_accuracy=0.32, lr=0.1] 33%|███▎      | 27/83 [09:48<18:52, 20.22s/epoch, loss=1.13, accuracy=0.754, val_loss=2.38, val_accuracy=0.426, lr=0.1] 34%|███▎      | 28/83 [10:09<18:33, 20.25s/epoch, loss=1.12, accuracy=0.752, val_loss=2.25, val_accuracy=0.472, lr=0.0316] 35%|███▍      | 29/83 [10:29<18:10, 20.20s/epoch, loss=1.13, accuracy=0.753, val_loss=1.49, val_accuracy=0.623, lr=0.1]    36%|███▌      | 30/83 [10:49<17:50, 20.19s/epoch, loss=1.13, accuracy=0.754, val_loss=2.19, val_accuracy=0.47, lr=0.1]  37%|███▋      | 31/83 [11:09<17:27, 20.14s/epoch, loss=1.13, accuracy=0.754, val_loss=1.81, val_accuracy=0.539, lr=0.1] 39%|███▊      | 32/83 [11:29<17:04, 20.09s/epoch, loss=1.13, accuracy=0.754, val_loss=2.13, val_accuracy=0.528, lr=0.1] 40%|███▉      | 33/83 [11:49<16:42, 20.05s/epoch, loss=1.13, accuracy=0.756, val_loss=2.11, val_accuracy=0.543, lr=0.0316] 41%|████      | 34/83 [12:09<16:20, 20.01s/epoch, loss=1.13, accuracy=0.756, val_loss=1.63, val_accuracy=0.601, lr=0.1]    42%|████▏     | 35/83 [12:29<16:00, 20.01s/epoch, loss=1.13, accuracy=0.754, val_loss=1.64, val_accuracy=0.6, lr=0.1]   43%|████▎     | 36/83 [12:49<15:40, 20.02s/epoch, loss=1.13, accuracy=0.754, val_loss=1.65, val_accuracy=0.621, lr=0.1] 45%|████▍     | 37/83 [13:09<15:19, 20.00s/epoch, loss=1.13, accuracy=0.756, val_loss=1.82, val_accuracy=0.544, lr=0.1] 46%|████▌     | 38/83 [13:29<15:01, 20.03s/epoch, loss=1.13, accuracy=0.753, val_loss=4.28, val_accuracy=0.326, lr=0.0316] 47%|████▋     | 39/83 [13:49<14:42, 20.06s/epoch, loss=1.13, accuracy=0.753, val_loss=1.61, val_accuracy=0.566, lr=0.1]    48%|████▊     | 40/83 [14:09<14:22, 20.05s/epoch, loss=1.12, accuracy=0.755, val_loss=1.3, val_accuracy=0.688, lr=0.1]  49%|████▉     | 41/83 [14:29<14:01, 20.03s/epoch, loss=1.12, accuracy=0.757, val_loss=1.71, val_accuracy=0.573, lr=0.1] 51%|█████     | 42/83 [14:49<13:39, 19.99s/epoch, loss=1.12, accuracy=0.757, val_loss=3.27, val_accuracy=0.391, lr=0.1] 52%|█████▏    | 43/83 [15:09<13:21, 20.03s/epoch, loss=1.13, accuracy=0.755, val_loss=2.68, val_accuracy=0.38, lr=0.1]  53%|█████▎    | 44/83 [15:29<13:00, 20.01s/epoch, loss=1.13, accuracy=0.754, val_loss=2.79, val_accuracy=0.385, lr=0.1] 54%|█████▍    | 45/83 [15:49<12:40, 20.00s/epoch, loss=1.12, accuracy=0.755, val_loss=4.7, val_accuracy=0.197, lr=0.0316] 55%|█████▌    | 46/83 [16:09<12:19, 19.99s/epoch, loss=1.12, accuracy=0.758, val_loss=1.88, val_accuracy=0.541, lr=0.1]   57%|█████▋    | 47/83 [16:29<12:00, 20.00s/epoch, loss=1.12, accuracy=0.758, val_loss=2.66, val_accuracy=0.325, lr=0.1] 58%|█████▊    | 48/83 [16:49<11:39, 19.99s/epoch, loss=1.13, accuracy=0.755, val_loss=1.78, val_accuracy=0.522, lr=0.1] 59%|█████▉    | 49/83 [17:09<11:20, 20.02s/epoch, loss=1.12, accuracy=0.758, val_loss=1.91, val_accuracy=0.535, lr=0.1] 60%|██████    | 50/83 [17:29<11:02, 20.09s/epoch, loss=1.12, accuracy=0.759, val_loss=2.01, val_accuracy=0.515, lr=0.0316] 61%|██████▏   | 51/83 [17:50<10:43, 20.12s/epoch, loss=1.12, accuracy=0.755, val_loss=2.82, val_accuracy=0.38, lr=0.1]     63%|██████▎   | 52/83 [18:09<10:22, 20.07s/epoch, loss=1.12, accuracy=0.754, val_loss=2.04, val_accuracy=0.484, lr=0.1] 64%|██████▍   | 53/83 [18:30<10:02, 20.09s/epoch, loss=1.12, accuracy=0.757, val_loss=1.74, val_accuracy=0.538, lr=0.1] 65%|██████▌   | 54/83 [18:50<09:41, 20.04s/epoch, loss=1.12, accuracy=0.755, val_loss=6.37, val_accuracy=0.166, lr=0.1] 66%|██████▋   | 55/83 [19:09<09:20, 20.01s/epoch, loss=1.12, accuracy=0.756, val_loss=2.34, val_accuracy=0.524, lr=0.0316] 67%|██████▋   | 56/83 [19:30<09:01, 20.05s/epoch, loss=1.11, accuracy=0.76, val_loss=3.27, val_accuracy=0.225, lr=0.1]     69%|██████▊   | 57/83 [19:50<08:42, 20.11s/epoch, loss=1.11, accuracy=0.757, val_loss=1.66, val_accuracy=0.579, lr=0.1] 70%|██████▉   | 58/83 [20:10<08:23, 20.15s/epoch, loss=1.11, accuracy=0.758, val_loss=2.52, val_accuracy=0.354, lr=0.1] 71%|███████   | 59/83 [20:30<08:03, 20.14s/epoch, loss=1.11, accuracy=0.758, val_loss=1.55, val_accuracy=0.625, lr=0.1] 72%|███████▏  | 60/83 [20:50<07:43, 20.14s/epoch, loss=1.11, accuracy=0.758, val_loss=2.16, val_accuracy=0.451, lr=0.0316] 73%|███████▎  | 61/83 [21:11<07:23, 20.16s/epoch, loss=1.11, accuracy=0.758, val_loss=3.36, val_accuracy=0.36, lr=0.1]     75%|███████▍  | 62/83 [21:31<07:03, 20.17s/epoch, loss=1.11, accuracy=0.761, val_loss=1.91, val_accuracy=0.549, lr=0.1] 76%|███████▌  | 63/83 [21:51<06:43, 20.20s/epoch, loss=1.12, accuracy=0.758, val_loss=1.43, val_accuracy=0.637, lr=0.1] 77%|███████▋  | 64/83 [22:11<06:23, 20.20s/epoch, loss=1.11, accuracy=0.759, val_loss=2.21, val_accuracy=0.522, lr=0.1] 78%|███████▊  | 65/83 [22:31<06:02, 20.17s/epoch, loss=1.11, accuracy=0.757, val_loss=1.92, val_accuracy=0.557, lr=0.0316] 80%|███████▉  | 66/83 [22:51<05:42, 20.15s/epoch, loss=1.1, accuracy=0.76, val_loss=2.07, val_accuracy=0.479, lr=0.1]      81%|████████  | 67/83 [23:11<05:21, 20.10s/epoch, loss=1.11, accuracy=0.757, val_loss=1.77, val_accuracy=0.574, lr=0.1] 82%|████████▏ | 68/83 [23:32<05:01, 20.12s/epoch, loss=1.11, accuracy=0.757, val_loss=7.27, val_accuracy=0.154, lr=0.1] 83%|████████▎ | 69/83 [23:52<04:41, 20.12s/epoch, loss=1.12, accuracy=0.758, val_loss=5.01, val_accuracy=0.194, lr=0.1] 84%|████████▍ | 70/83 [24:12<04:22, 20.17s/epoch, loss=1.11, accuracy=0.756, val_loss=2.19, val_accuracy=0.473, lr=0.0316] 86%|████████▌ | 71/83 [24:32<04:02, 20.21s/epoch, loss=1.1, accuracy=0.76, val_loss=1.68, val_accuracy=0.575, lr=0.1]      87%|████████▋ | 72/83 [24:52<03:42, 20.18s/epoch, loss=1.11, accuracy=0.756, val_loss=1.8, val_accuracy=0.594, lr=0.1] 88%|████████▊ | 73/83 [25:13<03:21, 20.20s/epoch, loss=1.1, accuracy=0.759, val_loss=4.1, val_accuracy=0.28, lr=0.1]   89%|████████▉ | 74/83 [25:33<03:02, 20.28s/epoch, loss=1.11, accuracy=0.758, val_loss=2.3, val_accuracy=0.379, lr=0.1] 90%|█████████ | 75/83 [25:53<02:42, 20.27s/epoch, loss=1.11, accuracy=0.759, val_loss=1.89, val_accuracy=0.51, lr=0.0316] 92%|█████████▏| 76/83 [26:14<02:22, 20.32s/epoch, loss=1.11, accuracy=0.757, val_loss=2.83, val_accuracy=0.391, lr=0.1]   93%|█████████▎| 77/83 [26:34<02:01, 20.31s/epoch, loss=1.1, accuracy=0.761, val_loss=2.6, val_accuracy=0.365, lr=0.1]   94%|█████████▍| 78/83 [26:54<01:41, 20.30s/epoch, loss=1.11, accuracy=0.757, val_loss=5.75, val_accuracy=0.287, lr=0.1] 95%|█████████▌| 79/83 [27:15<01:21, 20.26s/epoch, loss=1.1, accuracy=0.76, val_loss=2.7, val_accuracy=0.452, lr=0.1]    96%|█████████▋| 80/83 [27:35<01:00, 20.21s/epoch, loss=1.11, accuracy=0.756, val_loss=3.31, val_accuracy=0.368, lr=0.0316] 98%|█████████▊| 81/83 [27:55<00:40, 20.20s/epoch, loss=1.1, accuracy=0.758, val_loss=1.73, val_accuracy=0.575, lr=0.1]     99%|█████████▉| 82/83 [28:15<00:20, 20.14s/epoch, loss=0.909, accuracy=0.813, val_loss=0.913, val_accuracy=0.794, lr=0.01]100%|██████████| 83/83 [28:35<00:00, 20.02s/epoch, loss=0.722, accuracy=0.848, val_loss=0.818, val_accuracy=0.808, lr=0.01]100%|██████████| 83/83 [28:35<00:00, 20.66s/epoch, loss=0.722, accuracy=0.848, val_loss=0.818, val_accuracy=0.808, lr=0.01]
Using real-time data augmentation.
Test score: 0.8177993893623352
Test accuracy: 0.8082000017166138


* * * Run SGD for ID = 18_17. * * *


2024-03-05 17:35:00.850976: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 17:35:02.912783: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 17:35:02.913859: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-05 17:35:02.953103: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-03-05 17:35:02.953151: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 17:35:02.955901: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 17:35:02.955941: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 17:35:02.958072: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 17:35:02.959069: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 17:35:02.961356: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 17:35:02.962621: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 17:35:02.967081: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 17:35:02.971197: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 17:35:02.971303: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 17:35:04.201751: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-05 17:35:04.202709: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 17:35:04.203421: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-03-05 17:35:04.203450: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 17:35:04.203488: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 17:35:04.203505: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 17:35:04.203520: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 17:35:04.203536: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 17:35:04.203561: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 17:35:04.203577: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 17:35:04.203591: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 17:35:04.204017: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 17:35:04.204051: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 17:35:04.861744: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-05 17:35:04.861803: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-05 17:35:04.861812: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-05 17:35:04.862733: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': '18_17', 'seed': 17, 'out_folder': 'results/epoch_budget', 'batch_size': 128, 'epochs': 83, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'bootstrapping': False, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/83 [00:00<?, ?epoch/s]2024-03-05 17:35:05.703756: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-05 17:35:05.704352: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600020000 Hz
2024-03-05 17:35:07.666209: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 17:35:07.903277: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 17:35:08.640791: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-05 17:35:08.691662: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/83 [00:59<1:21:37, 59.73s/epoch, loss=3.07, accuracy=0.365, val_loss=4.43, val_accuracy=0.172, lr=0.1]  2%|▏         | 2/83 [01:19<49:16, 36.50s/epoch, loss=1.5, accuracy=0.564, val_loss=2.34, val_accuracy=0.36, lr=0.1]      4%|▎         | 3/83 [01:40<38:44, 29.06s/epoch, loss=1.3, accuracy=0.655, val_loss=4.62, val_accuracy=0.264, lr=0.1]  5%|▍         | 4/83 [02:00<33:38, 25.55s/epoch, loss=1.25, accuracy=0.692, val_loss=1.59, val_accuracy=0.596, lr=0.1]  6%|▌         | 5/83 [02:20<30:35, 23.53s/epoch, loss=1.22, accuracy=0.71, val_loss=1.68, val_accuracy=0.602, lr=0.1]   7%|▋         | 6/83 [02:40<28:37, 22.30s/epoch, loss=1.21, accuracy=0.717, val_loss=2.16, val_accuracy=0.453, lr=0.1]  8%|▊         | 7/83 [03:00<27:20, 21.59s/epoch, loss=1.2, accuracy=0.722, val_loss=2.08, val_accuracy=0.477, lr=0.1]  10%|▉         | 8/83 [03:21<26:40, 21.34s/epoch, loss=1.19, accuracy=0.728, val_loss=1.88, val_accuracy=0.54, lr=0.1] 11%|█         | 9/83 [03:41<25:49, 20.93s/epoch, loss=1.18, accuracy=0.732, val_loss=1.65, val_accuracy=0.572, lr=0.0316] 12%|█▏        | 10/83 [04:01<25:07, 20.65s/epoch, loss=1.18, accuracy=0.733, val_loss=1.58, val_accuracy=0.603, lr=0.1]   13%|█▎        | 11/83 [04:21<24:30, 20.42s/epoch, loss=1.17, accuracy=0.737, val_loss=1.55, val_accuracy=0.613, lr=0.1] 14%|█▍        | 12/83 [04:40<23:56, 20.24s/epoch, loss=1.16, accuracy=0.739, val_loss=2.04, val_accuracy=0.526, lr=0.1] 16%|█▌        | 13/83 [05:00<23:28, 20.12s/epoch, loss=1.16, accuracy=0.742, val_loss=1.88, val_accuracy=0.58, lr=0.1]  17%|█▋        | 14/83 [05:20<23:04, 20.06s/epoch, loss=1.16, accuracy=0.741, val_loss=1.79, val_accuracy=0.533, lr=0.1] 18%|█▊        | 15/83 [05:40<22:42, 20.03s/epoch, loss=1.17, accuracy=0.739, val_loss=3.46, val_accuracy=0.35, lr=0.1]  19%|█▉        | 16/83 [06:00<22:22, 20.03s/epoch, loss=1.15, accuracy=0.744, val_loss=2.51, val_accuracy=0.35, lr=0.0316] 20%|██        | 17/83 [06:20<21:59, 20.00s/epoch, loss=1.16, accuracy=0.744, val_loss=4.3, val_accuracy=0.224, lr=0.1]    22%|██▏       | 18/83 [06:40<21:38, 19.97s/epoch, loss=1.15, accuracy=0.745, val_loss=2.48, val_accuracy=0.451, lr=0.1] 23%|██▎       | 19/83 [07:00<21:19, 19.99s/epoch, loss=1.15, accuracy=0.746, val_loss=1.68, val_accuracy=0.56, lr=0.1]  24%|██▍       | 20/83 [07:20<20:55, 19.94s/epoch, loss=1.15, accuracy=0.748, val_loss=2.61, val_accuracy=0.47, lr=0.1] 25%|██▌       | 21/83 [07:40<20:38, 19.98s/epoch, loss=1.15, accuracy=0.747, val_loss=1.96, val_accuracy=0.545, lr=0.0316] 27%|██▋       | 22/83 [08:00<20:24, 20.07s/epoch, loss=1.14, accuracy=0.748, val_loss=5.18, val_accuracy=0.215, lr=0.1]    28%|██▊       | 23/83 [08:20<20:04, 20.08s/epoch, loss=1.14, accuracy=0.747, val_loss=2.3, val_accuracy=0.447, lr=0.1]  29%|██▉       | 24/83 [08:41<19:47, 20.13s/epoch, loss=1.14, accuracy=0.75, val_loss=1.63, val_accuracy=0.569, lr=0.1] 30%|███       | 25/83 [09:01<19:25, 20.10s/epoch, loss=1.14, accuracy=0.749, val_loss=2.5, val_accuracy=0.436, lr=0.1] 31%|███▏      | 26/83 [09:20<19:02, 20.04s/epoch, loss=1.13, accuracy=0.75, val_loss=1.47, val_accuracy=0.622, lr=0.1] 33%|███▎      | 27/83 [09:40<18:40, 20.01s/epoch, loss=1.13, accuracy=0.752, val_loss=1.86, val_accuracy=0.483, lr=0.1] 34%|███▎      | 28/83 [10:00<18:19, 20.00s/epoch, loss=1.13, accuracy=0.753, val_loss=2.07, val_accuracy=0.464, lr=0.1] 35%|███▍      | 29/83 [10:20<18:00, 20.01s/epoch, loss=1.13, accuracy=0.751, val_loss=1.58, val_accuracy=0.593, lr=0.1] 36%|███▌      | 30/83 [10:40<17:37, 19.96s/epoch, loss=1.13, accuracy=0.751, val_loss=1.81, val_accuracy=0.524, lr=0.1] 37%|███▋      | 31/83 [11:00<17:19, 20.00s/epoch, loss=1.13, accuracy=0.753, val_loss=10.2, val_accuracy=0.162, lr=0.0316] 39%|███▊      | 32/83 [11:20<16:57, 19.96s/epoch, loss=1.12, accuracy=0.755, val_loss=2.29, val_accuracy=0.449, lr=0.1]    40%|███▉      | 33/83 [11:40<16:37, 19.94s/epoch, loss=1.13, accuracy=0.752, val_loss=1.76, val_accuracy=0.568, lr=0.1] 41%|████      | 34/83 [12:00<16:17, 19.94s/epoch, loss=1.12, accuracy=0.753, val_loss=1.89, val_accuracy=0.533, lr=0.1] 42%|████▏     | 35/83 [12:20<15:57, 19.95s/epoch, loss=1.12, accuracy=0.751, val_loss=2.34, val_accuracy=0.46, lr=0.1]  43%|████▎     | 36/83 [12:40<15:38, 19.97s/epoch, loss=1.12, accuracy=0.754, val_loss=1.48, val_accuracy=0.633, lr=0.0316] 45%|████▍     | 37/83 [13:00<15:17, 19.95s/epoch, loss=1.12, accuracy=0.757, val_loss=3.06, val_accuracy=0.408, lr=0.1]    46%|████▌     | 38/83 [13:20<14:56, 19.92s/epoch, loss=1.11, accuracy=0.755, val_loss=2.6, val_accuracy=0.387, lr=0.1]  47%|████▋     | 39/83 [13:40<14:36, 19.93s/epoch, loss=1.12, accuracy=0.753, val_loss=3.49, val_accuracy=0.259, lr=0.1] 48%|████▊     | 40/83 [14:00<14:17, 19.94s/epoch, loss=1.11, accuracy=0.755, val_loss=2.41, val_accuracy=0.451, lr=0.1] 49%|████▉     | 41/83 [14:20<13:57, 19.93s/epoch, loss=1.11, accuracy=0.755, val_loss=2.43, val_accuracy=0.464, lr=0.0316] 51%|█████     | 42/83 [14:40<13:37, 19.93s/epoch, loss=1.11, accuracy=0.756, val_loss=2.67, val_accuracy=0.442, lr=0.1]    52%|█████▏    | 43/83 [15:00<13:19, 20.00s/epoch, loss=1.11, accuracy=0.756, val_loss=3.41, val_accuracy=0.379, lr=0.1] 53%|█████▎    | 44/83 [15:20<13:00, 20.02s/epoch, loss=1.1, accuracy=0.758, val_loss=3.1, val_accuracy=0.312, lr=0.1]   54%|█████▍    | 45/83 [15:40<12:41, 20.03s/epoch, loss=1.12, accuracy=0.755, val_loss=2.43, val_accuracy=0.451, lr=0.1] 55%|█████▌    | 46/83 [16:00<12:20, 20.02s/epoch, loss=1.11, accuracy=0.755, val_loss=7.5, val_accuracy=0.183, lr=0.0316] 57%|█████▋    | 47/83 [16:20<12:01, 20.04s/epoch, loss=1.1, accuracy=0.759, val_loss=2.97, val_accuracy=0.445, lr=0.1]    58%|█████▊    | 48/83 [16:40<11:41, 20.03s/epoch, loss=1.1, accuracy=0.758, val_loss=1.78, val_accuracy=0.557, lr=0.1] 59%|█████▉    | 49/83 [17:00<11:20, 20.01s/epoch, loss=1.11, accuracy=0.756, val_loss=2.27, val_accuracy=0.481, lr=0.1] 60%|██████    | 50/83 [17:20<11:02, 20.06s/epoch, loss=1.1, accuracy=0.758, val_loss=2.42, val_accuracy=0.435, lr=0.1]  61%|██████▏   | 51/83 [17:40<10:44, 20.13s/epoch, loss=1.1, accuracy=0.758, val_loss=1.96, val_accuracy=0.523, lr=0.0316] 63%|██████▎   | 52/83 [18:01<10:24, 20.14s/epoch, loss=1.11, accuracy=0.756, val_loss=1.92, val_accuracy=0.557, lr=0.1]   64%|██████▍   | 53/83 [18:21<10:04, 20.16s/epoch, loss=1.11, accuracy=0.757, val_loss=7.03, val_accuracy=0.184, lr=0.1] 65%|██████▌   | 54/83 [18:41<09:45, 20.17s/epoch, loss=1.11, accuracy=0.759, val_loss=2.16, val_accuracy=0.356, lr=0.1] 66%|██████▋   | 55/83 [19:01<09:24, 20.16s/epoch, loss=1.1, accuracy=0.758, val_loss=4.53, val_accuracy=0.269, lr=0.1]  67%|██████▋   | 56/83 [19:21<09:01, 20.05s/epoch, loss=1.1, accuracy=0.757, val_loss=1.95, val_accuracy=0.488, lr=0.0316] 69%|██████▊   | 57/83 [19:41<08:41, 20.07s/epoch, loss=1.1, accuracy=0.759, val_loss=4.93, val_accuracy=0.239, lr=0.1]    70%|██████▉   | 58/83 [20:01<08:23, 20.15s/epoch, loss=1.1, accuracy=0.758, val_loss=2.46, val_accuracy=0.359, lr=0.1] 71%|███████   | 59/83 [20:21<08:03, 20.14s/epoch, loss=1.1, accuracy=0.757, val_loss=2.15, val_accuracy=0.479, lr=0.1] 72%|███████▏  | 60/83 [20:42<07:44, 20.19s/epoch, loss=1.1, accuracy=0.757, val_loss=1.93, val_accuracy=0.565, lr=0.1] 73%|███████▎  | 61/83 [21:02<07:24, 20.20s/epoch, loss=1.1, accuracy=0.757, val_loss=1.43, val_accuracy=0.66, lr=0.1]  75%|███████▍  | 62/83 [21:22<07:03, 20.19s/epoch, loss=1.1, accuracy=0.757, val_loss=3.07, val_accuracy=0.374, lr=0.1] 76%|███████▌  | 63/83 [21:42<06:43, 20.17s/epoch, loss=1.1, accuracy=0.758, val_loss=8.62, val_accuracy=0.146, lr=0.1] 77%|███████▋  | 64/83 [22:02<06:23, 20.16s/epoch, loss=1.1, accuracy=0.756, val_loss=2.38, val_accuracy=0.453, lr=0.1] 78%|███████▊  | 65/83 [22:22<06:01, 20.10s/epoch, loss=1.1, accuracy=0.758, val_loss=2.78, val_accuracy=0.385, lr=0.1] 80%|███████▉  | 66/83 [22:43<05:42, 20.13s/epoch, loss=1.1, accuracy=0.759, val_loss=2.59, val_accuracy=0.394, lr=0.0316] 81%|████████  | 67/83 [23:03<05:21, 20.12s/epoch, loss=1.1, accuracy=0.759, val_loss=2.55, val_accuracy=0.374, lr=0.1]    82%|████████▏ | 68/83 [23:23<05:02, 20.18s/epoch, loss=1.09, accuracy=0.76, val_loss=2.74, val_accuracy=0.411, lr=0.1] 83%|████████▎ | 69/83 [23:43<04:42, 20.17s/epoch, loss=1.1, accuracy=0.759, val_loss=3.29, val_accuracy=0.348, lr=0.1] 84%|████████▍ | 70/83 [24:03<04:21, 20.14s/epoch, loss=1.1, accuracy=0.758, val_loss=1.51, val_accuracy=0.618, lr=0.1] 86%|████████▌ | 71/83 [24:23<04:00, 20.08s/epoch, loss=1.1, accuracy=0.757, val_loss=2.46, val_accuracy=0.439, lr=0.0316] 87%|████████▋ | 72/83 [24:43<03:40, 20.05s/epoch, loss=1.1, accuracy=0.759, val_loss=1.72, val_accuracy=0.536, lr=0.1]    88%|████████▊ | 73/83 [25:03<03:19, 20.00s/epoch, loss=1.1, accuracy=0.757, val_loss=2.06, val_accuracy=0.538, lr=0.1] 89%|████████▉ | 74/83 [25:23<02:59, 19.98s/epoch, loss=1.1, accuracy=0.758, val_loss=2.13, val_accuracy=0.525, lr=0.1] 90%|█████████ | 75/83 [25:43<02:39, 19.97s/epoch, loss=1.1, accuracy=0.759, val_loss=2.1, val_accuracy=0.454, lr=0.1]  92%|█████████▏| 76/83 [26:03<02:19, 19.97s/epoch, loss=1.09, accuracy=0.761, val_loss=2.88, val_accuracy=0.419, lr=0.0316] 93%|█████████▎| 77/83 [26:23<01:59, 20.00s/epoch, loss=1.1, accuracy=0.757, val_loss=1.8, val_accuracy=0.569, lr=0.1]      94%|█████████▍| 78/83 [26:43<01:40, 20.05s/epoch, loss=1.1, accuracy=0.757, val_loss=2.57, val_accuracy=0.387, lr=0.1] 95%|█████████▌| 79/83 [27:03<01:20, 20.09s/epoch, loss=1.1, accuracy=0.758, val_loss=2.32, val_accuracy=0.408, lr=0.1] 96%|█████████▋| 80/83 [27:23<01:00, 20.13s/epoch, loss=1.1, accuracy=0.759, val_loss=1.52, val_accuracy=0.615, lr=0.1] 98%|█████████▊| 81/83 [27:44<00:40, 20.14s/epoch, loss=1.1, accuracy=0.758, val_loss=3.06, val_accuracy=0.381, lr=0.0316] 99%|█████████▉| 82/83 [28:04<00:20, 20.14s/epoch, loss=0.888, accuracy=0.816, val_loss=0.856, val_accuracy=0.812, lr=0.01]100%|██████████| 83/83 [28:24<00:00, 20.11s/epoch, loss=0.724, accuracy=0.846, val_loss=0.795, val_accuracy=0.814, lr=0.01]100%|██████████| 83/83 [28:24<00:00, 20.53s/epoch, loss=0.724, accuracy=0.846, val_loss=0.795, val_accuracy=0.814, lr=0.01]
Using real-time data augmentation.
Test score: 0.7953525185585022
Test accuracy: 0.8137000203132629


* * * Run SGD for ID = 18_18. * * *


2024-03-05 18:03:33.854603: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 18:03:36.925916: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 18:03:36.927159: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-05 18:03:36.964834: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-03-05 18:03:36.964878: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 18:03:36.967884: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 18:03:36.967935: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 18:03:36.970175: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 18:03:36.970888: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 18:03:36.973251: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 18:03:36.974709: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 18:03:36.979293: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 18:03:36.979909: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 18:03:36.980006: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 18:03:38.228752: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-05 18:03:38.229434: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 18:03:38.230219: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-03-05 18:03:38.230254: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 18:03:38.230295: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 18:03:38.230313: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 18:03:38.230328: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 18:03:38.230347: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 18:03:38.230362: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 18:03:38.230376: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 18:03:38.230390: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 18:03:38.230822: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 18:03:38.230864: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 18:03:38.874232: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-05 18:03:38.874286: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-05 18:03:38.874294: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-05 18:03:38.875180: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': '18_18', 'seed': 18, 'out_folder': 'results/epoch_budget', 'batch_size': 128, 'epochs': 83, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'bootstrapping': False, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/83 [00:00<?, ?epoch/s]2024-03-05 18:03:39.744384: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-05 18:03:39.756112: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600020000 Hz
2024-03-05 18:03:41.780749: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 18:03:41.986101: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 18:03:42.873174: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-05 18:03:42.939189: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/83 [01:04<1:28:40, 64.89s/epoch, loss=3, accuracy=0.335, val_loss=3.06, val_accuracy=0.244, lr=0.1]  2%|▏         | 2/83 [01:24<51:59, 38.51s/epoch, loss=1.5, accuracy=0.571, val_loss=2.73, val_accuracy=0.29, lr=0.1]   4%|▎         | 3/83 [01:45<40:09, 30.11s/epoch, loss=1.31, accuracy=0.663, val_loss=2.11, val_accuracy=0.413, lr=0.1]  5%|▍         | 4/83 [02:05<34:24, 26.13s/epoch, loss=1.27, accuracy=0.688, val_loss=1.62, val_accuracy=0.553, lr=0.1]  6%|▌         | 5/83 [02:24<31:01, 23.87s/epoch, loss=1.24, accuracy=0.706, val_loss=1.83, val_accuracy=0.491, lr=0.1]  7%|▋         | 6/83 [02:45<29:06, 22.68s/epoch, loss=1.23, accuracy=0.715, val_loss=2, val_accuracy=0.469, lr=0.1]     8%|▊         | 7/83 [03:04<27:20, 21.58s/epoch, loss=1.22, accuracy=0.72, val_loss=1.44, val_accuracy=0.635, lr=0.1] 10%|▉         | 8/83 [03:23<26:05, 20.87s/epoch, loss=1.21, accuracy=0.725, val_loss=2.21, val_accuracy=0.404, lr=0.1] 11%|█         | 9/83 [03:43<25:08, 20.38s/epoch, loss=1.2, accuracy=0.727, val_loss=2.83, val_accuracy=0.402, lr=0.1]  12%|█▏        | 10/83 [04:02<24:22, 20.03s/epoch, loss=1.19, accuracy=0.733, val_loss=2.55, val_accuracy=0.377, lr=0.1] 13%|█▎        | 11/83 [04:22<23:54, 19.92s/epoch, loss=1.19, accuracy=0.732, val_loss=1.53, val_accuracy=0.621, lr=0.1] 14%|█▍        | 12/83 [04:41<23:23, 19.76s/epoch, loss=1.19, accuracy=0.739, val_loss=2.48, val_accuracy=0.479, lr=0.0316] 16%|█▌        | 13/83 [05:00<22:54, 19.63s/epoch, loss=1.19, accuracy=0.738, val_loss=1.56, val_accuracy=0.597, lr=0.1]    17%|█▋        | 14/83 [05:20<22:28, 19.55s/epoch, loss=1.17, accuracy=0.742, val_loss=2.09, val_accuracy=0.458, lr=0.1] 18%|█▊        | 15/83 [05:39<22:08, 19.54s/epoch, loss=1.18, accuracy=0.741, val_loss=2.09, val_accuracy=0.483, lr=0.1] 19%|█▉        | 16/83 [05:59<21:44, 19.47s/epoch, loss=1.18, accuracy=0.743, val_loss=1.63, val_accuracy=0.589, lr=0.1] 20%|██        | 17/83 [06:18<21:26, 19.49s/epoch, loss=1.17, accuracy=0.743, val_loss=2.49, val_accuracy=0.428, lr=0.0316] 22%|██▏       | 18/83 [06:38<21:04, 19.45s/epoch, loss=1.17, accuracy=0.743, val_loss=1.44, val_accuracy=0.667, lr=0.1]    23%|██▎       | 19/83 [06:57<20:42, 19.42s/epoch, loss=1.18, accuracy=0.744, val_loss=1.72, val_accuracy=0.521, lr=0.1] 24%|██▍       | 20/83 [07:16<20:24, 19.44s/epoch, loss=1.16, accuracy=0.747, val_loss=2.23, val_accuracy=0.445, lr=0.1] 25%|██▌       | 21/83 [07:36<20:04, 19.42s/epoch, loss=1.17, accuracy=0.745, val_loss=1.63, val_accuracy=0.595, lr=0.1] 27%|██▋       | 22/83 [07:55<19:48, 19.49s/epoch, loss=1.17, accuracy=0.748, val_loss=1.84, val_accuracy=0.56, lr=0.0316] 28%|██▊       | 23/83 [08:15<19:33, 19.56s/epoch, loss=1.16, accuracy=0.75, val_loss=1.74, val_accuracy=0.557, lr=0.1]    29%|██▉       | 24/83 [08:34<19:08, 19.47s/epoch, loss=1.16, accuracy=0.748, val_loss=1.53, val_accuracy=0.615, lr=0.1] 30%|███       | 25/83 [08:54<18:44, 19.39s/epoch, loss=1.16, accuracy=0.75, val_loss=1.91, val_accuracy=0.511, lr=0.1]  31%|███▏      | 26/83 [09:13<18:26, 19.40s/epoch, loss=1.16, accuracy=0.749, val_loss=2.37, val_accuracy=0.464, lr=0.1] 33%|███▎      | 27/83 [09:32<18:02, 19.33s/epoch, loss=1.16, accuracy=0.748, val_loss=2.44, val_accuracy=0.358, lr=0.0316] 34%|███▎      | 28/83 [09:51<17:40, 19.27s/epoch, loss=1.15, accuracy=0.75, val_loss=2.27, val_accuracy=0.497, lr=0.1]     35%|███▍      | 29/83 [10:11<17:21, 19.28s/epoch, loss=1.15, accuracy=0.752, val_loss=1.83, val_accuracy=0.524, lr=0.1] 36%|███▌      | 30/83 [10:30<17:00, 19.26s/epoch, loss=1.16, accuracy=0.748, val_loss=1.55, val_accuracy=0.621, lr=0.1] 37%|███▋      | 31/83 [10:49<16:45, 19.33s/epoch, loss=1.15, accuracy=0.75, val_loss=1.41, val_accuracy=0.652, lr=0.1]  39%|███▊      | 32/83 [11:09<16:24, 19.30s/epoch, loss=1.15, accuracy=0.751, val_loss=2.2, val_accuracy=0.498, lr=0.1] 40%|███▉      | 33/83 [11:28<16:02, 19.26s/epoch, loss=1.14, accuracy=0.753, val_loss=1.63, val_accuracy=0.577, lr=0.1] 41%|████      | 34/83 [11:47<15:41, 19.22s/epoch, loss=1.15, accuracy=0.752, val_loss=2.75, val_accuracy=0.383, lr=0.1] 42%|████▏     | 35/83 [12:06<15:28, 19.33s/epoch, loss=1.14, accuracy=0.755, val_loss=2.53, val_accuracy=0.412, lr=0.1] 43%|████▎     | 36/83 [12:26<15:09, 19.36s/epoch, loss=1.14, accuracy=0.753, val_loss=1.75, val_accuracy=0.56, lr=0.0316] 45%|████▍     | 37/83 [12:45<14:51, 19.38s/epoch, loss=1.14, accuracy=0.753, val_loss=2.79, val_accuracy=0.368, lr=0.1]   46%|████▌     | 38/83 [13:05<14:32, 19.40s/epoch, loss=1.14, accuracy=0.755, val_loss=1.92, val_accuracy=0.523, lr=0.1] 47%|████▋     | 39/83 [13:24<14:11, 19.35s/epoch, loss=1.14, accuracy=0.755, val_loss=2.7, val_accuracy=0.407, lr=0.1]  48%|████▊     | 40/83 [13:43<13:51, 19.34s/epoch, loss=1.15, accuracy=0.753, val_loss=2.07, val_accuracy=0.507, lr=0.1] 49%|████▉     | 41/83 [14:03<13:33, 19.37s/epoch, loss=1.14, accuracy=0.753, val_loss=1.51, val_accuracy=0.612, lr=0.0316] 51%|█████     | 42/83 [14:23<13:19, 19.50s/epoch, loss=1.14, accuracy=0.754, val_loss=2.1, val_accuracy=0.458, lr=0.1]     52%|█████▏    | 43/83 [14:42<12:58, 19.45s/epoch, loss=1.14, accuracy=0.756, val_loss=2.01, val_accuracy=0.508, lr=0.1] 53%|█████▎    | 44/83 [15:01<12:37, 19.43s/epoch, loss=1.15, accuracy=0.756, val_loss=1.82, val_accuracy=0.558, lr=0.1] 54%|█████▍    | 45/83 [15:21<12:19, 19.46s/epoch, loss=1.14, accuracy=0.755, val_loss=1.6, val_accuracy=0.596, lr=0.1]  55%|█████▌    | 46/83 [15:40<12:00, 19.48s/epoch, loss=1.14, accuracy=0.756, val_loss=1.83, val_accuracy=0.521, lr=0.0316] 57%|█████▋    | 47/83 [16:00<11:39, 19.43s/epoch, loss=1.13, accuracy=0.757, val_loss=1.72, val_accuracy=0.591, lr=0.1]    58%|█████▊    | 48/83 [16:19<11:19, 19.42s/epoch, loss=1.14, accuracy=0.756, val_loss=1.46, val_accuracy=0.644, lr=0.1] 59%|█████▉    | 49/83 [16:38<10:59, 19.40s/epoch, loss=1.14, accuracy=0.758, val_loss=1.98, val_accuracy=0.527, lr=0.1] 60%|██████    | 50/83 [16:58<10:39, 19.37s/epoch, loss=1.14, accuracy=0.757, val_loss=1.72, val_accuracy=0.529, lr=0.1] 61%|██████▏   | 51/83 [17:17<10:17, 19.31s/epoch, loss=1.13, accuracy=0.756, val_loss=2.79, val_accuracy=0.458, lr=0.0316] 63%|██████▎   | 52/83 [17:36<09:58, 19.30s/epoch, loss=1.14, accuracy=0.755, val_loss=3.46, val_accuracy=0.359, lr=0.1]    64%|██████▍   | 53/83 [17:56<09:44, 19.49s/epoch, loss=1.13, accuracy=0.76, val_loss=1.92, val_accuracy=0.569, lr=0.1]  65%|██████▌   | 54/83 [18:16<09:25, 19.49s/epoch, loss=1.14, accuracy=0.758, val_loss=2.8, val_accuracy=0.343, lr=0.1] 66%|██████▋   | 55/83 [18:35<09:03, 19.40s/epoch, loss=1.14, accuracy=0.759, val_loss=2.09, val_accuracy=0.463, lr=0.1] 67%|██████▋   | 56/83 [18:54<08:42, 19.36s/epoch, loss=1.14, accuracy=0.755, val_loss=2.19, val_accuracy=0.467, lr=0.0316] 69%|██████▊   | 57/83 [19:13<08:23, 19.38s/epoch, loss=1.12, accuracy=0.758, val_loss=4.62, val_accuracy=0.228, lr=0.1]    70%|██████▉   | 58/83 [19:33<08:04, 19.36s/epoch, loss=1.13, accuracy=0.759, val_loss=6.7, val_accuracy=0.185, lr=0.1]  71%|███████   | 59/83 [19:52<07:43, 19.33s/epoch, loss=1.13, accuracy=0.758, val_loss=1.72, val_accuracy=0.55, lr=0.1] 72%|███████▏  | 60/83 [20:11<07:24, 19.33s/epoch, loss=1.13, accuracy=0.754, val_loss=2.13, val_accuracy=0.505, lr=0.1] 73%|███████▎  | 61/83 [20:31<07:05, 19.36s/epoch, loss=1.13, accuracy=0.759, val_loss=1.97, val_accuracy=0.501, lr=0.0316] 75%|███████▍  | 62/83 [20:50<06:45, 19.30s/epoch, loss=1.13, accuracy=0.757, val_loss=1.54, val_accuracy=0.624, lr=0.1]    76%|███████▌  | 63/83 [21:09<06:25, 19.28s/epoch, loss=1.13, accuracy=0.755, val_loss=1.92, val_accuracy=0.554, lr=0.1] 77%|███████▋  | 64/83 [21:28<06:06, 19.26s/epoch, loss=1.13, accuracy=0.754, val_loss=4.47, val_accuracy=0.34, lr=0.1]  78%|███████▊  | 65/83 [21:47<05:45, 19.22s/epoch, loss=1.12, accuracy=0.758, val_loss=1.61, val_accuracy=0.603, lr=0.1] 80%|███████▉  | 66/83 [22:07<05:26, 19.23s/epoch, loss=1.12, accuracy=0.761, val_loss=3.03, val_accuracy=0.408, lr=0.0316] 81%|████████  | 67/83 [22:26<05:07, 19.24s/epoch, loss=1.12, accuracy=0.761, val_loss=1.61, val_accuracy=0.596, lr=0.1]    82%|████████▏ | 68/83 [22:45<04:48, 19.23s/epoch, loss=1.12, accuracy=0.76, val_loss=1.85, val_accuracy=0.567, lr=0.1]  83%|████████▎ | 69/83 [23:04<04:28, 19.18s/epoch, loss=1.13, accuracy=0.757, val_loss=1.84, val_accuracy=0.542, lr=0.1] 84%|████████▍ | 70/83 [23:23<04:08, 19.14s/epoch, loss=1.12, accuracy=0.757, val_loss=2.05, val_accuracy=0.491, lr=0.1] 86%|████████▌ | 71/83 [23:42<03:49, 19.13s/epoch, loss=1.12, accuracy=0.756, val_loss=1.84, val_accuracy=0.518, lr=0.0316] 87%|████████▋ | 72/83 [24:02<03:30, 19.13s/epoch, loss=1.12, accuracy=0.757, val_loss=2.03, val_accuracy=0.534, lr=0.1]    88%|████████▊ | 73/83 [24:21<03:12, 19.24s/epoch, loss=1.12, accuracy=0.758, val_loss=3.61, val_accuracy=0.294, lr=0.1] 89%|████████▉ | 74/83 [24:40<02:52, 19.22s/epoch, loss=1.12, accuracy=0.76, val_loss=2.55, val_accuracy=0.379, lr=0.1]  90%|█████████ | 75/83 [24:59<02:33, 19.16s/epoch, loss=1.13, accuracy=0.759, val_loss=1.99, val_accuracy=0.488, lr=0.1] 92%|█████████▏| 76/83 [25:18<02:13, 19.13s/epoch, loss=1.11, accuracy=0.76, val_loss=2.35, val_accuracy=0.349, lr=0.0316] 93%|█████████▎| 77/83 [25:37<01:54, 19.10s/epoch, loss=1.12, accuracy=0.758, val_loss=2.29, val_accuracy=0.441, lr=0.1]   94%|█████████▍| 78/83 [25:56<01:35, 19.10s/epoch, loss=1.12, accuracy=0.758, val_loss=2.1, val_accuracy=0.528, lr=0.1]  95%|█████████▌| 79/83 [26:16<01:16, 19.09s/epoch, loss=1.12, accuracy=0.758, val_loss=1.74, val_accuracy=0.544, lr=0.1] 96%|█████████▋| 80/83 [26:35<00:57, 19.12s/epoch, loss=1.12, accuracy=0.757, val_loss=1.72, val_accuracy=0.568, lr=0.1] 98%|█████████▊| 81/83 [26:54<00:38, 19.08s/epoch, loss=1.12, accuracy=0.759, val_loss=3.42, val_accuracy=0.392, lr=0.0316] 99%|█████████▉| 82/83 [27:13<00:19, 19.13s/epoch, loss=0.914, accuracy=0.818, val_loss=0.962, val_accuracy=0.783, lr=0.01]100%|██████████| 83/83 [27:32<00:00, 19.05s/epoch, loss=0.735, accuracy=0.851, val_loss=0.801, val_accuracy=0.813, lr=0.01]100%|██████████| 83/83 [27:32<00:00, 19.91s/epoch, loss=0.735, accuracy=0.851, val_loss=0.801, val_accuracy=0.813, lr=0.01]
Using real-time data augmentation.
Test score: 0.8007689714431763
Test accuracy: 0.8133999705314636
