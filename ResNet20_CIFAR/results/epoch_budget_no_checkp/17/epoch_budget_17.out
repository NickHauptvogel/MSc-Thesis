Thu Feb 15 13:57:00 2024       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA TITAN Xp                Off | 00000000:83:00.0 Off |                  N/A |
| 44%   67C    P0             101W / 250W |      0MiB / 12288MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|  No running processes found                                                           |
+---------------------------------------------------------------------------------------+


* * * Run SGD for cluster size = 17. * * *


Budget: 88


* * * Run SGD for ID = 17_1. * * *


2024-02-15 13:57:01.363457: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 13:57:07.072734: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 13:57:07.074326: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-15 13:57:07.112163: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 13:57:07.112213: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 13:57:07.115372: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 13:57:07.115415: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 13:57:07.124084: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 13:57:07.135503: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 13:57:07.154190: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 13:57:07.160014: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 13:57:07.167279: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 13:57:07.167923: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 13:57:07.168040: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 13:57:08.529781: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-15 13:57:08.530355: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 13:57:08.530835: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 13:57:08.530871: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 13:57:08.530907: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 13:57:08.530927: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 13:57:08.530946: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 13:57:08.530966: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 13:57:08.531002: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 13:57:08.531022: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 13:57:08.531041: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 13:57:08.531521: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 13:57:08.531566: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 13:57:09.313372: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-15 13:57:09.313453: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-15 13:57:09.313464: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-15 13:57:09.314763: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': 171, 'batch_size': 128, 'epochs': 88, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/88 [00:00<?, ?epoch/s]2024-02-15 13:57:10.130104: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-15 13:57:10.142813: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199950000 Hz
2024-02-15 13:57:12.298310: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 13:57:12.623847: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 13:57:13.614178: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-15 13:57:13.657262: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/88 [01:01<1:29:52, 61.98s/epoch, loss=3.19, accuracy=0.3, val_loss=2.46, val_accuracy=0.221, lr=0.1]  2%|▏         | 2/88 [01:27<58:05, 40.53s/epoch, loss=1.64, accuracy=0.495, val_loss=1.75, val_accuracy=0.435, lr=0.1]  3%|▎         | 3/88 [01:54<48:45, 34.42s/epoch, loss=1.39, accuracy=0.616, val_loss=2.27, val_accuracy=0.386, lr=0.1]  5%|▍         | 4/88 [02:21<44:11, 31.57s/epoch, loss=1.29, accuracy=0.679, val_loss=3.8, val_accuracy=0.25, lr=0.1]    6%|▌         | 5/88 [02:49<41:31, 30.02s/epoch, loss=1.25, accuracy=0.7, val_loss=2.11, val_accuracy=0.45, lr=0.1]   7%|▋         | 6/88 [03:16<39:52, 29.18s/epoch, loss=1.24, accuracy=0.712, val_loss=1.74, val_accuracy=0.585, lr=0.1]  8%|▊         | 7/88 [03:43<38:17, 28.36s/epoch, loss=1.22, accuracy=0.717, val_loss=1.71, val_accuracy=0.53, lr=0.1]   9%|▉         | 8/88 [04:08<36:14, 27.19s/epoch, loss=1.22, accuracy=0.724, val_loss=2.22, val_accuracy=0.465, lr=0.1] 10%|█         | 9/88 [04:33<35:16, 26.79s/epoch, loss=1.21, accuracy=0.729, val_loss=1.55, val_accuracy=0.631, lr=0.1] 11%|█▏        | 10/88 [05:00<34:40, 26.68s/epoch, loss=1.2, accuracy=0.735, val_loss=1.72, val_accuracy=0.579, lr=0.1] 12%|█▎        | 11/88 [05:28<34:37, 26.98s/epoch, loss=1.2, accuracy=0.733, val_loss=1.77, val_accuracy=0.574, lr=0.1] 14%|█▎        | 12/88 [05:52<33:19, 26.30s/epoch, loss=1.19, accuracy=0.737, val_loss=1.85, val_accuracy=0.52, lr=0.1] 15%|█▍        | 13/88 [06:20<33:20, 26.67s/epoch, loss=1.19, accuracy=0.738, val_loss=2.78, val_accuracy=0.312, lr=0.1] 16%|█▌        | 14/88 [06:47<32:58, 26.74s/epoch, loss=1.19, accuracy=0.74, val_loss=2.42, val_accuracy=0.42, lr=0.0316] 17%|█▋        | 15/88 [07:14<32:38, 26.83s/epoch, loss=1.19, accuracy=0.742, val_loss=2.09, val_accuracy=0.474, lr=0.1]  18%|█▊        | 16/88 [07:40<32:07, 26.78s/epoch, loss=1.18, accuracy=0.744, val_loss=3.45, val_accuracy=0.199, lr=0.1] 19%|█▉        | 17/88 [08:07<31:35, 26.69s/epoch, loss=1.18, accuracy=0.744, val_loss=2.28, val_accuracy=0.504, lr=0.1] 20%|██        | 18/88 [08:34<31:21, 26.89s/epoch, loss=1.18, accuracy=0.745, val_loss=2.38, val_accuracy=0.401, lr=0.1] 22%|██▏       | 19/88 [08:59<30:09, 26.23s/epoch, loss=1.18, accuracy=0.746, val_loss=1.72, val_accuracy=0.559, lr=0.0316] 23%|██▎       | 20/88 [09:26<30:10, 26.62s/epoch, loss=1.17, accuracy=0.747, val_loss=1.62, val_accuracy=0.596, lr=0.1]    24%|██▍       | 21/88 [09:52<29:16, 26.22s/epoch, loss=1.17, accuracy=0.75, val_loss=1.59, val_accuracy=0.587, lr=0.1]  25%|██▌       | 22/88 [10:18<28:56, 26.31s/epoch, loss=1.17, accuracy=0.748, val_loss=2.27, val_accuracy=0.388, lr=0.1] 26%|██▌       | 23/88 [10:46<28:55, 26.70s/epoch, loss=1.17, accuracy=0.749, val_loss=1.61, val_accuracy=0.6, lr=0.1]   27%|██▋       | 24/88 [11:10<27:47, 26.05s/epoch, loss=1.16, accuracy=0.749, val_loss=2.59, val_accuracy=0.468, lr=0.0316] 28%|██▊       | 25/88 [11:37<27:33, 26.25s/epoch, loss=1.16, accuracy=0.752, val_loss=1.4, val_accuracy=0.661, lr=0.1]     30%|██▉       | 26/88 [12:02<26:35, 25.73s/epoch, loss=1.17, accuracy=0.751, val_loss=1.65, val_accuracy=0.621, lr=0.1] 31%|███       | 27/88 [12:26<25:52, 25.46s/epoch, loss=1.16, accuracy=0.749, val_loss=2.42, val_accuracy=0.457, lr=0.1] 32%|███▏      | 28/88 [12:54<25:57, 25.95s/epoch, loss=1.15, accuracy=0.749, val_loss=2.43, val_accuracy=0.405, lr=0.1] 33%|███▎      | 29/88 [13:18<25:11, 25.61s/epoch, loss=1.16, accuracy=0.751, val_loss=1.67, val_accuracy=0.592, lr=0.1] 34%|███▍      | 30/88 [13:44<24:51, 25.71s/epoch, loss=1.16, accuracy=0.751, val_loss=2, val_accuracy=0.507, lr=0.0316] 35%|███▌      | 31/88 [14:12<24:59, 26.30s/epoch, loss=1.15, accuracy=0.754, val_loss=3.01, val_accuracy=0.36, lr=0.1]  36%|███▋      | 32/88 [14:39<24:51, 26.64s/epoch, loss=1.15, accuracy=0.755, val_loss=2.41, val_accuracy=0.45, lr=0.1] 38%|███▊      | 33/88 [15:06<24:22, 26.59s/epoch, loss=1.15, accuracy=0.752, val_loss=1.77, val_accuracy=0.556, lr=0.1] 39%|███▊      | 34/88 [15:33<24:08, 26.83s/epoch, loss=1.15, accuracy=0.753, val_loss=1.8, val_accuracy=0.596, lr=0.1]  40%|███▉      | 35/88 [15:57<22:59, 26.03s/epoch, loss=1.15, accuracy=0.754, val_loss=3.64, val_accuracy=0.357, lr=0.0316] 41%|████      | 36/88 [16:23<22:23, 25.83s/epoch, loss=1.15, accuracy=0.753, val_loss=3.29, val_accuracy=0.277, lr=0.1]    42%|████▏     | 37/88 [16:49<22:02, 25.93s/epoch, loss=1.16, accuracy=0.752, val_loss=2.73, val_accuracy=0.377, lr=0.1] 43%|████▎     | 38/88 [17:16<21:59, 26.38s/epoch, loss=1.15, accuracy=0.753, val_loss=3.25, val_accuracy=0.405, lr=0.1] 44%|████▍     | 39/88 [17:41<21:12, 25.97s/epoch, loss=1.15, accuracy=0.755, val_loss=3.19, val_accuracy=0.374, lr=0.1] 45%|████▌     | 40/88 [18:06<20:31, 25.65s/epoch, loss=1.15, accuracy=0.75, val_loss=1.82, val_accuracy=0.485, lr=0.0316] 47%|████▋     | 41/88 [18:31<19:48, 25.29s/epoch, loss=1.15, accuracy=0.752, val_loss=2.64, val_accuracy=0.421, lr=0.1]   48%|████▊     | 42/88 [18:56<19:28, 25.40s/epoch, loss=1.14, accuracy=0.755, val_loss=2.28, val_accuracy=0.43, lr=0.1]  49%|████▉     | 43/88 [19:21<18:52, 25.17s/epoch, loss=1.14, accuracy=0.756, val_loss=1.45, val_accuracy=0.641, lr=0.1] 50%|█████     | 44/88 [19:46<18:27, 25.17s/epoch, loss=1.15, accuracy=0.754, val_loss=3.64, val_accuracy=0.16, lr=0.1]  51%|█████     | 45/88 [20:12<18:15, 25.48s/epoch, loss=1.14, accuracy=0.754, val_loss=2.41, val_accuracy=0.455, lr=0.0316] 52%|█████▏    | 46/88 [20:39<18:08, 25.93s/epoch, loss=1.14, accuracy=0.757, val_loss=2.28, val_accuracy=0.44, lr=0.1]     53%|█████▎    | 47/88 [21:06<17:55, 26.24s/epoch, loss=1.14, accuracy=0.757, val_loss=2, val_accuracy=0.465, lr=0.1]   55%|█████▍    | 48/88 [21:31<17:06, 25.67s/epoch, loss=1.14, accuracy=0.756, val_loss=1.58, val_accuracy=0.603, lr=0.1] 56%|█████▌    | 49/88 [21:55<16:22, 25.19s/epoch, loss=1.15, accuracy=0.753, val_loss=1.81, val_accuracy=0.539, lr=0.1] 57%|█████▋    | 50/88 [22:20<16:02, 25.34s/epoch, loss=1.14, accuracy=0.754, val_loss=1.41, val_accuracy=0.661, lr=0.0316] 58%|█████▊    | 51/88 [22:45<15:24, 24.99s/epoch, loss=1.14, accuracy=0.757, val_loss=2.29, val_accuracy=0.446, lr=0.1]    59%|█████▉    | 52/88 [23:11<15:15, 25.43s/epoch, loss=1.14, accuracy=0.754, val_loss=3.79, val_accuracy=0.319, lr=0.1] 60%|██████    | 53/88 [23:38<15:09, 25.98s/epoch, loss=1.14, accuracy=0.756, val_loss=2.42, val_accuracy=0.484, lr=0.1] 61%|██████▏   | 54/88 [24:06<14:56, 26.38s/epoch, loss=1.13, accuracy=0.757, val_loss=1.8, val_accuracy=0.552, lr=0.1]  62%|██████▎   | 55/88 [24:30<14:09, 25.74s/epoch, loss=1.13, accuracy=0.758, val_loss=1.48, val_accuracy=0.644, lr=0.0316] 64%|██████▎   | 56/88 [24:57<13:59, 26.24s/epoch, loss=1.13, accuracy=0.756, val_loss=1.98, val_accuracy=0.483, lr=0.1]    65%|██████▍   | 57/88 [25:24<13:42, 26.52s/epoch, loss=1.13, accuracy=0.76, val_loss=2.27, val_accuracy=0.469, lr=0.1]  66%|██████▌   | 58/88 [25:49<13:01, 26.04s/epoch, loss=1.13, accuracy=0.757, val_loss=3.08, val_accuracy=0.288, lr=0.1] 67%|██████▋   | 59/88 [26:14<12:22, 25.61s/epoch, loss=1.14, accuracy=0.756, val_loss=2.45, val_accuracy=0.352, lr=0.1] 68%|██████▊   | 60/88 [26:38<11:43, 25.14s/epoch, loss=1.14, accuracy=0.757, val_loss=2.13, val_accuracy=0.556, lr=0.0316] 69%|██████▉   | 61/88 [27:04<11:23, 25.32s/epoch, loss=1.13, accuracy=0.757, val_loss=3.61, val_accuracy=0.306, lr=0.1]    70%|███████   | 62/88 [27:31<11:13, 25.89s/epoch, loss=1.13, accuracy=0.757, val_loss=1.86, val_accuracy=0.531, lr=0.1] 72%|███████▏  | 63/88 [27:57<10:50, 26.00s/epoch, loss=1.13, accuracy=0.759, val_loss=1.9, val_accuracy=0.574, lr=0.1]  73%|███████▎  | 64/88 [28:24<10:31, 26.33s/epoch, loss=1.13, accuracy=0.756, val_loss=3.08, val_accuracy=0.334, lr=0.1] 74%|███████▍  | 65/88 [28:49<09:53, 25.78s/epoch, loss=1.13, accuracy=0.757, val_loss=1.59, val_accuracy=0.574, lr=0.0316] 75%|███████▌  | 66/88 [29:15<09:26, 25.74s/epoch, loss=1.13, accuracy=0.758, val_loss=3.56, val_accuracy=0.336, lr=0.1]    76%|███████▌  | 67/88 [29:41<09:06, 26.00s/epoch, loss=1.13, accuracy=0.757, val_loss=1.41, val_accuracy=0.654, lr=0.1] 77%|███████▋  | 68/88 [30:05<08:28, 25.45s/epoch, loss=1.13, accuracy=0.757, val_loss=1.78, val_accuracy=0.551, lr=0.1] 78%|███████▊  | 69/88 [30:32<08:10, 25.80s/epoch, loss=1.13, accuracy=0.755, val_loss=2.22, val_accuracy=0.453, lr=0.1] 80%|███████▉  | 70/88 [30:58<07:46, 25.92s/epoch, loss=1.13, accuracy=0.757, val_loss=1.61, val_accuracy=0.579, lr=0.0316] 81%|████████  | 71/88 [31:22<07:10, 25.32s/epoch, loss=1.12, accuracy=0.758, val_loss=2.38, val_accuracy=0.377, lr=0.1]    82%|████████▏ | 72/88 [31:47<06:42, 25.18s/epoch, loss=1.12, accuracy=0.757, val_loss=1.49, val_accuracy=0.65, lr=0.1]  83%|████████▎ | 73/88 [32:11<06:11, 24.76s/epoch, loss=1.13, accuracy=0.756, val_loss=2.94, val_accuracy=0.356, lr=0.1] 84%|████████▍ | 74/88 [32:37<05:51, 25.14s/epoch, loss=1.13, accuracy=0.755, val_loss=1.72, val_accuracy=0.571, lr=0.1] 85%|████████▌ | 75/88 [33:01<05:24, 24.95s/epoch, loss=1.13, accuracy=0.757, val_loss=2.89, val_accuracy=0.426, lr=0.0316] 86%|████████▋ | 76/88 [33:27<05:02, 25.23s/epoch, loss=1.13, accuracy=0.755, val_loss=2.62, val_accuracy=0.368, lr=0.1]    88%|████████▊ | 77/88 [33:52<04:35, 25.02s/epoch, loss=1.13, accuracy=0.757, val_loss=3.53, val_accuracy=0.38, lr=0.1]  89%|████████▊ | 78/88 [34:17<04:12, 25.26s/epoch, loss=1.13, accuracy=0.755, val_loss=2.21, val_accuracy=0.501, lr=0.1] 90%|████████▉ | 79/88 [34:45<03:52, 25.87s/epoch, loss=1.12, accuracy=0.758, val_loss=3.76, val_accuracy=0.311, lr=0.1] 91%|█████████ | 80/88 [35:11<03:27, 25.96s/epoch, loss=1.12, accuracy=0.758, val_loss=1.93, val_accuracy=0.549, lr=0.0316] 92%|█████████▏| 81/88 [35:38<03:04, 26.41s/epoch, loss=1.12, accuracy=0.759, val_loss=2.71, val_accuracy=0.444, lr=0.1]    93%|█████████▎| 82/88 [36:05<02:38, 26.38s/epoch, loss=0.918, accuracy=0.817, val_loss=0.939, val_accuracy=0.796, lr=0.01] 94%|█████████▍| 83/88 [36:32<02:13, 26.69s/epoch, loss=0.732, accuracy=0.85, val_loss=0.903, val_accuracy=0.78, lr=0.01]   95%|█████████▌| 84/88 [36:59<01:47, 26.78s/epoch, loss=0.652, accuracy=0.856, val_loss=0.789, val_accuracy=0.805, lr=0.01] 97%|█████████▋| 85/88 [37:24<01:18, 26.30s/epoch, loss=0.608, accuracy=0.861, val_loss=0.734, val_accuracy=0.817, lr=0.01] 98%|█████████▊| 86/88 [37:50<00:52, 26.03s/epoch, loss=0.59, accuracy=0.86, val_loss=0.891, val_accuracy=0.766, lr=0.01]   99%|█████████▉| 87/88 [38:15<00:25, 25.85s/epoch, loss=0.572, accuracy=0.864, val_loss=0.749, val_accuracy=0.805, lr=0.01]100%|██████████| 88/88 [38:43<00:00, 26.39s/epoch, loss=0.57, accuracy=0.863, val_loss=0.739, val_accuracy=0.814, lr=0.01] 100%|██████████| 88/88 [38:43<00:00, 26.40s/epoch, loss=0.57, accuracy=0.863, val_loss=0.739, val_accuracy=0.814, lr=0.01]
Using real-time data augmentation.
Test loss: 0.7394088506698608
Test accuracy: 0.8137000203132629


* * * Run SGD for ID = 17_2. * * *


2024-02-15 14:35:56.056868: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 14:35:58.584264: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 14:35:58.585491: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-15 14:35:58.627272: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 14:35:58.627315: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 14:35:58.630452: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 14:35:58.630502: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 14:35:58.633040: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 14:35:58.633758: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 14:35:58.636493: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 14:35:58.638112: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 14:35:58.643339: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 14:35:58.643935: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 14:35:58.644237: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 14:36:00.011528: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-15 14:36:00.012105: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 14:36:00.012581: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 14:36:00.012617: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 14:36:00.012653: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 14:36:00.012671: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 14:36:00.012699: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 14:36:00.012718: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 14:36:00.012736: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 14:36:00.012753: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 14:36:00.012771: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 14:36:00.013255: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 14:36:00.013292: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 14:36:00.745651: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-15 14:36:00.745741: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-15 14:36:00.745754: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-15 14:36:00.747131: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': 172, 'batch_size': 128, 'epochs': 88, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/88 [00:00<?, ?epoch/s]2024-02-15 14:36:01.605313: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-15 14:36:01.605999: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199950000 Hz
2024-02-15 14:36:03.923513: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 14:36:04.165192: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 14:36:04.937388: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-15 14:36:04.985576: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/88 [00:58<1:24:18, 58.14s/epoch, loss=3.14, accuracy=0.315, val_loss=2.4, val_accuracy=0.262, lr=0.1]  2%|▏         | 2/88 [01:22<54:42, 38.17s/epoch, loss=1.53, accuracy=0.546, val_loss=1.83, val_accuracy=0.469, lr=0.1]   3%|▎         | 3/88 [01:47<45:38, 32.21s/epoch, loss=1.32, accuracy=0.652, val_loss=2.12, val_accuracy=0.437, lr=0.1]  5%|▍         | 4/88 [02:13<41:55, 29.95s/epoch, loss=1.26, accuracy=0.688, val_loss=1.69, val_accuracy=0.542, lr=0.1]  6%|▌         | 5/88 [02:39<39:23, 28.47s/epoch, loss=1.23, accuracy=0.704, val_loss=1.9, val_accuracy=0.508, lr=0.1]   7%|▋         | 6/88 [03:06<37:55, 27.75s/epoch, loss=1.22, accuracy=0.716, val_loss=1.74, val_accuracy=0.54, lr=0.1]  8%|▊         | 7/88 [03:31<36:13, 26.83s/epoch, loss=1.21, accuracy=0.722, val_loss=3.07, val_accuracy=0.385, lr=0.1]  9%|▉         | 8/88 [03:57<35:25, 26.56s/epoch, loss=1.2, accuracy=0.728, val_loss=1.42, val_accuracy=0.647, lr=0.1]  10%|█         | 9/88 [04:21<34:05, 25.89s/epoch, loss=1.2, accuracy=0.733, val_loss=2.26, val_accuracy=0.389, lr=0.1] 11%|█▏        | 10/88 [04:48<33:55, 26.10s/epoch, loss=1.19, accuracy=0.734, val_loss=1.48, val_accuracy=0.632, lr=0.1] 12%|█▎        | 11/88 [05:12<32:50, 25.59s/epoch, loss=1.19, accuracy=0.734, val_loss=2.19, val_accuracy=0.448, lr=0.1] 14%|█▎        | 12/88 [05:38<32:39, 25.78s/epoch, loss=1.18, accuracy=0.736, val_loss=3.01, val_accuracy=0.392, lr=0.1] 15%|█▍        | 13/88 [06:05<32:26, 25.96s/epoch, loss=1.17, accuracy=0.742, val_loss=1.59, val_accuracy=0.568, lr=0.0316] 16%|█▌        | 14/88 [06:31<32:07, 26.05s/epoch, loss=1.17, accuracy=0.742, val_loss=1.67, val_accuracy=0.561, lr=0.1]    17%|█▋        | 15/88 [06:57<31:47, 26.13s/epoch, loss=1.17, accuracy=0.744, val_loss=1.51, val_accuracy=0.628, lr=0.1] 18%|█▊        | 16/88 [07:24<31:27, 26.21s/epoch, loss=1.16, accuracy=0.747, val_loss=2.71, val_accuracy=0.367, lr=0.1] 19%|█▉        | 17/88 [07:50<30:58, 26.18s/epoch, loss=1.16, accuracy=0.746, val_loss=2.55, val_accuracy=0.389, lr=0.1] 20%|██        | 18/88 [08:16<30:34, 26.21s/epoch, loss=1.17, accuracy=0.747, val_loss=3.31, val_accuracy=0.389, lr=0.0316] 22%|██▏       | 19/88 [08:42<30:07, 26.20s/epoch, loss=1.16, accuracy=0.75, val_loss=1.45, val_accuracy=0.635, lr=0.1]     23%|██▎       | 20/88 [09:08<29:40, 26.19s/epoch, loss=1.15, accuracy=0.75, val_loss=1.56, val_accuracy=0.6, lr=0.1]   24%|██▍       | 21/88 [09:33<28:39, 25.66s/epoch, loss=1.16, accuracy=0.746, val_loss=1.45, val_accuracy=0.646, lr=0.1] 25%|██▌       | 22/88 [09:58<28:14, 25.67s/epoch, loss=1.15, accuracy=0.748, val_loss=2.02, val_accuracy=0.492, lr=0.1] 26%|██▌       | 23/88 [10:25<27:59, 25.84s/epoch, loss=1.16, accuracy=0.747, val_loss=2.26, val_accuracy=0.525, lr=0.0316] 27%|██▋       | 24/88 [10:49<27:01, 25.34s/epoch, loss=1.15, accuracy=0.752, val_loss=2.4, val_accuracy=0.381, lr=0.1]     28%|██▊       | 25/88 [11:13<26:24, 25.15s/epoch, loss=1.15, accuracy=0.749, val_loss=1.75, val_accuracy=0.56, lr=0.1] 30%|██▉       | 26/88 [11:38<25:39, 24.83s/epoch, loss=1.15, accuracy=0.751, val_loss=1.63, val_accuracy=0.559, lr=0.1] 31%|███       | 27/88 [12:03<25:31, 25.10s/epoch, loss=1.14, accuracy=0.752, val_loss=1.71, val_accuracy=0.567, lr=0.1] 32%|███▏      | 28/88 [12:30<25:26, 25.43s/epoch, loss=1.14, accuracy=0.752, val_loss=3.37, val_accuracy=0.355, lr=0.0316] 33%|███▎      | 29/88 [12:53<24:24, 24.81s/epoch, loss=1.14, accuracy=0.752, val_loss=1.54, val_accuracy=0.613, lr=0.1]    34%|███▍      | 30/88 [13:16<23:36, 24.43s/epoch, loss=1.14, accuracy=0.752, val_loss=1.79, val_accuracy=0.578, lr=0.1] 35%|███▌      | 31/88 [13:42<23:25, 24.66s/epoch, loss=1.14, accuracy=0.752, val_loss=1.78, val_accuracy=0.548, lr=0.1] 36%|███▋      | 32/88 [14:07<23:15, 24.91s/epoch, loss=1.14, accuracy=0.752, val_loss=1.75, val_accuracy=0.538, lr=0.1] 38%|███▊      | 33/88 [14:33<23:04, 25.17s/epoch, loss=1.13, accuracy=0.754, val_loss=2.36, val_accuracy=0.395, lr=0.0316] 39%|███▊      | 34/88 [14:58<22:30, 25.01s/epoch, loss=1.13, accuracy=0.752, val_loss=1.7, val_accuracy=0.553, lr=0.1]     40%|███▉      | 35/88 [15:24<22:25, 25.39s/epoch, loss=1.13, accuracy=0.755, val_loss=1.89, val_accuracy=0.507, lr=0.1] 41%|████      | 36/88 [15:50<22:16, 25.70s/epoch, loss=1.14, accuracy=0.754, val_loss=2.67, val_accuracy=0.353, lr=0.1] 42%|████▏     | 37/88 [16:17<22:02, 25.92s/epoch, loss=1.13, accuracy=0.754, val_loss=3.16, val_accuracy=0.424, lr=0.1] 43%|████▎     | 38/88 [16:43<21:41, 26.04s/epoch, loss=1.13, accuracy=0.756, val_loss=1.53, val_accuracy=0.62, lr=0.0316] 44%|████▍     | 39/88 [17:09<21:16, 26.05s/epoch, loss=1.13, accuracy=0.756, val_loss=2.33, val_accuracy=0.454, lr=0.1]   45%|████▌     | 40/88 [17:36<20:59, 26.25s/epoch, loss=1.13, accuracy=0.752, val_loss=1.88, val_accuracy=0.528, lr=0.1] 47%|████▋     | 41/88 [18:02<20:33, 26.24s/epoch, loss=1.13, accuracy=0.757, val_loss=3.14, val_accuracy=0.301, lr=0.1] 48%|████▊     | 42/88 [18:28<20:08, 26.27s/epoch, loss=1.13, accuracy=0.755, val_loss=1.76, val_accuracy=0.593, lr=0.1] 49%|████▉     | 43/88 [18:54<19:29, 26.00s/epoch, loss=1.13, accuracy=0.756, val_loss=1.62, val_accuracy=0.581, lr=0.0316] 50%|█████     | 44/88 [19:19<18:55, 25.81s/epoch, loss=1.13, accuracy=0.756, val_loss=1.99, val_accuracy=0.524, lr=0.1]    51%|█████     | 45/88 [19:45<18:30, 25.83s/epoch, loss=1.13, accuracy=0.757, val_loss=2.39, val_accuracy=0.447, lr=0.1] 52%|█████▏    | 46/88 [20:09<17:47, 25.41s/epoch, loss=1.13, accuracy=0.756, val_loss=1.51, val_accuracy=0.627, lr=0.1] 53%|█████▎    | 47/88 [20:33<16:56, 24.80s/epoch, loss=1.13, accuracy=0.754, val_loss=2.62, val_accuracy=0.486, lr=0.1] 55%|█████▍    | 48/88 [20:56<16:17, 24.45s/epoch, loss=1.13, accuracy=0.756, val_loss=1.83, val_accuracy=0.566, lr=0.0316] 56%|█████▌    | 49/88 [21:22<16:05, 24.75s/epoch, loss=1.13, accuracy=0.756, val_loss=1.79, val_accuracy=0.534, lr=0.1]    57%|█████▋    | 50/88 [21:46<15:34, 24.59s/epoch, loss=1.13, accuracy=0.754, val_loss=1.89, val_accuracy=0.563, lr=0.1] 58%|█████▊    | 51/88 [22:09<14:56, 24.22s/epoch, loss=1.13, accuracy=0.754, val_loss=2.2, val_accuracy=0.486, lr=0.1]  59%|█████▉    | 52/88 [22:33<14:22, 23.96s/epoch, loss=1.13, accuracy=0.754, val_loss=1.99, val_accuracy=0.496, lr=0.1] 60%|██████    | 53/88 [22:58<14:12, 24.36s/epoch, loss=1.13, accuracy=0.757, val_loss=1.95, val_accuracy=0.558, lr=0.0316] 61%|██████▏   | 54/88 [23:23<13:56, 24.62s/epoch, loss=1.13, accuracy=0.756, val_loss=1.89, val_accuracy=0.495, lr=0.1]    62%|██████▎   | 55/88 [23:47<13:23, 24.34s/epoch, loss=1.13, accuracy=0.755, val_loss=3.03, val_accuracy=0.304, lr=0.1] 64%|██████▎   | 56/88 [24:12<13:04, 24.53s/epoch, loss=1.12, accuracy=0.756, val_loss=2.14, val_accuracy=0.507, lr=0.1] 65%|██████▍   | 57/88 [24:37<12:41, 24.56s/epoch, loss=1.13, accuracy=0.754, val_loss=1.65, val_accuracy=0.595, lr=0.1] 66%|██████▌   | 58/88 [25:01<12:15, 24.53s/epoch, loss=1.11, accuracy=0.758, val_loss=2.16, val_accuracy=0.478, lr=0.0316] 67%|██████▋   | 59/88 [25:26<11:54, 24.63s/epoch, loss=1.12, accuracy=0.757, val_loss=1.98, val_accuracy=0.481, lr=0.1]    68%|██████▊   | 60/88 [25:52<11:45, 25.21s/epoch, loss=1.13, accuracy=0.756, val_loss=2.92, val_accuracy=0.347, lr=0.1] 69%|██████▉   | 61/88 [26:18<11:25, 25.38s/epoch, loss=1.13, accuracy=0.755, val_loss=1.74, val_accuracy=0.591, lr=0.1] 70%|███████   | 62/88 [26:45<11:11, 25.81s/epoch, loss=1.12, accuracy=0.758, val_loss=2.86, val_accuracy=0.463, lr=0.1] 72%|███████▏  | 63/88 [27:12<10:51, 26.05s/epoch, loss=1.12, accuracy=0.758, val_loss=4.71, val_accuracy=0.277, lr=0.0316] 73%|███████▎  | 64/88 [27:37<10:20, 25.84s/epoch, loss=1.12, accuracy=0.756, val_loss=2.54, val_accuracy=0.479, lr=0.1]    74%|███████▍  | 65/88 [28:01<09:44, 25.40s/epoch, loss=1.12, accuracy=0.756, val_loss=2.08, val_accuracy=0.446, lr=0.1] 75%|███████▌  | 66/88 [28:27<09:17, 25.35s/epoch, loss=1.12, accuracy=0.759, val_loss=3.47, val_accuracy=0.339, lr=0.1] 76%|███████▌  | 67/88 [28:50<08:40, 24.77s/epoch, loss=1.12, accuracy=0.758, val_loss=1.39, val_accuracy=0.658, lr=0.1] 77%|███████▋  | 68/88 [29:17<08:25, 25.29s/epoch, loss=1.12, accuracy=0.753, val_loss=1.95, val_accuracy=0.552, lr=0.1] 78%|███████▊  | 69/88 [29:41<07:54, 24.99s/epoch, loss=1.12, accuracy=0.755, val_loss=1.85, val_accuracy=0.522, lr=0.1] 80%|███████▉  | 70/88 [30:05<07:26, 24.81s/epoch, loss=1.12, accuracy=0.757, val_loss=1.7, val_accuracy=0.523, lr=0.1]  81%|████████  | 71/88 [30:32<07:11, 25.37s/epoch, loss=1.12, accuracy=0.756, val_loss=1.54, val_accuracy=0.623, lr=0.1] 82%|████████▏ | 72/88 [30:57<06:45, 25.35s/epoch, loss=1.11, accuracy=0.757, val_loss=1.5, val_accuracy=0.612, lr=0.0316] 83%|████████▎ | 73/88 [31:24<06:26, 25.78s/epoch, loss=1.11, accuracy=0.757, val_loss=1.75, val_accuracy=0.532, lr=0.1]   84%|████████▍ | 74/88 [31:51<06:05, 26.09s/epoch, loss=1.12, accuracy=0.757, val_loss=2.11, val_accuracy=0.416, lr=0.1] 85%|████████▌ | 75/88 [32:18<05:42, 26.37s/epoch, loss=1.12, accuracy=0.756, val_loss=1.46, val_accuracy=0.632, lr=0.1] 86%|████████▋ | 76/88 [32:44<05:14, 26.24s/epoch, loss=1.12, accuracy=0.759, val_loss=2.08, val_accuracy=0.474, lr=0.1] 88%|████████▊ | 77/88 [33:10<04:48, 26.19s/epoch, loss=1.12, accuracy=0.757, val_loss=1.81, val_accuracy=0.521, lr=0.0316] 89%|████████▊ | 78/88 [33:35<04:19, 25.98s/epoch, loss=1.12, accuracy=0.757, val_loss=2.07, val_accuracy=0.548, lr=0.1]    90%|████████▉ | 79/88 [34:01<03:52, 25.78s/epoch, loss=1.11, accuracy=0.759, val_loss=1.96, val_accuracy=0.456, lr=0.1] 91%|█████████ | 80/88 [34:27<03:27, 25.96s/epoch, loss=1.11, accuracy=0.759, val_loss=2.58, val_accuracy=0.406, lr=0.1] 92%|█████████▏| 81/88 [34:53<03:01, 25.96s/epoch, loss=1.12, accuracy=0.756, val_loss=3.39, val_accuracy=0.289, lr=0.1] 93%|█████████▎| 82/88 [35:19<02:34, 25.83s/epoch, loss=0.918, accuracy=0.815, val_loss=0.981, val_accuracy=0.778, lr=0.01] 94%|█████████▍| 83/88 [35:43<02:07, 25.44s/epoch, loss=0.733, accuracy=0.848, val_loss=0.932, val_accuracy=0.762, lr=0.01] 95%|█████████▌| 84/88 [36:08<01:41, 25.40s/epoch, loss=0.651, accuracy=0.856, val_loss=0.766, val_accuracy=0.812, lr=0.01] 97%|█████████▋| 85/88 [36:35<01:16, 25.64s/epoch, loss=0.609, accuracy=0.858, val_loss=0.685, val_accuracy=0.831, lr=0.01] 98%|█████████▊| 86/88 [37:01<00:51, 25.78s/epoch, loss=0.585, accuracy=0.862, val_loss=0.702, val_accuracy=0.817, lr=0.01] 99%|█████████▉| 87/88 [37:25<00:25, 25.36s/epoch, loss=0.571, accuracy=0.864, val_loss=0.767, val_accuracy=0.795, lr=0.01]100%|██████████| 88/88 [37:52<00:00, 25.72s/epoch, loss=0.568, accuracy=0.863, val_loss=0.906, val_accuracy=0.754, lr=0.01]100%|██████████| 88/88 [37:52<00:00, 25.82s/epoch, loss=0.568, accuracy=0.863, val_loss=0.906, val_accuracy=0.754, lr=0.01]
Using real-time data augmentation.
Test loss: 0.9063400626182556
Test accuracy: 0.7540000081062317


* * * Run SGD for ID = 17_3. * * *


2024-02-15 15:13:56.647209: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 15:13:59.561906: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 15:13:59.563236: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-15 15:13:59.603539: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 15:13:59.603579: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 15:13:59.606580: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 15:13:59.606629: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 15:13:59.609093: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 15:13:59.609845: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 15:13:59.612401: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 15:13:59.614026: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 15:13:59.619080: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 15:13:59.619626: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 15:13:59.619734: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 15:14:00.971138: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-15 15:14:00.971733: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 15:14:00.972207: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 15:14:00.972241: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 15:14:00.972278: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 15:14:00.972298: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 15:14:00.972316: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 15:14:00.972334: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 15:14:00.972352: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 15:14:00.972370: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 15:14:00.972389: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 15:14:00.972884: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 15:14:00.972922: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 15:14:01.708205: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-15 15:14:01.708271: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-15 15:14:01.708282: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-15 15:14:01.709711: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': 173, 'batch_size': 128, 'epochs': 88, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/88 [00:00<?, ?epoch/s]2024-02-15 15:14:02.573829: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-15 15:14:02.585829: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199950000 Hz
2024-02-15 15:14:04.960804: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 15:14:05.226775: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 15:14:06.058471: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-15 15:14:06.122670: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/88 [01:07<1:37:18, 67.11s/epoch, loss=3.45, accuracy=0.313, val_loss=3.11, val_accuracy=0.226, lr=0.1]  2%|▏         | 2/88 [01:30<59:29, 41.50s/epoch, loss=1.57, accuracy=0.54, val_loss=2.22, val_accuracy=0.362, lr=0.1]     3%|▎         | 3/88 [01:56<48:58, 34.57s/epoch, loss=1.36, accuracy=0.634, val_loss=3.53, val_accuracy=0.214, lr=0.1]  5%|▍         | 4/88 [02:22<43:29, 31.06s/epoch, loss=1.3, accuracy=0.674, val_loss=1.93, val_accuracy=0.515, lr=0.1]   6%|▌         | 5/88 [02:46<39:07, 28.28s/epoch, loss=1.27, accuracy=0.695, val_loss=1.92, val_accuracy=0.454, lr=0.1]  7%|▋         | 6/88 [03:10<36:53, 26.99s/epoch, loss=1.25, accuracy=0.707, val_loss=2.25, val_accuracy=0.407, lr=0.1]  8%|▊         | 7/88 [03:33<34:40, 25.69s/epoch, loss=1.23, accuracy=0.713, val_loss=1.61, val_accuracy=0.591, lr=0.1]  9%|▉         | 8/88 [03:56<33:08, 24.86s/epoch, loss=1.22, accuracy=0.719, val_loss=1.37, val_accuracy=0.664, lr=0.1] 10%|█         | 9/88 [04:20<32:21, 24.58s/epoch, loss=1.21, accuracy=0.724, val_loss=2.11, val_accuracy=0.47, lr=0.1]  11%|█▏        | 10/88 [04:45<32:04, 24.67s/epoch, loss=1.21, accuracy=0.729, val_loss=1.81, val_accuracy=0.566, lr=0.1] 12%|█▎        | 11/88 [05:08<31:07, 24.25s/epoch, loss=1.2, accuracy=0.732, val_loss=1.94, val_accuracy=0.528, lr=0.1]  14%|█▎        | 12/88 [05:32<30:36, 24.17s/epoch, loss=1.2, accuracy=0.732, val_loss=2.56, val_accuracy=0.408, lr=0.1] 15%|█▍        | 13/88 [05:59<31:01, 24.82s/epoch, loss=1.2, accuracy=0.736, val_loss=1.67, val_accuracy=0.559, lr=0.0316] 16%|█▌        | 14/88 [06:23<30:33, 24.78s/epoch, loss=1.19, accuracy=0.737, val_loss=2.44, val_accuracy=0.418, lr=0.1]   17%|█▋        | 15/88 [06:49<30:30, 25.08s/epoch, loss=1.19, accuracy=0.736, val_loss=2.47, val_accuracy=0.345, lr=0.1] 18%|█▊        | 16/88 [07:13<29:50, 24.87s/epoch, loss=1.19, accuracy=0.737, val_loss=1.79, val_accuracy=0.578, lr=0.1] 19%|█▉        | 17/88 [07:37<29:05, 24.58s/epoch, loss=1.18, accuracy=0.739, val_loss=1.82, val_accuracy=0.513, lr=0.1] 20%|██        | 18/88 [08:03<29:07, 24.96s/epoch, loss=1.19, accuracy=0.739, val_loss=1.38, val_accuracy=0.68, lr=0.0316] 22%|██▏       | 19/88 [08:27<28:13, 24.55s/epoch, loss=1.17, accuracy=0.741, val_loss=2.33, val_accuracy=0.442, lr=0.1]   23%|██▎       | 20/88 [08:50<27:24, 24.19s/epoch, loss=1.17, accuracy=0.746, val_loss=1.47, val_accuracy=0.658, lr=0.1] 24%|██▍       | 21/88 [09:14<26:59, 24.17s/epoch, loss=1.17, accuracy=0.745, val_loss=1.78, val_accuracy=0.542, lr=0.1] 25%|██▌       | 22/88 [09:40<26:57, 24.51s/epoch, loss=1.18, accuracy=0.744, val_loss=2, val_accuracy=0.535, lr=0.1]    26%|██▌       | 23/88 [10:05<26:57, 24.88s/epoch, loss=1.17, accuracy=0.745, val_loss=1.74, val_accuracy=0.561, lr=0.0316] 27%|██▋       | 24/88 [10:31<26:54, 25.22s/epoch, loss=1.17, accuracy=0.749, val_loss=2.21, val_accuracy=0.466, lr=0.1]    28%|██▊       | 25/88 [10:55<26:06, 24.87s/epoch, loss=1.17, accuracy=0.744, val_loss=2.58, val_accuracy=0.5, lr=0.1]   30%|██▉       | 26/88 [11:20<25:31, 24.71s/epoch, loss=1.17, accuracy=0.747, val_loss=1.9, val_accuracy=0.519, lr=0.1] 31%|███       | 27/88 [11:46<25:29, 25.08s/epoch, loss=1.16, accuracy=0.749, val_loss=3.2, val_accuracy=0.421, lr=0.1] 32%|███▏      | 28/88 [12:10<25:00, 25.01s/epoch, loss=1.16, accuracy=0.75, val_loss=1.8, val_accuracy=0.531, lr=0.0316] 33%|███▎      | 29/88 [12:35<24:25, 24.84s/epoch, loss=1.17, accuracy=0.75, val_loss=2.02, val_accuracy=0.51, lr=0.1]    34%|███▍      | 30/88 [13:00<23:56, 24.77s/epoch, loss=1.16, accuracy=0.752, val_loss=2.42, val_accuracy=0.416, lr=0.1] 35%|███▌      | 31/88 [13:25<23:47, 25.05s/epoch, loss=1.16, accuracy=0.75, val_loss=1.89, val_accuracy=0.547, lr=0.1]  36%|███▋      | 32/88 [13:51<23:42, 25.39s/epoch, loss=1.16, accuracy=0.751, val_loss=2.06, val_accuracy=0.445, lr=0.1] 38%|███▊      | 33/88 [14:16<23:06, 25.21s/epoch, loss=1.17, accuracy=0.75, val_loss=2.64, val_accuracy=0.368, lr=0.0316] 39%|███▊      | 34/88 [14:42<22:56, 25.49s/epoch, loss=1.16, accuracy=0.75, val_loss=2.36, val_accuracy=0.458, lr=0.1]    40%|███▉      | 35/88 [15:05<21:50, 24.73s/epoch, loss=1.16, accuracy=0.751, val_loss=1.9, val_accuracy=0.489, lr=0.1] 41%|████      | 36/88 [15:31<21:43, 25.06s/epoch, loss=1.16, accuracy=0.751, val_loss=1.59, val_accuracy=0.608, lr=0.1] 42%|████▏     | 37/88 [15:57<21:32, 25.35s/epoch, loss=1.15, accuracy=0.752, val_loss=1.65, val_accuracy=0.597, lr=0.1] 43%|████▎     | 38/88 [16:20<20:31, 24.63s/epoch, loss=1.16, accuracy=0.751, val_loss=2.29, val_accuracy=0.379, lr=0.0316] 44%|████▍     | 39/88 [16:45<20:11, 24.73s/epoch, loss=1.16, accuracy=0.751, val_loss=2.01, val_accuracy=0.466, lr=0.1]    45%|████▌     | 40/88 [17:08<19:21, 24.19s/epoch, loss=1.16, accuracy=0.749, val_loss=3.38, val_accuracy=0.245, lr=0.1] 47%|████▋     | 41/88 [17:33<19:07, 24.42s/epoch, loss=1.15, accuracy=0.752, val_loss=2.31, val_accuracy=0.459, lr=0.1] 48%|████▊     | 42/88 [17:56<18:22, 23.96s/epoch, loss=1.15, accuracy=0.752, val_loss=3.31, val_accuracy=0.358, lr=0.1] 49%|████▉     | 43/88 [18:22<18:26, 24.58s/epoch, loss=1.15, accuracy=0.753, val_loss=1.96, val_accuracy=0.452, lr=0.0316] 50%|█████     | 44/88 [18:48<18:24, 25.11s/epoch, loss=1.15, accuracy=0.751, val_loss=2.05, val_accuracy=0.53, lr=0.1]     51%|█████     | 45/88 [19:14<18:10, 25.36s/epoch, loss=1.14, accuracy=0.754, val_loss=2.63, val_accuracy=0.402, lr=0.1] 52%|█████▏    | 46/88 [19:40<17:57, 25.64s/epoch, loss=1.14, accuracy=0.752, val_loss=1.86, val_accuracy=0.521, lr=0.1] 53%|█████▎    | 47/88 [20:05<17:21, 25.40s/epoch, loss=1.14, accuracy=0.752, val_loss=1.59, val_accuracy=0.604, lr=0.1] 55%|█████▍    | 48/88 [20:31<16:57, 25.44s/epoch, loss=1.14, accuracy=0.751, val_loss=2.78, val_accuracy=0.392, lr=0.0316] 56%|█████▌    | 49/88 [20:56<16:23, 25.22s/epoch, loss=1.14, accuracy=0.751, val_loss=2.44, val_accuracy=0.441, lr=0.1]    57%|█████▋    | 50/88 [21:21<16:05, 25.42s/epoch, loss=1.14, accuracy=0.753, val_loss=2.19, val_accuracy=0.458, lr=0.1] 58%|█████▊    | 51/88 [21:47<15:39, 25.38s/epoch, loss=1.14, accuracy=0.753, val_loss=2.19, val_accuracy=0.452, lr=0.1] 59%|█████▉    | 52/88 [22:13<15:24, 25.68s/epoch, loss=1.15, accuracy=0.75, val_loss=1.71, val_accuracy=0.59, lr=0.1]   60%|██████    | 53/88 [22:39<15:00, 25.72s/epoch, loss=1.14, accuracy=0.753, val_loss=3.83, val_accuracy=0.234, lr=0.0316] 61%|██████▏   | 54/88 [23:05<14:35, 25.74s/epoch, loss=1.14, accuracy=0.752, val_loss=3.83, val_accuracy=0.345, lr=0.1]    62%|██████▎   | 55/88 [23:30<14:07, 25.69s/epoch, loss=1.14, accuracy=0.755, val_loss=2.53, val_accuracy=0.498, lr=0.1] 64%|██████▎   | 56/88 [23:56<13:40, 25.64s/epoch, loss=1.14, accuracy=0.753, val_loss=1.74, val_accuracy=0.553, lr=0.1] 65%|██████▍   | 57/88 [24:21<13:08, 25.43s/epoch, loss=1.13, accuracy=0.754, val_loss=1.53, val_accuracy=0.62, lr=0.1]  66%|██████▌   | 58/88 [24:45<12:30, 25.01s/epoch, loss=1.14, accuracy=0.753, val_loss=1.58, val_accuracy=0.588, lr=0.0316] 67%|██████▋   | 59/88 [25:09<11:58, 24.77s/epoch, loss=1.14, accuracy=0.753, val_loss=1.58, val_accuracy=0.603, lr=0.1]    68%|██████▊   | 60/88 [25:34<11:36, 24.87s/epoch, loss=1.13, accuracy=0.756, val_loss=3.16, val_accuracy=0.401, lr=0.1] 69%|██████▉   | 61/88 [25:59<11:09, 24.80s/epoch, loss=1.13, accuracy=0.755, val_loss=2.33, val_accuracy=0.506, lr=0.1] 70%|███████   | 62/88 [26:23<10:37, 24.51s/epoch, loss=1.14, accuracy=0.754, val_loss=2.54, val_accuracy=0.469, lr=0.1] 72%|███████▏  | 63/88 [26:47<10:10, 24.42s/epoch, loss=1.13, accuracy=0.756, val_loss=1.48, val_accuracy=0.633, lr=0.0316] 73%|███████▎  | 64/88 [27:12<09:52, 24.69s/epoch, loss=1.13, accuracy=0.759, val_loss=1.9, val_accuracy=0.496, lr=0.1]     74%|███████▍  | 65/88 [27:37<09:31, 24.86s/epoch, loss=1.14, accuracy=0.755, val_loss=1.84, val_accuracy=0.507, lr=0.1] 75%|███████▌  | 66/88 [28:00<08:53, 24.26s/epoch, loss=1.14, accuracy=0.756, val_loss=1.62, val_accuracy=0.583, lr=0.1] 76%|███████▌  | 67/88 [28:25<08:32, 24.43s/epoch, loss=1.14, accuracy=0.756, val_loss=1.77, val_accuracy=0.548, lr=0.1] 77%|███████▋  | 68/88 [28:50<08:09, 24.47s/epoch, loss=1.13, accuracy=0.756, val_loss=3.5, val_accuracy=0.338, lr=0.0316] 78%|███████▊  | 69/88 [29:13<07:41, 24.28s/epoch, loss=1.14, accuracy=0.755, val_loss=1.8, val_accuracy=0.539, lr=0.1]    80%|███████▉  | 70/88 [29:37<07:11, 23.96s/epoch, loss=1.14, accuracy=0.755, val_loss=2.49, val_accuracy=0.421, lr=0.1] 81%|████████  | 71/88 [30:01<06:51, 24.18s/epoch, loss=1.13, accuracy=0.754, val_loss=2.34, val_accuracy=0.487, lr=0.1] 82%|████████▏ | 72/88 [30:27<06:33, 24.62s/epoch, loss=1.13, accuracy=0.758, val_loss=3.16, val_accuracy=0.329, lr=0.1] 83%|████████▎ | 73/88 [30:53<06:15, 25.01s/epoch, loss=1.14, accuracy=0.754, val_loss=2.14, val_accuracy=0.455, lr=0.0316] 84%|████████▍ | 74/88 [31:19<05:56, 25.47s/epoch, loss=1.13, accuracy=0.757, val_loss=2.93, val_accuracy=0.344, lr=0.1]    85%|████████▌ | 75/88 [31:45<05:31, 25.48s/epoch, loss=1.13, accuracy=0.755, val_loss=1.69, val_accuracy=0.566, lr=0.1] 86%|████████▋ | 76/88 [32:11<05:08, 25.67s/epoch, loss=1.13, accuracy=0.755, val_loss=1.98, val_accuracy=0.506, lr=0.1] 88%|████████▊ | 77/88 [32:34<04:33, 24.86s/epoch, loss=1.13, accuracy=0.753, val_loss=1.81, val_accuracy=0.535, lr=0.1] 89%|████████▊ | 78/88 [33:00<04:11, 25.14s/epoch, loss=1.13, accuracy=0.757, val_loss=2, val_accuracy=0.485, lr=0.0316] 90%|████████▉ | 79/88 [33:24<03:44, 24.90s/epoch, loss=1.13, accuracy=0.757, val_loss=1.99, val_accuracy=0.503, lr=0.1] 91%|█████████ | 80/88 [33:48<03:16, 24.55s/epoch, loss=1.13, accuracy=0.755, val_loss=2.19, val_accuracy=0.488, lr=0.1] 92%|█████████▏| 81/88 [34:13<02:52, 24.65s/epoch, loss=1.13, accuracy=0.756, val_loss=2.07, val_accuracy=0.497, lr=0.1] 93%|█████████▎| 82/88 [34:39<02:30, 25.11s/epoch, loss=0.912, accuracy=0.815, val_loss=0.895, val_accuracy=0.804, lr=0.01] 94%|█████████▍| 83/88 [35:05<02:06, 25.34s/epoch, loss=0.73, accuracy=0.847, val_loss=0.799, val_accuracy=0.817, lr=0.01]  95%|█████████▌| 84/88 [35:30<01:40, 25.21s/epoch, loss=0.648, accuracy=0.857, val_loss=0.809, val_accuracy=0.795, lr=0.01] 97%|█████████▋| 85/88 [35:55<01:15, 25.28s/epoch, loss=0.607, accuracy=0.86, val_loss=0.813, val_accuracy=0.789, lr=0.01]  98%|█████████▊| 86/88 [36:20<00:50, 25.06s/epoch, loss=0.588, accuracy=0.86, val_loss=0.958, val_accuracy=0.748, lr=0.01] 99%|█████████▉| 87/88 [36:46<00:25, 25.40s/epoch, loss=0.579, accuracy=0.861, val_loss=0.777, val_accuracy=0.798, lr=0.01]100%|██████████| 88/88 [37:12<00:00, 25.63s/epoch, loss=0.568, accuracy=0.864, val_loss=0.729, val_accuracy=0.809, lr=0.01]100%|██████████| 88/88 [37:12<00:00, 25.37s/epoch, loss=0.568, accuracy=0.864, val_loss=0.729, val_accuracy=0.809, lr=0.01]
Using real-time data augmentation.
Test loss: 0.729408860206604
Test accuracy: 0.8093000054359436


* * * Run SGD for ID = 17_4. * * *


2024-02-15 15:51:17.984079: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 15:51:20.993897: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 15:51:20.995113: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-15 15:51:21.035501: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 15:51:21.035551: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 15:51:21.038431: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 15:51:21.038478: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 15:51:21.040673: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 15:51:21.041423: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 15:51:21.043891: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 15:51:21.045382: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 15:51:21.049987: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 15:51:21.050573: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 15:51:21.050664: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 15:51:22.384089: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-15 15:51:22.385110: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 15:51:22.385582: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 15:51:22.385618: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 15:51:22.385656: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 15:51:22.385676: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 15:51:22.385713: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 15:51:22.385733: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 15:51:22.385752: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 15:51:22.385771: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 15:51:22.385790: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 15:51:22.386266: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 15:51:22.386305: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 15:51:23.083154: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-15 15:51:23.083236: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-15 15:51:23.083255: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-15 15:51:23.084664: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': 174, 'batch_size': 128, 'epochs': 88, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/88 [00:00<?, ?epoch/s]2024-02-15 15:51:23.945218: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-15 15:51:23.957842: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199950000 Hz
2024-02-15 15:51:26.333883: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 15:51:26.593468: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 15:51:27.354912: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-15 15:51:27.402958: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/88 [00:58<1:24:46, 58.47s/epoch, loss=3.17, accuracy=0.335, val_loss=2.67, val_accuracy=0.195, lr=0.1]  2%|▏         | 2/88 [01:22<54:41, 38.16s/epoch, loss=1.58, accuracy=0.535, val_loss=2.72, val_accuracy=0.314, lr=0.1]    3%|▎         | 3/88 [01:45<44:34, 31.46s/epoch, loss=1.41, accuracy=0.62, val_loss=1.87, val_accuracy=0.48, lr=0.1]    5%|▍         | 4/88 [02:10<40:17, 28.78s/epoch, loss=1.33, accuracy=0.668, val_loss=2.12, val_accuracy=0.467, lr=0.1]  6%|▌         | 5/88 [02:36<38:31, 27.85s/epoch, loss=1.28, accuracy=0.696, val_loss=1.75, val_accuracy=0.57, lr=0.1]   7%|▋         | 6/88 [03:00<36:22, 26.62s/epoch, loss=1.26, accuracy=0.708, val_loss=1.65, val_accuracy=0.594, lr=0.1]  8%|▊         | 7/88 [03:24<34:31, 25.57s/epoch, loss=1.24, accuracy=0.716, val_loss=1.88, val_accuracy=0.489, lr=0.1]  9%|▉         | 8/88 [03:48<33:16, 24.96s/epoch, loss=1.23, accuracy=0.722, val_loss=1.37, val_accuracy=0.677, lr=0.1] 10%|█         | 9/88 [04:13<33:05, 25.14s/epoch, loss=1.21, accuracy=0.729, val_loss=1.51, val_accuracy=0.626, lr=0.1] 11%|█▏        | 10/88 [04:37<32:12, 24.78s/epoch, loss=1.21, accuracy=0.731, val_loss=1.6, val_accuracy=0.612, lr=0.1] 12%|█▎        | 11/88 [05:03<32:12, 25.09s/epoch, loss=1.21, accuracy=0.734, val_loss=1.69, val_accuracy=0.577, lr=0.1] 14%|█▎        | 12/88 [05:27<31:31, 24.89s/epoch, loss=1.2, accuracy=0.737, val_loss=1.92, val_accuracy=0.539, lr=0.1]  15%|█▍        | 13/88 [05:53<31:21, 25.08s/epoch, loss=1.19, accuracy=0.74, val_loss=2.67, val_accuracy=0.389, lr=0.0316] 16%|█▌        | 14/88 [06:19<31:19, 25.40s/epoch, loss=1.19, accuracy=0.738, val_loss=1.62, val_accuracy=0.61, lr=0.1]    17%|█▋        | 15/88 [06:45<31:08, 25.60s/epoch, loss=1.19, accuracy=0.742, val_loss=1.44, val_accuracy=0.668, lr=0.1] 18%|█▊        | 16/88 [07:10<30:34, 25.47s/epoch, loss=1.18, accuracy=0.741, val_loss=1.86, val_accuracy=0.576, lr=0.1] 19%|█▉        | 17/88 [07:37<30:26, 25.73s/epoch, loss=1.18, accuracy=0.743, val_loss=3.09, val_accuracy=0.42, lr=0.1]  20%|██        | 18/88 [08:01<29:44, 25.50s/epoch, loss=1.17, accuracy=0.747, val_loss=2.3, val_accuracy=0.4, lr=0.0316] 22%|██▏       | 19/88 [08:25<28:44, 24.99s/epoch, loss=1.18, accuracy=0.743, val_loss=2.42, val_accuracy=0.456, lr=0.1] 23%|██▎       | 20/88 [08:52<28:56, 25.54s/epoch, loss=1.17, accuracy=0.744, val_loss=1.66, val_accuracy=0.582, lr=0.1] 24%|██▍       | 21/88 [09:18<28:41, 25.70s/epoch, loss=1.17, accuracy=0.745, val_loss=2.75, val_accuracy=0.38, lr=0.1]  25%|██▌       | 22/88 [09:43<27:56, 25.39s/epoch, loss=1.16, accuracy=0.748, val_loss=1.98, val_accuracy=0.531, lr=0.1] 26%|██▌       | 23/88 [10:10<27:56, 25.79s/epoch, loss=1.16, accuracy=0.75, val_loss=1.91, val_accuracy=0.505, lr=0.0316] 27%|██▋       | 24/88 [10:34<27:10, 25.47s/epoch, loss=1.17, accuracy=0.748, val_loss=1.92, val_accuracy=0.531, lr=0.1]   28%|██▊       | 25/88 [10:58<26:12, 24.96s/epoch, loss=1.16, accuracy=0.746, val_loss=3.23, val_accuracy=0.357, lr=0.1] 30%|██▉       | 26/88 [11:22<25:23, 24.58s/epoch, loss=1.15, accuracy=0.75, val_loss=1.96, val_accuracy=0.52, lr=0.1]   31%|███       | 27/88 [11:46<24:56, 24.52s/epoch, loss=1.16, accuracy=0.75, val_loss=1.44, val_accuracy=0.638, lr=0.1] 32%|███▏      | 28/88 [12:13<25:06, 25.10s/epoch, loss=1.15, accuracy=0.749, val_loss=1.58, val_accuracy=0.635, lr=0.0316] 33%|███▎      | 29/88 [12:38<24:43, 25.14s/epoch, loss=1.16, accuracy=0.749, val_loss=2.99, val_accuracy=0.288, lr=0.1]    34%|███▍      | 30/88 [13:02<23:54, 24.73s/epoch, loss=1.15, accuracy=0.746, val_loss=1.98, val_accuracy=0.487, lr=0.1] 35%|███▌      | 31/88 [13:25<23:13, 24.45s/epoch, loss=1.15, accuracy=0.751, val_loss=2.26, val_accuracy=0.363, lr=0.1] 36%|███▋      | 32/88 [13:49<22:33, 24.17s/epoch, loss=1.16, accuracy=0.752, val_loss=2.21, val_accuracy=0.449, lr=0.1] 38%|███▊      | 33/88 [14:13<22:03, 24.06s/epoch, loss=1.14, accuracy=0.749, val_loss=2.3, val_accuracy=0.384, lr=0.0316] 39%|███▊      | 34/88 [14:38<21:56, 24.38s/epoch, loss=1.15, accuracy=0.751, val_loss=1.83, val_accuracy=0.501, lr=0.1]   40%|███▉      | 35/88 [15:02<21:31, 24.37s/epoch, loss=1.14, accuracy=0.755, val_loss=3.09, val_accuracy=0.323, lr=0.1] 41%|████      | 36/88 [15:26<20:59, 24.21s/epoch, loss=1.15, accuracy=0.753, val_loss=2.03, val_accuracy=0.519, lr=0.1] 42%|████▏     | 37/88 [15:50<20:32, 24.16s/epoch, loss=1.15, accuracy=0.754, val_loss=1.7, val_accuracy=0.542, lr=0.1]  43%|████▎     | 38/88 [16:16<20:35, 24.70s/epoch, loss=1.15, accuracy=0.752, val_loss=3.45, val_accuracy=0.311, lr=0.0316] 44%|████▍     | 39/88 [16:42<20:25, 25.02s/epoch, loss=1.14, accuracy=0.751, val_loss=1.78, val_accuracy=0.547, lr=0.1]    45%|████▌     | 40/88 [17:09<20:30, 25.63s/epoch, loss=1.14, accuracy=0.753, val_loss=1.92, val_accuracy=0.473, lr=0.1] 47%|████▋     | 41/88 [17:32<19:35, 25.01s/epoch, loss=1.14, accuracy=0.753, val_loss=2.78, val_accuracy=0.384, lr=0.1] 48%|████▊     | 42/88 [17:58<19:17, 25.15s/epoch, loss=1.14, accuracy=0.753, val_loss=1.53, val_accuracy=0.632, lr=0.1] 49%|████▉     | 43/88 [18:21<18:29, 24.65s/epoch, loss=1.14, accuracy=0.754, val_loss=3.05, val_accuracy=0.405, lr=0.0316] 50%|█████     | 44/88 [18:45<17:50, 24.32s/epoch, loss=1.15, accuracy=0.752, val_loss=1.86, val_accuracy=0.536, lr=0.1]    51%|█████     | 45/88 [19:09<17:17, 24.12s/epoch, loss=1.14, accuracy=0.755, val_loss=2.03, val_accuracy=0.482, lr=0.1] 52%|█████▏    | 46/88 [19:34<17:06, 24.44s/epoch, loss=1.14, accuracy=0.755, val_loss=2.22, val_accuracy=0.497, lr=0.1] 53%|█████▎    | 47/88 [19:59<16:47, 24.58s/epoch, loss=1.14, accuracy=0.755, val_loss=2.86, val_accuracy=0.31, lr=0.1]  55%|█████▍    | 48/88 [20:25<16:41, 25.03s/epoch, loss=1.14, accuracy=0.754, val_loss=3.45, val_accuracy=0.367, lr=0.0316] 56%|█████▌    | 49/88 [20:50<16:20, 25.14s/epoch, loss=1.13, accuracy=0.755, val_loss=2.06, val_accuracy=0.433, lr=0.1]    57%|█████▋    | 50/88 [21:14<15:38, 24.69s/epoch, loss=1.14, accuracy=0.754, val_loss=3.34, val_accuracy=0.33, lr=0.1]  58%|█████▊    | 51/88 [21:38<15:10, 24.62s/epoch, loss=1.13, accuracy=0.755, val_loss=1.63, val_accuracy=0.605, lr=0.1] 59%|█████▉    | 52/88 [22:04<14:56, 24.91s/epoch, loss=1.13, accuracy=0.756, val_loss=2.4, val_accuracy=0.426, lr=0.1]  60%|██████    | 53/88 [22:28<14:23, 24.67s/epoch, loss=1.14, accuracy=0.753, val_loss=1.96, val_accuracy=0.545, lr=0.0316] 61%|██████▏   | 54/88 [22:55<14:20, 25.30s/epoch, loss=1.13, accuracy=0.756, val_loss=2.08, val_accuracy=0.524, lr=0.1]    62%|██████▎   | 55/88 [23:21<14:00, 25.46s/epoch, loss=1.13, accuracy=0.755, val_loss=2.57, val_accuracy=0.402, lr=0.1] 64%|██████▎   | 56/88 [23:47<13:43, 25.73s/epoch, loss=1.13, accuracy=0.756, val_loss=1.88, val_accuracy=0.532, lr=0.1] 65%|██████▍   | 57/88 [24:11<12:57, 25.08s/epoch, loss=1.13, accuracy=0.753, val_loss=1.96, val_accuracy=0.467, lr=0.1] 66%|██████▌   | 58/88 [24:35<12:27, 24.93s/epoch, loss=1.13, accuracy=0.757, val_loss=2.13, val_accuracy=0.439, lr=0.0316] 67%|██████▋   | 59/88 [25:01<12:15, 25.36s/epoch, loss=1.13, accuracy=0.757, val_loss=2.93, val_accuracy=0.352, lr=0.1]    68%|██████▊   | 60/88 [25:26<11:39, 25.00s/epoch, loss=1.13, accuracy=0.756, val_loss=1.7, val_accuracy=0.546, lr=0.1]  69%|██████▉   | 61/88 [25:50<11:11, 24.89s/epoch, loss=1.12, accuracy=0.754, val_loss=1.72, val_accuracy=0.591, lr=0.1] 70%|███████   | 62/88 [26:15<10:45, 24.84s/epoch, loss=1.13, accuracy=0.755, val_loss=2.81, val_accuracy=0.3, lr=0.1]   72%|███████▏  | 63/88 [26:39<10:11, 24.46s/epoch, loss=1.13, accuracy=0.757, val_loss=3.52, val_accuracy=0.237, lr=0.0316] 73%|███████▎  | 64/88 [27:05<09:58, 24.92s/epoch, loss=1.13, accuracy=0.757, val_loss=1.65, val_accuracy=0.574, lr=0.1]    74%|███████▍  | 65/88 [27:30<09:34, 24.97s/epoch, loss=1.13, accuracy=0.756, val_loss=4.62, val_accuracy=0.271, lr=0.1] 75%|███████▌  | 66/88 [27:54<09:02, 24.66s/epoch, loss=1.13, accuracy=0.751, val_loss=4.98, val_accuracy=0.286, lr=0.1] 76%|███████▌  | 67/88 [28:18<08:39, 24.73s/epoch, loss=1.12, accuracy=0.758, val_loss=3.48, val_accuracy=0.4, lr=0.1]   77%|███████▋  | 68/88 [28:43<08:16, 24.81s/epoch, loss=1.13, accuracy=0.755, val_loss=1.67, val_accuracy=0.576, lr=0.0316] 78%|███████▊  | 69/88 [29:08<07:51, 24.82s/epoch, loss=1.13, accuracy=0.757, val_loss=2.4, val_accuracy=0.467, lr=0.1]     80%|███████▉  | 70/88 [29:35<07:36, 25.38s/epoch, loss=1.13, accuracy=0.756, val_loss=1.97, val_accuracy=0.536, lr=0.1] 81%|████████  | 71/88 [30:00<07:08, 25.19s/epoch, loss=1.13, accuracy=0.756, val_loss=3.21, val_accuracy=0.306, lr=0.1] 82%|████████▏ | 72/88 [30:25<06:42, 25.13s/epoch, loss=1.13, accuracy=0.757, val_loss=1.67, val_accuracy=0.568, lr=0.1] 83%|████████▎ | 73/88 [30:50<06:16, 25.10s/epoch, loss=1.12, accuracy=0.758, val_loss=1.93, val_accuracy=0.525, lr=0.0316] 84%|████████▍ | 74/88 [31:15<05:52, 25.18s/epoch, loss=1.12, accuracy=0.758, val_loss=1.89, val_accuracy=0.51, lr=0.1]     85%|████████▌ | 75/88 [31:41<05:31, 25.51s/epoch, loss=1.13, accuracy=0.755, val_loss=2.07, val_accuracy=0.49, lr=0.1] 86%|████████▋ | 76/88 [32:05<04:58, 24.87s/epoch, loss=1.12, accuracy=0.757, val_loss=2.08, val_accuracy=0.514, lr=0.1] 88%|████████▊ | 77/88 [32:28<04:28, 24.39s/epoch, loss=1.13, accuracy=0.755, val_loss=1.59, val_accuracy=0.609, lr=0.1] 89%|████████▊ | 78/88 [32:54<04:08, 24.85s/epoch, loss=1.13, accuracy=0.756, val_loss=2.83, val_accuracy=0.398, lr=0.0316] 90%|████████▉ | 79/88 [33:20<03:46, 25.14s/epoch, loss=1.12, accuracy=0.759, val_loss=1.81, val_accuracy=0.496, lr=0.1]    91%|█████████ | 80/88 [33:45<03:22, 25.30s/epoch, loss=1.13, accuracy=0.754, val_loss=7.21, val_accuracy=0.2, lr=0.1]   92%|█████████▏| 81/88 [34:11<02:57, 25.37s/epoch, loss=1.14, accuracy=0.754, val_loss=3.46, val_accuracy=0.372, lr=0.1] 93%|█████████▎| 82/88 [34:35<02:30, 25.03s/epoch, loss=0.935, accuracy=0.814, val_loss=1.02, val_accuracy=0.767, lr=0.01] 94%|█████████▍| 83/88 [35:00<02:05, 25.06s/epoch, loss=0.748, accuracy=0.846, val_loss=0.876, val_accuracy=0.781, lr=0.01] 95%|█████████▌| 84/88 [35:26<01:40, 25.23s/epoch, loss=0.662, accuracy=0.856, val_loss=0.873, val_accuracy=0.772, lr=0.01] 97%|█████████▋| 85/88 [35:51<01:15, 25.21s/epoch, loss=0.609, accuracy=0.861, val_loss=0.845, val_accuracy=0.772, lr=0.01] 98%|█████████▊| 86/88 [36:16<00:50, 25.17s/epoch, loss=0.588, accuracy=0.86, val_loss=0.739, val_accuracy=0.811, lr=0.01]  99%|█████████▉| 87/88 [36:41<00:25, 25.11s/epoch, loss=0.574, accuracy=0.861, val_loss=0.86, val_accuracy=0.76, lr=0.01] 100%|██████████| 88/88 [37:07<00:00, 25.32s/epoch, loss=0.573, accuracy=0.862, val_loss=0.996, val_accuracy=0.729, lr=0.01]100%|██████████| 88/88 [37:07<00:00, 25.31s/epoch, loss=0.573, accuracy=0.862, val_loss=0.996, val_accuracy=0.729, lr=0.01]
Using real-time data augmentation.
Test loss: 0.9959203004837036
Test accuracy: 0.729200005531311


* * * Run SGD for ID = 17_5. * * *


2024-02-15 16:28:34.143193: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 16:28:37.107947: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 16:28:37.109176: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-15 16:28:37.148034: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 16:28:37.148079: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 16:28:37.151141: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 16:28:37.151187: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 16:28:37.153742: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 16:28:37.154501: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 16:28:37.157298: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 16:28:37.158892: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 16:28:37.164107: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 16:28:37.164678: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 16:28:37.164781: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 16:28:38.528827: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-15 16:28:38.529350: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 16:28:38.529843: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 16:28:38.529878: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 16:28:38.529913: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 16:28:38.529932: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 16:28:38.529949: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 16:28:38.529967: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 16:28:38.530003: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 16:28:38.530020: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 16:28:38.530045: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 16:28:38.530510: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 16:28:38.530546: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 16:28:39.262550: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-15 16:28:39.262610: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-15 16:28:39.262620: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-15 16:28:39.264015: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': 175, 'batch_size': 128, 'epochs': 88, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/88 [00:00<?, ?epoch/s]2024-02-15 16:28:40.105667: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-15 16:28:40.117815: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199950000 Hz
2024-02-15 16:28:42.393756: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 16:28:42.620199: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 16:28:43.582204: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-15 16:28:43.712892: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/88 [01:15<1:48:47, 75.03s/epoch, loss=3.17, accuracy=0.286, val_loss=3.55, val_accuracy=0.162, lr=0.1]  2%|▏         | 2/88 [01:39<1:04:34, 45.05s/epoch, loss=1.6, accuracy=0.507, val_loss=2.29, val_accuracy=0.325, lr=0.1]   3%|▎         | 3/88 [02:05<51:32, 36.38s/epoch, loss=1.39, accuracy=0.608, val_loss=2.43, val_accuracy=0.4, lr=0.1]     5%|▍         | 4/88 [02:28<43:59, 31.42s/epoch, loss=1.3, accuracy=0.664, val_loss=2.63, val_accuracy=0.375, lr=0.1]  6%|▌         | 5/88 [02:55<41:06, 29.71s/epoch, loss=1.26, accuracy=0.689, val_loss=1.85, val_accuracy=0.478, lr=0.1]  7%|▋         | 6/88 [03:21<38:49, 28.40s/epoch, loss=1.24, accuracy=0.701, val_loss=1.52, val_accuracy=0.619, lr=0.1]  8%|▊         | 7/88 [03:47<37:19, 27.65s/epoch, loss=1.23, accuracy=0.712, val_loss=1.76, val_accuracy=0.525, lr=0.1]  9%|▉         | 8/88 [04:13<36:07, 27.10s/epoch, loss=1.22, accuracy=0.718, val_loss=2.09, val_accuracy=0.468, lr=0.1] 10%|█         | 9/88 [04:38<34:44, 26.39s/epoch, loss=1.21, accuracy=0.724, val_loss=2.06, val_accuracy=0.502, lr=0.1] 11%|█▏        | 10/88 [05:02<33:22, 25.68s/epoch, loss=1.2, accuracy=0.727, val_loss=2.59, val_accuracy=0.479, lr=0.1] 12%|█▎        | 11/88 [05:28<33:02, 25.75s/epoch, loss=1.19, accuracy=0.733, val_loss=2.68, val_accuracy=0.372, lr=0.0316] 14%|█▎        | 12/88 [05:52<31:58, 25.25s/epoch, loss=1.19, accuracy=0.733, val_loss=3.93, val_accuracy=0.29, lr=0.1]     15%|█▍        | 13/88 [06:17<31:21, 25.08s/epoch, loss=1.18, accuracy=0.736, val_loss=1.38, val_accuracy=0.67, lr=0.1] 16%|█▌        | 14/88 [06:42<31:02, 25.17s/epoch, loss=1.18, accuracy=0.737, val_loss=1.6, val_accuracy=0.59, lr=0.1]  17%|█▋        | 15/88 [07:06<30:09, 24.79s/epoch, loss=1.18, accuracy=0.739, val_loss=1.82, val_accuracy=0.553, lr=0.1] 18%|█▊        | 16/88 [07:30<29:29, 24.58s/epoch, loss=1.18, accuracy=0.737, val_loss=1.48, val_accuracy=0.619, lr=0.1] 19%|█▉        | 17/88 [07:57<29:50, 25.22s/epoch, loss=1.17, accuracy=0.738, val_loss=1.87, val_accuracy=0.555, lr=0.1] 20%|██        | 18/88 [08:21<29:01, 24.88s/epoch, loss=1.18, accuracy=0.741, val_loss=1.96, val_accuracy=0.523, lr=0.0316] 22%|██▏       | 19/88 [08:45<28:28, 24.76s/epoch, loss=1.17, accuracy=0.743, val_loss=6.83, val_accuracy=0.3, lr=0.1]      23%|██▎       | 20/88 [09:09<27:50, 24.57s/epoch, loss=1.17, accuracy=0.743, val_loss=1.99, val_accuracy=0.504, lr=0.1] 24%|██▍       | 21/88 [09:36<28:11, 25.25s/epoch, loss=1.17, accuracy=0.744, val_loss=1.81, val_accuracy=0.526, lr=0.1] 25%|██▌       | 22/88 [10:01<27:26, 24.95s/epoch, loss=1.17, accuracy=0.744, val_loss=1.74, val_accuracy=0.539, lr=0.1] 26%|██▌       | 23/88 [10:27<27:34, 25.45s/epoch, loss=1.17, accuracy=0.744, val_loss=3.79, val_accuracy=0.282, lr=0.0316] 27%|██▋       | 24/88 [10:51<26:32, 24.89s/epoch, loss=1.16, accuracy=0.744, val_loss=1.84, val_accuracy=0.498, lr=0.1]    28%|██▊       | 25/88 [11:14<25:44, 24.51s/epoch, loss=1.16, accuracy=0.746, val_loss=3.5, val_accuracy=0.32, lr=0.1]   30%|██▉       | 26/88 [11:40<25:45, 24.94s/epoch, loss=1.16, accuracy=0.746, val_loss=1.73, val_accuracy=0.586, lr=0.1] 31%|███       | 27/88 [12:04<24:56, 24.53s/epoch, loss=1.16, accuracy=0.748, val_loss=1.44, val_accuracy=0.652, lr=0.1] 32%|███▏      | 28/88 [12:30<25:08, 25.14s/epoch, loss=1.15, accuracy=0.749, val_loss=1.88, val_accuracy=0.553, lr=0.0316] 33%|███▎      | 29/88 [12:56<24:52, 25.29s/epoch, loss=1.16, accuracy=0.746, val_loss=1.99, val_accuracy=0.503, lr=0.1]    34%|███▍      | 30/88 [13:20<24:02, 24.87s/epoch, loss=1.15, accuracy=0.747, val_loss=2.44, val_accuracy=0.45, lr=0.1]  35%|███▌      | 31/88 [13:44<23:16, 24.50s/epoch, loss=1.16, accuracy=0.745, val_loss=2.31, val_accuracy=0.449, lr=0.1] 36%|███▋      | 32/88 [14:07<22:39, 24.28s/epoch, loss=1.16, accuracy=0.748, val_loss=2.23, val_accuracy=0.44, lr=0.1]  38%|███▊      | 33/88 [14:31<22:04, 24.08s/epoch, loss=1.15, accuracy=0.748, val_loss=1.6, val_accuracy=0.592, lr=0.0316] 39%|███▊      | 34/88 [14:55<21:40, 24.07s/epoch, loss=1.14, accuracy=0.752, val_loss=1.76, val_accuracy=0.556, lr=0.1]   40%|███▉      | 35/88 [15:19<21:18, 24.13s/epoch, loss=1.15, accuracy=0.749, val_loss=3, val_accuracy=0.374, lr=0.1]    41%|████      | 36/88 [15:45<21:23, 24.68s/epoch, loss=1.15, accuracy=0.751, val_loss=1.57, val_accuracy=0.611, lr=0.1] 42%|████▏     | 37/88 [16:11<21:09, 24.89s/epoch, loss=1.14, accuracy=0.751, val_loss=1.79, val_accuracy=0.538, lr=0.1] 43%|████▎     | 38/88 [16:36<20:57, 25.16s/epoch, loss=1.14, accuracy=0.749, val_loss=1.76, val_accuracy=0.557, lr=0.0316] 44%|████▍     | 39/88 [17:01<20:25, 25.01s/epoch, loss=1.15, accuracy=0.748, val_loss=2.15, val_accuracy=0.46, lr=0.1]     45%|████▌     | 40/88 [17:25<19:43, 24.65s/epoch, loss=1.13, accuracy=0.752, val_loss=2.16, val_accuracy=0.5, lr=0.1]  47%|████▋     | 41/88 [17:49<19:05, 24.38s/epoch, loss=1.14, accuracy=0.752, val_loss=2.28, val_accuracy=0.467, lr=0.1] 48%|████▊     | 42/88 [18:12<18:28, 24.09s/epoch, loss=1.14, accuracy=0.752, val_loss=3.33, val_accuracy=0.383, lr=0.1] 49%|████▉     | 43/88 [18:37<18:12, 24.27s/epoch, loss=1.14, accuracy=0.752, val_loss=2.79, val_accuracy=0.397, lr=0.0316] 50%|█████     | 44/88 [19:02<17:58, 24.51s/epoch, loss=1.14, accuracy=0.751, val_loss=2.18, val_accuracy=0.482, lr=0.1]    51%|█████     | 45/88 [19:25<17:17, 24.12s/epoch, loss=1.13, accuracy=0.751, val_loss=1.55, val_accuracy=0.627, lr=0.1] 52%|█████▏    | 46/88 [19:49<16:55, 24.17s/epoch, loss=1.13, accuracy=0.752, val_loss=2.37, val_accuracy=0.434, lr=0.1] 53%|█████▎    | 47/88 [20:14<16:35, 24.28s/epoch, loss=1.13, accuracy=0.753, val_loss=4.53, val_accuracy=0.388, lr=0.1] 55%|█████▍    | 48/88 [20:39<16:22, 24.56s/epoch, loss=1.13, accuracy=0.754, val_loss=1.63, val_accuracy=0.596, lr=0.0316] 56%|█████▌    | 49/88 [21:03<15:48, 24.33s/epoch, loss=1.13, accuracy=0.75, val_loss=1.7, val_accuracy=0.567, lr=0.1]      57%|█████▋    | 50/88 [21:28<15:34, 24.60s/epoch, loss=1.13, accuracy=0.752, val_loss=6.53, val_accuracy=0.196, lr=0.1] 58%|█████▊    | 51/88 [21:55<15:30, 25.16s/epoch, loss=1.13, accuracy=0.754, val_loss=1.87, val_accuracy=0.519, lr=0.1] 59%|█████▉    | 52/88 [22:18<14:51, 24.75s/epoch, loss=1.13, accuracy=0.753, val_loss=2.43, val_accuracy=0.522, lr=0.1] 60%|██████    | 53/88 [22:43<14:20, 24.59s/epoch, loss=1.13, accuracy=0.754, val_loss=2.16, val_accuracy=0.421, lr=0.0316] 61%|██████▏   | 54/88 [23:08<14:06, 24.90s/epoch, loss=1.14, accuracy=0.753, val_loss=2.28, val_accuracy=0.498, lr=0.1]    62%|██████▎   | 55/88 [23:35<13:56, 25.35s/epoch, loss=1.13, accuracy=0.751, val_loss=2.73, val_accuracy=0.388, lr=0.1] 64%|██████▎   | 56/88 [23:59<13:18, 24.96s/epoch, loss=1.13, accuracy=0.756, val_loss=1.77, val_accuracy=0.581, lr=0.1] 65%|██████▍   | 57/88 [24:22<12:43, 24.63s/epoch, loss=1.14, accuracy=0.754, val_loss=2.59, val_accuracy=0.435, lr=0.1] 66%|██████▌   | 58/88 [24:49<12:36, 25.21s/epoch, loss=1.13, accuracy=0.754, val_loss=3, val_accuracy=0.278, lr=0.0316] 67%|██████▋   | 59/88 [25:14<12:06, 25.04s/epoch, loss=1.13, accuracy=0.755, val_loss=2.16, val_accuracy=0.5, lr=0.1]   68%|██████▊   | 60/88 [25:37<11:30, 24.66s/epoch, loss=1.13, accuracy=0.753, val_loss=2, val_accuracy=0.474, lr=0.1]  69%|██████▉   | 61/88 [26:01<10:57, 24.36s/epoch, loss=1.13, accuracy=0.752, val_loss=4.09, val_accuracy=0.254, lr=0.1] 70%|███████   | 62/88 [26:26<10:34, 24.39s/epoch, loss=1.12, accuracy=0.753, val_loss=2.57, val_accuracy=0.533, lr=0.1] 72%|███████▏  | 63/88 [26:50<10:12, 24.50s/epoch, loss=1.13, accuracy=0.754, val_loss=2.23, val_accuracy=0.405, lr=0.0316] 73%|███████▎  | 64/88 [27:16<09:54, 24.76s/epoch, loss=1.12, accuracy=0.756, val_loss=1.69, val_accuracy=0.574, lr=0.1]    74%|███████▍  | 65/88 [27:39<09:19, 24.34s/epoch, loss=1.13, accuracy=0.756, val_loss=1.98, val_accuracy=0.54, lr=0.1]  75%|███████▌  | 66/88 [28:05<09:09, 24.96s/epoch, loss=1.12, accuracy=0.756, val_loss=3.08, val_accuracy=0.347, lr=0.1] 76%|███████▌  | 67/88 [28:29<08:34, 24.52s/epoch, loss=1.13, accuracy=0.754, val_loss=2.08, val_accuracy=0.479, lr=0.1] 77%|███████▋  | 68/88 [28:53<08:05, 24.26s/epoch, loss=1.13, accuracy=0.755, val_loss=1.73, val_accuracy=0.55, lr=0.0316] 78%|███████▊  | 69/88 [29:19<07:53, 24.93s/epoch, loss=1.13, accuracy=0.755, val_loss=1.62, val_accuracy=0.595, lr=0.1]   80%|███████▉  | 70/88 [29:43<07:21, 24.54s/epoch, loss=1.13, accuracy=0.756, val_loss=2.76, val_accuracy=0.408, lr=0.1] 81%|████████  | 71/88 [30:06<06:51, 24.21s/epoch, loss=1.13, accuracy=0.756, val_loss=3.06, val_accuracy=0.288, lr=0.1] 82%|████████▏ | 72/88 [30:30<06:23, 23.98s/epoch, loss=1.13, accuracy=0.756, val_loss=2.75, val_accuracy=0.379, lr=0.1] 83%|████████▎ | 73/88 [30:53<05:58, 23.92s/epoch, loss=1.13, accuracy=0.756, val_loss=1.82, val_accuracy=0.526, lr=0.0316] 84%|████████▍ | 74/88 [31:18<05:36, 24.05s/epoch, loss=1.12, accuracy=0.757, val_loss=2.75, val_accuracy=0.39, lr=0.1]     85%|████████▌ | 75/88 [31:44<05:22, 24.83s/epoch, loss=1.12, accuracy=0.757, val_loss=2.25, val_accuracy=0.394, lr=0.1] 86%|████████▋ | 76/88 [32:08<04:53, 24.46s/epoch, loss=1.12, accuracy=0.755, val_loss=3.24, val_accuracy=0.375, lr=0.1] 88%|████████▊ | 77/88 [32:34<04:33, 24.85s/epoch, loss=1.12, accuracy=0.755, val_loss=1.55, val_accuracy=0.632, lr=0.1] 89%|████████▊ | 78/88 [32:57<04:04, 24.45s/epoch, loss=1.13, accuracy=0.756, val_loss=2.51, val_accuracy=0.398, lr=0.0316] 90%|████████▉ | 79/88 [33:24<03:45, 25.05s/epoch, loss=1.12, accuracy=0.755, val_loss=2.29, val_accuracy=0.437, lr=0.1]    91%|█████████ | 80/88 [33:50<03:22, 25.32s/epoch, loss=1.12, accuracy=0.755, val_loss=1.73, val_accuracy=0.566, lr=0.1] 92%|█████████▏| 81/88 [34:13<02:53, 24.76s/epoch, loss=1.12, accuracy=0.754, val_loss=2.48, val_accuracy=0.408, lr=0.1] 93%|█████████▎| 82/88 [34:39<02:29, 24.96s/epoch, loss=0.925, accuracy=0.812, val_loss=0.871, val_accuracy=0.814, lr=0.01] 94%|█████████▍| 83/88 [35:02<02:02, 24.50s/epoch, loss=0.742, accuracy=0.846, val_loss=0.827, val_accuracy=0.81, lr=0.01]  95%|█████████▌| 84/88 [35:28<01:39, 24.86s/epoch, loss=0.661, accuracy=0.853, val_loss=0.796, val_accuracy=0.797, lr=0.01] 97%|█████████▋| 85/88 [35:54<01:16, 25.35s/epoch, loss=0.615, accuracy=0.857, val_loss=0.744, val_accuracy=0.808, lr=0.01] 98%|█████████▊| 86/88 [36:18<00:49, 24.75s/epoch, loss=0.592, accuracy=0.859, val_loss=0.848, val_accuracy=0.765, lr=0.01] 99%|█████████▉| 87/88 [36:44<00:25, 25.28s/epoch, loss=0.58, accuracy=0.86, val_loss=0.765, val_accuracy=0.798, lr=0.01]  100%|██████████| 88/88 [37:08<00:00, 24.84s/epoch, loss=0.574, accuracy=0.86, val_loss=0.855, val_accuracy=0.766, lr=0.01]100%|██████████| 88/88 [37:08<00:00, 25.32s/epoch, loss=0.574, accuracy=0.86, val_loss=0.855, val_accuracy=0.766, lr=0.01]
Using real-time data augmentation.
Test loss: 0.8550586104393005
Test accuracy: 0.7659000158309937


* * * Run SGD for ID = 17_6. * * *


2024-02-15 17:05:50.934186: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 17:05:53.712413: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 17:05:53.713789: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-15 17:05:53.753370: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 17:05:53.753404: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 17:05:53.756269: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 17:05:53.756313: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 17:05:53.758763: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 17:05:53.759439: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 17:05:53.761981: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 17:05:53.763448: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 17:05:53.768413: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 17:05:53.769030: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 17:05:53.769117: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 17:05:55.122592: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-15 17:05:55.123139: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 17:05:55.123609: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 17:05:55.123640: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 17:05:55.123674: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 17:05:55.123737: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 17:05:55.123756: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 17:05:55.123774: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 17:05:55.123793: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 17:05:55.123811: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 17:05:55.123829: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 17:05:55.124319: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 17:05:55.124353: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 17:05:55.871746: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-15 17:05:55.871830: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-15 17:05:55.871843: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-15 17:05:55.873265: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': 176, 'batch_size': 128, 'epochs': 88, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/88 [00:00<?, ?epoch/s]2024-02-15 17:05:56.729127: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-15 17:05:56.741819: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199950000 Hz
2024-02-15 17:05:59.080654: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 17:05:59.334728: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 17:06:00.241339: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-15 17:06:00.300194: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/88 [01:12<1:45:24, 72.70s/epoch, loss=3.23, accuracy=0.285, val_loss=2.4, val_accuracy=0.227, lr=0.1]  2%|▏         | 2/88 [01:36<1:02:47, 43.80s/epoch, loss=1.58, accuracy=0.522, val_loss=2.69, val_accuracy=0.312, lr=0.1]  3%|▎         | 3/88 [02:01<49:45, 35.12s/epoch, loss=1.36, accuracy=0.631, val_loss=2.06, val_accuracy=0.433, lr=0.1]    5%|▍         | 4/88 [02:27<44:32, 31.81s/epoch, loss=1.3, accuracy=0.671, val_loss=1.67, val_accuracy=0.531, lr=0.1]   6%|▌         | 5/88 [02:54<41:14, 29.82s/epoch, loss=1.28, accuracy=0.691, val_loss=1.85, val_accuracy=0.499, lr=0.1]  7%|▋         | 6/88 [03:20<39:22, 28.81s/epoch, loss=1.26, accuracy=0.701, val_loss=1.56, val_accuracy=0.608, lr=0.1]  8%|▊         | 7/88 [03:47<37:46, 27.99s/epoch, loss=1.24, accuracy=0.71, val_loss=1.86, val_accuracy=0.536, lr=0.1]   9%|▉         | 8/88 [04:13<36:33, 27.41s/epoch, loss=1.23, accuracy=0.715, val_loss=1.93, val_accuracy=0.458, lr=0.1] 10%|█         | 9/88 [04:38<35:00, 26.59s/epoch, loss=1.22, accuracy=0.721, val_loss=3.44, val_accuracy=0.318, lr=0.1] 11%|█▏        | 10/88 [05:04<34:19, 26.41s/epoch, loss=1.21, accuracy=0.723, val_loss=2.29, val_accuracy=0.482, lr=0.1] 12%|█▎        | 11/88 [05:29<33:26, 26.06s/epoch, loss=1.2, accuracy=0.728, val_loss=2.43, val_accuracy=0.445, lr=0.0316] 14%|█▎        | 12/88 [05:55<32:59, 26.04s/epoch, loss=1.2, accuracy=0.732, val_loss=1.91, val_accuracy=0.481, lr=0.1]    15%|█▍        | 13/88 [06:21<32:30, 26.01s/epoch, loss=1.19, accuracy=0.733, val_loss=1.35, val_accuracy=0.671, lr=0.1] 16%|█▌        | 14/88 [06:47<32:03, 25.99s/epoch, loss=1.18, accuracy=0.736, val_loss=2.16, val_accuracy=0.488, lr=0.1] 17%|█▋        | 15/88 [07:11<30:57, 25.45s/epoch, loss=1.17, accuracy=0.74, val_loss=2.06, val_accuracy=0.492, lr=0.1]  18%|█▊        | 16/88 [07:35<29:59, 25.00s/epoch, loss=1.18, accuracy=0.735, val_loss=1.91, val_accuracy=0.508, lr=0.1] 19%|█▉        | 17/88 [08:01<30:04, 25.42s/epoch, loss=1.18, accuracy=0.74, val_loss=1.84, val_accuracy=0.505, lr=0.1]  20%|██        | 18/88 [08:27<29:52, 25.61s/epoch, loss=1.17, accuracy=0.742, val_loss=1.59, val_accuracy=0.602, lr=0.0316] 22%|██▏       | 19/88 [08:52<29:13, 25.41s/epoch, loss=1.17, accuracy=0.741, val_loss=1.61, val_accuracy=0.583, lr=0.1]    23%|██▎       | 20/88 [09:16<28:07, 24.81s/epoch, loss=1.17, accuracy=0.743, val_loss=2.31, val_accuracy=0.486, lr=0.1] 24%|██▍       | 21/88 [09:39<27:08, 24.31s/epoch, loss=1.17, accuracy=0.744, val_loss=1.95, val_accuracy=0.527, lr=0.1] 25%|██▌       | 22/88 [10:03<26:33, 24.14s/epoch, loss=1.16, accuracy=0.745, val_loss=1.75, val_accuracy=0.538, lr=0.1] 26%|██▌       | 23/88 [10:28<26:25, 24.39s/epoch, loss=1.16, accuracy=0.745, val_loss=2.6, val_accuracy=0.39, lr=0.0316] 27%|██▋       | 24/88 [10:51<25:40, 24.07s/epoch, loss=1.16, accuracy=0.745, val_loss=2.59, val_accuracy=0.351, lr=0.1]  28%|██▊       | 25/88 [11:16<25:32, 24.32s/epoch, loss=1.16, accuracy=0.745, val_loss=1.44, val_accuracy=0.638, lr=0.1] 30%|██▉       | 26/88 [11:40<24:55, 24.12s/epoch, loss=1.16, accuracy=0.746, val_loss=2.12, val_accuracy=0.55, lr=0.1]  31%|███       | 27/88 [12:06<25:13, 24.82s/epoch, loss=1.16, accuracy=0.748, val_loss=2.66, val_accuracy=0.431, lr=0.1] 32%|███▏      | 28/88 [12:31<24:50, 24.85s/epoch, loss=1.15, accuracy=0.748, val_loss=1.94, val_accuracy=0.544, lr=0.0316] 33%|███▎      | 29/88 [12:56<24:35, 25.00s/epoch, loss=1.15, accuracy=0.747, val_loss=1.96, val_accuracy=0.49, lr=0.1]     34%|███▍      | 30/88 [13:23<24:32, 25.39s/epoch, loss=1.15, accuracy=0.748, val_loss=1.93, val_accuracy=0.48, lr=0.1] 35%|███▌      | 31/88 [13:46<23:40, 24.93s/epoch, loss=1.15, accuracy=0.746, val_loss=5.66, val_accuracy=0.141, lr=0.1] 36%|███▋      | 32/88 [14:12<23:32, 25.22s/epoch, loss=1.14, accuracy=0.748, val_loss=1.84, val_accuracy=0.524, lr=0.1] 38%|███▊      | 33/88 [14:37<23:05, 25.19s/epoch, loss=1.14, accuracy=0.751, val_loss=3.16, val_accuracy=0.341, lr=0.0316] 39%|███▊      | 34/88 [15:03<22:47, 25.32s/epoch, loss=1.14, accuracy=0.75, val_loss=1.76, val_accuracy=0.576, lr=0.1]     40%|███▉      | 35/88 [15:27<21:56, 24.84s/epoch, loss=1.15, accuracy=0.751, val_loss=2.21, val_accuracy=0.472, lr=0.1] 41%|████      | 36/88 [15:53<21:52, 25.25s/epoch, loss=1.14, accuracy=0.752, val_loss=1.68, val_accuracy=0.576, lr=0.1] 42%|████▏     | 37/88 [16:16<21:00, 24.72s/epoch, loss=1.15, accuracy=0.749, val_loss=2.38, val_accuracy=0.417, lr=0.1] 43%|████▎     | 38/88 [16:42<20:51, 25.02s/epoch, loss=1.13, accuracy=0.752, val_loss=1.73, val_accuracy=0.56, lr=0.0316] 44%|████▍     | 39/88 [17:09<20:45, 25.43s/epoch, loss=1.14, accuracy=0.753, val_loss=2.49, val_accuracy=0.364, lr=0.1]   45%|████▌     | 40/88 [17:34<20:21, 25.44s/epoch, loss=1.13, accuracy=0.751, val_loss=2.37, val_accuracy=0.343, lr=0.1] 47%|████▋     | 41/88 [17:59<19:43, 25.18s/epoch, loss=1.14, accuracy=0.751, val_loss=2.49, val_accuracy=0.446, lr=0.1] 48%|████▊     | 42/88 [18:22<18:55, 24.69s/epoch, loss=1.13, accuracy=0.752, val_loss=2.14, val_accuracy=0.445, lr=0.1] 49%|████▉     | 43/88 [18:46<18:17, 24.39s/epoch, loss=1.13, accuracy=0.752, val_loss=1.85, val_accuracy=0.534, lr=0.0316] 50%|█████     | 44/88 [19:09<17:42, 24.15s/epoch, loss=1.13, accuracy=0.754, val_loss=2.41, val_accuracy=0.463, lr=0.1]    51%|█████     | 45/88 [19:33<17:08, 23.91s/epoch, loss=1.13, accuracy=0.753, val_loss=2.13, val_accuracy=0.468, lr=0.1] 52%|█████▏    | 46/88 [19:56<16:36, 23.72s/epoch, loss=1.13, accuracy=0.752, val_loss=1.73, val_accuracy=0.553, lr=0.1] 53%|█████▎    | 47/88 [20:21<16:30, 24.15s/epoch, loss=1.13, accuracy=0.751, val_loss=2.2, val_accuracy=0.436, lr=0.1]  55%|█████▍    | 48/88 [20:46<16:11, 24.28s/epoch, loss=1.13, accuracy=0.756, val_loss=2.84, val_accuracy=0.352, lr=0.0316] 56%|█████▌    | 49/88 [21:11<15:55, 24.50s/epoch, loss=1.13, accuracy=0.752, val_loss=3.11, val_accuracy=0.33, lr=0.1]     57%|█████▋    | 50/88 [21:35<15:22, 24.26s/epoch, loss=1.13, accuracy=0.757, val_loss=2.01, val_accuracy=0.47, lr=0.1] 58%|█████▊    | 51/88 [21:58<14:50, 24.08s/epoch, loss=1.13, accuracy=0.755, val_loss=3.78, val_accuracy=0.319, lr=0.1] 59%|█████▉    | 52/88 [22:24<14:45, 24.61s/epoch, loss=1.13, accuracy=0.756, val_loss=2.56, val_accuracy=0.43, lr=0.1]  60%|██████    | 53/88 [22:50<14:30, 24.88s/epoch, loss=1.13, accuracy=0.753, val_loss=1.98, val_accuracy=0.519, lr=0.0316] 61%|██████▏   | 54/88 [23:16<14:23, 25.40s/epoch, loss=1.13, accuracy=0.753, val_loss=2.14, val_accuracy=0.49, lr=0.1]     62%|██████▎   | 55/88 [23:42<14:06, 25.65s/epoch, loss=1.12, accuracy=0.756, val_loss=3.88, val_accuracy=0.298, lr=0.1] 64%|██████▎   | 56/88 [24:07<13:29, 25.30s/epoch, loss=1.12, accuracy=0.753, val_loss=2.77, val_accuracy=0.363, lr=0.1] 65%|██████▍   | 57/88 [24:33<13:09, 25.47s/epoch, loss=1.12, accuracy=0.758, val_loss=1.55, val_accuracy=0.604, lr=0.1] 66%|██████▌   | 58/88 [24:58<12:37, 25.26s/epoch, loss=1.13, accuracy=0.757, val_loss=2.31, val_accuracy=0.444, lr=0.0316] 67%|██████▋   | 59/88 [25:23<12:14, 25.31s/epoch, loss=1.12, accuracy=0.756, val_loss=1.51, val_accuracy=0.619, lr=0.1]    68%|██████▊   | 60/88 [25:49<11:55, 25.56s/epoch, loss=1.13, accuracy=0.755, val_loss=1.56, val_accuracy=0.598, lr=0.1] 69%|██████▉   | 61/88 [26:14<11:22, 25.28s/epoch, loss=1.12, accuracy=0.758, val_loss=1.63, val_accuracy=0.61, lr=0.1]  70%|███████   | 62/88 [26:40<11:03, 25.51s/epoch, loss=1.13, accuracy=0.755, val_loss=2.46, val_accuracy=0.369, lr=0.1] 72%|███████▏  | 63/88 [27:06<10:42, 25.71s/epoch, loss=1.13, accuracy=0.755, val_loss=1.72, val_accuracy=0.572, lr=0.0316] 73%|███████▎  | 64/88 [27:29<09:59, 24.99s/epoch, loss=1.13, accuracy=0.756, val_loss=2.07, val_accuracy=0.45, lr=0.1]     74%|███████▍  | 65/88 [27:55<09:38, 25.13s/epoch, loss=1.12, accuracy=0.756, val_loss=4.05, val_accuracy=0.305, lr=0.1] 75%|███████▌  | 66/88 [28:19<09:06, 24.86s/epoch, loss=1.13, accuracy=0.753, val_loss=2.11, val_accuracy=0.448, lr=0.1] 76%|███████▌  | 67/88 [28:45<08:52, 25.35s/epoch, loss=1.13, accuracy=0.753, val_loss=2.1, val_accuracy=0.466, lr=0.1]  77%|███████▋  | 68/88 [29:11<08:25, 25.28s/epoch, loss=1.12, accuracy=0.754, val_loss=1.93, val_accuracy=0.487, lr=0.0316] 78%|███████▊  | 69/88 [29:35<07:56, 25.05s/epoch, loss=1.12, accuracy=0.758, val_loss=2.12, val_accuracy=0.488, lr=0.1]    80%|███████▉  | 70/88 [30:02<07:39, 25.51s/epoch, loss=1.12, accuracy=0.756, val_loss=1.4, val_accuracy=0.66, lr=0.1]   81%|████████  | 71/88 [30:25<07:02, 24.82s/epoch, loss=1.13, accuracy=0.757, val_loss=2.97, val_accuracy=0.319, lr=0.1] 82%|████████▏ | 72/88 [30:49<06:33, 24.61s/epoch, loss=1.12, accuracy=0.754, val_loss=2.78, val_accuracy=0.307, lr=0.1] 83%|████████▎ | 73/88 [31:14<06:11, 24.78s/epoch, loss=1.13, accuracy=0.754, val_loss=2.65, val_accuracy=0.306, lr=0.0316] 84%|████████▍ | 74/88 [31:39<05:47, 24.84s/epoch, loss=1.12, accuracy=0.757, val_loss=2.96, val_accuracy=0.305, lr=0.1]    85%|████████▌ | 75/88 [32:05<05:27, 25.18s/epoch, loss=1.12, accuracy=0.755, val_loss=2.16, val_accuracy=0.436, lr=0.1] 86%|████████▋ | 76/88 [32:30<05:02, 25.20s/epoch, loss=1.12, accuracy=0.755, val_loss=2.08, val_accuracy=0.401, lr=0.1] 88%|████████▊ | 77/88 [32:56<04:37, 25.26s/epoch, loss=1.13, accuracy=0.757, val_loss=3.49, val_accuracy=0.354, lr=0.1] 89%|████████▊ | 78/88 [33:21<04:11, 25.11s/epoch, loss=1.12, accuracy=0.756, val_loss=3.94, val_accuracy=0.33, lr=0.0316] 90%|████████▉ | 79/88 [33:47<03:48, 25.40s/epoch, loss=1.13, accuracy=0.756, val_loss=1.94, val_accuracy=0.503, lr=0.1]   91%|█████████ | 80/88 [34:10<03:18, 24.86s/epoch, loss=1.12, accuracy=0.757, val_loss=2.29, val_accuracy=0.44, lr=0.1]  92%|█████████▏| 81/88 [34:35<02:54, 24.94s/epoch, loss=1.12, accuracy=0.757, val_loss=2.66, val_accuracy=0.388, lr=0.1] 93%|█████████▎| 82/88 [35:00<02:30, 25.01s/epoch, loss=0.897, accuracy=0.818, val_loss=0.939, val_accuracy=0.783, lr=0.01] 94%|█████████▍| 83/88 [35:24<02:02, 24.58s/epoch, loss=0.731, accuracy=0.845, val_loss=0.881, val_accuracy=0.782, lr=0.01] 95%|█████████▌| 84/88 [35:50<01:40, 25.09s/epoch, loss=0.65, accuracy=0.854, val_loss=0.815, val_accuracy=0.79, lr=0.01]   97%|█████████▋| 85/88 [36:16<01:15, 25.23s/epoch, loss=0.607, accuracy=0.857, val_loss=0.816, val_accuracy=0.789, lr=0.01] 98%|█████████▊| 86/88 [36:39<00:49, 24.65s/epoch, loss=0.585, accuracy=0.859, val_loss=0.873, val_accuracy=0.774, lr=0.01] 99%|█████████▉| 87/88 [37:05<00:24, 24.95s/epoch, loss=0.577, accuracy=0.86, val_loss=0.983, val_accuracy=0.742, lr=0.01] 100%|██████████| 88/88 [37:28<00:00, 24.43s/epoch, loss=0.571, accuracy=0.862, val_loss=0.911, val_accuracy=0.751, lr=0.01]100%|██████████| 88/88 [37:28<00:00, 25.55s/epoch, loss=0.571, accuracy=0.862, val_loss=0.911, val_accuracy=0.751, lr=0.01]
Using real-time data augmentation.
Test loss: 0.9107324481010437
Test accuracy: 0.7512999773025513


* * * Run SGD for ID = 17_7. * * *


2024-02-15 17:43:27.850658: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 17:43:30.817076: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 17:43:30.818303: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-15 17:43:30.857951: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 17:43:30.858007: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 17:43:30.860876: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 17:43:30.860922: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 17:43:30.863309: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 17:43:30.864009: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 17:43:30.866502: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 17:43:30.868053: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 17:43:30.873093: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 17:43:30.873649: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 17:43:30.873757: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 17:43:32.219051: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-15 17:43:32.220079: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 17:43:32.220540: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 17:43:32.220574: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 17:43:32.220610: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 17:43:32.220629: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 17:43:32.220648: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 17:43:32.220667: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 17:43:32.220696: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 17:43:32.220718: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 17:43:32.220737: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 17:43:32.221221: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 17:43:32.221263: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 17:43:32.964227: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-15 17:43:32.964289: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-15 17:43:32.964301: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-15 17:43:32.965712: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': 177, 'batch_size': 128, 'epochs': 88, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/88 [00:00<?, ?epoch/s]2024-02-15 17:43:33.817950: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-15 17:43:33.829810: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199950000 Hz
2024-02-15 17:43:36.075798: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 17:43:36.309196: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 17:43:37.486528: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-15 17:43:37.543962: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/88 [01:06<1:36:41, 66.68s/epoch, loss=3.63, accuracy=0.293, val_loss=2.54, val_accuracy=0.197, lr=0.1]  2%|▏         | 2/88 [01:30<59:31, 41.53s/epoch, loss=1.7, accuracy=0.469, val_loss=1.77, val_accuracy=0.443, lr=0.1]     3%|▎         | 3/88 [01:55<47:56, 33.84s/epoch, loss=1.51, accuracy=0.553, val_loss=2.12, val_accuracy=0.424, lr=0.1]  5%|▍         | 4/88 [02:19<41:59, 30.00s/epoch, loss=1.4, accuracy=0.623, val_loss=1.73, val_accuracy=0.516, lr=0.1]   6%|▌         | 5/88 [02:44<39:00, 28.20s/epoch, loss=1.32, accuracy=0.67, val_loss=2.92, val_accuracy=0.363, lr=0.1]  7%|▋         | 6/88 [03:07<36:10, 26.47s/epoch, loss=1.28, accuracy=0.691, val_loss=2.22, val_accuracy=0.403, lr=0.1]  8%|▊         | 7/88 [03:33<35:33, 26.34s/epoch, loss=1.26, accuracy=0.705, val_loss=2.07, val_accuracy=0.463, lr=0.1]  9%|▉         | 8/88 [03:57<34:06, 25.59s/epoch, loss=1.25, accuracy=0.713, val_loss=2.29, val_accuracy=0.439, lr=0.1] 10%|█         | 9/88 [04:22<33:14, 25.24s/epoch, loss=1.25, accuracy=0.717, val_loss=2.55, val_accuracy=0.435, lr=0.0316] 11%|█▏        | 10/88 [04:47<32:43, 25.18s/epoch, loss=1.24, accuracy=0.721, val_loss=2.15, val_accuracy=0.396, lr=0.1]   12%|█▎        | 11/88 [05:11<31:59, 24.93s/epoch, loss=1.24, accuracy=0.724, val_loss=2.53, val_accuracy=0.39, lr=0.1]  14%|█▎        | 12/88 [05:35<31:16, 24.69s/epoch, loss=1.22, accuracy=0.728, val_loss=1.61, val_accuracy=0.583, lr=0.1] 15%|█▍        | 13/88 [06:01<31:19, 25.06s/epoch, loss=1.22, accuracy=0.733, val_loss=1.7, val_accuracy=0.541, lr=0.1]  16%|█▌        | 14/88 [06:25<30:30, 24.74s/epoch, loss=1.21, accuracy=0.734, val_loss=1.66, val_accuracy=0.584, lr=0.1] 17%|█▋        | 15/88 [06:48<29:29, 24.24s/epoch, loss=1.2, accuracy=0.739, val_loss=1.59, val_accuracy=0.617, lr=0.1]  18%|█▊        | 16/88 [07:11<28:45, 23.97s/epoch, loss=1.2, accuracy=0.738, val_loss=1.6, val_accuracy=0.586, lr=0.1]  19%|█▉        | 17/88 [07:37<28:47, 24.33s/epoch, loss=1.2, accuracy=0.737, val_loss=2.07, val_accuracy=0.498, lr=0.1] 20%|██        | 18/88 [08:01<28:22, 24.33s/epoch, loss=1.2, accuracy=0.737, val_loss=1.86, val_accuracy=0.549, lr=0.1] 22%|██▏       | 19/88 [08:25<27:48, 24.18s/epoch, loss=1.19, accuracy=0.742, val_loss=1.62, val_accuracy=0.601, lr=0.1] 23%|██▎       | 20/88 [08:49<27:21, 24.14s/epoch, loss=1.19, accuracy=0.742, val_loss=2.12, val_accuracy=0.479, lr=0.0316] 24%|██▍       | 21/88 [09:13<26:57, 24.15s/epoch, loss=1.19, accuracy=0.742, val_loss=2.1, val_accuracy=0.463, lr=0.1]     25%|██▌       | 22/88 [09:36<26:10, 23.79s/epoch, loss=1.18, accuracy=0.744, val_loss=1.72, val_accuracy=0.56, lr=0.1] 26%|██▌       | 23/88 [10:01<26:08, 24.13s/epoch, loss=1.19, accuracy=0.741, val_loss=2.02, val_accuracy=0.48, lr=0.1] 27%|██▋       | 24/88 [10:25<25:35, 23.99s/epoch, loss=1.18, accuracy=0.745, val_loss=2.27, val_accuracy=0.433, lr=0.1] 28%|██▊       | 25/88 [10:50<25:33, 24.34s/epoch, loss=1.17, accuracy=0.746, val_loss=3.83, val_accuracy=0.343, lr=0.0316] 30%|██▉       | 26/88 [11:14<25:12, 24.39s/epoch, loss=1.18, accuracy=0.745, val_loss=1.88, val_accuracy=0.514, lr=0.1]    31%|███       | 27/88 [11:38<24:30, 24.11s/epoch, loss=1.17, accuracy=0.746, val_loss=2.9, val_accuracy=0.331, lr=0.1]  32%|███▏      | 28/88 [12:01<24:00, 24.01s/epoch, loss=1.17, accuracy=0.748, val_loss=1.44, val_accuracy=0.636, lr=0.1] 33%|███▎      | 29/88 [12:25<23:27, 23.86s/epoch, loss=1.17, accuracy=0.75, val_loss=4.04, val_accuracy=0.28, lr=0.1]   34%|███▍      | 30/88 [12:49<23:12, 24.02s/epoch, loss=1.17, accuracy=0.748, val_loss=1.74, val_accuracy=0.561, lr=0.1] 35%|███▌      | 31/88 [13:13<22:41, 23.89s/epoch, loss=1.18, accuracy=0.747, val_loss=2.1, val_accuracy=0.476, lr=0.1]  36%|███▋      | 32/88 [13:37<22:13, 23.81s/epoch, loss=1.16, accuracy=0.749, val_loss=2.15, val_accuracy=0.533, lr=0.1] 38%|███▊      | 33/88 [14:00<21:46, 23.75s/epoch, loss=1.16, accuracy=0.749, val_loss=2.03, val_accuracy=0.47, lr=0.0316] 39%|███▊      | 34/88 [14:25<21:34, 23.96s/epoch, loss=1.17, accuracy=0.748, val_loss=1.88, val_accuracy=0.542, lr=0.1]   40%|███▉      | 35/88 [14:50<21:37, 24.49s/epoch, loss=1.16, accuracy=0.748, val_loss=2.04, val_accuracy=0.479, lr=0.1] 41%|████      | 36/88 [15:14<20:54, 24.13s/epoch, loss=1.16, accuracy=0.751, val_loss=2.55, val_accuracy=0.382, lr=0.1] 42%|████▏     | 37/88 [15:40<21:09, 24.89s/epoch, loss=1.16, accuracy=0.748, val_loss=1.52, val_accuracy=0.627, lr=0.1] 43%|████▎     | 38/88 [16:05<20:44, 24.89s/epoch, loss=1.16, accuracy=0.751, val_loss=1.53, val_accuracy=0.595, lr=0.0316] 44%|████▍     | 39/88 [16:29<19:58, 24.46s/epoch, loss=1.16, accuracy=0.749, val_loss=2.27, val_accuracy=0.49, lr=0.1]     45%|████▌     | 40/88 [16:52<19:19, 24.15s/epoch, loss=1.15, accuracy=0.751, val_loss=1.76, val_accuracy=0.536, lr=0.1] 47%|████▋     | 41/88 [17:15<18:40, 23.84s/epoch, loss=1.16, accuracy=0.751, val_loss=2.25, val_accuracy=0.483, lr=0.1] 48%|████▊     | 42/88 [17:40<18:23, 24.00s/epoch, loss=1.16, accuracy=0.75, val_loss=3.22, val_accuracy=0.294, lr=0.1]  49%|████▉     | 43/88 [18:06<18:34, 24.76s/epoch, loss=1.15, accuracy=0.753, val_loss=2.39, val_accuracy=0.451, lr=0.0316] 50%|█████     | 44/88 [18:30<18:03, 24.63s/epoch, loss=1.15, accuracy=0.753, val_loss=2.41, val_accuracy=0.418, lr=0.1]    51%|█████     | 45/88 [18:56<17:57, 25.06s/epoch, loss=1.16, accuracy=0.751, val_loss=3.12, val_accuracy=0.319, lr=0.1] 52%|█████▏    | 46/88 [19:23<17:46, 25.39s/epoch, loss=1.15, accuracy=0.752, val_loss=2.02, val_accuracy=0.541, lr=0.1] 53%|█████▎    | 47/88 [19:47<17:03, 24.96s/epoch, loss=1.14, accuracy=0.756, val_loss=1.76, val_accuracy=0.611, lr=0.1] 55%|█████▍    | 48/88 [20:10<16:17, 24.43s/epoch, loss=1.15, accuracy=0.752, val_loss=1.77, val_accuracy=0.564, lr=0.0316] 56%|█████▌    | 49/88 [20:33<15:38, 24.06s/epoch, loss=1.15, accuracy=0.752, val_loss=3.56, val_accuracy=0.287, lr=0.1]    57%|█████▋    | 50/88 [20:56<15:01, 23.72s/epoch, loss=1.14, accuracy=0.754, val_loss=2.4, val_accuracy=0.42, lr=0.1]   58%|█████▊    | 51/88 [21:20<14:39, 23.77s/epoch, loss=1.14, accuracy=0.753, val_loss=1.73, val_accuracy=0.568, lr=0.1] 59%|█████▉    | 52/88 [21:44<14:15, 23.77s/epoch, loss=1.15, accuracy=0.752, val_loss=4.75, val_accuracy=0.189, lr=0.1] 60%|██████    | 53/88 [22:07<13:53, 23.81s/epoch, loss=1.15, accuracy=0.753, val_loss=1.41, val_accuracy=0.657, lr=0.1] 61%|██████▏   | 54/88 [22:31<13:28, 23.78s/epoch, loss=1.15, accuracy=0.752, val_loss=2.8, val_accuracy=0.41, lr=0.1]   62%|██████▎   | 55/88 [22:55<13:00, 23.66s/epoch, loss=1.15, accuracy=0.752, val_loss=2.47, val_accuracy=0.359, lr=0.1] 64%|██████▎   | 56/88 [23:17<12:29, 23.43s/epoch, loss=1.15, accuracy=0.753, val_loss=1.56, val_accuracy=0.626, lr=0.1] 65%|██████▍   | 57/88 [23:40<12:01, 23.27s/epoch, loss=1.14, accuracy=0.749, val_loss=1.63, val_accuracy=0.575, lr=0.1] 66%|██████▌   | 58/88 [24:05<11:46, 23.56s/epoch, loss=1.14, accuracy=0.753, val_loss=2.19, val_accuracy=0.48, lr=0.0316] 67%|██████▋   | 59/88 [24:29<11:32, 23.86s/epoch, loss=1.14, accuracy=0.754, val_loss=1.83, val_accuracy=0.509, lr=0.1]   68%|██████▊   | 60/88 [24:53<11:10, 23.94s/epoch, loss=1.15, accuracy=0.753, val_loss=1.66, val_accuracy=0.576, lr=0.1] 69%|██████▉   | 61/88 [25:17<10:48, 24.03s/epoch, loss=1.14, accuracy=0.752, val_loss=3.78, val_accuracy=0.232, lr=0.1] 70%|███████   | 62/88 [25:41<10:20, 23.85s/epoch, loss=1.14, accuracy=0.755, val_loss=2.51, val_accuracy=0.382, lr=0.1] 72%|███████▏  | 63/88 [26:06<10:04, 24.18s/epoch, loss=1.14, accuracy=0.756, val_loss=1.94, val_accuracy=0.477, lr=0.0316] 73%|███████▎  | 64/88 [26:32<09:55, 24.82s/epoch, loss=1.14, accuracy=0.753, val_loss=3.13, val_accuracy=0.203, lr=0.1]    74%|███████▍  | 65/88 [26:58<09:38, 25.14s/epoch, loss=1.14, accuracy=0.755, val_loss=2.74, val_accuracy=0.257, lr=0.1] 75%|███████▌  | 66/88 [27:22<09:05, 24.78s/epoch, loss=1.14, accuracy=0.754, val_loss=2.66, val_accuracy=0.301, lr=0.1] 76%|███████▌  | 67/88 [27:48<08:48, 25.15s/epoch, loss=1.14, accuracy=0.756, val_loss=2.41, val_accuracy=0.472, lr=0.1] 77%|███████▋  | 68/88 [28:11<08:12, 24.62s/epoch, loss=1.13, accuracy=0.756, val_loss=2.95, val_accuracy=0.354, lr=0.0316] 78%|███████▊  | 69/88 [28:37<07:53, 24.91s/epoch, loss=1.13, accuracy=0.756, val_loss=1.72, val_accuracy=0.555, lr=0.1]    80%|███████▉  | 70/88 [29:02<07:27, 24.86s/epoch, loss=1.13, accuracy=0.754, val_loss=6.56, val_accuracy=0.216, lr=0.1] 81%|████████  | 71/88 [29:27<07:02, 24.86s/epoch, loss=1.13, accuracy=0.757, val_loss=1.63, val_accuracy=0.595, lr=0.1] 82%|████████▏ | 72/88 [29:53<06:44, 25.27s/epoch, loss=1.13, accuracy=0.753, val_loss=1.62, val_accuracy=0.573, lr=0.1] 83%|████████▎ | 73/88 [30:17<06:13, 24.88s/epoch, loss=1.12, accuracy=0.758, val_loss=1.73, val_accuracy=0.547, lr=0.0316] 84%|████████▍ | 74/88 [30:42<05:48, 24.91s/epoch, loss=1.14, accuracy=0.754, val_loss=1.6, val_accuracy=0.595, lr=0.1]     85%|████████▌ | 75/88 [31:08<05:29, 25.33s/epoch, loss=1.13, accuracy=0.753, val_loss=3.13, val_accuracy=0.324, lr=0.1] 86%|████████▋ | 76/88 [31:32<04:59, 24.92s/epoch, loss=1.14, accuracy=0.755, val_loss=2.35, val_accuracy=0.445, lr=0.1] 88%|████████▊ | 77/88 [31:58<04:36, 25.14s/epoch, loss=1.13, accuracy=0.756, val_loss=2.12, val_accuracy=0.483, lr=0.1] 89%|████████▊ | 78/88 [32:22<04:10, 25.03s/epoch, loss=1.13, accuracy=0.757, val_loss=2.12, val_accuracy=0.475, lr=0.0316] 90%|████████▉ | 79/88 [32:49<03:47, 25.33s/epoch, loss=1.12, accuracy=0.756, val_loss=3.81, val_accuracy=0.281, lr=0.1]    91%|█████████ | 80/88 [33:13<03:19, 24.94s/epoch, loss=1.13, accuracy=0.757, val_loss=2.65, val_accuracy=0.373, lr=0.1] 92%|█████████▏| 81/88 [33:39<02:57, 25.35s/epoch, loss=1.13, accuracy=0.755, val_loss=1.84, val_accuracy=0.543, lr=0.1] 93%|█████████▎| 82/88 [34:02<02:28, 24.71s/epoch, loss=0.914, accuracy=0.814, val_loss=0.92, val_accuracy=0.791, lr=0.01] 94%|█████████▍| 83/88 [34:25<02:01, 24.24s/epoch, loss=0.735, accuracy=0.845, val_loss=0.809, val_accuracy=0.807, lr=0.01] 95%|█████████▌| 84/88 [34:51<01:38, 24.66s/epoch, loss=0.657, accuracy=0.853, val_loss=0.731, val_accuracy=0.819, lr=0.01] 97%|█████████▋| 85/88 [35:14<01:12, 24.26s/epoch, loss=0.612, accuracy=0.857, val_loss=0.839, val_accuracy=0.784, lr=0.01] 98%|█████████▊| 86/88 [35:40<00:49, 24.78s/epoch, loss=0.591, accuracy=0.858, val_loss=0.803, val_accuracy=0.787, lr=0.01] 99%|█████████▉| 87/88 [36:05<00:24, 24.71s/epoch, loss=0.584, accuracy=0.858, val_loss=0.752, val_accuracy=0.803, lr=0.01]100%|██████████| 88/88 [36:30<00:00, 24.79s/epoch, loss=0.576, accuracy=0.861, val_loss=0.751, val_accuracy=0.804, lr=0.01]100%|██████████| 88/88 [36:30<00:00, 24.89s/epoch, loss=0.576, accuracy=0.861, val_loss=0.751, val_accuracy=0.804, lr=0.01]
Using real-time data augmentation.
Test loss: 0.7505055069923401
Test accuracy: 0.803600013256073


* * * Run SGD for ID = 17_8. * * *


2024-02-15 18:20:07.026104: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 18:20:09.850847: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 18:20:09.852096: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-15 18:20:09.890189: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 18:20:09.890226: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 18:20:09.893097: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 18:20:09.893143: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 18:20:09.895370: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 18:20:09.896022: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 18:20:09.898593: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 18:20:09.900249: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 18:20:09.905194: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 18:20:09.905786: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 18:20:09.905875: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 18:20:11.212755: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-15 18:20:11.213852: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 18:20:11.214327: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 18:20:11.214361: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 18:20:11.214395: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 18:20:11.214415: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 18:20:11.214438: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 18:20:11.214456: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 18:20:11.214474: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 18:20:11.214492: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 18:20:11.214510: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 18:20:11.215045: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 18:20:11.215082: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 18:20:11.902185: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-15 18:20:11.902264: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-15 18:20:11.902284: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-15 18:20:11.903668: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': 178, 'batch_size': 128, 'epochs': 88, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/88 [00:00<?, ?epoch/s]2024-02-15 18:20:12.743581: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-15 18:20:12.755810: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199950000 Hz
2024-02-15 18:20:15.008123: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 18:20:15.276893: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 18:20:16.165765: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-15 18:20:16.256310: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/88 [01:03<1:31:50, 63.33s/epoch, loss=3.19, accuracy=0.316, val_loss=2.34, val_accuracy=0.265, lr=0.1]  2%|▏         | 2/88 [01:29<59:03, 41.20s/epoch, loss=1.61, accuracy=0.515, val_loss=2.02, val_accuracy=0.435, lr=0.1]    3%|▎         | 3/88 [01:54<47:55, 33.83s/epoch, loss=1.4, accuracy=0.615, val_loss=1.57, val_accuracy=0.555, lr=0.1]   5%|▍         | 4/88 [02:18<42:18, 30.23s/epoch, loss=1.32, accuracy=0.663, val_loss=1.65, val_accuracy=0.564, lr=0.1]  6%|▌         | 5/88 [02:43<38:51, 28.09s/epoch, loss=1.28, accuracy=0.691, val_loss=1.68, val_accuracy=0.528, lr=0.1]  7%|▋         | 6/88 [03:08<37:18, 27.30s/epoch, loss=1.26, accuracy=0.704, val_loss=2.31, val_accuracy=0.394, lr=0.1]  8%|▊         | 7/88 [03:35<36:30, 27.04s/epoch, loss=1.24, accuracy=0.714, val_loss=1.91, val_accuracy=0.553, lr=0.1]  9%|▉         | 8/88 [04:01<35:51, 26.89s/epoch, loss=1.23, accuracy=0.718, val_loss=2.01, val_accuracy=0.508, lr=0.0316] 10%|█         | 9/88 [04:29<35:31, 26.99s/epoch, loss=1.23, accuracy=0.724, val_loss=1.66, val_accuracy=0.6, lr=0.1]      11%|█▏        | 10/88 [04:53<33:55, 26.10s/epoch, loss=1.23, accuracy=0.724, val_loss=1.76, val_accuracy=0.573, lr=0.1] 12%|█▎        | 11/88 [05:17<32:34, 25.38s/epoch, loss=1.21, accuracy=0.73, val_loss=1.88, val_accuracy=0.52, lr=0.1]   14%|█▎        | 12/88 [05:41<31:44, 25.06s/epoch, loss=1.21, accuracy=0.732, val_loss=2.08, val_accuracy=0.505, lr=0.1] 15%|█▍        | 13/88 [06:05<30:48, 24.65s/epoch, loss=1.21, accuracy=0.734, val_loss=2.04, val_accuracy=0.501, lr=0.0316] 16%|█▌        | 14/88 [06:30<30:38, 24.85s/epoch, loss=1.21, accuracy=0.736, val_loss=2, val_accuracy=0.484, lr=0.1]       17%|█▋        | 15/88 [06:54<30:04, 24.71s/epoch, loss=1.2, accuracy=0.738, val_loss=1.91, val_accuracy=0.549, lr=0.1] 18%|█▊        | 16/88 [07:20<30:12, 25.17s/epoch, loss=1.19, accuracy=0.738, val_loss=1.87, val_accuracy=0.53, lr=0.1] 19%|█▉        | 17/88 [07:45<29:38, 25.05s/epoch, loss=1.19, accuracy=0.739, val_loss=2.26, val_accuracy=0.518, lr=0.1] 20%|██        | 18/88 [08:09<28:43, 24.63s/epoch, loss=1.19, accuracy=0.742, val_loss=1.92, val_accuracy=0.527, lr=0.0316] 22%|██▏       | 19/88 [08:35<28:44, 25.00s/epoch, loss=1.19, accuracy=0.742, val_loss=2.06, val_accuracy=0.527, lr=0.1]    23%|██▎       | 20/88 [08:59<28:02, 24.74s/epoch, loss=1.18, accuracy=0.743, val_loss=2.86, val_accuracy=0.4, lr=0.1]   24%|██▍       | 21/88 [09:22<27:12, 24.37s/epoch, loss=1.18, accuracy=0.742, val_loss=1.85, val_accuracy=0.5, lr=0.1] 25%|██▌       | 22/88 [09:48<27:18, 24.83s/epoch, loss=1.18, accuracy=0.746, val_loss=2.01, val_accuracy=0.455, lr=0.1] 26%|██▌       | 23/88 [10:14<27:02, 24.96s/epoch, loss=1.18, accuracy=0.742, val_loss=2.32, val_accuracy=0.514, lr=0.0316] 27%|██▋       | 24/88 [10:38<26:24, 24.76s/epoch, loss=1.18, accuracy=0.747, val_loss=1.61, val_accuracy=0.61, lr=0.1]     28%|██▊       | 25/88 [11:02<25:54, 24.67s/epoch, loss=1.17, accuracy=0.744, val_loss=2.25, val_accuracy=0.503, lr=0.1] 30%|██▉       | 26/88 [11:28<25:51, 25.03s/epoch, loss=1.17, accuracy=0.748, val_loss=1.93, val_accuracy=0.493, lr=0.1] 31%|███       | 27/88 [11:54<25:45, 25.34s/epoch, loss=1.17, accuracy=0.744, val_loss=1.69, val_accuracy=0.581, lr=0.1] 32%|███▏      | 28/88 [12:21<25:41, 25.69s/epoch, loss=1.16, accuracy=0.75, val_loss=2.93, val_accuracy=0.349, lr=0.0316] 33%|███▎      | 29/88 [12:46<25:04, 25.50s/epoch, loss=1.17, accuracy=0.749, val_loss=2.34, val_accuracy=0.491, lr=0.1]   34%|███▍      | 30/88 [13:11<24:26, 25.29s/epoch, loss=1.16, accuracy=0.75, val_loss=3.88, val_accuracy=0.341, lr=0.1]  35%|███▌      | 31/88 [13:36<24:06, 25.38s/epoch, loss=1.16, accuracy=0.748, val_loss=1.5, val_accuracy=0.636, lr=0.1] 36%|███▋      | 32/88 [14:02<23:51, 25.56s/epoch, loss=1.16, accuracy=0.748, val_loss=1.79, val_accuracy=0.579, lr=0.1] 38%|███▊      | 33/88 [14:26<22:55, 25.02s/epoch, loss=1.15, accuracy=0.752, val_loss=2.29, val_accuracy=0.429, lr=0.1] 39%|███▊      | 34/88 [14:52<22:49, 25.35s/epoch, loss=1.16, accuracy=0.749, val_loss=1.97, val_accuracy=0.449, lr=0.1] 40%|███▉      | 35/88 [15:19<22:41, 25.69s/epoch, loss=1.16, accuracy=0.752, val_loss=1.35, val_accuracy=0.682, lr=0.1] 41%|████      | 36/88 [15:44<22:14, 25.66s/epoch, loss=1.15, accuracy=0.752, val_loss=1.83, val_accuracy=0.522, lr=0.1] 42%|████▏     | 37/88 [16:10<21:46, 25.62s/epoch, loss=1.15, accuracy=0.75, val_loss=2.48, val_accuracy=0.407, lr=0.1]  43%|████▎     | 38/88 [16:35<21:18, 25.56s/epoch, loss=1.15, accuracy=0.751, val_loss=2.29, val_accuracy=0.446, lr=0.1] 44%|████▍     | 39/88 [17:00<20:49, 25.50s/epoch, loss=1.15, accuracy=0.75, val_loss=2.29, val_accuracy=0.426, lr=0.1]  45%|████▌     | 40/88 [17:26<20:26, 25.55s/epoch, loss=1.15, accuracy=0.752, val_loss=1.51, val_accuracy=0.614, lr=0.0316] 47%|████▋     | 41/88 [17:50<19:34, 24.99s/epoch, loss=1.15, accuracy=0.75, val_loss=1.94, val_accuracy=0.56, lr=0.1]      48%|████▊     | 42/88 [18:16<19:33, 25.50s/epoch, loss=1.15, accuracy=0.754, val_loss=2.14, val_accuracy=0.481, lr=0.1] 49%|████▉     | 43/88 [18:42<19:03, 25.42s/epoch, loss=1.15, accuracy=0.754, val_loss=1.82, val_accuracy=0.547, lr=0.1] 50%|█████     | 44/88 [19:08<18:45, 25.59s/epoch, loss=1.15, accuracy=0.749, val_loss=1.7, val_accuracy=0.541, lr=0.1]  51%|█████     | 45/88 [19:32<17:57, 25.06s/epoch, loss=1.15, accuracy=0.751, val_loss=1.43, val_accuracy=0.663, lr=0.0316] 52%|█████▏    | 46/88 [19:59<17:58, 25.69s/epoch, loss=1.15, accuracy=0.751, val_loss=2.09, val_accuracy=0.51, lr=0.1]     53%|█████▎    | 47/88 [20:24<17:27, 25.55s/epoch, loss=1.16, accuracy=0.752, val_loss=1.69, val_accuracy=0.582, lr=0.1] 55%|█████▍    | 48/88 [20:50<17:08, 25.72s/epoch, loss=1.14, accuracy=0.755, val_loss=3.07, val_accuracy=0.348, lr=0.1] 56%|█████▌    | 49/88 [21:16<16:48, 25.86s/epoch, loss=1.15, accuracy=0.751, val_loss=1.69, val_accuracy=0.58, lr=0.1]  57%|█████▋    | 50/88 [21:41<16:07, 25.45s/epoch, loss=1.15, accuracy=0.754, val_loss=2.99, val_accuracy=0.382, lr=0.0316] 58%|█████▊    | 51/88 [22:06<15:39, 25.40s/epoch, loss=1.15, accuracy=0.752, val_loss=1.57, val_accuracy=0.595, lr=0.1]    59%|█████▉    | 52/88 [22:30<14:56, 24.91s/epoch, loss=1.15, accuracy=0.75, val_loss=1.87, val_accuracy=0.482, lr=0.1]  60%|██████    | 53/88 [22:57<14:52, 25.49s/epoch, loss=1.15, accuracy=0.755, val_loss=2.27, val_accuracy=0.417, lr=0.1] 61%|██████▏   | 54/88 [23:21<14:14, 25.12s/epoch, loss=1.14, accuracy=0.755, val_loss=1.67, val_accuracy=0.589, lr=0.1] 62%|██████▎   | 55/88 [23:44<13:32, 24.63s/epoch, loss=1.15, accuracy=0.75, val_loss=1.57, val_accuracy=0.591, lr=0.0316] 64%|██████▎   | 56/88 [24:09<13:09, 24.67s/epoch, loss=1.14, accuracy=0.756, val_loss=2.06, val_accuracy=0.542, lr=0.1]   65%|██████▍   | 57/88 [24:34<12:47, 24.75s/epoch, loss=1.14, accuracy=0.753, val_loss=2, val_accuracy=0.515, lr=0.1]    66%|██████▌   | 58/88 [24:59<12:27, 24.93s/epoch, loss=1.15, accuracy=0.754, val_loss=2.76, val_accuracy=0.383, lr=0.1] 67%|██████▋   | 59/88 [25:24<11:58, 24.78s/epoch, loss=1.14, accuracy=0.753, val_loss=1.8, val_accuracy=0.592, lr=0.1]  68%|██████▊   | 60/88 [25:50<11:48, 25.31s/epoch, loss=1.13, accuracy=0.757, val_loss=2.01, val_accuracy=0.569, lr=0.0316] 69%|██████▉   | 61/88 [26:17<11:33, 25.70s/epoch, loss=1.15, accuracy=0.752, val_loss=2.05, val_accuracy=0.466, lr=0.1]    70%|███████   | 62/88 [26:41<10:54, 25.19s/epoch, loss=1.13, accuracy=0.757, val_loss=2.04, val_accuracy=0.495, lr=0.1] 72%|███████▏  | 63/88 [27:05<10:18, 24.73s/epoch, loss=1.14, accuracy=0.756, val_loss=2.7, val_accuracy=0.47, lr=0.1]   73%|███████▎  | 64/88 [27:31<10:05, 25.22s/epoch, loss=1.14, accuracy=0.757, val_loss=2.62, val_accuracy=0.365, lr=0.1] 74%|███████▍  | 65/88 [27:56<09:38, 25.14s/epoch, loss=1.14, accuracy=0.753, val_loss=1.9, val_accuracy=0.536, lr=0.0316] 75%|███████▌  | 66/88 [28:22<09:17, 25.34s/epoch, loss=1.15, accuracy=0.754, val_loss=2.42, val_accuracy=0.48, lr=0.1]    76%|███████▌  | 67/88 [28:45<08:41, 24.83s/epoch, loss=1.14, accuracy=0.753, val_loss=1.79, val_accuracy=0.507, lr=0.1] 77%|███████▋  | 68/88 [29:11<08:18, 24.93s/epoch, loss=1.14, accuracy=0.755, val_loss=1.93, val_accuracy=0.519, lr=0.1] 78%|███████▊  | 69/88 [29:35<07:48, 24.66s/epoch, loss=1.13, accuracy=0.755, val_loss=1.89, val_accuracy=0.521, lr=0.1] 80%|███████▉  | 70/88 [30:01<07:34, 25.23s/epoch, loss=1.14, accuracy=0.755, val_loss=2.32, val_accuracy=0.356, lr=0.0316] 81%|████████  | 71/88 [30:28<07:14, 25.59s/epoch, loss=1.14, accuracy=0.755, val_loss=2.34, val_accuracy=0.45, lr=0.1]     82%|████████▏ | 72/88 [30:54<06:55, 25.95s/epoch, loss=1.13, accuracy=0.755, val_loss=2.05, val_accuracy=0.46, lr=0.1] 83%|████████▎ | 73/88 [31:21<06:31, 26.11s/epoch, loss=1.13, accuracy=0.759, val_loss=2.34, val_accuracy=0.394, lr=0.1] 84%|████████▍ | 74/88 [31:46<06:02, 25.92s/epoch, loss=1.13, accuracy=0.757, val_loss=2.72, val_accuracy=0.348, lr=0.1] 85%|████████▌ | 75/88 [32:12<05:35, 25.80s/epoch, loss=1.14, accuracy=0.753, val_loss=2.17, val_accuracy=0.445, lr=0.0316] 86%|████████▋ | 76/88 [32:38<05:10, 25.89s/epoch, loss=1.14, accuracy=0.753, val_loss=1.69, val_accuracy=0.562, lr=0.1]    88%|████████▊ | 77/88 [33:02<04:37, 25.20s/epoch, loss=1.14, accuracy=0.755, val_loss=2.23, val_accuracy=0.482, lr=0.1] 89%|████████▊ | 78/88 [33:26<04:09, 24.98s/epoch, loss=1.14, accuracy=0.754, val_loss=2.07, val_accuracy=0.495, lr=0.1] 90%|████████▉ | 79/88 [33:50<03:43, 24.83s/epoch, loss=1.13, accuracy=0.756, val_loss=1.6, val_accuracy=0.592, lr=0.1]  91%|█████████ | 80/88 [34:16<03:21, 25.13s/epoch, loss=1.14, accuracy=0.754, val_loss=1.6, val_accuracy=0.616, lr=0.0316] 92%|█████████▏| 81/88 [34:42<02:57, 25.40s/epoch, loss=1.13, accuracy=0.756, val_loss=1.56, val_accuracy=0.6, lr=0.1]     93%|█████████▎| 82/88 [35:09<02:34, 25.73s/epoch, loss=0.928, accuracy=0.812, val_loss=0.882, val_accuracy=0.809, lr=0.01] 94%|█████████▍| 83/88 [35:33<02:06, 25.39s/epoch, loss=0.743, accuracy=0.844, val_loss=0.888, val_accuracy=0.791, lr=0.01] 95%|█████████▌| 84/88 [36:00<01:43, 25.79s/epoch, loss=0.658, accuracy=0.855, val_loss=0.793, val_accuracy=0.803, lr=0.01] 97%|█████████▋| 85/88 [36:24<01:15, 25.31s/epoch, loss=0.612, accuracy=0.858, val_loss=0.783, val_accuracy=0.799, lr=0.01] 98%|█████████▊| 86/88 [36:51<00:51, 25.77s/epoch, loss=0.591, accuracy=0.86, val_loss=0.775, val_accuracy=0.794, lr=0.01]  99%|█████████▉| 87/88 [37:15<00:25, 25.12s/epoch, loss=0.577, accuracy=0.861, val_loss=0.753, val_accuracy=0.806, lr=0.01]100%|██████████| 88/88 [37:40<00:00, 25.02s/epoch, loss=0.576, accuracy=0.861, val_loss=0.71, val_accuracy=0.817, lr=0.01] 100%|██████████| 88/88 [37:40<00:00, 25.68s/epoch, loss=0.576, accuracy=0.861, val_loss=0.71, val_accuracy=0.817, lr=0.01]
Using real-time data augmentation.
Test loss: 0.7102928757667542
Test accuracy: 0.8172000050544739


* * * Run SGD for ID = 17_9. * * *


2024-02-15 18:57:55.869702: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 18:57:58.748090: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 18:57:58.749317: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-15 18:57:58.790041: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 18:57:58.790078: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 18:57:58.793242: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 18:57:58.793284: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 18:57:58.795826: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 18:57:58.796559: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 18:57:58.799222: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 18:57:58.800785: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 18:57:58.805813: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 18:57:58.806405: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 18:57:58.806482: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 18:58:00.233633: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-15 18:58:00.234195: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 18:58:00.234659: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 18:58:00.234711: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 18:58:00.234748: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 18:58:00.234768: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 18:58:00.234786: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 18:58:00.234804: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 18:58:00.234822: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 18:58:00.234839: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 18:58:00.234857: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 18:58:00.235371: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 18:58:00.235408: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 18:58:00.964287: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-15 18:58:00.964349: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-15 18:58:00.964375: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-15 18:58:00.965782: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': 179, 'batch_size': 128, 'epochs': 88, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/88 [00:00<?, ?epoch/s]2024-02-15 18:58:01.827415: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-15 18:58:01.839784: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199950000 Hz
2024-02-15 18:58:04.137586: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 18:58:04.437329: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 18:58:05.761241: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-15 18:58:05.821574: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/88 [01:10<1:42:51, 70.93s/epoch, loss=3.14, accuracy=0.315, val_loss=2.62, val_accuracy=0.193, lr=0.1]  2%|▏         | 2/88 [01:35<1:02:24, 43.54s/epoch, loss=1.67, accuracy=0.475, val_loss=1.96, val_accuracy=0.393, lr=0.1]  3%|▎         | 3/88 [02:00<49:49, 35.17s/epoch, loss=1.5, accuracy=0.56, val_loss=2.09, val_accuracy=0.428, lr=0.1]      5%|▍         | 4/88 [02:25<43:24, 31.01s/epoch, loss=1.41, accuracy=0.622, val_loss=2.6, val_accuracy=0.393, lr=0.1]  6%|▌         | 5/88 [02:50<39:57, 28.89s/epoch, loss=1.34, accuracy=0.667, val_loss=1.93, val_accuracy=0.519, lr=0.1]  7%|▋         | 6/88 [03:14<37:14, 27.25s/epoch, loss=1.29, accuracy=0.693, val_loss=1.68, val_accuracy=0.572, lr=0.1]  8%|▊         | 7/88 [03:40<36:11, 26.81s/epoch, loss=1.26, accuracy=0.71, val_loss=1.75, val_accuracy=0.549, lr=0.1]   9%|▉         | 8/88 [04:04<34:34, 25.93s/epoch, loss=1.24, accuracy=0.718, val_loss=1.95, val_accuracy=0.53, lr=0.1] 10%|█         | 9/88 [04:28<33:14, 25.25s/epoch, loss=1.23, accuracy=0.723, val_loss=2, val_accuracy=0.497, lr=0.1]   11%|█▏        | 10/88 [04:51<32:14, 24.81s/epoch, loss=1.22, accuracy=0.728, val_loss=1.51, val_accuracy=0.628, lr=0.1] 12%|█▎        | 11/88 [05:17<32:13, 25.12s/epoch, loss=1.22, accuracy=0.732, val_loss=2.74, val_accuracy=0.393, lr=0.1] 14%|█▎        | 12/88 [05:44<32:36, 25.74s/epoch, loss=1.21, accuracy=0.734, val_loss=1.9, val_accuracy=0.518, lr=0.1]  15%|█▍        | 13/88 [06:11<32:33, 26.04s/epoch, loss=1.21, accuracy=0.736, val_loss=1.83, val_accuracy=0.562, lr=0.1] 16%|█▌        | 14/88 [06:38<32:16, 26.17s/epoch, loss=1.2, accuracy=0.739, val_loss=1.44, val_accuracy=0.648, lr=0.1]  17%|█▋        | 15/88 [07:04<31:53, 26.22s/epoch, loss=1.2, accuracy=0.738, val_loss=1.99, val_accuracy=0.446, lr=0.1] 18%|█▊        | 16/88 [07:29<31:11, 25.99s/epoch, loss=1.2, accuracy=0.74, val_loss=1.83, val_accuracy=0.53, lr=0.1]   19%|█▉        | 17/88 [07:54<30:17, 25.59s/epoch, loss=1.2, accuracy=0.741, val_loss=1.55, val_accuracy=0.626, lr=0.1] 20%|██        | 18/88 [08:19<29:30, 25.29s/epoch, loss=1.19, accuracy=0.742, val_loss=1.9, val_accuracy=0.524, lr=0.1] 22%|██▏       | 19/88 [08:44<29:15, 25.45s/epoch, loss=1.19, accuracy=0.744, val_loss=2.04, val_accuracy=0.451, lr=0.0316] 23%|██▎       | 20/88 [09:09<28:40, 25.31s/epoch, loss=1.18, accuracy=0.746, val_loss=2.32, val_accuracy=0.447, lr=0.1]    24%|██▍       | 21/88 [09:33<27:46, 24.87s/epoch, loss=1.18, accuracy=0.744, val_loss=2.72, val_accuracy=0.344, lr=0.1] 25%|██▌       | 22/88 [09:58<27:27, 24.96s/epoch, loss=1.18, accuracy=0.746, val_loss=2.23, val_accuracy=0.468, lr=0.1] 26%|██▌       | 23/88 [10:25<27:32, 25.43s/epoch, loss=1.17, accuracy=0.747, val_loss=3.52, val_accuracy=0.4, lr=0.1]   27%|██▋       | 24/88 [10:49<26:47, 25.12s/epoch, loss=1.18, accuracy=0.748, val_loss=1.88, val_accuracy=0.536, lr=0.0316] 28%|██▊       | 25/88 [11:16<26:56, 25.66s/epoch, loss=1.17, accuracy=0.75, val_loss=3.62, val_accuracy=0.3, lr=0.1]       30%|██▉       | 26/88 [11:43<26:45, 25.89s/epoch, loss=1.17, accuracy=0.748, val_loss=1.55, val_accuracy=0.622, lr=0.1] 31%|███       | 27/88 [12:08<26:06, 25.68s/epoch, loss=1.17, accuracy=0.752, val_loss=1.68, val_accuracy=0.609, lr=0.1] 32%|███▏      | 28/88 [12:35<26:04, 26.08s/epoch, loss=1.17, accuracy=0.751, val_loss=4.1, val_accuracy=0.25, lr=0.1]   33%|███▎      | 29/88 [12:59<24:57, 25.39s/epoch, loss=1.16, accuracy=0.752, val_loss=2.1, val_accuracy=0.514, lr=0.0316] 34%|███▍      | 30/88 [13:26<25:00, 25.87s/epoch, loss=1.16, accuracy=0.751, val_loss=2.41, val_accuracy=0.406, lr=0.1]   35%|███▌      | 31/88 [13:51<24:17, 25.58s/epoch, loss=1.17, accuracy=0.752, val_loss=2.09, val_accuracy=0.525, lr=0.1] 36%|███▋      | 32/88 [14:17<24:15, 26.00s/epoch, loss=1.16, accuracy=0.751, val_loss=1.92, val_accuracy=0.524, lr=0.1] 38%|███▊      | 33/88 [14:43<23:46, 25.94s/epoch, loss=1.16, accuracy=0.752, val_loss=1.91, val_accuracy=0.504, lr=0.1] 39%|███▊      | 34/88 [15:08<23:01, 25.58s/epoch, loss=1.16, accuracy=0.752, val_loss=1.99, val_accuracy=0.495, lr=0.0316] 40%|███▉      | 35/88 [15:34<22:46, 25.78s/epoch, loss=1.16, accuracy=0.75, val_loss=2.03, val_accuracy=0.49, lr=0.1]      41%|████      | 36/88 [15:59<21:56, 25.32s/epoch, loss=1.16, accuracy=0.752, val_loss=2.76, val_accuracy=0.366, lr=0.1] 42%|████▏     | 37/88 [16:24<21:34, 25.39s/epoch, loss=1.16, accuracy=0.751, val_loss=2.08, val_accuracy=0.503, lr=0.1] 43%|████▎     | 38/88 [16:51<21:31, 25.83s/epoch, loss=1.15, accuracy=0.752, val_loss=2.26, val_accuracy=0.438, lr=0.1] 44%|████▍     | 39/88 [17:17<21:15, 26.04s/epoch, loss=1.16, accuracy=0.753, val_loss=1.55, val_accuracy=0.62, lr=0.0316] 45%|████▌     | 40/88 [17:42<20:27, 25.57s/epoch, loss=1.15, accuracy=0.754, val_loss=2.43, val_accuracy=0.473, lr=0.1]   47%|████▋     | 41/88 [18:08<20:06, 25.68s/epoch, loss=1.14, accuracy=0.753, val_loss=2.62, val_accuracy=0.435, lr=0.1] 48%|████▊     | 42/88 [18:35<19:59, 26.09s/epoch, loss=1.15, accuracy=0.753, val_loss=2.15, val_accuracy=0.463, lr=0.1] 49%|████▉     | 43/88 [18:59<19:04, 25.43s/epoch, loss=1.15, accuracy=0.755, val_loss=1.9, val_accuracy=0.562, lr=0.1]  50%|█████     | 44/88 [19:23<18:29, 25.20s/epoch, loss=1.14, accuracy=0.754, val_loss=1.52, val_accuracy=0.645, lr=0.0316] 51%|█████     | 45/88 [19:50<18:25, 25.71s/epoch, loss=1.14, accuracy=0.754, val_loss=3.73, val_accuracy=0.29, lr=0.1]     52%|█████▏    | 46/88 [20:17<18:13, 26.04s/epoch, loss=1.14, accuracy=0.757, val_loss=3.11, val_accuracy=0.229, lr=0.1] 53%|█████▎    | 47/88 [20:44<17:55, 26.23s/epoch, loss=1.14, accuracy=0.754, val_loss=1.97, val_accuracy=0.524, lr=0.1] 55%|█████▍    | 48/88 [21:10<17:34, 26.35s/epoch, loss=1.14, accuracy=0.757, val_loss=2.98, val_accuracy=0.371, lr=0.1] 56%|█████▌    | 49/88 [21:37<17:08, 26.36s/epoch, loss=1.15, accuracy=0.753, val_loss=1.83, val_accuracy=0.492, lr=0.0316] 57%|█████▋    | 50/88 [22:01<16:17, 25.72s/epoch, loss=1.14, accuracy=0.756, val_loss=1.54, val_accuracy=0.607, lr=0.1]    58%|█████▊    | 51/88 [22:29<16:10, 26.24s/epoch, loss=1.14, accuracy=0.755, val_loss=2.03, val_accuracy=0.548, lr=0.1] 59%|█████▉    | 52/88 [22:56<15:57, 26.59s/epoch, loss=1.14, accuracy=0.753, val_loss=1.84, val_accuracy=0.508, lr=0.1] 60%|██████    | 53/88 [23:20<15:02, 25.78s/epoch, loss=1.13, accuracy=0.758, val_loss=2.81, val_accuracy=0.327, lr=0.1] 61%|██████▏   | 54/88 [23:45<14:28, 25.54s/epoch, loss=1.14, accuracy=0.753, val_loss=2.13, val_accuracy=0.507, lr=0.0316] 62%|██████▎   | 55/88 [24:10<13:56, 25.35s/epoch, loss=1.13, accuracy=0.756, val_loss=1.65, val_accuracy=0.566, lr=0.1]    64%|██████▎   | 56/88 [24:36<13:37, 25.55s/epoch, loss=1.13, accuracy=0.757, val_loss=1.61, val_accuracy=0.618, lr=0.1] 65%|██████▍   | 57/88 [25:01<13:07, 25.41s/epoch, loss=1.13, accuracy=0.758, val_loss=1.36, val_accuracy=0.683, lr=0.1] 66%|██████▌   | 58/88 [25:25<12:35, 25.18s/epoch, loss=1.13, accuracy=0.756, val_loss=1.9, val_accuracy=0.484, lr=0.1]  67%|██████▋   | 59/88 [25:49<12:00, 24.83s/epoch, loss=1.13, accuracy=0.755, val_loss=1.76, val_accuracy=0.546, lr=0.1] 68%|██████▊   | 60/88 [26:14<11:35, 24.82s/epoch, loss=1.13, accuracy=0.756, val_loss=2.27, val_accuracy=0.456, lr=0.1] 69%|██████▉   | 61/88 [26:40<11:20, 25.22s/epoch, loss=1.13, accuracy=0.756, val_loss=3.46, val_accuracy=0.415, lr=0.1] 70%|███████   | 62/88 [27:06<10:56, 25.24s/epoch, loss=1.13, accuracy=0.758, val_loss=1.63, val_accuracy=0.569, lr=0.0316] 72%|███████▏  | 63/88 [27:33<10:44, 25.77s/epoch, loss=1.13, accuracy=0.759, val_loss=1.71, val_accuracy=0.582, lr=0.1]    73%|███████▎  | 64/88 [27:58<10:18, 25.76s/epoch, loss=1.14, accuracy=0.756, val_loss=1.94, val_accuracy=0.55, lr=0.1]  74%|███████▍  | 65/88 [28:23<09:47, 25.53s/epoch, loss=1.13, accuracy=0.757, val_loss=3.15, val_accuracy=0.367, lr=0.1] 75%|███████▌  | 66/88 [28:50<09:27, 25.81s/epoch, loss=1.13, accuracy=0.756, val_loss=1.96, val_accuracy=0.527, lr=0.1] 76%|███████▌  | 67/88 [29:15<08:56, 25.56s/epoch, loss=1.13, accuracy=0.759, val_loss=3.29, val_accuracy=0.282, lr=0.0316] 77%|███████▋  | 68/88 [29:39<08:22, 25.12s/epoch, loss=1.12, accuracy=0.759, val_loss=2.53, val_accuracy=0.505, lr=0.1]    78%|███████▊  | 69/88 [30:04<07:57, 25.13s/epoch, loss=1.13, accuracy=0.757, val_loss=1.75, val_accuracy=0.527, lr=0.1] 80%|███████▉  | 70/88 [30:28<07:25, 24.75s/epoch, loss=1.13, accuracy=0.757, val_loss=1.8, val_accuracy=0.573, lr=0.1]  81%|████████  | 71/88 [30:54<07:07, 25.13s/epoch, loss=1.13, accuracy=0.758, val_loss=3.14, val_accuracy=0.424, lr=0.1] 82%|████████▏ | 72/88 [31:18<06:37, 24.84s/epoch, loss=1.12, accuracy=0.759, val_loss=1.52, val_accuracy=0.633, lr=0.0316] 83%|████████▎ | 73/88 [31:42<06:07, 24.48s/epoch, loss=1.13, accuracy=0.758, val_loss=2.35, val_accuracy=0.426, lr=0.1]    84%|████████▍ | 74/88 [32:07<05:43, 24.56s/epoch, loss=1.12, accuracy=0.758, val_loss=1.58, val_accuracy=0.587, lr=0.1] 85%|████████▌ | 75/88 [32:30<05:16, 24.33s/epoch, loss=1.12, accuracy=0.76, val_loss=1.92, val_accuracy=0.539, lr=0.1]  86%|████████▋ | 76/88 [32:55<04:53, 24.48s/epoch, loss=1.12, accuracy=0.76, val_loss=2.43, val_accuracy=0.388, lr=0.1] 88%|████████▊ | 77/88 [33:21<04:34, 24.96s/epoch, loss=1.12, accuracy=0.758, val_loss=2.67, val_accuracy=0.362, lr=0.0316] 89%|████████▊ | 78/88 [33:45<04:05, 24.59s/epoch, loss=1.13, accuracy=0.757, val_loss=3.17, val_accuracy=0.323, lr=0.1]    90%|████████▉ | 79/88 [34:10<03:42, 24.74s/epoch, loss=1.13, accuracy=0.758, val_loss=1.91, val_accuracy=0.52, lr=0.1]  91%|█████████ | 80/88 [34:34<03:15, 24.40s/epoch, loss=1.12, accuracy=0.759, val_loss=2.43, val_accuracy=0.467, lr=0.1] 92%|█████████▏| 81/88 [34:58<02:50, 24.38s/epoch, loss=1.12, accuracy=0.757, val_loss=9.36, val_accuracy=0.12, lr=0.1]  93%|█████████▎| 82/88 [35:24<02:29, 24.95s/epoch, loss=0.913, accuracy=0.816, val_loss=0.898, val_accuracy=0.804, lr=0.01] 94%|█████████▍| 83/88 [35:50<02:05, 25.06s/epoch, loss=0.727, accuracy=0.849, val_loss=0.801, val_accuracy=0.816, lr=0.01] 95%|█████████▌| 84/88 [36:14<01:38, 24.74s/epoch, loss=0.647, accuracy=0.858, val_loss=0.793, val_accuracy=0.804, lr=0.01] 97%|█████████▋| 85/88 [36:40<01:15, 25.25s/epoch, loss=0.601, accuracy=0.862, val_loss=0.832, val_accuracy=0.777, lr=0.01] 98%|█████████▊| 86/88 [37:07<00:51, 25.69s/epoch, loss=0.581, accuracy=0.862, val_loss=0.736, val_accuracy=0.809, lr=0.01] 99%|█████████▉| 87/88 [37:31<00:25, 25.21s/epoch, loss=0.572, accuracy=0.863, val_loss=0.722, val_accuracy=0.81, lr=0.01] 100%|██████████| 88/88 [37:58<00:00, 25.64s/epoch, loss=0.561, accuracy=0.867, val_loss=0.824, val_accuracy=0.789, lr=0.01]100%|██████████| 88/88 [37:58<00:00, 25.89s/epoch, loss=0.561, accuracy=0.867, val_loss=0.824, val_accuracy=0.789, lr=0.01]
Using real-time data augmentation.
Test loss: 0.8237597942352295
Test accuracy: 0.7886000275611877


* * * Run SGD for ID = 17_10. * * *


2024-02-15 19:36:02.522630: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 19:36:05.546852: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 19:36:05.548226: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-15 19:36:05.589208: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 19:36:05.589259: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 19:36:05.592254: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 19:36:05.592300: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 19:36:05.594687: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 19:36:05.595346: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 19:36:05.597823: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 19:36:05.599408: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 19:36:05.604383: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 19:36:05.605010: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 19:36:05.605089: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 19:36:06.962464: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-15 19:36:06.963600: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 19:36:06.964105: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 19:36:06.964151: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 19:36:06.964186: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 19:36:06.964222: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 19:36:06.964240: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 19:36:06.964257: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 19:36:06.964275: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 19:36:06.964292: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 19:36:06.964311: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 19:36:06.964823: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 19:36:06.964860: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 19:36:07.727658: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-15 19:36:07.727742: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-15 19:36:07.727763: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-15 19:36:07.729239: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': 1710, 'batch_size': 128, 'epochs': 88, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/88 [00:00<?, ?epoch/s]2024-02-15 19:36:08.588720: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-15 19:36:08.600821: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199950000 Hz
2024-02-15 19:36:10.876048: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 19:36:11.215755: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 19:36:12.075734: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-15 19:36:12.127797: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/88 [01:04<1:34:06, 64.90s/epoch, loss=3.83, accuracy=0.293, val_loss=3.5, val_accuracy=0.126, lr=0.1]  2%|▏         | 2/88 [01:31<1:00:39, 42.32s/epoch, loss=1.63, accuracy=0.511, val_loss=2.08, val_accuracy=0.396, lr=0.1]  3%|▎         | 3/88 [01:57<49:18, 34.80s/epoch, loss=1.4, accuracy=0.609, val_loss=1.74, val_accuracy=0.508, lr=0.1]     5%|▍         | 4/88 [02:23<44:05, 31.50s/epoch, loss=1.32, accuracy=0.656, val_loss=1.93, val_accuracy=0.498, lr=0.1]  6%|▌         | 5/88 [02:49<40:44, 29.46s/epoch, loss=1.28, accuracy=0.683, val_loss=1.78, val_accuracy=0.56, lr=0.1]   7%|▋         | 6/88 [03:16<39:09, 28.65s/epoch, loss=1.25, accuracy=0.699, val_loss=1.92, val_accuracy=0.518, lr=0.1]  8%|▊         | 7/88 [03:40<36:32, 27.06s/epoch, loss=1.24, accuracy=0.71, val_loss=1.76, val_accuracy=0.521, lr=0.1]   9%|▉         | 8/88 [04:06<35:49, 26.87s/epoch, loss=1.22, accuracy=0.718, val_loss=1.78, val_accuracy=0.521, lr=0.0316] 10%|█         | 9/88 [04:30<34:13, 25.99s/epoch, loss=1.2, accuracy=0.725, val_loss=1.62, val_accuracy=0.543, lr=0.1]     11%|█▏        | 10/88 [04:55<33:13, 25.56s/epoch, loss=1.21, accuracy=0.727, val_loss=1.99, val_accuracy=0.481, lr=0.1] 12%|█▎        | 11/88 [05:22<33:17, 25.95s/epoch, loss=1.21, accuracy=0.729, val_loss=2.01, val_accuracy=0.511, lr=0.1] 14%|█▎        | 12/88 [05:49<33:09, 26.17s/epoch, loss=1.2, accuracy=0.729, val_loss=1.7, val_accuracy=0.575, lr=0.1]   15%|█▍        | 13/88 [06:13<32:06, 25.68s/epoch, loss=1.18, accuracy=0.736, val_loss=2.17, val_accuracy=0.386, lr=0.1] 16%|█▌        | 14/88 [06:38<31:21, 25.43s/epoch, loss=1.17, accuracy=0.738, val_loss=2.41, val_accuracy=0.438, lr=0.0316] 17%|█▋        | 15/88 [07:04<31:15, 25.69s/epoch, loss=1.17, accuracy=0.742, val_loss=2.72, val_accuracy=0.391, lr=0.1]    18%|█▊        | 16/88 [07:28<30:12, 25.17s/epoch, loss=1.17, accuracy=0.742, val_loss=2.02, val_accuracy=0.511, lr=0.1] 19%|█▉        | 17/88 [07:54<30:08, 25.47s/epoch, loss=1.17, accuracy=0.742, val_loss=2.21, val_accuracy=0.485, lr=0.1] 20%|██        | 18/88 [08:21<30:13, 25.90s/epoch, loss=1.17, accuracy=0.742, val_loss=2.86, val_accuracy=0.447, lr=0.1] 22%|██▏       | 19/88 [08:47<29:37, 25.77s/epoch, loss=1.17, accuracy=0.743, val_loss=2.1, val_accuracy=0.463, lr=0.0316] 23%|██▎       | 20/88 [09:10<28:31, 25.16s/epoch, loss=1.16, accuracy=0.744, val_loss=2.5, val_accuracy=0.421, lr=0.1]    24%|██▍       | 21/88 [09:35<27:56, 25.02s/epoch, loss=1.16, accuracy=0.744, val_loss=1.49, val_accuracy=0.632, lr=0.1] 25%|██▌       | 22/88 [10:02<28:04, 25.53s/epoch, loss=1.16, accuracy=0.745, val_loss=2.23, val_accuracy=0.401, lr=0.1] 26%|██▌       | 23/88 [10:28<27:41, 25.56s/epoch, loss=1.15, accuracy=0.75, val_loss=1.48, val_accuracy=0.624, lr=0.1]  27%|██▋       | 24/88 [10:54<27:28, 25.76s/epoch, loss=1.15, accuracy=0.748, val_loss=1.63, val_accuracy=0.559, lr=0.1] 28%|██▊       | 25/88 [11:18<26:32, 25.27s/epoch, loss=1.15, accuracy=0.747, val_loss=3.11, val_accuracy=0.358, lr=0.1] 30%|██▉       | 26/88 [11:45<26:40, 25.81s/epoch, loss=1.15, accuracy=0.748, val_loss=2.11, val_accuracy=0.442, lr=0.1] 31%|███       | 27/88 [12:10<26:04, 25.65s/epoch, loss=1.14, accuracy=0.749, val_loss=1.98, val_accuracy=0.463, lr=0.1] 32%|███▏      | 28/88 [12:35<25:20, 25.35s/epoch, loss=1.14, accuracy=0.749, val_loss=1.84, val_accuracy=0.492, lr=0.0316] 33%|███▎      | 29/88 [12:59<24:41, 25.10s/epoch, loss=1.14, accuracy=0.75, val_loss=3.12, val_accuracy=0.293, lr=0.1]     34%|███▍      | 30/88 [13:26<24:43, 25.58s/epoch, loss=1.14, accuracy=0.751, val_loss=1.51, val_accuracy=0.604, lr=0.1] 35%|███▌      | 31/88 [13:52<24:19, 25.61s/epoch, loss=1.13, accuracy=0.751, val_loss=3.3, val_accuracy=0.421, lr=0.1]  36%|███▋      | 32/88 [14:16<23:26, 25.11s/epoch, loss=1.14, accuracy=0.75, val_loss=1.76, val_accuracy=0.606, lr=0.1] 38%|███▊      | 33/88 [14:42<23:24, 25.54s/epoch, loss=1.14, accuracy=0.749, val_loss=1.56, val_accuracy=0.589, lr=0.0316] 39%|███▊      | 34/88 [15:06<22:37, 25.14s/epoch, loss=1.13, accuracy=0.752, val_loss=1.44, val_accuracy=0.648, lr=0.1]    40%|███▉      | 35/88 [15:31<21:59, 24.90s/epoch, loss=1.14, accuracy=0.749, val_loss=1.68, val_accuracy=0.6, lr=0.1]   41%|████      | 36/88 [15:55<21:18, 24.58s/epoch, loss=1.14, accuracy=0.751, val_loss=2.05, val_accuracy=0.483, lr=0.1] 42%|████▏     | 37/88 [16:20<21:12, 24.95s/epoch, loss=1.13, accuracy=0.753, val_loss=2.34, val_accuracy=0.458, lr=0.1] 43%|████▎     | 38/88 [16:47<21:12, 25.45s/epoch, loss=1.13, accuracy=0.752, val_loss=2.13, val_accuracy=0.44, lr=0.1]  44%|████▍     | 39/88 [17:13<20:59, 25.69s/epoch, loss=1.13, accuracy=0.756, val_loss=2.01, val_accuracy=0.507, lr=0.0316] 45%|████▌     | 40/88 [17:38<20:24, 25.50s/epoch, loss=1.13, accuracy=0.756, val_loss=2.32, val_accuracy=0.423, lr=0.1]    47%|████▋     | 41/88 [18:02<19:32, 24.96s/epoch, loss=1.13, accuracy=0.755, val_loss=1.89, val_accuracy=0.534, lr=0.1] 48%|████▊     | 42/88 [18:28<19:24, 25.31s/epoch, loss=1.13, accuracy=0.755, val_loss=2.37, val_accuracy=0.432, lr=0.1] 49%|████▉     | 43/88 [18:55<19:14, 25.66s/epoch, loss=1.12, accuracy=0.754, val_loss=2.07, val_accuracy=0.495, lr=0.1] 50%|█████     | 44/88 [19:21<18:53, 25.75s/epoch, loss=1.13, accuracy=0.755, val_loss=1.76, val_accuracy=0.557, lr=0.0316] 51%|█████     | 45/88 [19:47<18:29, 25.81s/epoch, loss=1.13, accuracy=0.755, val_loss=1.77, val_accuracy=0.585, lr=0.1]    52%|█████▏    | 46/88 [20:11<17:48, 25.45s/epoch, loss=1.13, accuracy=0.756, val_loss=2.39, val_accuracy=0.45, lr=0.1]  53%|█████▎    | 47/88 [20:35<17:00, 24.89s/epoch, loss=1.14, accuracy=0.754, val_loss=2.24, val_accuracy=0.458, lr=0.1] 55%|█████▍    | 48/88 [21:01<16:49, 25.24s/epoch, loss=1.13, accuracy=0.758, val_loss=2.2, val_accuracy=0.486, lr=0.1]  56%|█████▌    | 49/88 [21:26<16:28, 25.35s/epoch, loss=1.13, accuracy=0.754, val_loss=1.88, val_accuracy=0.537, lr=0.0316] 57%|█████▋    | 50/88 [21:51<15:57, 25.21s/epoch, loss=1.12, accuracy=0.757, val_loss=2.84, val_accuracy=0.398, lr=0.1]    58%|█████▊    | 51/88 [22:18<15:49, 25.65s/epoch, loss=1.13, accuracy=0.755, val_loss=2.03, val_accuracy=0.466, lr=0.1] 59%|█████▉    | 52/88 [22:44<15:30, 25.86s/epoch, loss=1.12, accuracy=0.754, val_loss=2.58, val_accuracy=0.4, lr=0.1]   60%|██████    | 53/88 [23:09<14:49, 25.42s/epoch, loss=1.13, accuracy=0.757, val_loss=1.93, val_accuracy=0.521, lr=0.1] 61%|██████▏   | 54/88 [23:36<14:39, 25.87s/epoch, loss=1.12, accuracy=0.756, val_loss=1.74, val_accuracy=0.53, lr=0.0316] 62%|██████▎   | 55/88 [24:01<14:07, 25.68s/epoch, loss=1.12, accuracy=0.756, val_loss=1.85, val_accuracy=0.513, lr=0.1]   64%|██████▎   | 56/88 [24:25<13:22, 25.06s/epoch, loss=1.12, accuracy=0.76, val_loss=2.25, val_accuracy=0.409, lr=0.1]  65%|██████▍   | 57/88 [24:49<12:48, 24.80s/epoch, loss=1.13, accuracy=0.756, val_loss=2.85, val_accuracy=0.381, lr=0.1] 66%|██████▌   | 58/88 [25:14<12:27, 24.93s/epoch, loss=1.13, accuracy=0.755, val_loss=2.38, val_accuracy=0.439, lr=0.1] 67%|██████▋   | 59/88 [25:40<12:16, 25.41s/epoch, loss=1.12, accuracy=0.758, val_loss=2.44, val_accuracy=0.422, lr=0.0316] 68%|██████▊   | 60/88 [26:06<11:50, 25.39s/epoch, loss=1.12, accuracy=0.756, val_loss=2.01, val_accuracy=0.539, lr=0.1]    69%|██████▉   | 61/88 [26:31<11:24, 25.34s/epoch, loss=1.12, accuracy=0.756, val_loss=3.62, val_accuracy=0.308, lr=0.1] 70%|███████   | 62/88 [26:55<10:48, 24.93s/epoch, loss=1.12, accuracy=0.757, val_loss=1.37, val_accuracy=0.664, lr=0.1] 72%|███████▏  | 63/88 [27:22<10:35, 25.43s/epoch, loss=1.12, accuracy=0.755, val_loss=1.78, val_accuracy=0.544, lr=0.1] 73%|███████▎  | 64/88 [27:48<10:19, 25.79s/epoch, loss=1.12, accuracy=0.756, val_loss=2.06, val_accuracy=0.502, lr=0.1] 74%|███████▍  | 65/88 [28:15<09:56, 25.94s/epoch, loss=1.11, accuracy=0.759, val_loss=1.69, val_accuracy=0.552, lr=0.1] 75%|███████▌  | 66/88 [28:41<09:35, 26.17s/epoch, loss=1.12, accuracy=0.756, val_loss=1.66, val_accuracy=0.607, lr=0.1] 76%|███████▌  | 67/88 [29:07<09:08, 26.11s/epoch, loss=1.11, accuracy=0.76, val_loss=5.14, val_accuracy=0.243, lr=0.0316] 77%|███████▋  | 68/88 [29:32<08:32, 25.64s/epoch, loss=1.11, accuracy=0.76, val_loss=3.18, val_accuracy=0.338, lr=0.1]    78%|███████▊  | 69/88 [29:58<08:07, 25.68s/epoch, loss=1.12, accuracy=0.756, val_loss=2.57, val_accuracy=0.447, lr=0.1] 80%|███████▉  | 70/88 [30:23<07:41, 25.62s/epoch, loss=1.11, accuracy=0.757, val_loss=2.87, val_accuracy=0.417, lr=0.1] 81%|████████  | 71/88 [30:48<07:14, 25.55s/epoch, loss=1.12, accuracy=0.76, val_loss=2.49, val_accuracy=0.394, lr=0.1]  82%|████████▏ | 72/88 [31:15<06:53, 25.86s/epoch, loss=1.12, accuracy=0.756, val_loss=2.03, val_accuracy=0.428, lr=0.0316] 83%|████████▎ | 73/88 [31:40<06:23, 25.58s/epoch, loss=1.11, accuracy=0.76, val_loss=1.83, val_accuracy=0.491, lr=0.1]     84%|████████▍ | 74/88 [32:06<06:01, 25.82s/epoch, loss=1.11, accuracy=0.762, val_loss=2.49, val_accuracy=0.483, lr=0.1] 85%|████████▌ | 75/88 [32:30<05:26, 25.09s/epoch, loss=1.11, accuracy=0.758, val_loss=1.84, val_accuracy=0.491, lr=0.1] 86%|████████▋ | 76/88 [32:57<05:07, 25.65s/epoch, loss=1.11, accuracy=0.759, val_loss=2.47, val_accuracy=0.398, lr=0.1] 88%|████████▊ | 77/88 [33:21<04:37, 25.25s/epoch, loss=1.11, accuracy=0.76, val_loss=2.59, val_accuracy=0.409, lr=0.0316] 89%|████████▊ | 78/88 [33:45<04:08, 24.86s/epoch, loss=1.12, accuracy=0.756, val_loss=1.61, val_accuracy=0.603, lr=0.1]   90%|████████▉ | 79/88 [34:11<03:47, 25.25s/epoch, loss=1.11, accuracy=0.759, val_loss=3.42, val_accuracy=0.371, lr=0.1] 91%|█████████ | 80/88 [34:36<03:22, 25.30s/epoch, loss=1.11, accuracy=0.76, val_loss=2.96, val_accuracy=0.378, lr=0.1]  92%|█████████▏| 81/88 [35:00<02:53, 24.79s/epoch, loss=1.11, accuracy=0.759, val_loss=6.47, val_accuracy=0.189, lr=0.1] 93%|█████████▎| 82/88 [35:24<02:26, 24.41s/epoch, loss=0.922, accuracy=0.816, val_loss=0.942, val_accuracy=0.792, lr=0.01] 94%|█████████▍| 83/88 [35:47<02:00, 24.13s/epoch, loss=0.735, accuracy=0.851, val_loss=0.832, val_accuracy=0.806, lr=0.01] 95%|█████████▌| 84/88 [36:14<01:39, 24.85s/epoch, loss=0.656, accuracy=0.856, val_loss=0.918, val_accuracy=0.765, lr=0.01] 97%|█████████▋| 85/88 [36:39<01:15, 25.15s/epoch, loss=0.605, accuracy=0.862, val_loss=0.871, val_accuracy=0.776, lr=0.01] 98%|█████████▊| 86/88 [37:06<00:51, 25.63s/epoch, loss=0.58, accuracy=0.863, val_loss=0.802, val_accuracy=0.79, lr=0.01]   99%|█████████▉| 87/88 [37:32<00:25, 25.63s/epoch, loss=0.568, accuracy=0.864, val_loss=0.877, val_accuracy=0.777, lr=0.01]100%|██████████| 88/88 [37:58<00:00, 25.89s/epoch, loss=0.563, accuracy=0.864, val_loss=0.87, val_accuracy=0.761, lr=0.01] 100%|██████████| 88/88 [37:58<00:00, 25.90s/epoch, loss=0.563, accuracy=0.864, val_loss=0.87, val_accuracy=0.761, lr=0.01]
Using real-time data augmentation.
Test loss: 0.8700618147850037
Test accuracy: 0.760699987411499


* * * Run SGD for ID = 17_11. * * *


2024-02-15 20:14:11.201961: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 20:14:24.170653: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 20:14:24.172001: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-15 20:14:24.211106: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 20:14:24.211143: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 20:14:24.216560: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 20:14:24.216608: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 20:14:24.220292: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 20:14:24.222159: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 20:14:24.225978: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 20:14:24.229331: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 20:14:24.235886: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 20:14:24.236492: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 20:14:24.236588: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 20:14:25.560612: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-15 20:14:25.561221: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 20:14:25.561752: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 20:14:25.561788: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 20:14:25.561825: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 20:14:25.561845: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 20:14:25.561864: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 20:14:25.561883: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 20:14:25.561903: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 20:14:25.561922: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 20:14:25.561941: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 20:14:25.563860: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 20:14:25.563910: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 20:14:26.253351: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-15 20:14:26.253431: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-15 20:14:26.253443: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-15 20:14:26.254862: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': 1711, 'batch_size': 128, 'epochs': 88, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/88 [00:00<?, ?epoch/s]2024-02-15 20:14:27.095027: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-15 20:14:27.106810: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199950000 Hz
2024-02-15 20:14:29.407188: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 20:14:29.719799: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 20:14:30.510926: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-15 20:14:30.560877: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/88 [01:08<1:39:35, 68.69s/epoch, loss=3.19, accuracy=0.31, val_loss=2.27, val_accuracy=0.257, lr=0.1]  2%|▏         | 2/88 [01:34<1:02:01, 43.28s/epoch, loss=1.63, accuracy=0.499, val_loss=2.17, val_accuracy=0.406, lr=0.1]  3%|▎         | 3/88 [01:59<49:39, 35.05s/epoch, loss=1.38, accuracy=0.619, val_loss=1.53, val_accuracy=0.586, lr=0.1]    5%|▍         | 4/88 [02:25<43:54, 31.37s/epoch, loss=1.29, accuracy=0.672, val_loss=1.8, val_accuracy=0.554, lr=0.1]   6%|▌         | 5/88 [02:50<40:13, 29.08s/epoch, loss=1.27, accuracy=0.695, val_loss=1.45, val_accuracy=0.639, lr=0.1]  7%|▋         | 6/88 [03:16<38:35, 28.23s/epoch, loss=1.24, accuracy=0.71, val_loss=2.05, val_accuracy=0.491, lr=0.1]   8%|▊         | 7/88 [03:43<37:38, 27.88s/epoch, loss=1.23, accuracy=0.717, val_loss=1.93, val_accuracy=0.532, lr=0.1]  9%|▉         | 8/88 [04:07<35:25, 26.57s/epoch, loss=1.22, accuracy=0.724, val_loss=2.04, val_accuracy=0.504, lr=0.1] 10%|█         | 9/88 [04:31<33:44, 25.63s/epoch, loss=1.22, accuracy=0.727, val_loss=1.63, val_accuracy=0.592, lr=0.1] 11%|█▏        | 10/88 [04:54<32:33, 25.04s/epoch, loss=1.21, accuracy=0.732, val_loss=2.25, val_accuracy=0.444, lr=0.0316] 12%|█▎        | 11/88 [05:19<32:00, 24.95s/epoch, loss=1.21, accuracy=0.732, val_loss=2.55, val_accuracy=0.446, lr=0.1]    14%|█▎        | 12/88 [05:44<31:42, 25.03s/epoch, loss=1.21, accuracy=0.734, val_loss=1.8, val_accuracy=0.568, lr=0.1]  15%|█▍        | 13/88 [06:08<30:51, 24.68s/epoch, loss=1.2, accuracy=0.736, val_loss=1.99, val_accuracy=0.472, lr=0.1] 16%|█▌        | 14/88 [06:32<30:03, 24.37s/epoch, loss=1.19, accuracy=0.738, val_loss=1.85, val_accuracy=0.524, lr=0.1] 17%|█▋        | 15/88 [06:59<30:38, 25.19s/epoch, loss=1.18, accuracy=0.741, val_loss=1.31, val_accuracy=0.701, lr=0.1] 18%|█▊        | 16/88 [07:23<29:36, 24.68s/epoch, loss=1.19, accuracy=0.74, val_loss=2.06, val_accuracy=0.429, lr=0.1]  19%|█▉        | 17/88 [07:48<29:31, 24.95s/epoch, loss=1.19, accuracy=0.739, val_loss=1.62, val_accuracy=0.588, lr=0.1] 20%|██        | 18/88 [08:15<29:39, 25.43s/epoch, loss=1.19, accuracy=0.744, val_loss=1.46, val_accuracy=0.647, lr=0.1] 22%|██▏       | 19/88 [08:39<29:00, 25.23s/epoch, loss=1.18, accuracy=0.745, val_loss=2.44, val_accuracy=0.355, lr=0.1] 23%|██▎       | 20/88 [09:03<28:10, 24.86s/epoch, loss=1.17, accuracy=0.747, val_loss=1.95, val_accuracy=0.525, lr=0.0316] 24%|██▍       | 21/88 [09:30<28:20, 25.38s/epoch, loss=1.17, accuracy=0.742, val_loss=2.38, val_accuracy=0.378, lr=0.1]    25%|██▌       | 22/88 [09:55<27:56, 25.41s/epoch, loss=1.17, accuracy=0.744, val_loss=1.71, val_accuracy=0.58, lr=0.1]  26%|██▌       | 23/88 [10:20<27:07, 25.04s/epoch, loss=1.17, accuracy=0.747, val_loss=2.18, val_accuracy=0.514, lr=0.1] 27%|██▋       | 24/88 [10:46<27:08, 25.45s/epoch, loss=1.18, accuracy=0.744, val_loss=1.42, val_accuracy=0.67, lr=0.1]  28%|██▊       | 25/88 [11:11<26:26, 25.18s/epoch, loss=1.17, accuracy=0.748, val_loss=1.82, val_accuracy=0.574, lr=0.0316] 30%|██▉       | 26/88 [11:36<26:00, 25.17s/epoch, loss=1.17, accuracy=0.75, val_loss=4.05, val_accuracy=0.238, lr=0.1]     31%|███       | 27/88 [12:01<25:40, 25.26s/epoch, loss=1.16, accuracy=0.749, val_loss=1.89, val_accuracy=0.484, lr=0.1] 32%|███▏      | 28/88 [12:26<25:12, 25.20s/epoch, loss=1.16, accuracy=0.749, val_loss=1.56, val_accuracy=0.615, lr=0.1] 33%|███▎      | 29/88 [12:50<24:21, 24.77s/epoch, loss=1.16, accuracy=0.749, val_loss=1.93, val_accuracy=0.466, lr=0.1] 34%|███▍      | 30/88 [13:16<24:14, 25.08s/epoch, loss=1.16, accuracy=0.748, val_loss=3.8, val_accuracy=0.337, lr=0.0316] 35%|███▌      | 31/88 [13:41<23:57, 25.23s/epoch, loss=1.15, accuracy=0.752, val_loss=1.93, val_accuracy=0.492, lr=0.1]   36%|███▋      | 32/88 [14:05<23:12, 24.86s/epoch, loss=1.15, accuracy=0.752, val_loss=3.4, val_accuracy=0.439, lr=0.1]  38%|███▊      | 33/88 [14:29<22:32, 24.59s/epoch, loss=1.15, accuracy=0.751, val_loss=1.88, val_accuracy=0.523, lr=0.1] 39%|███▊      | 34/88 [14:56<22:42, 25.22s/epoch, loss=1.15, accuracy=0.751, val_loss=1.73, val_accuracy=0.58, lr=0.1]  40%|███▉      | 35/88 [15:23<22:42, 25.71s/epoch, loss=1.15, accuracy=0.751, val_loss=2.05, val_accuracy=0.523, lr=0.0316] 41%|████      | 36/88 [15:50<22:30, 25.97s/epoch, loss=1.15, accuracy=0.75, val_loss=2.17, val_accuracy=0.428, lr=0.1]     42%|████▏     | 37/88 [16:17<22:24, 26.37s/epoch, loss=1.15, accuracy=0.752, val_loss=2.64, val_accuracy=0.383, lr=0.1] 43%|████▎     | 38/88 [16:44<22:04, 26.50s/epoch, loss=1.15, accuracy=0.751, val_loss=2.2, val_accuracy=0.48, lr=0.1]   44%|████▍     | 39/88 [17:07<20:58, 25.69s/epoch, loss=1.15, accuracy=0.75, val_loss=4.69, val_accuracy=0.227, lr=0.1] 45%|████▌     | 40/88 [17:32<20:12, 25.26s/epoch, loss=1.14, accuracy=0.75, val_loss=2, val_accuracy=0.552, lr=0.0316] 47%|████▋     | 41/88 [17:57<19:50, 25.34s/epoch, loss=1.15, accuracy=0.752, val_loss=1.62, val_accuracy=0.603, lr=0.1] 48%|████▊     | 42/88 [18:23<19:25, 25.34s/epoch, loss=1.14, accuracy=0.753, val_loss=1.44, val_accuracy=0.646, lr=0.1] 49%|████▉     | 43/88 [18:47<18:42, 24.95s/epoch, loss=1.14, accuracy=0.752, val_loss=2.1, val_accuracy=0.463, lr=0.1]  50%|█████     | 44/88 [19:13<18:38, 25.42s/epoch, loss=1.14, accuracy=0.753, val_loss=2.08, val_accuracy=0.424, lr=0.1] 51%|█████     | 45/88 [19:40<18:27, 25.76s/epoch, loss=1.14, accuracy=0.753, val_loss=3.29, val_accuracy=0.292, lr=0.0316] 52%|█████▏    | 46/88 [20:03<17:36, 25.15s/epoch, loss=1.14, accuracy=0.754, val_loss=3.64, val_accuracy=0.364, lr=0.1]    53%|█████▎    | 47/88 [20:27<16:52, 24.70s/epoch, loss=1.15, accuracy=0.75, val_loss=1.42, val_accuracy=0.654, lr=0.1]  55%|█████▍    | 48/88 [20:51<16:18, 24.47s/epoch, loss=1.14, accuracy=0.754, val_loss=1.54, val_accuracy=0.601, lr=0.1] 56%|█████▌    | 49/88 [21:17<16:15, 25.01s/epoch, loss=1.14, accuracy=0.754, val_loss=1.64, val_accuracy=0.605, lr=0.1] 57%|█████▋    | 50/88 [21:43<16:02, 25.34s/epoch, loss=1.13, accuracy=0.757, val_loss=1.71, val_accuracy=0.574, lr=0.0316] 58%|█████▊    | 51/88 [22:10<15:52, 25.74s/epoch, loss=1.14, accuracy=0.753, val_loss=1.6, val_accuracy=0.606, lr=0.1]     59%|█████▉    | 52/88 [22:37<15:40, 26.11s/epoch, loss=1.14, accuracy=0.754, val_loss=2.94, val_accuracy=0.274, lr=0.1] 60%|██████    | 53/88 [23:01<14:49, 25.42s/epoch, loss=1.14, accuracy=0.754, val_loss=1.66, val_accuracy=0.592, lr=0.1] 61%|██████▏   | 54/88 [23:26<14:19, 25.29s/epoch, loss=1.14, accuracy=0.755, val_loss=1.69, val_accuracy=0.598, lr=0.1] 62%|██████▎   | 55/88 [23:52<14:07, 25.68s/epoch, loss=1.14, accuracy=0.755, val_loss=1.79, val_accuracy=0.564, lr=0.0316] 64%|██████▎   | 56/88 [24:20<13:56, 26.14s/epoch, loss=1.14, accuracy=0.755, val_loss=3.3, val_accuracy=0.357, lr=0.1]     65%|██████▍   | 57/88 [24:44<13:16, 25.69s/epoch, loss=1.13, accuracy=0.756, val_loss=2.44, val_accuracy=0.42, lr=0.1] 66%|██████▌   | 58/88 [25:08<12:33, 25.13s/epoch, loss=1.14, accuracy=0.757, val_loss=2.55, val_accuracy=0.422, lr=0.1] 67%|██████▋   | 59/88 [25:33<12:11, 25.21s/epoch, loss=1.14, accuracy=0.754, val_loss=1.85, val_accuracy=0.533, lr=0.1] 68%|██████▊   | 60/88 [26:00<11:53, 25.50s/epoch, loss=1.13, accuracy=0.756, val_loss=2.45, val_accuracy=0.41, lr=0.0316] 69%|██████▉   | 61/88 [26:26<11:31, 25.62s/epoch, loss=1.13, accuracy=0.757, val_loss=2.2, val_accuracy=0.498, lr=0.1]    70%|███████   | 62/88 [26:50<10:57, 25.28s/epoch, loss=1.13, accuracy=0.757, val_loss=1.59, val_accuracy=0.584, lr=0.1] 72%|███████▏  | 63/88 [27:15<10:26, 25.04s/epoch, loss=1.13, accuracy=0.755, val_loss=2.46, val_accuracy=0.331, lr=0.1] 73%|███████▎  | 64/88 [27:39<09:56, 24.86s/epoch, loss=1.13, accuracy=0.757, val_loss=3.55, val_accuracy=0.336, lr=0.1] 74%|███████▍  | 65/88 [28:05<09:41, 25.30s/epoch, loss=1.14, accuracy=0.756, val_loss=4.31, val_accuracy=0.242, lr=0.0316] 75%|███████▌  | 66/88 [28:31<09:18, 25.38s/epoch, loss=1.13, accuracy=0.758, val_loss=1.96, val_accuracy=0.559, lr=0.1]    76%|███████▌  | 67/88 [28:55<08:42, 24.87s/epoch, loss=1.13, accuracy=0.758, val_loss=1.94, val_accuracy=0.513, lr=0.1] 77%|███████▋  | 68/88 [29:20<08:21, 25.07s/epoch, loss=1.13, accuracy=0.755, val_loss=2.76, val_accuracy=0.39, lr=0.1]  78%|███████▊  | 69/88 [29:47<08:05, 25.54s/epoch, loss=1.13, accuracy=0.755, val_loss=2.07, val_accuracy=0.44, lr=0.1] 80%|███████▉  | 70/88 [30:13<07:44, 25.79s/epoch, loss=1.13, accuracy=0.758, val_loss=1.94, val_accuracy=0.525, lr=0.0316] 81%|████████  | 71/88 [30:39<07:18, 25.82s/epoch, loss=1.14, accuracy=0.759, val_loss=2.33, val_accuracy=0.424, lr=0.1]    82%|████████▏ | 72/88 [31:06<06:57, 26.11s/epoch, loss=1.13, accuracy=0.756, val_loss=1.56, val_accuracy=0.611, lr=0.1] 83%|████████▎ | 73/88 [31:31<06:26, 25.78s/epoch, loss=1.13, accuracy=0.754, val_loss=2.05, val_accuracy=0.461, lr=0.1] 84%|████████▍ | 74/88 [31:56<05:58, 25.62s/epoch, loss=1.14, accuracy=0.754, val_loss=1.59, val_accuracy=0.615, lr=0.1] 85%|████████▌ | 75/88 [32:20<05:27, 25.22s/epoch, loss=1.13, accuracy=0.755, val_loss=4.91, val_accuracy=0.204, lr=0.0316] 86%|████████▋ | 76/88 [32:46<05:03, 25.30s/epoch, loss=1.13, accuracy=0.756, val_loss=1.95, val_accuracy=0.486, lr=0.1]    88%|████████▊ | 77/88 [33:12<04:42, 25.67s/epoch, loss=1.12, accuracy=0.759, val_loss=2.32, val_accuracy=0.377, lr=0.1] 89%|████████▊ | 78/88 [33:36<04:11, 25.10s/epoch, loss=1.13, accuracy=0.755, val_loss=2.67, val_accuracy=0.479, lr=0.1] 90%|████████▉ | 79/88 [34:00<03:41, 24.66s/epoch, loss=1.13, accuracy=0.756, val_loss=3.61, val_accuracy=0.362, lr=0.1] 91%|█████████ | 80/88 [34:27<03:22, 25.32s/epoch, loss=1.13, accuracy=0.755, val_loss=2.92, val_accuracy=0.375, lr=0.0316] 92%|█████████▏| 81/88 [34:50<02:53, 24.77s/epoch, loss=1.13, accuracy=0.756, val_loss=1.73, val_accuracy=0.552, lr=0.1]    93%|█████████▎| 82/88 [35:16<02:31, 25.17s/epoch, loss=0.918, accuracy=0.816, val_loss=0.966, val_accuracy=0.785, lr=0.01] 94%|█████████▍| 83/88 [35:42<02:07, 25.44s/epoch, loss=0.735, accuracy=0.847, val_loss=0.822, val_accuracy=0.805, lr=0.01] 95%|█████████▌| 84/88 [36:08<01:42, 25.58s/epoch, loss=0.65, accuracy=0.857, val_loss=0.779, val_accuracy=0.808, lr=0.01]  97%|█████████▋| 85/88 [36:34<01:17, 25.72s/epoch, loss=0.612, accuracy=0.859, val_loss=0.804, val_accuracy=0.789, lr=0.01] 98%|█████████▊| 86/88 [36:59<00:50, 25.47s/epoch, loss=0.586, accuracy=0.86, val_loss=0.843, val_accuracy=0.791, lr=0.01]  99%|█████████▉| 87/88 [37:23<00:25, 25.01s/epoch, loss=0.578, accuracy=0.863, val_loss=0.876, val_accuracy=0.77, lr=0.01]100%|██████████| 88/88 [37:49<00:00, 25.35s/epoch, loss=0.567, accuracy=0.864, val_loss=0.873, val_accuracy=0.782, lr=0.01]100%|██████████| 88/88 [37:49<00:00, 25.79s/epoch, loss=0.567, accuracy=0.864, val_loss=0.873, val_accuracy=0.782, lr=0.01]
Using real-time data augmentation.
Test loss: 0.8728166818618774
Test accuracy: 0.7817999720573425


* * * Run SGD for ID = 17_12. * * *


2024-02-15 20:52:19.416927: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 20:52:22.284819: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 20:52:22.286095: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-15 20:52:22.325253: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 20:52:22.325297: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 20:52:22.328302: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 20:52:22.328349: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 20:52:22.330591: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 20:52:22.331302: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 20:52:22.333883: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 20:52:22.335518: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 20:52:22.340569: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 20:52:22.341166: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 20:52:22.341261: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 20:52:23.680972: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-15 20:52:23.682008: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 20:52:23.682481: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 20:52:23.682515: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 20:52:23.682550: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 20:52:23.682570: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 20:52:23.682589: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 20:52:23.682608: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 20:52:23.682626: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 20:52:23.682645: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 20:52:23.682664: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 20:52:23.683194: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 20:52:23.683237: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 20:52:24.396913: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-15 20:52:24.396974: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-15 20:52:24.396988: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-15 20:52:24.398445: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': 1712, 'batch_size': 128, 'epochs': 88, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/88 [00:00<?, ?epoch/s]2024-02-15 20:52:25.254398: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-15 20:52:25.266809: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199950000 Hz
2024-02-15 20:52:27.551650: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 20:52:27.828531: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 20:52:28.777929: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-15 20:52:28.838823: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/88 [01:03<1:31:41, 63.24s/epoch, loss=3.15, accuracy=0.322, val_loss=2.29, val_accuracy=0.281, lr=0.1]  2%|▏         | 2/88 [01:26<57:06, 39.85s/epoch, loss=1.55, accuracy=0.541, val_loss=2.08, val_accuracy=0.413, lr=0.1]    3%|▎         | 3/88 [01:49<45:33, 32.16s/epoch, loss=1.33, accuracy=0.649, val_loss=1.75, val_accuracy=0.536, lr=0.1]  5%|▍         | 4/88 [02:15<41:15, 29.48s/epoch, loss=1.27, accuracy=0.689, val_loss=1.53, val_accuracy=0.609, lr=0.1]  6%|▌         | 5/88 [02:38<37:50, 27.36s/epoch, loss=1.25, accuracy=0.701, val_loss=1.68, val_accuracy=0.558, lr=0.1]  7%|▋         | 6/88 [03:03<36:11, 26.48s/epoch, loss=1.24, accuracy=0.712, val_loss=1.75, val_accuracy=0.54, lr=0.1]   8%|▊         | 7/88 [03:30<35:52, 26.57s/epoch, loss=1.23, accuracy=0.72, val_loss=1.68, val_accuracy=0.542, lr=0.1]  9%|▉         | 8/88 [03:55<34:50, 26.13s/epoch, loss=1.22, accuracy=0.724, val_loss=4.78, val_accuracy=0.287, lr=0.1] 10%|█         | 9/88 [04:21<34:31, 26.22s/epoch, loss=1.22, accuracy=0.728, val_loss=2.08, val_accuracy=0.461, lr=0.0316] 11%|█▏        | 10/88 [04:45<32:59, 25.37s/epoch, loss=1.21, accuracy=0.729, val_loss=2.56, val_accuracy=0.444, lr=0.1]   12%|█▎        | 11/88 [05:11<32:57, 25.68s/epoch, loss=1.21, accuracy=0.732, val_loss=2.78, val_accuracy=0.429, lr=0.1] 14%|█▎        | 12/88 [05:37<32:37, 25.75s/epoch, loss=1.2, accuracy=0.734, val_loss=1.75, val_accuracy=0.577, lr=0.1]  15%|█▍        | 13/88 [06:03<32:25, 25.94s/epoch, loss=1.2, accuracy=0.733, val_loss=2.13, val_accuracy=0.453, lr=0.1] 16%|█▌        | 14/88 [06:28<31:32, 25.58s/epoch, loss=1.2, accuracy=0.734, val_loss=1.5, val_accuracy=0.628, lr=0.1]  17%|█▋        | 15/88 [06:55<31:25, 25.83s/epoch, loss=1.2, accuracy=0.735, val_loss=2.07, val_accuracy=0.479, lr=0.1] 18%|█▊        | 16/88 [07:21<31:16, 26.06s/epoch, loss=1.19, accuracy=0.737, val_loss=2.3, val_accuracy=0.471, lr=0.1] 19%|█▉        | 17/88 [07:46<30:20, 25.64s/epoch, loss=1.19, accuracy=0.739, val_loss=1.9, val_accuracy=0.493, lr=0.1] 20%|██        | 18/88 [08:12<30:11, 25.88s/epoch, loss=1.18, accuracy=0.74, val_loss=2.46, val_accuracy=0.459, lr=0.1] 22%|██▏       | 19/88 [08:37<29:17, 25.46s/epoch, loss=1.18, accuracy=0.744, val_loss=2.55, val_accuracy=0.36, lr=0.0316] 23%|██▎       | 20/88 [09:03<29:09, 25.72s/epoch, loss=1.18, accuracy=0.742, val_loss=1.62, val_accuracy=0.609, lr=0.1]   24%|██▍       | 21/88 [09:27<27:58, 25.05s/epoch, loss=1.18, accuracy=0.743, val_loss=2.39, val_accuracy=0.438, lr=0.1] 25%|██▌       | 22/88 [09:53<27:53, 25.35s/epoch, loss=1.18, accuracy=0.744, val_loss=1.81, val_accuracy=0.569, lr=0.1] 26%|██▌       | 23/88 [10:16<26:50, 24.77s/epoch, loss=1.19, accuracy=0.743, val_loss=3.57, val_accuracy=0.22, lr=0.1]  27%|██▋       | 24/88 [10:40<26:00, 24.39s/epoch, loss=1.17, accuracy=0.744, val_loss=1.4, val_accuracy=0.673, lr=0.1] 28%|██▊       | 25/88 [11:03<25:19, 24.12s/epoch, loss=1.18, accuracy=0.745, val_loss=1.52, val_accuracy=0.621, lr=0.1] 30%|██▉       | 26/88 [11:29<25:23, 24.57s/epoch, loss=1.17, accuracy=0.746, val_loss=1.81, val_accuracy=0.574, lr=0.1] 31%|███       | 27/88 [11:55<25:31, 25.10s/epoch, loss=1.17, accuracy=0.746, val_loss=2.81, val_accuracy=0.37, lr=0.1]  32%|███▏      | 28/88 [12:21<25:25, 25.43s/epoch, loss=1.17, accuracy=0.744, val_loss=1.59, val_accuracy=0.617, lr=0.1] 33%|███▎      | 29/88 [12:48<25:24, 25.83s/epoch, loss=1.17, accuracy=0.746, val_loss=2.05, val_accuracy=0.521, lr=0.0316] 34%|███▍      | 30/88 [13:12<24:19, 25.17s/epoch, loss=1.16, accuracy=0.748, val_loss=3.29, val_accuracy=0.37, lr=0.1]     35%|███▌      | 31/88 [13:37<24:06, 25.38s/epoch, loss=1.16, accuracy=0.749, val_loss=1.74, val_accuracy=0.573, lr=0.1] 36%|███▋      | 32/88 [14:02<23:23, 25.06s/epoch, loss=1.16, accuracy=0.748, val_loss=1.77, val_accuracy=0.527, lr=0.1] 38%|███▊      | 33/88 [14:27<23:04, 25.18s/epoch, loss=1.16, accuracy=0.752, val_loss=2.17, val_accuracy=0.436, lr=0.1] 39%|███▊      | 34/88 [14:54<23:00, 25.56s/epoch, loss=1.16, accuracy=0.752, val_loss=1.86, val_accuracy=0.505, lr=0.0316] 40%|███▉      | 35/88 [15:18<22:12, 25.14s/epoch, loss=1.16, accuracy=0.747, val_loss=1.99, val_accuracy=0.53, lr=0.1]     41%|████      | 36/88 [15:42<21:29, 24.80s/epoch, loss=1.16, accuracy=0.748, val_loss=1.84, val_accuracy=0.532, lr=0.1] 42%|████▏     | 37/88 [16:08<21:28, 25.27s/epoch, loss=1.16, accuracy=0.749, val_loss=2.15, val_accuracy=0.462, lr=0.1] 43%|████▎     | 38/88 [16:34<21:05, 25.30s/epoch, loss=1.16, accuracy=0.748, val_loss=2.55, val_accuracy=0.325, lr=0.1] 44%|████▍     | 39/88 [16:59<20:40, 25.32s/epoch, loss=1.16, accuracy=0.75, val_loss=1.81, val_accuracy=0.544, lr=0.0316] 45%|████▌     | 40/88 [17:24<20:11, 25.24s/epoch, loss=1.15, accuracy=0.75, val_loss=1.66, val_accuracy=0.557, lr=0.1]    47%|████▋     | 41/88 [17:50<19:57, 25.48s/epoch, loss=1.15, accuracy=0.748, val_loss=3.14, val_accuracy=0.425, lr=0.1] 48%|████▊     | 42/88 [18:14<19:11, 25.03s/epoch, loss=1.16, accuracy=0.751, val_loss=2.04, val_accuracy=0.545, lr=0.1] 49%|████▉     | 43/88 [18:39<18:45, 25.02s/epoch, loss=1.15, accuracy=0.749, val_loss=2.78, val_accuracy=0.335, lr=0.1] 50%|█████     | 44/88 [19:03<18:02, 24.59s/epoch, loss=1.14, accuracy=0.754, val_loss=1.68, val_accuracy=0.594, lr=0.0316] 51%|█████     | 45/88 [19:29<17:57, 25.07s/epoch, loss=1.15, accuracy=0.753, val_loss=2.82, val_accuracy=0.355, lr=0.1]    52%|█████▏    | 46/88 [19:53<17:23, 24.85s/epoch, loss=1.15, accuracy=0.752, val_loss=2.03, val_accuracy=0.472, lr=0.1] 53%|█████▎    | 47/88 [20:17<16:44, 24.50s/epoch, loss=1.15, accuracy=0.749, val_loss=2.05, val_accuracy=0.477, lr=0.1] 55%|█████▍    | 48/88 [20:43<16:36, 24.91s/epoch, loss=1.14, accuracy=0.754, val_loss=1.68, val_accuracy=0.592, lr=0.1] 56%|█████▌    | 49/88 [21:09<16:30, 25.40s/epoch, loss=1.15, accuracy=0.751, val_loss=1.73, val_accuracy=0.56, lr=0.0316] 57%|█████▋    | 50/88 [21:36<16:15, 25.67s/epoch, loss=1.14, accuracy=0.753, val_loss=1.91, val_accuracy=0.522, lr=0.1]   58%|█████▊    | 51/88 [21:59<15:30, 25.14s/epoch, loss=1.15, accuracy=0.754, val_loss=2.59, val_accuracy=0.432, lr=0.1] 59%|█████▉    | 52/88 [22:23<14:49, 24.71s/epoch, loss=1.14, accuracy=0.755, val_loss=1.7, val_accuracy=0.579, lr=0.1]  60%|██████    | 53/88 [22:47<14:12, 24.35s/epoch, loss=1.15, accuracy=0.751, val_loss=2.04, val_accuracy=0.48, lr=0.1] 61%|██████▏   | 54/88 [23:10<13:38, 24.08s/epoch, loss=1.14, accuracy=0.753, val_loss=1.72, val_accuracy=0.585, lr=0.0316] 62%|██████▎   | 55/88 [23:34<13:13, 24.05s/epoch, loss=1.14, accuracy=0.755, val_loss=2.1, val_accuracy=0.488, lr=0.1]     64%|██████▎   | 56/88 [24:00<13:04, 24.53s/epoch, loss=1.14, accuracy=0.753, val_loss=1.87, val_accuracy=0.505, lr=0.1] 65%|██████▍   | 57/88 [24:26<12:53, 24.97s/epoch, loss=1.14, accuracy=0.752, val_loss=2.07, val_accuracy=0.455, lr=0.1] 66%|██████▌   | 58/88 [24:51<12:33, 25.13s/epoch, loss=1.14, accuracy=0.755, val_loss=2.84, val_accuracy=0.25, lr=0.1]  67%|██████▋   | 59/88 [25:17<12:16, 25.39s/epoch, loss=1.14, accuracy=0.756, val_loss=1.57, val_accuracy=0.604, lr=0.0316] 68%|██████▊   | 60/88 [25:44<12:00, 25.72s/epoch, loss=1.14, accuracy=0.753, val_loss=1.76, val_accuracy=0.558, lr=0.1]    69%|██████▉   | 61/88 [26:10<11:35, 25.76s/epoch, loss=1.14, accuracy=0.754, val_loss=2.32, val_accuracy=0.434, lr=0.1] 70%|███████   | 62/88 [26:35<11:09, 25.75s/epoch, loss=1.14, accuracy=0.756, val_loss=1.68, val_accuracy=0.58, lr=0.1]  72%|███████▏  | 63/88 [26:59<10:26, 25.06s/epoch, loss=1.14, accuracy=0.752, val_loss=2.31, val_accuracy=0.474, lr=0.1] 73%|███████▎  | 64/88 [27:24<10:06, 25.25s/epoch, loss=1.15, accuracy=0.753, val_loss=1.76, val_accuracy=0.541, lr=0.0316] 74%|███████▍  | 65/88 [27:51<09:48, 25.59s/epoch, loss=1.14, accuracy=0.752, val_loss=1.48, val_accuracy=0.639, lr=0.1]    75%|███████▌  | 66/88 [28:14<09:09, 24.96s/epoch, loss=1.13, accuracy=0.757, val_loss=2.15, val_accuracy=0.456, lr=0.1] 76%|███████▌  | 67/88 [28:40<08:45, 25.03s/epoch, loss=1.14, accuracy=0.755, val_loss=2.16, val_accuracy=0.479, lr=0.1] 77%|███████▋  | 68/88 [29:06<08:26, 25.32s/epoch, loss=1.13, accuracy=0.755, val_loss=1.76, val_accuracy=0.55, lr=0.1]  78%|███████▊  | 69/88 [29:32<08:06, 25.59s/epoch, loss=1.14, accuracy=0.755, val_loss=2.28, val_accuracy=0.431, lr=0.0316] 80%|███████▉  | 70/88 [29:55<07:29, 24.96s/epoch, loss=1.13, accuracy=0.756, val_loss=1.55, val_accuracy=0.611, lr=0.1]    81%|████████  | 71/88 [30:21<07:10, 25.31s/epoch, loss=1.13, accuracy=0.755, val_loss=1.94, val_accuracy=0.485, lr=0.1] 82%|████████▏ | 72/88 [30:46<06:40, 25.04s/epoch, loss=1.14, accuracy=0.754, val_loss=2.83, val_accuracy=0.399, lr=0.1] 83%|████████▎ | 73/88 [31:11<06:16, 25.07s/epoch, loss=1.13, accuracy=0.755, val_loss=2.44, val_accuracy=0.411, lr=0.1] 84%|████████▍ | 74/88 [31:34<05:44, 24.61s/epoch, loss=1.12, accuracy=0.756, val_loss=1.94, val_accuracy=0.553, lr=0.0316] 85%|████████▌ | 75/88 [31:58<05:14, 24.22s/epoch, loss=1.13, accuracy=0.755, val_loss=1.5, val_accuracy=0.622, lr=0.1]     86%|████████▋ | 76/88 [32:22<04:52, 24.35s/epoch, loss=1.13, accuracy=0.754, val_loss=1.77, val_accuracy=0.581, lr=0.1] 88%|████████▊ | 77/88 [32:49<04:34, 24.99s/epoch, loss=1.13, accuracy=0.755, val_loss=3.28, val_accuracy=0.395, lr=0.1] 89%|████████▊ | 78/88 [33:12<04:04, 24.50s/epoch, loss=1.13, accuracy=0.755, val_loss=1.69, val_accuracy=0.579, lr=0.1] 90%|████████▉ | 79/88 [33:37<03:40, 24.45s/epoch, loss=1.14, accuracy=0.754, val_loss=3.76, val_accuracy=0.277, lr=0.0316] 91%|█████████ | 80/88 [34:01<03:14, 24.33s/epoch, loss=1.14, accuracy=0.751, val_loss=1.78, val_accuracy=0.526, lr=0.1]    92%|█████████▏| 81/88 [34:24<02:48, 24.05s/epoch, loss=1.13, accuracy=0.752, val_loss=1.49, val_accuracy=0.621, lr=0.1] 93%|█████████▎| 82/88 [34:50<02:27, 24.62s/epoch, loss=0.929, accuracy=0.813, val_loss=0.897, val_accuracy=0.807, lr=0.01] 94%|█████████▍| 83/88 [35:15<02:04, 24.86s/epoch, loss=0.742, accuracy=0.846, val_loss=0.781, val_accuracy=0.825, lr=0.01] 95%|█████████▌| 84/88 [35:41<01:40, 25.17s/epoch, loss=0.662, accuracy=0.853, val_loss=0.734, val_accuracy=0.822, lr=0.01] 97%|█████████▋| 85/88 [36:05<01:13, 24.60s/epoch, loss=0.613, accuracy=0.86, val_loss=0.779, val_accuracy=0.799, lr=0.01]  98%|█████████▊| 86/88 [36:31<00:50, 25.19s/epoch, loss=0.591, accuracy=0.859, val_loss=0.795, val_accuracy=0.795, lr=0.01] 99%|█████████▉| 87/88 [36:56<00:25, 25.07s/epoch, loss=0.58, accuracy=0.86, val_loss=0.892, val_accuracy=0.764, lr=0.01]  100%|██████████| 88/88 [37:19<00:00, 24.56s/epoch, loss=0.573, accuracy=0.863, val_loss=0.701, val_accuracy=0.82, lr=0.01]100%|██████████| 88/88 [37:19<00:00, 25.45s/epoch, loss=0.573, accuracy=0.863, val_loss=0.701, val_accuracy=0.82, lr=0.01]
Using real-time data augmentation.
Test loss: 0.7009524703025818
Test accuracy: 0.8199999928474426


* * * Run SGD for ID = 17_13. * * *


2024-02-15 21:29:47.727659: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 21:29:50.730273: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 21:29:50.731502: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-15 21:29:50.770772: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 21:29:50.770812: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 21:29:50.773869: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 21:29:50.773916: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 21:29:50.776307: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 21:29:50.777076: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 21:29:50.779646: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 21:29:50.781260: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 21:29:50.786252: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 21:29:50.786817: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 21:29:50.786912: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 21:29:52.059262: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-15 21:29:52.059891: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 21:29:52.060390: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 21:29:52.060427: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 21:29:52.060462: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 21:29:52.060482: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 21:29:52.060501: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 21:29:52.060519: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 21:29:52.060538: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 21:29:52.060556: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 21:29:52.060575: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 21:29:52.061105: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 21:29:52.061147: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 21:29:52.745836: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-15 21:29:52.745913: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-15 21:29:52.745925: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-15 21:29:52.747338: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': 1713, 'batch_size': 128, 'epochs': 88, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/88 [00:00<?, ?epoch/s]2024-02-15 21:29:53.581201: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-15 21:29:53.593811: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199950000 Hz
2024-02-15 21:29:55.791384: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 21:29:56.082366: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 21:29:56.789173: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-15 21:29:56.833984: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/88 [00:59<1:25:59, 59.30s/epoch, loss=3.32, accuracy=0.285, val_loss=3.42, val_accuracy=0.0839, lr=0.1]  2%|▏         | 2/88 [01:24<56:32, 39.45s/epoch, loss=1.6, accuracy=0.508, val_loss=1.86, val_accuracy=0.457, lr=0.1]      3%|▎         | 3/88 [01:51<47:24, 33.46s/epoch, loss=1.36, accuracy=0.634, val_loss=2.07, val_accuracy=0.458, lr=0.1]  5%|▍         | 4/88 [02:14<41:26, 29.60s/epoch, loss=1.29, accuracy=0.68, val_loss=1.69, val_accuracy=0.54, lr=0.1]    6%|▌         | 5/88 [02:40<38:46, 28.03s/epoch, loss=1.26, accuracy=0.7, val_loss=2.6, val_accuracy=0.383, lr=0.1]   7%|▋         | 6/88 [03:04<36:37, 26.80s/epoch, loss=1.25, accuracy=0.707, val_loss=2.25, val_accuracy=0.435, lr=0.1]  8%|▊         | 7/88 [03:29<35:19, 26.17s/epoch, loss=1.22, accuracy=0.716, val_loss=1.8, val_accuracy=0.541, lr=0.1]   9%|▉         | 8/88 [03:56<35:08, 26.35s/epoch, loss=1.22, accuracy=0.722, val_loss=2.94, val_accuracy=0.444, lr=0.1] 10%|█         | 9/88 [04:22<34:40, 26.33s/epoch, loss=1.22, accuracy=0.721, val_loss=1.62, val_accuracy=0.596, lr=0.1] 11%|█▏        | 10/88 [04:49<34:28, 26.52s/epoch, loss=1.2, accuracy=0.728, val_loss=1.65, val_accuracy=0.594, lr=0.1] 12%|█▎        | 11/88 [05:15<33:42, 26.26s/epoch, loss=1.21, accuracy=0.728, val_loss=1.65, val_accuracy=0.6, lr=0.1]  14%|█▎        | 12/88 [05:38<32:10, 25.40s/epoch, loss=1.19, accuracy=0.731, val_loss=1.77, val_accuracy=0.557, lr=0.1] 15%|█▍        | 13/88 [06:04<31:52, 25.50s/epoch, loss=1.18, accuracy=0.736, val_loss=1.83, val_accuracy=0.566, lr=0.1] 16%|█▌        | 14/88 [06:29<31:33, 25.58s/epoch, loss=1.17, accuracy=0.74, val_loss=2.24, val_accuracy=0.526, lr=0.0316] 17%|█▋        | 15/88 [06:57<31:42, 26.07s/epoch, loss=1.18, accuracy=0.739, val_loss=1.43, val_accuracy=0.656, lr=0.1]   18%|█▊        | 16/88 [07:22<30:58, 25.82s/epoch, loss=1.17, accuracy=0.74, val_loss=3.1, val_accuracy=0.41, lr=0.1]    19%|█▉        | 17/88 [07:47<30:07, 25.45s/epoch, loss=1.17, accuracy=0.74, val_loss=2.99, val_accuracy=0.363, lr=0.1] 20%|██        | 18/88 [08:13<30:07, 25.82s/epoch, loss=1.18, accuracy=0.74, val_loss=1.43, val_accuracy=0.651, lr=0.1] 22%|██▏       | 19/88 [08:40<30:05, 26.17s/epoch, loss=1.17, accuracy=0.742, val_loss=1.69, val_accuracy=0.554, lr=0.1] 23%|██▎       | 20/88 [09:06<29:31, 26.05s/epoch, loss=1.17, accuracy=0.744, val_loss=1.72, val_accuracy=0.535, lr=0.0316] 24%|██▍       | 21/88 [09:31<28:40, 25.68s/epoch, loss=1.16, accuracy=0.744, val_loss=2.3, val_accuracy=0.405, lr=0.1]     25%|██▌       | 22/88 [09:57<28:25, 25.84s/epoch, loss=1.16, accuracy=0.745, val_loss=1.43, val_accuracy=0.633, lr=0.1] 26%|██▌       | 23/88 [10:23<27:59, 25.84s/epoch, loss=1.17, accuracy=0.742, val_loss=1.91, val_accuracy=0.516, lr=0.1] 27%|██▋       | 24/88 [10:48<27:24, 25.70s/epoch, loss=1.15, accuracy=0.747, val_loss=4.38, val_accuracy=0.306, lr=0.1] 28%|██▊       | 25/88 [11:13<26:47, 25.52s/epoch, loss=1.15, accuracy=0.745, val_loss=1.61, val_accuracy=0.598, lr=0.0316] 30%|██▉       | 26/88 [11:39<26:32, 25.69s/epoch, loss=1.15, accuracy=0.748, val_loss=1.93, val_accuracy=0.539, lr=0.1]    31%|███       | 27/88 [12:03<25:30, 25.09s/epoch, loss=1.15, accuracy=0.747, val_loss=1.81, val_accuracy=0.555, lr=0.1] 32%|███▏      | 28/88 [12:29<25:29, 25.48s/epoch, loss=1.15, accuracy=0.747, val_loss=1.99, val_accuracy=0.474, lr=0.1] 33%|███▎      | 29/88 [12:53<24:28, 24.89s/epoch, loss=1.15, accuracy=0.749, val_loss=1.72, val_accuracy=0.561, lr=0.1] 34%|███▍      | 30/88 [13:17<23:42, 24.52s/epoch, loss=1.15, accuracy=0.749, val_loss=2.67, val_accuracy=0.425, lr=0.0316] 35%|███▌      | 31/88 [13:40<23:01, 24.23s/epoch, loss=1.15, accuracy=0.749, val_loss=1.97, val_accuracy=0.444, lr=0.1]    36%|███▋      | 32/88 [14:04<22:24, 24.01s/epoch, loss=1.14, accuracy=0.75, val_loss=2.12, val_accuracy=0.465, lr=0.1]  38%|███▊      | 33/88 [14:27<21:53, 23.89s/epoch, loss=1.14, accuracy=0.75, val_loss=3.66, val_accuracy=0.226, lr=0.1] 39%|███▊      | 34/88 [14:54<22:14, 24.72s/epoch, loss=1.14, accuracy=0.749, val_loss=2.8, val_accuracy=0.449, lr=0.1] 40%|███▉      | 35/88 [15:21<22:21, 25.30s/epoch, loss=1.14, accuracy=0.748, val_loss=3.4, val_accuracy=0.419, lr=0.0316] 41%|████      | 36/88 [15:45<21:42, 25.04s/epoch, loss=1.14, accuracy=0.752, val_loss=2.24, val_accuracy=0.476, lr=0.1]   42%|████▏     | 37/88 [16:10<21:22, 25.15s/epoch, loss=1.14, accuracy=0.753, val_loss=2.04, val_accuracy=0.436, lr=0.1] 43%|████▎     | 38/88 [16:37<21:17, 25.55s/epoch, loss=1.14, accuracy=0.753, val_loss=1.48, val_accuracy=0.639, lr=0.1] 44%|████▍     | 39/88 [17:01<20:30, 25.12s/epoch, loss=1.14, accuracy=0.751, val_loss=2.36, val_accuracy=0.445, lr=0.1] 45%|████▌     | 40/88 [17:27<20:15, 25.31s/epoch, loss=1.13, accuracy=0.751, val_loss=2.32, val_accuracy=0.412, lr=0.0316] 47%|████▋     | 41/88 [17:53<20:03, 25.61s/epoch, loss=1.13, accuracy=0.753, val_loss=3.62, val_accuracy=0.221, lr=0.1]    48%|████▊     | 42/88 [18:19<19:42, 25.71s/epoch, loss=1.14, accuracy=0.752, val_loss=1.77, val_accuracy=0.55, lr=0.1]  49%|████▉     | 43/88 [18:43<18:47, 25.06s/epoch, loss=1.13, accuracy=0.753, val_loss=3.23, val_accuracy=0.394, lr=0.1] 50%|█████     | 44/88 [19:08<18:25, 25.14s/epoch, loss=1.13, accuracy=0.753, val_loss=2.5, val_accuracy=0.395, lr=0.1]  51%|█████     | 45/88 [19:33<18:01, 25.15s/epoch, loss=1.13, accuracy=0.752, val_loss=1.64, val_accuracy=0.596, lr=0.0316] 52%|█████▏    | 46/88 [19:59<17:41, 25.27s/epoch, loss=1.13, accuracy=0.754, val_loss=2.41, val_accuracy=0.518, lr=0.1]    53%|█████▎    | 47/88 [20:24<17:16, 25.29s/epoch, loss=1.13, accuracy=0.755, val_loss=1.49, val_accuracy=0.64, lr=0.1]  55%|█████▍    | 48/88 [20:47<16:30, 24.76s/epoch, loss=1.12, accuracy=0.755, val_loss=1.75, val_accuracy=0.519, lr=0.1] 56%|█████▌    | 49/88 [21:12<16:00, 24.62s/epoch, loss=1.13, accuracy=0.755, val_loss=3.65, val_accuracy=0.405, lr=0.1] 57%|█████▋    | 50/88 [21:38<15:55, 25.14s/epoch, loss=1.13, accuracy=0.754, val_loss=6.97, val_accuracy=0.188, lr=0.0316] 58%|█████▊    | 51/88 [22:05<15:48, 25.65s/epoch, loss=1.12, accuracy=0.756, val_loss=3.84, val_accuracy=0.357, lr=0.1]    59%|█████▉    | 52/88 [22:31<15:31, 25.87s/epoch, loss=1.13, accuracy=0.754, val_loss=2.35, val_accuracy=0.428, lr=0.1] 60%|██████    | 53/88 [22:57<14:59, 25.71s/epoch, loss=1.13, accuracy=0.754, val_loss=3.12, val_accuracy=0.391, lr=0.1] 61%|██████▏   | 54/88 [23:23<14:37, 25.81s/epoch, loss=1.13, accuracy=0.754, val_loss=2.1, val_accuracy=0.468, lr=0.1]  62%|██████▎   | 55/88 [23:49<14:11, 25.81s/epoch, loss=1.12, accuracy=0.756, val_loss=2.16, val_accuracy=0.41, lr=0.0316] 64%|██████▎   | 56/88 [24:15<13:55, 26.10s/epoch, loss=1.12, accuracy=0.755, val_loss=2.32, val_accuracy=0.457, lr=0.1]   65%|██████▍   | 57/88 [24:42<13:30, 26.16s/epoch, loss=1.13, accuracy=0.755, val_loss=2.11, val_accuracy=0.483, lr=0.1] 66%|██████▌   | 58/88 [25:05<12:43, 25.44s/epoch, loss=1.12, accuracy=0.757, val_loss=1.68, val_accuracy=0.562, lr=0.1] 67%|██████▋   | 59/88 [25:31<12:16, 25.41s/epoch, loss=1.12, accuracy=0.755, val_loss=2.36, val_accuracy=0.407, lr=0.1] 68%|██████▊   | 60/88 [25:57<11:57, 25.62s/epoch, loss=1.13, accuracy=0.755, val_loss=3.4, val_accuracy=0.305, lr=0.0316] 69%|██████▉   | 61/88 [26:24<11:40, 25.95s/epoch, loss=1.12, accuracy=0.757, val_loss=2.19, val_accuracy=0.513, lr=0.1]   70%|███████   | 62/88 [26:50<11:19, 26.15s/epoch, loss=1.13, accuracy=0.752, val_loss=2.93, val_accuracy=0.351, lr=0.1] 72%|███████▏  | 63/88 [27:17<10:56, 26.27s/epoch, loss=1.12, accuracy=0.756, val_loss=5.53, val_accuracy=0.254, lr=0.1] 73%|███████▎  | 64/88 [27:44<10:34, 26.46s/epoch, loss=1.12, accuracy=0.757, val_loss=2.26, val_accuracy=0.468, lr=0.1] 74%|███████▍  | 65/88 [28:10<10:11, 26.57s/epoch, loss=1.12, accuracy=0.755, val_loss=2.05, val_accuracy=0.486, lr=0.0316] 75%|███████▌  | 66/88 [28:37<09:44, 26.58s/epoch, loss=1.12, accuracy=0.757, val_loss=2, val_accuracy=0.492, lr=0.1]       76%|███████▌  | 67/88 [29:04<09:19, 26.62s/epoch, loss=1.11, accuracy=0.758, val_loss=2.49, val_accuracy=0.384, lr=0.1] 77%|███████▋  | 68/88 [29:28<08:39, 25.98s/epoch, loss=1.12, accuracy=0.755, val_loss=7.19, val_accuracy=0.172, lr=0.1] 78%|███████▊  | 69/88 [29:55<08:17, 26.21s/epoch, loss=1.12, accuracy=0.756, val_loss=1.67, val_accuracy=0.57, lr=0.1]  80%|███████▉  | 70/88 [30:20<07:47, 25.99s/epoch, loss=1.12, accuracy=0.756, val_loss=2.61, val_accuracy=0.377, lr=0.0316] 81%|████████  | 71/88 [30:45<07:13, 25.52s/epoch, loss=1.12, accuracy=0.757, val_loss=4.38, val_accuracy=0.265, lr=0.1]    82%|████████▏ | 72/88 [31:13<06:58, 26.17s/epoch, loss=1.12, accuracy=0.755, val_loss=2.19, val_accuracy=0.499, lr=0.1] 83%|████████▎ | 73/88 [31:36<06:21, 25.45s/epoch, loss=1.12, accuracy=0.758, val_loss=1.6, val_accuracy=0.595, lr=0.1]  84%|████████▍ | 74/88 [32:00<05:48, 24.92s/epoch, loss=1.12, accuracy=0.756, val_loss=2.43, val_accuracy=0.362, lr=0.1] 85%|████████▌ | 75/88 [32:24<05:20, 24.65s/epoch, loss=1.11, accuracy=0.757, val_loss=2.77, val_accuracy=0.36, lr=0.0316] 86%|████████▋ | 76/88 [32:48<04:53, 24.50s/epoch, loss=1.12, accuracy=0.755, val_loss=2.34, val_accuracy=0.477, lr=0.1]   88%|████████▊ | 77/88 [33:12<04:26, 24.25s/epoch, loss=1.11, accuracy=0.757, val_loss=2.03, val_accuracy=0.516, lr=0.1] 89%|████████▊ | 78/88 [33:35<04:00, 24.04s/epoch, loss=1.11, accuracy=0.758, val_loss=2.45, val_accuracy=0.413, lr=0.1] 90%|████████▉ | 79/88 [33:59<03:35, 23.90s/epoch, loss=1.11, accuracy=0.757, val_loss=3.8, val_accuracy=0.318, lr=0.1]  91%|█████████ | 80/88 [34:23<03:10, 23.86s/epoch, loss=1.12, accuracy=0.757, val_loss=3.19, val_accuracy=0.418, lr=0.0316] 92%|█████████▏| 81/88 [34:47<02:48, 24.10s/epoch, loss=1.12, accuracy=0.757, val_loss=1.56, val_accuracy=0.6, lr=0.1]      93%|█████████▎| 82/88 [35:14<02:28, 24.73s/epoch, loss=0.907, accuracy=0.815, val_loss=0.875, val_accuracy=0.805, lr=0.01] 94%|█████████▍| 83/88 [35:40<02:06, 25.26s/epoch, loss=0.728, accuracy=0.848, val_loss=0.78, val_accuracy=0.82, lr=0.01]   95%|█████████▌| 84/88 [36:05<01:40, 25.24s/epoch, loss=0.647, accuracy=0.857, val_loss=0.785, val_accuracy=0.8, lr=0.01] 97%|█████████▋| 85/88 [36:29<01:14, 24.72s/epoch, loss=0.608, accuracy=0.859, val_loss=0.825, val_accuracy=0.778, lr=0.01] 98%|█████████▊| 86/88 [36:54<00:49, 24.76s/epoch, loss=0.586, accuracy=0.859, val_loss=0.984, val_accuracy=0.723, lr=0.01] 99%|█████████▉| 87/88 [37:17<00:24, 24.35s/epoch, loss=0.572, accuracy=0.862, val_loss=0.691, val_accuracy=0.822, lr=0.01]100%|██████████| 88/88 [37:43<00:00, 24.90s/epoch, loss=0.57, accuracy=0.863, val_loss=1.09, val_accuracy=0.725, lr=0.01]  100%|██████████| 88/88 [37:43<00:00, 25.72s/epoch, loss=0.57, accuracy=0.863, val_loss=1.09, val_accuracy=0.725, lr=0.01]
Using real-time data augmentation.
Test loss: 1.0857517719268799
Test accuracy: 0.7250999808311462


* * * Run SGD for ID = 17_14. * * *


2024-02-15 22:07:40.192475: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 22:07:43.146719: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 22:07:43.148054: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-15 22:07:43.187676: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 22:07:43.187745: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 22:07:43.190728: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 22:07:43.190773: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 22:07:43.193278: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 22:07:43.193987: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 22:07:43.196574: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 22:07:43.198124: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 22:07:43.203150: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 22:07:43.203710: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 22:07:43.203791: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 22:07:44.554624: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-15 22:07:44.555614: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 22:07:44.556097: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 22:07:44.556132: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 22:07:44.556166: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 22:07:44.556184: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 22:07:44.556201: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 22:07:44.556218: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 22:07:44.556235: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 22:07:44.556252: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 22:07:44.556269: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 22:07:44.556759: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 22:07:44.556803: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 22:07:45.277091: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-15 22:07:45.277152: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-15 22:07:45.277162: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-15 22:07:45.278560: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': 1714, 'batch_size': 128, 'epochs': 88, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/88 [00:00<?, ?epoch/s]2024-02-15 22:07:46.124508: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-15 22:07:46.136822: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199950000 Hz
2024-02-15 22:07:48.393016: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 22:07:48.654433: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 22:07:49.378490: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-15 22:07:49.436873: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/88 [01:03<1:32:32, 63.82s/epoch, loss=3.23, accuracy=0.313, val_loss=2.19, val_accuracy=0.264, lr=0.1]  2%|▏         | 2/88 [01:28<58:24, 40.75s/epoch, loss=1.63, accuracy=0.494, val_loss=1.65, val_accuracy=0.486, lr=0.1]    3%|▎         | 3/88 [01:54<48:08, 33.99s/epoch, loss=1.43, accuracy=0.601, val_loss=2.11, val_accuracy=0.441, lr=0.1]  5%|▍         | 4/88 [02:19<42:32, 30.39s/epoch, loss=1.34, accuracy=0.662, val_loss=1.56, val_accuracy=0.582, lr=0.1]  6%|▌         | 5/88 [02:45<40:06, 28.99s/epoch, loss=1.28, accuracy=0.691, val_loss=2.57, val_accuracy=0.396, lr=0.1]  7%|▋         | 6/88 [03:12<38:32, 28.20s/epoch, loss=1.25, accuracy=0.706, val_loss=1.56, val_accuracy=0.613, lr=0.1]  8%|▊         | 7/88 [03:37<36:43, 27.20s/epoch, loss=1.24, accuracy=0.715, val_loss=2.02, val_accuracy=0.501, lr=0.1]  9%|▉         | 8/88 [04:01<34:40, 26.01s/epoch, loss=1.24, accuracy=0.72, val_loss=1.97, val_accuracy=0.502, lr=0.1]  10%|█         | 9/88 [04:27<34:28, 26.18s/epoch, loss=1.23, accuracy=0.722, val_loss=2.38, val_accuracy=0.437, lr=0.1] 11%|█▏        | 10/88 [04:51<33:02, 25.42s/epoch, loss=1.22, accuracy=0.729, val_loss=1.54, val_accuracy=0.608, lr=0.1] 12%|█▎        | 11/88 [05:14<31:52, 24.83s/epoch, loss=1.21, accuracy=0.731, val_loss=2.23, val_accuracy=0.453, lr=0.1] 14%|█▎        | 12/88 [05:40<31:55, 25.20s/epoch, loss=1.21, accuracy=0.733, val_loss=1.98, val_accuracy=0.503, lr=0.1] 15%|█▍        | 13/88 [06:04<30:52, 24.69s/epoch, loss=1.21, accuracy=0.732, val_loss=1.57, val_accuracy=0.625, lr=0.1] 16%|█▌        | 14/88 [06:30<31:05, 25.21s/epoch, loss=1.2, accuracy=0.737, val_loss=1.53, val_accuracy=0.602, lr=0.1]  17%|█▋        | 15/88 [06:56<30:50, 25.35s/epoch, loss=1.2, accuracy=0.736, val_loss=2.37, val_accuracy=0.408, lr=0.1] 18%|█▊        | 16/88 [07:20<30:01, 25.03s/epoch, loss=1.19, accuracy=0.74, val_loss=1.64, val_accuracy=0.565, lr=0.1] 19%|█▉        | 17/88 [07:46<30:01, 25.37s/epoch, loss=1.19, accuracy=0.739, val_loss=2.07, val_accuracy=0.494, lr=0.1] 20%|██        | 18/88 [08:11<29:10, 25.01s/epoch, loss=1.19, accuracy=0.741, val_loss=1.46, val_accuracy=0.646, lr=0.1] 22%|██▏       | 19/88 [08:34<28:12, 24.52s/epoch, loss=1.18, accuracy=0.743, val_loss=2.22, val_accuracy=0.389, lr=0.1] 23%|██▎       | 20/88 [08:59<27:57, 24.67s/epoch, loss=1.18, accuracy=0.743, val_loss=2, val_accuracy=0.534, lr=0.1]    24%|██▍       | 21/88 [09:23<27:24, 24.54s/epoch, loss=1.19, accuracy=0.741, val_loss=1.59, val_accuracy=0.589, lr=0.1] 25%|██▌       | 22/88 [09:47<26:37, 24.20s/epoch, loss=1.18, accuracy=0.745, val_loss=1.55, val_accuracy=0.628, lr=0.1] 26%|██▌       | 23/88 [10:13<26:57, 24.89s/epoch, loss=1.18, accuracy=0.745, val_loss=1.58, val_accuracy=0.619, lr=0.0316] 27%|██▋       | 24/88 [10:38<26:40, 25.01s/epoch, loss=1.18, accuracy=0.744, val_loss=2.35, val_accuracy=0.472, lr=0.1]    28%|██▊       | 25/88 [11:05<26:49, 25.54s/epoch, loss=1.17, accuracy=0.745, val_loss=2.07, val_accuracy=0.502, lr=0.1] 30%|██▉       | 26/88 [11:31<26:32, 25.69s/epoch, loss=1.17, accuracy=0.745, val_loss=2.19, val_accuracy=0.512, lr=0.1] 31%|███       | 27/88 [11:55<25:33, 25.14s/epoch, loss=1.17, accuracy=0.748, val_loss=2.06, val_accuracy=0.444, lr=0.1] 32%|███▏      | 28/88 [12:19<24:52, 24.87s/epoch, loss=1.16, accuracy=0.748, val_loss=1.77, val_accuracy=0.551, lr=0.0316] 33%|███▎      | 29/88 [12:44<24:20, 24.75s/epoch, loss=1.17, accuracy=0.748, val_loss=2.06, val_accuracy=0.473, lr=0.1]    34%|███▍      | 30/88 [13:10<24:26, 25.29s/epoch, loss=1.17, accuracy=0.747, val_loss=1.65, val_accuracy=0.617, lr=0.1] 35%|███▌      | 31/88 [13:36<24:12, 25.48s/epoch, loss=1.16, accuracy=0.751, val_loss=1.77, val_accuracy=0.555, lr=0.1] 36%|███▋      | 32/88 [14:00<23:17, 24.96s/epoch, loss=1.16, accuracy=0.748, val_loss=1.89, val_accuracy=0.552, lr=0.1] 38%|███▊      | 33/88 [14:25<22:45, 24.83s/epoch, loss=1.16, accuracy=0.749, val_loss=1.51, val_accuracy=0.616, lr=0.0316] 39%|███▊      | 34/88 [14:48<22:01, 24.48s/epoch, loss=1.16, accuracy=0.749, val_loss=1.5, val_accuracy=0.628, lr=0.1]     40%|███▉      | 35/88 [15:12<21:23, 24.22s/epoch, loss=1.16, accuracy=0.749, val_loss=3.25, val_accuracy=0.348, lr=0.1] 41%|████      | 36/88 [15:39<21:41, 25.02s/epoch, loss=1.16, accuracy=0.751, val_loss=3.28, val_accuracy=0.312, lr=0.1] 42%|████▏     | 37/88 [16:03<21:03, 24.78s/epoch, loss=1.15, accuracy=0.75, val_loss=1.98, val_accuracy=0.448, lr=0.1]  43%|████▎     | 38/88 [16:26<20:21, 24.43s/epoch, loss=1.15, accuracy=0.751, val_loss=1.72, val_accuracy=0.549, lr=0.0316] 44%|████▍     | 39/88 [16:51<20:04, 24.58s/epoch, loss=1.15, accuracy=0.75, val_loss=1.81, val_accuracy=0.533, lr=0.1]     45%|████▌     | 40/88 [17:15<19:23, 24.24s/epoch, loss=1.15, accuracy=0.753, val_loss=1.85, val_accuracy=0.528, lr=0.1] 47%|████▋     | 41/88 [17:42<19:33, 24.97s/epoch, loss=1.16, accuracy=0.751, val_loss=1.61, val_accuracy=0.61, lr=0.1]  48%|████▊     | 42/88 [18:06<19:03, 24.86s/epoch, loss=1.15, accuracy=0.753, val_loss=1.49, val_accuracy=0.633, lr=0.1] 49%|████▉     | 43/88 [18:30<18:30, 24.68s/epoch, loss=1.16, accuracy=0.753, val_loss=1.95, val_accuracy=0.473, lr=0.0316] 50%|█████     | 44/88 [18:54<17:49, 24.31s/epoch, loss=1.16, accuracy=0.751, val_loss=2.07, val_accuracy=0.519, lr=0.1]    51%|█████     | 45/88 [19:19<17:34, 24.53s/epoch, loss=1.15, accuracy=0.754, val_loss=1.61, val_accuracy=0.597, lr=0.1] 52%|█████▏    | 46/88 [19:43<17:00, 24.29s/epoch, loss=1.15, accuracy=0.752, val_loss=1.46, val_accuracy=0.646, lr=0.1] 53%|█████▎    | 47/88 [20:07<16:40, 24.41s/epoch, loss=1.15, accuracy=0.753, val_loss=1.57, val_accuracy=0.593, lr=0.1] 55%|█████▍    | 48/88 [20:33<16:30, 24.77s/epoch, loss=1.16, accuracy=0.75, val_loss=1.79, val_accuracy=0.554, lr=0.0316] 56%|█████▌    | 49/88 [20:58<16:10, 24.90s/epoch, loss=1.15, accuracy=0.754, val_loss=2.09, val_accuracy=0.504, lr=0.1]   57%|█████▋    | 50/88 [21:23<15:46, 24.91s/epoch, loss=1.15, accuracy=0.755, val_loss=1.54, val_accuracy=0.639, lr=0.1] 58%|█████▊    | 51/88 [21:49<15:28, 25.09s/epoch, loss=1.15, accuracy=0.755, val_loss=1.62, val_accuracy=0.61, lr=0.1]  59%|█████▉    | 52/88 [22:14<15:04, 25.12s/epoch, loss=1.15, accuracy=0.754, val_loss=1.97, val_accuracy=0.512, lr=0.1] 60%|██████    | 53/88 [22:38<14:28, 24.81s/epoch, loss=1.15, accuracy=0.754, val_loss=3.32, val_accuracy=0.291, lr=0.0316] 61%|██████▏   | 54/88 [23:01<13:51, 24.45s/epoch, loss=1.15, accuracy=0.752, val_loss=4.17, val_accuracy=0.294, lr=0.1]    62%|██████▎   | 55/88 [23:27<13:39, 24.83s/epoch, loss=1.14, accuracy=0.755, val_loss=1.61, val_accuracy=0.583, lr=0.1] 64%|██████▎   | 56/88 [23:52<13:11, 24.73s/epoch, loss=1.15, accuracy=0.75, val_loss=2.88, val_accuracy=0.362, lr=0.1]  65%|██████▍   | 57/88 [24:16<12:44, 24.66s/epoch, loss=1.15, accuracy=0.753, val_loss=1.47, val_accuracy=0.652, lr=0.1] 66%|██████▌   | 58/88 [24:43<12:35, 25.17s/epoch, loss=1.14, accuracy=0.755, val_loss=2.13, val_accuracy=0.563, lr=0.0316] 67%|██████▋   | 59/88 [25:09<12:24, 25.68s/epoch, loss=1.15, accuracy=0.752, val_loss=2.22, val_accuracy=0.369, lr=0.1]    68%|██████▊   | 60/88 [25:35<11:54, 25.51s/epoch, loss=1.14, accuracy=0.754, val_loss=1.38, val_accuracy=0.683, lr=0.1] 69%|██████▉   | 61/88 [25:58<11:13, 24.93s/epoch, loss=1.14, accuracy=0.755, val_loss=1.56, val_accuracy=0.627, lr=0.1] 70%|███████   | 62/88 [26:23<10:43, 24.77s/epoch, loss=1.14, accuracy=0.756, val_loss=1.88, val_accuracy=0.489, lr=0.1] 72%|███████▏  | 63/88 [26:49<10:30, 25.21s/epoch, loss=1.14, accuracy=0.755, val_loss=1.51, val_accuracy=0.636, lr=0.1] 73%|███████▎  | 64/88 [27:16<10:17, 25.72s/epoch, loss=1.14, accuracy=0.755, val_loss=1.76, val_accuracy=0.57, lr=0.1]  74%|███████▍  | 65/88 [27:42<09:57, 25.99s/epoch, loss=1.14, accuracy=0.756, val_loss=3.61, val_accuracy=0.232, lr=0.0316] 75%|███████▌  | 66/88 [28:07<09:26, 25.75s/epoch, loss=1.14, accuracy=0.754, val_loss=2.68, val_accuracy=0.29, lr=0.1]     76%|███████▌  | 67/88 [28:32<08:56, 25.53s/epoch, loss=1.14, accuracy=0.755, val_loss=2.6, val_accuracy=0.327, lr=0.1] 77%|███████▋  | 68/88 [28:56<08:18, 24.92s/epoch, loss=1.14, accuracy=0.754, val_loss=1.43, val_accuracy=0.646, lr=0.1] 78%|███████▊  | 69/88 [29:22<07:58, 25.20s/epoch, loss=1.14, accuracy=0.756, val_loss=2.17, val_accuracy=0.433, lr=0.1] 80%|███████▉  | 70/88 [29:45<07:24, 24.71s/epoch, loss=1.13, accuracy=0.757, val_loss=2.22, val_accuracy=0.472, lr=0.0316] 81%|████████  | 71/88 [30:09<06:54, 24.37s/epoch, loss=1.13, accuracy=0.754, val_loss=1.71, val_accuracy=0.585, lr=0.1]    82%|████████▏ | 72/88 [30:35<06:39, 24.96s/epoch, loss=1.14, accuracy=0.757, val_loss=2.37, val_accuracy=0.445, lr=0.1] 83%|████████▎ | 73/88 [31:00<06:15, 25.02s/epoch, loss=1.13, accuracy=0.757, val_loss=1.51, val_accuracy=0.63, lr=0.1]  84%|████████▍ | 74/88 [31:26<05:54, 25.29s/epoch, loss=1.13, accuracy=0.757, val_loss=2.49, val_accuracy=0.329, lr=0.1] 85%|████████▌ | 75/88 [31:51<05:26, 25.14s/epoch, loss=1.13, accuracy=0.759, val_loss=4.76, val_accuracy=0.317, lr=0.0316] 86%|████████▋ | 76/88 [32:15<04:57, 24.80s/epoch, loss=1.13, accuracy=0.755, val_loss=1.96, val_accuracy=0.49, lr=0.1]     88%|████████▊ | 77/88 [32:39<04:29, 24.48s/epoch, loss=1.12, accuracy=0.758, val_loss=1.87, val_accuracy=0.539, lr=0.1] 89%|████████▊ | 78/88 [33:02<04:01, 24.19s/epoch, loss=1.13, accuracy=0.757, val_loss=2.99, val_accuracy=0.341, lr=0.1] 90%|████████▉ | 79/88 [33:28<03:40, 24.49s/epoch, loss=1.13, accuracy=0.757, val_loss=2.04, val_accuracy=0.444, lr=0.1] 91%|█████████ | 80/88 [33:53<03:18, 24.75s/epoch, loss=1.13, accuracy=0.757, val_loss=1.58, val_accuracy=0.61, lr=0.0316] 92%|█████████▏| 81/88 [34:20<02:56, 25.28s/epoch, loss=1.13, accuracy=0.755, val_loss=2.06, val_accuracy=0.546, lr=0.1]   93%|█████████▎| 82/88 [34:44<02:30, 25.08s/epoch, loss=0.913, accuracy=0.817, val_loss=0.9, val_accuracy=0.802, lr=0.01] 94%|█████████▍| 83/88 [35:08<02:04, 24.87s/epoch, loss=0.734, accuracy=0.847, val_loss=0.783, val_accuracy=0.818, lr=0.01] 95%|█████████▌| 84/88 [35:34<01:40, 25.20s/epoch, loss=0.654, accuracy=0.855, val_loss=0.764, val_accuracy=0.808, lr=0.01] 97%|█████████▋| 85/88 [36:00<01:16, 25.39s/epoch, loss=0.607, accuracy=0.86, val_loss=0.742, val_accuracy=0.808, lr=0.01]  98%|█████████▊| 86/88 [36:24<00:49, 24.76s/epoch, loss=0.589, accuracy=0.86, val_loss=0.769, val_accuracy=0.796, lr=0.01] 99%|█████████▉| 87/88 [36:48<00:24, 24.65s/epoch, loss=0.571, accuracy=0.863, val_loss=0.734, val_accuracy=0.807, lr=0.01]100%|██████████| 88/88 [37:14<00:00, 24.92s/epoch, loss=0.569, accuracy=0.864, val_loss=1.29, val_accuracy=0.648, lr=0.01] 100%|██████████| 88/88 [37:14<00:00, 25.39s/epoch, loss=0.569, accuracy=0.864, val_loss=1.29, val_accuracy=0.648, lr=0.01]
Using real-time data augmentation.
Test loss: 1.2886039018630981
Test accuracy: 0.6478000283241272


* * * Run SGD for ID = 17_15. * * *


2024-02-15 22:45:02.953534: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 22:45:05.858799: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 22:45:05.860137: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-15 22:45:05.900114: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 22:45:05.900153: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 22:45:05.903322: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 22:45:05.903368: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 22:45:05.905775: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 22:45:05.906480: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 22:45:05.909086: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 22:45:05.910752: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 22:45:05.915867: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 22:45:05.916451: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 22:45:05.916534: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 22:45:07.267063: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-15 22:45:07.267631: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 22:45:07.268119: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 22:45:07.268155: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 22:45:07.268191: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 22:45:07.268211: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 22:45:07.268229: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 22:45:07.268247: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 22:45:07.268265: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 22:45:07.268284: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 22:45:07.268302: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 22:45:07.268800: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 22:45:07.268845: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 22:45:07.983384: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-15 22:45:07.983459: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-15 22:45:07.983471: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-15 22:45:07.984907: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': 1715, 'batch_size': 128, 'epochs': 88, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/88 [00:00<?, ?epoch/s]2024-02-15 22:45:08.837241: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-15 22:45:08.849814: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199950000 Hz
2024-02-15 22:45:11.124368: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 22:45:11.449656: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 22:45:12.183051: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-15 22:45:12.244998: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/88 [01:05<1:34:21, 65.07s/epoch, loss=3.34, accuracy=0.304, val_loss=2.99, val_accuracy=0.19, lr=0.1]  2%|▏         | 2/88 [01:28<58:29, 40.81s/epoch, loss=1.54, accuracy=0.549, val_loss=1.75, val_accuracy=0.463, lr=0.1]   3%|▎         | 3/88 [01:53<47:21, 33.43s/epoch, loss=1.41, accuracy=0.607, val_loss=1.72, val_accuracy=0.496, lr=0.1]  5%|▍         | 4/88 [02:17<41:35, 29.71s/epoch, loss=1.35, accuracy=0.65, val_loss=2.62, val_accuracy=0.407, lr=0.1]   6%|▌         | 5/88 [02:42<38:33, 27.87s/epoch, loss=1.3, accuracy=0.678, val_loss=1.84, val_accuracy=0.518, lr=0.1]  7%|▋         | 6/88 [03:07<37:08, 27.17s/epoch, loss=1.27, accuracy=0.701, val_loss=1.99, val_accuracy=0.518, lr=0.1]  8%|▊         | 7/88 [03:31<35:12, 26.08s/epoch, loss=1.25, accuracy=0.711, val_loss=1.92, val_accuracy=0.533, lr=0.1]  9%|▉         | 8/88 [03:57<34:44, 26.06s/epoch, loss=1.24, accuracy=0.715, val_loss=1.55, val_accuracy=0.608, lr=0.1] 10%|█         | 9/88 [04:23<34:01, 25.85s/epoch, loss=1.23, accuracy=0.72, val_loss=2.2, val_accuracy=0.48, lr=0.1]    11%|█▏        | 10/88 [04:49<33:35, 25.84s/epoch, loss=1.22, accuracy=0.722, val_loss=1.99, val_accuracy=0.527, lr=0.1] 12%|█▎        | 11/88 [05:15<33:31, 26.12s/epoch, loss=1.21, accuracy=0.729, val_loss=1.74, val_accuracy=0.581, lr=0.1] 14%|█▎        | 12/88 [05:39<32:16, 25.48s/epoch, loss=1.2, accuracy=0.732, val_loss=1.67, val_accuracy=0.579, lr=0.1]  15%|█▍        | 13/88 [06:03<31:17, 25.04s/epoch, loss=1.2, accuracy=0.733, val_loss=2.23, val_accuracy=0.447, lr=0.0316] 16%|█▌        | 14/88 [06:29<31:12, 25.30s/epoch, loss=1.21, accuracy=0.73, val_loss=1.27, val_accuracy=0.705, lr=0.1]    17%|█▋        | 15/88 [06:55<31:02, 25.51s/epoch, loss=1.19, accuracy=0.735, val_loss=4.02, val_accuracy=0.314, lr=0.1] 18%|█▊        | 16/88 [07:19<30:03, 25.06s/epoch, loss=1.2, accuracy=0.736, val_loss=3.17, val_accuracy=0.357, lr=0.1]  19%|█▉        | 17/88 [07:47<30:29, 25.76s/epoch, loss=1.19, accuracy=0.738, val_loss=1.86, val_accuracy=0.533, lr=0.1] 20%|██        | 18/88 [08:14<30:31, 26.16s/epoch, loss=1.18, accuracy=0.742, val_loss=2.29, val_accuracy=0.446, lr=0.1] 22%|██▏       | 19/88 [08:39<29:38, 25.77s/epoch, loss=1.18, accuracy=0.741, val_loss=1.87, val_accuracy=0.49, lr=0.0316] 23%|██▎       | 20/88 [09:02<28:33, 25.20s/epoch, loss=1.18, accuracy=0.74, val_loss=2.03, val_accuracy=0.522, lr=0.1]    24%|██▍       | 21/88 [09:27<27:57, 25.04s/epoch, loss=1.18, accuracy=0.741, val_loss=2.37, val_accuracy=0.456, lr=0.1] 25%|██▌       | 22/88 [09:53<27:39, 25.15s/epoch, loss=1.17, accuracy=0.745, val_loss=2.04, val_accuracy=0.507, lr=0.1] 26%|██▌       | 23/88 [10:20<27:51, 25.72s/epoch, loss=1.17, accuracy=0.745, val_loss=6.7, val_accuracy=0.193, lr=0.1]  27%|██▋       | 24/88 [10:43<26:48, 25.13s/epoch, loss=1.16, accuracy=0.745, val_loss=1.51, val_accuracy=0.639, lr=0.0316] 28%|██▊       | 25/88 [11:09<26:36, 25.34s/epoch, loss=1.17, accuracy=0.747, val_loss=7.43, val_accuracy=0.117, lr=0.1]    30%|██▉       | 26/88 [11:35<26:28, 25.62s/epoch, loss=1.16, accuracy=0.745, val_loss=2.74, val_accuracy=0.388, lr=0.1] 31%|███       | 27/88 [12:02<26:27, 26.02s/epoch, loss=1.17, accuracy=0.747, val_loss=2.87, val_accuracy=0.3, lr=0.1]   32%|███▏      | 28/88 [12:28<25:48, 25.81s/epoch, loss=1.16, accuracy=0.749, val_loss=2.1, val_accuracy=0.506, lr=0.1] 33%|███▎      | 29/88 [12:55<25:46, 26.22s/epoch, loss=1.15, accuracy=0.75, val_loss=2.63, val_accuracy=0.275, lr=0.0316] 34%|███▍      | 30/88 [13:21<25:19, 26.20s/epoch, loss=1.16, accuracy=0.747, val_loss=2.18, val_accuracy=0.498, lr=0.1]   35%|███▌      | 31/88 [13:46<24:25, 25.71s/epoch, loss=1.15, accuracy=0.751, val_loss=2.09, val_accuracy=0.446, lr=0.1] 36%|███▋      | 32/88 [14:12<24:07, 25.84s/epoch, loss=1.15, accuracy=0.748, val_loss=1.95, val_accuracy=0.494, lr=0.1] 38%|███▊      | 33/88 [14:36<23:07, 25.23s/epoch, loss=1.15, accuracy=0.752, val_loss=1.6, val_accuracy=0.582, lr=0.1]  39%|███▊      | 34/88 [15:02<22:58, 25.52s/epoch, loss=1.15, accuracy=0.751, val_loss=2.82, val_accuracy=0.369, lr=0.0316] 40%|███▉      | 35/88 [15:28<22:43, 25.73s/epoch, loss=1.14, accuracy=0.753, val_loss=3.39, val_accuracy=0.389, lr=0.1]    41%|████      | 36/88 [15:53<22:01, 25.41s/epoch, loss=1.15, accuracy=0.749, val_loss=2.78, val_accuracy=0.456, lr=0.1] 42%|████▏     | 37/88 [16:19<21:52, 25.73s/epoch, loss=1.14, accuracy=0.752, val_loss=1.61, val_accuracy=0.622, lr=0.1] 43%|████▎     | 38/88 [16:44<21:19, 25.58s/epoch, loss=1.14, accuracy=0.752, val_loss=1.99, val_accuracy=0.494, lr=0.1] 44%|████▍     | 39/88 [17:11<21:07, 25.87s/epoch, loss=1.14, accuracy=0.754, val_loss=2.93, val_accuracy=0.313, lr=0.0316] 45%|████▌     | 40/88 [17:38<20:59, 26.24s/epoch, loss=1.15, accuracy=0.751, val_loss=1.86, val_accuracy=0.539, lr=0.1]    47%|████▋     | 41/88 [18:05<20:42, 26.43s/epoch, loss=1.14, accuracy=0.754, val_loss=3.29, val_accuracy=0.313, lr=0.1] 48%|████▊     | 42/88 [18:31<20:06, 26.22s/epoch, loss=1.14, accuracy=0.754, val_loss=1.46, val_accuracy=0.626, lr=0.1] 49%|████▉     | 43/88 [18:54<19:08, 25.52s/epoch, loss=1.14, accuracy=0.751, val_loss=1.76, val_accuracy=0.584, lr=0.1] 50%|█████     | 44/88 [19:20<18:42, 25.52s/epoch, loss=1.14, accuracy=0.752, val_loss=1.44, val_accuracy=0.646, lr=0.0316] 51%|█████     | 45/88 [19:44<18:02, 25.18s/epoch, loss=1.14, accuracy=0.751, val_loss=1.91, val_accuracy=0.499, lr=0.1]    52%|█████▏    | 46/88 [20:11<17:54, 25.59s/epoch, loss=1.14, accuracy=0.753, val_loss=2.01, val_accuracy=0.477, lr=0.1] 53%|█████▎    | 47/88 [20:37<17:40, 25.87s/epoch, loss=1.14, accuracy=0.756, val_loss=2.33, val_accuracy=0.49, lr=0.1]  55%|█████▍    | 48/88 [21:03<17:10, 25.76s/epoch, loss=1.14, accuracy=0.755, val_loss=2.31, val_accuracy=0.425, lr=0.1] 56%|█████▌    | 49/88 [21:30<16:54, 26.00s/epoch, loss=1.13, accuracy=0.755, val_loss=1.81, val_accuracy=0.542, lr=0.0316] 57%|█████▋    | 50/88 [21:54<16:06, 25.44s/epoch, loss=1.12, accuracy=0.757, val_loss=2.39, val_accuracy=0.384, lr=0.1]    58%|█████▊    | 51/88 [22:20<15:50, 25.68s/epoch, loss=1.13, accuracy=0.756, val_loss=2.62, val_accuracy=0.421, lr=0.1] 59%|█████▉    | 52/88 [22:45<15:23, 25.64s/epoch, loss=1.13, accuracy=0.756, val_loss=1.52, val_accuracy=0.627, lr=0.1] 60%|██████    | 53/88 [23:10<14:40, 25.17s/epoch, loss=1.14, accuracy=0.751, val_loss=2.42, val_accuracy=0.491, lr=0.1] 61%|██████▏   | 54/88 [23:36<14:33, 25.69s/epoch, loss=1.13, accuracy=0.752, val_loss=1.51, val_accuracy=0.625, lr=0.0316] 62%|██████▎   | 55/88 [24:04<14:23, 26.17s/epoch, loss=1.13, accuracy=0.756, val_loss=1.48, val_accuracy=0.624, lr=0.1]    64%|██████▎   | 56/88 [24:29<13:47, 25.86s/epoch, loss=1.13, accuracy=0.756, val_loss=1.97, val_accuracy=0.538, lr=0.1] 65%|██████▍   | 57/88 [24:56<13:36, 26.35s/epoch, loss=1.13, accuracy=0.756, val_loss=2.12, val_accuracy=0.502, lr=0.1] 66%|██████▌   | 58/88 [25:24<13:20, 26.67s/epoch, loss=1.13, accuracy=0.757, val_loss=1.82, val_accuracy=0.542, lr=0.1] 67%|██████▋   | 59/88 [25:48<12:32, 25.94s/epoch, loss=1.13, accuracy=0.757, val_loss=1.61, val_accuracy=0.591, lr=0.0316] 68%|██████▊   | 60/88 [26:14<12:10, 26.09s/epoch, loss=1.13, accuracy=0.757, val_loss=2.13, val_accuracy=0.558, lr=0.1]    69%|██████▉   | 61/88 [26:41<11:44, 26.10s/epoch, loss=1.13, accuracy=0.757, val_loss=1.72, val_accuracy=0.557, lr=0.1] 70%|███████   | 62/88 [27:05<11:07, 25.66s/epoch, loss=1.13, accuracy=0.758, val_loss=2.09, val_accuracy=0.511, lr=0.1] 72%|███████▏  | 63/88 [27:31<10:43, 25.75s/epoch, loss=1.12, accuracy=0.757, val_loss=2, val_accuracy=0.536, lr=0.1]    73%|███████▎  | 64/88 [27:55<10:07, 25.31s/epoch, loss=1.13, accuracy=0.753, val_loss=1.83, val_accuracy=0.523, lr=0.0316] 74%|███████▍  | 65/88 [28:22<09:50, 25.68s/epoch, loss=1.13, accuracy=0.755, val_loss=1.86, val_accuracy=0.495, lr=0.1]    75%|███████▌  | 66/88 [28:48<09:25, 25.73s/epoch, loss=1.12, accuracy=0.759, val_loss=6.17, val_accuracy=0.159, lr=0.1] 76%|███████▌  | 67/88 [29:12<08:47, 25.12s/epoch, loss=1.13, accuracy=0.757, val_loss=1.91, val_accuracy=0.479, lr=0.1] 77%|███████▋  | 68/88 [29:37<08:26, 25.33s/epoch, loss=1.13, accuracy=0.757, val_loss=1.63, val_accuracy=0.587, lr=0.1] 78%|███████▊  | 69/88 [30:02<07:57, 25.13s/epoch, loss=1.12, accuracy=0.755, val_loss=2.11, val_accuracy=0.474, lr=0.0316] 80%|███████▉  | 70/88 [30:28<07:35, 25.30s/epoch, loss=1.13, accuracy=0.755, val_loss=2.33, val_accuracy=0.399, lr=0.1]    81%|████████  | 71/88 [30:52<07:04, 24.98s/epoch, loss=1.12, accuracy=0.758, val_loss=2.09, val_accuracy=0.539, lr=0.1] 82%|████████▏ | 72/88 [31:19<06:47, 25.45s/epoch, loss=1.12, accuracy=0.759, val_loss=2.22, val_accuracy=0.471, lr=0.1] 83%|████████▎ | 73/88 [31:45<06:27, 25.82s/epoch, loss=1.12, accuracy=0.757, val_loss=2.5, val_accuracy=0.462, lr=0.1]  84%|████████▍ | 74/88 [32:09<05:55, 25.37s/epoch, loss=1.12, accuracy=0.758, val_loss=2.39, val_accuracy=0.404, lr=0.0316] 85%|████████▌ | 75/88 [32:33<05:24, 24.95s/epoch, loss=1.12, accuracy=0.759, val_loss=4.34, val_accuracy=0.22, lr=0.1]     86%|████████▋ | 76/88 [33:00<05:06, 25.54s/epoch, loss=1.13, accuracy=0.76, val_loss=1.5, val_accuracy=0.622, lr=0.1]  88%|████████▊ | 77/88 [33:24<04:35, 25.04s/epoch, loss=1.13, accuracy=0.755, val_loss=1.85, val_accuracy=0.55, lr=0.1] 89%|████████▊ | 78/88 [33:49<04:10, 25.03s/epoch, loss=1.12, accuracy=0.758, val_loss=1.81, val_accuracy=0.522, lr=0.1] 90%|████████▉ | 79/88 [34:15<03:46, 25.16s/epoch, loss=1.12, accuracy=0.76, val_loss=1.84, val_accuracy=0.562, lr=0.0316] 91%|█████████ | 80/88 [34:39<03:18, 24.77s/epoch, loss=1.12, accuracy=0.758, val_loss=2.34, val_accuracy=0.488, lr=0.1]   92%|█████████▏| 81/88 [35:05<02:56, 25.17s/epoch, loss=1.12, accuracy=0.76, val_loss=1.85, val_accuracy=0.541, lr=0.1]  93%|█████████▎| 82/88 [35:28<02:28, 24.71s/epoch, loss=0.914, accuracy=0.817, val_loss=1.07, val_accuracy=0.742, lr=0.01] 94%|█████████▍| 83/88 [35:54<02:04, 24.86s/epoch, loss=0.731, accuracy=0.851, val_loss=0.893, val_accuracy=0.777, lr=0.01] 95%|█████████▌| 84/88 [36:19<01:40, 25.13s/epoch, loss=0.648, accuracy=0.858, val_loss=0.879, val_accuracy=0.772, lr=0.01] 97%|█████████▋| 85/88 [36:45<01:16, 25.37s/epoch, loss=0.604, accuracy=0.862, val_loss=0.935, val_accuracy=0.738, lr=0.01] 98%|█████████▊| 86/88 [37:10<00:50, 25.27s/epoch, loss=0.582, accuracy=0.863, val_loss=0.9, val_accuracy=0.752, lr=0.01]   99%|█████████▉| 87/88 [37:34<00:24, 24.76s/epoch, loss=0.567, accuracy=0.865, val_loss=0.758, val_accuracy=0.802, lr=0.01]100%|██████████| 88/88 [38:00<00:00, 25.22s/epoch, loss=0.562, accuracy=0.864, val_loss=0.824, val_accuracy=0.786, lr=0.01]100%|██████████| 88/88 [38:00<00:00, 25.92s/epoch, loss=0.562, accuracy=0.864, val_loss=0.824, val_accuracy=0.786, lr=0.01]
Using real-time data augmentation.
Test loss: 0.8243167996406555
Test accuracy: 0.7860999703407288


* * * Run SGD for ID = 17_16. * * *


2024-02-15 23:23:11.840613: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 23:23:14.640006: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 23:23:14.641329: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-15 23:23:14.679768: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 23:23:14.679809: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 23:23:14.682970: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 23:23:14.683015: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 23:23:14.685456: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 23:23:14.686197: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 23:23:14.688901: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 23:23:14.690631: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 23:23:14.695519: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 23:23:14.696115: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 23:23:14.696196: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 23:23:16.077220: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-15 23:23:16.077801: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 23:23:16.078249: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 23:23:16.078283: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 23:23:16.078316: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 23:23:16.078336: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 23:23:16.078354: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 23:23:16.078374: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 23:23:16.078394: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 23:23:16.078417: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 23:23:16.078437: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 23:23:16.078965: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 23:23:16.079008: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 23:23:16.817561: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-15 23:23:16.817637: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-15 23:23:16.817647: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-15 23:23:16.819113: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': 1716, 'batch_size': 128, 'epochs': 88, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/88 [00:00<?, ?epoch/s]2024-02-15 23:23:17.670958: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-15 23:23:17.682783: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199950000 Hz
2024-02-15 23:23:19.948223: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 23:23:20.183925: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 23:23:20.980460: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-15 23:23:21.053368: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/88 [01:07<1:38:30, 67.93s/epoch, loss=3.2, accuracy=0.303, val_loss=2.47, val_accuracy=0.247, lr=0.1]  2%|▏         | 2/88 [01:34<1:02:09, 43.37s/epoch, loss=1.59, accuracy=0.515, val_loss=2.06, val_accuracy=0.435, lr=0.1]  3%|▎         | 3/88 [02:00<50:29, 35.64s/epoch, loss=1.37, accuracy=0.628, val_loss=1.98, val_accuracy=0.5, lr=0.1]      5%|▍         | 4/88 [02:24<43:20, 30.95s/epoch, loss=1.28, accuracy=0.681, val_loss=1.61, val_accuracy=0.572, lr=0.1]  6%|▌         | 5/88 [02:51<40:43, 29.45s/epoch, loss=1.25, accuracy=0.7, val_loss=2.16, val_accuracy=0.41, lr=0.1]     7%|▋         | 6/88 [03:17<38:54, 28.47s/epoch, loss=1.23, accuracy=0.711, val_loss=1.93, val_accuracy=0.463, lr=0.1]  8%|▊         | 7/88 [03:43<37:26, 27.74s/epoch, loss=1.21, accuracy=0.721, val_loss=2.73, val_accuracy=0.435, lr=0.1]  9%|▉         | 8/88 [04:10<36:35, 27.44s/epoch, loss=1.21, accuracy=0.725, val_loss=1.61, val_accuracy=0.564, lr=0.1] 10%|█         | 9/88 [04:37<35:41, 27.11s/epoch, loss=1.2, accuracy=0.729, val_loss=2.62, val_accuracy=0.388, lr=0.0316] 11%|█▏        | 10/88 [05:03<35:03, 26.97s/epoch, loss=1.2, accuracy=0.73, val_loss=2, val_accuracy=0.51, lr=0.1]        12%|█▎        | 11/88 [05:30<34:35, 26.96s/epoch, loss=1.19, accuracy=0.732, val_loss=2.37, val_accuracy=0.456, lr=0.1] 14%|█▎        | 12/88 [05:57<33:54, 26.77s/epoch, loss=1.19, accuracy=0.735, val_loss=2.37, val_accuracy=0.405, lr=0.1] 15%|█▍        | 13/88 [06:23<33:10, 26.54s/epoch, loss=1.19, accuracy=0.738, val_loss=3.64, val_accuracy=0.344, lr=0.1] 16%|█▌        | 14/88 [06:49<32:40, 26.50s/epoch, loss=1.17, accuracy=0.74, val_loss=2.31, val_accuracy=0.389, lr=0.0316] 17%|█▋        | 15/88 [07:16<32:17, 26.54s/epoch, loss=1.18, accuracy=0.74, val_loss=1.57, val_accuracy=0.609, lr=0.1]    18%|█▊        | 16/88 [07:42<31:58, 26.65s/epoch, loss=1.18, accuracy=0.746, val_loss=1.82, val_accuracy=0.535, lr=0.1] 19%|█▉        | 17/88 [08:08<31:14, 26.40s/epoch, loss=1.17, accuracy=0.746, val_loss=7.2, val_accuracy=0.201, lr=0.1]  20%|██        | 18/88 [08:36<31:06, 26.66s/epoch, loss=1.17, accuracy=0.746, val_loss=2.56, val_accuracy=0.344, lr=0.1] 22%|██▏       | 19/88 [09:01<30:15, 26.32s/epoch, loss=1.17, accuracy=0.747, val_loss=1.8, val_accuracy=0.585, lr=0.1]  23%|██▎       | 20/88 [09:28<29:59, 26.46s/epoch, loss=1.17, accuracy=0.743, val_loss=2.48, val_accuracy=0.384, lr=0.0316] 24%|██▍       | 21/88 [09:54<29:33, 26.47s/epoch, loss=1.16, accuracy=0.745, val_loss=2.21, val_accuracy=0.459, lr=0.1]    25%|██▌       | 22/88 [10:20<28:41, 26.08s/epoch, loss=1.16, accuracy=0.749, val_loss=1.41, val_accuracy=0.674, lr=0.1] 26%|██▌       | 23/88 [10:46<28:18, 26.13s/epoch, loss=1.16, accuracy=0.748, val_loss=1.44, val_accuracy=0.649, lr=0.1] 27%|██▋       | 24/88 [11:13<28:08, 26.38s/epoch, loss=1.15, accuracy=0.75, val_loss=3.45, val_accuracy=0.375, lr=0.1]  28%|██▊       | 25/88 [11:39<27:43, 26.41s/epoch, loss=1.15, accuracy=0.751, val_loss=2.48, val_accuracy=0.376, lr=0.1] 30%|██▉       | 26/88 [12:06<27:16, 26.40s/epoch, loss=1.15, accuracy=0.75, val_loss=1.77, val_accuracy=0.525, lr=0.1]  31%|███       | 27/88 [12:32<26:42, 26.27s/epoch, loss=1.14, accuracy=0.753, val_loss=2.1, val_accuracy=0.49, lr=0.0316] 32%|███▏      | 28/88 [12:58<26:24, 26.41s/epoch, loss=1.13, accuracy=0.756, val_loss=1.84, val_accuracy=0.537, lr=0.1]  33%|███▎      | 29/88 [13:22<25:10, 25.61s/epoch, loss=1.14, accuracy=0.752, val_loss=2.02, val_accuracy=0.458, lr=0.1] 34%|███▍      | 30/88 [13:48<24:56, 25.79s/epoch, loss=1.14, accuracy=0.752, val_loss=4.8, val_accuracy=0.289, lr=0.1]  35%|███▌      | 31/88 [14:13<24:13, 25.50s/epoch, loss=1.14, accuracy=0.753, val_loss=3.05, val_accuracy=0.42, lr=0.1] 36%|███▋      | 32/88 [14:40<24:05, 25.82s/epoch, loss=1.15, accuracy=0.752, val_loss=2.27, val_accuracy=0.448, lr=0.0316] 38%|███▊      | 33/88 [15:05<23:33, 25.71s/epoch, loss=1.13, accuracy=0.755, val_loss=1.43, val_accuracy=0.658, lr=0.1]    39%|███▊      | 34/88 [15:32<23:27, 26.07s/epoch, loss=1.14, accuracy=0.751, val_loss=1.7, val_accuracy=0.552, lr=0.1]  40%|███▉      | 35/88 [15:59<23:11, 26.26s/epoch, loss=1.14, accuracy=0.753, val_loss=1.52, val_accuracy=0.613, lr=0.1] 41%|████      | 36/88 [16:24<22:32, 26.00s/epoch, loss=1.14, accuracy=0.752, val_loss=1.55, val_accuracy=0.626, lr=0.1] 42%|████▏     | 37/88 [16:48<21:37, 25.43s/epoch, loss=1.13, accuracy=0.755, val_loss=2.37, val_accuracy=0.402, lr=0.0316] 43%|████▎     | 38/88 [17:15<21:27, 25.75s/epoch, loss=1.14, accuracy=0.753, val_loss=1.72, val_accuracy=0.566, lr=0.1]    44%|████▍     | 39/88 [17:42<21:19, 26.11s/epoch, loss=1.13, accuracy=0.755, val_loss=2.3, val_accuracy=0.43, lr=0.1]   45%|████▌     | 40/88 [18:08<20:58, 26.23s/epoch, loss=1.13, accuracy=0.756, val_loss=2.37, val_accuracy=0.408, lr=0.1] 47%|████▋     | 41/88 [18:35<20:43, 26.45s/epoch, loss=1.13, accuracy=0.757, val_loss=1.67, val_accuracy=0.558, lr=0.1] 48%|████▊     | 42/88 [18:59<19:41, 25.68s/epoch, loss=1.13, accuracy=0.753, val_loss=3.65, val_accuracy=0.334, lr=0.0316] 49%|████▉     | 43/88 [19:26<19:32, 26.06s/epoch, loss=1.13, accuracy=0.756, val_loss=2.16, val_accuracy=0.47, lr=0.1]     50%|█████     | 44/88 [19:52<19:02, 25.97s/epoch, loss=1.12, accuracy=0.759, val_loss=1.76, val_accuracy=0.535, lr=0.1] 51%|█████     | 45/88 [20:19<18:50, 26.29s/epoch, loss=1.13, accuracy=0.756, val_loss=2.87, val_accuracy=0.449, lr=0.1] 52%|█████▏    | 46/88 [20:44<18:10, 25.98s/epoch, loss=1.13, accuracy=0.756, val_loss=1.54, val_accuracy=0.608, lr=0.1] 53%|█████▎    | 47/88 [21:08<17:24, 25.47s/epoch, loss=1.12, accuracy=0.756, val_loss=3.34, val_accuracy=0.35, lr=0.0316] 55%|█████▍    | 48/88 [21:35<17:12, 25.81s/epoch, loss=1.13, accuracy=0.757, val_loss=2.28, val_accuracy=0.472, lr=0.1]   56%|█████▌    | 49/88 [22:01<16:52, 25.96s/epoch, loss=1.13, accuracy=0.759, val_loss=1.93, val_accuracy=0.517, lr=0.1] 57%|█████▋    | 50/88 [22:28<16:33, 26.15s/epoch, loss=1.13, accuracy=0.756, val_loss=2.61, val_accuracy=0.407, lr=0.1] 58%|█████▊    | 51/88 [22:54<16:07, 26.15s/epoch, loss=1.13, accuracy=0.757, val_loss=2.09, val_accuracy=0.465, lr=0.1] 59%|█████▉    | 52/88 [23:20<15:40, 26.13s/epoch, loss=1.12, accuracy=0.756, val_loss=2.01, val_accuracy=0.505, lr=0.0316] 60%|██████    | 53/88 [23:47<15:21, 26.33s/epoch, loss=1.12, accuracy=0.758, val_loss=2.19, val_accuracy=0.448, lr=0.1]    61%|██████▏   | 54/88 [24:14<15:01, 26.52s/epoch, loss=1.12, accuracy=0.755, val_loss=1.76, val_accuracy=0.557, lr=0.1] 62%|██████▎   | 55/88 [24:40<14:31, 26.42s/epoch, loss=1.13, accuracy=0.756, val_loss=2.06, val_accuracy=0.514, lr=0.1] 64%|██████▎   | 56/88 [25:07<14:09, 26.56s/epoch, loss=1.12, accuracy=0.755, val_loss=3.39, val_accuracy=0.345, lr=0.1] 65%|██████▍   | 57/88 [25:33<13:43, 26.56s/epoch, loss=1.12, accuracy=0.76, val_loss=1.77, val_accuracy=0.532, lr=0.0316] 66%|██████▌   | 58/88 [26:00<13:16, 26.57s/epoch, loss=1.12, accuracy=0.756, val_loss=1.84, val_accuracy=0.489, lr=0.1]   67%|██████▋   | 59/88 [26:26<12:49, 26.53s/epoch, loss=1.12, accuracy=0.759, val_loss=2.48, val_accuracy=0.411, lr=0.1] 68%|██████▊   | 60/88 [26:53<12:21, 26.50s/epoch, loss=1.12, accuracy=0.758, val_loss=1.79, val_accuracy=0.58, lr=0.1]  69%|██████▉   | 61/88 [27:19<11:51, 26.34s/epoch, loss=1.12, accuracy=0.756, val_loss=1.69, val_accuracy=0.541, lr=0.1] 70%|███████   | 62/88 [27:46<11:29, 26.53s/epoch, loss=1.13, accuracy=0.753, val_loss=1.63, val_accuracy=0.612, lr=0.0316] 72%|███████▏  | 63/88 [28:12<11:04, 26.58s/epoch, loss=1.12, accuracy=0.758, val_loss=2.18, val_accuracy=0.44, lr=0.1]     73%|███████▎  | 64/88 [28:39<10:35, 26.50s/epoch, loss=1.12, accuracy=0.757, val_loss=1.73, val_accuracy=0.525, lr=0.1] 74%|███████▍  | 65/88 [29:06<10:11, 26.58s/epoch, loss=1.12, accuracy=0.756, val_loss=2.21, val_accuracy=0.525, lr=0.1] 75%|███████▌  | 66/88 [29:32<09:43, 26.54s/epoch, loss=1.11, accuracy=0.758, val_loss=2.12, val_accuracy=0.5, lr=0.1]   76%|███████▌  | 67/88 [29:56<09:03, 25.89s/epoch, loss=1.12, accuracy=0.758, val_loss=2.89, val_accuracy=0.286, lr=0.0316] 77%|███████▋  | 68/88 [30:22<08:37, 25.86s/epoch, loss=1.12, accuracy=0.756, val_loss=1.99, val_accuracy=0.519, lr=0.1]    78%|███████▊  | 69/88 [30:49<08:15, 26.10s/epoch, loss=1.12, accuracy=0.759, val_loss=1.75, val_accuracy=0.579, lr=0.1] 80%|███████▉  | 70/88 [31:14<07:46, 25.93s/epoch, loss=1.12, accuracy=0.759, val_loss=1.61, val_accuracy=0.584, lr=0.1] 81%|████████  | 71/88 [31:40<07:19, 25.87s/epoch, loss=1.12, accuracy=0.756, val_loss=1.83, val_accuracy=0.538, lr=0.1] 82%|████████▏ | 72/88 [32:07<06:58, 26.18s/epoch, loss=1.11, accuracy=0.76, val_loss=2.39, val_accuracy=0.416, lr=0.0316] 83%|████████▎ | 73/88 [32:33<06:30, 26.01s/epoch, loss=1.11, accuracy=0.759, val_loss=2.31, val_accuracy=0.442, lr=0.1]   84%|████████▍ | 74/88 [32:58<06:02, 25.86s/epoch, loss=1.11, accuracy=0.758, val_loss=2.39, val_accuracy=0.454, lr=0.1] 85%|████████▌ | 75/88 [33:25<05:40, 26.18s/epoch, loss=1.11, accuracy=0.759, val_loss=2.76, val_accuracy=0.482, lr=0.1] 86%|████████▋ | 76/88 [33:52<05:16, 26.36s/epoch, loss=1.12, accuracy=0.757, val_loss=1.58, val_accuracy=0.591, lr=0.1] 88%|████████▊ | 77/88 [34:18<04:49, 26.34s/epoch, loss=1.11, accuracy=0.758, val_loss=1.63, val_accuracy=0.541, lr=0.0316] 89%|████████▊ | 78/88 [34:45<04:24, 26.46s/epoch, loss=1.11, accuracy=0.759, val_loss=2.09, val_accuracy=0.449, lr=0.1]    90%|████████▉ | 79/88 [35:11<03:57, 26.41s/epoch, loss=1.12, accuracy=0.757, val_loss=1.87, val_accuracy=0.519, lr=0.1] 91%|█████████ | 80/88 [35:38<03:31, 26.47s/epoch, loss=1.11, accuracy=0.757, val_loss=2.03, val_accuracy=0.456, lr=0.1] 92%|█████████▏| 81/88 [36:04<03:05, 26.45s/epoch, loss=1.11, accuracy=0.761, val_loss=1.32, val_accuracy=0.668, lr=0.1] 93%|█████████▎| 82/88 [36:29<02:36, 26.09s/epoch, loss=0.9, accuracy=0.817, val_loss=0.904, val_accuracy=0.795, lr=0.01] 94%|█████████▍| 83/88 [36:56<02:11, 26.31s/epoch, loss=0.727, accuracy=0.848, val_loss=0.843, val_accuracy=0.794, lr=0.01] 95%|█████████▌| 84/88 [37:23<01:45, 26.40s/epoch, loss=0.651, accuracy=0.856, val_loss=0.751, val_accuracy=0.817, lr=0.01] 97%|█████████▋| 85/88 [37:50<01:19, 26.48s/epoch, loss=0.605, accuracy=0.86, val_loss=0.786, val_accuracy=0.807, lr=0.01]  98%|█████████▊| 86/88 [38:14<00:51, 25.85s/epoch, loss=0.586, accuracy=0.86, val_loss=0.706, val_accuracy=0.816, lr=0.01] 99%|█████████▉| 87/88 [38:40<00:26, 26.08s/epoch, loss=0.574, accuracy=0.862, val_loss=0.816, val_accuracy=0.784, lr=0.01]100%|██████████| 88/88 [39:07<00:00, 26.10s/epoch, loss=0.571, accuracy=0.863, val_loss=0.802, val_accuracy=0.785, lr=0.01]100%|██████████| 88/88 [39:07<00:00, 26.67s/epoch, loss=0.571, accuracy=0.863, val_loss=0.802, val_accuracy=0.785, lr=0.01]
Using real-time data augmentation.
Test loss: 0.8018903136253357
Test accuracy: 0.7849000096321106


* * * Run SGD for ID = 17_17. * * *


2024-02-16 00:02:27.374927: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-16 00:02:30.887789: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-16 00:02:30.888994: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-16 00:02:30.927814: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-16 00:02:30.927853: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-16 00:02:30.931022: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-16 00:02:30.931065: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-16 00:02:30.933312: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-16 00:02:30.934121: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-16 00:02:30.936541: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-16 00:02:30.938178: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-16 00:02:30.943335: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-16 00:02:30.943927: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-16 00:02:30.944034: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-16 00:02:32.258134: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-16 00:02:32.258775: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-16 00:02:32.259282: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-16 00:02:32.259326: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-16 00:02:32.259362: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-16 00:02:32.259381: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-16 00:02:32.259399: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-16 00:02:32.259416: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-16 00:02:32.259434: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-16 00:02:32.259451: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-16 00:02:32.259469: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-16 00:02:32.259974: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-16 00:02:32.260028: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-16 00:02:32.933445: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-16 00:02:32.933514: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-16 00:02:32.933534: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-16 00:02:32.934908: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': 1717, 'batch_size': 128, 'epochs': 88, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/88 [00:00<?, ?epoch/s]2024-02-16 00:02:33.743042: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-16 00:02:33.754820: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199950000 Hz
2024-02-16 00:02:35.860656: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-16 00:02:36.130730: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-16 00:02:36.992520: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-16 00:02:37.044823: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/88 [01:08<1:39:06, 68.35s/epoch, loss=3.32, accuracy=0.314, val_loss=4.09, val_accuracy=0.119, lr=0.1]  2%|▏         | 2/88 [01:32<1:00:56, 42.51s/epoch, loss=1.53, accuracy=0.547, val_loss=1.99, val_accuracy=0.468, lr=0.1]  3%|▎         | 3/88 [01:58<49:13, 34.75s/epoch, loss=1.33, accuracy=0.646, val_loss=2.69, val_accuracy=0.371, lr=0.1]    5%|▍         | 4/88 [02:23<43:38, 31.17s/epoch, loss=1.27, accuracy=0.683, val_loss=1.57, val_accuracy=0.566, lr=0.1]  6%|▌         | 5/88 [02:50<40:34, 29.34s/epoch, loss=1.25, accuracy=0.698, val_loss=1.62, val_accuracy=0.572, lr=0.1]  7%|▋         | 6/88 [03:15<38:30, 28.18s/epoch, loss=1.23, accuracy=0.712, val_loss=2.58, val_accuracy=0.431, lr=0.1]  8%|▊         | 7/88 [03:42<37:08, 27.51s/epoch, loss=1.22, accuracy=0.717, val_loss=2.69, val_accuracy=0.402, lr=0.1]  9%|▉         | 8/88 [04:08<36:11, 27.14s/epoch, loss=1.22, accuracy=0.722, val_loss=1.83, val_accuracy=0.545, lr=0.1] 10%|█         | 9/88 [04:34<35:15, 26.78s/epoch, loss=1.2, accuracy=0.725, val_loss=2.24, val_accuracy=0.388, lr=0.0316] 11%|█▏        | 10/88 [05:00<34:34, 26.60s/epoch, loss=1.2, accuracy=0.728, val_loss=2.14, val_accuracy=0.502, lr=0.1]   12%|█▎        | 11/88 [05:26<34:00, 26.50s/epoch, loss=1.2, accuracy=0.732, val_loss=1.64, val_accuracy=0.594, lr=0.1] 14%|█▎        | 12/88 [05:52<33:16, 26.27s/epoch, loss=1.19, accuracy=0.734, val_loss=3.12, val_accuracy=0.36, lr=0.1] 15%|█▍        | 13/88 [06:18<32:48, 26.24s/epoch, loss=1.19, accuracy=0.734, val_loss=1.41, val_accuracy=0.645, lr=0.1] 16%|█▌        | 14/88 [06:44<32:05, 26.02s/epoch, loss=1.18, accuracy=0.736, val_loss=1.87, val_accuracy=0.502, lr=0.1] 17%|█▋        | 15/88 [07:08<31:05, 25.56s/epoch, loss=1.18, accuracy=0.74, val_loss=1.68, val_accuracy=0.584, lr=0.1]  18%|█▊        | 16/88 [07:35<30:55, 25.77s/epoch, loss=1.18, accuracy=0.739, val_loss=1.71, val_accuracy=0.586, lr=0.1] 19%|█▉        | 17/88 [08:00<30:27, 25.74s/epoch, loss=1.17, accuracy=0.744, val_loss=1.38, val_accuracy=0.673, lr=0.1] 20%|██        | 18/88 [08:26<30:09, 25.85s/epoch, loss=1.17, accuracy=0.743, val_loss=4.57, val_accuracy=0.322, lr=0.1] 22%|██▏       | 19/88 [08:52<29:41, 25.82s/epoch, loss=1.17, accuracy=0.741, val_loss=1.57, val_accuracy=0.611, lr=0.1] 23%|██▎       | 20/88 [09:17<29:03, 25.64s/epoch, loss=1.16, accuracy=0.743, val_loss=1.77, val_accuracy=0.548, lr=0.1] 24%|██▍       | 21/88 [09:43<28:42, 25.71s/epoch, loss=1.16, accuracy=0.744, val_loss=2.01, val_accuracy=0.538, lr=0.1] 25%|██▌       | 22/88 [10:09<28:23, 25.81s/epoch, loss=1.16, accuracy=0.743, val_loss=1.6, val_accuracy=0.588, lr=0.0316] 26%|██▌       | 23/88 [10:35<27:57, 25.81s/epoch, loss=1.16, accuracy=0.746, val_loss=1.49, val_accuracy=0.633, lr=0.1]   27%|██▋       | 24/88 [11:01<27:31, 25.80s/epoch, loss=1.16, accuracy=0.743, val_loss=2.17, val_accuracy=0.446, lr=0.1] 28%|██▊       | 25/88 [11:26<26:55, 25.64s/epoch, loss=1.16, accuracy=0.743, val_loss=2.67, val_accuracy=0.367, lr=0.1] 30%|██▉       | 26/88 [11:51<26:19, 25.48s/epoch, loss=1.15, accuracy=0.745, val_loss=2.53, val_accuracy=0.404, lr=0.1] 31%|███       | 27/88 [12:17<25:56, 25.52s/epoch, loss=1.15, accuracy=0.745, val_loss=2.63, val_accuracy=0.472, lr=0.0316] 32%|███▏      | 28/88 [12:42<25:33, 25.56s/epoch, loss=1.15, accuracy=0.746, val_loss=2.29, val_accuracy=0.469, lr=0.1]    33%|███▎      | 29/88 [13:08<25:12, 25.63s/epoch, loss=1.14, accuracy=0.749, val_loss=2.79, val_accuracy=0.419, lr=0.1] 34%|███▍      | 30/88 [13:34<24:54, 25.77s/epoch, loss=1.15, accuracy=0.749, val_loss=1.83, val_accuracy=0.551, lr=0.1] 35%|███▌      | 31/88 [13:58<23:47, 25.04s/epoch, loss=1.14, accuracy=0.749, val_loss=3.31, val_accuracy=0.292, lr=0.1] 36%|███▋      | 32/88 [14:22<23:08, 24.80s/epoch, loss=1.14, accuracy=0.749, val_loss=2.47, val_accuracy=0.365, lr=0.0316] 38%|███▊      | 33/88 [14:48<23:03, 25.16s/epoch, loss=1.14, accuracy=0.751, val_loss=1.58, val_accuracy=0.64, lr=0.1]     39%|███▊      | 34/88 [15:13<22:43, 25.24s/epoch, loss=1.14, accuracy=0.749, val_loss=2.61, val_accuracy=0.443, lr=0.1] 40%|███▉      | 35/88 [15:39<22:24, 25.36s/epoch, loss=1.15, accuracy=0.749, val_loss=1.73, val_accuracy=0.572, lr=0.1] 41%|████      | 36/88 [16:03<21:40, 25.01s/epoch, loss=1.14, accuracy=0.749, val_loss=1.45, val_accuracy=0.617, lr=0.1] 42%|████▏     | 37/88 [16:29<21:31, 25.33s/epoch, loss=1.13, accuracy=0.753, val_loss=2.43, val_accuracy=0.458, lr=0.0316] 43%|████▎     | 38/88 [16:55<21:18, 25.57s/epoch, loss=1.14, accuracy=0.749, val_loss=1.49, val_accuracy=0.617, lr=0.1]    44%|████▍     | 39/88 [17:21<20:56, 25.64s/epoch, loss=1.13, accuracy=0.751, val_loss=2.07, val_accuracy=0.485, lr=0.1] 45%|████▌     | 40/88 [17:46<20:24, 25.52s/epoch, loss=1.13, accuracy=0.751, val_loss=2.66, val_accuracy=0.392, lr=0.1] 47%|████▋     | 41/88 [18:13<20:07, 25.70s/epoch, loss=1.13, accuracy=0.751, val_loss=1.98, val_accuracy=0.516, lr=0.1] 48%|████▊     | 42/88 [18:38<19:42, 25.70s/epoch, loss=1.14, accuracy=0.75, val_loss=4.79, val_accuracy=0.361, lr=0.0316] 49%|████▉     | 43/88 [19:04<19:22, 25.82s/epoch, loss=1.15, accuracy=0.749, val_loss=2.29, val_accuracy=0.457, lr=0.1]   50%|█████     | 44/88 [19:30<18:58, 25.88s/epoch, loss=1.13, accuracy=0.753, val_loss=1.94, val_accuracy=0.463, lr=0.1] 51%|█████     | 45/88 [19:56<18:33, 25.89s/epoch, loss=1.13, accuracy=0.752, val_loss=1.92, val_accuracy=0.565, lr=0.1] 52%|█████▏    | 46/88 [20:22<18:01, 25.75s/epoch, loss=1.13, accuracy=0.751, val_loss=2.19, val_accuracy=0.48, lr=0.1]  53%|█████▎    | 47/88 [20:48<17:39, 25.85s/epoch, loss=1.13, accuracy=0.752, val_loss=3.14, val_accuracy=0.309, lr=0.0316] 55%|█████▍    | 48/88 [21:14<17:16, 25.90s/epoch, loss=1.14, accuracy=0.752, val_loss=2.53, val_accuracy=0.38, lr=0.1]     56%|█████▌    | 49/88 [21:40<16:53, 25.99s/epoch, loss=1.13, accuracy=0.752, val_loss=2.35, val_accuracy=0.423, lr=0.1] 57%|█████▋    | 50/88 [22:05<16:12, 25.59s/epoch, loss=1.13, accuracy=0.75, val_loss=2.51, val_accuracy=0.416, lr=0.1]  58%|█████▊    | 51/88 [22:31<15:49, 25.65s/epoch, loss=1.14, accuracy=0.75, val_loss=2.16, val_accuracy=0.498, lr=0.1] 59%|█████▉    | 52/88 [22:56<15:25, 25.72s/epoch, loss=1.13, accuracy=0.754, val_loss=1.94, val_accuracy=0.532, lr=0.0316] 60%|██████    | 53/88 [23:20<14:40, 25.15s/epoch, loss=1.13, accuracy=0.754, val_loss=1.62, val_accuracy=0.573, lr=0.1]    61%|██████▏   | 54/88 [23:46<14:23, 25.40s/epoch, loss=1.14, accuracy=0.752, val_loss=2.34, val_accuracy=0.442, lr=0.1] 62%|██████▎   | 55/88 [24:12<14:06, 25.64s/epoch, loss=1.13, accuracy=0.751, val_loss=1.8, val_accuracy=0.559, lr=0.1]  64%|██████▎   | 56/88 [24:38<13:44, 25.78s/epoch, loss=1.13, accuracy=0.754, val_loss=1.59, val_accuracy=0.607, lr=0.1] 65%|██████▍   | 57/88 [25:05<13:21, 25.86s/epoch, loss=1.13, accuracy=0.755, val_loss=5.08, val_accuracy=0.223, lr=0.0316] 66%|██████▌   | 58/88 [25:31<12:59, 25.99s/epoch, loss=1.13, accuracy=0.754, val_loss=4.48, val_accuracy=0.285, lr=0.1]    67%|██████▋   | 59/88 [25:57<12:36, 26.09s/epoch, loss=1.12, accuracy=0.752, val_loss=2.25, val_accuracy=0.462, lr=0.1] 68%|██████▊   | 60/88 [26:23<12:11, 26.11s/epoch, loss=1.13, accuracy=0.753, val_loss=1.63, val_accuracy=0.602, lr=0.1] 69%|██████▉   | 61/88 [26:49<11:44, 26.10s/epoch, loss=1.13, accuracy=0.754, val_loss=3.01, val_accuracy=0.404, lr=0.1] 70%|███████   | 62/88 [27:15<11:17, 26.07s/epoch, loss=1.13, accuracy=0.752, val_loss=1.77, val_accuracy=0.544, lr=0.0316] 72%|███████▏  | 63/88 [27:42<10:53, 26.12s/epoch, loss=1.13, accuracy=0.751, val_loss=2.7, val_accuracy=0.394, lr=0.1]     73%|███████▎  | 64/88 [28:07<10:23, 25.98s/epoch, loss=1.14, accuracy=0.75, val_loss=1.72, val_accuracy=0.59, lr=0.1]  74%|███████▍  | 65/88 [28:33<09:55, 25.88s/epoch, loss=1.13, accuracy=0.753, val_loss=2.15, val_accuracy=0.509, lr=0.1] 75%|███████▌  | 66/88 [28:59<09:29, 25.87s/epoch, loss=1.13, accuracy=0.753, val_loss=2.33, val_accuracy=0.478, lr=0.1] 76%|███████▌  | 67/88 [29:24<09:00, 25.72s/epoch, loss=1.13, accuracy=0.751, val_loss=1.67, val_accuracy=0.566, lr=0.0316] 77%|███████▋  | 68/88 [29:50<08:34, 25.72s/epoch, loss=1.13, accuracy=0.753, val_loss=1.41, val_accuracy=0.658, lr=0.1]    78%|███████▊  | 69/88 [30:14<08:02, 25.40s/epoch, loss=1.13, accuracy=0.754, val_loss=2.38, val_accuracy=0.513, lr=0.1] 80%|███████▉  | 70/88 [30:40<07:39, 25.51s/epoch, loss=1.14, accuracy=0.749, val_loss=1.74, val_accuracy=0.536, lr=0.1] 81%|████████  | 71/88 [31:06<07:15, 25.61s/epoch, loss=1.13, accuracy=0.754, val_loss=1.58, val_accuracy=0.613, lr=0.1] 82%|████████▏ | 72/88 [31:32<06:49, 25.59s/epoch, loss=1.13, accuracy=0.753, val_loss=2.85, val_accuracy=0.425, lr=0.0316] 83%|████████▎ | 73/88 [31:58<06:26, 25.76s/epoch, loss=1.13, accuracy=0.752, val_loss=2.63, val_accuracy=0.465, lr=0.1]    84%|████████▍ | 74/88 [32:22<05:55, 25.40s/epoch, loss=1.13, accuracy=0.753, val_loss=2.12, val_accuracy=0.463, lr=0.1] 85%|████████▌ | 75/88 [32:49<05:33, 25.63s/epoch, loss=1.13, accuracy=0.754, val_loss=1.81, val_accuracy=0.531, lr=0.1] 86%|████████▋ | 76/88 [33:14<05:08, 25.70s/epoch, loss=1.13, accuracy=0.752, val_loss=4.49, val_accuracy=0.308, lr=0.1] 88%|████████▊ | 77/88 [33:41<04:44, 25.88s/epoch, loss=1.13, accuracy=0.753, val_loss=2.29, val_accuracy=0.461, lr=0.0316] 89%|████████▊ | 78/88 [34:07<04:19, 25.98s/epoch, loss=1.13, accuracy=0.752, val_loss=2.31, val_accuracy=0.406, lr=0.1]    90%|████████▉ | 79/88 [34:33<03:53, 25.99s/epoch, loss=1.13, accuracy=0.754, val_loss=2.14, val_accuracy=0.479, lr=0.1] 91%|█████████ | 80/88 [34:57<03:23, 25.47s/epoch, loss=1.13, accuracy=0.753, val_loss=1.56, val_accuracy=0.581, lr=0.1] 92%|█████████▏| 81/88 [35:22<02:57, 25.35s/epoch, loss=1.12, accuracy=0.754, val_loss=2.09, val_accuracy=0.505, lr=0.1] 93%|█████████▎| 82/88 [35:47<02:31, 25.27s/epoch, loss=0.923, accuracy=0.812, val_loss=0.906, val_accuracy=0.805, lr=0.01] 94%|█████████▍| 83/88 [36:13<02:06, 25.32s/epoch, loss=0.742, accuracy=0.844, val_loss=0.958, val_accuracy=0.755, lr=0.01] 95%|█████████▌| 84/88 [36:38<01:41, 25.32s/epoch, loss=0.661, accuracy=0.853, val_loss=0.719, val_accuracy=0.823, lr=0.01] 97%|█████████▋| 85/88 [37:03<01:15, 25.12s/epoch, loss=0.615, accuracy=0.856, val_loss=0.743, val_accuracy=0.812, lr=0.01] 98%|█████████▊| 86/88 [37:26<00:49, 24.52s/epoch, loss=0.598, accuracy=0.857, val_loss=0.731, val_accuracy=0.812, lr=0.01] 99%|█████████▉| 87/88 [37:52<00:24, 24.89s/epoch, loss=0.585, accuracy=0.859, val_loss=0.737, val_accuracy=0.804, lr=0.01]100%|██████████| 88/88 [38:17<00:00, 25.01s/epoch, loss=0.581, accuracy=0.86, val_loss=0.854, val_accuracy=0.769, lr=0.01] 100%|██████████| 88/88 [38:17<00:00, 26.11s/epoch, loss=0.581, accuracy=0.86, val_loss=0.854, val_accuracy=0.769, lr=0.01]
Using real-time data augmentation.
Test loss: 0.8544031977653503
Test accuracy: 0.76910001039505
