Tue Mar  5 05:34:44 2024       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 545.23.08              Driver Version: 545.23.08    CUDA Version: 12.3     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA TITAN Xp                Off | 00000000:18:00.0 Off |                  N/A |
| 51%   73C    P5              22W / 250W |      0MiB / 12288MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|  No running processes found                                                           |
+---------------------------------------------------------------------------------------+


* * * Run SGD for cluster size = 16. * * *


Budget: 93


* * * Run SGD for ID = 16_1. * * *


2024-03-05 05:34:44.842579: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 05:34:48.137388: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 05:34:48.138533: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-05 05:34:48.181620: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:18:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-05 05:34:48.181659: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 05:34:48.185226: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 05:34:48.185289: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 05:34:48.187819: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 05:34:48.189190: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 05:34:48.192098: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 05:34:48.193982: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 05:34:48.199517: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 05:34:48.200211: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 05:34:48.200300: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 05:34:49.399925: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-05 05:34:49.401047: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 05:34:49.402119: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:18:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-05 05:34:49.402153: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 05:34:49.402189: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 05:34:49.402203: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 05:34:49.402215: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 05:34:49.402227: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 05:34:49.402241: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 05:34:49.402255: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 05:34:49.402269: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 05:34:49.402802: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 05:34:49.402848: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 05:34:50.068933: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-05 05:34:50.068987: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-05 05:34:50.068997: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-05 05:34:50.070040: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:18:00.0, compute capability: 6.1)
{'id': '16_01', 'seed': 1, 'out_folder': 'results/epoch_budget', 'batch_size': 128, 'epochs': 93, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'bootstrapping': False, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/93 [00:00<?, ?epoch/s]2024-03-05 05:34:50.891544: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-05 05:34:50.904002: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2100000000 Hz
2024-03-05 05:34:52.785236: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 05:34:53.070506: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 05:34:54.057936: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-05 05:34:54.116255: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/93 [01:05<1:41:06, 65.94s/epoch, loss=3.36, accuracy=0.326, val_loss=2.35, val_accuracy=0.253, lr=0.1]  2%|▏         | 2/93 [01:32<1:04:56, 42.82s/epoch, loss=1.56, accuracy=0.546, val_loss=2.12, val_accuracy=0.415, lr=0.1]  3%|▎         | 3/93 [01:58<52:55, 35.28s/epoch, loss=1.43, accuracy=0.604, val_loss=2.37, val_accuracy=0.335, lr=0.1]    4%|▍         | 4/93 [02:25<47:13, 31.84s/epoch, loss=1.37, accuracy=0.645, val_loss=1.76, val_accuracy=0.548, lr=0.1]  5%|▌         | 5/93 [02:51<43:45, 29.84s/epoch, loss=1.32, accuracy=0.668, val_loss=2.01, val_accuracy=0.447, lr=0.1]  6%|▋         | 6/93 [03:18<41:36, 28.69s/epoch, loss=1.29, accuracy=0.683, val_loss=4.16, val_accuracy=0.206, lr=0.1]  8%|▊         | 7/93 [03:44<40:06, 27.99s/epoch, loss=1.27, accuracy=0.7, val_loss=1.79, val_accuracy=0.582, lr=0.1]    9%|▊         | 8/93 [04:11<38:58, 27.51s/epoch, loss=1.26, accuracy=0.708, val_loss=2.75, val_accuracy=0.398, lr=0.1] 10%|▉         | 9/93 [04:37<38:07, 27.24s/epoch, loss=1.24, accuracy=0.713, val_loss=1.79, val_accuracy=0.537, lr=0.0316] 11%|█         | 10/93 [05:04<37:15, 26.93s/epoch, loss=1.24, accuracy=0.714, val_loss=1.78, val_accuracy=0.531, lr=0.1]   12%|█▏        | 11/93 [05:30<36:37, 26.80s/epoch, loss=1.24, accuracy=0.72, val_loss=2.01, val_accuracy=0.469, lr=0.1]  13%|█▎        | 12/93 [05:56<35:58, 26.64s/epoch, loss=1.23, accuracy=0.724, val_loss=2.1, val_accuracy=0.486, lr=0.1] 14%|█▍        | 13/93 [06:23<35:38, 26.73s/epoch, loss=1.22, accuracy=0.723, val_loss=2.9, val_accuracy=0.339, lr=0.1] 15%|█▌        | 14/93 [06:51<35:35, 27.03s/epoch, loss=1.22, accuracy=0.728, val_loss=1.69, val_accuracy=0.552, lr=0.1] 16%|█▌        | 15/93 [07:19<35:24, 27.23s/epoch, loss=1.21, accuracy=0.734, val_loss=1.93, val_accuracy=0.538, lr=0.1] 17%|█▋        | 16/93 [07:46<35:08, 27.39s/epoch, loss=1.2, accuracy=0.734, val_loss=1.51, val_accuracy=0.62, lr=0.1]   18%|█▊        | 17/93 [08:14<34:54, 27.55s/epoch, loss=1.2, accuracy=0.736, val_loss=1.48, val_accuracy=0.644, lr=0.1] 19%|█▉        | 18/93 [08:42<34:33, 27.65s/epoch, loss=1.19, accuracy=0.738, val_loss=2.24, val_accuracy=0.463, lr=0.1] 20%|██        | 19/93 [09:10<34:05, 27.64s/epoch, loss=1.19, accuracy=0.739, val_loss=2.27, val_accuracy=0.463, lr=0.1] 22%|██▏       | 20/93 [09:38<33:39, 27.66s/epoch, loss=1.19, accuracy=0.74, val_loss=2.07, val_accuracy=0.492, lr=0.1]  23%|██▎       | 21/93 [10:06<33:17, 27.74s/epoch, loss=1.18, accuracy=0.74, val_loss=1.72, val_accuracy=0.572, lr=0.1] 24%|██▎       | 22/93 [10:33<32:52, 27.79s/epoch, loss=1.18, accuracy=0.745, val_loss=2.07, val_accuracy=0.522, lr=0.0316] 25%|██▍       | 23/93 [11:01<32:26, 27.80s/epoch, loss=1.18, accuracy=0.74, val_loss=2.17, val_accuracy=0.488, lr=0.1]     26%|██▌       | 24/93 [11:29<31:50, 27.69s/epoch, loss=1.17, accuracy=0.743, val_loss=2, val_accuracy=0.506, lr=0.1]   27%|██▋       | 25/93 [11:57<31:25, 27.73s/epoch, loss=1.17, accuracy=0.743, val_loss=1.92, val_accuracy=0.514, lr=0.1] 28%|██▊       | 26/93 [12:24<30:57, 27.72s/epoch, loss=1.17, accuracy=0.745, val_loss=1.71, val_accuracy=0.548, lr=0.1] 29%|██▉       | 27/93 [12:51<30:15, 27.51s/epoch, loss=1.18, accuracy=0.744, val_loss=2.96, val_accuracy=0.356, lr=0.0316] 30%|███       | 28/93 [13:19<29:48, 27.51s/epoch, loss=1.17, accuracy=0.747, val_loss=2.41, val_accuracy=0.412, lr=0.1]    31%|███       | 29/93 [13:45<28:50, 27.04s/epoch, loss=1.17, accuracy=0.745, val_loss=3.21, val_accuracy=0.286, lr=0.1] 32%|███▏      | 30/93 [14:12<28:34, 27.21s/epoch, loss=1.16, accuracy=0.75, val_loss=1.96, val_accuracy=0.512, lr=0.1]  33%|███▎      | 31/93 [14:40<28:13, 27.31s/epoch, loss=1.16, accuracy=0.749, val_loss=1.65, val_accuracy=0.607, lr=0.1] 34%|███▍      | 32/93 [15:06<27:32, 27.09s/epoch, loss=1.16, accuracy=0.75, val_loss=2.33, val_accuracy=0.434, lr=0.0316] 35%|███▌      | 33/93 [15:34<27:16, 27.28s/epoch, loss=1.17, accuracy=0.749, val_loss=1.8, val_accuracy=0.55, lr=0.1]     37%|███▋      | 34/93 [16:02<26:57, 27.42s/epoch, loss=1.17, accuracy=0.749, val_loss=1.67, val_accuracy=0.553, lr=0.1] 38%|███▊      | 35/93 [16:29<26:27, 27.37s/epoch, loss=1.16, accuracy=0.75, val_loss=2.04, val_accuracy=0.523, lr=0.1]  39%|███▊      | 36/93 [16:57<26:02, 27.42s/epoch, loss=1.16, accuracy=0.75, val_loss=2.15, val_accuracy=0.53, lr=0.1]  40%|███▉      | 37/93 [17:24<25:41, 27.53s/epoch, loss=1.16, accuracy=0.748, val_loss=1.64, val_accuracy=0.596, lr=0.0316] 41%|████      | 38/93 [17:52<25:11, 27.48s/epoch, loss=1.16, accuracy=0.749, val_loss=1.76, val_accuracy=0.533, lr=0.1]    42%|████▏     | 39/93 [18:18<24:26, 27.15s/epoch, loss=1.16, accuracy=0.749, val_loss=2, val_accuracy=0.494, lr=0.1]    43%|████▎     | 40/93 [18:46<24:03, 27.23s/epoch, loss=1.16, accuracy=0.748, val_loss=1.94, val_accuracy=0.55, lr=0.1] 44%|████▍     | 41/93 [19:13<23:33, 27.19s/epoch, loss=1.16, accuracy=0.751, val_loss=1.4, val_accuracy=0.657, lr=0.1] 45%|████▌     | 42/93 [19:40<23:08, 27.23s/epoch, loss=1.15, accuracy=0.752, val_loss=2.66, val_accuracy=0.43, lr=0.1] 46%|████▌     | 43/93 [20:07<22:41, 27.23s/epoch, loss=1.15, accuracy=0.752, val_loss=1.99, val_accuracy=0.518, lr=0.1] 47%|████▋     | 44/93 [20:34<22:13, 27.21s/epoch, loss=1.15, accuracy=0.751, val_loss=1.87, val_accuracy=0.562, lr=0.1] 48%|████▊     | 45/93 [21:02<21:52, 27.35s/epoch, loss=1.14, accuracy=0.753, val_loss=2.23, val_accuracy=0.453, lr=0.1] 49%|████▉     | 46/93 [21:30<21:31, 27.48s/epoch, loss=1.14, accuracy=0.752, val_loss=2.03, val_accuracy=0.548, lr=0.0316] 51%|█████     | 47/93 [21:57<21:01, 27.43s/epoch, loss=1.14, accuracy=0.755, val_loss=1.54, val_accuracy=0.628, lr=0.1]    52%|█████▏    | 48/93 [22:24<20:30, 27.34s/epoch, loss=1.15, accuracy=0.752, val_loss=1.55, val_accuracy=0.61, lr=0.1]  53%|█████▎    | 49/93 [22:52<20:05, 27.40s/epoch, loss=1.14, accuracy=0.754, val_loss=3.19, val_accuracy=0.373, lr=0.1] 54%|█████▍    | 50/93 [23:19<19:32, 27.26s/epoch, loss=1.14, accuracy=0.753, val_loss=1.55, val_accuracy=0.613, lr=0.1] 55%|█████▍    | 51/93 [23:46<19:09, 27.38s/epoch, loss=1.14, accuracy=0.753, val_loss=1.88, val_accuracy=0.496, lr=0.0316] 56%|█████▌    | 52/93 [24:13<18:36, 27.23s/epoch, loss=1.14, accuracy=0.752, val_loss=2.97, val_accuracy=0.37, lr=0.1]     57%|█████▋    | 53/93 [24:41<18:15, 27.39s/epoch, loss=1.15, accuracy=0.754, val_loss=2.89, val_accuracy=0.383, lr=0.1] 58%|█████▊    | 54/93 [25:09<17:52, 27.49s/epoch, loss=1.14, accuracy=0.752, val_loss=2.22, val_accuracy=0.475, lr=0.1] 59%|█████▉    | 55/93 [25:36<17:23, 27.46s/epoch, loss=1.14, accuracy=0.753, val_loss=2.18, val_accuracy=0.47, lr=0.1]  60%|██████    | 56/93 [26:03<16:46, 27.19s/epoch, loss=1.15, accuracy=0.753, val_loss=2.43, val_accuracy=0.497, lr=0.0316] 61%|██████▏   | 57/93 [26:30<16:17, 27.16s/epoch, loss=1.14, accuracy=0.755, val_loss=2.67, val_accuracy=0.462, lr=0.1]    62%|██████▏   | 58/93 [26:57<15:52, 27.22s/epoch, loss=1.14, accuracy=0.753, val_loss=1.78, val_accuracy=0.546, lr=0.1] 63%|██████▎   | 59/93 [27:24<15:23, 27.16s/epoch, loss=1.14, accuracy=0.756, val_loss=2.6, val_accuracy=0.433, lr=0.1]  65%|██████▍   | 60/93 [27:52<14:59, 27.25s/epoch, loss=1.13, accuracy=0.755, val_loss=1.61, val_accuracy=0.587, lr=0.1] 66%|██████▌   | 61/93 [28:20<14:37, 27.43s/epoch, loss=1.14, accuracy=0.753, val_loss=1.64, val_accuracy=0.568, lr=0.0316] 67%|██████▋   | 62/93 [28:47<14:12, 27.50s/epoch, loss=1.14, accuracy=0.753, val_loss=2.46, val_accuracy=0.501, lr=0.1]    68%|██████▊   | 63/93 [29:15<13:43, 27.47s/epoch, loss=1.14, accuracy=0.752, val_loss=3.6, val_accuracy=0.307, lr=0.1]  69%|██████▉   | 64/93 [29:42<13:16, 27.46s/epoch, loss=1.14, accuracy=0.753, val_loss=2.21, val_accuracy=0.496, lr=0.1] 70%|██████▉   | 65/93 [30:10<12:48, 27.45s/epoch, loss=1.14, accuracy=0.751, val_loss=1.85, val_accuracy=0.498, lr=0.1] 71%|███████   | 66/93 [30:37<12:21, 27.47s/epoch, loss=1.13, accuracy=0.753, val_loss=2.24, val_accuracy=0.407, lr=0.0316] 72%|███████▏  | 67/93 [31:04<11:47, 27.19s/epoch, loss=1.14, accuracy=0.753, val_loss=1.61, val_accuracy=0.619, lr=0.1]    73%|███████▎  | 68/93 [31:31<11:20, 27.23s/epoch, loss=1.14, accuracy=0.754, val_loss=2.1, val_accuracy=0.468, lr=0.1]  74%|███████▍  | 69/93 [31:58<10:56, 27.34s/epoch, loss=1.14, accuracy=0.753, val_loss=2.67, val_accuracy=0.42, lr=0.1] 75%|███████▌  | 70/93 [32:26<10:30, 27.41s/epoch, loss=1.13, accuracy=0.754, val_loss=2.49, val_accuracy=0.354, lr=0.1] 76%|███████▋  | 71/93 [32:53<10:01, 27.35s/epoch, loss=1.13, accuracy=0.756, val_loss=4.13, val_accuracy=0.24, lr=0.0316] 77%|███████▋  | 72/93 [33:20<09:32, 27.27s/epoch, loss=1.13, accuracy=0.755, val_loss=3.54, val_accuracy=0.413, lr=0.1]   78%|███████▊  | 73/93 [33:47<09:03, 27.16s/epoch, loss=1.14, accuracy=0.751, val_loss=1.95, val_accuracy=0.534, lr=0.1] 80%|███████▉  | 74/93 [34:15<08:37, 27.22s/epoch, loss=1.14, accuracy=0.752, val_loss=2.48, val_accuracy=0.484, lr=0.1] 81%|████████  | 75/93 [34:41<08:07, 27.10s/epoch, loss=1.14, accuracy=0.752, val_loss=2.01, val_accuracy=0.525, lr=0.1] 82%|████████▏ | 76/93 [35:08<07:39, 27.04s/epoch, loss=1.14, accuracy=0.754, val_loss=2.03, val_accuracy=0.483, lr=0.0316] 83%|████████▎ | 77/93 [35:35<07:09, 26.86s/epoch, loss=1.13, accuracy=0.758, val_loss=3.9, val_accuracy=0.31, lr=0.1]      84%|████████▍ | 78/93 [36:01<06:40, 26.72s/epoch, loss=1.12, accuracy=0.755, val_loss=1.99, val_accuracy=0.507, lr=0.1] 85%|████████▍ | 79/93 [36:28<06:14, 26.77s/epoch, loss=1.13, accuracy=0.755, val_loss=3.35, val_accuracy=0.265, lr=0.1] 86%|████████▌ | 80/93 [36:55<05:48, 26.80s/epoch, loss=1.13, accuracy=0.753, val_loss=2.32, val_accuracy=0.398, lr=0.1] 87%|████████▋ | 81/93 [37:22<05:21, 26.77s/epoch, loss=1.13, accuracy=0.754, val_loss=2.08, val_accuracy=0.539, lr=0.0316] 88%|████████▊ | 82/93 [37:49<04:57, 27.01s/epoch, loss=0.932, accuracy=0.811, val_loss=1.01, val_accuracy=0.763, lr=0.01]  89%|████████▉ | 83/93 [38:16<04:30, 27.04s/epoch, loss=0.745, accuracy=0.846, val_loss=0.786, val_accuracy=0.824, lr=0.01] 90%|█████████ | 84/93 [38:44<04:04, 27.20s/epoch, loss=0.66, accuracy=0.854, val_loss=0.768, val_accuracy=0.81, lr=0.01]   91%|█████████▏| 85/93 [39:11<03:38, 27.28s/epoch, loss=0.614, accuracy=0.858, val_loss=0.776, val_accuracy=0.793, lr=0.01] 92%|█████████▏| 86/93 [39:39<03:11, 27.30s/epoch, loss=0.593, accuracy=0.859, val_loss=0.87, val_accuracy=0.777, lr=0.01]  94%|█████████▎| 87/93 [40:06<02:43, 27.31s/epoch, loss=0.58, accuracy=0.861, val_loss=0.837, val_accuracy=0.777, lr=0.01] 95%|█████████▍| 88/93 [40:33<02:15, 27.13s/epoch, loss=0.574, accuracy=0.861, val_loss=0.755, val_accuracy=0.796, lr=0.01] 96%|█████████▌| 89/93 [41:00<01:48, 27.05s/epoch, loss=0.57, accuracy=0.863, val_loss=0.813, val_accuracy=0.789, lr=0.01]  97%|█████████▋| 90/93 [41:27<01:21, 27.13s/epoch, loss=0.567, accuracy=0.864, val_loss=0.777, val_accuracy=0.793, lr=0.01] 98%|█████████▊| 91/93 [41:54<00:53, 26.99s/epoch, loss=0.564, accuracy=0.867, val_loss=0.736, val_accuracy=0.813, lr=0.01] 99%|█████████▉| 92/93 [42:21<00:27, 27.00s/epoch, loss=0.561, accuracy=0.868, val_loss=0.861, val_accuracy=0.775, lr=0.01]100%|██████████| 93/93 [42:48<00:00, 27.00s/epoch, loss=0.564, accuracy=0.87, val_loss=1.02, val_accuracy=0.717, lr=0.01]  100%|██████████| 93/93 [42:48<00:00, 27.61s/epoch, loss=0.564, accuracy=0.87, val_loss=1.02, val_accuracy=0.717, lr=0.01]
Using real-time data augmentation.
Test score: 1.0192630290985107
Test accuracy: 0.7172999978065491


* * * Run SGD for ID = 16_2. * * *


2024-03-05 06:17:42.968023: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 06:17:46.909202: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 06:17:46.910569: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-05 06:17:46.952753: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:18:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-05 06:17:46.952796: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 06:17:46.957955: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 06:17:46.958026: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 06:17:46.961604: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 06:17:46.963451: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 06:17:46.967976: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 06:17:46.970144: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 06:17:46.977771: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 06:17:46.978491: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 06:17:46.978583: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 06:17:48.287775: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-05 06:17:48.288806: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 06:17:48.289628: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:18:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-05 06:17:48.289665: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 06:17:48.289713: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 06:17:48.289731: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 06:17:48.289745: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 06:17:48.289759: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 06:17:48.289782: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 06:17:48.289796: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 06:17:48.289811: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 06:17:48.290418: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 06:17:48.290462: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 06:17:48.967328: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-05 06:17:48.967376: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-05 06:17:48.967386: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-05 06:17:48.968403: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:18:00.0, compute capability: 6.1)
{'id': '16_02', 'seed': 2, 'out_folder': 'results/epoch_budget', 'batch_size': 128, 'epochs': 93, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'bootstrapping': False, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/93 [00:00<?, ?epoch/s]2024-03-05 06:17:49.852477: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-05 06:17:49.864991: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2100000000 Hz
2024-03-05 06:17:51.970389: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 06:17:52.247939: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 06:17:53.472742: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-05 06:17:53.526150: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/93 [01:05<1:39:59, 65.21s/epoch, loss=2.97, accuracy=0.351, val_loss=3.21, val_accuracy=0.213, lr=0.1]  2%|▏         | 2/93 [01:31<1:04:29, 42.53s/epoch, loss=1.46, accuracy=0.59, val_loss=1.9, val_accuracy=0.479, lr=0.1]    3%|▎         | 3/93 [01:59<53:29, 35.66s/epoch, loss=1.3, accuracy=0.662, val_loss=2.41, val_accuracy=0.348, lr=0.1]   4%|▍         | 4/93 [02:26<48:06, 32.43s/epoch, loss=1.26, accuracy=0.692, val_loss=1.62, val_accuracy=0.581, lr=0.1]  5%|▌         | 5/93 [02:54<45:00, 30.68s/epoch, loss=1.24, accuracy=0.707, val_loss=1.62, val_accuracy=0.573, lr=0.1]  6%|▋         | 6/93 [03:22<43:01, 29.68s/epoch, loss=1.22, accuracy=0.717, val_loss=2.33, val_accuracy=0.492, lr=0.1]  8%|▊         | 7/93 [03:49<41:22, 28.86s/epoch, loss=1.2, accuracy=0.724, val_loss=1.72, val_accuracy=0.558, lr=0.1]   9%|▊         | 8/93 [04:17<40:23, 28.51s/epoch, loss=1.2, accuracy=0.726, val_loss=1.61, val_accuracy=0.585, lr=0.1] 10%|▉         | 9/93 [04:44<39:32, 28.25s/epoch, loss=1.2, accuracy=0.731, val_loss=2.32, val_accuracy=0.346, lr=0.1] 11%|█         | 10/93 [05:12<38:41, 27.97s/epoch, loss=1.19, accuracy=0.732, val_loss=1.82, val_accuracy=0.562, lr=0.1] 12%|█▏        | 11/93 [05:38<37:36, 27.52s/epoch, loss=1.19, accuracy=0.734, val_loss=1.53, val_accuracy=0.636, lr=0.1] 13%|█▎        | 12/93 [06:06<37:06, 27.49s/epoch, loss=1.18, accuracy=0.74, val_loss=1.86, val_accuracy=0.531, lr=0.1]  14%|█▍        | 13/93 [06:33<36:43, 27.54s/epoch, loss=1.18, accuracy=0.738, val_loss=2.39, val_accuracy=0.444, lr=0.1] 15%|█▌        | 14/93 [07:01<36:13, 27.52s/epoch, loss=1.17, accuracy=0.742, val_loss=1.95, val_accuracy=0.52, lr=0.1]  16%|█▌        | 15/93 [07:28<35:52, 27.60s/epoch, loss=1.17, accuracy=0.742, val_loss=1.41, val_accuracy=0.662, lr=0.1] 17%|█▋        | 16/93 [07:56<35:19, 27.52s/epoch, loss=1.17, accuracy=0.743, val_loss=2.32, val_accuracy=0.402, lr=0.1] 18%|█▊        | 17/93 [08:24<34:58, 27.62s/epoch, loss=1.16, accuracy=0.744, val_loss=1.94, val_accuracy=0.509, lr=0.1] 19%|█▉        | 18/93 [08:51<34:30, 27.60s/epoch, loss=1.17, accuracy=0.743, val_loss=1.54, val_accuracy=0.608, lr=0.1] 20%|██        | 19/93 [09:19<34:00, 27.57s/epoch, loss=1.17, accuracy=0.746, val_loss=2.21, val_accuracy=0.436, lr=0.1] 22%|██▏       | 20/93 [09:46<33:35, 27.60s/epoch, loss=1.16, accuracy=0.747, val_loss=3.67, val_accuracy=0.303, lr=0.0316] 23%|██▎       | 21/93 [10:14<33:06, 27.59s/epoch, loss=1.15, accuracy=0.748, val_loss=1.53, val_accuracy=0.603, lr=0.1]    24%|██▎       | 22/93 [10:41<32:31, 27.49s/epoch, loss=1.15, accuracy=0.747, val_loss=1.9, val_accuracy=0.516, lr=0.1]  25%|██▍       | 23/93 [11:08<31:57, 27.39s/epoch, loss=1.15, accuracy=0.749, val_loss=2.07, val_accuracy=0.465, lr=0.1] 26%|██▌       | 24/93 [11:36<31:39, 27.53s/epoch, loss=1.15, accuracy=0.75, val_loss=1.57, val_accuracy=0.599, lr=0.1]  27%|██▋       | 25/93 [12:04<31:12, 27.53s/epoch, loss=1.15, accuracy=0.751, val_loss=1.93, val_accuracy=0.574, lr=0.0316] 28%|██▊       | 26/93 [12:31<30:46, 27.56s/epoch, loss=1.15, accuracy=0.751, val_loss=2.35, val_accuracy=0.417, lr=0.1]    29%|██▉       | 27/93 [12:59<30:22, 27.61s/epoch, loss=1.14, accuracy=0.753, val_loss=2.63, val_accuracy=0.373, lr=0.1] 30%|███       | 28/93 [13:27<29:58, 27.68s/epoch, loss=1.15, accuracy=0.752, val_loss=1.89, val_accuracy=0.48, lr=0.1]  31%|███       | 29/93 [13:54<29:22, 27.54s/epoch, loss=1.14, accuracy=0.751, val_loss=3.14, val_accuracy=0.332, lr=0.1] 32%|███▏      | 30/93 [14:22<29:02, 27.65s/epoch, loss=1.14, accuracy=0.752, val_loss=1.77, val_accuracy=0.562, lr=0.0316] 33%|███▎      | 31/93 [14:50<28:38, 27.71s/epoch, loss=1.14, accuracy=0.754, val_loss=2.23, val_accuracy=0.447, lr=0.1]    34%|███▍      | 32/93 [15:17<28:08, 27.68s/epoch, loss=1.13, accuracy=0.754, val_loss=2.21, val_accuracy=0.491, lr=0.1] 35%|███▌      | 33/93 [15:45<27:41, 27.69s/epoch, loss=1.13, accuracy=0.755, val_loss=1.67, val_accuracy=0.598, lr=0.1] 37%|███▋      | 34/93 [16:13<27:12, 27.67s/epoch, loss=1.13, accuracy=0.755, val_loss=2.25, val_accuracy=0.495, lr=0.1] 38%|███▊      | 35/93 [16:40<26:42, 27.63s/epoch, loss=1.13, accuracy=0.756, val_loss=1.86, val_accuracy=0.563, lr=0.0316] 39%|███▊      | 36/93 [17:08<26:20, 27.72s/epoch, loss=1.13, accuracy=0.756, val_loss=1.7, val_accuracy=0.584, lr=0.1]     40%|███▉      | 37/93 [17:36<25:49, 27.66s/epoch, loss=1.13, accuracy=0.755, val_loss=2.66, val_accuracy=0.405, lr=0.1] 41%|████      | 38/93 [18:04<25:22, 27.67s/epoch, loss=1.13, accuracy=0.755, val_loss=2.32, val_accuracy=0.461, lr=0.1] 42%|████▏     | 39/93 [18:31<24:50, 27.60s/epoch, loss=1.13, accuracy=0.755, val_loss=1.92, val_accuracy=0.518, lr=0.1] 43%|████▎     | 40/93 [18:58<24:21, 27.57s/epoch, loss=1.13, accuracy=0.756, val_loss=2.07, val_accuracy=0.494, lr=0.0316] 44%|████▍     | 41/93 [19:26<23:49, 27.50s/epoch, loss=1.12, accuracy=0.757, val_loss=1.45, val_accuracy=0.638, lr=0.1]    45%|████▌     | 42/93 [19:53<23:23, 27.52s/epoch, loss=1.12, accuracy=0.755, val_loss=1.54, val_accuracy=0.65, lr=0.1]  46%|████▌     | 43/93 [20:21<22:58, 27.58s/epoch, loss=1.13, accuracy=0.758, val_loss=1.72, val_accuracy=0.571, lr=0.1] 47%|████▋     | 44/93 [20:46<21:55, 26.84s/epoch, loss=1.12, accuracy=0.759, val_loss=2.77, val_accuracy=0.458, lr=0.1] 48%|████▊     | 45/93 [21:14<21:42, 27.14s/epoch, loss=1.13, accuracy=0.757, val_loss=2.29, val_accuracy=0.468, lr=0.0316] 49%|████▉     | 46/93 [21:42<21:27, 27.40s/epoch, loss=1.12, accuracy=0.758, val_loss=1.51, val_accuracy=0.642, lr=0.1]    51%|█████     | 47/93 [22:09<20:59, 27.37s/epoch, loss=1.13, accuracy=0.756, val_loss=1.43, val_accuracy=0.647, lr=0.1] 52%|█████▏    | 48/93 [22:36<20:23, 27.19s/epoch, loss=1.11, accuracy=0.757, val_loss=3.68, val_accuracy=0.355, lr=0.1] 53%|█████▎    | 49/93 [23:03<19:47, 26.99s/epoch, loss=1.12, accuracy=0.756, val_loss=2.82, val_accuracy=0.357, lr=0.1] 54%|█████▍    | 50/93 [23:29<19:08, 26.71s/epoch, loss=1.12, accuracy=0.756, val_loss=3.54, val_accuracy=0.364, lr=0.0316] 55%|█████▍    | 51/93 [23:56<18:43, 26.76s/epoch, loss=1.12, accuracy=0.758, val_loss=2.3, val_accuracy=0.492, lr=0.1]     56%|█████▌    | 52/93 [24:22<18:11, 26.63s/epoch, loss=1.12, accuracy=0.757, val_loss=2.24, val_accuracy=0.439, lr=0.1] 57%|█████▋    | 53/93 [24:49<17:47, 26.68s/epoch, loss=1.12, accuracy=0.757, val_loss=1.76, val_accuracy=0.575, lr=0.1] 58%|█████▊    | 54/93 [25:15<17:19, 26.66s/epoch, loss=1.12, accuracy=0.758, val_loss=2.22, val_accuracy=0.502, lr=0.1] 59%|█████▉    | 55/93 [25:41<16:47, 26.52s/epoch, loss=1.11, accuracy=0.76, val_loss=3.47, val_accuracy=0.283, lr=0.0316] 60%|██████    | 56/93 [26:09<16:31, 26.80s/epoch, loss=1.12, accuracy=0.758, val_loss=10.1, val_accuracy=0.116, lr=0.1]   61%|██████▏   | 57/93 [26:37<16:13, 27.04s/epoch, loss=1.12, accuracy=0.759, val_loss=1.7, val_accuracy=0.553, lr=0.1]  62%|██████▏   | 58/93 [27:04<15:49, 27.14s/epoch, loss=1.12, accuracy=0.759, val_loss=1.95, val_accuracy=0.532, lr=0.1] 63%|██████▎   | 59/93 [27:31<15:24, 27.18s/epoch, loss=1.12, accuracy=0.757, val_loss=4.19, val_accuracy=0.267, lr=0.1] 65%|██████▍   | 60/93 [27:58<14:51, 27.03s/epoch, loss=1.12, accuracy=0.758, val_loss=1.85, val_accuracy=0.519, lr=0.0316] 66%|██████▌   | 61/93 [28:24<14:17, 26.78s/epoch, loss=1.12, accuracy=0.76, val_loss=2.64, val_accuracy=0.455, lr=0.1]     67%|██████▋   | 62/93 [28:50<13:46, 26.67s/epoch, loss=1.11, accuracy=0.761, val_loss=2.56, val_accuracy=0.402, lr=0.1] 68%|██████▊   | 63/93 [29:17<13:17, 26.58s/epoch, loss=1.11, accuracy=0.76, val_loss=1.68, val_accuracy=0.581, lr=0.1]  69%|██████▉   | 64/93 [29:43<12:50, 26.57s/epoch, loss=1.11, accuracy=0.76, val_loss=4, val_accuracy=0.281, lr=0.1]    70%|██████▉   | 65/93 [30:10<12:21, 26.47s/epoch, loss=1.11, accuracy=0.76, val_loss=1.69, val_accuracy=0.566, lr=0.0316] 71%|███████   | 66/93 [30:36<11:52, 26.40s/epoch, loss=1.11, accuracy=0.759, val_loss=2.91, val_accuracy=0.446, lr=0.1]   72%|███████▏  | 67/93 [31:02<11:23, 26.30s/epoch, loss=1.12, accuracy=0.757, val_loss=1.35, val_accuracy=0.688, lr=0.1] 73%|███████▎  | 68/93 [31:29<11:01, 26.46s/epoch, loss=1.11, accuracy=0.757, val_loss=2.55, val_accuracy=0.38, lr=0.1]  74%|███████▍  | 69/93 [31:55<10:34, 26.45s/epoch, loss=1.11, accuracy=0.759, val_loss=5.26, val_accuracy=0.349, lr=0.1] 75%|███████▌  | 70/93 [32:23<10:15, 26.75s/epoch, loss=1.11, accuracy=0.758, val_loss=1.92, val_accuracy=0.492, lr=0.1] 76%|███████▋  | 71/93 [32:50<09:52, 26.95s/epoch, loss=1.11, accuracy=0.757, val_loss=1.83, val_accuracy=0.539, lr=0.1] 77%|███████▋  | 72/93 [33:18<09:29, 27.13s/epoch, loss=1.11, accuracy=0.761, val_loss=1.56, val_accuracy=0.617, lr=0.0316] 78%|███████▊  | 73/93 [33:45<09:02, 27.13s/epoch, loss=1.12, accuracy=0.757, val_loss=1.86, val_accuracy=0.553, lr=0.1]    80%|███████▉  | 74/93 [34:12<08:38, 27.28s/epoch, loss=1.11, accuracy=0.76, val_loss=2.09, val_accuracy=0.504, lr=0.1]  81%|████████  | 75/93 [34:40<08:10, 27.25s/epoch, loss=1.11, accuracy=0.761, val_loss=2.31, val_accuracy=0.506, lr=0.1] 82%|████████▏ | 76/93 [35:07<07:44, 27.32s/epoch, loss=1.11, accuracy=0.756, val_loss=1.95, val_accuracy=0.488, lr=0.1] 83%|████████▎ | 77/93 [35:34<07:16, 27.28s/epoch, loss=1.11, accuracy=0.757, val_loss=4.4, val_accuracy=0.306, lr=0.0316] 84%|████████▍ | 78/93 [36:02<06:49, 27.28s/epoch, loss=1.11, accuracy=0.759, val_loss=2.46, val_accuracy=0.412, lr=0.1]   85%|████████▍ | 79/93 [36:29<06:22, 27.33s/epoch, loss=1.1, accuracy=0.76, val_loss=2.27, val_accuracy=0.409, lr=0.1]   86%|████████▌ | 80/93 [36:56<05:55, 27.31s/epoch, loss=1.11, accuracy=0.757, val_loss=1.89, val_accuracy=0.53, lr=0.1] 87%|████████▋ | 81/93 [37:23<05:24, 27.07s/epoch, loss=1.11, accuracy=0.76, val_loss=2.3, val_accuracy=0.475, lr=0.1]  88%|████████▊ | 82/93 [37:50<04:58, 27.10s/epoch, loss=0.91, accuracy=0.813, val_loss=0.98, val_accuracy=0.775, lr=0.01] 89%|████████▉ | 83/93 [38:17<04:31, 27.15s/epoch, loss=0.728, accuracy=0.846, val_loss=0.79, val_accuracy=0.811, lr=0.01] 90%|█████████ | 84/93 [38:44<04:04, 27.19s/epoch, loss=0.639, accuracy=0.858, val_loss=0.78, val_accuracy=0.808, lr=0.01] 91%|█████████▏| 85/93 [39:11<03:36, 27.11s/epoch, loss=0.603, accuracy=0.859, val_loss=0.879, val_accuracy=0.769, lr=0.01] 92%|█████████▏| 86/93 [39:38<03:08, 26.90s/epoch, loss=0.578, accuracy=0.862, val_loss=0.778, val_accuracy=0.794, lr=0.01] 94%|█████████▎| 87/93 [40:05<02:41, 26.96s/epoch, loss=0.569, accuracy=0.864, val_loss=0.698, val_accuracy=0.822, lr=0.01] 95%|█████████▍| 88/93 [40:32<02:15, 27.02s/epoch, loss=0.56, accuracy=0.864, val_loss=0.909, val_accuracy=0.765, lr=0.01]  96%|█████████▌| 89/93 [40:59<01:48, 27.05s/epoch, loss=0.561, accuracy=0.865, val_loss=0.863, val_accuracy=0.77, lr=0.01] 97%|█████████▋| 90/93 [41:27<01:21, 27.15s/epoch, loss=0.557, accuracy=0.866, val_loss=0.922, val_accuracy=0.757, lr=0.01] 98%|█████████▊| 91/93 [41:54<00:54, 27.15s/epoch, loss=0.554, accuracy=0.87, val_loss=1.19, val_accuracy=0.675, lr=0.01]   99%|█████████▉| 92/93 [42:20<00:26, 26.98s/epoch, loss=0.553, accuracy=0.869, val_loss=0.761, val_accuracy=0.8, lr=0.00316]100%|██████████| 93/93 [42:47<00:00, 26.90s/epoch, loss=0.558, accuracy=0.869, val_loss=0.737, val_accuracy=0.818, lr=0.01] 100%|██████████| 93/93 [42:47<00:00, 27.61s/epoch, loss=0.558, accuracy=0.869, val_loss=0.737, val_accuracy=0.818, lr=0.01]
Using real-time data augmentation.
Test score: 0.7365756630897522
Test accuracy: 0.817799985408783


* * * Run SGD for ID = 16_3. * * *


2024-03-05 07:00:41.196350: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 07:00:43.705931: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 07:00:43.707045: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-05 07:00:43.747925: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:18:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-05 07:00:43.747964: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 07:00:43.751340: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 07:00:43.751403: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 07:00:43.753925: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 07:00:43.755107: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 07:00:43.757822: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 07:00:43.759757: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 07:00:43.765229: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 07:00:43.765912: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 07:00:43.765999: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 07:00:44.927322: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-05 07:00:44.928031: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 07:00:44.929187: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:18:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-05 07:00:44.929222: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 07:00:44.929259: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 07:00:44.929273: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 07:00:44.929285: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 07:00:44.929297: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 07:00:44.929310: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 07:00:44.929324: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 07:00:44.929338: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 07:00:44.929870: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 07:00:44.929905: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 07:00:45.538178: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-05 07:00:45.538242: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-05 07:00:45.538252: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-05 07:00:45.539293: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:18:00.0, compute capability: 6.1)
{'id': '16_03', 'seed': 3, 'out_folder': 'results/epoch_budget', 'batch_size': 128, 'epochs': 93, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'bootstrapping': False, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/93 [00:00<?, ?epoch/s]2024-03-05 07:00:46.355004: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-05 07:00:46.355750: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2100000000 Hz
2024-03-05 07:00:48.178280: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 07:00:48.487011: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 07:00:49.340656: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-05 07:00:49.386411: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/93 [01:05<1:41:09, 65.98s/epoch, loss=2.9, accuracy=0.387, val_loss=2.52, val_accuracy=0.252, lr=0.1]  2%|▏         | 2/93 [01:33<1:06:07, 43.60s/epoch, loss=1.48, accuracy=0.584, val_loss=2.18, val_accuracy=0.412, lr=0.1]  3%|▎         | 3/93 [02:01<54:33, 36.37s/epoch, loss=1.3, accuracy=0.665, val_loss=2.62, val_accuracy=0.333, lr=0.1]     4%|▍         | 4/93 [02:29<48:49, 32.92s/epoch, loss=1.24, accuracy=0.696, val_loss=2.54, val_accuracy=0.406, lr=0.1]  5%|▌         | 5/93 [02:56<45:30, 31.03s/epoch, loss=1.23, accuracy=0.712, val_loss=1.93, val_accuracy=0.45, lr=0.1]   6%|▋         | 6/93 [03:24<43:20, 29.89s/epoch, loss=1.21, accuracy=0.72, val_loss=1.62, val_accuracy=0.604, lr=0.1]  8%|▊         | 7/93 [03:52<41:40, 29.08s/epoch, loss=1.2, accuracy=0.727, val_loss=2.38, val_accuracy=0.438, lr=0.1]  9%|▊         | 8/93 [04:19<40:29, 28.58s/epoch, loss=1.19, accuracy=0.731, val_loss=1.97, val_accuracy=0.552, lr=0.1] 10%|▉         | 9/93 [04:47<39:33, 28.26s/epoch, loss=1.19, accuracy=0.732, val_loss=1.59, val_accuracy=0.587, lr=0.1] 11%|█         | 10/93 [05:15<39:07, 28.29s/epoch, loss=1.18, accuracy=0.738, val_loss=1.99, val_accuracy=0.567, lr=0.1] 12%|█▏        | 11/93 [05:42<38:19, 28.04s/epoch, loss=1.17, accuracy=0.743, val_loss=1.9, val_accuracy=0.529, lr=0.1]  13%|█▎        | 12/93 [06:10<37:43, 27.95s/epoch, loss=1.18, accuracy=0.742, val_loss=1.73, val_accuracy=0.538, lr=0.1] 14%|█▍        | 13/93 [06:38<37:03, 27.79s/epoch, loss=1.17, accuracy=0.745, val_loss=2.95, val_accuracy=0.407, lr=0.1] 15%|█▌        | 14/93 [07:05<36:34, 27.78s/epoch, loss=1.17, accuracy=0.745, val_loss=1.91, val_accuracy=0.547, lr=0.0316] 16%|█▌        | 15/93 [07:33<35:55, 27.64s/epoch, loss=1.17, accuracy=0.744, val_loss=2, val_accuracy=0.501, lr=0.1]       17%|█▋        | 16/93 [08:01<35:35, 27.73s/epoch, loss=1.16, accuracy=0.749, val_loss=3.06, val_accuracy=0.367, lr=0.1] 18%|█▊        | 17/93 [08:28<35:06, 27.71s/epoch, loss=1.16, accuracy=0.748, val_loss=1.69, val_accuracy=0.541, lr=0.1] 19%|█▉        | 18/93 [08:56<34:41, 27.76s/epoch, loss=1.15, accuracy=0.751, val_loss=1.99, val_accuracy=0.473, lr=0.1] 20%|██        | 19/93 [09:24<34:05, 27.64s/epoch, loss=1.16, accuracy=0.749, val_loss=2.38, val_accuracy=0.481, lr=0.0316] 22%|██▏       | 20/93 [09:52<33:46, 27.75s/epoch, loss=1.16, accuracy=0.75, val_loss=2.12, val_accuracy=0.474, lr=0.1]     23%|██▎       | 21/93 [10:19<33:14, 27.70s/epoch, loss=1.15, accuracy=0.752, val_loss=1.59, val_accuracy=0.634, lr=0.1] 24%|██▎       | 22/93 [10:47<32:47, 27.71s/epoch, loss=1.15, accuracy=0.751, val_loss=1.9, val_accuracy=0.477, lr=0.1]  25%|██▍       | 23/93 [11:14<32:11, 27.60s/epoch, loss=1.15, accuracy=0.753, val_loss=1.47, val_accuracy=0.642, lr=0.1] 26%|██▌       | 24/93 [11:42<31:44, 27.61s/epoch, loss=1.14, accuracy=0.751, val_loss=1.94, val_accuracy=0.504, lr=0.1] 27%|██▋       | 25/93 [12:09<31:17, 27.61s/epoch, loss=1.15, accuracy=0.749, val_loss=2.53, val_accuracy=0.372, lr=0.1] 28%|██▊       | 26/93 [12:38<31:01, 27.79s/epoch, loss=1.14, accuracy=0.752, val_loss=3.76, val_accuracy=0.31, lr=0.1]  29%|██▉       | 27/93 [13:06<30:38, 27.86s/epoch, loss=1.14, accuracy=0.751, val_loss=2.37, val_accuracy=0.43, lr=0.1] 30%|███       | 28/93 [13:33<30:02, 27.73s/epoch, loss=1.13, accuracy=0.753, val_loss=2.25, val_accuracy=0.42, lr=0.0316] 31%|███       | 29/93 [14:01<29:30, 27.67s/epoch, loss=1.14, accuracy=0.752, val_loss=1.74, val_accuracy=0.555, lr=0.1]   32%|███▏      | 30/93 [14:28<28:58, 27.60s/epoch, loss=1.14, accuracy=0.752, val_loss=2.32, val_accuracy=0.451, lr=0.1] 33%|███▎      | 31/93 [14:55<28:26, 27.52s/epoch, loss=1.13, accuracy=0.755, val_loss=1.73, val_accuracy=0.544, lr=0.1] 34%|███▍      | 32/93 [15:23<28:00, 27.55s/epoch, loss=1.13, accuracy=0.756, val_loss=4.36, val_accuracy=0.155, lr=0.1] 35%|███▌      | 33/93 [15:51<27:39, 27.66s/epoch, loss=1.14, accuracy=0.753, val_loss=1.83, val_accuracy=0.563, lr=0.0316] 37%|███▋      | 34/93 [16:18<27:08, 27.60s/epoch, loss=1.14, accuracy=0.753, val_loss=1.5, val_accuracy=0.624, lr=0.1]     38%|███▊      | 35/93 [16:46<26:34, 27.50s/epoch, loss=1.12, accuracy=0.757, val_loss=1.67, val_accuracy=0.562, lr=0.1] 39%|███▊      | 36/93 [17:12<25:43, 27.08s/epoch, loss=1.12, accuracy=0.756, val_loss=3.17, val_accuracy=0.351, lr=0.1] 40%|███▉      | 37/93 [17:38<25:04, 26.86s/epoch, loss=1.12, accuracy=0.757, val_loss=2.08, val_accuracy=0.536, lr=0.1] 41%|████      | 38/93 [18:06<24:46, 27.02s/epoch, loss=1.12, accuracy=0.757, val_loss=2.13, val_accuracy=0.492, lr=0.0316] 42%|████▏     | 39/93 [18:32<24:17, 26.99s/epoch, loss=1.12, accuracy=0.755, val_loss=1.91, val_accuracy=0.522, lr=0.1]    43%|████▎     | 40/93 [19:00<23:56, 27.10s/epoch, loss=1.12, accuracy=0.758, val_loss=1.37, val_accuracy=0.679, lr=0.1] 44%|████▍     | 41/93 [19:27<23:35, 27.23s/epoch, loss=1.12, accuracy=0.757, val_loss=1.78, val_accuracy=0.543, lr=0.1] 45%|████▌     | 42/93 [19:55<23:12, 27.30s/epoch, loss=1.12, accuracy=0.757, val_loss=2.71, val_accuracy=0.379, lr=0.1] 46%|████▌     | 43/93 [20:21<22:34, 27.08s/epoch, loss=1.12, accuracy=0.758, val_loss=3.62, val_accuracy=0.244, lr=0.1] 47%|████▋     | 44/93 [20:48<21:55, 26.86s/epoch, loss=1.13, accuracy=0.755, val_loss=1.82, val_accuracy=0.543, lr=0.1] 48%|████▊     | 45/93 [21:15<21:31, 26.91s/epoch, loss=1.12, accuracy=0.758, val_loss=1.72, val_accuracy=0.562, lr=0.0316] 49%|████▉     | 46/93 [21:41<21:01, 26.84s/epoch, loss=1.12, accuracy=0.759, val_loss=1.72, val_accuracy=0.592, lr=0.1]    51%|█████     | 47/93 [22:09<20:44, 27.06s/epoch, loss=1.11, accuracy=0.761, val_loss=2.1, val_accuracy=0.464, lr=0.1]  52%|█████▏    | 48/93 [22:37<20:26, 27.26s/epoch, loss=1.11, accuracy=0.759, val_loss=1.74, val_accuracy=0.554, lr=0.1] 53%|█████▎    | 49/93 [23:04<20:05, 27.40s/epoch, loss=1.12, accuracy=0.756, val_loss=1.7, val_accuracy=0.59, lr=0.1]   54%|█████▍    | 50/93 [23:32<19:40, 27.46s/epoch, loss=1.11, accuracy=0.759, val_loss=2.18, val_accuracy=0.454, lr=0.0316] 55%|█████▍    | 51/93 [23:59<19:12, 27.45s/epoch, loss=1.12, accuracy=0.758, val_loss=2.36, val_accuracy=0.396, lr=0.1]    56%|█████▌    | 52/93 [24:27<18:40, 27.34s/epoch, loss=1.11, accuracy=0.758, val_loss=1.77, val_accuracy=0.522, lr=0.1] 57%|█████▋    | 53/93 [24:54<18:10, 27.27s/epoch, loss=1.12, accuracy=0.759, val_loss=1.8, val_accuracy=0.516, lr=0.1]  58%|█████▊    | 54/93 [25:21<17:41, 27.21s/epoch, loss=1.11, accuracy=0.76, val_loss=1.71, val_accuracy=0.583, lr=0.1] 59%|█████▉    | 55/93 [25:49<17:21, 27.41s/epoch, loss=1.11, accuracy=0.758, val_loss=1.6, val_accuracy=0.586, lr=0.0316] 60%|██████    | 56/93 [26:16<16:52, 27.37s/epoch, loss=1.11, accuracy=0.757, val_loss=2.24, val_accuracy=0.444, lr=0.1]   61%|██████▏   | 57/93 [26:43<16:26, 27.39s/epoch, loss=1.11, accuracy=0.759, val_loss=2.16, val_accuracy=0.421, lr=0.1] 62%|██████▏   | 58/93 [27:11<16:00, 27.44s/epoch, loss=1.12, accuracy=0.756, val_loss=2.08, val_accuracy=0.42, lr=0.1]  63%|██████▎   | 59/93 [27:38<15:25, 27.22s/epoch, loss=1.11, accuracy=0.76, val_loss=1.89, val_accuracy=0.5, lr=0.1]   65%|██████▍   | 60/93 [28:04<14:48, 26.93s/epoch, loss=1.11, accuracy=0.761, val_loss=2.61, val_accuracy=0.312, lr=0.0316] 66%|██████▌   | 61/93 [28:28<13:53, 26.04s/epoch, loss=1.12, accuracy=0.759, val_loss=1.94, val_accuracy=0.488, lr=0.1]    67%|██████▋   | 62/93 [28:52<13:11, 25.55s/epoch, loss=1.1, accuracy=0.76, val_loss=2.25, val_accuracy=0.442, lr=0.1]   68%|██████▊   | 63/93 [29:18<12:45, 25.52s/epoch, loss=1.11, accuracy=0.76, val_loss=1.46, val_accuracy=0.64, lr=0.1] 69%|██████▉   | 64/93 [29:45<12:36, 26.09s/epoch, loss=1.11, accuracy=0.759, val_loss=2.45, val_accuracy=0.36, lr=0.1] 70%|██████▉   | 65/93 [30:13<12:22, 26.52s/epoch, loss=1.12, accuracy=0.758, val_loss=2.58, val_accuracy=0.39, lr=0.0316] 71%|███████   | 66/93 [30:39<11:57, 26.58s/epoch, loss=1.11, accuracy=0.759, val_loss=1.92, val_accuracy=0.514, lr=0.1]   72%|███████▏  | 67/93 [31:06<11:35, 26.73s/epoch, loss=1.11, accuracy=0.759, val_loss=1.51, val_accuracy=0.605, lr=0.1] 73%|███████▎  | 68/93 [31:34<11:11, 26.86s/epoch, loss=1.1, accuracy=0.759, val_loss=3.12, val_accuracy=0.324, lr=0.1]  74%|███████▍  | 69/93 [32:01<10:49, 27.06s/epoch, loss=1.11, accuracy=0.758, val_loss=1.89, val_accuracy=0.543, lr=0.1] 75%|███████▌  | 70/93 [32:28<10:23, 27.11s/epoch, loss=1.1, accuracy=0.76, val_loss=1.61, val_accuracy=0.607, lr=0.0316] 76%|███████▋  | 71/93 [32:56<09:57, 27.18s/epoch, loss=1.11, accuracy=0.76, val_loss=2.41, val_accuracy=0.466, lr=0.1]   77%|███████▋  | 72/93 [33:23<09:31, 27.23s/epoch, loss=1.11, accuracy=0.759, val_loss=1.78, val_accuracy=0.504, lr=0.1] 78%|███████▊  | 73/93 [33:50<09:05, 27.27s/epoch, loss=1.11, accuracy=0.758, val_loss=1.61, val_accuracy=0.581, lr=0.1] 80%|███████▉  | 74/93 [34:17<08:37, 27.22s/epoch, loss=1.11, accuracy=0.758, val_loss=2.15, val_accuracy=0.474, lr=0.1] 81%|████████  | 75/93 [34:45<08:11, 27.32s/epoch, loss=1.11, accuracy=0.759, val_loss=2.22, val_accuracy=0.488, lr=0.0316] 82%|████████▏ | 76/93 [35:12<07:44, 27.32s/epoch, loss=1.11, accuracy=0.759, val_loss=2.98, val_accuracy=0.267, lr=0.1]    83%|████████▎ | 77/93 [35:39<07:15, 27.20s/epoch, loss=1.11, accuracy=0.759, val_loss=2.19, val_accuracy=0.416, lr=0.1] 84%|████████▍ | 78/93 [36:07<06:48, 27.25s/epoch, loss=1.11, accuracy=0.759, val_loss=5.86, val_accuracy=0.229, lr=0.1] 85%|████████▍ | 79/93 [36:33<06:18, 27.04s/epoch, loss=1.11, accuracy=0.756, val_loss=2.22, val_accuracy=0.495, lr=0.1] 86%|████████▌ | 80/93 [37:00<05:51, 27.04s/epoch, loss=1.11, accuracy=0.76, val_loss=2.95, val_accuracy=0.213, lr=0.0316] 87%|████████▋ | 81/93 [37:27<05:25, 27.11s/epoch, loss=1.11, accuracy=0.76, val_loss=3.57, val_accuracy=0.351, lr=0.1]    88%|████████▊ | 82/93 [37:55<04:59, 27.19s/epoch, loss=0.914, accuracy=0.816, val_loss=0.899, val_accuracy=0.801, lr=0.01] 89%|████████▉ | 83/93 [38:22<04:32, 27.21s/epoch, loss=0.725, accuracy=0.85, val_loss=0.77, val_accuracy=0.821, lr=0.01]   90%|█████████ | 84/93 [38:50<04:05, 27.30s/epoch, loss=0.642, accuracy=0.858, val_loss=0.864, val_accuracy=0.774, lr=0.01] 91%|█████████▏| 85/93 [39:17<03:38, 27.32s/epoch, loss=0.601, accuracy=0.861, val_loss=0.723, val_accuracy=0.816, lr=0.01] 92%|█████████▏| 86/93 [39:44<03:11, 27.36s/epoch, loss=0.578, accuracy=0.863, val_loss=0.938, val_accuracy=0.742, lr=0.01] 94%|█████████▎| 87/93 [40:11<02:43, 27.27s/epoch, loss=0.575, accuracy=0.861, val_loss=0.793, val_accuracy=0.79, lr=0.01]  95%|█████████▍| 88/93 [40:39<02:16, 27.36s/epoch, loss=0.563, accuracy=0.865, val_loss=1.21, val_accuracy=0.663, lr=0.01] 96%|█████████▌| 89/93 [41:06<01:49, 27.33s/epoch, loss=0.56, accuracy=0.864, val_loss=0.813, val_accuracy=0.778, lr=0.01] 97%|█████████▋| 90/93 [41:34<01:22, 27.38s/epoch, loss=0.558, accuracy=0.866, val_loss=0.831, val_accuracy=0.786, lr=0.00316] 98%|█████████▊| 91/93 [42:00<00:54, 27.11s/epoch, loss=0.557, accuracy=0.867, val_loss=0.802, val_accuracy=0.801, lr=0.01]    99%|█████████▉| 92/93 [42:28<00:27, 27.15s/epoch, loss=0.556, accuracy=0.871, val_loss=0.758, val_accuracy=0.81, lr=0.01] 100%|██████████| 93/93 [42:55<00:00, 27.26s/epoch, loss=0.556, accuracy=0.872, val_loss=0.85, val_accuracy=0.77, lr=0.01] 100%|██████████| 93/93 [42:55<00:00, 27.69s/epoch, loss=0.556, accuracy=0.872, val_loss=0.85, val_accuracy=0.77, lr=0.01]
Using real-time data augmentation.
Test score: 0.8495767712593079
Test accuracy: 0.7700999975204468


* * * Run SGD for ID = 16_4. * * *


2024-03-05 07:43:46.702941: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 07:43:52.629722: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 07:43:52.630967: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-05 07:43:52.671149: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:18:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-05 07:43:52.671191: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 07:43:52.676585: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 07:43:52.676645: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 07:43:52.680442: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 07:43:52.682440: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 07:43:52.685935: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 07:43:52.688914: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 07:43:52.695075: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 07:43:52.695743: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 07:43:52.695844: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 07:43:53.857883: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-05 07:43:53.858560: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 07:43:53.859694: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:18:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-05 07:43:53.859742: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 07:43:53.859782: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 07:43:53.859802: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 07:43:53.859821: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 07:43:53.859849: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 07:43:53.859870: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 07:43:53.859890: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 07:43:53.859910: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 07:43:53.860473: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 07:43:53.860519: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 07:43:54.484177: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-05 07:43:54.484235: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-05 07:43:54.484246: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-05 07:43:54.485302: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:18:00.0, compute capability: 6.1)
{'id': '16_04', 'seed': 4, 'out_folder': 'results/epoch_budget', 'batch_size': 128, 'epochs': 93, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'bootstrapping': False, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/93 [00:00<?, ?epoch/s]2024-03-05 07:43:55.314861: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-05 07:43:55.326993: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2100000000 Hz
2024-03-05 07:43:57.135968: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 07:43:57.411217: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 07:43:58.519377: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-05 07:43:58.578288: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/93 [01:07<1:42:55, 67.12s/epoch, loss=2.98, accuracy=0.361, val_loss=2.17, val_accuracy=0.357, lr=0.1]  2%|▏         | 2/93 [01:33<1:05:32, 43.21s/epoch, loss=1.48, accuracy=0.574, val_loss=3.1, val_accuracy=0.342, lr=0.1]   3%|▎         | 3/93 [02:00<53:25, 35.61s/epoch, loss=1.3, accuracy=0.657, val_loss=1.65, val_accuracy=0.554, lr=0.1]    4%|▍         | 4/93 [02:27<47:47, 32.22s/epoch, loss=1.25, accuracy=0.692, val_loss=1.6, val_accuracy=0.569, lr=0.1]  5%|▌         | 5/93 [02:53<44:06, 30.08s/epoch, loss=1.22, accuracy=0.71, val_loss=1.99, val_accuracy=0.494, lr=0.1]  6%|▋         | 6/93 [03:20<42:00, 28.97s/epoch, loss=1.22, accuracy=0.72, val_loss=2.15, val_accuracy=0.491, lr=0.1]  8%|▊         | 7/93 [03:46<40:20, 28.14s/epoch, loss=1.21, accuracy=0.724, val_loss=1.72, val_accuracy=0.575, lr=0.1]  9%|▊         | 8/93 [04:13<39:05, 27.59s/epoch, loss=1.2, accuracy=0.728, val_loss=1.92, val_accuracy=0.536, lr=0.1]  10%|▉         | 9/93 [04:40<38:18, 27.36s/epoch, loss=1.19, accuracy=0.734, val_loss=1.55, val_accuracy=0.63, lr=0.1] 11%|█         | 10/93 [05:07<37:59, 27.46s/epoch, loss=1.19, accuracy=0.737, val_loss=2, val_accuracy=0.481, lr=0.1]  12%|█▏        | 11/93 [05:34<37:27, 27.41s/epoch, loss=1.18, accuracy=0.741, val_loss=1.94, val_accuracy=0.504, lr=0.1] 13%|█▎        | 12/93 [06:02<37:02, 27.44s/epoch, loss=1.17, accuracy=0.74, val_loss=3.64, val_accuracy=0.408, lr=0.1]  14%|█▍        | 13/93 [06:30<36:39, 27.49s/epoch, loss=1.17, accuracy=0.744, val_loss=1.94, val_accuracy=0.441, lr=0.1] 15%|█▌        | 14/93 [06:57<36:00, 27.34s/epoch, loss=1.17, accuracy=0.745, val_loss=2.51, val_accuracy=0.437, lr=0.0316] 16%|█▌        | 15/93 [07:24<35:36, 27.39s/epoch, loss=1.17, accuracy=0.745, val_loss=2.48, val_accuracy=0.365, lr=0.1]    17%|█▋        | 16/93 [07:51<34:49, 27.14s/epoch, loss=1.17, accuracy=0.747, val_loss=2.12, val_accuracy=0.495, lr=0.1] 18%|█▊        | 17/93 [08:17<33:58, 26.83s/epoch, loss=1.17, accuracy=0.747, val_loss=2, val_accuracy=0.512, lr=0.1]    19%|█▉        | 18/93 [08:43<33:23, 26.72s/epoch, loss=1.17, accuracy=0.747, val_loss=2.03, val_accuracy=0.468, lr=0.1] 20%|██        | 19/93 [09:10<32:49, 26.61s/epoch, loss=1.16, accuracy=0.747, val_loss=1.54, val_accuracy=0.639, lr=0.1] 22%|██▏       | 20/93 [09:36<32:18, 26.56s/epoch, loss=1.16, accuracy=0.75, val_loss=6.81, val_accuracy=0.23, lr=0.1]   23%|██▎       | 21/93 [10:03<32:07, 26.77s/epoch, loss=1.16, accuracy=0.749, val_loss=2.13, val_accuracy=0.462, lr=0.1] 24%|██▎       | 22/93 [10:31<31:51, 26.93s/epoch, loss=1.15, accuracy=0.752, val_loss=3.63, val_accuracy=0.334, lr=0.1] 25%|██▍       | 23/93 [10:58<31:31, 27.03s/epoch, loss=1.15, accuracy=0.749, val_loss=1.89, val_accuracy=0.54, lr=0.1]  26%|██▌       | 24/93 [11:24<30:55, 26.90s/epoch, loss=1.15, accuracy=0.751, val_loss=2.65, val_accuracy=0.406, lr=0.0316] 27%|██▋       | 25/93 [11:52<30:33, 26.96s/epoch, loss=1.15, accuracy=0.753, val_loss=2.39, val_accuracy=0.426, lr=0.1]    28%|██▊       | 26/93 [12:19<30:07, 26.97s/epoch, loss=1.15, accuracy=0.753, val_loss=2.08, val_accuracy=0.523, lr=0.1] 29%|██▉       | 27/93 [12:45<29:33, 26.87s/epoch, loss=1.15, accuracy=0.753, val_loss=2.07, val_accuracy=0.477, lr=0.1] 30%|███       | 28/93 [13:11<28:55, 26.70s/epoch, loss=1.14, accuracy=0.753, val_loss=4.07, val_accuracy=0.341, lr=0.1] 31%|███       | 29/93 [13:38<28:18, 26.54s/epoch, loss=1.15, accuracy=0.753, val_loss=1.56, val_accuracy=0.615, lr=0.0316] 32%|███▏      | 30/93 [14:04<27:46, 26.45s/epoch, loss=1.14, accuracy=0.753, val_loss=2.7, val_accuracy=0.447, lr=0.1]     33%|███▎      | 31/93 [14:31<27:30, 26.62s/epoch, loss=1.14, accuracy=0.757, val_loss=2.16, val_accuracy=0.379, lr=0.1] 34%|███▍      | 32/93 [14:58<27:05, 26.64s/epoch, loss=1.14, accuracy=0.756, val_loss=1.9, val_accuracy=0.501, lr=0.1]  35%|███▌      | 33/93 [15:25<26:47, 26.79s/epoch, loss=1.14, accuracy=0.755, val_loss=2.88, val_accuracy=0.363, lr=0.1] 37%|███▋      | 34/93 [15:52<26:25, 26.87s/epoch, loss=1.14, accuracy=0.754, val_loss=3.45, val_accuracy=0.278, lr=0.0316] 38%|███▊      | 35/93 [16:19<26:04, 26.97s/epoch, loss=1.14, accuracy=0.755, val_loss=2.71, val_accuracy=0.482, lr=0.1]    39%|███▊      | 36/93 [16:47<25:47, 27.15s/epoch, loss=1.14, accuracy=0.754, val_loss=2.4, val_accuracy=0.467, lr=0.1]  40%|███▉      | 37/93 [17:14<25:26, 27.26s/epoch, loss=1.14, accuracy=0.755, val_loss=2.37, val_accuracy=0.367, lr=0.1] 41%|████      | 38/93 [17:42<25:03, 27.33s/epoch, loss=1.14, accuracy=0.757, val_loss=1.65, val_accuracy=0.558, lr=0.1] 42%|████▏     | 39/93 [18:09<24:33, 27.29s/epoch, loss=1.13, accuracy=0.756, val_loss=2, val_accuracy=0.511, lr=0.0316] 43%|████▎     | 40/93 [18:36<24:08, 27.32s/epoch, loss=1.13, accuracy=0.757, val_loss=2.13, val_accuracy=0.479, lr=0.1] 44%|████▍     | 41/93 [19:04<23:43, 27.37s/epoch, loss=1.13, accuracy=0.755, val_loss=1.84, val_accuracy=0.507, lr=0.1] 45%|████▌     | 42/93 [19:31<23:15, 27.36s/epoch, loss=1.13, accuracy=0.758, val_loss=1.64, val_accuracy=0.597, lr=0.1] 46%|████▌     | 43/93 [19:58<22:49, 27.40s/epoch, loss=1.13, accuracy=0.757, val_loss=1.65, val_accuracy=0.586, lr=0.1] 47%|████▋     | 44/93 [20:26<22:24, 27.44s/epoch, loss=1.14, accuracy=0.754, val_loss=1.81, val_accuracy=0.566, lr=0.0316] 48%|████▊     | 45/93 [20:53<21:56, 27.43s/epoch, loss=1.13, accuracy=0.756, val_loss=1.62, val_accuracy=0.592, lr=0.1]    49%|████▉     | 46/93 [21:21<21:33, 27.53s/epoch, loss=1.14, accuracy=0.756, val_loss=2.63, val_accuracy=0.404, lr=0.1] 51%|█████     | 47/93 [21:48<21:01, 27.42s/epoch, loss=1.13, accuracy=0.755, val_loss=1.75, val_accuracy=0.562, lr=0.1] 52%|█████▏    | 48/93 [22:15<20:25, 27.23s/epoch, loss=1.12, accuracy=0.755, val_loss=2.36, val_accuracy=0.428, lr=0.1] 53%|█████▎    | 49/93 [22:43<20:01, 27.30s/epoch, loss=1.13, accuracy=0.756, val_loss=1.63, val_accuracy=0.595, lr=0.0316] 54%|█████▍    | 50/93 [23:10<19:39, 27.42s/epoch, loss=1.13, accuracy=0.758, val_loss=1.67, val_accuracy=0.583, lr=0.1]    55%|█████▍    | 51/93 [23:38<19:15, 27.51s/epoch, loss=1.13, accuracy=0.756, val_loss=1.92, val_accuracy=0.516, lr=0.1] 56%|█████▌    | 52/93 [24:06<18:50, 27.57s/epoch, loss=1.13, accuracy=0.756, val_loss=1.62, val_accuracy=0.606, lr=0.1] 57%|█████▋    | 53/93 [24:32<18:11, 27.29s/epoch, loss=1.12, accuracy=0.76, val_loss=1.54, val_accuracy=0.652, lr=0.1]  58%|█████▊    | 54/93 [25:00<17:49, 27.42s/epoch, loss=1.13, accuracy=0.758, val_loss=2.54, val_accuracy=0.467, lr=0.1] 59%|█████▉    | 55/93 [25:28<17:25, 27.51s/epoch, loss=1.13, accuracy=0.756, val_loss=3.28, val_accuracy=0.241, lr=0.1] 60%|██████    | 56/93 [25:55<16:53, 27.39s/epoch, loss=1.13, accuracy=0.758, val_loss=2.04, val_accuracy=0.47, lr=0.1]  61%|██████▏   | 57/93 [26:22<16:26, 27.42s/epoch, loss=1.13, accuracy=0.757, val_loss=1.85, val_accuracy=0.574, lr=0.1] 62%|██████▏   | 58/93 [26:50<15:59, 27.41s/epoch, loss=1.13, accuracy=0.757, val_loss=1.96, val_accuracy=0.484, lr=0.0316] 63%|██████▎   | 59/93 [27:17<15:30, 27.38s/epoch, loss=1.13, accuracy=0.758, val_loss=2.19, val_accuracy=0.448, lr=0.1]    65%|██████▍   | 60/93 [27:44<14:58, 27.23s/epoch, loss=1.13, accuracy=0.758, val_loss=1.72, val_accuracy=0.555, lr=0.1] 66%|██████▌   | 61/93 [28:11<14:32, 27.26s/epoch, loss=1.13, accuracy=0.759, val_loss=1.97, val_accuracy=0.461, lr=0.1] 67%|██████▋   | 62/93 [28:38<14:00, 27.12s/epoch, loss=1.13, accuracy=0.757, val_loss=3.23, val_accuracy=0.37, lr=0.1]  68%|██████▊   | 63/93 [29:05<13:36, 27.20s/epoch, loss=1.12, accuracy=0.76, val_loss=2.87, val_accuracy=0.315, lr=0.0316] 69%|██████▉   | 64/93 [29:32<13:05, 27.07s/epoch, loss=1.12, accuracy=0.758, val_loss=2.33, val_accuracy=0.497, lr=0.1]   70%|██████▉   | 65/93 [29:59<12:37, 27.07s/epoch, loss=1.13, accuracy=0.758, val_loss=2.36, val_accuracy=0.366, lr=0.1] 71%|███████   | 66/93 [30:27<12:14, 27.22s/epoch, loss=1.11, accuracy=0.76, val_loss=1.94, val_accuracy=0.502, lr=0.1]  72%|███████▏  | 67/93 [30:54<11:49, 27.27s/epoch, loss=1.12, accuracy=0.759, val_loss=1.52, val_accuracy=0.613, lr=0.1] 73%|███████▎  | 68/93 [31:22<11:24, 27.37s/epoch, loss=1.12, accuracy=0.76, val_loss=1.97, val_accuracy=0.535, lr=0.1]  74%|███████▍  | 69/93 [31:49<10:56, 27.33s/epoch, loss=1.12, accuracy=0.759, val_loss=3.3, val_accuracy=0.325, lr=0.1] 75%|███████▌  | 70/93 [32:15<10:20, 27.00s/epoch, loss=1.12, accuracy=0.758, val_loss=4.39, val_accuracy=0.315, lr=0.1] 76%|███████▋  | 71/93 [32:42<09:52, 26.92s/epoch, loss=1.12, accuracy=0.757, val_loss=1.52, val_accuracy=0.62, lr=0.1]  77%|███████▋  | 72/93 [33:09<09:22, 26.77s/epoch, loss=1.11, accuracy=0.758, val_loss=1.5, val_accuracy=0.624, lr=0.1] 78%|███████▊  | 73/93 [33:35<08:51, 26.60s/epoch, loss=1.11, accuracy=0.761, val_loss=1.85, val_accuracy=0.555, lr=0.1] 80%|███████▉  | 74/93 [34:02<08:27, 26.69s/epoch, loss=1.11, accuracy=0.76, val_loss=1.63, val_accuracy=0.572, lr=0.1]  81%|████████  | 75/93 [34:29<08:04, 26.92s/epoch, loss=1.11, accuracy=0.758, val_loss=2.08, val_accuracy=0.43, lr=0.1] 82%|████████▏ | 76/93 [34:56<07:35, 26.82s/epoch, loss=1.12, accuracy=0.758, val_loss=1.5, val_accuracy=0.625, lr=0.1] 83%|████████▎ | 77/93 [35:21<07:02, 26.43s/epoch, loss=1.12, accuracy=0.756, val_loss=1.54, val_accuracy=0.603, lr=0.1] 84%|████████▍ | 78/93 [35:47<06:34, 26.29s/epoch, loss=1.11, accuracy=0.761, val_loss=1.75, val_accuracy=0.541, lr=0.1] 85%|████████▍ | 79/93 [36:15<06:13, 26.69s/epoch, loss=1.11, accuracy=0.758, val_loss=1.65, val_accuracy=0.558, lr=0.1] 86%|████████▌ | 80/93 [36:42<05:49, 26.91s/epoch, loss=1.12, accuracy=0.759, val_loss=2.42, val_accuracy=0.428, lr=0.1] 87%|████████▋ | 81/93 [37:09<05:24, 27.03s/epoch, loss=1.11, accuracy=0.756, val_loss=3.38, val_accuracy=0.31, lr=0.0316] 88%|████████▊ | 82/93 [37:37<04:58, 27.15s/epoch, loss=0.901, accuracy=0.819, val_loss=0.911, val_accuracy=0.802, lr=0.01] 89%|████████▉ | 83/93 [38:04<04:30, 27.03s/epoch, loss=0.724, accuracy=0.851, val_loss=0.75, val_accuracy=0.83, lr=0.01]   90%|█████████ | 84/93 [38:31<04:04, 27.13s/epoch, loss=0.64, accuracy=0.861, val_loss=0.752, val_accuracy=0.815, lr=0.01] 91%|█████████▏| 85/93 [38:58<03:36, 27.03s/epoch, loss=0.601, accuracy=0.862, val_loss=0.953, val_accuracy=0.755, lr=0.01] 92%|█████████▏| 86/93 [39:25<03:09, 27.06s/epoch, loss=0.58, accuracy=0.863, val_loss=0.747, val_accuracy=0.802, lr=0.01]  94%|█████████▎| 87/93 [39:52<02:43, 27.19s/epoch, loss=0.566, accuracy=0.866, val_loss=0.705, val_accuracy=0.818, lr=0.01] 95%|█████████▍| 88/93 [40:19<02:14, 26.96s/epoch, loss=0.566, accuracy=0.864, val_loss=1.09, val_accuracy=0.706, lr=0.01]  96%|█████████▌| 89/93 [40:46<01:48, 27.02s/epoch, loss=0.561, accuracy=0.866, val_loss=0.852, val_accuracy=0.773, lr=0.01] 97%|█████████▋| 90/93 [41:13<01:21, 27.14s/epoch, loss=0.555, accuracy=0.868, val_loss=0.758, val_accuracy=0.801, lr=0.01] 98%|█████████▊| 91/93 [41:40<00:54, 27.11s/epoch, loss=0.552, accuracy=0.871, val_loss=0.826, val_accuracy=0.78, lr=0.01]  99%|█████████▉| 92/93 [42:07<00:26, 27.00s/epoch, loss=0.559, accuracy=0.868, val_loss=1.01, val_accuracy=0.738, lr=0.00316]100%|██████████| 93/93 [42:35<00:00, 27.10s/epoch, loss=0.553, accuracy=0.872, val_loss=0.768, val_accuracy=0.796, lr=0.01]  100%|██████████| 93/93 [42:35<00:00, 27.47s/epoch, loss=0.553, accuracy=0.872, val_loss=0.768, val_accuracy=0.796, lr=0.01]
Using real-time data augmentation.
Test score: 0.768202006816864
Test accuracy: 0.7955999970436096


* * * Run SGD for ID = 16_5. * * *


2024-03-05 08:26:34.222381: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 08:26:36.762571: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 08:26:36.763754: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-05 08:26:36.804574: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:18:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-05 08:26:36.804617: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 08:26:36.808161: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 08:26:36.808231: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 08:26:36.810649: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 08:26:36.811345: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 08:26:36.814220: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 08:26:36.815940: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 08:26:36.821513: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 08:26:36.822193: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 08:26:36.822287: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 08:26:37.989156: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-05 08:26:37.990431: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 08:26:37.991486: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:18:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-05 08:26:37.991521: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 08:26:37.991559: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 08:26:37.991573: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 08:26:37.991584: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 08:26:37.991605: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 08:26:37.991619: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 08:26:37.991633: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 08:26:37.991647: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 08:26:37.992184: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 08:26:37.992227: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 08:26:38.602857: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-05 08:26:38.602913: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-05 08:26:38.602923: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-05 08:26:38.603963: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:18:00.0, compute capability: 6.1)
{'id': '16_05', 'seed': 5, 'out_folder': 'results/epoch_budget', 'batch_size': 128, 'epochs': 93, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'bootstrapping': False, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/93 [00:00<?, ?epoch/s]2024-03-05 08:26:39.416869: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-05 08:26:39.428985: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2100000000 Hz
2024-03-05 08:26:41.258306: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 08:26:41.544586: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 08:26:42.317688: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-05 08:26:42.382294: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/93 [01:08<1:44:51, 68.38s/epoch, loss=2.95, accuracy=0.335, val_loss=2.95, val_accuracy=0.162, lr=0.1]  2%|▏         | 2/93 [01:35<1:06:34, 43.90s/epoch, loss=1.5, accuracy=0.572, val_loss=4.41, val_accuracy=0.279, lr=0.1]   3%|▎         | 3/93 [02:02<54:20, 36.23s/epoch, loss=1.31, accuracy=0.662, val_loss=1.65, val_accuracy=0.547, lr=0.1]   4%|▍         | 4/93 [02:29<48:40, 32.82s/epoch, loss=1.26, accuracy=0.69, val_loss=2.28, val_accuracy=0.4, lr=0.1]     5%|▌         | 5/93 [02:57<45:17, 30.88s/epoch, loss=1.23, accuracy=0.704, val_loss=1.92, val_accuracy=0.478, lr=0.1]  6%|▋         | 6/93 [03:25<43:15, 29.83s/epoch, loss=1.22, accuracy=0.711, val_loss=2.1, val_accuracy=0.557, lr=0.1]   8%|▊         | 7/93 [03:52<41:43, 29.11s/epoch, loss=1.21, accuracy=0.719, val_loss=1.79, val_accuracy=0.564, lr=0.1]  9%|▊         | 8/93 [04:20<40:32, 28.62s/epoch, loss=1.2, accuracy=0.725, val_loss=1.77, val_accuracy=0.562, lr=0.0316] 10%|▉         | 9/93 [04:47<39:31, 28.24s/epoch, loss=1.2, accuracy=0.727, val_loss=1.94, val_accuracy=0.48, lr=0.1]     11%|█         | 10/93 [05:14<38:40, 27.96s/epoch, loss=1.18, accuracy=0.734, val_loss=1.97, val_accuracy=0.496, lr=0.1] 12%|█▏        | 11/93 [05:42<37:55, 27.75s/epoch, loss=1.19, accuracy=0.734, val_loss=2.62, val_accuracy=0.402, lr=0.1] 13%|█▎        | 12/93 [06:09<37:25, 27.72s/epoch, loss=1.18, accuracy=0.737, val_loss=1.99, val_accuracy=0.484, lr=0.1] 14%|█▍        | 13/93 [06:37<36:51, 27.64s/epoch, loss=1.18, accuracy=0.737, val_loss=2.07, val_accuracy=0.454, lr=0.0316] 15%|█▌        | 14/93 [07:05<36:24, 27.65s/epoch, loss=1.17, accuracy=0.74, val_loss=1.86, val_accuracy=0.532, lr=0.1]     16%|█▌        | 15/93 [07:32<35:49, 27.55s/epoch, loss=1.17, accuracy=0.74, val_loss=2.63, val_accuracy=0.414, lr=0.1] 17%|█▋        | 16/93 [07:59<35:17, 27.50s/epoch, loss=1.17, accuracy=0.743, val_loss=1.7, val_accuracy=0.551, lr=0.1] 18%|█▊        | 17/93 [08:27<34:51, 27.52s/epoch, loss=1.17, accuracy=0.742, val_loss=1.82, val_accuracy=0.538, lr=0.1] 19%|█▉        | 18/93 [08:55<34:30, 27.60s/epoch, loss=1.16, accuracy=0.745, val_loss=1.67, val_accuracy=0.613, lr=0.0316] 20%|██        | 19/93 [09:21<33:44, 27.35s/epoch, loss=1.16, accuracy=0.744, val_loss=1.57, val_accuracy=0.612, lr=0.1]    22%|██▏       | 20/93 [09:49<33:18, 27.38s/epoch, loss=1.16, accuracy=0.746, val_loss=1.51, val_accuracy=0.626, lr=0.1] 23%|██▎       | 21/93 [10:17<32:58, 27.49s/epoch, loss=1.16, accuracy=0.747, val_loss=3.29, val_accuracy=0.358, lr=0.1] 24%|██▎       | 22/93 [10:44<32:30, 27.47s/epoch, loss=1.16, accuracy=0.747, val_loss=2.8, val_accuracy=0.411, lr=0.1]  25%|██▍       | 23/93 [11:11<32:01, 27.45s/epoch, loss=1.15, accuracy=0.749, val_loss=2.93, val_accuracy=0.349, lr=0.1] 26%|██▌       | 24/93 [11:38<31:24, 27.31s/epoch, loss=1.15, accuracy=0.748, val_loss=3.28, val_accuracy=0.299, lr=0.1] 27%|██▋       | 25/93 [12:06<30:56, 27.29s/epoch, loss=1.15, accuracy=0.75, val_loss=2, val_accuracy=0.518, lr=0.0316]  28%|██▊       | 26/93 [12:33<30:33, 27.36s/epoch, loss=1.15, accuracy=0.751, val_loss=1.54, val_accuracy=0.629, lr=0.1] 29%|██▉       | 27/93 [13:01<30:11, 27.44s/epoch, loss=1.15, accuracy=0.749, val_loss=1.76, val_accuracy=0.561, lr=0.1] 30%|███       | 28/93 [13:28<29:42, 27.43s/epoch, loss=1.15, accuracy=0.749, val_loss=2.58, val_accuracy=0.443, lr=0.1] 31%|███       | 29/93 [13:56<29:15, 27.43s/epoch, loss=1.15, accuracy=0.748, val_loss=1.9, val_accuracy=0.521, lr=0.1]  32%|███▏      | 30/93 [14:23<28:42, 27.35s/epoch, loss=1.14, accuracy=0.75, val_loss=2.21, val_accuracy=0.423, lr=0.0316] 33%|███▎      | 31/93 [14:50<28:11, 27.27s/epoch, loss=1.14, accuracy=0.753, val_loss=2.59, val_accuracy=0.418, lr=0.1]   34%|███▍      | 32/93 [15:17<27:47, 27.33s/epoch, loss=1.14, accuracy=0.754, val_loss=1.72, val_accuracy=0.554, lr=0.1] 35%|███▌      | 33/93 [15:45<27:21, 27.36s/epoch, loss=1.14, accuracy=0.752, val_loss=2.16, val_accuracy=0.461, lr=0.1] 37%|███▋      | 34/93 [16:12<26:46, 27.23s/epoch, loss=1.13, accuracy=0.753, val_loss=2.6, val_accuracy=0.419, lr=0.1]  38%|███▊      | 35/93 [16:39<26:12, 27.11s/epoch, loss=1.13, accuracy=0.755, val_loss=1.53, val_accuracy=0.613, lr=0.0316] 39%|███▊      | 36/93 [17:05<25:28, 26.82s/epoch, loss=1.14, accuracy=0.754, val_loss=1.61, val_accuracy=0.617, lr=0.1]    40%|███▉      | 37/93 [17:31<24:53, 26.67s/epoch, loss=1.13, accuracy=0.755, val_loss=1.85, val_accuracy=0.573, lr=0.1] 41%|████      | 38/93 [17:57<24:20, 26.55s/epoch, loss=1.13, accuracy=0.756, val_loss=2.52, val_accuracy=0.445, lr=0.1] 42%|████▏     | 39/93 [18:24<23:54, 26.56s/epoch, loss=1.14, accuracy=0.754, val_loss=1.98, val_accuracy=0.536, lr=0.1] 43%|████▎     | 40/93 [18:51<23:37, 26.75s/epoch, loss=1.12, accuracy=0.756, val_loss=1.95, val_accuracy=0.503, lr=0.0316] 44%|████▍     | 41/93 [19:19<23:24, 27.01s/epoch, loss=1.13, accuracy=0.756, val_loss=2.1, val_accuracy=0.536, lr=0.1]     45%|████▌     | 42/93 [19:46<23:04, 27.14s/epoch, loss=1.13, accuracy=0.754, val_loss=2.2, val_accuracy=0.448, lr=0.1] 46%|████▌     | 43/93 [20:13<22:40, 27.22s/epoch, loss=1.13, accuracy=0.757, val_loss=1.79, val_accuracy=0.57, lr=0.1] 47%|████▋     | 44/93 [20:41<22:17, 27.30s/epoch, loss=1.12, accuracy=0.755, val_loss=2.53, val_accuracy=0.347, lr=0.1] 48%|████▊     | 45/93 [21:09<21:53, 27.37s/epoch, loss=1.12, accuracy=0.756, val_loss=1.85, val_accuracy=0.572, lr=0.0316] 49%|████▉     | 46/93 [21:36<21:25, 27.36s/epoch, loss=1.12, accuracy=0.754, val_loss=1.69, val_accuracy=0.604, lr=0.1]    51%|█████     | 47/93 [22:04<21:04, 27.48s/epoch, loss=1.12, accuracy=0.757, val_loss=1.65, val_accuracy=0.595, lr=0.1] 52%|█████▏    | 48/93 [22:31<20:39, 27.55s/epoch, loss=1.12, accuracy=0.759, val_loss=2.03, val_accuracy=0.424, lr=0.1] 53%|█████▎    | 49/93 [22:58<19:57, 27.23s/epoch, loss=1.13, accuracy=0.756, val_loss=2.75, val_accuracy=0.419, lr=0.1] 54%|█████▍    | 50/93 [23:24<19:19, 26.97s/epoch, loss=1.12, accuracy=0.757, val_loss=1.4, val_accuracy=0.648, lr=0.1]  55%|█████▍    | 51/93 [23:51<18:54, 27.00s/epoch, loss=1.12, accuracy=0.756, val_loss=1.68, val_accuracy=0.581, lr=0.1] 56%|█████▌    | 52/93 [24:19<18:32, 27.14s/epoch, loss=1.11, accuracy=0.76, val_loss=2.89, val_accuracy=0.396, lr=0.1]  57%|█████▋    | 53/93 [24:46<18:12, 27.31s/epoch, loss=1.11, accuracy=0.759, val_loss=2.24, val_accuracy=0.491, lr=0.1] 58%|█████▊    | 54/93 [25:14<17:49, 27.43s/epoch, loss=1.12, accuracy=0.757, val_loss=3.22, val_accuracy=0.365, lr=0.1] 59%|█████▉    | 55/93 [25:42<17:22, 27.43s/epoch, loss=1.12, accuracy=0.758, val_loss=1.88, val_accuracy=0.548, lr=0.0316] 60%|██████    | 56/93 [26:09<16:57, 27.49s/epoch, loss=1.11, accuracy=0.757, val_loss=2.07, val_accuracy=0.521, lr=0.1]    61%|██████▏   | 57/93 [26:37<16:28, 27.46s/epoch, loss=1.11, accuracy=0.76, val_loss=2.12, val_accuracy=0.462, lr=0.1]  62%|██████▏   | 58/93 [27:04<15:57, 27.35s/epoch, loss=1.11, accuracy=0.757, val_loss=2.35, val_accuracy=0.362, lr=0.1] 63%|██████▎   | 59/93 [27:31<15:27, 27.28s/epoch, loss=1.11, accuracy=0.757, val_loss=1.42, val_accuracy=0.652, lr=0.1] 65%|██████▍   | 60/93 [27:58<14:57, 27.19s/epoch, loss=1.12, accuracy=0.754, val_loss=2.09, val_accuracy=0.442, lr=0.0316] 66%|██████▌   | 61/93 [28:25<14:33, 27.29s/epoch, loss=1.12, accuracy=0.757, val_loss=2.52, val_accuracy=0.471, lr=0.1]    67%|██████▋   | 62/93 [28:53<14:09, 27.39s/epoch, loss=1.11, accuracy=0.758, val_loss=1.78, val_accuracy=0.544, lr=0.1] 68%|██████▊   | 63/93 [29:20<13:40, 27.34s/epoch, loss=1.11, accuracy=0.756, val_loss=2.03, val_accuracy=0.522, lr=0.1] 69%|██████▉   | 64/93 [29:47<13:12, 27.31s/epoch, loss=1.11, accuracy=0.759, val_loss=3.55, val_accuracy=0.337, lr=0.1] 70%|██████▉   | 65/93 [30:15<12:44, 27.31s/epoch, loss=1.11, accuracy=0.756, val_loss=1.84, val_accuracy=0.504, lr=0.0316] 71%|███████   | 66/93 [30:42<12:19, 27.37s/epoch, loss=1.11, accuracy=0.758, val_loss=2.39, val_accuracy=0.419, lr=0.1]    72%|███████▏  | 67/93 [31:10<11:53, 27.43s/epoch, loss=1.12, accuracy=0.756, val_loss=3.03, val_accuracy=0.338, lr=0.1] 73%|███████▎  | 68/93 [31:37<11:21, 27.28s/epoch, loss=1.11, accuracy=0.759, val_loss=2.12, val_accuracy=0.486, lr=0.1] 74%|███████▍  | 69/93 [32:04<10:51, 27.14s/epoch, loss=1.11, accuracy=0.757, val_loss=1.93, val_accuracy=0.467, lr=0.1] 75%|███████▌  | 70/93 [32:31<10:25, 27.17s/epoch, loss=1.11, accuracy=0.757, val_loss=3.42, val_accuracy=0.386, lr=0.0316] 76%|███████▋  | 71/93 [32:58<10:00, 27.28s/epoch, loss=1.11, accuracy=0.755, val_loss=3.46, val_accuracy=0.343, lr=0.1]    77%|███████▋  | 72/93 [33:26<09:33, 27.32s/epoch, loss=1.1, accuracy=0.759, val_loss=1.86, val_accuracy=0.521, lr=0.1]  78%|███████▊  | 73/93 [33:54<09:09, 27.48s/epoch, loss=1.11, accuracy=0.759, val_loss=1.86, val_accuracy=0.578, lr=0.1] 80%|███████▉  | 74/93 [34:21<08:44, 27.58s/epoch, loss=1.11, accuracy=0.756, val_loss=2.03, val_accuracy=0.484, lr=0.1] 81%|████████  | 75/93 [34:49<08:16, 27.59s/epoch, loss=1.11, accuracy=0.759, val_loss=2.94, val_accuracy=0.278, lr=0.0316] 82%|████████▏ | 76/93 [35:17<07:50, 27.67s/epoch, loss=1.1, accuracy=0.76, val_loss=2.17, val_accuracy=0.49, lr=0.1]       83%|████████▎ | 77/93 [35:44<07:19, 27.47s/epoch, loss=1.11, accuracy=0.758, val_loss=2.54, val_accuracy=0.416, lr=0.1] 84%|████████▍ | 78/93 [36:12<06:53, 27.55s/epoch, loss=1.1, accuracy=0.761, val_loss=2, val_accuracy=0.488, lr=0.1]     85%|████████▍ | 79/93 [36:39<06:24, 27.43s/epoch, loss=1.1, accuracy=0.761, val_loss=2.22, val_accuracy=0.485, lr=0.1] 86%|████████▌ | 80/93 [37:06<05:57, 27.50s/epoch, loss=1.1, accuracy=0.76, val_loss=2.54, val_accuracy=0.429, lr=0.0316] 87%|████████▋ | 81/93 [37:34<05:29, 27.47s/epoch, loss=1.1, accuracy=0.759, val_loss=2.2, val_accuracy=0.464, lr=0.1]    88%|████████▊ | 82/93 [38:01<05:01, 27.43s/epoch, loss=0.891, accuracy=0.819, val_loss=0.937, val_accuracy=0.787, lr=0.01] 89%|████████▉ | 83/93 [38:27<04:30, 27.08s/epoch, loss=0.717, accuracy=0.85, val_loss=0.809, val_accuracy=0.8, lr=0.01]    90%|█████████ | 84/93 [38:54<04:01, 26.85s/epoch, loss=0.641, accuracy=0.857, val_loss=0.746, val_accuracy=0.819, lr=0.01] 91%|█████████▏| 85/93 [39:20<03:32, 26.62s/epoch, loss=0.601, accuracy=0.86, val_loss=0.732, val_accuracy=0.81, lr=0.01]   92%|█████████▏| 86/93 [39:47<03:07, 26.83s/epoch, loss=0.579, accuracy=0.863, val_loss=0.773, val_accuracy=0.794, lr=0.01] 94%|█████████▎| 87/93 [40:14<02:41, 26.88s/epoch, loss=0.57, accuracy=0.862, val_loss=0.93, val_accuracy=0.758, lr=0.01]   95%|█████████▍| 88/93 [40:42<02:15, 27.14s/epoch, loss=0.563, accuracy=0.865, val_loss=0.717, val_accuracy=0.815, lr=0.01] 96%|█████████▌| 89/93 [41:09<01:48, 27.16s/epoch, loss=0.558, accuracy=0.865, val_loss=0.866, val_accuracy=0.771, lr=0.01] 97%|█████████▋| 90/93 [41:36<01:21, 27.19s/epoch, loss=0.559, accuracy=0.867, val_loss=0.762, val_accuracy=0.805, lr=0.01] 98%|█████████▊| 91/93 [42:03<00:54, 27.14s/epoch, loss=0.558, accuracy=0.866, val_loss=0.963, val_accuracy=0.736, lr=0.01] 99%|█████████▉| 92/93 [42:28<00:26, 26.52s/epoch, loss=0.554, accuracy=0.871, val_loss=0.816, val_accuracy=0.794, lr=0.01]100%|██████████| 93/93 [42:55<00:00, 26.50s/epoch, loss=0.557, accuracy=0.87, val_loss=0.858, val_accuracy=0.768, lr=0.00316]100%|██████████| 93/93 [42:55<00:00, 27.69s/epoch, loss=0.557, accuracy=0.87, val_loss=0.858, val_accuracy=0.768, lr=0.00316]
Using real-time data augmentation.
Test score: 0.8582624197006226
Test accuracy: 0.7680000066757202


* * * Run SGD for ID = 16_6. * * *


2024-03-05 09:09:38.648993: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 09:09:41.141027: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 09:09:41.142326: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-05 09:09:41.183730: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:18:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-05 09:09:41.183785: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 09:09:41.187727: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 09:09:41.187802: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 09:09:41.190644: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 09:09:41.191684: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 09:09:41.194764: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 09:09:41.196602: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 09:09:41.202788: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 09:09:41.203513: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 09:09:41.203609: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 09:09:42.449866: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-05 09:09:42.450538: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 09:09:42.451567: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:18:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-05 09:09:42.451601: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 09:09:42.451637: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 09:09:42.451651: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 09:09:42.451662: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 09:09:42.451674: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 09:09:42.451688: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 09:09:42.451701: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 09:09:42.451715: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 09:09:42.452241: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 09:09:42.452281: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 09:09:43.101082: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-05 09:09:43.101132: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-05 09:09:43.101143: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-05 09:09:43.102268: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:18:00.0, compute capability: 6.1)
{'id': '16_06', 'seed': 6, 'out_folder': 'results/epoch_budget', 'batch_size': 128, 'epochs': 93, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'bootstrapping': False, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/93 [00:00<?, ?epoch/s]2024-03-05 09:09:43.971629: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-05 09:09:43.972358: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2100000000 Hz
2024-03-05 09:09:45.978973: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 09:09:46.282003: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 09:09:47.112034: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-05 09:09:47.157194: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/93 [01:01<1:33:51, 61.22s/epoch, loss=3.1, accuracy=0.307, val_loss=3.19, val_accuracy=0.189, lr=0.1]  2%|▏         | 2/93 [01:28<1:02:51, 41.44s/epoch, loss=1.5, accuracy=0.562, val_loss=2.45, val_accuracy=0.387, lr=0.1]  3%|▎         | 3/93 [01:56<52:35, 35.06s/epoch, loss=1.29, accuracy=0.663, val_loss=1.84, val_accuracy=0.478, lr=0.1]   4%|▍         | 4/93 [02:22<47:02, 31.71s/epoch, loss=1.25, accuracy=0.692, val_loss=1.72, val_accuracy=0.544, lr=0.1]  5%|▌         | 5/93 [02:49<43:37, 29.75s/epoch, loss=1.23, accuracy=0.707, val_loss=2.08, val_accuracy=0.395, lr=0.1]  6%|▋         | 6/93 [03:15<41:28, 28.61s/epoch, loss=1.21, accuracy=0.716, val_loss=2.12, val_accuracy=0.402, lr=0.1]  8%|▊         | 7/93 [03:42<40:13, 28.07s/epoch, loss=1.2, accuracy=0.724, val_loss=1.57, val_accuracy=0.589, lr=0.1]   9%|▊         | 8/93 [04:09<39:19, 27.75s/epoch, loss=1.19, accuracy=0.73, val_loss=3.06, val_accuracy=0.383, lr=0.1] 10%|▉         | 9/93 [04:36<38:37, 27.59s/epoch, loss=1.19, accuracy=0.733, val_loss=1.72, val_accuracy=0.545, lr=0.1] 11%|█         | 10/93 [05:04<38:04, 27.52s/epoch, loss=1.18, accuracy=0.733, val_loss=2.42, val_accuracy=0.402, lr=0.1] 12%|█▏        | 11/93 [05:31<37:35, 27.51s/epoch, loss=1.18, accuracy=0.736, val_loss=1.63, val_accuracy=0.571, lr=0.1] 13%|█▎        | 12/93 [05:59<37:14, 27.58s/epoch, loss=1.18, accuracy=0.736, val_loss=3.59, val_accuracy=0.252, lr=0.0316] 14%|█▍        | 13/93 [06:26<36:41, 27.52s/epoch, loss=1.17, accuracy=0.738, val_loss=1.7, val_accuracy=0.531, lr=0.1]     15%|█▌        | 14/93 [06:53<36:01, 27.37s/epoch, loss=1.17, accuracy=0.738, val_loss=2.17, val_accuracy=0.429, lr=0.1] 16%|█▌        | 15/93 [07:21<35:35, 27.38s/epoch, loss=1.17, accuracy=0.737, val_loss=1.89, val_accuracy=0.565, lr=0.1] 17%|█▋        | 16/93 [07:48<35:08, 27.38s/epoch, loss=1.16, accuracy=0.739, val_loss=2.1, val_accuracy=0.465, lr=0.1]  18%|█▊        | 17/93 [08:15<34:41, 27.39s/epoch, loss=1.17, accuracy=0.742, val_loss=1.52, val_accuracy=0.631, lr=0.1] 19%|█▉        | 18/93 [08:43<34:10, 27.34s/epoch, loss=1.16, accuracy=0.744, val_loss=2.16, val_accuracy=0.449, lr=0.1] 20%|██        | 19/93 [09:09<33:18, 27.01s/epoch, loss=1.16, accuracy=0.744, val_loss=1.84, val_accuracy=0.562, lr=0.1] 22%|██▏       | 20/93 [09:36<32:58, 27.10s/epoch, loss=1.16, accuracy=0.743, val_loss=2.36, val_accuracy=0.458, lr=0.1] 23%|██▎       | 21/93 [10:03<32:33, 27.13s/epoch, loss=1.15, accuracy=0.746, val_loss=2.21, val_accuracy=0.432, lr=0.1] 24%|██▎       | 22/93 [10:30<32:03, 27.09s/epoch, loss=1.15, accuracy=0.745, val_loss=3.42, val_accuracy=0.388, lr=0.0316] 25%|██▍       | 23/93 [10:57<31:34, 27.07s/epoch, loss=1.14, accuracy=0.748, val_loss=2.22, val_accuracy=0.438, lr=0.1]    26%|██▌       | 24/93 [11:25<31:18, 27.22s/epoch, loss=1.14, accuracy=0.75, val_loss=3.17, val_accuracy=0.227, lr=0.1]  27%|██▋       | 25/93 [11:53<30:56, 27.29s/epoch, loss=1.14, accuracy=0.749, val_loss=2.33, val_accuracy=0.443, lr=0.1] 28%|██▊       | 26/93 [12:20<30:26, 27.26s/epoch, loss=1.14, accuracy=0.75, val_loss=1.3, val_accuracy=0.69, lr=0.1]    29%|██▉       | 27/93 [12:47<29:53, 27.17s/epoch, loss=1.14, accuracy=0.749, val_loss=2.2, val_accuracy=0.417, lr=0.1] 30%|███       | 28/93 [13:14<29:37, 27.34s/epoch, loss=1.13, accuracy=0.747, val_loss=1.82, val_accuracy=0.53, lr=0.1] 31%|███       | 29/93 [13:42<29:13, 27.39s/epoch, loss=1.13, accuracy=0.749, val_loss=3.67, val_accuracy=0.377, lr=0.1] 32%|███▏      | 30/93 [14:09<28:46, 27.40s/epoch, loss=1.13, accuracy=0.751, val_loss=4.23, val_accuracy=0.302, lr=0.1] 33%|███▎      | 31/93 [14:37<28:23, 27.48s/epoch, loss=1.13, accuracy=0.75, val_loss=2.81, val_accuracy=0.402, lr=0.0316] 34%|███▍      | 32/93 [15:05<27:57, 27.50s/epoch, loss=1.13, accuracy=0.75, val_loss=1.74, val_accuracy=0.567, lr=0.1]    35%|███▌      | 33/93 [15:32<27:29, 27.50s/epoch, loss=1.13, accuracy=0.757, val_loss=1.55, val_accuracy=0.616, lr=0.1] 37%|███▋      | 34/93 [16:00<27:03, 27.51s/epoch, loss=1.13, accuracy=0.751, val_loss=2.78, val_accuracy=0.358, lr=0.1] 38%|███▊      | 35/93 [16:28<26:54, 27.83s/epoch, loss=1.12, accuracy=0.756, val_loss=2.08, val_accuracy=0.423, lr=0.1] 39%|███▊      | 36/93 [16:56<26:21, 27.75s/epoch, loss=1.12, accuracy=0.754, val_loss=2.33, val_accuracy=0.461, lr=0.0316] 40%|███▉      | 37/93 [17:24<25:56, 27.79s/epoch, loss=1.12, accuracy=0.755, val_loss=2.15, val_accuracy=0.423, lr=0.1]    41%|████      | 38/93 [17:51<25:25, 27.74s/epoch, loss=1.12, accuracy=0.757, val_loss=2.29, val_accuracy=0.393, lr=0.1] 42%|████▏     | 39/93 [18:18<24:50, 27.60s/epoch, loss=1.11, accuracy=0.757, val_loss=2.23, val_accuracy=0.44, lr=0.1]  43%|████▎     | 40/93 [18:47<24:32, 27.78s/epoch, loss=1.12, accuracy=0.757, val_loss=1.94, val_accuracy=0.456, lr=0.1] 44%|████▍     | 41/93 [19:14<24:04, 27.78s/epoch, loss=1.12, accuracy=0.756, val_loss=1.65, val_accuracy=0.58, lr=0.0316] 45%|████▌     | 42/93 [19:42<23:32, 27.69s/epoch, loss=1.12, accuracy=0.757, val_loss=2.06, val_accuracy=0.468, lr=0.1]   46%|████▌     | 43/93 [20:09<23:02, 27.64s/epoch, loss=1.12, accuracy=0.756, val_loss=1.85, val_accuracy=0.543, lr=0.1] 47%|████▋     | 44/93 [20:37<22:35, 27.66s/epoch, loss=1.11, accuracy=0.757, val_loss=2.55, val_accuracy=0.365, lr=0.1] 48%|████▊     | 45/93 [21:05<22:14, 27.81s/epoch, loss=1.11, accuracy=0.756, val_loss=1.99, val_accuracy=0.52, lr=0.1]  49%|████▉     | 46/93 [21:33<21:48, 27.84s/epoch, loss=1.11, accuracy=0.756, val_loss=3.24, val_accuracy=0.267, lr=0.0316] 51%|█████     | 47/93 [22:01<21:25, 27.95s/epoch, loss=1.11, accuracy=0.759, val_loss=2.04, val_accuracy=0.523, lr=0.1]    52%|█████▏    | 48/93 [22:29<20:54, 27.89s/epoch, loss=1.11, accuracy=0.76, val_loss=1.57, val_accuracy=0.588, lr=0.1]  53%|█████▎    | 49/93 [22:57<20:20, 27.75s/epoch, loss=1.11, accuracy=0.757, val_loss=2.85, val_accuracy=0.334, lr=0.1] 54%|█████▍    | 50/93 [23:24<19:51, 27.71s/epoch, loss=1.1, accuracy=0.759, val_loss=1.78, val_accuracy=0.552, lr=0.1]  55%|█████▍    | 51/93 [23:52<19:24, 27.74s/epoch, loss=1.1, accuracy=0.76, val_loss=1.89, val_accuracy=0.482, lr=0.0316] 56%|█████▌    | 52/93 [24:20<18:57, 27.74s/epoch, loss=1.11, accuracy=0.758, val_loss=1.65, val_accuracy=0.553, lr=0.1]  57%|█████▋    | 53/93 [24:48<18:33, 27.85s/epoch, loss=1.1, accuracy=0.757, val_loss=2.74, val_accuracy=0.398, lr=0.1]  58%|█████▊    | 54/93 [25:16<18:04, 27.82s/epoch, loss=1.1, accuracy=0.759, val_loss=2.4, val_accuracy=0.401, lr=0.1]  59%|█████▉    | 55/93 [25:43<17:35, 27.78s/epoch, loss=1.1, accuracy=0.758, val_loss=2.12, val_accuracy=0.493, lr=0.1] 60%|██████    | 56/93 [26:11<17:10, 27.85s/epoch, loss=1.11, accuracy=0.76, val_loss=2.85, val_accuracy=0.266, lr=0.0316] 61%|██████▏   | 57/93 [26:39<16:38, 27.74s/epoch, loss=1.1, accuracy=0.757, val_loss=4.74, val_accuracy=0.258, lr=0.1]    62%|██████▏   | 58/93 [27:07<16:10, 27.73s/epoch, loss=1.1, accuracy=0.759, val_loss=4.6, val_accuracy=0.144, lr=0.1]  63%|██████▎   | 59/93 [27:34<15:44, 27.78s/epoch, loss=1.1, accuracy=0.76, val_loss=3.06, val_accuracy=0.259, lr=0.1] 65%|██████▍   | 60/93 [28:03<15:22, 27.95s/epoch, loss=1.11, accuracy=0.758, val_loss=2.34, val_accuracy=0.436, lr=0.1] 66%|██████▌   | 61/93 [28:31<14:53, 27.91s/epoch, loss=1.1, accuracy=0.757, val_loss=4.25, val_accuracy=0.243, lr=0.0316] 67%|██████▋   | 62/93 [28:58<14:22, 27.82s/epoch, loss=1.1, accuracy=0.759, val_loss=2.4, val_accuracy=0.368, lr=0.1]     68%|██████▊   | 63/93 [29:26<13:53, 27.77s/epoch, loss=1.1, accuracy=0.759, val_loss=2.1, val_accuracy=0.46, lr=0.1]  69%|██████▉   | 64/93 [29:54<13:25, 27.77s/epoch, loss=1.1, accuracy=0.757, val_loss=2.14, val_accuracy=0.482, lr=0.1] 70%|██████▉   | 65/93 [30:20<12:49, 27.48s/epoch, loss=1.1, accuracy=0.76, val_loss=2.09, val_accuracy=0.469, lr=0.1]  71%|███████   | 66/93 [30:48<12:21, 27.48s/epoch, loss=1.1, accuracy=0.757, val_loss=1.86, val_accuracy=0.467, lr=0.0316] 72%|███████▏  | 67/93 [31:15<11:54, 27.47s/epoch, loss=1.09, accuracy=0.761, val_loss=2.06, val_accuracy=0.459, lr=0.1]   73%|███████▎  | 68/93 [31:43<11:27, 27.50s/epoch, loss=1.1, accuracy=0.758, val_loss=3.71, val_accuracy=0.331, lr=0.1]  74%|███████▍  | 69/93 [32:10<10:58, 27.45s/epoch, loss=1.1, accuracy=0.756, val_loss=8.46, val_accuracy=0.105, lr=0.1] 75%|███████▌  | 70/93 [32:38<10:30, 27.42s/epoch, loss=1.1, accuracy=0.76, val_loss=5.41, val_accuracy=0.234, lr=0.1]  76%|███████▋  | 71/93 [33:05<10:02, 27.37s/epoch, loss=1.1, accuracy=0.758, val_loss=2.45, val_accuracy=0.37, lr=0.0316] 77%|███████▋  | 72/93 [33:33<09:37, 27.49s/epoch, loss=1.1, accuracy=0.759, val_loss=2.62, val_accuracy=0.433, lr=0.1]   78%|███████▊  | 73/93 [34:00<09:09, 27.48s/epoch, loss=1.1, accuracy=0.757, val_loss=4.48, val_accuracy=0.223, lr=0.1] 80%|███████▉  | 74/93 [34:27<08:37, 27.25s/epoch, loss=1.1, accuracy=0.757, val_loss=1.67, val_accuracy=0.541, lr=0.1] 81%|████████  | 75/93 [34:54<08:11, 27.33s/epoch, loss=1.1, accuracy=0.76, val_loss=2.4, val_accuracy=0.415, lr=0.1]   82%|████████▏ | 76/93 [35:22<07:46, 27.42s/epoch, loss=1.09, accuracy=0.76, val_loss=3.08, val_accuracy=0.321, lr=0.0316] 83%|████████▎ | 77/93 [35:48<07:12, 27.02s/epoch, loss=1.1, accuracy=0.76, val_loss=1.76, val_accuracy=0.52, lr=0.1]      84%|████████▍ | 78/93 [36:15<06:46, 27.08s/epoch, loss=1.1, accuracy=0.76, val_loss=2.13, val_accuracy=0.453, lr=0.1] 85%|████████▍ | 79/93 [36:43<06:21, 27.24s/epoch, loss=1.1, accuracy=0.758, val_loss=4.82, val_accuracy=0.27, lr=0.1] 86%|████████▌ | 80/93 [37:10<05:54, 27.24s/epoch, loss=1.09, accuracy=0.761, val_loss=2.32, val_accuracy=0.41, lr=0.1] 87%|████████▋ | 81/93 [37:38<05:28, 27.36s/epoch, loss=1.11, accuracy=0.757, val_loss=2.49, val_accuracy=0.413, lr=0.0316] 88%|████████▊ | 82/93 [38:05<05:00, 27.30s/epoch, loss=0.889, accuracy=0.819, val_loss=0.922, val_accuracy=0.792, lr=0.01] 89%|████████▉ | 83/93 [38:32<04:33, 27.33s/epoch, loss=0.714, accuracy=0.85, val_loss=0.803, val_accuracy=0.803, lr=0.01]  90%|█████████ | 84/93 [39:00<04:05, 27.32s/epoch, loss=0.636, accuracy=0.858, val_loss=0.77, val_accuracy=0.808, lr=0.01] 91%|█████████▏| 85/93 [39:27<03:37, 27.23s/epoch, loss=0.598, accuracy=0.859, val_loss=0.778, val_accuracy=0.798, lr=0.01] 92%|█████████▏| 86/93 [39:54<03:10, 27.14s/epoch, loss=0.576, accuracy=0.862, val_loss=0.906, val_accuracy=0.756, lr=0.01] 94%|█████████▎| 87/93 [40:21<02:42, 27.09s/epoch, loss=0.569, accuracy=0.862, val_loss=0.817, val_accuracy=0.78, lr=0.01]  95%|█████████▍| 88/93 [40:48<02:15, 27.07s/epoch, loss=0.561, accuracy=0.864, val_loss=0.987, val_accuracy=0.727, lr=0.01] 96%|█████████▌| 89/93 [41:14<01:47, 26.87s/epoch, loss=0.56, accuracy=0.863, val_loss=1.27, val_accuracy=0.668, lr=0.00316] 97%|█████████▋| 90/93 [41:41<01:20, 26.90s/epoch, loss=0.558, accuracy=0.866, val_loss=0.834, val_accuracy=0.772, lr=0.01]  98%|█████████▊| 91/93 [42:08<00:54, 27.09s/epoch, loss=0.555, accuracy=0.868, val_loss=0.974, val_accuracy=0.74, lr=0.01]  99%|█████████▉| 92/93 [42:36<00:27, 27.09s/epoch, loss=0.556, accuracy=0.868, val_loss=0.997, val_accuracy=0.737, lr=0.01]100%|██████████| 93/93 [43:03<00:00, 27.16s/epoch, loss=0.55, accuracy=0.87, val_loss=1.06, val_accuracy=0.722, lr=0.01]   100%|██████████| 93/93 [43:03<00:00, 27.78s/epoch, loss=0.55, accuracy=0.87, val_loss=1.06, val_accuracy=0.722, lr=0.01]
Using real-time data augmentation.
Test score: 1.0617998838424683
Test accuracy: 0.722000002861023


* * * Run SGD for ID = 16_7. * * *


2024-03-05 09:52:50.931239: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 09:52:53.517374: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 09:52:53.518552: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-05 09:52:53.559347: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:18:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-05 09:52:53.559389: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 09:52:53.562809: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 09:52:53.562893: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 09:52:53.565346: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 09:52:53.566137: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 09:52:53.568983: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 09:52:53.570736: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 09:52:53.576093: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 09:52:53.576764: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 09:52:53.576862: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 09:52:54.828578: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-05 09:52:54.829326: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 09:52:54.831957: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:18:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-05 09:52:54.832009: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 09:52:54.832057: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 09:52:54.832081: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 09:52:54.832095: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 09:52:54.832109: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 09:52:54.832130: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 09:52:54.832152: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 09:52:54.832173: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 09:52:54.832770: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 09:52:54.832810: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 09:52:55.487318: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-05 09:52:55.487371: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-05 09:52:55.487383: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-05 09:52:55.488530: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:18:00.0, compute capability: 6.1)
{'id': '16_07', 'seed': 7, 'out_folder': 'results/epoch_budget', 'batch_size': 128, 'epochs': 93, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'bootstrapping': False, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/93 [00:00<?, ?epoch/s]2024-03-05 09:52:56.482666: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-05 09:52:56.494995: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2100000000 Hz
2024-03-05 09:52:58.341182: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 09:52:58.617976: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 09:52:59.707317: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-05 09:52:59.758773: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/93 [01:02<1:36:05, 62.67s/epoch, loss=3.2, accuracy=0.32, val_loss=2.79, val_accuracy=0.169, lr=0.1]  2%|▏         | 2/93 [01:29<1:02:43, 41.36s/epoch, loss=1.58, accuracy=0.528, val_loss=2.25, val_accuracy=0.328, lr=0.1]  3%|▎         | 3/93 [01:55<51:52, 34.58s/epoch, loss=1.41, accuracy=0.615, val_loss=2.1, val_accuracy=0.422, lr=0.1]     4%|▍         | 4/93 [02:22<46:31, 31.37s/epoch, loss=1.35, accuracy=0.655, val_loss=2.72, val_accuracy=0.375, lr=0.1]  5%|▌         | 5/93 [02:49<43:41, 29.79s/epoch, loss=1.29, accuracy=0.684, val_loss=1.74, val_accuracy=0.539, lr=0.1]  6%|▋         | 6/93 [03:16<42:01, 28.98s/epoch, loss=1.25, accuracy=0.701, val_loss=1.69, val_accuracy=0.538, lr=0.1]  8%|▊         | 7/93 [03:44<41:00, 28.61s/epoch, loss=1.22, accuracy=0.712, val_loss=1.57, val_accuracy=0.594, lr=0.1]  9%|▊         | 8/93 [04:11<40:01, 28.25s/epoch, loss=1.22, accuracy=0.72, val_loss=2.28, val_accuracy=0.446, lr=0.1]  10%|▉         | 9/93 [04:39<39:07, 27.95s/epoch, loss=1.22, accuracy=0.721, val_loss=4.7, val_accuracy=0.319, lr=0.1] 11%|█         | 10/93 [05:06<38:36, 27.91s/epoch, loss=1.21, accuracy=0.725, val_loss=1.95, val_accuracy=0.498, lr=0.1] 12%|█▏        | 11/93 [05:34<37:53, 27.73s/epoch, loss=1.2, accuracy=0.732, val_loss=1.7, val_accuracy=0.545, lr=0.1]   13%|█▎        | 12/93 [06:01<37:10, 27.54s/epoch, loss=1.19, accuracy=0.733, val_loss=1.89, val_accuracy=0.471, lr=0.0316] 14%|█▍        | 13/93 [06:27<36:01, 27.01s/epoch, loss=1.2, accuracy=0.733, val_loss=1.47, val_accuracy=0.634, lr=0.1]     15%|█▌        | 14/93 [06:55<36:01, 27.36s/epoch, loss=1.19, accuracy=0.736, val_loss=2.23, val_accuracy=0.477, lr=0.1] 16%|█▌        | 15/93 [07:22<35:19, 27.17s/epoch, loss=1.19, accuracy=0.739, val_loss=1.83, val_accuracy=0.531, lr=0.1] 17%|█▋        | 16/93 [07:49<35:07, 27.37s/epoch, loss=1.19, accuracy=0.739, val_loss=1.89, val_accuracy=0.543, lr=0.1] 18%|█▊        | 17/93 [08:17<34:47, 27.46s/epoch, loss=1.19, accuracy=0.737, val_loss=1.78, val_accuracy=0.578, lr=0.1] 19%|█▉        | 18/93 [08:44<34:00, 27.21s/epoch, loss=1.18, accuracy=0.741, val_loss=1.94, val_accuracy=0.507, lr=0.0316] 20%|██        | 19/93 [09:10<33:09, 26.88s/epoch, loss=1.18, accuracy=0.741, val_loss=2.22, val_accuracy=0.486, lr=0.1]    22%|██▏       | 20/93 [09:37<32:42, 26.88s/epoch, loss=1.18, accuracy=0.742, val_loss=2.18, val_accuracy=0.483, lr=0.1] 23%|██▎       | 21/93 [10:03<32:11, 26.83s/epoch, loss=1.18, accuracy=0.743, val_loss=1.57, val_accuracy=0.605, lr=0.1] 24%|██▎       | 22/93 [10:30<31:38, 26.74s/epoch, loss=1.18, accuracy=0.741, val_loss=1.57, val_accuracy=0.605, lr=0.1] 25%|██▍       | 23/93 [10:56<31:03, 26.63s/epoch, loss=1.18, accuracy=0.743, val_loss=1.8, val_accuracy=0.559, lr=0.0316] 26%|██▌       | 24/93 [11:23<30:36, 26.61s/epoch, loss=1.17, accuracy=0.743, val_loss=3.02, val_accuracy=0.351, lr=0.1]   27%|██▋       | 25/93 [11:49<30:02, 26.51s/epoch, loss=1.17, accuracy=0.745, val_loss=2.65, val_accuracy=0.262, lr=0.1] 28%|██▊       | 26/93 [12:16<29:34, 26.49s/epoch, loss=1.17, accuracy=0.744, val_loss=1.81, val_accuracy=0.501, lr=0.1] 29%|██▉       | 27/93 [12:43<29:29, 26.80s/epoch, loss=1.17, accuracy=0.745, val_loss=1.49, val_accuracy=0.628, lr=0.1] 30%|███       | 28/93 [13:11<29:24, 27.15s/epoch, loss=1.16, accuracy=0.747, val_loss=1.99, val_accuracy=0.542, lr=0.0316] 31%|███       | 29/93 [13:38<28:54, 27.10s/epoch, loss=1.16, accuracy=0.747, val_loss=2.64, val_accuracy=0.415, lr=0.1]    32%|███▏      | 30/93 [14:05<28:15, 26.92s/epoch, loss=1.16, accuracy=0.747, val_loss=2.3, val_accuracy=0.46, lr=0.1]   33%|███▎      | 31/93 [14:32<27:59, 27.09s/epoch, loss=1.16, accuracy=0.746, val_loss=1.58, val_accuracy=0.636, lr=0.1] 34%|███▍      | 32/93 [15:00<27:43, 27.28s/epoch, loss=1.16, accuracy=0.749, val_loss=1.91, val_accuracy=0.519, lr=0.1] 35%|███▌      | 33/93 [15:27<27:17, 27.29s/epoch, loss=1.16, accuracy=0.747, val_loss=2.37, val_accuracy=0.397, lr=0.0316] 37%|███▋      | 34/93 [15:54<26:49, 27.29s/epoch, loss=1.16, accuracy=0.749, val_loss=1.9, val_accuracy=0.498, lr=0.1]     38%|███▊      | 35/93 [16:21<26:09, 27.06s/epoch, loss=1.15, accuracy=0.751, val_loss=2.15, val_accuracy=0.539, lr=0.1] 39%|███▊      | 36/93 [16:48<25:44, 27.10s/epoch, loss=1.16, accuracy=0.749, val_loss=4.85, val_accuracy=0.173, lr=0.1] 40%|███▉      | 37/93 [17:15<25:17, 27.10s/epoch, loss=1.15, accuracy=0.75, val_loss=2.57, val_accuracy=0.411, lr=0.1]  41%|████      | 38/93 [17:43<24:56, 27.20s/epoch, loss=1.15, accuracy=0.75, val_loss=3.46, val_accuracy=0.351, lr=0.0316] 42%|████▏     | 39/93 [18:10<24:35, 27.33s/epoch, loss=1.14, accuracy=0.751, val_loss=2.33, val_accuracy=0.467, lr=0.1]   43%|████▎     | 40/93 [18:37<24:06, 27.30s/epoch, loss=1.16, accuracy=0.75, val_loss=2.13, val_accuracy=0.534, lr=0.1]  44%|████▍     | 41/93 [19:04<23:35, 27.21s/epoch, loss=1.15, accuracy=0.75, val_loss=2.21, val_accuracy=0.418, lr=0.1] 45%|████▌     | 42/93 [19:32<23:09, 27.25s/epoch, loss=1.15, accuracy=0.751, val_loss=1.56, val_accuracy=0.585, lr=0.1] 46%|████▌     | 43/93 [19:59<22:43, 27.27s/epoch, loss=1.15, accuracy=0.749, val_loss=1.86, val_accuracy=0.496, lr=0.0316] 47%|████▋     | 44/93 [20:27<22:20, 27.35s/epoch, loss=1.16, accuracy=0.748, val_loss=1.51, val_accuracy=0.631, lr=0.1]    48%|████▊     | 45/93 [20:53<21:43, 27.16s/epoch, loss=1.15, accuracy=0.752, val_loss=1.73, val_accuracy=0.549, lr=0.1] 49%|████▉     | 46/93 [21:20<21:10, 27.03s/epoch, loss=1.15, accuracy=0.75, val_loss=1.78, val_accuracy=0.579, lr=0.1]  51%|█████     | 47/93 [21:47<20:34, 26.85s/epoch, loss=1.15, accuracy=0.75, val_loss=1.73, val_accuracy=0.555, lr=0.1] 52%|█████▏    | 48/93 [22:13<20:03, 26.75s/epoch, loss=1.14, accuracy=0.754, val_loss=2.09, val_accuracy=0.426, lr=0.0316] 53%|█████▎    | 49/93 [22:39<19:28, 26.56s/epoch, loss=1.15, accuracy=0.752, val_loss=1.88, val_accuracy=0.524, lr=0.1]    54%|█████▍    | 50/93 [23:05<18:55, 26.42s/epoch, loss=1.14, accuracy=0.753, val_loss=2.19, val_accuracy=0.456, lr=0.1] 55%|█████▍    | 51/93 [23:32<18:38, 26.63s/epoch, loss=1.15, accuracy=0.751, val_loss=1.47, val_accuracy=0.654, lr=0.1] 56%|█████▌    | 52/93 [24:00<18:22, 26.88s/epoch, loss=1.15, accuracy=0.752, val_loss=2.08, val_accuracy=0.501, lr=0.1] 57%|█████▋    | 53/93 [24:27<17:56, 26.91s/epoch, loss=1.14, accuracy=0.752, val_loss=2.57, val_accuracy=0.423, lr=0.1] 58%|█████▊    | 54/93 [24:54<17:31, 26.96s/epoch, loss=1.14, accuracy=0.753, val_loss=2.72, val_accuracy=0.318, lr=0.1] 59%|█████▉    | 55/93 [25:21<17:09, 27.09s/epoch, loss=1.15, accuracy=0.751, val_loss=1.63, val_accuracy=0.57, lr=0.1]  60%|██████    | 56/93 [25:49<16:50, 27.30s/epoch, loss=1.14, accuracy=0.752, val_loss=4.36, val_accuracy=0.338, lr=0.0316] 61%|██████▏   | 57/93 [26:16<16:24, 27.34s/epoch, loss=1.14, accuracy=0.753, val_loss=2.17, val_accuracy=0.399, lr=0.1]    62%|██████▏   | 58/93 [26:44<15:54, 27.26s/epoch, loss=1.15, accuracy=0.747, val_loss=1.73, val_accuracy=0.528, lr=0.1] 63%|██████▎   | 59/93 [27:11<15:27, 27.28s/epoch, loss=1.15, accuracy=0.751, val_loss=1.76, val_accuracy=0.56, lr=0.1]  65%|██████▍   | 60/93 [27:38<14:58, 27.24s/epoch, loss=1.14, accuracy=0.752, val_loss=2.13, val_accuracy=0.481, lr=0.1] 66%|██████▌   | 61/93 [28:05<14:31, 27.24s/epoch, loss=1.15, accuracy=0.748, val_loss=2.28, val_accuracy=0.492, lr=0.0316] 67%|██████▋   | 62/93 [28:32<14:02, 27.18s/epoch, loss=1.15, accuracy=0.751, val_loss=1.62, val_accuracy=0.569, lr=0.1]    68%|██████▊   | 63/93 [28:59<13:31, 27.05s/epoch, loss=1.14, accuracy=0.752, val_loss=1.64, val_accuracy=0.565, lr=0.1] 69%|██████▉   | 64/93 [29:26<13:07, 27.15s/epoch, loss=1.14, accuracy=0.75, val_loss=1.5, val_accuracy=0.642, lr=0.1]   70%|██████▉   | 65/93 [29:54<12:42, 27.22s/epoch, loss=1.14, accuracy=0.752, val_loss=2.2, val_accuracy=0.44, lr=0.1] 71%|███████   | 66/93 [30:20<12:08, 26.99s/epoch, loss=1.14, accuracy=0.753, val_loss=2.19, val_accuracy=0.448, lr=0.0316] 72%|███████▏  | 67/93 [30:48<11:46, 27.17s/epoch, loss=1.14, accuracy=0.753, val_loss=1.81, val_accuracy=0.537, lr=0.1]    73%|███████▎  | 68/93 [31:15<11:19, 27.17s/epoch, loss=1.14, accuracy=0.749, val_loss=2.88, val_accuracy=0.359, lr=0.1] 74%|███████▍  | 69/93 [31:43<10:54, 27.26s/epoch, loss=1.14, accuracy=0.751, val_loss=2.11, val_accuracy=0.548, lr=0.1] 75%|███████▌  | 70/93 [32:10<10:28, 27.34s/epoch, loss=1.14, accuracy=0.751, val_loss=3.64, val_accuracy=0.298, lr=0.1] 76%|███████▋  | 71/93 [32:38<10:02, 27.41s/epoch, loss=1.15, accuracy=0.751, val_loss=2.66, val_accuracy=0.382, lr=0.0316] 77%|███████▋  | 72/93 [33:05<09:33, 27.29s/epoch, loss=1.14, accuracy=0.75, val_loss=2.81, val_accuracy=0.438, lr=0.1]     78%|███████▊  | 73/93 [33:32<09:07, 27.39s/epoch, loss=1.14, accuracy=0.753, val_loss=3.4, val_accuracy=0.323, lr=0.1] 80%|███████▉  | 74/93 [33:59<08:39, 27.32s/epoch, loss=1.14, accuracy=0.749, val_loss=1.97, val_accuracy=0.432, lr=0.1] 81%|████████  | 75/93 [34:27<08:13, 27.39s/epoch, loss=1.14, accuracy=0.749, val_loss=1.55, val_accuracy=0.614, lr=0.1] 82%|████████▏ | 76/93 [34:54<07:46, 27.42s/epoch, loss=1.14, accuracy=0.75, val_loss=2.48, val_accuracy=0.429, lr=0.0316] 83%|████████▎ | 77/93 [35:22<07:19, 27.45s/epoch, loss=1.14, accuracy=0.751, val_loss=2.07, val_accuracy=0.427, lr=0.1]   84%|████████▍ | 78/93 [35:49<06:51, 27.40s/epoch, loss=1.13, accuracy=0.753, val_loss=5.86, val_accuracy=0.235, lr=0.1] 85%|████████▍ | 79/93 [36:17<06:23, 27.37s/epoch, loss=1.14, accuracy=0.75, val_loss=1.98, val_accuracy=0.596, lr=0.1]  86%|████████▌ | 80/93 [36:44<05:54, 27.27s/epoch, loss=1.15, accuracy=0.749, val_loss=1.56, val_accuracy=0.605, lr=0.1] 87%|████████▋ | 81/93 [37:11<05:28, 27.37s/epoch, loss=1.14, accuracy=0.752, val_loss=2.14, val_accuracy=0.497, lr=0.0316] 88%|████████▊ | 82/93 [37:39<05:01, 27.42s/epoch, loss=0.918, accuracy=0.813, val_loss=0.909, val_accuracy=0.8, lr=0.01]   89%|████████▉ | 83/93 [38:06<04:34, 27.47s/epoch, loss=0.739, accuracy=0.845, val_loss=0.787, val_accuracy=0.817, lr=0.01] 90%|█████████ | 84/93 [38:34<04:07, 27.46s/epoch, loss=0.658, accuracy=0.853, val_loss=0.756, val_accuracy=0.817, lr=0.01] 91%|█████████▏| 85/93 [39:01<03:38, 27.35s/epoch, loss=0.619, accuracy=0.853, val_loss=0.874, val_accuracy=0.775, lr=0.01] 92%|█████████▏| 86/93 [39:28<03:11, 27.37s/epoch, loss=0.599, accuracy=0.856, val_loss=0.759, val_accuracy=0.796, lr=0.01] 94%|█████████▎| 87/93 [39:55<02:43, 27.32s/epoch, loss=0.584, accuracy=0.859, val_loss=0.726, val_accuracy=0.814, lr=0.01] 95%|█████████▍| 88/93 [40:23<02:16, 27.38s/epoch, loss=0.579, accuracy=0.859, val_loss=0.804, val_accuracy=0.784, lr=0.01] 96%|█████████▌| 89/93 [40:50<01:49, 27.38s/epoch, loss=0.579, accuracy=0.862, val_loss=0.989, val_accuracy=0.754, lr=0.01] 97%|█████████▋| 90/93 [41:18<01:22, 27.37s/epoch, loss=0.573, accuracy=0.865, val_loss=0.74, val_accuracy=0.807, lr=0.01]  98%|█████████▊| 91/93 [41:45<00:54, 27.32s/epoch, loss=0.571, accuracy=0.864, val_loss=0.848, val_accuracy=0.774, lr=0.01] 99%|█████████▉| 92/93 [42:12<00:27, 27.32s/epoch, loss=0.569, accuracy=0.864, val_loss=0.981, val_accuracy=0.736, lr=0.00316]100%|██████████| 93/93 [42:40<00:00, 27.37s/epoch, loss=0.569, accuracy=0.868, val_loss=0.854, val_accuracy=0.779, lr=0.01]   100%|██████████| 93/93 [42:40<00:00, 27.53s/epoch, loss=0.569, accuracy=0.868, val_loss=0.854, val_accuracy=0.779, lr=0.01]
Using real-time data augmentation.
Test score: 0.8535700440406799
Test accuracy: 0.7785000205039978


* * * Run SGD for ID = 16_8. * * *


2024-03-05 10:35:40.458633: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 10:35:43.000701: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 10:35:43.001922: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-05 10:35:43.042120: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:18:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-05 10:35:43.042158: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 10:35:43.045480: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 10:35:43.045546: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 10:35:43.048099: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 10:35:43.048778: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 10:35:43.051590: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 10:35:43.053186: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 10:35:43.058724: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 10:35:43.059424: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 10:35:43.059508: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 10:35:44.256015: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-05 10:35:44.256622: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 10:35:44.257754: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:18:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-05 10:35:44.257788: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 10:35:44.257826: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 10:35:44.257847: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 10:35:44.257867: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 10:35:44.257879: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 10:35:44.257892: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 10:35:44.257906: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 10:35:44.257920: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 10:35:44.258448: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 10:35:44.258483: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 10:35:44.894347: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-05 10:35:44.894395: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-05 10:35:44.894406: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-05 10:35:44.895410: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:18:00.0, compute capability: 6.1)
{'id': '16_08', 'seed': 8, 'out_folder': 'results/epoch_budget', 'batch_size': 128, 'epochs': 93, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'bootstrapping': False, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/93 [00:00<?, ?epoch/s]2024-03-05 10:35:45.748770: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-05 10:35:45.749507: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2100000000 Hz
2024-03-05 10:35:47.692079: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 10:35:47.978418: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 10:35:48.947282: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-05 10:35:48.992874: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/93 [01:01<1:35:02, 61.99s/epoch, loss=2.75, accuracy=0.446, val_loss=2.74, val_accuracy=0.375, lr=0.1]  2%|▏         | 2/93 [01:28<1:02:24, 41.14s/epoch, loss=1.42, accuracy=0.625, val_loss=1.75, val_accuracy=0.521, lr=0.1]  3%|▎         | 3/93 [01:54<51:23, 34.27s/epoch, loss=1.29, accuracy=0.684, val_loss=1.65, val_accuracy=0.577, lr=0.1]    4%|▍         | 4/93 [02:21<46:26, 31.31s/epoch, loss=1.24, accuracy=0.707, val_loss=2.3, val_accuracy=0.421, lr=0.1]   5%|▌         | 5/93 [02:48<43:53, 29.93s/epoch, loss=1.22, accuracy=0.718, val_loss=2.26, val_accuracy=0.444, lr=0.1]  6%|▋         | 6/93 [03:16<42:16, 29.15s/epoch, loss=1.21, accuracy=0.724, val_loss=1.58, val_accuracy=0.604, lr=0.1]  8%|▊         | 7/93 [03:43<40:58, 28.59s/epoch, loss=1.2, accuracy=0.729, val_loss=1.59, val_accuracy=0.595, lr=0.1]   9%|▊         | 8/93 [04:11<39:58, 28.22s/epoch, loss=1.19, accuracy=0.735, val_loss=1.84, val_accuracy=0.556, lr=0.1] 10%|▉         | 9/93 [04:38<39:07, 27.94s/epoch, loss=1.19, accuracy=0.737, val_loss=4.1, val_accuracy=0.184, lr=0.1]  11%|█         | 10/93 [05:06<38:29, 27.82s/epoch, loss=1.18, accuracy=0.738, val_loss=2.01, val_accuracy=0.489, lr=0.1] 12%|█▏        | 11/93 [05:33<37:44, 27.62s/epoch, loss=1.18, accuracy=0.739, val_loss=2.08, val_accuracy=0.466, lr=0.0316] 13%|█▎        | 12/93 [06:00<37:06, 27.49s/epoch, loss=1.17, accuracy=0.744, val_loss=1.95, val_accuracy=0.488, lr=0.1]    14%|█▍        | 13/93 [06:28<36:37, 27.47s/epoch, loss=1.17, accuracy=0.742, val_loss=1.95, val_accuracy=0.488, lr=0.1] 15%|█▌        | 14/93 [06:54<35:52, 27.24s/epoch, loss=1.16, accuracy=0.749, val_loss=1.57, val_accuracy=0.591, lr=0.1] 16%|█▌        | 15/93 [07:21<35:19, 27.17s/epoch, loss=1.17, accuracy=0.747, val_loss=1.96, val_accuracy=0.561, lr=0.1] 17%|█▋        | 16/93 [07:49<34:56, 27.23s/epoch, loss=1.19, accuracy=0.743, val_loss=2.14, val_accuracy=0.435, lr=0.1] 18%|█▊        | 17/93 [08:16<34:42, 27.40s/epoch, loss=1.15, accuracy=0.748, val_loss=2.21, val_accuracy=0.454, lr=0.1] 19%|█▉        | 18/93 [08:44<34:11, 27.35s/epoch, loss=1.16, accuracy=0.748, val_loss=2.79, val_accuracy=0.427, lr=0.1] 20%|██        | 19/93 [09:11<33:50, 27.44s/epoch, loss=1.15, accuracy=0.752, val_loss=1.63, val_accuracy=0.6, lr=0.0316] 22%|██▏       | 20/93 [09:39<33:28, 27.51s/epoch, loss=1.14, accuracy=0.75, val_loss=2.03, val_accuracy=0.475, lr=0.1]   23%|██▎       | 21/93 [10:07<33:05, 27.58s/epoch, loss=1.14, accuracy=0.753, val_loss=1.68, val_accuracy=0.591, lr=0.1] 24%|██▎       | 22/93 [10:34<32:35, 27.54s/epoch, loss=1.15, accuracy=0.752, val_loss=1.59, val_accuracy=0.607, lr=0.1] 25%|██▍       | 23/93 [11:02<32:10, 27.58s/epoch, loss=1.15, accuracy=0.75, val_loss=1.6, val_accuracy=0.597, lr=0.1]   26%|██▌       | 24/93 [11:29<31:44, 27.60s/epoch, loss=1.14, accuracy=0.751, val_loss=1.91, val_accuracy=0.549, lr=0.0316] 27%|██▋       | 25/93 [11:57<31:10, 27.51s/epoch, loss=1.13, accuracy=0.754, val_loss=2.09, val_accuracy=0.496, lr=0.1]    28%|██▊       | 26/93 [12:24<30:43, 27.51s/epoch, loss=1.14, accuracy=0.755, val_loss=1.84, val_accuracy=0.562, lr=0.1] 29%|██▉       | 27/93 [12:52<30:19, 27.56s/epoch, loss=1.13, accuracy=0.757, val_loss=2.88, val_accuracy=0.27, lr=0.1]  30%|███       | 28/93 [13:19<29:47, 27.50s/epoch, loss=1.13, accuracy=0.755, val_loss=1.93, val_accuracy=0.513, lr=0.1] 31%|███       | 29/93 [13:45<28:45, 26.96s/epoch, loss=1.13, accuracy=0.754, val_loss=3.01, val_accuracy=0.283, lr=0.0316] 32%|███▏      | 30/93 [14:12<28:22, 27.03s/epoch, loss=1.12, accuracy=0.759, val_loss=3.12, val_accuracy=0.248, lr=0.1]    33%|███▎      | 31/93 [14:38<27:29, 26.61s/epoch, loss=1.13, accuracy=0.755, val_loss=2.04, val_accuracy=0.515, lr=0.1] 34%|███▍      | 32/93 [15:05<27:12, 26.77s/epoch, loss=1.12, accuracy=0.756, val_loss=1.63, val_accuracy=0.613, lr=0.1] 35%|███▌      | 33/93 [15:33<27:03, 27.06s/epoch, loss=1.12, accuracy=0.758, val_loss=1.74, val_accuracy=0.571, lr=0.1] 37%|███▋      | 34/93 [16:00<26:45, 27.22s/epoch, loss=1.13, accuracy=0.755, val_loss=3.63, val_accuracy=0.241, lr=0.0316] 38%|███▊      | 35/93 [16:28<26:26, 27.35s/epoch, loss=1.12, accuracy=0.756, val_loss=1.55, val_accuracy=0.615, lr=0.1]    39%|███▊      | 36/93 [16:56<26:05, 27.46s/epoch, loss=1.12, accuracy=0.758, val_loss=1.8, val_accuracy=0.565, lr=0.1]  40%|███▉      | 37/93 [17:23<25:33, 27.39s/epoch, loss=1.12, accuracy=0.758, val_loss=2.58, val_accuracy=0.393, lr=0.1] 41%|████      | 38/93 [17:50<25:07, 27.40s/epoch, loss=1.12, accuracy=0.76, val_loss=1.6, val_accuracy=0.593, lr=0.1]   42%|████▏     | 39/93 [18:17<24:33, 27.29s/epoch, loss=1.12, accuracy=0.758, val_loss=2.29, val_accuracy=0.397, lr=0.1] 43%|████▎     | 40/93 [18:44<23:57, 27.13s/epoch, loss=1.11, accuracy=0.759, val_loss=1.76, val_accuracy=0.533, lr=0.0316] 44%|████▍     | 41/93 [19:12<23:38, 27.28s/epoch, loss=1.12, accuracy=0.758, val_loss=1.89, val_accuracy=0.533, lr=0.1]    45%|████▌     | 42/93 [19:39<23:07, 27.21s/epoch, loss=1.12, accuracy=0.757, val_loss=2.19, val_accuracy=0.438, lr=0.1] 46%|████▌     | 43/93 [20:05<22:30, 27.01s/epoch, loss=1.12, accuracy=0.757, val_loss=1.78, val_accuracy=0.516, lr=0.1] 47%|████▋     | 44/93 [20:33<22:10, 27.15s/epoch, loss=1.11, accuracy=0.759, val_loss=1.88, val_accuracy=0.5, lr=0.1]   48%|████▊     | 45/93 [21:00<21:37, 27.03s/epoch, loss=1.13, accuracy=0.758, val_loss=1.87, val_accuracy=0.548, lr=0.0316] 49%|████▉     | 46/93 [21:26<20:59, 26.80s/epoch, loss=1.12, accuracy=0.758, val_loss=2.75, val_accuracy=0.414, lr=0.1]    51%|█████     | 47/93 [21:52<20:23, 26.60s/epoch, loss=1.11, accuracy=0.76, val_loss=2.23, val_accuracy=0.448, lr=0.1]  52%|█████▏    | 48/93 [22:19<20:08, 26.85s/epoch, loss=1.11, accuracy=0.76, val_loss=2.63, val_accuracy=0.415, lr=0.1] 53%|█████▎    | 49/93 [22:47<19:45, 26.94s/epoch, loss=1.12, accuracy=0.756, val_loss=1.65, val_accuracy=0.589, lr=0.1] 54%|█████▍    | 50/93 [23:13<19:17, 26.91s/epoch, loss=1.11, accuracy=0.758, val_loss=1.49, val_accuracy=0.634, lr=0.1] 55%|█████▍    | 51/93 [23:41<18:54, 27.01s/epoch, loss=1.11, accuracy=0.759, val_loss=2.14, val_accuracy=0.433, lr=0.1] 56%|█████▌    | 52/93 [24:08<18:27, 27.02s/epoch, loss=1.12, accuracy=0.758, val_loss=1.94, val_accuracy=0.504, lr=0.1] 57%|█████▋    | 53/93 [24:35<18:04, 27.11s/epoch, loss=1.12, accuracy=0.756, val_loss=1.93, val_accuracy=0.461, lr=0.1] 58%|█████▊    | 54/93 [25:02<17:37, 27.11s/epoch, loss=1.12, accuracy=0.759, val_loss=1.44, val_accuracy=0.653, lr=0.1] 59%|█████▉    | 55/93 [25:29<17:11, 27.15s/epoch, loss=1.11, accuracy=0.759, val_loss=1.75, val_accuracy=0.534, lr=0.1] 60%|██████    | 56/93 [25:57<16:47, 27.22s/epoch, loss=1.11, accuracy=0.759, val_loss=2.13, val_accuracy=0.455, lr=0.1] 61%|██████▏   | 57/93 [26:24<16:17, 27.16s/epoch, loss=1.11, accuracy=0.757, val_loss=1.93, val_accuracy=0.497, lr=0.1] 62%|██████▏   | 58/93 [26:51<15:52, 27.21s/epoch, loss=1.12, accuracy=0.757, val_loss=3.77, val_accuracy=0.322, lr=0.1] 63%|██████▎   | 59/93 [27:18<15:23, 27.17s/epoch, loss=1.12, accuracy=0.76, val_loss=1.88, val_accuracy=0.539, lr=0.0316] 65%|██████▍   | 60/93 [27:46<14:59, 27.27s/epoch, loss=1.1, accuracy=0.759, val_loss=1.55, val_accuracy=0.611, lr=0.1]    66%|██████▌   | 61/93 [28:13<14:32, 27.26s/epoch, loss=1.11, accuracy=0.759, val_loss=2.54, val_accuracy=0.354, lr=0.1] 67%|██████▋   | 62/93 [28:40<14:06, 27.30s/epoch, loss=1.11, accuracy=0.76, val_loss=2.42, val_accuracy=0.406, lr=0.1]  68%|██████▊   | 63/93 [29:07<13:37, 27.27s/epoch, loss=1.11, accuracy=0.759, val_loss=4.09, val_accuracy=0.327, lr=0.1] 69%|██████▉   | 64/93 [29:34<13:02, 26.99s/epoch, loss=1.11, accuracy=0.758, val_loss=1.74, val_accuracy=0.531, lr=0.0316] 70%|██████▉   | 65/93 [30:00<12:31, 26.84s/epoch, loss=1.11, accuracy=0.758, val_loss=2.4, val_accuracy=0.376, lr=0.1]     71%|███████   | 66/93 [30:27<12:03, 26.78s/epoch, loss=1.11, accuracy=0.758, val_loss=2.54, val_accuracy=0.316, lr=0.1] 72%|███████▏  | 67/93 [30:54<11:41, 26.98s/epoch, loss=1.1, accuracy=0.76, val_loss=4.95, val_accuracy=0.275, lr=0.1]   73%|███████▎  | 68/93 [31:22<11:18, 27.14s/epoch, loss=1.1, accuracy=0.759, val_loss=2.5, val_accuracy=0.333, lr=0.1] 74%|███████▍  | 69/93 [31:49<10:51, 27.13s/epoch, loss=1.1, accuracy=0.76, val_loss=1.83, val_accuracy=0.558, lr=0.0316] 75%|███████▌  | 70/93 [32:16<10:22, 27.05s/epoch, loss=1.1, accuracy=0.761, val_loss=1.92, val_accuracy=0.496, lr=0.1]   76%|███████▋  | 71/93 [32:43<09:55, 27.08s/epoch, loss=1.1, accuracy=0.76, val_loss=2.13, val_accuracy=0.425, lr=0.1]  77%|███████▋  | 72/93 [33:10<09:29, 27.11s/epoch, loss=1.11, accuracy=0.76, val_loss=2.09, val_accuracy=0.465, lr=0.1] 78%|███████▊  | 73/93 [33:37<09:02, 27.14s/epoch, loss=1.1, accuracy=0.761, val_loss=1.56, val_accuracy=0.618, lr=0.1] 80%|███████▉  | 74/93 [34:05<08:35, 27.12s/epoch, loss=1.11, accuracy=0.755, val_loss=2.78, val_accuracy=0.363, lr=0.0316] 81%|████████  | 75/93 [34:32<08:08, 27.15s/epoch, loss=1.1, accuracy=0.759, val_loss=1.82, val_accuracy=0.505, lr=0.1]     82%|████████▏ | 76/93 [34:59<07:44, 27.30s/epoch, loss=1.11, accuracy=0.757, val_loss=3.01, val_accuracy=0.369, lr=0.1] 83%|████████▎ | 77/93 [35:27<07:17, 27.37s/epoch, loss=1.11, accuracy=0.758, val_loss=1.41, val_accuracy=0.657, lr=0.1] 84%|████████▍ | 78/93 [35:54<06:49, 27.31s/epoch, loss=1.1, accuracy=0.76, val_loss=3.62, val_accuracy=0.34, lr=0.1]    85%|████████▍ | 79/93 [36:22<06:23, 27.42s/epoch, loss=1.1, accuracy=0.759, val_loss=1.73, val_accuracy=0.579, lr=0.1] 86%|████████▌ | 80/93 [36:49<05:55, 27.35s/epoch, loss=1.11, accuracy=0.757, val_loss=2.03, val_accuracy=0.459, lr=0.1] 87%|████████▋ | 81/93 [37:16<05:27, 27.27s/epoch, loss=1.11, accuracy=0.758, val_loss=1.75, val_accuracy=0.534, lr=0.1] 88%|████████▊ | 82/93 [37:43<04:57, 27.08s/epoch, loss=0.898, accuracy=0.819, val_loss=0.939, val_accuracy=0.788, lr=0.01] 89%|████████▉ | 83/93 [38:10<04:30, 27.07s/epoch, loss=0.72, accuracy=0.851, val_loss=0.801, val_accuracy=0.81, lr=0.01]   90%|█████████ | 84/93 [38:37<04:04, 27.20s/epoch, loss=0.642, accuracy=0.859, val_loss=0.696, val_accuracy=0.835, lr=0.01] 91%|█████████▏| 85/93 [39:05<03:38, 27.27s/epoch, loss=0.602, accuracy=0.859, val_loss=0.735, val_accuracy=0.813, lr=0.01] 92%|█████████▏| 86/93 [39:32<03:10, 27.21s/epoch, loss=0.58, accuracy=0.862, val_loss=0.775, val_accuracy=0.797, lr=0.01]  94%|█████████▎| 87/93 [39:59<02:42, 27.12s/epoch, loss=0.569, accuracy=0.863, val_loss=0.714, val_accuracy=0.818, lr=0.01] 95%|█████████▍| 88/93 [40:26<02:15, 27.18s/epoch, loss=0.559, accuracy=0.864, val_loss=0.931, val_accuracy=0.753, lr=0.01] 96%|█████████▌| 89/93 [40:53<01:48, 27.20s/epoch, loss=0.56, accuracy=0.864, val_loss=0.917, val_accuracy=0.754, lr=0.00316] 97%|█████████▋| 90/93 [41:21<01:21, 27.29s/epoch, loss=0.558, accuracy=0.866, val_loss=0.847, val_accuracy=0.782, lr=0.01]   98%|█████████▊| 91/93 [41:48<00:54, 27.23s/epoch, loss=0.551, accuracy=0.868, val_loss=0.816, val_accuracy=0.789, lr=0.01] 99%|█████████▉| 92/93 [42:14<00:26, 26.89s/epoch, loss=0.551, accuracy=0.871, val_loss=0.863, val_accuracy=0.777, lr=0.01]100%|██████████| 93/93 [42:40<00:00, 26.67s/epoch, loss=0.553, accuracy=0.869, val_loss=0.76, val_accuracy=0.8, lr=0.01]   100%|██████████| 93/93 [42:40<00:00, 27.53s/epoch, loss=0.553, accuracy=0.869, val_loss=0.76, val_accuracy=0.8, lr=0.01]
Using real-time data augmentation.
Test score: 0.7596008777618408
Test accuracy: 0.8003000020980835


* * * Run SGD for ID = 16_9. * * *


2024-03-05 11:18:29.959293: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 11:18:32.485825: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 11:18:32.487113: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-05 11:18:32.528537: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:18:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-05 11:18:32.528589: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 11:18:32.531798: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 11:18:32.531868: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 11:18:32.534234: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 11:18:32.535350: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 11:18:32.538014: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 11:18:32.539562: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 11:18:32.544763: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 11:18:32.546414: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 11:18:32.546501: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 11:18:33.724194: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-05 11:18:33.725316: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 11:18:33.726375: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:18:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-05 11:18:33.726423: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 11:18:33.726463: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 11:18:33.726483: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 11:18:33.726501: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 11:18:33.726519: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 11:18:33.726539: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 11:18:33.726559: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 11:18:33.726579: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 11:18:33.728677: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 11:18:33.728715: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 11:18:34.384962: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-05 11:18:34.385015: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-05 11:18:34.385025: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-05 11:18:34.386123: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:18:00.0, compute capability: 6.1)
{'id': '16_09', 'seed': 9, 'out_folder': 'results/epoch_budget', 'batch_size': 128, 'epochs': 93, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'bootstrapping': False, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/93 [00:00<?, ?epoch/s]2024-03-05 11:18:35.313817: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-05 11:18:35.325995: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2100000000 Hz
2024-03-05 11:18:37.202742: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 11:18:37.420314: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 11:18:38.242203: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-05 11:18:38.295543: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/93 [01:11<1:49:06, 71.16s/epoch, loss=2.8, accuracy=0.424, val_loss=3.08, val_accuracy=0.233, lr=0.1]  2%|▏         | 2/93 [01:37<1:08:10, 44.96s/epoch, loss=1.44, accuracy=0.608, val_loss=3.23, val_accuracy=0.32, lr=0.1]  3%|▎         | 3/93 [02:04<55:07, 36.75s/epoch, loss=1.29, accuracy=0.675, val_loss=1.76, val_accuracy=0.512, lr=0.1]   4%|▍         | 4/93 [02:31<48:48, 32.91s/epoch, loss=1.24, accuracy=0.703, val_loss=2.63, val_accuracy=0.359, lr=0.1]  5%|▌         | 5/93 [02:59<45:29, 31.02s/epoch, loss=1.23, accuracy=0.712, val_loss=1.69, val_accuracy=0.541, lr=0.1]  6%|▋         | 6/93 [03:26<43:10, 29.78s/epoch, loss=1.2, accuracy=0.72, val_loss=2.11, val_accuracy=0.476, lr=0.1]    8%|▊         | 7/93 [03:54<41:34, 29.00s/epoch, loss=1.19, accuracy=0.729, val_loss=1.93, val_accuracy=0.515, lr=0.1]  9%|▊         | 8/93 [04:21<40:19, 28.46s/epoch, loss=1.19, accuracy=0.732, val_loss=1.61, val_accuracy=0.597, lr=0.1] 10%|▉         | 9/93 [04:48<39:19, 28.08s/epoch, loss=1.19, accuracy=0.732, val_loss=3.53, val_accuracy=0.309, lr=0.1] 11%|█         | 10/93 [05:16<38:35, 27.89s/epoch, loss=1.18, accuracy=0.736, val_loss=2.22, val_accuracy=0.496, lr=0.1] 12%|█▏        | 11/93 [05:43<38:00, 27.82s/epoch, loss=1.17, accuracy=0.739, val_loss=1.63, val_accuracy=0.585, lr=0.1] 13%|█▎        | 12/93 [06:11<37:30, 27.79s/epoch, loss=1.17, accuracy=0.739, val_loss=2.78, val_accuracy=0.424, lr=0.1] 14%|█▍        | 13/93 [06:39<36:55, 27.70s/epoch, loss=1.16, accuracy=0.743, val_loss=1.7, val_accuracy=0.563, lr=0.0316] 15%|█▌        | 14/93 [07:05<36:04, 27.40s/epoch, loss=1.17, accuracy=0.741, val_loss=2.01, val_accuracy=0.532, lr=0.1]   16%|█▌        | 15/93 [07:32<35:29, 27.30s/epoch, loss=1.17, accuracy=0.743, val_loss=1.82, val_accuracy=0.558, lr=0.1] 17%|█▋        | 16/93 [08:00<35:10, 27.41s/epoch, loss=1.16, accuracy=0.746, val_loss=2.12, val_accuracy=0.494, lr=0.1] 18%|█▊        | 17/93 [08:28<34:56, 27.59s/epoch, loss=1.16, accuracy=0.745, val_loss=1.98, val_accuracy=0.482, lr=0.1] 19%|█▉        | 18/93 [08:56<34:28, 27.58s/epoch, loss=1.15, accuracy=0.749, val_loss=2.07, val_accuracy=0.492, lr=0.0316] 20%|██        | 19/93 [09:23<34:03, 27.62s/epoch, loss=1.15, accuracy=0.75, val_loss=1.85, val_accuracy=0.549, lr=0.1]     22%|██▏       | 20/93 [09:51<33:32, 27.56s/epoch, loss=1.15, accuracy=0.751, val_loss=2.35, val_accuracy=0.483, lr=0.1] 23%|██▎       | 21/93 [10:18<33:06, 27.59s/epoch, loss=1.15, accuracy=0.752, val_loss=1.67, val_accuracy=0.59, lr=0.1]  24%|██▎       | 22/93 [10:46<32:36, 27.56s/epoch, loss=1.14, accuracy=0.751, val_loss=2.05, val_accuracy=0.511, lr=0.1] 25%|██▍       | 23/93 [11:14<32:14, 27.64s/epoch, loss=1.14, accuracy=0.753, val_loss=1.52, val_accuracy=0.631, lr=0.1] 26%|██▌       | 24/93 [11:41<31:32, 27.43s/epoch, loss=1.15, accuracy=0.753, val_loss=2.16, val_accuracy=0.495, lr=0.1] 27%|██▋       | 25/93 [12:08<31:07, 27.46s/epoch, loss=1.14, accuracy=0.753, val_loss=7.62, val_accuracy=0.16, lr=0.1]  28%|██▊       | 26/93 [12:35<30:36, 27.42s/epoch, loss=1.14, accuracy=0.754, val_loss=1.71, val_accuracy=0.58, lr=0.1] 29%|██▉       | 27/93 [13:03<30:07, 27.39s/epoch, loss=1.14, accuracy=0.752, val_loss=1.77, val_accuracy=0.514, lr=0.1] 30%|███       | 28/93 [13:30<29:41, 27.41s/epoch, loss=1.14, accuracy=0.752, val_loss=1.73, val_accuracy=0.54, lr=0.0316] 31%|███       | 29/93 [13:58<29:21, 27.52s/epoch, loss=1.14, accuracy=0.755, val_loss=1.7, val_accuracy=0.551, lr=0.1]    32%|███▏      | 30/93 [14:25<28:51, 27.48s/epoch, loss=1.13, accuracy=0.753, val_loss=1.58, val_accuracy=0.596, lr=0.1] 33%|███▎      | 31/93 [14:53<28:26, 27.52s/epoch, loss=1.13, accuracy=0.757, val_loss=2.13, val_accuracy=0.443, lr=0.1] 34%|███▍      | 32/93 [15:21<28:02, 27.59s/epoch, loss=1.13, accuracy=0.756, val_loss=2.42, val_accuracy=0.339, lr=0.1] 35%|███▌      | 33/93 [15:48<27:34, 27.58s/epoch, loss=1.13, accuracy=0.753, val_loss=5.92, val_accuracy=0.137, lr=0.0316] 37%|███▋      | 34/93 [16:15<26:56, 27.40s/epoch, loss=1.14, accuracy=0.755, val_loss=1.33, val_accuracy=0.689, lr=0.1]    38%|███▊      | 35/93 [16:43<26:28, 27.39s/epoch, loss=1.14, accuracy=0.754, val_loss=2.11, val_accuracy=0.48, lr=0.1]  39%|███▊      | 36/93 [17:11<26:09, 27.53s/epoch, loss=1.14, accuracy=0.755, val_loss=1.47, val_accuracy=0.638, lr=0.1] 40%|███▉      | 37/93 [17:38<25:46, 27.62s/epoch, loss=1.13, accuracy=0.756, val_loss=1.86, val_accuracy=0.528, lr=0.1] 41%|████      | 38/93 [18:06<25:14, 27.53s/epoch, loss=1.13, accuracy=0.755, val_loss=1.57, val_accuracy=0.612, lr=0.1] 42%|████▏     | 39/93 [18:33<24:46, 27.53s/epoch, loss=1.13, accuracy=0.757, val_loss=1.99, val_accuracy=0.493, lr=0.0316] 43%|████▎     | 40/93 [19:01<24:20, 27.55s/epoch, loss=1.12, accuracy=0.758, val_loss=2.29, val_accuracy=0.477, lr=0.1]    44%|████▍     | 41/93 [19:29<23:55, 27.61s/epoch, loss=1.12, accuracy=0.758, val_loss=2.19, val_accuracy=0.46, lr=0.1]  45%|████▌     | 42/93 [19:56<23:28, 27.61s/epoch, loss=1.12, accuracy=0.759, val_loss=1.89, val_accuracy=0.493, lr=0.1] 46%|████▌     | 43/93 [20:23<22:54, 27.49s/epoch, loss=1.12, accuracy=0.757, val_loss=2.58, val_accuracy=0.451, lr=0.1] 47%|████▋     | 44/93 [20:51<22:21, 27.37s/epoch, loss=1.12, accuracy=0.757, val_loss=2.13, val_accuracy=0.493, lr=0.0316] 48%|████▊     | 45/93 [21:18<21:50, 27.30s/epoch, loss=1.12, accuracy=0.759, val_loss=1.56, val_accuracy=0.615, lr=0.1]    49%|████▉     | 46/93 [21:46<21:31, 27.48s/epoch, loss=1.13, accuracy=0.755, val_loss=2.51, val_accuracy=0.407, lr=0.1] 51%|█████     | 47/93 [22:13<21:02, 27.45s/epoch, loss=1.12, accuracy=0.76, val_loss=1.75, val_accuracy=0.568, lr=0.1]  52%|█████▏    | 48/93 [22:41<20:38, 27.53s/epoch, loss=1.12, accuracy=0.759, val_loss=1.38, val_accuracy=0.665, lr=0.1] 53%|█████▎    | 49/93 [23:08<20:07, 27.45s/epoch, loss=1.12, accuracy=0.758, val_loss=2.34, val_accuracy=0.424, lr=0.0316] 54%|█████▍    | 50/93 [23:35<19:39, 27.42s/epoch, loss=1.12, accuracy=0.757, val_loss=3, val_accuracy=0.441, lr=0.1]       55%|█████▍    | 51/93 [24:03<19:13, 27.47s/epoch, loss=1.12, accuracy=0.758, val_loss=2.26, val_accuracy=0.397, lr=0.1] 56%|█████▌    | 52/93 [24:30<18:39, 27.31s/epoch, loss=1.12, accuracy=0.757, val_loss=1.92, val_accuracy=0.562, lr=0.1] 57%|█████▋    | 53/93 [24:56<18:00, 27.02s/epoch, loss=1.12, accuracy=0.758, val_loss=4.9, val_accuracy=0.122, lr=0.1]  58%|█████▊    | 54/93 [25:22<17:23, 26.75s/epoch, loss=1.12, accuracy=0.757, val_loss=2.29, val_accuracy=0.458, lr=0.0316] 59%|█████▉    | 55/93 [25:50<17:02, 26.91s/epoch, loss=1.12, accuracy=0.757, val_loss=2.01, val_accuracy=0.559, lr=0.1]    60%|██████    | 56/93 [26:17<16:47, 27.23s/epoch, loss=1.11, accuracy=0.759, val_loss=1.89, val_accuracy=0.526, lr=0.1] 61%|██████▏   | 57/93 [26:45<16:24, 27.35s/epoch, loss=1.12, accuracy=0.76, val_loss=1.83, val_accuracy=0.567, lr=0.1]  62%|██████▏   | 58/93 [27:13<16:01, 27.48s/epoch, loss=1.11, accuracy=0.762, val_loss=3.35, val_accuracy=0.367, lr=0.1] 63%|██████▎   | 59/93 [27:41<15:35, 27.51s/epoch, loss=1.11, accuracy=0.761, val_loss=2.02, val_accuracy=0.444, lr=0.0316] 65%|██████▍   | 60/93 [28:08<15:07, 27.49s/epoch, loss=1.12, accuracy=0.759, val_loss=3.34, val_accuracy=0.408, lr=0.1]    66%|██████▌   | 61/93 [28:35<14:38, 27.46s/epoch, loss=1.11, accuracy=0.759, val_loss=2.31, val_accuracy=0.389, lr=0.1] 67%|██████▋   | 62/93 [29:04<14:18, 27.71s/epoch, loss=1.11, accuracy=0.759, val_loss=1.73, val_accuracy=0.565, lr=0.1] 68%|██████▊   | 63/93 [29:31<13:49, 27.64s/epoch, loss=1.11, accuracy=0.76, val_loss=1.41, val_accuracy=0.662, lr=0.1]  69%|██████▉   | 64/93 [29:59<13:26, 27.80s/epoch, loss=1.11, accuracy=0.763, val_loss=2.14, val_accuracy=0.523, lr=0.0316] 70%|██████▉   | 65/93 [30:27<12:53, 27.64s/epoch, loss=1.11, accuracy=0.76, val_loss=6.56, val_accuracy=0.269, lr=0.1]     71%|███████   | 66/93 [30:54<12:24, 27.59s/epoch, loss=1.11, accuracy=0.758, val_loss=3.04, val_accuracy=0.297, lr=0.1] 72%|███████▏  | 67/93 [31:22<12:00, 27.70s/epoch, loss=1.11, accuracy=0.762, val_loss=2.07, val_accuracy=0.427, lr=0.1] 73%|███████▎  | 68/93 [31:51<11:40, 28.02s/epoch, loss=1.11, accuracy=0.759, val_loss=1.74, val_accuracy=0.58, lr=0.1]  74%|███████▍  | 69/93 [32:19<11:12, 28.03s/epoch, loss=1.11, accuracy=0.763, val_loss=1.78, val_accuracy=0.571, lr=0.0316] 75%|███████▌  | 70/93 [32:47<10:42, 27.95s/epoch, loss=1.11, accuracy=0.759, val_loss=3.07, val_accuracy=0.43, lr=0.1]     76%|███████▋  | 71/93 [33:15<10:18, 28.11s/epoch, loss=1.11, accuracy=0.759, val_loss=1.98, val_accuracy=0.481, lr=0.1] 77%|███████▋  | 72/93 [33:43<09:51, 28.18s/epoch, loss=1.1, accuracy=0.762, val_loss=1.85, val_accuracy=0.518, lr=0.1]  78%|███████▊  | 73/93 [34:11<09:20, 28.04s/epoch, loss=1.11, accuracy=0.759, val_loss=3.04, val_accuracy=0.291, lr=0.1] 80%|███████▉  | 74/93 [34:39<08:51, 27.96s/epoch, loss=1.11, accuracy=0.762, val_loss=2.61, val_accuracy=0.469, lr=0.0316] 81%|████████  | 75/93 [35:08<08:27, 28.20s/epoch, loss=1.11, accuracy=0.759, val_loss=1.91, val_accuracy=0.535, lr=0.1]    82%|████████▏ | 76/93 [35:35<07:57, 28.06s/epoch, loss=1.11, accuracy=0.76, val_loss=2.64, val_accuracy=0.418, lr=0.1]  83%|████████▎ | 77/93 [36:03<07:25, 27.86s/epoch, loss=1.11, accuracy=0.76, val_loss=1.63, val_accuracy=0.625, lr=0.1] 84%|████████▍ | 78/93 [36:30<06:55, 27.70s/epoch, loss=1.1, accuracy=0.76, val_loss=2.83, val_accuracy=0.38, lr=0.1]   85%|████████▍ | 79/93 [36:58<06:29, 27.84s/epoch, loss=1.11, accuracy=0.762, val_loss=1.92, val_accuracy=0.565, lr=0.0316] 86%|████████▌ | 80/93 [37:26<06:01, 27.84s/epoch, loss=1.1, accuracy=0.761, val_loss=1.81, val_accuracy=0.508, lr=0.1]     87%|████████▋ | 81/93 [37:55<05:36, 28.08s/epoch, loss=1.1, accuracy=0.759, val_loss=2.58, val_accuracy=0.367, lr=0.1] 88%|████████▊ | 82/93 [38:23<05:10, 28.19s/epoch, loss=0.903, accuracy=0.818, val_loss=0.858, val_accuracy=0.817, lr=0.01] 89%|████████▉ | 83/93 [38:51<04:41, 28.13s/epoch, loss=0.73, accuracy=0.847, val_loss=1.07, val_accuracy=0.715, lr=0.01]   90%|█████████ | 84/93 [39:19<04:12, 28.02s/epoch, loss=0.65, accuracy=0.856, val_loss=0.708, val_accuracy=0.83, lr=0.01] 91%|█████████▏| 85/93 [39:47<03:43, 27.91s/epoch, loss=0.602, accuracy=0.862, val_loss=0.779, val_accuracy=0.791, lr=0.01] 92%|█████████▏| 86/93 [40:14<03:13, 27.67s/epoch, loss=0.58, accuracy=0.861, val_loss=0.81, val_accuracy=0.786, lr=0.01]   94%|█████████▎| 87/93 [40:41<02:45, 27.66s/epoch, loss=0.572, accuracy=0.861, val_loss=0.816, val_accuracy=0.783, lr=0.01] 95%|█████████▍| 88/93 [41:10<02:19, 27.93s/epoch, loss=0.564, accuracy=0.866, val_loss=0.91, val_accuracy=0.752, lr=0.01]  96%|█████████▌| 89/93 [41:37<01:50, 27.72s/epoch, loss=0.557, accuracy=0.866, val_loss=0.761, val_accuracy=0.795, lr=0.00316] 97%|█████████▋| 90/93 [42:04<01:22, 27.48s/epoch, loss=0.558, accuracy=0.865, val_loss=0.969, val_accuracy=0.742, lr=0.01]    98%|█████████▊| 91/93 [42:31<00:54, 27.35s/epoch, loss=0.557, accuracy=0.87, val_loss=1.26, val_accuracy=0.679, lr=0.01]   99%|█████████▉| 92/93 [42:57<00:26, 26.98s/epoch, loss=0.552, accuracy=0.872, val_loss=0.844, val_accuracy=0.778, lr=0.01]100%|██████████| 93/93 [43:24<00:00, 27.00s/epoch, loss=0.552, accuracy=0.872, val_loss=0.914, val_accuracy=0.751, lr=0.01]100%|██████████| 93/93 [43:24<00:00, 28.01s/epoch, loss=0.552, accuracy=0.872, val_loss=0.914, val_accuracy=0.751, lr=0.01]
Using real-time data augmentation.
Test score: 0.914120614528656
Test accuracy: 0.7511000037193298


* * * Run SGD for ID = 16_10. * * *


2024-03-05 12:02:03.929854: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 12:02:06.505536: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 12:02:06.506854: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-05 12:02:06.549092: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:18:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-05 12:02:06.549131: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 12:02:06.552822: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 12:02:06.552898: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 12:02:06.555641: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 12:02:06.556411: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 12:02:06.559415: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 12:02:06.561266: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 12:02:06.566929: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 12:02:06.567591: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 12:02:06.567672: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 12:02:07.801505: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-05 12:02:07.802586: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 12:02:07.803672: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:18:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-05 12:02:07.803707: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 12:02:07.803745: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 12:02:07.803759: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 12:02:07.803771: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 12:02:07.803784: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 12:02:07.803798: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 12:02:07.803813: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 12:02:07.803834: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 12:02:07.804359: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 12:02:07.804400: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 12:02:08.435187: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-05 12:02:08.435239: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-05 12:02:08.435251: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-05 12:02:08.436395: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:18:00.0, compute capability: 6.1)
{'id': '16_10', 'seed': 10, 'out_folder': 'results/epoch_budget', 'batch_size': 128, 'epochs': 93, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'bootstrapping': False, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/93 [00:00<?, ?epoch/s]2024-03-05 12:02:09.337973: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-05 12:02:09.338661: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2100000000 Hz
2024-03-05 12:02:11.373570: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 12:02:11.625930: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 12:02:12.621071: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-05 12:02:12.679731: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/93 [01:05<1:40:40, 65.66s/epoch, loss=2.91, accuracy=0.368, val_loss=3, val_accuracy=0.255, lr=0.1]  2%|▏         | 2/93 [01:32<1:05:22, 43.10s/epoch, loss=1.5, accuracy=0.57, val_loss=3.29, val_accuracy=0.325, lr=0.1]  3%|▎         | 3/93 [01:59<53:04, 35.39s/epoch, loss=1.3, accuracy=0.663, val_loss=2.12, val_accuracy=0.478, lr=0.1]   4%|▍         | 4/93 [02:26<47:35, 32.08s/epoch, loss=1.26, accuracy=0.694, val_loss=2.15, val_accuracy=0.471, lr=0.1]  5%|▌         | 5/93 [02:53<44:47, 30.54s/epoch, loss=1.24, accuracy=0.707, val_loss=2.02, val_accuracy=0.516, lr=0.1]  6%|▋         | 6/93 [03:21<42:52, 29.57s/epoch, loss=1.22, accuracy=0.718, val_loss=2.13, val_accuracy=0.502, lr=0.1]  8%|▊         | 7/93 [03:49<41:31, 28.98s/epoch, loss=1.2, accuracy=0.724, val_loss=2.06, val_accuracy=0.484, lr=0.1]   9%|▊         | 8/93 [04:16<40:24, 28.52s/epoch, loss=1.2, accuracy=0.729, val_loss=2.68, val_accuracy=0.408, lr=0.1] 10%|▉         | 9/93 [04:44<39:34, 28.27s/epoch, loss=1.2, accuracy=0.731, val_loss=1.69, val_accuracy=0.569, lr=0.1] 11%|█         | 10/93 [05:12<38:45, 28.02s/epoch, loss=1.19, accuracy=0.734, val_loss=3.27, val_accuracy=0.361, lr=0.1] 12%|█▏        | 11/93 [05:39<38:03, 27.84s/epoch, loss=1.19, accuracy=0.736, val_loss=2.17, val_accuracy=0.472, lr=0.1] 13%|█▎        | 12/93 [06:07<37:33, 27.82s/epoch, loss=1.18, accuracy=0.741, val_loss=3.84, val_accuracy=0.326, lr=0.1] 14%|█▍        | 13/93 [06:34<37:00, 27.76s/epoch, loss=1.18, accuracy=0.74, val_loss=10.8, val_accuracy=0.153, lr=0.1]  15%|█▌        | 14/93 [07:02<36:22, 27.62s/epoch, loss=1.17, accuracy=0.742, val_loss=1.73, val_accuracy=0.563, lr=0.0316] 16%|█▌        | 15/93 [07:29<35:44, 27.49s/epoch, loss=1.17, accuracy=0.744, val_loss=2.89, val_accuracy=0.384, lr=0.1]    17%|█▋        | 16/93 [07:56<35:15, 27.47s/epoch, loss=1.17, accuracy=0.743, val_loss=1.34, val_accuracy=0.691, lr=0.1] 18%|█▊        | 17/93 [08:23<34:24, 27.17s/epoch, loss=1.17, accuracy=0.745, val_loss=1.94, val_accuracy=0.498, lr=0.1] 19%|█▉        | 18/93 [08:50<33:50, 27.08s/epoch, loss=1.16, accuracy=0.748, val_loss=1.53, val_accuracy=0.62, lr=0.1]  20%|██        | 19/93 [09:16<33:11, 26.91s/epoch, loss=1.17, accuracy=0.746, val_loss=1.67, val_accuracy=0.616, lr=0.1] 22%|██▏       | 20/93 [09:43<32:41, 26.87s/epoch, loss=1.16, accuracy=0.748, val_loss=1.59, val_accuracy=0.614, lr=0.1] 23%|██▎       | 21/93 [10:10<32:16, 26.90s/epoch, loss=1.16, accuracy=0.747, val_loss=1.84, val_accuracy=0.531, lr=0.0316] 24%|██▎       | 22/93 [10:38<32:07, 27.15s/epoch, loss=1.15, accuracy=0.748, val_loss=1.76, val_accuracy=0.534, lr=0.1]    25%|██▍       | 23/93 [11:06<31:53, 27.34s/epoch, loss=1.15, accuracy=0.75, val_loss=2.25, val_accuracy=0.404, lr=0.1]  26%|██▌       | 24/93 [11:33<31:32, 27.42s/epoch, loss=1.15, accuracy=0.75, val_loss=1.63, val_accuracy=0.588, lr=0.1] 27%|██▋       | 25/93 [12:01<31:10, 27.51s/epoch, loss=1.15, accuracy=0.751, val_loss=1.56, val_accuracy=0.606, lr=0.1] 28%|██▊       | 26/93 [12:28<30:42, 27.50s/epoch, loss=1.15, accuracy=0.751, val_loss=1.89, val_accuracy=0.479, lr=0.0316] 29%|██▉       | 27/93 [12:56<30:16, 27.53s/epoch, loss=1.15, accuracy=0.751, val_loss=2.18, val_accuracy=0.467, lr=0.1]    30%|███       | 28/93 [13:24<29:51, 27.56s/epoch, loss=1.15, accuracy=0.754, val_loss=3.29, val_accuracy=0.428, lr=0.1] 31%|███       | 29/93 [13:51<29:24, 27.57s/epoch, loss=1.14, accuracy=0.752, val_loss=1.33, val_accuracy=0.686, lr=0.1] 32%|███▏      | 30/93 [14:19<28:59, 27.61s/epoch, loss=1.14, accuracy=0.753, val_loss=1.81, val_accuracy=0.556, lr=0.1] 33%|███▎      | 31/93 [14:46<28:31, 27.61s/epoch, loss=1.13, accuracy=0.753, val_loss=2.54, val_accuracy=0.371, lr=0.1] 34%|███▍      | 32/93 [15:14<28:03, 27.60s/epoch, loss=1.14, accuracy=0.756, val_loss=1.92, val_accuracy=0.55, lr=0.1]  35%|███▌      | 33/93 [15:41<27:29, 27.49s/epoch, loss=1.14, accuracy=0.754, val_loss=1.57, val_accuracy=0.631, lr=0.1] 37%|███▋      | 34/93 [16:08<26:48, 27.27s/epoch, loss=1.13, accuracy=0.754, val_loss=1.82, val_accuracy=0.533, lr=0.0316] 38%|███▊      | 35/93 [16:35<26:17, 27.20s/epoch, loss=1.13, accuracy=0.754, val_loss=1.46, val_accuracy=0.627, lr=0.1]    39%|███▊      | 36/93 [17:02<25:47, 27.15s/epoch, loss=1.14, accuracy=0.752, val_loss=2.75, val_accuracy=0.455, lr=0.1] 40%|███▉      | 37/93 [17:29<25:21, 27.17s/epoch, loss=1.13, accuracy=0.755, val_loss=1.75, val_accuracy=0.519, lr=0.1] 41%|████      | 38/93 [17:57<24:59, 27.27s/epoch, loss=1.13, accuracy=0.757, val_loss=1.65, val_accuracy=0.585, lr=0.1] 42%|████▏     | 39/93 [18:24<24:35, 27.32s/epoch, loss=1.13, accuracy=0.756, val_loss=1.63, val_accuracy=0.588, lr=0.0316] 43%|████▎     | 40/93 [18:52<24:15, 27.47s/epoch, loss=1.13, accuracy=0.756, val_loss=2.14, val_accuracy=0.457, lr=0.1]    44%|████▍     | 41/93 [19:20<23:49, 27.48s/epoch, loss=1.13, accuracy=0.755, val_loss=1.78, val_accuracy=0.571, lr=0.1] 45%|████▌     | 42/93 [19:47<23:22, 27.51s/epoch, loss=1.13, accuracy=0.757, val_loss=1.87, val_accuracy=0.489, lr=0.1] 46%|████▌     | 43/93 [20:14<22:49, 27.38s/epoch, loss=1.13, accuracy=0.756, val_loss=2.14, val_accuracy=0.517, lr=0.1] 47%|████▋     | 44/93 [20:42<22:23, 27.41s/epoch, loss=1.12, accuracy=0.758, val_loss=2.29, val_accuracy=0.453, lr=0.0316] 48%|████▊     | 45/93 [21:09<21:52, 27.34s/epoch, loss=1.13, accuracy=0.757, val_loss=2.24, val_accuracy=0.476, lr=0.1]    49%|████▉     | 46/93 [21:36<21:27, 27.39s/epoch, loss=1.12, accuracy=0.759, val_loss=3.17, val_accuracy=0.306, lr=0.1] 51%|█████     | 47/93 [22:04<21:07, 27.55s/epoch, loss=1.13, accuracy=0.758, val_loss=1.93, val_accuracy=0.477, lr=0.1] 52%|█████▏    | 48/93 [22:32<20:37, 27.51s/epoch, loss=1.12, accuracy=0.758, val_loss=2.51, val_accuracy=0.373, lr=0.1] 53%|█████▎    | 49/93 [22:59<20:12, 27.56s/epoch, loss=1.13, accuracy=0.754, val_loss=2.25, val_accuracy=0.426, lr=0.0316] 54%|█████▍    | 50/93 [23:27<19:41, 27.48s/epoch, loss=1.12, accuracy=0.756, val_loss=2.79, val_accuracy=0.385, lr=0.1]    55%|█████▍    | 51/93 [23:54<19:16, 27.55s/epoch, loss=1.12, accuracy=0.757, val_loss=2.3, val_accuracy=0.509, lr=0.1]  56%|█████▌    | 52/93 [24:22<18:55, 27.69s/epoch, loss=1.13, accuracy=0.755, val_loss=5.37, val_accuracy=0.189, lr=0.1] 57%|█████▋    | 53/93 [24:50<18:25, 27.64s/epoch, loss=1.12, accuracy=0.756, val_loss=1.78, val_accuracy=0.551, lr=0.1] 58%|█████▊    | 54/93 [25:18<17:59, 27.69s/epoch, loss=1.12, accuracy=0.754, val_loss=1.83, val_accuracy=0.558, lr=0.0316] 59%|█████▉    | 55/93 [25:45<17:31, 27.66s/epoch, loss=1.13, accuracy=0.758, val_loss=2.08, val_accuracy=0.524, lr=0.1]    60%|██████    | 56/93 [26:13<17:05, 27.71s/epoch, loss=1.12, accuracy=0.758, val_loss=2.46, val_accuracy=0.418, lr=0.1] 61%|██████▏   | 57/93 [26:41<16:38, 27.73s/epoch, loss=1.12, accuracy=0.758, val_loss=1.84, val_accuracy=0.525, lr=0.1] 62%|██████▏   | 58/93 [27:09<16:09, 27.71s/epoch, loss=1.12, accuracy=0.757, val_loss=3.25, val_accuracy=0.378, lr=0.1] 63%|██████▎   | 59/93 [27:36<15:36, 27.54s/epoch, loss=1.12, accuracy=0.758, val_loss=2.65, val_accuracy=0.458, lr=0.0316] 65%|██████▍   | 60/93 [28:03<15:06, 27.46s/epoch, loss=1.12, accuracy=0.756, val_loss=1.67, val_accuracy=0.58, lr=0.1]     66%|██████▌   | 61/93 [28:30<14:33, 27.28s/epoch, loss=1.12, accuracy=0.757, val_loss=2.39, val_accuracy=0.374, lr=0.1] 67%|██████▋   | 62/93 [28:58<14:09, 27.39s/epoch, loss=1.12, accuracy=0.758, val_loss=1.47, val_accuracy=0.652, lr=0.1] 68%|██████▊   | 63/93 [29:26<13:46, 27.57s/epoch, loss=1.12, accuracy=0.758, val_loss=1.91, val_accuracy=0.476, lr=0.1] 69%|██████▉   | 64/93 [29:54<13:23, 27.72s/epoch, loss=1.11, accuracy=0.761, val_loss=1.6, val_accuracy=0.584, lr=0.0316] 70%|██████▉   | 65/93 [30:22<12:58, 27.81s/epoch, loss=1.12, accuracy=0.759, val_loss=1.46, val_accuracy=0.649, lr=0.1]   71%|███████   | 66/93 [30:50<12:32, 27.88s/epoch, loss=1.12, accuracy=0.758, val_loss=1.69, val_accuracy=0.576, lr=0.1] 72%|███████▏  | 67/93 [31:18<12:04, 27.87s/epoch, loss=1.12, accuracy=0.755, val_loss=2.5, val_accuracy=0.413, lr=0.1]  73%|███████▎  | 68/93 [31:45<11:36, 27.85s/epoch, loss=1.12, accuracy=0.757, val_loss=2.48, val_accuracy=0.35, lr=0.1] 74%|███████▍  | 69/93 [32:13<11:08, 27.85s/epoch, loss=1.11, accuracy=0.761, val_loss=2.25, val_accuracy=0.483, lr=0.0316] 75%|███████▌  | 70/93 [32:41<10:39, 27.81s/epoch, loss=1.12, accuracy=0.758, val_loss=3.57, val_accuracy=0.283, lr=0.1]    76%|███████▋  | 71/93 [33:08<10:08, 27.64s/epoch, loss=1.11, accuracy=0.76, val_loss=1.72, val_accuracy=0.582, lr=0.1]  77%|███████▋  | 72/93 [33:35<09:37, 27.52s/epoch, loss=1.11, accuracy=0.757, val_loss=2.33, val_accuracy=0.42, lr=0.1] 78%|███████▊  | 73/93 [34:03<09:12, 27.62s/epoch, loss=1.11, accuracy=0.759, val_loss=3.54, val_accuracy=0.359, lr=0.1] 80%|███████▉  | 74/93 [34:30<08:42, 27.48s/epoch, loss=1.11, accuracy=0.758, val_loss=2.21, val_accuracy=0.505, lr=0.0316] 81%|████████  | 75/93 [34:58<08:17, 27.63s/epoch, loss=1.11, accuracy=0.759, val_loss=2.27, val_accuracy=0.496, lr=0.1]    82%|████████▏ | 76/93 [35:26<07:49, 27.63s/epoch, loss=1.11, accuracy=0.756, val_loss=2.11, val_accuracy=0.429, lr=0.1] 83%|████████▎ | 77/93 [35:54<07:23, 27.72s/epoch, loss=1.11, accuracy=0.759, val_loss=3.34, val_accuracy=0.359, lr=0.1] 84%|████████▍ | 78/93 [36:22<06:56, 27.74s/epoch, loss=1.11, accuracy=0.76, val_loss=4.02, val_accuracy=0.251, lr=0.1]  85%|████████▍ | 79/93 [36:50<06:28, 27.77s/epoch, loss=1.12, accuracy=0.756, val_loss=1.5, val_accuracy=0.63, lr=0.0316] 86%|████████▌ | 80/93 [37:17<06:00, 27.75s/epoch, loss=1.11, accuracy=0.76, val_loss=3.3, val_accuracy=0.372, lr=0.1]    87%|████████▋ | 81/93 [37:45<05:33, 27.77s/epoch, loss=1.11, accuracy=0.757, val_loss=2.58, val_accuracy=0.406, lr=0.1] 88%|████████▊ | 82/93 [38:13<05:04, 27.69s/epoch, loss=0.904, accuracy=0.818, val_loss=0.873, val_accuracy=0.809, lr=0.01] 89%|████████▉ | 83/93 [38:40<04:35, 27.60s/epoch, loss=0.725, accuracy=0.849, val_loss=0.789, val_accuracy=0.813, lr=0.01] 90%|█████████ | 84/93 [39:07<04:07, 27.54s/epoch, loss=0.648, accuracy=0.856, val_loss=0.725, val_accuracy=0.822, lr=0.01] 91%|█████████▏| 85/93 [39:34<03:39, 27.42s/epoch, loss=0.602, accuracy=0.861, val_loss=0.695, val_accuracy=0.825, lr=0.01] 92%|█████████▏| 86/93 [40:02<03:12, 27.53s/epoch, loss=0.581, accuracy=0.861, val_loss=0.942, val_accuracy=0.75, lr=0.01]  94%|█████████▎| 87/93 [40:29<02:44, 27.37s/epoch, loss=0.568, accuracy=0.863, val_loss=0.685, val_accuracy=0.822, lr=0.01] 95%|█████████▍| 88/93 [40:57<02:16, 27.38s/epoch, loss=0.564, accuracy=0.865, val_loss=0.804, val_accuracy=0.788, lr=0.01] 96%|█████████▌| 89/93 [41:24<01:49, 27.35s/epoch, loss=0.558, accuracy=0.866, val_loss=0.788, val_accuracy=0.798, lr=0.01] 97%|█████████▋| 90/93 [41:51<01:21, 27.30s/epoch, loss=0.557, accuracy=0.867, val_loss=0.733, val_accuracy=0.808, lr=0.01] 98%|█████████▊| 91/93 [42:18<00:54, 27.28s/epoch, loss=0.555, accuracy=0.87, val_loss=0.926, val_accuracy=0.758, lr=0.01]  99%|█████████▉| 92/93 [42:46<00:27, 27.35s/epoch, loss=0.554, accuracy=0.871, val_loss=0.817, val_accuracy=0.787, lr=0.00316]100%|██████████| 93/93 [43:13<00:00, 27.26s/epoch, loss=0.552, accuracy=0.871, val_loss=0.806, val_accuracy=0.798, lr=0.01]   100%|██████████| 93/93 [43:13<00:00, 27.89s/epoch, loss=0.552, accuracy=0.871, val_loss=0.806, val_accuracy=0.798, lr=0.01]
Using real-time data augmentation.
Test score: 0.8063353300094604
Test accuracy: 0.7980999946594238


* * * Run SGD for ID = 16_11. * * *


2024-03-05 12:45:26.363812: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 12:45:28.999447: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 12:45:29.000664: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-05 12:45:29.042270: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:18:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-05 12:45:29.042312: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 12:45:29.045669: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 12:45:29.045741: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 12:45:29.048383: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 12:45:29.049170: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 12:45:29.052064: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 12:45:29.053790: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 12:45:29.059874: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 12:45:29.060526: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 12:45:29.060607: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 12:45:30.289785: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-05 12:45:30.290428: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 12:45:30.291578: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:18:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-05 12:45:30.291612: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 12:45:30.291657: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 12:45:30.291678: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 12:45:30.291690: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 12:45:30.291702: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 12:45:30.291716: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 12:45:30.291730: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 12:45:30.291744: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 12:45:30.292301: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 12:45:30.292339: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 12:45:30.918938: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-05 12:45:30.918990: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-05 12:45:30.919002: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-05 12:45:30.920509: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:18:00.0, compute capability: 6.1)
{'id': '16_11', 'seed': 11, 'out_folder': 'results/epoch_budget', 'batch_size': 128, 'epochs': 93, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'bootstrapping': False, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/93 [00:00<?, ?epoch/s]2024-03-05 12:45:31.777996: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-05 12:45:31.789998: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2100000000 Hz
2024-03-05 12:45:33.736092: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 12:45:34.084516: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 12:45:35.271001: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-05 12:45:35.329496: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/93 [01:05<1:40:25, 65.49s/epoch, loss=2.76, accuracy=0.421, val_loss=2.1, val_accuracy=0.394, lr=0.1]  2%|▏         | 2/93 [01:33<1:05:34, 43.24s/epoch, loss=1.44, accuracy=0.61, val_loss=1.87, val_accuracy=0.482, lr=0.1]  3%|▎         | 3/93 [02:00<54:18, 36.20s/epoch, loss=1.3, accuracy=0.675, val_loss=2.19, val_accuracy=0.418, lr=0.1]    4%|▍         | 4/93 [02:28<48:31, 32.72s/epoch, loss=1.25, accuracy=0.701, val_loss=1.94, val_accuracy=0.473, lr=0.1]  5%|▌         | 5/93 [02:56<45:24, 30.96s/epoch, loss=1.24, accuracy=0.711, val_loss=1.87, val_accuracy=0.554, lr=0.1]  6%|▋         | 6/93 [03:23<43:07, 29.74s/epoch, loss=1.22, accuracy=0.719, val_loss=1.75, val_accuracy=0.539, lr=0.1]  8%|▊         | 7/93 [03:51<41:39, 29.06s/epoch, loss=1.21, accuracy=0.725, val_loss=1.93, val_accuracy=0.514, lr=0.1]  9%|▊         | 8/93 [04:18<40:28, 28.57s/epoch, loss=1.2, accuracy=0.727, val_loss=1.8, val_accuracy=0.55, lr=0.1]    10%|▉         | 9/93 [04:46<39:35, 28.28s/epoch, loss=1.2, accuracy=0.731, val_loss=1.46, val_accuracy=0.641, lr=0.1] 11%|█         | 10/93 [05:13<38:33, 27.88s/epoch, loss=1.2, accuracy=0.734, val_loss=1.46, val_accuracy=0.638, lr=0.1] 12%|█▏        | 11/93 [05:39<37:31, 27.45s/epoch, loss=1.19, accuracy=0.736, val_loss=2.12, val_accuracy=0.477, lr=0.1] 13%|█▎        | 12/93 [06:06<36:36, 27.12s/epoch, loss=1.19, accuracy=0.737, val_loss=1.58, val_accuracy=0.585, lr=0.1] 14%|█▍        | 13/93 [06:32<35:47, 26.84s/epoch, loss=1.18, accuracy=0.738, val_loss=1.72, val_accuracy=0.601, lr=0.1] 15%|█▌        | 14/93 [06:59<35:19, 26.83s/epoch, loss=1.18, accuracy=0.741, val_loss=1.38, val_accuracy=0.671, lr=0.1] 16%|█▌        | 15/93 [07:26<35:14, 27.11s/epoch, loss=1.18, accuracy=0.741, val_loss=2.38, val_accuracy=0.399, lr=0.1] 17%|█▋        | 16/93 [07:54<35:01, 27.30s/epoch, loss=1.17, accuracy=0.743, val_loss=1.69, val_accuracy=0.589, lr=0.1] 18%|█▊        | 17/93 [08:22<34:39, 27.37s/epoch, loss=1.17, accuracy=0.745, val_loss=1.53, val_accuracy=0.619, lr=0.1] 19%|█▉        | 18/93 [08:49<34:13, 27.38s/epoch, loss=1.16, accuracy=0.745, val_loss=1.52, val_accuracy=0.642, lr=0.1] 20%|██        | 19/93 [09:16<33:43, 27.34s/epoch, loss=1.17, accuracy=0.745, val_loss=2.89, val_accuracy=0.433, lr=0.0316] 22%|██▏       | 20/93 [09:43<32:56, 27.08s/epoch, loss=1.16, accuracy=0.748, val_loss=6.3, val_accuracy=0.244, lr=0.1]     23%|██▎       | 21/93 [10:09<32:17, 26.91s/epoch, loss=1.16, accuracy=0.748, val_loss=1.7, val_accuracy=0.543, lr=0.1] 24%|██▎       | 22/93 [10:36<31:50, 26.90s/epoch, loss=1.16, accuracy=0.747, val_loss=4.22, val_accuracy=0.216, lr=0.1] 25%|██▍       | 23/93 [11:03<31:25, 26.94s/epoch, loss=1.16, accuracy=0.749, val_loss=2.96, val_accuracy=0.462, lr=0.1] 26%|██▌       | 24/93 [11:30<31:02, 26.99s/epoch, loss=1.16, accuracy=0.749, val_loss=1.82, val_accuracy=0.561, lr=0.0316] 27%|██▋       | 25/93 [11:58<30:51, 27.22s/epoch, loss=1.16, accuracy=0.751, val_loss=2.31, val_accuracy=0.482, lr=0.1]    28%|██▊       | 26/93 [12:26<30:43, 27.51s/epoch, loss=1.16, accuracy=0.75, val_loss=1.77, val_accuracy=0.598, lr=0.1]  29%|██▉       | 27/93 [12:53<30:06, 27.37s/epoch, loss=1.15, accuracy=0.751, val_loss=2.33, val_accuracy=0.451, lr=0.1] 30%|███       | 28/93 [13:20<29:21, 27.10s/epoch, loss=1.16, accuracy=0.75, val_loss=2.02, val_accuracy=0.501, lr=0.1]  31%|███       | 29/93 [13:46<28:43, 26.93s/epoch, loss=1.15, accuracy=0.75, val_loss=3.31, val_accuracy=0.351, lr=0.0316] 32%|███▏      | 30/93 [14:13<28:07, 26.79s/epoch, loss=1.15, accuracy=0.751, val_loss=3.62, val_accuracy=0.31, lr=0.1]    33%|███▎      | 31/93 [14:39<27:35, 26.70s/epoch, loss=1.15, accuracy=0.752, val_loss=1.66, val_accuracy=0.59, lr=0.1] 34%|███▍      | 32/93 [15:06<27:12, 26.77s/epoch, loss=1.15, accuracy=0.752, val_loss=1.62, val_accuracy=0.571, lr=0.1] 35%|███▌      | 33/93 [15:33<26:54, 26.90s/epoch, loss=1.15, accuracy=0.753, val_loss=3.11, val_accuracy=0.407, lr=0.1] 37%|███▋      | 34/93 [16:01<26:36, 27.06s/epoch, loss=1.15, accuracy=0.75, val_loss=2.79, val_accuracy=0.409, lr=0.0316] 38%|███▊      | 35/93 [16:28<26:16, 27.19s/epoch, loss=1.14, accuracy=0.753, val_loss=1.78, val_accuracy=0.533, lr=0.1]   39%|███▊      | 36/93 [16:56<25:59, 27.36s/epoch, loss=1.14, accuracy=0.755, val_loss=2.46, val_accuracy=0.356, lr=0.1] 40%|███▉      | 37/93 [17:24<25:35, 27.42s/epoch, loss=1.15, accuracy=0.754, val_loss=1.91, val_accuracy=0.549, lr=0.1] 41%|████      | 38/93 [17:52<25:16, 27.58s/epoch, loss=1.14, accuracy=0.754, val_loss=2.02, val_accuracy=0.438, lr=0.1] 42%|████▏     | 39/93 [18:19<24:53, 27.65s/epoch, loss=1.14, accuracy=0.753, val_loss=2.1, val_accuracy=0.453, lr=0.0316] 43%|████▎     | 40/93 [18:47<24:27, 27.68s/epoch, loss=1.15, accuracy=0.755, val_loss=1.77, val_accuracy=0.572, lr=0.1]   44%|████▍     | 41/93 [19:14<23:42, 27.35s/epoch, loss=1.15, accuracy=0.752, val_loss=3.52, val_accuracy=0.36, lr=0.1]  45%|████▌     | 42/93 [19:40<23:02, 27.10s/epoch, loss=1.14, accuracy=0.755, val_loss=1.79, val_accuracy=0.584, lr=0.1] 46%|████▌     | 43/93 [20:07<22:35, 27.12s/epoch, loss=1.14, accuracy=0.756, val_loss=1.77, val_accuracy=0.567, lr=0.1] 47%|████▋     | 44/93 [20:35<22:13, 27.21s/epoch, loss=1.14, accuracy=0.754, val_loss=2.15, val_accuracy=0.43, lr=0.0316] 48%|████▊     | 45/93 [21:02<21:49, 27.28s/epoch, loss=1.15, accuracy=0.755, val_loss=1.52, val_accuracy=0.618, lr=0.1]   49%|████▉     | 46/93 [21:30<21:21, 27.26s/epoch, loss=1.14, accuracy=0.756, val_loss=2.18, val_accuracy=0.487, lr=0.1] 51%|█████     | 47/93 [21:57<20:55, 27.30s/epoch, loss=1.14, accuracy=0.755, val_loss=1.68, val_accuracy=0.564, lr=0.1] 52%|█████▏    | 48/93 [22:25<20:36, 27.49s/epoch, loss=1.14, accuracy=0.755, val_loss=1.69, val_accuracy=0.594, lr=0.1] 53%|█████▎    | 49/93 [22:53<20:12, 27.55s/epoch, loss=1.14, accuracy=0.755, val_loss=6.16, val_accuracy=0.236, lr=0.0316] 54%|█████▍    | 50/93 [23:19<19:33, 27.29s/epoch, loss=1.13, accuracy=0.757, val_loss=1.58, val_accuracy=0.619, lr=0.1]    55%|█████▍    | 51/93 [23:46<18:55, 27.03s/epoch, loss=1.14, accuracy=0.755, val_loss=1.52, val_accuracy=0.65, lr=0.1]  56%|█████▌    | 52/93 [24:13<18:30, 27.09s/epoch, loss=1.14, accuracy=0.755, val_loss=2.3, val_accuracy=0.47, lr=0.1]  57%|█████▋    | 53/93 [24:40<18:08, 27.20s/epoch, loss=1.14, accuracy=0.757, val_loss=1.54, val_accuracy=0.62, lr=0.1] 58%|█████▊    | 54/93 [25:08<17:45, 27.33s/epoch, loss=1.14, accuracy=0.757, val_loss=1.79, val_accuracy=0.542, lr=0.0316] 59%|█████▉    | 55/93 [25:35<17:17, 27.30s/epoch, loss=1.13, accuracy=0.761, val_loss=1.51, val_accuracy=0.625, lr=0.1]    60%|██████    | 56/93 [26:03<16:50, 27.31s/epoch, loss=1.14, accuracy=0.756, val_loss=2.58, val_accuracy=0.307, lr=0.1] 61%|██████▏   | 57/93 [26:30<16:27, 27.43s/epoch, loss=1.13, accuracy=0.756, val_loss=1.88, val_accuracy=0.498, lr=0.1] 62%|██████▏   | 58/93 [26:58<16:03, 27.54s/epoch, loss=1.14, accuracy=0.758, val_loss=1.89, val_accuracy=0.534, lr=0.1] 63%|██████▎   | 59/93 [27:26<15:38, 27.60s/epoch, loss=1.13, accuracy=0.757, val_loss=1.61, val_accuracy=0.572, lr=0.0316] 65%|██████▍   | 60/93 [27:54<15:14, 27.70s/epoch, loss=1.13, accuracy=0.76, val_loss=1.74, val_accuracy=0.589, lr=0.1]     66%|██████▌   | 61/93 [28:21<14:41, 27.55s/epoch, loss=1.13, accuracy=0.757, val_loss=2.23, val_accuracy=0.473, lr=0.1] 67%|██████▋   | 62/93 [28:49<14:19, 27.73s/epoch, loss=1.13, accuracy=0.758, val_loss=2.25, val_accuracy=0.415, lr=0.1] 68%|██████▊   | 63/93 [29:17<13:54, 27.80s/epoch, loss=1.13, accuracy=0.759, val_loss=1.82, val_accuracy=0.559, lr=0.1] 69%|██████▉   | 64/93 [29:45<13:24, 27.75s/epoch, loss=1.13, accuracy=0.76, val_loss=2.86, val_accuracy=0.334, lr=0.0316] 70%|██████▉   | 65/93 [30:12<12:51, 27.56s/epoch, loss=1.13, accuracy=0.758, val_loss=1.85, val_accuracy=0.548, lr=0.1]   71%|███████   | 66/93 [30:39<12:23, 27.55s/epoch, loss=1.13, accuracy=0.756, val_loss=1.84, val_accuracy=0.536, lr=0.1] 72%|███████▏  | 67/93 [31:07<11:55, 27.51s/epoch, loss=1.13, accuracy=0.759, val_loss=1.57, val_accuracy=0.631, lr=0.1] 73%|███████▎  | 68/93 [31:34<11:27, 27.52s/epoch, loss=1.12, accuracy=0.759, val_loss=2.08, val_accuracy=0.432, lr=0.1] 74%|███████▍  | 69/93 [32:02<11:00, 27.53s/epoch, loss=1.13, accuracy=0.758, val_loss=1.93, val_accuracy=0.533, lr=0.0316] 75%|███████▌  | 70/93 [32:29<10:30, 27.43s/epoch, loss=1.13, accuracy=0.759, val_loss=2.27, val_accuracy=0.512, lr=0.1]    76%|███████▋  | 71/93 [32:56<09:58, 27.18s/epoch, loss=1.13, accuracy=0.758, val_loss=1.41, val_accuracy=0.654, lr=0.1] 77%|███████▋  | 72/93 [33:23<09:30, 27.18s/epoch, loss=1.13, accuracy=0.758, val_loss=2.68, val_accuracy=0.418, lr=0.1] 78%|███████▊  | 73/93 [33:49<08:57, 26.90s/epoch, loss=1.12, accuracy=0.758, val_loss=2.26, val_accuracy=0.517, lr=0.1] 80%|███████▉  | 74/93 [34:16<08:30, 26.86s/epoch, loss=1.13, accuracy=0.758, val_loss=1.5, val_accuracy=0.615, lr=0.0316] 81%|████████  | 75/93 [34:44<08:10, 27.24s/epoch, loss=1.12, accuracy=0.759, val_loss=2.16, val_accuracy=0.543, lr=0.1]   82%|████████▏ | 76/93 [35:12<07:46, 27.45s/epoch, loss=1.12, accuracy=0.758, val_loss=3.71, val_accuracy=0.336, lr=0.1] 83%|████████▎ | 77/93 [35:40<07:21, 27.57s/epoch, loss=1.13, accuracy=0.756, val_loss=1.82, val_accuracy=0.551, lr=0.1] 84%|████████▍ | 78/93 [36:07<06:53, 27.58s/epoch, loss=1.13, accuracy=0.759, val_loss=2.29, val_accuracy=0.435, lr=0.1] 85%|████████▍ | 79/93 [36:35<06:26, 27.62s/epoch, loss=1.13, accuracy=0.757, val_loss=2.26, val_accuracy=0.46, lr=0.0316] 86%|████████▌ | 80/93 [37:02<05:55, 27.37s/epoch, loss=1.13, accuracy=0.758, val_loss=2.46, val_accuracy=0.375, lr=0.1]   87%|████████▋ | 81/93 [37:29<05:29, 27.43s/epoch, loss=1.13, accuracy=0.757, val_loss=2.17, val_accuracy=0.451, lr=0.1] 88%|████████▊ | 82/93 [37:56<04:59, 27.24s/epoch, loss=0.925, accuracy=0.817, val_loss=0.911, val_accuracy=0.801, lr=0.01] 89%|████████▉ | 83/93 [38:24<04:33, 27.30s/epoch, loss=0.736, accuracy=0.851, val_loss=0.767, val_accuracy=0.827, lr=0.01] 90%|█████████ | 84/93 [38:51<04:05, 27.24s/epoch, loss=0.652, accuracy=0.857, val_loss=0.735, val_accuracy=0.823, lr=0.01] 91%|█████████▏| 85/93 [39:18<03:38, 27.31s/epoch, loss=0.607, accuracy=0.86, val_loss=0.779, val_accuracy=0.8, lr=0.01]    92%|█████████▏| 86/93 [39:46<03:11, 27.42s/epoch, loss=0.582, accuracy=0.865, val_loss=0.772, val_accuracy=0.8, lr=0.01] 94%|█████████▎| 87/93 [40:13<02:43, 27.32s/epoch, loss=0.572, accuracy=0.864, val_loss=0.829, val_accuracy=0.782, lr=0.01] 95%|█████████▍| 88/93 [40:40<02:15, 27.08s/epoch, loss=0.564, accuracy=0.864, val_loss=0.715, val_accuracy=0.817, lr=0.01] 96%|█████████▌| 89/93 [41:06<01:47, 26.78s/epoch, loss=0.564, accuracy=0.865, val_loss=0.939, val_accuracy=0.753, lr=0.01] 97%|█████████▋| 90/93 [41:33<01:21, 27.03s/epoch, loss=0.561, accuracy=0.867, val_loss=0.825, val_accuracy=0.784, lr=0.01] 98%|█████████▊| 91/93 [42:00<00:53, 26.95s/epoch, loss=0.562, accuracy=0.866, val_loss=0.768, val_accuracy=0.81, lr=0.01]  99%|█████████▉| 92/93 [42:27<00:27, 27.07s/epoch, loss=0.558, accuracy=0.869, val_loss=0.905, val_accuracy=0.768, lr=0.01]100%|██████████| 93/93 [42:53<00:00, 26.78s/epoch, loss=0.556, accuracy=0.872, val_loss=0.936, val_accuracy=0.756, lr=0.00316]100%|██████████| 93/93 [42:53<00:00, 27.68s/epoch, loss=0.556, accuracy=0.872, val_loss=0.936, val_accuracy=0.756, lr=0.00316]
Using real-time data augmentation.
Test score: 0.9360975623130798
Test accuracy: 0.7559000253677368


* * * Run SGD for ID = 16_12. * * *


2024-03-05 13:28:29.427171: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 13:28:31.942010: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 13:28:31.943298: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-05 13:28:31.984008: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:18:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-05 13:28:31.984047: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 13:28:31.987347: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 13:28:31.987409: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 13:28:31.989852: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 13:28:31.990585: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 13:28:31.993416: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 13:28:31.995106: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 13:28:32.000654: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 13:28:32.001396: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 13:28:32.001488: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 13:28:33.218227: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-05 13:28:33.218933: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 13:28:33.221521: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:18:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-05 13:28:33.221574: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 13:28:33.221622: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 13:28:33.221644: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 13:28:33.221658: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 13:28:33.221673: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 13:28:33.221693: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 13:28:33.221714: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 13:28:33.221736: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 13:28:33.222346: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 13:28:33.222386: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 13:28:33.891779: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-05 13:28:33.891840: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-05 13:28:33.891860: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-05 13:28:33.893011: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:18:00.0, compute capability: 6.1)
{'id': '16_12', 'seed': 12, 'out_folder': 'results/epoch_budget', 'batch_size': 128, 'epochs': 93, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'bootstrapping': False, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/93 [00:00<?, ?epoch/s]2024-03-05 13:28:34.843264: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-05 13:28:34.854999: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2100000000 Hz
2024-03-05 13:28:36.695302: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 13:28:36.969917: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 13:28:37.915950: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-05 13:28:37.972093: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/93 [01:03<1:37:45, 63.75s/epoch, loss=3, accuracy=0.339, val_loss=2.29, val_accuracy=0.318, lr=0.1]  2%|▏         | 2/93 [01:30<1:03:43, 42.01s/epoch, loss=1.51, accuracy=0.561, val_loss=2.14, val_accuracy=0.391, lr=0.1]  3%|▎         | 3/93 [01:57<52:36, 35.08s/epoch, loss=1.29, accuracy=0.662, val_loss=1.9, val_accuracy=0.516, lr=0.1]     4%|▍         | 4/93 [02:23<46:49, 31.57s/epoch, loss=1.24, accuracy=0.691, val_loss=3.21, val_accuracy=0.353, lr=0.1]  5%|▌         | 5/93 [02:50<44:02, 30.03s/epoch, loss=1.22, accuracy=0.704, val_loss=1.85, val_accuracy=0.489, lr=0.1]  6%|▋         | 6/93 [03:18<42:22, 29.22s/epoch, loss=1.21, accuracy=0.716, val_loss=1.75, val_accuracy=0.539, lr=0.1]  8%|▊         | 7/93 [03:45<40:53, 28.53s/epoch, loss=1.2, accuracy=0.723, val_loss=2.15, val_accuracy=0.495, lr=0.1]   9%|▊         | 8/93 [04:13<40:06, 28.31s/epoch, loss=1.19, accuracy=0.724, val_loss=1.54, val_accuracy=0.599, lr=0.1] 10%|▉         | 9/93 [04:40<39:14, 28.03s/epoch, loss=1.18, accuracy=0.729, val_loss=2.95, val_accuracy=0.408, lr=0.1] 11%|█         | 10/93 [05:08<38:45, 28.02s/epoch, loss=1.18, accuracy=0.731, val_loss=1.52, val_accuracy=0.594, lr=0.1] 12%|█▏        | 11/93 [05:36<38:17, 28.01s/epoch, loss=1.17, accuracy=0.733, val_loss=1.49, val_accuracy=0.628, lr=0.1] 13%|█▎        | 12/93 [06:03<37:16, 27.61s/epoch, loss=1.16, accuracy=0.74, val_loss=1.77, val_accuracy=0.533, lr=0.1]  14%|█▍        | 13/93 [06:30<36:27, 27.34s/epoch, loss=1.17, accuracy=0.74, val_loss=2.82, val_accuracy=0.417, lr=0.1] 15%|█▌        | 14/93 [06:57<36:06, 27.43s/epoch, loss=1.16, accuracy=0.743, val_loss=1.5, val_accuracy=0.644, lr=0.1] 16%|█▌        | 15/93 [07:24<35:21, 27.20s/epoch, loss=1.17, accuracy=0.741, val_loss=2.02, val_accuracy=0.5, lr=0.1]  17%|█▋        | 16/93 [07:50<34:32, 26.92s/epoch, loss=1.17, accuracy=0.742, val_loss=3.36, val_accuracy=0.398, lr=0.0316] 18%|█▊        | 17/93 [08:17<34:03, 26.89s/epoch, loss=1.16, accuracy=0.744, val_loss=1.56, val_accuracy=0.615, lr=0.1]    19%|█▉        | 18/93 [08:44<33:43, 26.98s/epoch, loss=1.15, accuracy=0.747, val_loss=2.02, val_accuracy=0.497, lr=0.1] 20%|██        | 19/93 [09:12<33:24, 27.09s/epoch, loss=1.15, accuracy=0.747, val_loss=1.92, val_accuracy=0.513, lr=0.1] 22%|██▏       | 20/93 [09:39<33:05, 27.20s/epoch, loss=1.15, accuracy=0.746, val_loss=1.95, val_accuracy=0.548, lr=0.1] 23%|██▎       | 21/93 [10:07<32:48, 27.35s/epoch, loss=1.15, accuracy=0.747, val_loss=2.15, val_accuracy=0.431, lr=0.0316] 24%|██▎       | 22/93 [10:34<32:17, 27.29s/epoch, loss=1.14, accuracy=0.749, val_loss=2.24, val_accuracy=0.454, lr=0.1]    25%|██▍       | 23/93 [11:01<31:43, 27.19s/epoch, loss=1.15, accuracy=0.746, val_loss=1.52, val_accuracy=0.616, lr=0.1] 26%|██▌       | 24/93 [11:29<31:25, 27.32s/epoch, loss=1.14, accuracy=0.749, val_loss=2.49, val_accuracy=0.443, lr=0.1] 27%|██▋       | 25/93 [11:56<31:01, 27.38s/epoch, loss=1.14, accuracy=0.751, val_loss=1.76, val_accuracy=0.583, lr=0.1] 28%|██▊       | 26/93 [12:23<30:31, 27.33s/epoch, loss=1.14, accuracy=0.75, val_loss=1.91, val_accuracy=0.518, lr=0.0316] 29%|██▉       | 27/93 [12:51<30:08, 27.40s/epoch, loss=1.14, accuracy=0.75, val_loss=1.98, val_accuracy=0.565, lr=0.1]    30%|███       | 28/93 [13:18<29:34, 27.30s/epoch, loss=1.14, accuracy=0.754, val_loss=1.71, val_accuracy=0.559, lr=0.1] 31%|███       | 29/93 [13:46<29:12, 27.38s/epoch, loss=1.14, accuracy=0.753, val_loss=4.16, val_accuracy=0.26, lr=0.1]  32%|███▏      | 30/93 [14:13<28:41, 27.33s/epoch, loss=1.14, accuracy=0.751, val_loss=2.31, val_accuracy=0.376, lr=0.1] 33%|███▎      | 31/93 [14:40<28:07, 27.22s/epoch, loss=1.13, accuracy=0.753, val_loss=3.37, val_accuracy=0.426, lr=0.0316] 34%|███▍      | 32/93 [15:07<27:40, 27.22s/epoch, loss=1.13, accuracy=0.751, val_loss=1.56, val_accuracy=0.622, lr=0.1]    35%|███▌      | 33/93 [15:35<27:24, 27.41s/epoch, loss=1.13, accuracy=0.753, val_loss=2.93, val_accuracy=0.388, lr=0.1] 37%|███▋      | 34/93 [16:02<27:01, 27.48s/epoch, loss=1.13, accuracy=0.752, val_loss=5.41, val_accuracy=0.283, lr=0.1] 38%|███▊      | 35/93 [16:29<26:26, 27.36s/epoch, loss=1.13, accuracy=0.753, val_loss=1.52, val_accuracy=0.606, lr=0.1] 39%|███▊      | 36/93 [16:57<26:00, 27.37s/epoch, loss=1.13, accuracy=0.752, val_loss=3.38, val_accuracy=0.316, lr=0.0316] 40%|███▉      | 37/93 [17:24<25:24, 27.23s/epoch, loss=1.13, accuracy=0.753, val_loss=1.55, val_accuracy=0.596, lr=0.1]    41%|████      | 38/93 [17:51<25:02, 27.33s/epoch, loss=1.13, accuracy=0.752, val_loss=2.21, val_accuracy=0.46, lr=0.1]  42%|████▏     | 39/93 [18:19<24:36, 27.34s/epoch, loss=1.13, accuracy=0.754, val_loss=2.13, val_accuracy=0.452, lr=0.1] 43%|████▎     | 40/93 [18:46<24:12, 27.41s/epoch, loss=1.12, accuracy=0.757, val_loss=2.87, val_accuracy=0.34, lr=0.1]  44%|████▍     | 41/93 [19:14<23:54, 27.59s/epoch, loss=1.12, accuracy=0.757, val_loss=1.77, val_accuracy=0.488, lr=0.0316] 45%|████▌     | 42/93 [19:42<23:29, 27.64s/epoch, loss=1.12, accuracy=0.755, val_loss=1.64, val_accuracy=0.562, lr=0.1]    46%|████▌     | 43/93 [20:10<23:03, 27.68s/epoch, loss=1.12, accuracy=0.756, val_loss=2.87, val_accuracy=0.408, lr=0.1] 47%|████▋     | 44/93 [20:38<22:37, 27.70s/epoch, loss=1.12, accuracy=0.757, val_loss=2.13, val_accuracy=0.461, lr=0.1] 48%|████▊     | 45/93 [21:05<22:09, 27.69s/epoch, loss=1.12, accuracy=0.756, val_loss=1.64, val_accuracy=0.575, lr=0.1] 49%|████▉     | 46/93 [21:33<21:40, 27.67s/epoch, loss=1.12, accuracy=0.757, val_loss=1.36, val_accuracy=0.666, lr=0.1] 51%|█████     | 47/93 [22:00<21:08, 27.57s/epoch, loss=1.12, accuracy=0.755, val_loss=1.6, val_accuracy=0.579, lr=0.1]  52%|█████▏    | 48/93 [22:28<20:37, 27.51s/epoch, loss=1.12, accuracy=0.757, val_loss=2.09, val_accuracy=0.518, lr=0.1] 53%|█████▎    | 49/93 [22:55<20:08, 27.47s/epoch, loss=1.13, accuracy=0.756, val_loss=1.64, val_accuracy=0.584, lr=0.1] 54%|█████▍    | 50/93 [23:22<19:41, 27.48s/epoch, loss=1.12, accuracy=0.755, val_loss=1.52, val_accuracy=0.628, lr=0.1] 55%|█████▍    | 51/93 [23:50<19:15, 27.52s/epoch, loss=1.12, accuracy=0.757, val_loss=2.23, val_accuracy=0.47, lr=0.0316] 56%|█████▌    | 52/93 [24:17<18:45, 27.44s/epoch, loss=1.12, accuracy=0.757, val_loss=2.27, val_accuracy=0.444, lr=0.1]   57%|█████▋    | 53/93 [24:45<18:24, 27.61s/epoch, loss=1.12, accuracy=0.761, val_loss=2.5, val_accuracy=0.492, lr=0.1]  58%|█████▊    | 54/93 [25:13<17:55, 27.59s/epoch, loss=1.12, accuracy=0.757, val_loss=2.33, val_accuracy=0.488, lr=0.1] 59%|█████▉    | 55/93 [25:40<17:26, 27.55s/epoch, loss=1.11, accuracy=0.759, val_loss=2.52, val_accuracy=0.306, lr=0.1] 60%|██████    | 56/93 [26:08<17:00, 27.59s/epoch, loss=1.12, accuracy=0.757, val_loss=1.54, val_accuracy=0.629, lr=0.0316] 61%|██████▏   | 57/93 [26:35<16:29, 27.50s/epoch, loss=1.12, accuracy=0.757, val_loss=2.37, val_accuracy=0.462, lr=0.1]    62%|██████▏   | 58/93 [27:03<16:00, 27.45s/epoch, loss=1.11, accuracy=0.758, val_loss=2.71, val_accuracy=0.295, lr=0.1] 63%|██████▎   | 59/93 [27:30<15:34, 27.50s/epoch, loss=1.12, accuracy=0.759, val_loss=1.47, val_accuracy=0.642, lr=0.1] 65%|██████▍   | 60/93 [27:58<15:09, 27.56s/epoch, loss=1.11, accuracy=0.758, val_loss=1.67, val_accuracy=0.539, lr=0.1] 66%|██████▌   | 61/93 [28:26<14:44, 27.64s/epoch, loss=1.12, accuracy=0.756, val_loss=1.63, val_accuracy=0.59, lr=0.0316] 67%|██████▋   | 62/93 [28:54<14:18, 27.71s/epoch, loss=1.11, accuracy=0.758, val_loss=1.71, val_accuracy=0.585, lr=0.1]   68%|██████▊   | 63/93 [29:21<13:48, 27.63s/epoch, loss=1.12, accuracy=0.755, val_loss=1.89, val_accuracy=0.492, lr=0.1] 69%|██████▉   | 64/93 [29:48<13:18, 27.52s/epoch, loss=1.11, accuracy=0.759, val_loss=1.96, val_accuracy=0.544, lr=0.1] 70%|██████▉   | 65/93 [30:16<12:51, 27.54s/epoch, loss=1.11, accuracy=0.757, val_loss=1.76, val_accuracy=0.601, lr=0.1] 71%|███████   | 66/93 [30:43<12:23, 27.55s/epoch, loss=1.11, accuracy=0.759, val_loss=2.88, val_accuracy=0.383, lr=0.0316] 72%|███████▏  | 67/93 [31:11<11:54, 27.48s/epoch, loss=1.11, accuracy=0.757, val_loss=1.67, val_accuracy=0.562, lr=0.1]    73%|███████▎  | 68/93 [31:38<11:28, 27.54s/epoch, loss=1.12, accuracy=0.758, val_loss=3.54, val_accuracy=0.338, lr=0.1] 74%|███████▍  | 69/93 [32:05<10:55, 27.32s/epoch, loss=1.11, accuracy=0.76, val_loss=2.28, val_accuracy=0.488, lr=0.1]  75%|███████▌  | 70/93 [32:32<10:23, 27.10s/epoch, loss=1.11, accuracy=0.759, val_loss=3.43, val_accuracy=0.352, lr=0.1] 76%|███████▋  | 71/93 [32:58<09:49, 26.79s/epoch, loss=1.12, accuracy=0.757, val_loss=1.69, val_accuracy=0.545, lr=0.0316] 77%|███████▋  | 72/93 [33:25<09:26, 27.00s/epoch, loss=1.11, accuracy=0.759, val_loss=1.4, val_accuracy=0.66, lr=0.1]      78%|███████▊  | 73/93 [33:51<08:54, 26.71s/epoch, loss=1.11, accuracy=0.759, val_loss=1.67, val_accuracy=0.577, lr=0.1] 80%|███████▉  | 74/93 [34:18<08:26, 26.68s/epoch, loss=1.11, accuracy=0.758, val_loss=3.36, val_accuracy=0.344, lr=0.1] 81%|████████  | 75/93 [34:44<07:56, 26.47s/epoch, loss=1.11, accuracy=0.759, val_loss=2.27, val_accuracy=0.456, lr=0.1] 82%|████████▏ | 76/93 [35:11<07:30, 26.50s/epoch, loss=1.12, accuracy=0.757, val_loss=2.06, val_accuracy=0.523, lr=0.0316] 83%|████████▎ | 77/93 [35:37<07:04, 26.52s/epoch, loss=1.11, accuracy=0.758, val_loss=2.14, val_accuracy=0.502, lr=0.1]    84%|████████▍ | 78/93 [36:04<06:39, 26.60s/epoch, loss=1.11, accuracy=0.758, val_loss=2.63, val_accuracy=0.375, lr=0.1] 85%|████████▍ | 79/93 [36:31<06:12, 26.62s/epoch, loss=1.11, accuracy=0.76, val_loss=2.03, val_accuracy=0.494, lr=0.1]  86%|████████▌ | 80/93 [36:58<05:50, 26.98s/epoch, loss=1.12, accuracy=0.755, val_loss=4.08, val_accuracy=0.338, lr=0.1] 87%|████████▋ | 81/93 [37:26<05:26, 27.24s/epoch, loss=1.1, accuracy=0.759, val_loss=2.26, val_accuracy=0.469, lr=0.0316] 88%|████████▊ | 82/93 [37:54<05:01, 27.37s/epoch, loss=0.896, accuracy=0.819, val_loss=0.931, val_accuracy=0.79, lr=0.01] 89%|████████▉ | 83/93 [38:22<04:34, 27.43s/epoch, loss=0.726, accuracy=0.849, val_loss=0.795, val_accuracy=0.816, lr=0.01] 90%|█████████ | 84/93 [38:49<04:07, 27.47s/epoch, loss=0.65, accuracy=0.857, val_loss=0.814, val_accuracy=0.79, lr=0.01]   91%|█████████▏| 85/93 [39:16<03:39, 27.42s/epoch, loss=0.603, accuracy=0.861, val_loss=0.898, val_accuracy=0.76, lr=0.01] 92%|█████████▏| 86/93 [39:44<03:12, 27.46s/epoch, loss=0.579, accuracy=0.862, val_loss=0.891, val_accuracy=0.759, lr=0.01] 94%|█████████▎| 87/93 [40:12<02:45, 27.52s/epoch, loss=0.571, accuracy=0.862, val_loss=0.825, val_accuracy=0.79, lr=0.01]  95%|█████████▍| 88/93 [40:39<02:17, 27.55s/epoch, loss=0.57, accuracy=0.862, val_loss=0.79, val_accuracy=0.79, lr=0.01]   96%|█████████▌| 89/93 [41:07<01:50, 27.68s/epoch, loss=0.565, accuracy=0.865, val_loss=0.838, val_accuracy=0.789, lr=0.01] 97%|█████████▋| 90/93 [41:35<01:23, 27.80s/epoch, loss=0.563, accuracy=0.867, val_loss=0.983, val_accuracy=0.735, lr=0.01] 98%|█████████▊| 91/93 [42:03<00:55, 27.70s/epoch, loss=0.556, accuracy=0.87, val_loss=0.755, val_accuracy=0.808, lr=0.01]  99%|█████████▉| 92/93 [42:31<00:27, 27.71s/epoch, loss=0.559, accuracy=0.871, val_loss=0.972, val_accuracy=0.749, lr=0.01]100%|██████████| 93/93 [42:58<00:00, 27.76s/epoch, loss=0.554, accuracy=0.873, val_loss=0.733, val_accuracy=0.823, lr=0.01]100%|██████████| 93/93 [42:58<00:00, 27.73s/epoch, loss=0.554, accuracy=0.873, val_loss=0.733, val_accuracy=0.823, lr=0.01]
Using real-time data augmentation.
Test score: 0.7334837317466736
Test accuracy: 0.8234000205993652


* * * Run SGD for ID = 16_13. * * *


2024-03-05 14:11:37.798301: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 14:11:40.522183: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 14:11:40.523600: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-05 14:11:40.566589: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:18:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-05 14:11:40.566633: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 14:11:40.570288: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 14:11:40.570365: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 14:11:40.573235: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 14:11:40.574010: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 14:11:40.577097: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 14:11:40.578886: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 14:11:40.585144: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 14:11:40.585911: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 14:11:40.585998: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 14:11:41.914292: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-05 14:11:41.915357: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 14:11:41.915880: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:18:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-05 14:11:41.915913: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 14:11:41.915948: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 14:11:41.915963: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 14:11:41.915976: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 14:11:41.915991: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 14:11:41.916004: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 14:11:41.916018: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 14:11:41.916032: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 14:11:41.916597: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 14:11:41.916636: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 14:11:42.636543: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-05 14:11:42.636618: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-05 14:11:42.636629: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-05 14:11:42.638485: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:18:00.0, compute capability: 6.1)
{'id': '16_13', 'seed': 13, 'out_folder': 'results/epoch_budget', 'batch_size': 128, 'epochs': 93, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'bootstrapping': False, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/93 [00:00<?, ?epoch/s]2024-03-05 14:11:43.571478: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-05 14:11:43.572218: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2100000000 Hz
2024-03-05 14:11:45.810253: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 14:11:46.162821: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 14:11:47.184038: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-05 14:11:47.235137: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/93 [01:04<1:39:34, 64.94s/epoch, loss=2.73, accuracy=0.459, val_loss=2.07, val_accuracy=0.435, lr=0.1]  2%|▏         | 2/93 [01:32<1:05:05, 42.92s/epoch, loss=1.39, accuracy=0.633, val_loss=1.8, val_accuracy=0.529, lr=0.1]   3%|▎         | 3/93 [02:00<53:51, 35.91s/epoch, loss=1.26, accuracy=0.682, val_loss=2.17, val_accuracy=0.398, lr=0.1]   4%|▍         | 4/93 [02:28<48:45, 32.87s/epoch, loss=1.22, accuracy=0.707, val_loss=3.08, val_accuracy=0.331, lr=0.1]  5%|▌         | 5/93 [02:55<45:23, 30.95s/epoch, loss=1.2, accuracy=0.72, val_loss=2.11, val_accuracy=0.51, lr=0.1]     6%|▋         | 6/93 [03:22<43:02, 29.68s/epoch, loss=1.2, accuracy=0.723, val_loss=1.71, val_accuracy=0.559, lr=0.1]  8%|▊         | 7/93 [03:50<41:34, 29.00s/epoch, loss=1.18, accuracy=0.732, val_loss=3.24, val_accuracy=0.383, lr=0.1]  9%|▊         | 8/93 [04:18<40:26, 28.55s/epoch, loss=1.18, accuracy=0.733, val_loss=1.62, val_accuracy=0.569, lr=0.1] 10%|▉         | 9/93 [04:45<39:29, 28.21s/epoch, loss=1.18, accuracy=0.737, val_loss=2.14, val_accuracy=0.451, lr=0.1] 11%|█         | 10/93 [05:13<38:52, 28.10s/epoch, loss=1.16, accuracy=0.741, val_loss=1.81, val_accuracy=0.536, lr=0.1] 12%|█▏        | 11/93 [05:41<38:16, 28.00s/epoch, loss=1.16, accuracy=0.742, val_loss=4.02, val_accuracy=0.27, lr=0.1]  13%|█▎        | 12/93 [06:09<38:03, 28.20s/epoch, loss=1.16, accuracy=0.743, val_loss=2.12, val_accuracy=0.463, lr=0.1] 14%|█▍        | 13/93 [06:37<37:32, 28.16s/epoch, loss=1.15, accuracy=0.744, val_loss=1.6, val_accuracy=0.589, lr=0.1]  15%|█▌        | 14/93 [07:05<36:58, 28.08s/epoch, loss=1.16, accuracy=0.746, val_loss=1.72, val_accuracy=0.554, lr=0.1] 16%|█▌        | 15/93 [07:34<36:38, 28.19s/epoch, loss=1.15, accuracy=0.746, val_loss=1.75, val_accuracy=0.543, lr=0.1] 17%|█▋        | 16/93 [08:02<35:58, 28.04s/epoch, loss=1.15, accuracy=0.75, val_loss=2.27, val_accuracy=0.414, lr=0.1]  18%|█▊        | 17/93 [08:30<35:48, 28.26s/epoch, loss=1.14, accuracy=0.75, val_loss=1.78, val_accuracy=0.518, lr=0.1] 19%|█▉        | 18/93 [08:58<35:17, 28.24s/epoch, loss=1.14, accuracy=0.75, val_loss=2.3, val_accuracy=0.461, lr=0.0316] 20%|██        | 19/93 [09:27<34:54, 28.31s/epoch, loss=1.14, accuracy=0.749, val_loss=2.21, val_accuracy=0.477, lr=0.1]  22%|██▏       | 20/93 [09:55<34:15, 28.16s/epoch, loss=1.14, accuracy=0.752, val_loss=1.76, val_accuracy=0.527, lr=0.1] 23%|██▎       | 21/93 [10:22<33:31, 27.94s/epoch, loss=1.14, accuracy=0.753, val_loss=2.03, val_accuracy=0.423, lr=0.1] 24%|██▎       | 22/93 [10:49<32:50, 27.75s/epoch, loss=1.13, accuracy=0.753, val_loss=1.51, val_accuracy=0.625, lr=0.1] 25%|██▍       | 23/93 [11:17<32:16, 27.67s/epoch, loss=1.14, accuracy=0.751, val_loss=2.32, val_accuracy=0.438, lr=0.1] 26%|██▌       | 24/93 [11:45<31:48, 27.66s/epoch, loss=1.13, accuracy=0.754, val_loss=1.68, val_accuracy=0.597, lr=0.1] 27%|██▋       | 25/93 [12:12<31:24, 27.71s/epoch, loss=1.14, accuracy=0.752, val_loss=1.86, val_accuracy=0.516, lr=0.1] 28%|██▊       | 26/93 [12:40<30:43, 27.52s/epoch, loss=1.13, accuracy=0.755, val_loss=1.78, val_accuracy=0.585, lr=0.1] 29%|██▉       | 27/93 [13:07<30:17, 27.53s/epoch, loss=1.14, accuracy=0.754, val_loss=2.46, val_accuracy=0.407, lr=0.0316] 30%|███       | 28/93 [13:35<29:48, 27.51s/epoch, loss=1.13, accuracy=0.758, val_loss=1.56, val_accuracy=0.588, lr=0.1]    31%|███       | 29/93 [14:02<29:20, 27.51s/epoch, loss=1.13, accuracy=0.756, val_loss=2.43, val_accuracy=0.41, lr=0.1]  32%|███▏      | 30/93 [14:29<28:51, 27.49s/epoch, loss=1.12, accuracy=0.756, val_loss=1.99, val_accuracy=0.503, lr=0.1] 33%|███▎      | 31/93 [14:57<28:16, 27.37s/epoch, loss=1.13, accuracy=0.756, val_loss=2.55, val_accuracy=0.419, lr=0.1] 34%|███▍      | 32/93 [15:24<27:50, 27.39s/epoch, loss=1.14, accuracy=0.758, val_loss=1.68, val_accuracy=0.58, lr=0.0316] 35%|███▌      | 33/93 [15:52<27:25, 27.43s/epoch, loss=1.13, accuracy=0.757, val_loss=2.13, val_accuracy=0.442, lr=0.1]   37%|███▋      | 34/93 [16:19<26:58, 27.43s/epoch, loss=1.13, accuracy=0.755, val_loss=2.21, val_accuracy=0.48, lr=0.1]  38%|███▊      | 35/93 [16:46<26:29, 27.40s/epoch, loss=1.13, accuracy=0.756, val_loss=1.71, val_accuracy=0.559, lr=0.1] 39%|███▊      | 36/93 [17:14<26:04, 27.44s/epoch, loss=1.12, accuracy=0.757, val_loss=2.6, val_accuracy=0.411, lr=0.1]  40%|███▉      | 37/93 [17:41<25:27, 27.27s/epoch, loss=1.12, accuracy=0.756, val_loss=1.71, val_accuracy=0.567, lr=0.0316] 41%|████      | 38/93 [18:08<24:59, 27.26s/epoch, loss=1.13, accuracy=0.754, val_loss=7.1, val_accuracy=0.146, lr=0.1]     42%|████▏     | 39/93 [18:35<24:33, 27.28s/epoch, loss=1.13, accuracy=0.757, val_loss=1.99, val_accuracy=0.475, lr=0.1] 43%|████▎     | 40/93 [19:02<24:00, 27.17s/epoch, loss=1.12, accuracy=0.756, val_loss=2.56, val_accuracy=0.413, lr=0.1] 44%|████▍     | 41/93 [19:30<23:38, 27.29s/epoch, loss=1.11, accuracy=0.76, val_loss=2.07, val_accuracy=0.489, lr=0.1]  45%|████▌     | 42/93 [19:57<23:14, 27.33s/epoch, loss=1.12, accuracy=0.759, val_loss=1.58, val_accuracy=0.615, lr=0.0316] 46%|████▌     | 43/93 [20:25<22:48, 27.37s/epoch, loss=1.12, accuracy=0.76, val_loss=1.57, val_accuracy=0.592, lr=0.1]     47%|████▋     | 44/93 [20:52<22:18, 27.31s/epoch, loss=1.12, accuracy=0.757, val_loss=2.89, val_accuracy=0.404, lr=0.1] 48%|████▊     | 45/93 [21:19<21:54, 27.39s/epoch, loss=1.11, accuracy=0.761, val_loss=2.78, val_accuracy=0.413, lr=0.1] 49%|████▉     | 46/93 [21:47<21:28, 27.41s/epoch, loss=1.11, accuracy=0.757, val_loss=1.78, val_accuracy=0.562, lr=0.1] 51%|█████     | 47/93 [22:15<21:05, 27.52s/epoch, loss=1.12, accuracy=0.756, val_loss=1.68, val_accuracy=0.56, lr=0.0316] 52%|█████▏    | 48/93 [22:42<20:42, 27.60s/epoch, loss=1.11, accuracy=0.758, val_loss=1.36, val_accuracy=0.676, lr=0.1]   53%|█████▎    | 49/93 [23:10<20:13, 27.57s/epoch, loss=1.12, accuracy=0.756, val_loss=1.9, val_accuracy=0.51, lr=0.1]   54%|█████▍    | 50/93 [23:37<19:44, 27.55s/epoch, loss=1.11, accuracy=0.758, val_loss=2.54, val_accuracy=0.374, lr=0.1] 55%|█████▍    | 51/93 [24:05<19:20, 27.63s/epoch, loss=1.12, accuracy=0.757, val_loss=1.75, val_accuracy=0.595, lr=0.1] 56%|█████▌    | 52/93 [24:33<18:52, 27.62s/epoch, loss=1.11, accuracy=0.76, val_loss=2.18, val_accuracy=0.508, lr=0.1]  57%|█████▋    | 53/93 [25:00<18:24, 27.62s/epoch, loss=1.11, accuracy=0.76, val_loss=2.36, val_accuracy=0.418, lr=0.0316] 58%|█████▊    | 54/93 [25:28<17:58, 27.65s/epoch, loss=1.1, accuracy=0.76, val_loss=1.36, val_accuracy=0.651, lr=0.1]     59%|█████▉    | 55/93 [25:56<17:32, 27.70s/epoch, loss=1.11, accuracy=0.76, val_loss=1.77, val_accuracy=0.534, lr=0.1] 60%|██████    | 56/93 [26:24<17:04, 27.69s/epoch, loss=1.11, accuracy=0.758, val_loss=1.94, val_accuracy=0.509, lr=0.1] 61%|██████▏   | 57/93 [26:51<16:32, 27.57s/epoch, loss=1.11, accuracy=0.758, val_loss=2.16, val_accuracy=0.41, lr=0.1]  62%|██████▏   | 58/93 [27:18<15:56, 27.32s/epoch, loss=1.11, accuracy=0.759, val_loss=1.52, val_accuracy=0.609, lr=0.0316] 63%|██████▎   | 59/93 [27:44<15:20, 27.09s/epoch, loss=1.11, accuracy=0.761, val_loss=2.48, val_accuracy=0.447, lr=0.1]    65%|██████▍   | 60/93 [28:12<14:56, 27.18s/epoch, loss=1.11, accuracy=0.759, val_loss=1.59, val_accuracy=0.607, lr=0.1] 66%|██████▌   | 61/93 [28:40<14:36, 27.40s/epoch, loss=1.11, accuracy=0.76, val_loss=1.85, val_accuracy=0.501, lr=0.1]  67%|██████▋   | 62/93 [29:07<14:13, 27.55s/epoch, loss=1.11, accuracy=0.76, val_loss=1.98, val_accuracy=0.477, lr=0.1] 68%|██████▊   | 63/93 [29:35<13:44, 27.49s/epoch, loss=1.1, accuracy=0.763, val_loss=2.82, val_accuracy=0.302, lr=0.0316] 69%|██████▉   | 64/93 [30:02<13:12, 27.34s/epoch, loss=1.11, accuracy=0.759, val_loss=1.6, val_accuracy=0.593, lr=0.1]    70%|██████▉   | 65/93 [30:29<12:46, 27.36s/epoch, loss=1.11, accuracy=0.757, val_loss=1.94, val_accuracy=0.45, lr=0.1] 71%|███████   | 66/93 [30:57<12:20, 27.42s/epoch, loss=1.11, accuracy=0.757, val_loss=1.88, val_accuracy=0.537, lr=0.1] 72%|███████▏  | 67/93 [31:23<11:47, 27.21s/epoch, loss=1.1, accuracy=0.759, val_loss=3.47, val_accuracy=0.413, lr=0.1]  73%|███████▎  | 68/93 [31:51<11:23, 27.33s/epoch, loss=1.1, accuracy=0.759, val_loss=4.66, val_accuracy=0.298, lr=0.0316] 74%|███████▍  | 69/93 [32:18<10:56, 27.34s/epoch, loss=1.11, accuracy=0.76, val_loss=1.92, val_accuracy=0.505, lr=0.1]    75%|███████▌  | 70/93 [32:46<10:31, 27.47s/epoch, loss=1.11, accuracy=0.759, val_loss=1.38, val_accuracy=0.681, lr=0.1] 76%|███████▋  | 71/93 [33:13<10:00, 27.29s/epoch, loss=1.11, accuracy=0.76, val_loss=2.36, val_accuracy=0.464, lr=0.1]  77%|███████▋  | 72/93 [33:40<09:32, 27.28s/epoch, loss=1.11, accuracy=0.758, val_loss=1.72, val_accuracy=0.555, lr=0.1] 78%|███████▊  | 73/93 [34:08<09:07, 27.35s/epoch, loss=1.12, accuracy=0.757, val_loss=1.89, val_accuracy=0.526, lr=0.0316] 80%|███████▉  | 74/93 [34:35<08:41, 27.44s/epoch, loss=1.1, accuracy=0.762, val_loss=3.32, val_accuracy=0.292, lr=0.1]     81%|████████  | 75/93 [35:03<08:11, 27.32s/epoch, loss=1.11, accuracy=0.758, val_loss=1.81, val_accuracy=0.537, lr=0.1] 82%|████████▏ | 76/93 [35:29<07:41, 27.17s/epoch, loss=1.11, accuracy=0.76, val_loss=1.59, val_accuracy=0.591, lr=0.1]  83%|████████▎ | 77/93 [35:57<07:15, 27.20s/epoch, loss=1.1, accuracy=0.76, val_loss=2.49, val_accuracy=0.485, lr=0.1]  84%|████████▍ | 78/93 [36:23<06:45, 27.01s/epoch, loss=1.1, accuracy=0.759, val_loss=2.38, val_accuracy=0.382, lr=0.0316] 85%|████████▍ | 79/93 [36:49<06:14, 26.74s/epoch, loss=1.1, accuracy=0.761, val_loss=2, val_accuracy=0.508, lr=0.1]       86%|████████▌ | 80/93 [37:15<05:45, 26.56s/epoch, loss=1.1, accuracy=0.76, val_loss=1.51, val_accuracy=0.612, lr=0.1] 87%|████████▋ | 81/93 [37:43<05:21, 26.79s/epoch, loss=1.11, accuracy=0.757, val_loss=2.03, val_accuracy=0.531, lr=0.1] 88%|████████▊ | 82/93 [38:10<04:54, 26.80s/epoch, loss=0.904, accuracy=0.816, val_loss=0.913, val_accuracy=0.794, lr=0.01] 89%|████████▉ | 83/93 [38:37<04:29, 26.97s/epoch, loss=0.725, accuracy=0.849, val_loss=0.783, val_accuracy=0.816, lr=0.01] 90%|█████████ | 84/93 [39:04<04:03, 27.06s/epoch, loss=0.642, accuracy=0.858, val_loss=0.775, val_accuracy=0.808, lr=0.01] 91%|█████████▏| 85/93 [39:32<03:37, 27.17s/epoch, loss=0.604, accuracy=0.858, val_loss=0.742, val_accuracy=0.808, lr=0.01] 92%|█████████▏| 86/93 [39:59<03:10, 27.19s/epoch, loss=0.579, accuracy=0.861, val_loss=0.71, val_accuracy=0.816, lr=0.01]  94%|█████████▎| 87/93 [40:27<02:44, 27.36s/epoch, loss=0.565, accuracy=0.864, val_loss=0.942, val_accuracy=0.744, lr=0.01] 95%|█████████▍| 88/93 [40:54<02:16, 27.23s/epoch, loss=0.566, accuracy=0.863, val_loss=0.736, val_accuracy=0.807, lr=0.01] 96%|█████████▌| 89/93 [41:21<01:49, 27.29s/epoch, loss=0.557, accuracy=0.867, val_loss=0.754, val_accuracy=0.804, lr=0.01] 97%|█████████▋| 90/93 [41:48<01:21, 27.31s/epoch, loss=0.557, accuracy=0.867, val_loss=0.841, val_accuracy=0.77, lr=0.01]  98%|█████████▊| 91/93 [42:15<00:54, 27.16s/epoch, loss=0.558, accuracy=0.867, val_loss=0.758, val_accuracy=0.805, lr=0.00316] 99%|█████████▉| 92/93 [42:41<00:26, 26.86s/epoch, loss=0.554, accuracy=0.869, val_loss=0.998, val_accuracy=0.741, lr=0.01]   100%|██████████| 93/93 [43:08<00:00, 26.92s/epoch, loss=0.55, accuracy=0.872, val_loss=0.83, val_accuracy=0.785, lr=0.01]  100%|██████████| 93/93 [43:08<00:00, 27.84s/epoch, loss=0.55, accuracy=0.872, val_loss=0.83, val_accuracy=0.785, lr=0.01]
Using real-time data augmentation.
Test score: 0.8301526308059692
Test accuracy: 0.7853000164031982


* * * Run SGD for ID = 16_14. * * *


2024-03-05 14:54:56.251488: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 14:54:58.963983: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 14:54:58.965345: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-05 14:54:59.006480: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:18:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-05 14:54:59.006525: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 14:54:59.010052: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 14:54:59.010123: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 14:54:59.012624: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 14:54:59.013350: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 14:54:59.016316: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 14:54:59.018103: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 14:54:59.023992: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 14:54:59.024662: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 14:54:59.024746: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 14:55:00.238651: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-05 14:55:00.239273: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 14:55:00.240371: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:18:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-05 14:55:00.240421: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 14:55:00.240476: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 14:55:00.240496: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 14:55:00.240514: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 14:55:00.240532: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 14:55:00.240552: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 14:55:00.240572: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 14:55:00.240592: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 14:55:00.241164: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 14:55:00.241207: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 14:55:00.852397: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-05 14:55:00.852463: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-05 14:55:00.852474: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-05 14:55:00.853617: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:18:00.0, compute capability: 6.1)
{'id': '16_14', 'seed': 14, 'out_folder': 'results/epoch_budget', 'batch_size': 128, 'epochs': 93, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'bootstrapping': False, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/93 [00:00<?, ?epoch/s]2024-03-05 14:55:01.745263: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-05 14:55:01.745908: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2100000000 Hz
2024-03-05 14:55:03.802638: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 14:55:04.131869: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 14:55:05.191260: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-05 14:55:05.253602: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/93 [01:08<1:45:25, 68.75s/epoch, loss=3.14, accuracy=0.31, val_loss=2.14, val_accuracy=0.308, lr=0.1]  2%|▏         | 2/93 [01:35<1:06:39, 43.95s/epoch, loss=1.54, accuracy=0.545, val_loss=2.19, val_accuracy=0.367, lr=0.1]  3%|▎         | 3/93 [02:01<53:56, 35.96s/epoch, loss=1.34, accuracy=0.645, val_loss=1.47, val_accuracy=0.596, lr=0.1]    4%|▍         | 4/93 [02:28<47:52, 32.27s/epoch, loss=1.28, accuracy=0.685, val_loss=1.61, val_accuracy=0.572, lr=0.1]  5%|▌         | 5/93 [02:55<44:33, 30.38s/epoch, loss=1.25, accuracy=0.7, val_loss=1.81, val_accuracy=0.551, lr=0.1]    6%|▋         | 6/93 [03:22<42:31, 29.33s/epoch, loss=1.24, accuracy=0.709, val_loss=1.97, val_accuracy=0.476, lr=0.1]  8%|▊         | 7/93 [03:49<41:02, 28.63s/epoch, loss=1.22, accuracy=0.718, val_loss=3.23, val_accuracy=0.414, lr=0.1]  9%|▊         | 8/93 [04:17<40:04, 28.28s/epoch, loss=1.22, accuracy=0.718, val_loss=1.84, val_accuracy=0.5, lr=0.0316] 10%|▉         | 9/93 [04:42<38:12, 27.29s/epoch, loss=1.21, accuracy=0.724, val_loss=2.04, val_accuracy=0.486, lr=0.1]  11%|█         | 10/93 [05:10<38:02, 27.49s/epoch, loss=1.2, accuracy=0.725, val_loss=1.64, val_accuracy=0.586, lr=0.1] 12%|█▏        | 11/93 [05:37<37:26, 27.39s/epoch, loss=1.2, accuracy=0.729, val_loss=1.87, val_accuracy=0.546, lr=0.1] 13%|█▎        | 12/93 [06:04<36:53, 27.33s/epoch, loss=1.19, accuracy=0.733, val_loss=3.09, val_accuracy=0.397, lr=0.1] 14%|█▍        | 13/93 [06:32<36:42, 27.53s/epoch, loss=1.19, accuracy=0.733, val_loss=2.43, val_accuracy=0.382, lr=0.0316] 15%|█▌        | 14/93 [07:00<36:24, 27.65s/epoch, loss=1.19, accuracy=0.734, val_loss=1.97, val_accuracy=0.487, lr=0.1]    16%|█▌        | 15/93 [07:28<35:49, 27.56s/epoch, loss=1.18, accuracy=0.735, val_loss=2.92, val_accuracy=0.309, lr=0.1] 17%|█▋        | 16/93 [07:55<35:17, 27.50s/epoch, loss=1.18, accuracy=0.738, val_loss=1.87, val_accuracy=0.502, lr=0.1] 18%|█▊        | 17/93 [08:22<34:46, 27.46s/epoch, loss=1.18, accuracy=0.737, val_loss=3.09, val_accuracy=0.265, lr=0.1] 19%|█▉        | 18/93 [08:49<34:10, 27.34s/epoch, loss=1.18, accuracy=0.74, val_loss=2.61, val_accuracy=0.357, lr=0.0316] 20%|██        | 19/93 [09:17<33:48, 27.42s/epoch, loss=1.18, accuracy=0.737, val_loss=3.57, val_accuracy=0.312, lr=0.1]   22%|██▏       | 20/93 [09:45<33:27, 27.50s/epoch, loss=1.17, accuracy=0.741, val_loss=1.56, val_accuracy=0.617, lr=0.1] 23%|██▎       | 21/93 [10:12<32:58, 27.48s/epoch, loss=1.17, accuracy=0.742, val_loss=2.25, val_accuracy=0.5, lr=0.1]   24%|██▎       | 22/93 [10:40<32:34, 27.53s/epoch, loss=1.17, accuracy=0.74, val_loss=4.03, val_accuracy=0.211, lr=0.1] 25%|██▍       | 23/93 [11:07<32:06, 27.52s/epoch, loss=1.17, accuracy=0.742, val_loss=1.85, val_accuracy=0.495, lr=0.0316] 26%|██▌       | 24/93 [11:35<31:39, 27.52s/epoch, loss=1.17, accuracy=0.744, val_loss=2.3, val_accuracy=0.479, lr=0.1]     27%|██▋       | 25/93 [12:02<31:12, 27.53s/epoch, loss=1.17, accuracy=0.745, val_loss=2.37, val_accuracy=0.454, lr=0.1] 28%|██▊       | 26/93 [12:29<30:30, 27.32s/epoch, loss=1.16, accuracy=0.746, val_loss=1.64, val_accuracy=0.57, lr=0.1]  29%|██▉       | 27/93 [12:56<30:01, 27.29s/epoch, loss=1.16, accuracy=0.748, val_loss=2.27, val_accuracy=0.504, lr=0.1] 30%|███       | 28/93 [13:24<29:40, 27.39s/epoch, loss=1.17, accuracy=0.745, val_loss=3.49, val_accuracy=0.349, lr=0.0316] 31%|███       | 29/93 [13:51<29:04, 27.26s/epoch, loss=1.16, accuracy=0.746, val_loss=2.26, val_accuracy=0.437, lr=0.1]    32%|███▏      | 30/93 [14:18<28:36, 27.24s/epoch, loss=1.16, accuracy=0.748, val_loss=1.69, val_accuracy=0.591, lr=0.1] 33%|███▎      | 31/93 [14:46<28:16, 27.36s/epoch, loss=1.17, accuracy=0.747, val_loss=3.49, val_accuracy=0.319, lr=0.1] 34%|███▍      | 32/93 [15:13<27:45, 27.31s/epoch, loss=1.16, accuracy=0.747, val_loss=1.91, val_accuracy=0.529, lr=0.1] 35%|███▌      | 33/93 [15:40<27:18, 27.31s/epoch, loss=1.16, accuracy=0.745, val_loss=2.68, val_accuracy=0.372, lr=0.0316] 37%|███▋      | 34/93 [16:07<26:47, 27.25s/epoch, loss=1.16, accuracy=0.747, val_loss=1.82, val_accuracy=0.51, lr=0.1]     38%|███▊      | 35/93 [16:35<26:23, 27.29s/epoch, loss=1.15, accuracy=0.747, val_loss=5.66, val_accuracy=0.191, lr=0.1] 39%|███▊      | 36/93 [17:02<25:58, 27.34s/epoch, loss=1.15, accuracy=0.748, val_loss=1.7, val_accuracy=0.548, lr=0.1]  40%|███▉      | 37/93 [17:30<25:29, 27.32s/epoch, loss=1.15, accuracy=0.75, val_loss=1.58, val_accuracy=0.598, lr=0.1] 41%|████      | 38/93 [17:57<25:07, 27.41s/epoch, loss=1.16, accuracy=0.749, val_loss=1.88, val_accuracy=0.564, lr=0.0316] 42%|████▏     | 39/93 [18:25<24:40, 27.42s/epoch, loss=1.15, accuracy=0.753, val_loss=2.27, val_accuracy=0.489, lr=0.1]    43%|████▎     | 40/93 [18:52<24:19, 27.54s/epoch, loss=1.15, accuracy=0.753, val_loss=1.94, val_accuracy=0.507, lr=0.1] 44%|████▍     | 41/93 [19:20<23:52, 27.55s/epoch, loss=1.15, accuracy=0.751, val_loss=1.81, val_accuracy=0.495, lr=0.1] 45%|████▌     | 42/93 [19:47<23:24, 27.53s/epoch, loss=1.15, accuracy=0.753, val_loss=1.48, val_accuracy=0.637, lr=0.1] 46%|████▌     | 43/93 [20:15<22:55, 27.52s/epoch, loss=1.15, accuracy=0.75, val_loss=3.03, val_accuracy=0.385, lr=0.0316] 47%|████▋     | 44/93 [20:43<22:29, 27.55s/epoch, loss=1.14, accuracy=0.751, val_loss=2.13, val_accuracy=0.518, lr=0.1]   48%|████▊     | 45/93 [21:10<21:58, 27.47s/epoch, loss=1.14, accuracy=0.752, val_loss=1.88, val_accuracy=0.543, lr=0.1] 49%|████▉     | 46/93 [21:37<21:24, 27.33s/epoch, loss=1.14, accuracy=0.753, val_loss=2.35, val_accuracy=0.426, lr=0.1] 51%|█████     | 47/93 [22:04<20:54, 27.28s/epoch, loss=1.15, accuracy=0.754, val_loss=1.62, val_accuracy=0.588, lr=0.1] 52%|█████▏    | 48/93 [22:31<20:24, 27.22s/epoch, loss=1.14, accuracy=0.754, val_loss=3.82, val_accuracy=0.304, lr=0.0316] 53%|█████▎    | 49/93 [22:58<19:53, 27.13s/epoch, loss=1.14, accuracy=0.755, val_loss=2.5, val_accuracy=0.457, lr=0.1]     54%|█████▍    | 50/93 [23:25<19:24, 27.07s/epoch, loss=1.15, accuracy=0.752, val_loss=3.17, val_accuracy=0.323, lr=0.1] 55%|█████▍    | 51/93 [23:52<18:56, 27.06s/epoch, loss=1.14, accuracy=0.754, val_loss=1.98, val_accuracy=0.513, lr=0.1] 56%|█████▌    | 52/93 [24:19<18:32, 27.14s/epoch, loss=1.13, accuracy=0.753, val_loss=1.59, val_accuracy=0.595, lr=0.1] 57%|█████▋    | 53/93 [24:46<18:05, 27.13s/epoch, loss=1.14, accuracy=0.752, val_loss=2.33, val_accuracy=0.391, lr=0.0316] 58%|█████▊    | 54/93 [25:14<17:37, 27.13s/epoch, loss=1.14, accuracy=0.751, val_loss=3.2, val_accuracy=0.348, lr=0.1]     59%|█████▉    | 55/93 [25:41<17:09, 27.10s/epoch, loss=1.14, accuracy=0.753, val_loss=2.07, val_accuracy=0.511, lr=0.1] 60%|██████    | 56/93 [26:07<16:33, 26.85s/epoch, loss=1.14, accuracy=0.753, val_loss=2.18, val_accuracy=0.394, lr=0.1] 61%|██████▏   | 57/93 [26:33<16:03, 26.78s/epoch, loss=1.13, accuracy=0.753, val_loss=1.47, val_accuracy=0.638, lr=0.1] 62%|██████▏   | 58/93 [27:00<15:32, 26.65s/epoch, loss=1.14, accuracy=0.753, val_loss=1.95, val_accuracy=0.54, lr=0.1]  63%|██████▎   | 59/93 [27:27<15:11, 26.80s/epoch, loss=1.13, accuracy=0.754, val_loss=1.68, val_accuracy=0.572, lr=0.1] 65%|██████▍   | 60/93 [27:54<14:43, 26.78s/epoch, loss=1.14, accuracy=0.753, val_loss=1.85, val_accuracy=0.547, lr=0.1] 66%|██████▌   | 61/93 [28:21<14:16, 26.78s/epoch, loss=1.14, accuracy=0.754, val_loss=1.92, val_accuracy=0.506, lr=0.1] 67%|██████▋   | 62/93 [28:47<13:46, 26.66s/epoch, loss=1.15, accuracy=0.75, val_loss=2.22, val_accuracy=0.459, lr=0.0316] 68%|██████▊   | 63/93 [29:13<13:17, 26.57s/epoch, loss=1.13, accuracy=0.753, val_loss=2.12, val_accuracy=0.432, lr=0.1]   69%|██████▉   | 64/93 [29:40<12:52, 26.64s/epoch, loss=1.13, accuracy=0.753, val_loss=1.63, val_accuracy=0.567, lr=0.1] 70%|██████▉   | 65/93 [30:08<12:34, 26.93s/epoch, loss=1.14, accuracy=0.753, val_loss=2.06, val_accuracy=0.506, lr=0.1] 71%|███████   | 66/93 [30:34<12:04, 26.84s/epoch, loss=1.14, accuracy=0.755, val_loss=1.88, val_accuracy=0.505, lr=0.1] 72%|███████▏  | 67/93 [31:02<11:40, 26.96s/epoch, loss=1.14, accuracy=0.752, val_loss=1.86, val_accuracy=0.572, lr=0.0316] 73%|███████▎  | 68/93 [31:28<11:12, 26.92s/epoch, loss=1.13, accuracy=0.756, val_loss=1.74, val_accuracy=0.545, lr=0.1]    74%|███████▍  | 69/93 [31:55<10:43, 26.81s/epoch, loss=1.14, accuracy=0.752, val_loss=2.31, val_accuracy=0.428, lr=0.1] 75%|███████▌  | 70/93 [32:22<10:20, 26.97s/epoch, loss=1.13, accuracy=0.755, val_loss=2.24, val_accuracy=0.458, lr=0.1] 76%|███████▋  | 71/93 [32:49<09:52, 26.93s/epoch, loss=1.13, accuracy=0.754, val_loss=5.27, val_accuracy=0.207, lr=0.1] 77%|███████▋  | 72/93 [33:15<09:20, 26.67s/epoch, loss=1.12, accuracy=0.756, val_loss=3.06, val_accuracy=0.39, lr=0.0316] 78%|███████▊  | 73/93 [33:42<08:51, 26.58s/epoch, loss=1.13, accuracy=0.751, val_loss=2.17, val_accuracy=0.476, lr=0.1]   80%|███████▉  | 74/93 [34:08<08:23, 26.51s/epoch, loss=1.13, accuracy=0.754, val_loss=4, val_accuracy=0.281, lr=0.1]    81%|████████  | 75/93 [34:35<08:00, 26.70s/epoch, loss=1.13, accuracy=0.753, val_loss=3.3, val_accuracy=0.466, lr=0.1] 82%|████████▏ | 76/93 [35:03<07:38, 26.95s/epoch, loss=1.12, accuracy=0.756, val_loss=1.7, val_accuracy=0.571, lr=0.1] 83%|████████▎ | 77/93 [35:30<07:12, 27.06s/epoch, loss=1.13, accuracy=0.756, val_loss=2.33, val_accuracy=0.415, lr=0.0316] 84%|████████▍ | 78/93 [35:57<06:45, 27.06s/epoch, loss=1.13, accuracy=0.754, val_loss=2.2, val_accuracy=0.473, lr=0.1]     85%|████████▍ | 79/93 [36:24<06:17, 26.93s/epoch, loss=1.12, accuracy=0.754, val_loss=2.05, val_accuracy=0.518, lr=0.1] 86%|████████▌ | 80/93 [36:51<05:51, 27.02s/epoch, loss=1.12, accuracy=0.755, val_loss=4.82, val_accuracy=0.255, lr=0.1] 87%|████████▋ | 81/93 [37:18<05:23, 27.00s/epoch, loss=1.12, accuracy=0.755, val_loss=2.47, val_accuracy=0.425, lr=0.1] 88%|████████▊ | 82/93 [37:45<04:56, 26.94s/epoch, loss=0.915, accuracy=0.814, val_loss=0.892, val_accuracy=0.811, lr=0.01] 89%|████████▉ | 83/93 [38:12<04:29, 26.99s/epoch, loss=0.736, accuracy=0.846, val_loss=0.817, val_accuracy=0.805, lr=0.01] 90%|█████████ | 84/93 [38:38<04:02, 26.94s/epoch, loss=0.656, accuracy=0.856, val_loss=0.831, val_accuracy=0.795, lr=0.01] 91%|█████████▏| 85/93 [39:06<03:36, 27.02s/epoch, loss=0.608, accuracy=0.859, val_loss=0.73, val_accuracy=0.817, lr=0.01]  92%|█████████▏| 86/93 [39:33<03:09, 27.00s/epoch, loss=0.585, accuracy=0.861, val_loss=0.703, val_accuracy=0.817, lr=0.01] 94%|█████████▎| 87/93 [40:00<02:42, 27.09s/epoch, loss=0.576, accuracy=0.86, val_loss=0.851, val_accuracy=0.766, lr=0.01]  95%|█████████▍| 88/93 [40:27<02:15, 27.07s/epoch, loss=0.571, accuracy=0.862, val_loss=0.731, val_accuracy=0.805, lr=0.01] 96%|█████████▌| 89/93 [40:54<01:48, 27.12s/epoch, loss=0.567, accuracy=0.863, val_loss=0.795, val_accuracy=0.779, lr=0.01] 97%|█████████▋| 90/93 [41:22<01:21, 27.27s/epoch, loss=0.567, accuracy=0.863, val_loss=1.02, val_accuracy=0.729, lr=0.01]  98%|█████████▊| 91/93 [41:48<00:54, 27.06s/epoch, loss=0.567, accuracy=0.866, val_loss=0.83, val_accuracy=0.787, lr=0.00316] 99%|█████████▉| 92/93 [42:15<00:27, 27.07s/epoch, loss=0.559, accuracy=0.869, val_loss=0.839, val_accuracy=0.784, lr=0.01]  100%|██████████| 93/93 [42:42<00:00, 27.03s/epoch, loss=0.561, accuracy=0.869, val_loss=1.02, val_accuracy=0.727, lr=0.01] 100%|██████████| 93/93 [42:42<00:00, 27.56s/epoch, loss=0.561, accuracy=0.869, val_loss=1.02, val_accuracy=0.727, lr=0.01]
Using real-time data augmentation.
Test score: 1.0180126428604126
Test accuracy: 0.7268000245094299


* * * Run SGD for ID = 16_15. * * *


2024-03-05 15:37:48.596157: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 15:37:51.301554: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 15:37:51.302868: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-05 15:37:51.345081: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:18:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-05 15:37:51.345123: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 15:37:51.348784: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 15:37:51.348867: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 15:37:51.351724: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 15:37:51.352564: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 15:37:51.355678: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 15:37:51.357509: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 15:37:51.363600: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 15:37:51.364345: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 15:37:51.364432: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 15:37:52.636427: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-05 15:37:52.637892: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 15:37:52.639065: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:18:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-05 15:37:52.639102: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 15:37:52.639142: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 15:37:52.639158: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 15:37:52.639172: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 15:37:52.639186: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 15:37:52.639202: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 15:37:52.639217: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 15:37:52.639233: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 15:37:52.639816: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 15:37:52.639871: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 15:37:53.283872: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-05 15:37:53.283920: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-05 15:37:53.283930: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-05 15:37:53.284979: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:18:00.0, compute capability: 6.1)
{'id': '16_15', 'seed': 15, 'out_folder': 'results/epoch_budget', 'batch_size': 128, 'epochs': 93, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'bootstrapping': False, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/93 [00:00<?, ?epoch/s]2024-03-05 15:37:54.146820: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-05 15:37:54.159001: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2100000000 Hz
2024-03-05 15:37:56.104023: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 15:37:56.447021: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 15:37:57.262774: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-05 15:37:57.322244: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/93 [01:06<1:41:19, 66.09s/epoch, loss=3.23, accuracy=0.296, val_loss=2.49, val_accuracy=0.247, lr=0.1]  2%|▏         | 2/93 [01:32<1:05:04, 42.91s/epoch, loss=1.62, accuracy=0.499, val_loss=2.73, val_accuracy=0.333, lr=0.1]  3%|▎         | 3/93 [01:59<53:17, 35.53s/epoch, loss=1.4, accuracy=0.609, val_loss=1.78, val_accuracy=0.517, lr=0.1]     4%|▍         | 4/93 [02:26<47:32, 32.05s/epoch, loss=1.33, accuracy=0.656, val_loss=1.57, val_accuracy=0.571, lr=0.1]  5%|▌         | 5/93 [02:52<44:03, 30.04s/epoch, loss=1.28, accuracy=0.685, val_loss=1.71, val_accuracy=0.578, lr=0.1]  6%|▋         | 6/93 [03:19<42:07, 29.06s/epoch, loss=1.26, accuracy=0.697, val_loss=2.02, val_accuracy=0.512, lr=0.1]  8%|▊         | 7/93 [03:47<40:53, 28.53s/epoch, loss=1.25, accuracy=0.704, val_loss=2.06, val_accuracy=0.431, lr=0.1]  9%|▊         | 8/93 [04:13<39:22, 27.79s/epoch, loss=1.24, accuracy=0.711, val_loss=4.59, val_accuracy=0.271, lr=0.1] 10%|▉         | 9/93 [04:40<38:21, 27.39s/epoch, loss=1.22, accuracy=0.719, val_loss=1.95, val_accuracy=0.499, lr=0.0316] 11%|█         | 10/93 [05:07<37:43, 27.27s/epoch, loss=1.22, accuracy=0.723, val_loss=2.2, val_accuracy=0.467, lr=0.1]    12%|█▏        | 11/93 [05:33<36:49, 26.95s/epoch, loss=1.22, accuracy=0.723, val_loss=2.19, val_accuracy=0.431, lr=0.1] 13%|█▎        | 12/93 [06:00<36:41, 27.18s/epoch, loss=1.21, accuracy=0.73, val_loss=2.67, val_accuracy=0.408, lr=0.1]  14%|█▍        | 13/93 [06:28<36:25, 27.32s/epoch, loss=1.21, accuracy=0.727, val_loss=1.59, val_accuracy=0.601, lr=0.1] 15%|█▌        | 14/93 [06:56<36:05, 27.41s/epoch, loss=1.2, accuracy=0.731, val_loss=1.9, val_accuracy=0.533, lr=0.0316] 16%|█▌        | 15/93 [07:23<35:24, 27.24s/epoch, loss=1.2, accuracy=0.732, val_loss=1.99, val_accuracy=0.506, lr=0.1]   17%|█▋        | 16/93 [07:50<35:03, 27.32s/epoch, loss=1.19, accuracy=0.737, val_loss=2.07, val_accuracy=0.461, lr=0.1] 18%|█▊        | 17/93 [08:18<34:44, 27.42s/epoch, loss=1.2, accuracy=0.738, val_loss=2.5, val_accuracy=0.391, lr=0.1]   19%|█▉        | 18/93 [08:45<34:10, 27.34s/epoch, loss=1.19, accuracy=0.737, val_loss=1.71, val_accuracy=0.553, lr=0.1] 20%|██        | 19/93 [09:12<33:39, 27.29s/epoch, loss=1.19, accuracy=0.738, val_loss=2, val_accuracy=0.56, lr=0.0316]  22%|██▏       | 20/93 [09:40<33:22, 27.43s/epoch, loss=1.18, accuracy=0.74, val_loss=1.97, val_accuracy=0.573, lr=0.1] 23%|██▎       | 21/93 [10:07<32:43, 27.28s/epoch, loss=1.19, accuracy=0.74, val_loss=3.2, val_accuracy=0.308, lr=0.1]  24%|██▎       | 22/93 [10:34<32:07, 27.14s/epoch, loss=1.18, accuracy=0.738, val_loss=2.63, val_accuracy=0.333, lr=0.1] 25%|██▍       | 23/93 [11:01<31:47, 27.25s/epoch, loss=1.18, accuracy=0.741, val_loss=1.64, val_accuracy=0.576, lr=0.1] 26%|██▌       | 24/93 [11:29<31:30, 27.40s/epoch, loss=1.18, accuracy=0.74, val_loss=1.93, val_accuracy=0.529, lr=0.0316] 27%|██▋       | 25/93 [11:56<31:03, 27.40s/epoch, loss=1.18, accuracy=0.741, val_loss=2.45, val_accuracy=0.379, lr=0.1]   28%|██▊       | 26/93 [12:23<30:17, 27.13s/epoch, loss=1.18, accuracy=0.74, val_loss=1.66, val_accuracy=0.589, lr=0.1]  29%|██▉       | 27/93 [12:45<28:14, 25.67s/epoch, loss=1.17, accuracy=0.743, val_loss=2.89, val_accuracy=0.374, lr=0.1] 30%|███       | 28/93 [13:07<26:38, 24.59s/epoch, loss=1.16, accuracy=0.744, val_loss=2.41, val_accuracy=0.406, lr=0.1] 31%|███       | 29/93 [13:30<25:46, 24.17s/epoch, loss=1.16, accuracy=0.746, val_loss=3.36, val_accuracy=0.316, lr=0.0316] 32%|███▏      | 30/93 [13:52<24:38, 23.47s/epoch, loss=1.16, accuracy=0.745, val_loss=2.11, val_accuracy=0.471, lr=0.1]    33%|███▎      | 31/93 [14:16<24:15, 23.47s/epoch, loss=1.16, accuracy=0.747, val_loss=1.86, val_accuracy=0.51, lr=0.1]  34%|███▍      | 32/93 [14:38<23:37, 23.23s/epoch, loss=1.16, accuracy=0.747, val_loss=1.79, val_accuracy=0.522, lr=0.1] 35%|███▌      | 33/93 [15:00<22:51, 22.85s/epoch, loss=1.15, accuracy=0.747, val_loss=3.33, val_accuracy=0.359, lr=0.1] 37%|███▋      | 34/93 [15:23<22:20, 22.72s/epoch, loss=1.15, accuracy=0.746, val_loss=2.63, val_accuracy=0.445, lr=0.0316] 38%|███▊      | 35/93 [15:45<21:45, 22.51s/epoch, loss=1.15, accuracy=0.748, val_loss=3.11, val_accuracy=0.229, lr=0.1]    39%|███▊      | 36/93 [16:07<21:26, 22.57s/epoch, loss=1.15, accuracy=0.746, val_loss=4.62, val_accuracy=0.261, lr=0.1] 40%|███▉      | 37/93 [16:32<21:32, 23.08s/epoch, loss=1.15, accuracy=0.748, val_loss=1.87, val_accuracy=0.536, lr=0.1] 41%|████      | 38/93 [16:58<22:01, 24.03s/epoch, loss=1.14, accuracy=0.75, val_loss=2.09, val_accuracy=0.438, lr=0.1]  42%|████▏     | 39/93 [17:23<21:53, 24.32s/epoch, loss=1.15, accuracy=0.747, val_loss=2.13, val_accuracy=0.479, lr=0.0316] 43%|████▎     | 40/93 [17:47<21:33, 24.41s/epoch, loss=1.15, accuracy=0.748, val_loss=1.53, val_accuracy=0.608, lr=0.1]    44%|████▍     | 41/93 [18:13<21:27, 24.76s/epoch, loss=1.15, accuracy=0.747, val_loss=2.16, val_accuracy=0.474, lr=0.1] 45%|████▌     | 42/93 [18:38<21:12, 24.94s/epoch, loss=1.14, accuracy=0.75, val_loss=1.92, val_accuracy=0.536, lr=0.1]  46%|████▌     | 43/93 [19:04<20:50, 25.01s/epoch, loss=1.15, accuracy=0.749, val_loss=2.87, val_accuracy=0.376, lr=0.1] 47%|████▋     | 44/93 [19:29<20:24, 24.99s/epoch, loss=1.15, accuracy=0.749, val_loss=1.67, val_accuracy=0.588, lr=0.1] 48%|████▊     | 45/93 [19:54<20:02, 25.05s/epoch, loss=1.15, accuracy=0.75, val_loss=2.6, val_accuracy=0.397, lr=0.0316] 49%|████▉     | 46/93 [20:19<19:44, 25.20s/epoch, loss=1.14, accuracy=0.751, val_loss=1.67, val_accuracy=0.609, lr=0.1]  51%|█████     | 47/93 [20:45<19:25, 25.34s/epoch, loss=1.14, accuracy=0.749, val_loss=2.41, val_accuracy=0.426, lr=0.1] 52%|█████▏    | 48/93 [21:11<19:04, 25.44s/epoch, loss=1.15, accuracy=0.751, val_loss=2.42, val_accuracy=0.424, lr=0.1] 53%|█████▎    | 49/93 [21:36<18:43, 25.54s/epoch, loss=1.15, accuracy=0.75, val_loss=2.93, val_accuracy=0.377, lr=0.1]  54%|█████▍    | 50/93 [21:59<17:45, 24.79s/epoch, loss=1.13, accuracy=0.753, val_loss=2.39, val_accuracy=0.37, lr=0.0316] 55%|█████▍    | 51/93 [22:22<16:47, 24.00s/epoch, loss=1.13, accuracy=0.753, val_loss=3.13, val_accuracy=0.336, lr=0.1]   56%|█████▌    | 52/93 [22:44<16:08, 23.63s/epoch, loss=1.14, accuracy=0.75, val_loss=1.46, val_accuracy=0.639, lr=0.1]  57%|█████▋    | 53/93 [23:08<15:49, 23.75s/epoch, loss=1.14, accuracy=0.753, val_loss=1.94, val_accuracy=0.566, lr=0.1] 58%|█████▊    | 54/93 [23:30<15:05, 23.23s/epoch, loss=1.14, accuracy=0.753, val_loss=2.24, val_accuracy=0.51, lr=0.1]  59%|█████▉    | 55/93 [23:54<14:48, 23.39s/epoch, loss=1.14, accuracy=0.75, val_loss=2.73, val_accuracy=0.447, lr=0.1] 60%|██████    | 56/93 [24:19<14:40, 23.80s/epoch, loss=1.13, accuracy=0.753, val_loss=1.65, val_accuracy=0.583, lr=0.1] 61%|██████▏   | 57/93 [24:43<14:18, 23.84s/epoch, loss=1.13, accuracy=0.754, val_loss=2.51, val_accuracy=0.527, lr=0.0316] 62%|██████▏   | 58/93 [25:07<14:00, 24.02s/epoch, loss=1.13, accuracy=0.753, val_loss=1.36, val_accuracy=0.682, lr=0.1]    63%|██████▎   | 59/93 [25:32<13:47, 24.34s/epoch, loss=1.13, accuracy=0.754, val_loss=2.08, val_accuracy=0.444, lr=0.1] 65%|██████▍   | 60/93 [25:57<13:27, 24.48s/epoch, loss=1.13, accuracy=0.752, val_loss=1.89, val_accuracy=0.532, lr=0.1] 66%|██████▌   | 61/93 [26:22<13:06, 24.58s/epoch, loss=1.13, accuracy=0.755, val_loss=2.1, val_accuracy=0.467, lr=0.1]  67%|██████▋   | 62/93 [26:44<12:20, 23.88s/epoch, loss=1.13, accuracy=0.755, val_loss=2.16, val_accuracy=0.39, lr=0.1] 68%|██████▊   | 63/93 [27:07<11:48, 23.63s/epoch, loss=1.13, accuracy=0.754, val_loss=2.36, val_accuracy=0.423, lr=0.0316] 69%|██████▉   | 64/93 [27:29<11:09, 23.09s/epoch, loss=1.13, accuracy=0.75, val_loss=2.01, val_accuracy=0.479, lr=0.1]     70%|██████▉   | 65/93 [27:51<10:39, 22.85s/epoch, loss=1.12, accuracy=0.756, val_loss=1.64, val_accuracy=0.6, lr=0.1]  71%|███████   | 66/93 [28:13<10:07, 22.50s/epoch, loss=1.12, accuracy=0.755, val_loss=2.34, val_accuracy=0.414, lr=0.1] 72%|███████▏  | 67/93 [28:36<09:51, 22.76s/epoch, loss=1.13, accuracy=0.753, val_loss=2.86, val_accuracy=0.403, lr=0.1] 73%|███████▎  | 68/93 [28:59<09:29, 22.80s/epoch, loss=1.12, accuracy=0.75, val_loss=1.57, val_accuracy=0.605, lr=0.0316] 74%|███████▍  | 69/93 [29:21<09:02, 22.60s/epoch, loss=1.13, accuracy=0.75, val_loss=2.34, val_accuracy=0.427, lr=0.1]    75%|███████▌  | 70/93 [29:43<08:34, 22.37s/epoch, loss=1.12, accuracy=0.755, val_loss=2.52, val_accuracy=0.406, lr=0.1] 76%|███████▋  | 71/93 [30:06<08:12, 22.40s/epoch, loss=1.12, accuracy=0.755, val_loss=2.05, val_accuracy=0.437, lr=0.1] 77%|███████▋  | 72/93 [30:28<07:48, 22.30s/epoch, loss=1.13, accuracy=0.754, val_loss=2.71, val_accuracy=0.425, lr=0.1] 78%|███████▊  | 73/93 [30:51<07:32, 22.64s/epoch, loss=1.13, accuracy=0.755, val_loss=2.27, val_accuracy=0.419, lr=0.0316] 80%|███████▉  | 74/93 [31:13<07:06, 22.44s/epoch, loss=1.13, accuracy=0.754, val_loss=3.26, val_accuracy=0.343, lr=0.1]    81%|████████  | 75/93 [31:36<06:44, 22.45s/epoch, loss=1.12, accuracy=0.756, val_loss=1.73, val_accuracy=0.561, lr=0.1] 82%|████████▏ | 76/93 [31:58<06:23, 22.54s/epoch, loss=1.12, accuracy=0.756, val_loss=1.7, val_accuracy=0.567, lr=0.1]  83%|████████▎ | 77/93 [32:21<05:59, 22.49s/epoch, loss=1.12, accuracy=0.754, val_loss=2.22, val_accuracy=0.501, lr=0.1] 84%|████████▍ | 78/93 [32:43<05:35, 22.36s/epoch, loss=1.13, accuracy=0.754, val_loss=2.4, val_accuracy=0.413, lr=0.0316] 85%|████████▍ | 79/93 [33:08<05:25, 23.23s/epoch, loss=1.12, accuracy=0.754, val_loss=1.96, val_accuracy=0.501, lr=0.1]   86%|████████▌ | 80/93 [33:32<05:04, 23.41s/epoch, loss=1.12, accuracy=0.753, val_loss=2.41, val_accuracy=0.441, lr=0.1] 87%|████████▋ | 81/93 [33:54<04:34, 22.88s/epoch, loss=1.12, accuracy=0.756, val_loss=4.92, val_accuracy=0.22, lr=0.1]  88%|████████▊ | 82/93 [34:18<04:17, 23.37s/epoch, loss=0.91, accuracy=0.815, val_loss=0.988, val_accuracy=0.764, lr=0.01] 89%|████████▉ | 83/93 [34:40<03:48, 22.82s/epoch, loss=0.733, accuracy=0.848, val_loss=0.787, val_accuracy=0.817, lr=0.01] 90%|█████████ | 84/93 [35:02<03:23, 22.60s/epoch, loss=0.655, accuracy=0.855, val_loss=1.01, val_accuracy=0.721, lr=0.01]  91%|█████████▏| 85/93 [35:26<03:05, 23.23s/epoch, loss=0.612, accuracy=0.859, val_loss=0.785, val_accuracy=0.797, lr=0.01] 92%|█████████▏| 86/93 [35:48<02:39, 22.78s/epoch, loss=0.59, accuracy=0.86, val_loss=1.29, val_accuracy=0.669, lr=0.01]    94%|█████████▎| 87/93 [36:10<02:14, 22.41s/epoch, loss=0.579, accuracy=0.861, val_loss=0.969, val_accuracy=0.744, lr=0.01] 95%|█████████▍| 88/93 [36:32<01:52, 22.48s/epoch, loss=0.576, accuracy=0.86, val_loss=0.812, val_accuracy=0.782, lr=0.01]  96%|█████████▌| 89/93 [36:58<01:33, 23.36s/epoch, loss=0.568, accuracy=0.864, val_loss=1.06, val_accuracy=0.724, lr=0.01] 97%|█████████▋| 90/93 [37:19<01:08, 22.84s/epoch, loss=0.566, accuracy=0.865, val_loss=0.826, val_accuracy=0.783, lr=0.00316] 98%|█████████▊| 91/93 [37:41<00:45, 22.60s/epoch, loss=0.565, accuracy=0.867, val_loss=0.857, val_accuracy=0.785, lr=0.01]    99%|█████████▉| 92/93 [38:03<00:22, 22.36s/epoch, loss=0.566, accuracy=0.868, val_loss=1.08, val_accuracy=0.728, lr=0.01] 100%|██████████| 93/93 [38:25<00:00, 22.13s/epoch, loss=0.566, accuracy=0.868, val_loss=0.793, val_accuracy=0.796, lr=0.01]100%|██████████| 93/93 [38:25<00:00, 24.79s/epoch, loss=0.566, accuracy=0.868, val_loss=0.793, val_accuracy=0.796, lr=0.01]
Using real-time data augmentation.
Test score: 0.7930058836936951
Test accuracy: 0.7960000038146973


* * * Run SGD for ID = 16_16. * * *


2024-03-05 16:16:23.829293: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 16:16:30.074161: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 16:16:30.075819: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-05 16:16:30.115651: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:18:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-05 16:16:30.115688: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 16:16:30.138472: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 16:16:30.138530: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 16:16:30.152188: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 16:16:30.171352: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 16:16:30.190285: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 16:16:30.204006: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 16:16:30.220476: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 16:16:30.221141: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 16:16:30.221232: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 16:16:31.547894: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-05 16:16:31.549330: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 16:16:31.549811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:18:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-05 16:16:31.549854: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 16:16:31.549888: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 16:16:31.549901: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 16:16:31.549913: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 16:16:31.549926: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 16:16:31.549938: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 16:16:31.549950: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 16:16:31.549963: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 16:16:31.550498: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 16:16:31.550530: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 16:16:32.441211: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-05 16:16:32.441283: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-05 16:16:32.441293: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-05 16:16:32.442851: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:18:00.0, compute capability: 6.1)
{'id': '16_16', 'seed': 16, 'out_folder': 'results/epoch_budget', 'batch_size': 128, 'epochs': 93, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'bootstrapping': False, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/93 [00:00<?, ?epoch/s]2024-03-05 16:16:33.255065: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-05 16:16:33.255688: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2100000000 Hz
2024-03-05 16:16:35.035036: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 16:16:35.297274: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 16:16:36.358237: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-05 16:16:36.394033: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/93 [00:54<1:23:49, 54.66s/epoch, loss=3.07, accuracy=0.314, val_loss=2.46, val_accuracy=0.289, lr=0.1]  2%|▏         | 2/93 [01:16<53:59, 35.60s/epoch, loss=1.56, accuracy=0.537, val_loss=2.95, val_accuracy=0.309, lr=0.1]    3%|▎         | 3/93 [01:39<44:11, 29.46s/epoch, loss=1.34, accuracy=0.644, val_loss=1.96, val_accuracy=0.434, lr=0.1]  4%|▍         | 4/93 [02:01<39:17, 26.49s/epoch, loss=1.27, accuracy=0.683, val_loss=2.07, val_accuracy=0.483, lr=0.1]  5%|▌         | 5/93 [02:22<36:24, 24.82s/epoch, loss=1.24, accuracy=0.703, val_loss=1.98, val_accuracy=0.496, lr=0.1]  6%|▋         | 6/93 [02:44<34:35, 23.86s/epoch, loss=1.23, accuracy=0.714, val_loss=2.49, val_accuracy=0.472, lr=0.1]  8%|▊         | 7/93 [03:06<33:21, 23.27s/epoch, loss=1.21, accuracy=0.724, val_loss=1.69, val_accuracy=0.576, lr=0.1]  9%|▊         | 8/93 [03:28<32:20, 22.83s/epoch, loss=1.2, accuracy=0.727, val_loss=2.05, val_accuracy=0.47, lr=0.1]   10%|▉         | 9/93 [03:50<31:32, 22.53s/epoch, loss=1.19, accuracy=0.734, val_loss=2.78, val_accuracy=0.447, lr=0.1] 11%|█         | 10/93 [04:12<30:51, 22.31s/epoch, loss=1.18, accuracy=0.736, val_loss=3.13, val_accuracy=0.377, lr=0.1] 12%|█▏        | 11/93 [04:36<31:21, 22.94s/epoch, loss=1.18, accuracy=0.738, val_loss=2.73, val_accuracy=0.426, lr=0.1] 13%|█▎        | 12/93 [05:01<31:47, 23.55s/epoch, loss=1.17, accuracy=0.741, val_loss=1.62, val_accuracy=0.581, lr=0.1] 14%|█▍        | 13/93 [05:24<30:52, 23.16s/epoch, loss=1.17, accuracy=0.741, val_loss=1.95, val_accuracy=0.573, lr=0.1] 15%|█▌        | 14/93 [05:46<30:02, 22.82s/epoch, loss=1.17, accuracy=0.745, val_loss=3.26, val_accuracy=0.397, lr=0.1] 16%|█▌        | 15/93 [06:08<29:41, 22.84s/epoch, loss=1.16, accuracy=0.743, val_loss=2.08, val_accuracy=0.576, lr=0.1] 17%|█▋        | 16/93 [06:34<30:12, 23.54s/epoch, loss=1.16, accuracy=0.746, val_loss=1.67, val_accuracy=0.54, lr=0.1]  18%|█▊        | 17/93 [06:59<30:36, 24.16s/epoch, loss=1.16, accuracy=0.747, val_loss=2.93, val_accuracy=0.32, lr=0.0316] 19%|█▉        | 18/93 [07:22<29:32, 23.64s/epoch, loss=1.15, accuracy=0.749, val_loss=1.82, val_accuracy=0.547, lr=0.1]   20%|██        | 19/93 [07:45<29:12, 23.68s/epoch, loss=1.15, accuracy=0.749, val_loss=1.99, val_accuracy=0.536, lr=0.1] 22%|██▏       | 20/93 [08:07<28:07, 23.12s/epoch, loss=1.14, accuracy=0.75, val_loss=1.74, val_accuracy=0.589, lr=0.1]  23%|██▎       | 21/93 [08:29<27:15, 22.71s/epoch, loss=1.16, accuracy=0.748, val_loss=1.62, val_accuracy=0.604, lr=0.1] 24%|██▎       | 22/93 [08:52<26:48, 22.65s/epoch, loss=1.15, accuracy=0.75, val_loss=1.84, val_accuracy=0.558, lr=0.1]  25%|██▍       | 23/93 [09:14<26:20, 22.58s/epoch, loss=1.14, accuracy=0.752, val_loss=2.29, val_accuracy=0.447, lr=0.1] 26%|██▌       | 24/93 [09:36<25:52, 22.50s/epoch, loss=1.15, accuracy=0.751, val_loss=1.67, val_accuracy=0.573, lr=0.1] 27%|██▋       | 25/93 [09:58<25:23, 22.40s/epoch, loss=1.15, accuracy=0.754, val_loss=2.44, val_accuracy=0.409, lr=0.1] 28%|██▊       | 26/93 [10:23<25:38, 22.96s/epoch, loss=1.15, accuracy=0.752, val_loss=4.19, val_accuracy=0.209, lr=0.0316] 29%|██▉       | 27/93 [10:48<25:52, 23.52s/epoch, loss=1.13, accuracy=0.756, val_loss=3.35, val_accuracy=0.376, lr=0.1]    30%|███       | 28/93 [11:14<26:24, 24.38s/epoch, loss=1.14, accuracy=0.752, val_loss=2.04, val_accuracy=0.515, lr=0.1] 31%|███       | 29/93 [11:40<26:38, 24.98s/epoch, loss=1.13, accuracy=0.754, val_loss=1.63, val_accuracy=0.587, lr=0.1] 32%|███▏      | 30/93 [12:08<27:08, 25.84s/epoch, loss=1.14, accuracy=0.753, val_loss=2.23, val_accuracy=0.435, lr=0.1] 33%|███▎      | 31/93 [12:36<27:25, 26.53s/epoch, loss=1.14, accuracy=0.752, val_loss=1.43, val_accuracy=0.66, lr=0.1]  34%|███▍      | 32/93 [13:04<27:27, 27.01s/epoch, loss=1.13, accuracy=0.755, val_loss=3.42, val_accuracy=0.32, lr=0.1] 35%|███▌      | 33/93 [13:33<27:24, 27.40s/epoch, loss=1.13, accuracy=0.758, val_loss=1.7, val_accuracy=0.597, lr=0.1] 37%|███▋      | 34/93 [14:00<26:59, 27.46s/epoch, loss=1.14, accuracy=0.755, val_loss=1.9, val_accuracy=0.505, lr=0.1] 38%|███▊      | 35/93 [14:29<26:48, 27.73s/epoch, loss=1.13, accuracy=0.755, val_loss=8.83, val_accuracy=0.101, lr=0.1] 39%|███▊      | 36/93 [14:56<26:18, 27.69s/epoch, loss=1.13, accuracy=0.754, val_loss=2.49, val_accuracy=0.408, lr=0.0316] 40%|███▉      | 37/93 [15:25<26:11, 28.06s/epoch, loss=1.12, accuracy=0.758, val_loss=1.5, val_accuracy=0.646, lr=0.1]     41%|████      | 38/93 [15:54<25:50, 28.20s/epoch, loss=1.13, accuracy=0.756, val_loss=2.94, val_accuracy=0.292, lr=0.1] 42%|████▏     | 39/93 [16:21<25:14, 28.04s/epoch, loss=1.12, accuracy=0.755, val_loss=2.32, val_accuracy=0.477, lr=0.1] 43%|████▎     | 40/93 [16:50<24:53, 28.19s/epoch, loss=1.11, accuracy=0.757, val_loss=6.18, val_accuracy=0.218, lr=0.1] 44%|████▍     | 41/93 [17:18<24:27, 28.22s/epoch, loss=1.12, accuracy=0.756, val_loss=5.14, val_accuracy=0.243, lr=0.0316] 45%|████▌     | 42/93 [17:47<24:03, 28.31s/epoch, loss=1.11, accuracy=0.759, val_loss=2.31, val_accuracy=0.495, lr=0.1]    46%|████▌     | 43/93 [18:15<23:36, 28.33s/epoch, loss=1.12, accuracy=0.758, val_loss=1.52, val_accuracy=0.623, lr=0.1] 47%|████▋     | 44/93 [18:44<23:15, 28.48s/epoch, loss=1.12, accuracy=0.759, val_loss=1.6, val_accuracy=0.603, lr=0.1]  48%|████▊     | 45/93 [19:14<23:15, 29.07s/epoch, loss=1.11, accuracy=0.758, val_loss=1.97, val_accuracy=0.469, lr=0.1] 49%|████▉     | 46/93 [19:43<22:43, 29.00s/epoch, loss=1.12, accuracy=0.76, val_loss=2.49, val_accuracy=0.331, lr=0.0316] 51%|█████     | 47/93 [20:10<21:45, 28.38s/epoch, loss=1.11, accuracy=0.757, val_loss=1.79, val_accuracy=0.518, lr=0.1]   52%|█████▏    | 48/93 [20:38<21:11, 28.25s/epoch, loss=1.12, accuracy=0.758, val_loss=2.1, val_accuracy=0.484, lr=0.1]  53%|█████▎    | 49/93 [21:05<20:27, 27.89s/epoch, loss=1.11, accuracy=0.759, val_loss=3.05, val_accuracy=0.41, lr=0.1] 54%|█████▍    | 50/93 [21:30<19:24, 27.09s/epoch, loss=1.12, accuracy=0.757, val_loss=1.5, val_accuracy=0.63, lr=0.1]  55%|█████▍    | 51/93 [21:57<18:54, 27.01s/epoch, loss=1.12, accuracy=0.757, val_loss=2.13, val_accuracy=0.499, lr=0.0316] 56%|█████▌    | 52/93 [22:25<18:33, 27.15s/epoch, loss=1.12, accuracy=0.756, val_loss=1.63, val_accuracy=0.591, lr=0.1]    57%|█████▋    | 53/93 [22:52<18:09, 27.24s/epoch, loss=1.11, accuracy=0.76, val_loss=2.41, val_accuracy=0.413, lr=0.1]  58%|█████▊    | 54/93 [23:20<17:45, 27.32s/epoch, loss=1.12, accuracy=0.755, val_loss=1.68, val_accuracy=0.539, lr=0.1] 59%|█████▉    | 55/93 [23:47<17:20, 27.37s/epoch, loss=1.11, accuracy=0.759, val_loss=2.16, val_accuracy=0.433, lr=0.1] 60%|██████    | 56/93 [24:12<16:25, 26.63s/epoch, loss=1.11, accuracy=0.758, val_loss=3.03, val_accuracy=0.263, lr=0.0316] 61%|██████▏   | 57/93 [24:37<15:40, 26.13s/epoch, loss=1.11, accuracy=0.759, val_loss=1.9, val_accuracy=0.546, lr=0.1]     62%|██████▏   | 58/93 [25:02<15:03, 25.82s/epoch, loss=1.12, accuracy=0.756, val_loss=5.11, val_accuracy=0.245, lr=0.1] 63%|██████▎   | 59/93 [25:27<14:28, 25.54s/epoch, loss=1.11, accuracy=0.76, val_loss=1.69, val_accuracy=0.578, lr=0.1]  65%|██████▍   | 60/93 [25:52<13:53, 25.25s/epoch, loss=1.11, accuracy=0.76, val_loss=4.07, val_accuracy=0.166, lr=0.1] 66%|██████▌   | 61/93 [26:15<13:13, 24.80s/epoch, loss=1.11, accuracy=0.759, val_loss=2.38, val_accuracy=0.43, lr=0.0316] 67%|██████▋   | 62/93 [26:40<12:49, 24.81s/epoch, loss=1.1, accuracy=0.761, val_loss=1.78, val_accuracy=0.532, lr=0.1]    68%|██████▊   | 63/93 [27:07<12:40, 25.34s/epoch, loss=1.1, accuracy=0.76, val_loss=1.87, val_accuracy=0.604, lr=0.1]  69%|██████▉   | 64/93 [27:35<12:37, 26.11s/epoch, loss=1.12, accuracy=0.76, val_loss=1.49, val_accuracy=0.637, lr=0.1] 70%|██████▉   | 65/93 [28:00<12:05, 25.90s/epoch, loss=1.11, accuracy=0.758, val_loss=1.51, val_accuracy=0.629, lr=0.1] 71%|███████   | 66/93 [28:24<11:26, 25.44s/epoch, loss=1.11, accuracy=0.759, val_loss=2.51, val_accuracy=0.42, lr=0.0316] 72%|███████▏  | 67/93 [28:49<10:57, 25.30s/epoch, loss=1.11, accuracy=0.759, val_loss=2.41, val_accuracy=0.476, lr=0.1]   73%|███████▎  | 68/93 [29:15<10:35, 25.41s/epoch, loss=1.11, accuracy=0.758, val_loss=2.12, val_accuracy=0.438, lr=0.1] 74%|███████▍  | 69/93 [29:41<10:15, 25.66s/epoch, loss=1.11, accuracy=0.762, val_loss=1.59, val_accuracy=0.579, lr=0.1] 75%|███████▌  | 70/93 [30:07<09:47, 25.55s/epoch, loss=1.1, accuracy=0.762, val_loss=2, val_accuracy=0.535, lr=0.1]     76%|███████▋  | 71/93 [30:31<09:16, 25.29s/epoch, loss=1.11, accuracy=0.76, val_loss=1.78, val_accuracy=0.507, lr=0.0316] 77%|███████▋  | 72/93 [30:56<08:48, 25.17s/epoch, loss=1.11, accuracy=0.758, val_loss=2.02, val_accuracy=0.502, lr=0.1]   78%|███████▊  | 73/93 [31:22<08:25, 25.29s/epoch, loss=1.11, accuracy=0.76, val_loss=3.3, val_accuracy=0.297, lr=0.1]   80%|███████▉  | 74/93 [31:47<08:00, 25.28s/epoch, loss=1.1, accuracy=0.76, val_loss=1.91, val_accuracy=0.457, lr=0.1] 81%|████████  | 75/93 [32:13<07:37, 25.41s/epoch, loss=1.1, accuracy=0.761, val_loss=5.2, val_accuracy=0.284, lr=0.1] 82%|████████▏ | 76/93 [32:40<07:21, 25.98s/epoch, loss=1.11, accuracy=0.759, val_loss=2.56, val_accuracy=0.425, lr=0.0316] 83%|████████▎ | 77/93 [33:07<07:02, 26.39s/epoch, loss=1.11, accuracy=0.76, val_loss=2.29, val_accuracy=0.462, lr=0.1]     84%|████████▍ | 78/93 [33:35<06:40, 26.72s/epoch, loss=1.1, accuracy=0.759, val_loss=2.56, val_accuracy=0.311, lr=0.1] 85%|████████▍ | 79/93 [34:01<06:10, 26.47s/epoch, loss=1.1, accuracy=0.761, val_loss=1.75, val_accuracy=0.574, lr=0.1] 86%|████████▌ | 80/93 [34:26<05:38, 26.08s/epoch, loss=1.1, accuracy=0.76, val_loss=1.72, val_accuracy=0.564, lr=0.1]  87%|████████▋ | 81/93 [34:50<05:07, 25.63s/epoch, loss=1.11, accuracy=0.758, val_loss=1.7, val_accuracy=0.547, lr=0.0316] 88%|████████▊ | 82/93 [35:15<04:37, 25.27s/epoch, loss=0.892, accuracy=0.818, val_loss=0.864, val_accuracy=0.812, lr=0.01] 89%|████████▉ | 83/93 [35:40<04:10, 25.10s/epoch, loss=0.72, accuracy=0.849, val_loss=0.789, val_accuracy=0.81, lr=0.01]   90%|█████████ | 84/93 [36:04<03:44, 24.92s/epoch, loss=0.639, accuracy=0.856, val_loss=0.931, val_accuracy=0.758, lr=0.01] 91%|█████████▏| 85/93 [36:29<03:18, 24.81s/epoch, loss=0.596, accuracy=0.862, val_loss=0.832, val_accuracy=0.771, lr=0.01] 92%|█████████▏| 86/93 [36:53<02:52, 24.70s/epoch, loss=0.576, accuracy=0.862, val_loss=0.73, val_accuracy=0.806, lr=0.01]  94%|█████████▎| 87/93 [37:17<02:27, 24.61s/epoch, loss=0.569, accuracy=0.861, val_loss=0.88, val_accuracy=0.765, lr=0.01] 95%|█████████▍| 88/93 [37:42<02:02, 24.49s/epoch, loss=0.564, accuracy=0.864, val_loss=0.765, val_accuracy=0.799, lr=0.01] 96%|█████████▌| 89/93 [38:06<01:37, 24.44s/epoch, loss=0.558, accuracy=0.865, val_loss=1.04, val_accuracy=0.716, lr=0.01]  97%|█████████▋| 90/93 [38:31<01:13, 24.52s/epoch, loss=0.557, accuracy=0.865, val_loss=0.816, val_accuracy=0.779, lr=0.01] 98%|█████████▊| 91/93 [38:55<00:48, 24.48s/epoch, loss=0.556, accuracy=0.867, val_loss=0.807, val_accuracy=0.78, lr=0.00316] 99%|█████████▉| 92/93 [39:20<00:24, 24.47s/epoch, loss=0.552, accuracy=0.871, val_loss=0.804, val_accuracy=0.791, lr=0.01]  100%|██████████| 93/93 [39:44<00:00, 24.33s/epoch, loss=0.551, accuracy=0.87, val_loss=0.699, val_accuracy=0.823, lr=0.01] 100%|██████████| 93/93 [39:44<00:00, 25.64s/epoch, loss=0.551, accuracy=0.87, val_loss=0.699, val_accuracy=0.823, lr=0.01]
Using real-time data augmentation.
Test score: 0.6994608640670776
Test accuracy: 0.8230000138282776
