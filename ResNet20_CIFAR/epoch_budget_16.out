Thu Feb 15 13:39:18 2024       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA TITAN Xp                Off | 00000000:83:00.0 Off |                  N/A |
| 47%   72C    P0              90W / 250W |      0MiB / 12288MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|  No running processes found                                                           |
+---------------------------------------------------------------------------------------+


* * * Run SGD for cluster size = 16. * * *


Budget: 93


* * * Run SGD for ID = 16_1. * * *


2024-02-15 13:39:19.775852: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 13:39:25.799544: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 13:39:25.800933: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-15 13:39:25.839889: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 13:39:25.839923: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 13:39:25.854817: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 13:39:25.854875: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 13:39:25.874388: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 13:39:25.901144: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 13:39:25.948309: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 13:39:25.960339: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 13:39:25.984273: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 13:39:25.984928: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 13:39:25.985010: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 13:39:27.355105: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-15 13:39:27.355672: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 13:39:27.356152: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 13:39:27.356182: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 13:39:27.356215: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 13:39:27.356232: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 13:39:27.356248: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 13:39:27.356264: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 13:39:27.356280: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 13:39:27.356296: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 13:39:27.356312: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 13:39:27.356751: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 13:39:27.356787: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 13:39:28.185642: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-15 13:39:28.185707: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-15 13:39:28.185718: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-15 13:39:28.187044: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': 161, 'batch_size': 128, 'epochs': 93, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/93 [00:00<?, ?epoch/s]2024-02-15 13:39:28.982250: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-15 13:39:28.994699: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2200060000 Hz
2024-02-15 13:39:30.948823: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 13:39:31.264976: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 13:39:32.181792: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-15 13:39:32.209969: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/93 [00:48<1:14:58, 48.90s/epoch, loss=3.42, accuracy=0.287, val_loss=2.63, val_accuracy=0.217, lr=0.1]  2%|▏         | 2/93 [01:13<52:28, 34.59s/epoch, loss=1.7, accuracy=0.46, val_loss=2.22, val_accuracy=0.361, lr=0.1]      3%|▎         | 3/93 [01:36<43:59, 29.33s/epoch, loss=1.5, accuracy=0.557, val_loss=2.49, val_accuracy=0.373, lr=0.1]  4%|▍         | 4/93 [01:58<39:21, 26.53s/epoch, loss=1.34, accuracy=0.653, val_loss=1.68, val_accuracy=0.55, lr=0.1]  5%|▌         | 5/93 [02:20<36:29, 24.88s/epoch, loss=1.28, accuracy=0.685, val_loss=1.91, val_accuracy=0.505, lr=0.1]  6%|▋         | 6/93 [02:42<34:41, 23.93s/epoch, loss=1.26, accuracy=0.702, val_loss=2.13, val_accuracy=0.522, lr=0.1]  8%|▊         | 7/93 [03:05<33:31, 23.39s/epoch, loss=1.25, accuracy=0.711, val_loss=1.63, val_accuracy=0.581, lr=0.1]  9%|▊         | 8/93 [03:27<32:38, 23.04s/epoch, loss=1.23, accuracy=0.717, val_loss=1.95, val_accuracy=0.475, lr=0.1] 10%|▉         | 9/93 [03:49<31:49, 22.74s/epoch, loss=1.23, accuracy=0.721, val_loss=2.06, val_accuracy=0.44, lr=0.1]  11%|█         | 10/93 [04:11<31:13, 22.57s/epoch, loss=1.22, accuracy=0.727, val_loss=1.9, val_accuracy=0.529, lr=0.1] 12%|█▏        | 11/93 [04:34<30:50, 22.57s/epoch, loss=1.21, accuracy=0.732, val_loss=1.9, val_accuracy=0.475, lr=0.1] 13%|█▎        | 12/93 [04:56<30:15, 22.42s/epoch, loss=1.2, accuracy=0.735, val_loss=2.11, val_accuracy=0.461, lr=0.0316] 14%|█▍        | 13/93 [05:18<29:43, 22.29s/epoch, loss=1.21, accuracy=0.734, val_loss=2.19, val_accuracy=0.402, lr=0.1]   15%|█▌        | 14/93 [05:40<29:11, 22.17s/epoch, loss=1.19, accuracy=0.74, val_loss=1.71, val_accuracy=0.554, lr=0.1]  16%|█▌        | 15/93 [06:02<28:45, 22.12s/epoch, loss=1.2, accuracy=0.738, val_loss=1.59, val_accuracy=0.634, lr=0.1] 17%|█▋        | 16/93 [06:24<28:23, 22.12s/epoch, loss=1.19, accuracy=0.741, val_loss=1.77, val_accuracy=0.532, lr=0.1] 18%|█▊        | 17/93 [06:47<28:23, 22.41s/epoch, loss=1.18, accuracy=0.745, val_loss=2.35, val_accuracy=0.458, lr=0.1] 19%|█▉        | 18/93 [07:09<27:52, 22.30s/epoch, loss=1.18, accuracy=0.746, val_loss=1.87, val_accuracy=0.559, lr=0.1] 20%|██        | 19/93 [07:31<27:29, 22.30s/epoch, loss=1.18, accuracy=0.744, val_loss=1.84, val_accuracy=0.519, lr=0.1] 22%|██▏       | 20/93 [07:54<27:14, 22.39s/epoch, loss=1.17, accuracy=0.747, val_loss=1.87, val_accuracy=0.478, lr=0.0316] 23%|██▎       | 21/93 [08:16<26:48, 22.33s/epoch, loss=1.18, accuracy=0.745, val_loss=1.76, val_accuracy=0.552, lr=0.1]    24%|██▎       | 22/93 [08:39<26:29, 22.39s/epoch, loss=1.16, accuracy=0.748, val_loss=2.33, val_accuracy=0.375, lr=0.1] 25%|██▍       | 23/93 [09:01<26:06, 22.38s/epoch, loss=1.16, accuracy=0.749, val_loss=1.68, val_accuracy=0.596, lr=0.1] 26%|██▌       | 24/93 [09:23<25:38, 22.30s/epoch, loss=1.16, accuracy=0.747, val_loss=2.84, val_accuracy=0.426, lr=0.1] 27%|██▋       | 25/93 [09:45<25:16, 22.31s/epoch, loss=1.16, accuracy=0.749, val_loss=2.2, val_accuracy=0.46, lr=0.0316] 28%|██▊       | 26/93 [10:08<25:01, 22.41s/epoch, loss=1.15, accuracy=0.753, val_loss=3.41, val_accuracy=0.246, lr=0.1]  29%|██▉       | 27/93 [10:30<24:40, 22.44s/epoch, loss=1.16, accuracy=0.751, val_loss=2.81, val_accuracy=0.395, lr=0.1] 30%|███       | 28/93 [10:53<24:22, 22.50s/epoch, loss=1.15, accuracy=0.752, val_loss=1.6, val_accuracy=0.591, lr=0.1]  31%|███       | 29/93 [11:16<24:00, 22.51s/epoch, loss=1.15, accuracy=0.75, val_loss=1.8, val_accuracy=0.542, lr=0.1]  32%|███▏      | 30/93 [11:38<23:39, 22.53s/epoch, loss=1.15, accuracy=0.755, val_loss=1.46, val_accuracy=0.637, lr=0.1] 33%|███▎      | 31/93 [12:01<23:14, 22.50s/epoch, loss=1.16, accuracy=0.754, val_loss=2.07, val_accuracy=0.48, lr=0.1]  34%|███▍      | 32/93 [12:23<22:46, 22.41s/epoch, loss=1.15, accuracy=0.752, val_loss=2.25, val_accuracy=0.5, lr=0.1]  35%|███▌      | 33/93 [12:45<22:18, 22.30s/epoch, loss=1.15, accuracy=0.751, val_loss=2.77, val_accuracy=0.397, lr=0.1] 37%|███▋      | 34/93 [13:08<22:01, 22.40s/epoch, loss=1.14, accuracy=0.753, val_loss=2.57, val_accuracy=0.354, lr=0.1] 38%|███▊      | 35/93 [13:31<21:52, 22.63s/epoch, loss=1.15, accuracy=0.753, val_loss=2.66, val_accuracy=0.35, lr=0.0316] 39%|███▊      | 36/93 [13:54<21:32, 22.68s/epoch, loss=1.14, accuracy=0.756, val_loss=2.69, val_accuracy=0.447, lr=0.1]   40%|███▉      | 37/93 [14:16<21:13, 22.74s/epoch, loss=1.14, accuracy=0.754, val_loss=1.49, val_accuracy=0.615, lr=0.1] 41%|████      | 38/93 [14:39<20:55, 22.83s/epoch, loss=1.14, accuracy=0.756, val_loss=2.27, val_accuracy=0.53, lr=0.1]  42%|████▏     | 39/93 [15:02<20:24, 22.68s/epoch, loss=1.13, accuracy=0.755, val_loss=1.88, val_accuracy=0.526, lr=0.1] 43%|████▎     | 40/93 [15:25<20:09, 22.83s/epoch, loss=1.14, accuracy=0.752, val_loss=1.74, val_accuracy=0.562, lr=0.0316] 44%|████▍     | 41/93 [15:48<19:51, 22.92s/epoch, loss=1.13, accuracy=0.756, val_loss=2.09, val_accuracy=0.507, lr=0.1]    45%|████▌     | 42/93 [16:11<19:31, 22.98s/epoch, loss=1.14, accuracy=0.752, val_loss=3.14, val_accuracy=0.377, lr=0.1] 46%|████▌     | 43/93 [16:34<19:11, 23.03s/epoch, loss=1.13, accuracy=0.754, val_loss=1.68, val_accuracy=0.595, lr=0.1] 47%|████▋     | 44/93 [16:57<18:46, 23.00s/epoch, loss=1.12, accuracy=0.759, val_loss=1.84, val_accuracy=0.536, lr=0.1] 48%|████▊     | 45/93 [17:20<18:19, 22.91s/epoch, loss=1.13, accuracy=0.756, val_loss=2.1, val_accuracy=0.478, lr=0.0316] 49%|████▉     | 46/93 [17:43<17:57, 22.92s/epoch, loss=1.12, accuracy=0.757, val_loss=1.89, val_accuracy=0.526, lr=0.1]   51%|█████     | 47/93 [18:06<17:32, 22.88s/epoch, loss=1.13, accuracy=0.755, val_loss=2.18, val_accuracy=0.514, lr=0.1] 52%|█████▏    | 48/93 [18:29<17:08, 22.86s/epoch, loss=1.13, accuracy=0.757, val_loss=1.48, val_accuracy=0.619, lr=0.1] 53%|█████▎    | 49/93 [18:52<16:59, 23.17s/epoch, loss=1.13, accuracy=0.757, val_loss=2.83, val_accuracy=0.387, lr=0.1] 54%|█████▍    | 50/93 [19:16<16:36, 23.17s/epoch, loss=1.12, accuracy=0.758, val_loss=1.87, val_accuracy=0.517, lr=0.0316] 55%|█████▍    | 51/93 [19:38<16:05, 23.00s/epoch, loss=1.13, accuracy=0.757, val_loss=1.89, val_accuracy=0.571, lr=0.1]    56%|█████▌    | 52/93 [20:02<15:47, 23.11s/epoch, loss=1.12, accuracy=0.759, val_loss=2.07, val_accuracy=0.524, lr=0.1] 57%|█████▋    | 53/93 [20:24<15:17, 22.93s/epoch, loss=1.13, accuracy=0.757, val_loss=1.63, val_accuracy=0.581, lr=0.1] 58%|█████▊    | 54/93 [20:48<15:00, 23.10s/epoch, loss=1.12, accuracy=0.757, val_loss=1.49, val_accuracy=0.623, lr=0.1] 59%|█████▉    | 55/93 [21:11<14:42, 23.21s/epoch, loss=1.13, accuracy=0.756, val_loss=2.47, val_accuracy=0.339, lr=0.0316] 60%|██████    | 56/93 [21:35<14:32, 23.58s/epoch, loss=1.13, accuracy=0.755, val_loss=1.65, val_accuracy=0.577, lr=0.1]    61%|██████▏   | 57/93 [22:01<14:33, 24.25s/epoch, loss=1.12, accuracy=0.759, val_loss=7.64, val_accuracy=0.151, lr=0.1] 62%|██████▏   | 58/93 [22:27<14:19, 24.55s/epoch, loss=1.12, accuracy=0.761, val_loss=1.86, val_accuracy=0.537, lr=0.1] 63%|██████▎   | 59/93 [22:52<14:01, 24.75s/epoch, loss=1.12, accuracy=0.76, val_loss=1.37, val_accuracy=0.658, lr=0.1]  65%|██████▍   | 60/93 [23:15<13:25, 24.41s/epoch, loss=1.12, accuracy=0.758, val_loss=1.82, val_accuracy=0.528, lr=0.1] 66%|██████▌   | 61/93 [23:40<13:00, 24.39s/epoch, loss=1.12, accuracy=0.758, val_loss=1.66, val_accuracy=0.561, lr=0.1] 67%|██████▋   | 62/93 [24:05<12:41, 24.56s/epoch, loss=1.12, accuracy=0.757, val_loss=3.48, val_accuracy=0.322, lr=0.1] 68%|██████▊   | 63/93 [24:28<12:02, 24.07s/epoch, loss=1.11, accuracy=0.76, val_loss=1.84, val_accuracy=0.529, lr=0.1]  69%|██████▉   | 64/93 [24:53<11:46, 24.35s/epoch, loss=1.12, accuracy=0.76, val_loss=1.83, val_accuracy=0.531, lr=0.0316] 70%|██████▉   | 65/93 [25:17<11:25, 24.49s/epoch, loss=1.11, accuracy=0.759, val_loss=1.48, val_accuracy=0.635, lr=0.1]   71%|███████   | 66/93 [25:41<10:55, 24.26s/epoch, loss=1.11, accuracy=0.758, val_loss=2.71, val_accuracy=0.32, lr=0.1]  72%|███████▏  | 67/93 [26:06<10:35, 24.44s/epoch, loss=1.11, accuracy=0.76, val_loss=2.29, val_accuracy=0.46, lr=0.1]  73%|███████▎  | 68/93 [26:31<10:13, 24.56s/epoch, loss=1.11, accuracy=0.76, val_loss=2.55, val_accuracy=0.456, lr=0.1] 74%|███████▍  | 69/93 [26:54<09:39, 24.15s/epoch, loss=1.11, accuracy=0.762, val_loss=2.02, val_accuracy=0.498, lr=0.0316] 75%|███████▌  | 70/93 [27:18<09:16, 24.21s/epoch, loss=1.11, accuracy=0.76, val_loss=1.67, val_accuracy=0.616, lr=0.1]     76%|███████▋  | 71/93 [27:43<08:52, 24.22s/epoch, loss=1.11, accuracy=0.758, val_loss=2.72, val_accuracy=0.428, lr=0.1] 77%|███████▋  | 72/93 [28:07<08:32, 24.39s/epoch, loss=1.11, accuracy=0.758, val_loss=1.55, val_accuracy=0.613, lr=0.1] 78%|███████▊  | 73/93 [28:32<08:11, 24.58s/epoch, loss=1.11, accuracy=0.759, val_loss=1.63, val_accuracy=0.593, lr=0.1] 80%|███████▉  | 74/93 [28:57<07:49, 24.69s/epoch, loss=1.11, accuracy=0.757, val_loss=2.68, val_accuracy=0.377, lr=0.0316] 81%|████████  | 75/93 [29:21<07:18, 24.36s/epoch, loss=1.11, accuracy=0.757, val_loss=2.25, val_accuracy=0.45, lr=0.1]     82%|████████▏ | 76/93 [29:44<06:49, 24.10s/epoch, loss=1.11, accuracy=0.758, val_loss=1.71, val_accuracy=0.579, lr=0.1] 83%|████████▎ | 77/93 [30:08<06:23, 23.96s/epoch, loss=1.11, accuracy=0.759, val_loss=1.86, val_accuracy=0.552, lr=0.1] 84%|████████▍ | 78/93 [30:33<06:03, 24.22s/epoch, loss=1.11, accuracy=0.759, val_loss=2.75, val_accuracy=0.389, lr=0.1] 85%|████████▍ | 79/93 [30:58<05:41, 24.37s/epoch, loss=1.11, accuracy=0.757, val_loss=2, val_accuracy=0.479, lr=0.0316] 86%|████████▌ | 80/93 [31:22<05:18, 24.48s/epoch, loss=1.11, accuracy=0.759, val_loss=2.1, val_accuracy=0.484, lr=0.1]  87%|████████▋ | 81/93 [31:47<04:52, 24.39s/epoch, loss=1.11, accuracy=0.76, val_loss=2.06, val_accuracy=0.483, lr=0.1] 88%|████████▊ | 82/93 [32:11<04:28, 24.44s/epoch, loss=0.895, accuracy=0.819, val_loss=0.889, val_accuracy=0.804, lr=0.01] 89%|████████▉ | 83/93 [32:35<04:02, 24.26s/epoch, loss=0.722, accuracy=0.85, val_loss=0.739, val_accuracy=0.835, lr=0.01]  90%|█████████ | 84/93 [32:59<03:37, 24.17s/epoch, loss=0.639, accuracy=0.858, val_loss=0.727, val_accuracy=0.819, lr=0.01] 91%|█████████▏| 85/93 [33:23<03:12, 24.03s/epoch, loss=0.599, accuracy=0.86, val_loss=0.731, val_accuracy=0.812, lr=0.01]  92%|█████████▏| 86/93 [33:47<02:49, 24.25s/epoch, loss=0.579, accuracy=0.862, val_loss=0.755, val_accuracy=0.804, lr=0.01] 94%|█████████▎| 87/93 [34:11<02:24, 24.14s/epoch, loss=0.566, accuracy=0.864, val_loss=0.82, val_accuracy=0.784, lr=0.01]  95%|█████████▍| 88/93 [34:36<02:01, 24.29s/epoch, loss=0.563, accuracy=0.866, val_loss=0.693, val_accuracy=0.821, lr=0.01] 96%|█████████▌| 89/93 [34:59<01:35, 23.85s/epoch, loss=0.557, accuracy=0.866, val_loss=0.743, val_accuracy=0.806, lr=0.01] 97%|█████████▋| 90/93 [35:23<01:12, 24.07s/epoch, loss=0.562, accuracy=0.866, val_loss=0.766, val_accuracy=0.804, lr=0.01] 98%|█████████▊| 91/93 [35:46<00:47, 23.73s/epoch, loss=0.556, accuracy=0.869, val_loss=0.715, val_accuracy=0.818, lr=0.01] 99%|█████████▉| 92/93 [36:11<00:23, 23.94s/epoch, loss=0.556, accuracy=0.871, val_loss=0.717, val_accuracy=0.821, lr=0.01]100%|██████████| 93/93 [36:35<00:00, 24.15s/epoch, loss=0.554, accuracy=0.871, val_loss=0.94, val_accuracy=0.777, lr=0.00316]100%|██████████| 93/93 [36:35<00:00, 23.61s/epoch, loss=0.554, accuracy=0.871, val_loss=0.94, val_accuracy=0.777, lr=0.00316]
Using real-time data augmentation.
Test loss: 0.9402450919151306
Test accuracy: 0.7773000001907349


* * * Run SGD for ID = 16_2. * * *


2024-02-15 14:16:07.265085: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 14:16:10.086904: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 14:16:10.087986: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-15 14:16:10.127472: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 14:16:10.127503: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 14:16:10.130218: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 14:16:10.130262: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 14:16:10.132444: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 14:16:10.133503: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 14:16:10.135894: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 14:16:10.137361: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 14:16:10.142003: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 14:16:10.144276: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 14:16:10.144376: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 14:16:11.440865: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-15 14:16:11.441438: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 14:16:11.441899: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 14:16:11.441931: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 14:16:11.441964: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 14:16:11.441982: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 14:16:11.441999: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 14:16:11.442015: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 14:16:11.442032: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 14:16:11.442068: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 14:16:11.442086: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 14:16:11.442522: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 14:16:11.442561: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 14:16:12.108895: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-15 14:16:12.108951: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-15 14:16:12.108962: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-15 14:16:12.109865: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': 162, 'batch_size': 128, 'epochs': 93, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/93 [00:00<?, ?epoch/s]2024-02-15 14:16:12.933268: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-15 14:16:12.945723: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2200060000 Hz
2024-02-15 14:16:15.046044: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 14:16:15.282434: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 14:16:16.018374: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-15 14:16:16.059850: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/93 [00:53<1:21:52, 53.40s/epoch, loss=3.1, accuracy=0.321, val_loss=2.62, val_accuracy=0.219, lr=0.1]  2%|▏         | 2/93 [01:16<53:50, 35.50s/epoch, loss=1.54, accuracy=0.544, val_loss=1.66, val_accuracy=0.531, lr=0.1]   3%|▎         | 3/93 [01:40<45:38, 30.43s/epoch, loss=1.34, accuracy=0.648, val_loss=1.76, val_accuracy=0.539, lr=0.1]  4%|▍         | 4/93 [02:05<41:53, 28.24s/epoch, loss=1.28, accuracy=0.684, val_loss=1.88, val_accuracy=0.493, lr=0.1]  5%|▌         | 5/93 [02:30<39:43, 27.08s/epoch, loss=1.24, accuracy=0.703, val_loss=2.44, val_accuracy=0.46, lr=0.1]   6%|▋         | 6/93 [02:55<38:01, 26.22s/epoch, loss=1.23, accuracy=0.714, val_loss=1.87, val_accuracy=0.53, lr=0.1]  8%|▊         | 7/93 [03:19<36:28, 25.45s/epoch, loss=1.21, accuracy=0.721, val_loss=2.49, val_accuracy=0.449, lr=0.0316]  9%|▊         | 8/93 [03:44<35:50, 25.30s/epoch, loss=1.2, accuracy=0.724, val_loss=1.49, val_accuracy=0.638, lr=0.1]     10%|▉         | 9/93 [04:08<35:04, 25.05s/epoch, loss=1.2, accuracy=0.728, val_loss=1.63, val_accuracy=0.556, lr=0.1] 11%|█         | 10/93 [04:31<33:47, 24.42s/epoch, loss=1.19, accuracy=0.732, val_loss=2.22, val_accuracy=0.487, lr=0.1] 12%|█▏        | 11/93 [04:55<33:06, 24.23s/epoch, loss=1.18, accuracy=0.737, val_loss=1.94, val_accuracy=0.536, lr=0.1] 13%|█▎        | 12/93 [05:20<32:53, 24.36s/epoch, loss=1.17, accuracy=0.74, val_loss=1.66, val_accuracy=0.574, lr=0.1]  14%|█▍        | 13/93 [05:43<31:55, 23.94s/epoch, loss=1.17, accuracy=0.737, val_loss=1.57, val_accuracy=0.616, lr=0.0316] 15%|█▌        | 14/93 [06:06<31:24, 23.85s/epoch, loss=1.16, accuracy=0.741, val_loss=5.25, val_accuracy=0.237, lr=0.1]    16%|█▌        | 15/93 [06:31<31:22, 24.14s/epoch, loss=1.16, accuracy=0.742, val_loss=2.26, val_accuracy=0.458, lr=0.1] 17%|█▋        | 16/93 [06:55<31:03, 24.20s/epoch, loss=1.16, accuracy=0.745, val_loss=2.23, val_accuracy=0.393, lr=0.1] 18%|█▊        | 17/93 [07:18<30:11, 23.84s/epoch, loss=1.15, accuracy=0.747, val_loss=1.73, val_accuracy=0.566, lr=0.1] 19%|█▉        | 18/93 [07:43<30:09, 24.12s/epoch, loss=1.15, accuracy=0.745, val_loss=1.5, val_accuracy=0.598, lr=0.0316] 20%|██        | 19/93 [08:07<29:43, 24.10s/epoch, loss=1.15, accuracy=0.747, val_loss=1.53, val_accuracy=0.619, lr=0.1]   22%|██▏       | 20/93 [08:32<29:32, 24.28s/epoch, loss=1.14, accuracy=0.749, val_loss=1.56, val_accuracy=0.605, lr=0.1] 23%|██▎       | 21/93 [08:57<29:26, 24.53s/epoch, loss=1.14, accuracy=0.749, val_loss=3.35, val_accuracy=0.428, lr=0.1] 24%|██▎       | 22/93 [09:22<29:09, 24.64s/epoch, loss=1.15, accuracy=0.748, val_loss=1.56, val_accuracy=0.61, lr=0.1]  25%|██▍       | 23/93 [09:47<28:46, 24.66s/epoch, loss=1.14, accuracy=0.75, val_loss=2.14, val_accuracy=0.486, lr=0.0316] 26%|██▌       | 24/93 [10:10<27:58, 24.32s/epoch, loss=1.14, accuracy=0.749, val_loss=2.74, val_accuracy=0.427, lr=0.1]   27%|██▋       | 25/93 [10:35<27:41, 24.44s/epoch, loss=1.13, accuracy=0.751, val_loss=2.38, val_accuracy=0.46, lr=0.1]  28%|██▊       | 26/93 [10:59<27:04, 24.25s/epoch, loss=1.14, accuracy=0.752, val_loss=1.74, val_accuracy=0.535, lr=0.1] 29%|██▉       | 27/93 [11:23<26:38, 24.21s/epoch, loss=1.14, accuracy=0.752, val_loss=1.63, val_accuracy=0.604, lr=0.1] 30%|███       | 28/93 [11:48<26:35, 24.54s/epoch, loss=1.13, accuracy=0.754, val_loss=2.45, val_accuracy=0.422, lr=0.0316] 31%|███       | 29/93 [12:13<26:16, 24.63s/epoch, loss=1.13, accuracy=0.753, val_loss=1.72, val_accuracy=0.566, lr=0.1]    32%|███▏      | 30/93 [12:37<25:42, 24.48s/epoch, loss=1.12, accuracy=0.752, val_loss=1.73, val_accuracy=0.569, lr=0.1] 33%|███▎      | 31/93 [13:01<25:15, 24.44s/epoch, loss=1.13, accuracy=0.755, val_loss=2.33, val_accuracy=0.481, lr=0.1] 34%|███▍      | 32/93 [13:27<25:07, 24.71s/epoch, loss=1.13, accuracy=0.753, val_loss=4.37, val_accuracy=0.257, lr=0.1] 35%|███▌      | 33/93 [13:52<24:45, 24.76s/epoch, loss=1.13, accuracy=0.755, val_loss=2.86, val_accuracy=0.353, lr=0.0316] 37%|███▋      | 34/93 [14:17<24:34, 24.98s/epoch, loss=1.13, accuracy=0.755, val_loss=2.04, val_accuracy=0.509, lr=0.1]    38%|███▊      | 35/93 [14:41<23:52, 24.69s/epoch, loss=1.13, accuracy=0.755, val_loss=3.1, val_accuracy=0.324, lr=0.1]  39%|███▊      | 36/93 [15:06<23:26, 24.68s/epoch, loss=1.12, accuracy=0.755, val_loss=2.27, val_accuracy=0.49, lr=0.1] 40%|███▉      | 37/93 [15:30<22:59, 24.63s/epoch, loss=1.13, accuracy=0.753, val_loss=2.27, val_accuracy=0.51, lr=0.1] 41%|████      | 38/93 [15:55<22:39, 24.71s/epoch, loss=1.12, accuracy=0.757, val_loss=2.36, val_accuracy=0.477, lr=0.0316] 42%|████▏     | 39/93 [16:20<22:10, 24.65s/epoch, loss=1.13, accuracy=0.756, val_loss=2.65, val_accuracy=0.476, lr=0.1]    43%|████▎     | 40/93 [16:45<21:50, 24.73s/epoch, loss=1.12, accuracy=0.757, val_loss=2.5, val_accuracy=0.47, lr=0.1]   44%|████▍     | 41/93 [17:10<21:29, 24.79s/epoch, loss=1.13, accuracy=0.753, val_loss=3.83, val_accuracy=0.339, lr=0.1] 45%|████▌     | 42/93 [17:33<20:37, 24.27s/epoch, loss=1.12, accuracy=0.755, val_loss=1.94, val_accuracy=0.472, lr=0.1] 46%|████▌     | 43/93 [17:57<20:16, 24.34s/epoch, loss=1.12, accuracy=0.754, val_loss=1.79, val_accuracy=0.531, lr=0.0316] 47%|████▋     | 44/93 [18:22<20:00, 24.51s/epoch, loss=1.12, accuracy=0.754, val_loss=2.77, val_accuracy=0.365, lr=0.1]    48%|████▊     | 45/93 [18:45<19:20, 24.18s/epoch, loss=1.12, accuracy=0.756, val_loss=6.73, val_accuracy=0.177, lr=0.1] 49%|████▉     | 46/93 [19:10<19:06, 24.39s/epoch, loss=1.13, accuracy=0.754, val_loss=1.87, val_accuracy=0.507, lr=0.1] 51%|█████     | 47/93 [19:35<18:44, 24.45s/epoch, loss=1.13, accuracy=0.755, val_loss=1.79, val_accuracy=0.559, lr=0.1] 52%|█████▏    | 48/93 [20:00<18:25, 24.56s/epoch, loss=1.13, accuracy=0.755, val_loss=1.73, val_accuracy=0.587, lr=0.0316] 53%|█████▎    | 49/93 [20:25<18:08, 24.73s/epoch, loss=1.12, accuracy=0.757, val_loss=1.63, val_accuracy=0.59, lr=0.1]     54%|█████▍    | 50/93 [20:50<17:51, 24.93s/epoch, loss=1.12, accuracy=0.756, val_loss=2.11, val_accuracy=0.508, lr=0.1] 55%|█████▍    | 51/93 [21:15<17:24, 24.87s/epoch, loss=1.12, accuracy=0.755, val_loss=2.23, val_accuracy=0.459, lr=0.1] 56%|█████▌    | 52/93 [21:40<16:57, 24.82s/epoch, loss=1.12, accuracy=0.759, val_loss=2.43, val_accuracy=0.419, lr=0.1] 57%|█████▋    | 53/93 [22:05<16:38, 24.96s/epoch, loss=1.12, accuracy=0.757, val_loss=4.7, val_accuracy=0.229, lr=0.0316] 58%|█████▊    | 54/93 [22:28<15:57, 24.54s/epoch, loss=1.12, accuracy=0.758, val_loss=1.88, val_accuracy=0.53, lr=0.1]    59%|█████▉    | 55/93 [22:53<15:28, 24.44s/epoch, loss=1.12, accuracy=0.755, val_loss=2.4, val_accuracy=0.456, lr=0.1] 60%|██████    | 56/93 [23:18<15:12, 24.66s/epoch, loss=1.12, accuracy=0.756, val_loss=1.45, val_accuracy=0.648, lr=0.1] 61%|██████▏   | 57/93 [23:43<14:51, 24.78s/epoch, loss=1.12, accuracy=0.757, val_loss=2.56, val_accuracy=0.468, lr=0.1] 62%|██████▏   | 58/93 [24:07<14:21, 24.62s/epoch, loss=1.12, accuracy=0.757, val_loss=2.49, val_accuracy=0.427, lr=0.1] 63%|██████▎   | 59/93 [24:30<13:39, 24.11s/epoch, loss=1.11, accuracy=0.757, val_loss=2.39, val_accuracy=0.377, lr=0.1] 65%|██████▍   | 60/93 [24:53<13:06, 23.83s/epoch, loss=1.11, accuracy=0.758, val_loss=3.64, val_accuracy=0.349, lr=0.1] 66%|██████▌   | 61/93 [25:16<12:32, 23.51s/epoch, loss=1.12, accuracy=0.756, val_loss=2.15, val_accuracy=0.47, lr=0.0316] 67%|██████▋   | 62/93 [25:41<12:22, 23.94s/epoch, loss=1.11, accuracy=0.756, val_loss=2.67, val_accuracy=0.395, lr=0.1]   68%|██████▊   | 63/93 [26:04<11:51, 23.73s/epoch, loss=1.11, accuracy=0.758, val_loss=2.48, val_accuracy=0.386, lr=0.1] 69%|██████▉   | 64/93 [26:28<11:29, 23.78s/epoch, loss=1.11, accuracy=0.757, val_loss=1.74, val_accuracy=0.571, lr=0.1] 70%|██████▉   | 65/93 [26:53<11:15, 24.14s/epoch, loss=1.11, accuracy=0.76, val_loss=3.33, val_accuracy=0.287, lr=0.1]  71%|███████   | 66/93 [27:18<10:54, 24.23s/epoch, loss=1.11, accuracy=0.759, val_loss=1.56, val_accuracy=0.585, lr=0.0316] 72%|███████▏  | 67/93 [27:42<10:30, 24.25s/epoch, loss=1.1, accuracy=0.761, val_loss=1.81, val_accuracy=0.522, lr=0.1]     73%|███████▎  | 68/93 [28:05<09:57, 23.91s/epoch, loss=1.11, accuracy=0.756, val_loss=2.14, val_accuracy=0.456, lr=0.1] 74%|███████▍  | 69/93 [28:29<09:35, 23.98s/epoch, loss=1.11, accuracy=0.756, val_loss=1.51, val_accuracy=0.633, lr=0.1] 75%|███████▌  | 70/93 [28:54<09:15, 24.16s/epoch, loss=1.11, accuracy=0.758, val_loss=1.57, val_accuracy=0.59, lr=0.1]  76%|███████▋  | 71/93 [29:18<08:55, 24.35s/epoch, loss=1.11, accuracy=0.757, val_loss=1.42, val_accuracy=0.649, lr=0.1] 77%|███████▋  | 72/93 [29:41<08:21, 23.88s/epoch, loss=1.11, accuracy=0.758, val_loss=3.52, val_accuracy=0.257, lr=0.1] 78%|███████▊  | 73/93 [30:06<08:01, 24.05s/epoch, loss=1.11, accuracy=0.757, val_loss=1.87, val_accuracy=0.51, lr=0.1]  80%|███████▉  | 74/93 [30:30<07:39, 24.17s/epoch, loss=1.11, accuracy=0.759, val_loss=2.26, val_accuracy=0.406, lr=0.1] 81%|████████  | 75/93 [30:55<07:17, 24.29s/epoch, loss=1.1, accuracy=0.76, val_loss=1.72, val_accuracy=0.571, lr=0.1]   82%|████████▏ | 76/93 [31:20<06:55, 24.46s/epoch, loss=1.1, accuracy=0.761, val_loss=2.05, val_accuracy=0.452, lr=0.0316] 83%|████████▎ | 77/93 [31:44<06:30, 24.39s/epoch, loss=1.11, accuracy=0.76, val_loss=6.7, val_accuracy=0.2, lr=0.1]       84%|████████▍ | 78/93 [32:08<06:03, 24.24s/epoch, loss=1.11, accuracy=0.759, val_loss=2.79, val_accuracy=0.41, lr=0.1] 85%|████████▍ | 79/93 [32:32<05:40, 24.34s/epoch, loss=1.11, accuracy=0.758, val_loss=4.96, val_accuracy=0.248, lr=0.1] 86%|████████▌ | 80/93 [32:57<05:17, 24.41s/epoch, loss=1.11, accuracy=0.759, val_loss=6.71, val_accuracy=0.187, lr=0.1] 87%|████████▋ | 81/93 [33:21<04:51, 24.33s/epoch, loss=1.11, accuracy=0.76, val_loss=2.12, val_accuracy=0.522, lr=0.0316] 88%|████████▊ | 82/93 [33:44<04:22, 23.90s/epoch, loss=0.893, accuracy=0.821, val_loss=0.899, val_accuracy=0.801, lr=0.01] 89%|████████▉ | 83/93 [34:08<04:01, 24.11s/epoch, loss=0.725, accuracy=0.848, val_loss=0.761, val_accuracy=0.823, lr=0.01] 90%|█████████ | 84/93 [34:33<03:37, 24.21s/epoch, loss=0.643, accuracy=0.859, val_loss=0.784, val_accuracy=0.801, lr=0.01] 91%|█████████▏| 85/93 [34:57<03:13, 24.14s/epoch, loss=0.598, accuracy=0.862, val_loss=0.82, val_accuracy=0.781, lr=0.01]  92%|█████████▏| 86/93 [35:21<02:48, 24.10s/epoch, loss=0.578, accuracy=0.862, val_loss=0.73, val_accuracy=0.806, lr=0.01] 94%|█████████▎| 87/93 [35:45<02:25, 24.22s/epoch, loss=0.57, accuracy=0.86, val_loss=0.795, val_accuracy=0.782, lr=0.01]  95%|█████████▍| 88/93 [36:10<02:01, 24.38s/epoch, loss=0.564, accuracy=0.862, val_loss=0.795, val_accuracy=0.791, lr=0.01] 96%|█████████▌| 89/93 [36:33<01:36, 24.07s/epoch, loss=0.557, accuracy=0.865, val_loss=0.747, val_accuracy=0.808, lr=0.01] 97%|█████████▋| 90/93 [36:58<01:12, 24.20s/epoch, loss=0.559, accuracy=0.866, val_loss=0.947, val_accuracy=0.753, lr=0.01] 98%|█████████▊| 91/93 [37:22<00:48, 24.29s/epoch, loss=0.556, accuracy=0.868, val_loss=1.13, val_accuracy=0.704, lr=0.00316] 99%|█████████▉| 92/93 [37:47<00:24, 24.22s/epoch, loss=0.558, accuracy=0.868, val_loss=0.723, val_accuracy=0.808, lr=0.01]  100%|██████████| 93/93 [38:11<00:00, 24.39s/epoch, loss=0.55, accuracy=0.872, val_loss=0.755, val_accuracy=0.801, lr=0.01] 100%|██████████| 93/93 [38:11<00:00, 24.64s/epoch, loss=0.55, accuracy=0.872, val_loss=0.755, val_accuracy=0.801, lr=0.01]
Using real-time data augmentation.
Test loss: 0.7547256946563721
Test accuracy: 0.8008000254631042


* * * Run SGD for ID = 16_3. * * *


2024-02-15 14:54:27.324822: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 14:54:30.467937: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 14:54:30.469217: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-15 14:54:30.508504: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 14:54:30.508538: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 14:54:30.511452: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 14:54:30.511502: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 14:54:30.513753: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 14:54:30.514522: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 14:54:30.517044: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 14:54:30.518971: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 14:54:30.523558: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 14:54:30.524071: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 14:54:30.524158: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 14:54:31.841459: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-15 14:54:31.842292: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 14:54:31.842786: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 14:54:31.842819: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 14:54:31.842854: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 14:54:31.842872: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 14:54:31.842890: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 14:54:31.842926: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 14:54:31.842943: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 14:54:31.842959: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 14:54:31.842977: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 14:54:31.843413: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 14:54:31.843456: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 14:54:32.559137: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-15 14:54:32.559196: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-15 14:54:32.559206: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-15 14:54:32.562135: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': 163, 'batch_size': 128, 'epochs': 93, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/93 [00:00<?, ?epoch/s]2024-02-15 14:54:33.409121: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-15 14:54:33.421728: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2200060000 Hz
2024-02-15 14:54:35.532671: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 14:54:35.805181: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 14:54:36.599416: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-15 14:54:36.644874: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/93 [00:54<1:22:52, 54.05s/epoch, loss=3.12, accuracy=0.3, val_loss=2.67, val_accuracy=0.24, lr=0.1]  2%|▏         | 2/93 [01:18<55:44, 36.76s/epoch, loss=1.62, accuracy=0.509, val_loss=4.22, val_accuracy=0.187, lr=0.1]  3%|▎         | 3/93 [01:43<46:52, 31.25s/epoch, loss=1.4, accuracy=0.612, val_loss=2.45, val_accuracy=0.338, lr=0.1]   4%|▍         | 4/93 [02:05<41:16, 27.83s/epoch, loss=1.3, accuracy=0.668, val_loss=1.89, val_accuracy=0.462, lr=0.1]  5%|▌         | 5/93 [02:30<38:56, 26.55s/epoch, loss=1.26, accuracy=0.693, val_loss=2.16, val_accuracy=0.423, lr=0.1]  6%|▋         | 6/93 [02:54<37:09, 25.62s/epoch, loss=1.24, accuracy=0.707, val_loss=2.47, val_accuracy=0.421, lr=0.1]  8%|▊         | 7/93 [03:18<35:59, 25.11s/epoch, loss=1.23, accuracy=0.715, val_loss=1.7, val_accuracy=0.575, lr=0.1]   9%|▊         | 8/93 [03:42<35:19, 24.93s/epoch, loss=1.23, accuracy=0.721, val_loss=1.52, val_accuracy=0.612, lr=0.1] 10%|▉         | 9/93 [04:05<33:55, 24.23s/epoch, loss=1.22, accuracy=0.725, val_loss=1.5, val_accuracy=0.622, lr=0.1]  11%|█         | 10/93 [04:29<33:18, 24.08s/epoch, loss=1.22, accuracy=0.728, val_loss=2.35, val_accuracy=0.425, lr=0.1] 12%|█▏        | 11/93 [04:53<32:55, 24.09s/epoch, loss=1.21, accuracy=0.731, val_loss=2.45, val_accuracy=0.428, lr=0.1] 13%|█▎        | 12/93 [05:17<32:38, 24.18s/epoch, loss=1.21, accuracy=0.733, val_loss=2.49, val_accuracy=0.401, lr=0.1] 14%|█▍        | 13/93 [05:42<32:21, 24.26s/epoch, loss=1.21, accuracy=0.734, val_loss=1.6, val_accuracy=0.609, lr=0.1]  15%|█▌        | 14/93 [06:06<32:01, 24.33s/epoch, loss=1.21, accuracy=0.736, val_loss=2.47, val_accuracy=0.387, lr=0.0316] 16%|█▌        | 15/93 [06:29<31:15, 24.04s/epoch, loss=1.2, accuracy=0.737, val_loss=2.41, val_accuracy=0.391, lr=0.1]     17%|█▋        | 16/93 [06:53<30:29, 23.77s/epoch, loss=1.21, accuracy=0.734, val_loss=2.8, val_accuracy=0.411, lr=0.1] 18%|█▊        | 17/93 [07:18<30:40, 24.22s/epoch, loss=1.2, accuracy=0.739, val_loss=2.45, val_accuracy=0.432, lr=0.1] 19%|█▉        | 18/93 [07:42<30:19, 24.26s/epoch, loss=1.2, accuracy=0.738, val_loss=1.62, val_accuracy=0.605, lr=0.1] 20%|██        | 19/93 [08:07<30:08, 24.44s/epoch, loss=1.2, accuracy=0.74, val_loss=1.9, val_accuracy=0.514, lr=0.0316] 22%|██▏       | 20/93 [08:32<29:54, 24.58s/epoch, loss=1.19, accuracy=0.742, val_loss=1.7, val_accuracy=0.564, lr=0.1]  23%|██▎       | 21/93 [08:56<29:29, 24.57s/epoch, loss=1.19, accuracy=0.743, val_loss=2.76, val_accuracy=0.441, lr=0.1] 24%|██▎       | 22/93 [09:20<28:39, 24.22s/epoch, loss=1.19, accuracy=0.742, val_loss=1.77, val_accuracy=0.541, lr=0.1] 25%|██▍       | 23/93 [09:45<28:34, 24.49s/epoch, loss=1.19, accuracy=0.744, val_loss=1.99, val_accuracy=0.545, lr=0.1] 26%|██▌       | 24/93 [10:10<28:27, 24.75s/epoch, loss=1.19, accuracy=0.746, val_loss=1.73, val_accuracy=0.554, lr=0.0316] 27%|██▋       | 25/93 [10:35<27:59, 24.70s/epoch, loss=1.18, accuracy=0.745, val_loss=2.6, val_accuracy=0.467, lr=0.1]     28%|██▊       | 26/93 [11:00<27:41, 24.79s/epoch, loss=1.18, accuracy=0.748, val_loss=1.65, val_accuracy=0.596, lr=0.1] 29%|██▉       | 27/93 [11:25<27:13, 24.76s/epoch, loss=1.19, accuracy=0.746, val_loss=2.2, val_accuracy=0.493, lr=0.1]  30%|███       | 28/93 [11:48<26:31, 24.49s/epoch, loss=1.19, accuracy=0.745, val_loss=2.45, val_accuracy=0.418, lr=0.1] 31%|███       | 29/93 [12:12<25:47, 24.18s/epoch, loss=1.18, accuracy=0.747, val_loss=1.52, val_accuracy=0.621, lr=0.0316] 32%|███▏      | 30/93 [12:36<25:29, 24.27s/epoch, loss=1.18, accuracy=0.743, val_loss=2.33, val_accuracy=0.502, lr=0.1]    33%|███▎      | 31/93 [13:01<25:12, 24.39s/epoch, loss=1.17, accuracy=0.749, val_loss=1.71, val_accuracy=0.558, lr=0.1] 34%|███▍      | 32/93 [13:25<24:44, 24.33s/epoch, loss=1.17, accuracy=0.748, val_loss=1.66, val_accuracy=0.58, lr=0.1]  35%|███▌      | 33/93 [13:49<24:15, 24.26s/epoch, loss=1.17, accuracy=0.75, val_loss=2.14, val_accuracy=0.531, lr=0.1] 37%|███▋      | 34/93 [14:14<23:59, 24.39s/epoch, loss=1.17, accuracy=0.75, val_loss=2.39, val_accuracy=0.43, lr=0.0316] 38%|███▊      | 35/93 [14:37<23:10, 23.98s/epoch, loss=1.17, accuracy=0.747, val_loss=1.84, val_accuracy=0.525, lr=0.1]  39%|███▊      | 36/93 [15:00<22:27, 23.64s/epoch, loss=1.17, accuracy=0.749, val_loss=2.42, val_accuracy=0.451, lr=0.1] 40%|███▉      | 37/93 [15:24<22:05, 23.68s/epoch, loss=1.17, accuracy=0.751, val_loss=2.2, val_accuracy=0.465, lr=0.1]  41%|████      | 38/93 [15:48<21:50, 23.82s/epoch, loss=1.17, accuracy=0.748, val_loss=1.64, val_accuracy=0.589, lr=0.1] 42%|████▏     | 39/93 [16:12<21:28, 23.87s/epoch, loss=1.16, accuracy=0.752, val_loss=1.78, val_accuracy=0.539, lr=0.0316] 43%|████▎     | 40/93 [16:35<20:55, 23.69s/epoch, loss=1.16, accuracy=0.75, val_loss=1.58, val_accuracy=0.587, lr=0.1]     44%|████▍     | 41/93 [16:59<20:28, 23.63s/epoch, loss=1.16, accuracy=0.754, val_loss=1.51, val_accuracy=0.612, lr=0.1] 45%|████▌     | 42/93 [17:22<20:05, 23.63s/epoch, loss=1.15, accuracy=0.754, val_loss=1.58, val_accuracy=0.636, lr=0.1] 46%|████▌     | 43/93 [17:46<19:48, 23.76s/epoch, loss=1.16, accuracy=0.75, val_loss=2.35, val_accuracy=0.482, lr=0.1]  47%|████▋     | 44/93 [18:09<19:10, 23.47s/epoch, loss=1.16, accuracy=0.752, val_loss=1.8, val_accuracy=0.512, lr=0.0316] 48%|████▊     | 45/93 [18:32<18:34, 23.22s/epoch, loss=1.15, accuracy=0.753, val_loss=2.64, val_accuracy=0.405, lr=0.1]   49%|████▉     | 46/93 [18:55<18:17, 23.34s/epoch, loss=1.15, accuracy=0.757, val_loss=1.67, val_accuracy=0.565, lr=0.1] 51%|█████     | 47/93 [19:18<17:50, 23.27s/epoch, loss=1.15, accuracy=0.753, val_loss=2.37, val_accuracy=0.456, lr=0.1] 52%|█████▏    | 48/93 [19:41<17:15, 23.01s/epoch, loss=1.16, accuracy=0.751, val_loss=1.69, val_accuracy=0.584, lr=0.1] 53%|█████▎    | 49/93 [20:03<16:45, 22.86s/epoch, loss=1.16, accuracy=0.753, val_loss=2.76, val_accuracy=0.432, lr=0.0316] 54%|█████▍    | 50/93 [20:28<16:40, 23.27s/epoch, loss=1.16, accuracy=0.754, val_loss=2.46, val_accuracy=0.332, lr=0.1]    55%|█████▍    | 51/93 [20:51<16:16, 23.26s/epoch, loss=1.15, accuracy=0.755, val_loss=1.71, val_accuracy=0.606, lr=0.1] 56%|█████▌    | 52/93 [21:16<16:11, 23.69s/epoch, loss=1.15, accuracy=0.754, val_loss=1.96, val_accuracy=0.528, lr=0.1] 57%|█████▋    | 53/93 [21:40<15:52, 23.82s/epoch, loss=1.16, accuracy=0.751, val_loss=1.63, val_accuracy=0.59, lr=0.1]  58%|█████▊    | 54/93 [22:04<15:36, 24.02s/epoch, loss=1.15, accuracy=0.754, val_loss=1.51, val_accuracy=0.627, lr=0.0316] 59%|█████▉    | 55/93 [22:28<15:13, 24.05s/epoch, loss=1.16, accuracy=0.752, val_loss=1.89, val_accuracy=0.535, lr=0.1]    60%|██████    | 56/93 [22:53<14:58, 24.28s/epoch, loss=1.15, accuracy=0.755, val_loss=1.89, val_accuracy=0.518, lr=0.1] 61%|██████▏   | 57/93 [23:16<14:21, 23.94s/epoch, loss=1.15, accuracy=0.753, val_loss=1.75, val_accuracy=0.556, lr=0.1] 62%|██████▏   | 58/93 [23:39<13:47, 23.65s/epoch, loss=1.14, accuracy=0.759, val_loss=2.43, val_accuracy=0.378, lr=0.1] 63%|██████▎   | 59/93 [24:03<13:22, 23.60s/epoch, loss=1.15, accuracy=0.752, val_loss=1.77, val_accuracy=0.543, lr=0.0316] 65%|██████▍   | 60/93 [24:27<13:09, 23.92s/epoch, loss=1.15, accuracy=0.756, val_loss=1.6, val_accuracy=0.606, lr=0.1]     66%|██████▌   | 61/93 [24:51<12:44, 23.88s/epoch, loss=1.14, accuracy=0.757, val_loss=1.88, val_accuracy=0.516, lr=0.1] 67%|██████▋   | 62/93 [25:15<12:15, 23.73s/epoch, loss=1.14, accuracy=0.754, val_loss=1.54, val_accuracy=0.618, lr=0.1] 68%|██████▊   | 63/93 [25:37<11:43, 23.44s/epoch, loss=1.14, accuracy=0.757, val_loss=2.8, val_accuracy=0.355, lr=0.1]  69%|██████▉   | 64/93 [26:01<11:21, 23.51s/epoch, loss=1.14, accuracy=0.757, val_loss=1.52, val_accuracy=0.623, lr=0.0316] 70%|██████▉   | 65/93 [26:25<11:06, 23.81s/epoch, loss=1.14, accuracy=0.755, val_loss=2.28, val_accuracy=0.467, lr=0.1]    71%|███████   | 66/93 [26:50<10:46, 23.95s/epoch, loss=1.13, accuracy=0.757, val_loss=1.67, val_accuracy=0.577, lr=0.1] 72%|███████▏  | 67/93 [27:13<10:18, 23.79s/epoch, loss=1.14, accuracy=0.753, val_loss=2.29, val_accuracy=0.421, lr=0.1] 73%|███████▎  | 68/93 [27:37<09:55, 23.82s/epoch, loss=1.13, accuracy=0.755, val_loss=1.8, val_accuracy=0.533, lr=0.1]  74%|███████▍  | 69/93 [28:01<09:34, 23.92s/epoch, loss=1.13, accuracy=0.758, val_loss=2.71, val_accuracy=0.398, lr=0.0316] 75%|███████▌  | 70/93 [28:26<09:14, 24.11s/epoch, loss=1.14, accuracy=0.755, val_loss=1.95, val_accuracy=0.507, lr=0.1]    76%|███████▋  | 71/93 [28:49<08:43, 23.78s/epoch, loss=1.13, accuracy=0.757, val_loss=1.99, val_accuracy=0.504, lr=0.1] 77%|███████▋  | 72/93 [29:13<08:21, 23.89s/epoch, loss=1.13, accuracy=0.757, val_loss=2.19, val_accuracy=0.439, lr=0.1] 78%|███████▊  | 73/93 [29:37<07:59, 23.99s/epoch, loss=1.14, accuracy=0.756, val_loss=2.18, val_accuracy=0.457, lr=0.1] 80%|███████▉  | 74/93 [30:00<07:29, 23.68s/epoch, loss=1.14, accuracy=0.755, val_loss=3.13, val_accuracy=0.244, lr=0.0316] 81%|████████  | 75/93 [30:24<07:05, 23.65s/epoch, loss=1.13, accuracy=0.757, val_loss=1.86, val_accuracy=0.573, lr=0.1]    82%|████████▏ | 76/93 [30:48<06:44, 23.77s/epoch, loss=1.13, accuracy=0.756, val_loss=3.59, val_accuracy=0.279, lr=0.1] 83%|████████▎ | 77/93 [31:12<06:22, 23.89s/epoch, loss=1.13, accuracy=0.757, val_loss=2.57, val_accuracy=0.452, lr=0.1] 84%|████████▍ | 78/93 [31:36<05:58, 23.92s/epoch, loss=1.12, accuracy=0.759, val_loss=4.29, val_accuracy=0.249, lr=0.1] 85%|████████▍ | 79/93 [32:00<05:34, 23.89s/epoch, loss=1.13, accuracy=0.759, val_loss=3.32, val_accuracy=0.326, lr=0.0316] 86%|████████▌ | 80/93 [32:24<05:12, 24.00s/epoch, loss=1.13, accuracy=0.757, val_loss=2.05, val_accuracy=0.418, lr=0.1]    87%|████████▋ | 81/93 [32:48<04:49, 24.09s/epoch, loss=1.14, accuracy=0.755, val_loss=2.34, val_accuracy=0.483, lr=0.1] 88%|████████▊ | 82/93 [33:12<04:22, 23.88s/epoch, loss=0.913, accuracy=0.817, val_loss=0.962, val_accuracy=0.777, lr=0.01] 89%|████████▉ | 83/93 [33:35<03:57, 23.71s/epoch, loss=0.735, accuracy=0.849, val_loss=0.788, val_accuracy=0.817, lr=0.01] 90%|█████████ | 84/93 [33:59<03:35, 23.93s/epoch, loss=0.655, accuracy=0.855, val_loss=0.808, val_accuracy=0.793, lr=0.01] 91%|█████████▏| 85/93 [34:23<03:10, 23.87s/epoch, loss=0.608, accuracy=0.861, val_loss=0.719, val_accuracy=0.821, lr=0.01] 92%|█████████▏| 86/93 [34:48<02:48, 24.04s/epoch, loss=0.589, accuracy=0.86, val_loss=0.74, val_accuracy=0.803, lr=0.01]   94%|█████████▎| 87/93 [35:12<02:25, 24.18s/epoch, loss=0.575, accuracy=0.864, val_loss=0.715, val_accuracy=0.812, lr=0.01] 95%|█████████▍| 88/93 [35:36<02:01, 24.25s/epoch, loss=0.567, accuracy=0.865, val_loss=0.689, val_accuracy=0.822, lr=0.01] 96%|█████████▌| 89/93 [36:00<01:36, 24.16s/epoch, loss=0.564, accuracy=0.867, val_loss=0.758, val_accuracy=0.803, lr=0.01] 97%|█████████▋| 90/93 [36:24<01:11, 23.96s/epoch, loss=0.559, accuracy=0.868, val_loss=1.61, val_accuracy=0.623, lr=0.01]  98%|█████████▊| 91/93 [36:47<00:47, 23.73s/epoch, loss=0.561, accuracy=0.868, val_loss=0.788, val_accuracy=0.801, lr=0.01] 99%|█████████▉| 92/93 [37:11<00:23, 23.69s/epoch, loss=0.559, accuracy=0.87, val_loss=0.856, val_accuracy=0.776, lr=0.01] 100%|██████████| 93/93 [37:34<00:00, 23.71s/epoch, loss=0.563, accuracy=0.869, val_loss=0.804, val_accuracy=0.802, lr=0.00316]100%|██████████| 93/93 [37:34<00:00, 24.25s/epoch, loss=0.563, accuracy=0.869, val_loss=0.804, val_accuracy=0.802, lr=0.00316]
Using real-time data augmentation.
Test loss: 0.8040264248847961
Test accuracy: 0.8021000027656555


* * * Run SGD for ID = 16_4. * * *


2024-02-15 15:32:10.852478: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 15:32:13.674383: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 15:32:13.675508: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-15 15:32:13.716786: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 15:32:13.716825: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 15:32:13.719657: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 15:32:13.719701: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 15:32:13.721853: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 15:32:13.722512: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 15:32:13.725021: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 15:32:13.726542: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 15:32:13.731325: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 15:32:13.731861: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 15:32:13.731941: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 15:32:15.041684: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-15 15:32:15.042860: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 15:32:15.043315: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 15:32:15.043345: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 15:32:15.043379: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 15:32:15.043397: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 15:32:15.043414: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 15:32:15.043430: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 15:32:15.043447: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 15:32:15.043464: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 15:32:15.043481: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 15:32:15.043981: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 15:32:15.044016: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 15:32:15.754743: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-15 15:32:15.754819: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-15 15:32:15.754830: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-15 15:32:15.756196: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': 164, 'batch_size': 128, 'epochs': 93, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/93 [00:00<?, ?epoch/s]2024-02-15 15:32:16.584887: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-15 15:32:16.596715: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2200060000 Hz
2024-02-15 15:32:18.663799: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 15:32:18.911364: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 15:32:19.622945: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-15 15:32:19.657971: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/93 [00:55<1:24:33, 55.14s/epoch, loss=3.2, accuracy=0.296, val_loss=2.28, val_accuracy=0.25, lr=0.1]  2%|▏         | 2/93 [01:18<55:19, 36.48s/epoch, loss=1.65, accuracy=0.483, val_loss=2.45, val_accuracy=0.336, lr=0.1]  3%|▎         | 3/93 [01:42<45:50, 30.56s/epoch, loss=1.42, accuracy=0.6, val_loss=1.63, val_accuracy=0.551, lr=0.1]    4%|▍         | 4/93 [02:05<41:07, 27.72s/epoch, loss=1.31, accuracy=0.671, val_loss=1.62, val_accuracy=0.567, lr=0.1]  5%|▌         | 5/93 [02:28<38:02, 25.94s/epoch, loss=1.28, accuracy=0.691, val_loss=2.18, val_accuracy=0.434, lr=0.1]  6%|▋         | 6/93 [02:53<37:08, 25.62s/epoch, loss=1.25, accuracy=0.706, val_loss=1.44, val_accuracy=0.622, lr=0.1]  8%|▊         | 7/93 [03:17<36:12, 25.27s/epoch, loss=1.24, accuracy=0.714, val_loss=1.99, val_accuracy=0.446, lr=0.1]  9%|▊         | 8/93 [03:42<35:42, 25.20s/epoch, loss=1.23, accuracy=0.717, val_loss=1.58, val_accuracy=0.594, lr=0.1] 10%|▉         | 9/93 [04:06<34:38, 24.74s/epoch, loss=1.22, accuracy=0.724, val_loss=2.06, val_accuracy=0.51, lr=0.1]  11%|█         | 10/93 [04:30<34:02, 24.61s/epoch, loss=1.22, accuracy=0.726, val_loss=1.87, val_accuracy=0.541, lr=0.1] 12%|█▏        | 11/93 [04:55<33:40, 24.64s/epoch, loss=1.21, accuracy=0.727, val_loss=1.62, val_accuracy=0.572, lr=0.0316] 13%|█▎        | 12/93 [05:20<33:26, 24.77s/epoch, loss=1.21, accuracy=0.734, val_loss=1.75, val_accuracy=0.544, lr=0.1]    14%|█▍        | 13/93 [05:45<32:55, 24.69s/epoch, loss=1.2, accuracy=0.735, val_loss=1.66, val_accuracy=0.578, lr=0.1]  15%|█▌        | 14/93 [06:08<32:03, 24.35s/epoch, loss=1.2, accuracy=0.736, val_loss=1.78, val_accuracy=0.539, lr=0.1] 16%|█▌        | 15/93 [06:32<31:24, 24.15s/epoch, loss=1.19, accuracy=0.738, val_loss=1.59, val_accuracy=0.625, lr=0.1] 17%|█▋        | 16/93 [06:55<30:39, 23.90s/epoch, loss=1.2, accuracy=0.738, val_loss=2.34, val_accuracy=0.532, lr=0.0316] 18%|█▊        | 17/93 [07:19<30:11, 23.84s/epoch, loss=1.19, accuracy=0.737, val_loss=2.71, val_accuracy=0.421, lr=0.1]   19%|█▉        | 18/93 [07:43<30:04, 24.06s/epoch, loss=1.2, accuracy=0.741, val_loss=2.25, val_accuracy=0.469, lr=0.1]  20%|██        | 19/93 [08:06<29:16, 23.73s/epoch, loss=1.2, accuracy=0.738, val_loss=2.16, val_accuracy=0.383, lr=0.1] 22%|██▏       | 20/93 [08:29<28:35, 23.51s/epoch, loss=1.18, accuracy=0.74, val_loss=1.69, val_accuracy=0.591, lr=0.1] 23%|██▎       | 21/93 [08:52<28:00, 23.34s/epoch, loss=1.18, accuracy=0.742, val_loss=1.95, val_accuracy=0.51, lr=0.0316] 24%|██▎       | 22/93 [09:16<27:35, 23.31s/epoch, loss=1.18, accuracy=0.742, val_loss=1.93, val_accuracy=0.528, lr=0.1]   25%|██▍       | 23/93 [09:41<27:49, 23.85s/epoch, loss=1.18, accuracy=0.743, val_loss=1.84, val_accuracy=0.551, lr=0.1] 26%|██▌       | 24/93 [10:05<27:42, 24.09s/epoch, loss=1.17, accuracy=0.746, val_loss=2.3, val_accuracy=0.436, lr=0.1]  27%|██▋       | 25/93 [10:28<26:55, 23.75s/epoch, loss=1.18, accuracy=0.744, val_loss=1.97, val_accuracy=0.524, lr=0.1] 28%|██▊       | 26/93 [10:52<26:23, 23.63s/epoch, loss=1.18, accuracy=0.744, val_loss=1.42, val_accuracy=0.654, lr=0.1] 29%|██▉       | 27/93 [11:17<26:26, 24.04s/epoch, loss=1.17, accuracy=0.744, val_loss=1.75, val_accuracy=0.591, lr=0.1] 30%|███       | 28/93 [11:42<26:23, 24.37s/epoch, loss=1.18, accuracy=0.744, val_loss=1.85, val_accuracy=0.527, lr=0.1] 31%|███       | 29/93 [12:07<26:15, 24.62s/epoch, loss=1.17, accuracy=0.748, val_loss=2.04, val_accuracy=0.484, lr=0.1] 32%|███▏      | 30/93 [12:31<25:42, 24.48s/epoch, loss=1.17, accuracy=0.747, val_loss=1.91, val_accuracy=0.493, lr=0.1] 33%|███▎      | 31/93 [12:55<25:03, 24.25s/epoch, loss=1.17, accuracy=0.747, val_loss=1.46, val_accuracy=0.639, lr=0.0316] 34%|███▍      | 32/93 [13:20<24:59, 24.58s/epoch, loss=1.17, accuracy=0.749, val_loss=2.47, val_accuracy=0.453, lr=0.1]    35%|███▌      | 33/93 [13:44<24:14, 24.25s/epoch, loss=1.16, accuracy=0.747, val_loss=1.86, val_accuracy=0.501, lr=0.1] 37%|███▋      | 34/93 [14:08<23:59, 24.40s/epoch, loss=1.16, accuracy=0.75, val_loss=1.9, val_accuracy=0.525, lr=0.1]   38%|███▊      | 35/93 [14:33<23:43, 24.54s/epoch, loss=1.17, accuracy=0.747, val_loss=1.47, val_accuracy=0.65, lr=0.1] 39%|███▊      | 36/93 [14:58<23:21, 24.58s/epoch, loss=1.16, accuracy=0.749, val_loss=2.17, val_accuracy=0.472, lr=0.0316] 40%|███▉      | 37/93 [15:23<22:55, 24.55s/epoch, loss=1.17, accuracy=0.749, val_loss=1.73, val_accuracy=0.59, lr=0.1]     41%|████      | 38/93 [15:46<22:20, 24.37s/epoch, loss=1.16, accuracy=0.75, val_loss=1.83, val_accuracy=0.546, lr=0.1] 42%|████▏     | 39/93 [16:11<22:00, 24.45s/epoch, loss=1.15, accuracy=0.75, val_loss=1.8, val_accuracy=0.536, lr=0.1]  43%|████▎     | 40/93 [16:36<21:41, 24.55s/epoch, loss=1.16, accuracy=0.751, val_loss=3.55, val_accuracy=0.385, lr=0.1] 44%|████▍     | 41/93 [17:00<21:14, 24.51s/epoch, loss=1.15, accuracy=0.752, val_loss=1.89, val_accuracy=0.552, lr=0.0316] 45%|████▌     | 42/93 [17:25<20:46, 24.44s/epoch, loss=1.15, accuracy=0.75, val_loss=1.84, val_accuracy=0.52, lr=0.1]      46%|████▌     | 43/93 [17:49<20:28, 24.58s/epoch, loss=1.16, accuracy=0.751, val_loss=1.99, val_accuracy=0.471, lr=0.1] 47%|████▋     | 44/93 [18:14<19:56, 24.42s/epoch, loss=1.15, accuracy=0.753, val_loss=2.13, val_accuracy=0.51, lr=0.1]  48%|████▊     | 45/93 [18:38<19:26, 24.30s/epoch, loss=1.15, accuracy=0.751, val_loss=3.08, val_accuracy=0.41, lr=0.1] 49%|████▉     | 46/93 [19:02<18:59, 24.25s/epoch, loss=1.15, accuracy=0.75, val_loss=1.93, val_accuracy=0.493, lr=0.0316] 51%|█████     | 47/93 [19:26<18:40, 24.37s/epoch, loss=1.16, accuracy=0.75, val_loss=2.22, val_accuracy=0.523, lr=0.1]    52%|█████▏    | 48/93 [19:51<18:24, 24.54s/epoch, loss=1.15, accuracy=0.751, val_loss=1.41, val_accuracy=0.663, lr=0.1] 53%|█████▎    | 49/93 [20:14<17:40, 24.11s/epoch, loss=1.14, accuracy=0.753, val_loss=2.51, val_accuracy=0.429, lr=0.1] 54%|█████▍    | 50/93 [20:39<17:26, 24.34s/epoch, loss=1.14, accuracy=0.754, val_loss=1.67, val_accuracy=0.604, lr=0.1] 55%|█████▍    | 51/93 [21:04<17:07, 24.47s/epoch, loss=1.14, accuracy=0.753, val_loss=2.25, val_accuracy=0.488, lr=0.1] 56%|█████▌    | 52/93 [21:29<16:47, 24.58s/epoch, loss=1.15, accuracy=0.754, val_loss=1.58, val_accuracy=0.614, lr=0.1] 57%|█████▋    | 53/93 [21:52<16:08, 24.21s/epoch, loss=1.15, accuracy=0.752, val_loss=1.98, val_accuracy=0.539, lr=0.0316] 58%|█████▊    | 54/93 [22:17<15:46, 24.26s/epoch, loss=1.15, accuracy=0.754, val_loss=2.14, val_accuracy=0.535, lr=0.1]    59%|█████▉    | 55/93 [22:41<15:23, 24.30s/epoch, loss=1.15, accuracy=0.754, val_loss=3.37, val_accuracy=0.319, lr=0.1] 60%|██████    | 56/93 [23:06<15:03, 24.41s/epoch, loss=1.15, accuracy=0.752, val_loss=1.76, val_accuracy=0.563, lr=0.1] 61%|██████▏   | 57/93 [23:29<14:29, 24.16s/epoch, loss=1.14, accuracy=0.755, val_loss=3.78, val_accuracy=0.248, lr=0.1] 62%|██████▏   | 58/93 [23:54<14:12, 24.36s/epoch, loss=1.15, accuracy=0.752, val_loss=1.91, val_accuracy=0.545, lr=0.0316] 63%|██████▎   | 59/93 [24:19<13:51, 24.44s/epoch, loss=1.14, accuracy=0.756, val_loss=1.83, val_accuracy=0.514, lr=0.1]    65%|██████▍   | 60/93 [24:43<13:29, 24.54s/epoch, loss=1.14, accuracy=0.756, val_loss=1.5, val_accuracy=0.639, lr=0.1]  66%|██████▌   | 61/93 [25:08<13:05, 24.54s/epoch, loss=1.15, accuracy=0.749, val_loss=2.3, val_accuracy=0.467, lr=0.1] 67%|██████▋   | 62/93 [25:32<12:32, 24.27s/epoch, loss=1.14, accuracy=0.754, val_loss=1.53, val_accuracy=0.603, lr=0.1] 68%|██████▊   | 63/93 [25:56<12:06, 24.21s/epoch, loss=1.14, accuracy=0.753, val_loss=1.63, val_accuracy=0.608, lr=0.0316] 69%|██████▉   | 64/93 [26:21<11:48, 24.43s/epoch, loss=1.14, accuracy=0.754, val_loss=1.79, val_accuracy=0.562, lr=0.1]    70%|██████▉   | 65/93 [26:45<11:23, 24.42s/epoch, loss=1.14, accuracy=0.754, val_loss=2.82, val_accuracy=0.407, lr=0.1] 71%|███████   | 66/93 [27:08<10:49, 24.06s/epoch, loss=1.14, accuracy=0.756, val_loss=1.73, val_accuracy=0.589, lr=0.1] 72%|███████▏  | 67/93 [27:31<10:15, 23.67s/epoch, loss=1.15, accuracy=0.753, val_loss=2.59, val_accuracy=0.423, lr=0.1] 73%|███████▎  | 68/93 [27:55<09:55, 23.84s/epoch, loss=1.15, accuracy=0.752, val_loss=1.58, val_accuracy=0.635, lr=0.0316] 74%|███████▍  | 69/93 [28:19<09:29, 23.72s/epoch, loss=1.15, accuracy=0.754, val_loss=1.5, val_accuracy=0.623, lr=0.1]     75%|███████▌  | 70/93 [28:43<09:12, 24.03s/epoch, loss=1.14, accuracy=0.754, val_loss=1.67, val_accuracy=0.561, lr=0.1] 76%|███████▋  | 71/93 [29:08<08:52, 24.21s/epoch, loss=1.14, accuracy=0.754, val_loss=1.76, val_accuracy=0.567, lr=0.1] 77%|███████▋  | 72/93 [29:32<08:24, 24.01s/epoch, loss=1.14, accuracy=0.755, val_loss=1.62, val_accuracy=0.609, lr=0.1] 78%|███████▊  | 73/93 [29:57<08:06, 24.31s/epoch, loss=1.14, accuracy=0.755, val_loss=3, val_accuracy=0.381, lr=0.0316] 80%|███████▉  | 74/93 [30:20<07:34, 23.90s/epoch, loss=1.14, accuracy=0.753, val_loss=2.54, val_accuracy=0.357, lr=0.1] 81%|████████  | 75/93 [30:43<07:09, 23.88s/epoch, loss=1.15, accuracy=0.754, val_loss=1.45, val_accuracy=0.641, lr=0.1] 82%|████████▏ | 76/93 [31:08<06:50, 24.15s/epoch, loss=1.14, accuracy=0.752, val_loss=1.96, val_accuracy=0.547, lr=0.1] 83%|████████▎ | 77/93 [31:33<06:27, 24.24s/epoch, loss=1.14, accuracy=0.751, val_loss=1.99, val_accuracy=0.486, lr=0.1] 84%|████████▍ | 78/93 [31:56<06:01, 24.11s/epoch, loss=1.14, accuracy=0.756, val_loss=1.84, val_accuracy=0.538, lr=0.0316] 85%|████████▍ | 79/93 [32:21<05:39, 24.27s/epoch, loss=1.14, accuracy=0.755, val_loss=2.59, val_accuracy=0.402, lr=0.1]    86%|████████▌ | 80/93 [32:45<05:14, 24.17s/epoch, loss=1.14, accuracy=0.755, val_loss=1.91, val_accuracy=0.529, lr=0.1] 87%|████████▋ | 81/93 [33:09<04:50, 24.25s/epoch, loss=1.15, accuracy=0.752, val_loss=1.52, val_accuracy=0.614, lr=0.1] 88%|████████▊ | 82/93 [33:33<04:26, 24.18s/epoch, loss=0.931, accuracy=0.815, val_loss=0.951, val_accuracy=0.788, lr=0.01] 89%|████████▉ | 83/93 [33:56<03:57, 23.77s/epoch, loss=0.748, accuracy=0.846, val_loss=0.816, val_accuracy=0.809, lr=0.01] 90%|█████████ | 84/93 [34:19<03:31, 23.48s/epoch, loss=0.663, accuracy=0.856, val_loss=0.831, val_accuracy=0.789, lr=0.01] 91%|█████████▏| 85/93 [34:44<03:10, 23.75s/epoch, loss=0.619, accuracy=0.858, val_loss=0.744, val_accuracy=0.811, lr=0.01] 92%|█████████▏| 86/93 [35:06<02:44, 23.45s/epoch, loss=0.598, accuracy=0.859, val_loss=0.7, val_accuracy=0.823, lr=0.01]   94%|█████████▎| 87/93 [35:31<02:22, 23.77s/epoch, loss=0.59, accuracy=0.859, val_loss=0.819, val_accuracy=0.79, lr=0.01] 95%|█████████▍| 88/93 [35:55<01:59, 24.00s/epoch, loss=0.582, accuracy=0.86, val_loss=0.746, val_accuracy=0.801, lr=0.01] 96%|█████████▌| 89/93 [36:20<01:36, 24.24s/epoch, loss=0.577, accuracy=0.863, val_loss=0.956, val_accuracy=0.754, lr=0.01] 97%|█████████▋| 90/93 [36:45<01:13, 24.34s/epoch, loss=0.574, accuracy=0.865, val_loss=0.757, val_accuracy=0.803, lr=0.01] 98%|█████████▊| 91/93 [37:09<00:48, 24.43s/epoch, loss=0.572, accuracy=0.865, val_loss=0.77, val_accuracy=0.801, lr=0.00316] 99%|█████████▉| 92/93 [37:34<00:24, 24.51s/epoch, loss=0.573, accuracy=0.866, val_loss=0.977, val_accuracy=0.759, lr=0.01]  100%|██████████| 93/93 [37:57<00:00, 24.09s/epoch, loss=0.571, accuracy=0.867, val_loss=0.717, val_accuracy=0.82, lr=0.01] 100%|██████████| 93/93 [37:57<00:00, 24.49s/epoch, loss=0.571, accuracy=0.867, val_loss=0.717, val_accuracy=0.82, lr=0.01]
Using real-time data augmentation.
Test loss: 0.7174198627471924
Test accuracy: 0.8197000026702881


* * * Run SGD for ID = 16_5. * * *


2024-02-15 16:10:16.599448: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 16:10:19.539268: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 16:10:19.540397: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-15 16:10:19.579254: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 16:10:19.579292: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 16:10:19.582192: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 16:10:19.582236: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 16:10:19.584397: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 16:10:19.585041: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 16:10:19.587403: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 16:10:19.588901: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 16:10:19.593531: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 16:10:19.594053: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 16:10:19.594131: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 16:10:20.908105: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-15 16:10:20.908728: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 16:10:20.909172: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 16:10:20.909202: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 16:10:20.909236: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 16:10:20.909256: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 16:10:20.909275: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 16:10:20.909293: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 16:10:20.909312: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 16:10:20.909330: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 16:10:20.909355: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 16:10:20.909838: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 16:10:20.909896: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 16:10:21.614391: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-15 16:10:21.614450: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-15 16:10:21.614460: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-15 16:10:21.615699: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': 165, 'batch_size': 128, 'epochs': 93, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/93 [00:00<?, ?epoch/s]2024-02-15 16:10:22.429341: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-15 16:10:22.441719: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2200060000 Hz
2024-02-15 16:10:24.559445: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 16:10:24.796330: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 16:10:25.727235: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-15 16:10:25.776490: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/93 [00:59<1:30:32, 59.05s/epoch, loss=3.2, accuracy=0.3, val_loss=2.63, val_accuracy=0.219, lr=0.1]  2%|▏         | 2/93 [01:24<59:09, 39.00s/epoch, loss=1.51, accuracy=0.557, val_loss=2.27, val_accuracy=0.379, lr=0.1]  3%|▎         | 3/93 [01:48<48:38, 32.43s/epoch, loss=1.3, accuracy=0.657, val_loss=1.8, val_accuracy=0.52, lr=0.1]     4%|▍         | 4/93 [02:12<42:48, 28.86s/epoch, loss=1.25, accuracy=0.693, val_loss=1.95, val_accuracy=0.482, lr=0.1]  5%|▌         | 5/93 [02:36<39:53, 27.20s/epoch, loss=1.23, accuracy=0.706, val_loss=2.92, val_accuracy=0.382, lr=0.1]  6%|▋         | 6/93 [03:00<37:44, 26.03s/epoch, loss=1.21, accuracy=0.717, val_loss=2.01, val_accuracy=0.489, lr=0.1]  8%|▊         | 7/93 [03:24<36:40, 25.59s/epoch, loss=1.21, accuracy=0.718, val_loss=2.3, val_accuracy=0.43, lr=0.1]    9%|▊         | 8/93 [03:47<34:57, 24.67s/epoch, loss=1.2, accuracy=0.727, val_loss=1.85, val_accuracy=0.57, lr=0.0316] 10%|▉         | 9/93 [04:11<34:26, 24.60s/epoch, loss=1.19, accuracy=0.731, val_loss=2.26, val_accuracy=0.427, lr=0.1]  11%|█         | 10/93 [04:36<33:52, 24.49s/epoch, loss=1.19, accuracy=0.732, val_loss=1.37, val_accuracy=0.659, lr=0.1] 12%|█▏        | 11/93 [05:00<33:28, 24.49s/epoch, loss=1.18, accuracy=0.734, val_loss=2.16, val_accuracy=0.492, lr=0.1] 13%|█▎        | 12/93 [05:24<32:53, 24.36s/epoch, loss=1.18, accuracy=0.737, val_loss=2.04, val_accuracy=0.552, lr=0.1] 14%|█▍        | 13/93 [05:48<32:14, 24.18s/epoch, loss=1.17, accuracy=0.739, val_loss=2.09, val_accuracy=0.468, lr=0.1] 15%|█▌        | 14/93 [06:11<31:16, 23.75s/epoch, loss=1.17, accuracy=0.741, val_loss=1.81, val_accuracy=0.544, lr=0.1] 16%|█▌        | 15/93 [06:36<31:21, 24.12s/epoch, loss=1.17, accuracy=0.74, val_loss=1.97, val_accuracy=0.472, lr=0.0316] 17%|█▋        | 16/93 [07:00<31:12, 24.31s/epoch, loss=1.16, accuracy=0.742, val_loss=1.89, val_accuracy=0.545, lr=0.1]   18%|█▊        | 17/93 [07:25<30:43, 24.26s/epoch, loss=1.17, accuracy=0.74, val_loss=1.79, val_accuracy=0.499, lr=0.1]  19%|█▉        | 18/93 [07:49<30:27, 24.36s/epoch, loss=1.17, accuracy=0.742, val_loss=1.57, val_accuracy=0.627, lr=0.1] 20%|██        | 19/93 [08:14<30:03, 24.37s/epoch, loss=1.17, accuracy=0.744, val_loss=1.58, val_accuracy=0.618, lr=0.1] 22%|██▏       | 20/93 [08:37<29:25, 24.19s/epoch, loss=1.16, accuracy=0.747, val_loss=1.66, val_accuracy=0.612, lr=0.0316] 23%|██▎       | 21/93 [09:02<29:05, 24.24s/epoch, loss=1.15, accuracy=0.749, val_loss=2.94, val_accuracy=0.364, lr=0.1]    24%|██▎       | 22/93 [09:26<28:51, 24.39s/epoch, loss=1.15, accuracy=0.748, val_loss=2.14, val_accuracy=0.547, lr=0.1] 25%|██▍       | 23/93 [09:51<28:29, 24.42s/epoch, loss=1.15, accuracy=0.748, val_loss=1.8, val_accuracy=0.549, lr=0.1]  26%|██▌       | 24/93 [10:16<28:12, 24.53s/epoch, loss=1.15, accuracy=0.747, val_loss=2.31, val_accuracy=0.431, lr=0.1] 27%|██▋       | 25/93 [10:40<27:44, 24.47s/epoch, loss=1.15, accuracy=0.747, val_loss=2.7, val_accuracy=0.393, lr=0.0316] 28%|██▊       | 26/93 [11:05<27:23, 24.53s/epoch, loss=1.14, accuracy=0.75, val_loss=2.08, val_accuracy=0.466, lr=0.1]    29%|██▉       | 27/93 [11:30<27:05, 24.63s/epoch, loss=1.14, accuracy=0.749, val_loss=2.17, val_accuracy=0.5, lr=0.1]  30%|███       | 28/93 [11:54<26:35, 24.54s/epoch, loss=1.14, accuracy=0.75, val_loss=2.07, val_accuracy=0.484, lr=0.1] 31%|███       | 29/93 [12:17<25:50, 24.23s/epoch, loss=1.14, accuracy=0.752, val_loss=1.68, val_accuracy=0.567, lr=0.1] 32%|███▏      | 30/93 [12:41<25:06, 23.92s/epoch, loss=1.14, accuracy=0.752, val_loss=2.31, val_accuracy=0.468, lr=0.0316] 33%|███▎      | 31/93 [13:05<25:01, 24.22s/epoch, loss=1.13, accuracy=0.754, val_loss=1.94, val_accuracy=0.553, lr=0.1]    34%|███▍      | 32/93 [13:30<24:39, 24.26s/epoch, loss=1.14, accuracy=0.751, val_loss=1.56, val_accuracy=0.634, lr=0.1] 35%|███▌      | 33/93 [13:54<24:22, 24.37s/epoch, loss=1.13, accuracy=0.755, val_loss=1.76, val_accuracy=0.538, lr=0.1] 37%|███▋      | 34/93 [14:18<23:41, 24.09s/epoch, loss=1.14, accuracy=0.753, val_loss=2.01, val_accuracy=0.533, lr=0.1] 38%|███▊      | 35/93 [14:42<23:19, 24.14s/epoch, loss=1.13, accuracy=0.753, val_loss=1.79, val_accuracy=0.58, lr=0.0316] 39%|███▊      | 36/93 [15:07<23:02, 24.25s/epoch, loss=1.14, accuracy=0.754, val_loss=3.2, val_accuracy=0.361, lr=0.1]    40%|███▉      | 37/93 [15:31<22:35, 24.21s/epoch, loss=1.13, accuracy=0.754, val_loss=1.56, val_accuracy=0.621, lr=0.1] 41%|████      | 38/93 [15:54<22:00, 24.00s/epoch, loss=1.13, accuracy=0.753, val_loss=2.38, val_accuracy=0.378, lr=0.1] 42%|████▏     | 39/93 [16:18<21:33, 23.96s/epoch, loss=1.12, accuracy=0.754, val_loss=1.62, val_accuracy=0.599, lr=0.1] 43%|████▎     | 40/93 [16:43<21:23, 24.22s/epoch, loss=1.13, accuracy=0.756, val_loss=2.24, val_accuracy=0.474, lr=0.0316] 44%|████▍     | 41/93 [17:07<20:53, 24.11s/epoch, loss=1.13, accuracy=0.754, val_loss=2.55, val_accuracy=0.395, lr=0.1]    45%|████▌     | 42/93 [17:31<20:36, 24.25s/epoch, loss=1.12, accuracy=0.757, val_loss=1.76, val_accuracy=0.54, lr=0.1]  46%|████▌     | 43/93 [17:56<20:16, 24.33s/epoch, loss=1.12, accuracy=0.756, val_loss=2.06, val_accuracy=0.474, lr=0.1] 47%|████▋     | 44/93 [18:20<19:43, 24.15s/epoch, loss=1.13, accuracy=0.754, val_loss=3.18, val_accuracy=0.296, lr=0.1] 48%|████▊     | 45/93 [18:44<19:17, 24.11s/epoch, loss=1.13, accuracy=0.754, val_loss=1.59, val_accuracy=0.629, lr=0.0316] 49%|████▉     | 46/93 [19:08<18:56, 24.18s/epoch, loss=1.12, accuracy=0.757, val_loss=2.6, val_accuracy=0.303, lr=0.1]     51%|█████     | 47/93 [19:32<18:27, 24.07s/epoch, loss=1.12, accuracy=0.756, val_loss=1.87, val_accuracy=0.524, lr=0.1] 52%|█████▏    | 48/93 [19:56<18:09, 24.22s/epoch, loss=1.13, accuracy=0.756, val_loss=2.31, val_accuracy=0.487, lr=0.1] 53%|█████▎    | 49/93 [20:20<17:38, 24.06s/epoch, loss=1.12, accuracy=0.754, val_loss=1.89, val_accuracy=0.534, lr=0.1] 54%|█████▍    | 50/93 [20:45<17:25, 24.32s/epoch, loss=1.12, accuracy=0.755, val_loss=2.27, val_accuracy=0.371, lr=0.0316] 55%|█████▍    | 51/93 [21:08<16:43, 23.89s/epoch, loss=1.11, accuracy=0.754, val_loss=1.63, val_accuracy=0.573, lr=0.1]    56%|█████▌    | 52/93 [21:31<16:09, 23.63s/epoch, loss=1.12, accuracy=0.758, val_loss=1.97, val_accuracy=0.459, lr=0.1] 57%|█████▋    | 53/93 [21:56<15:56, 23.92s/epoch, loss=1.11, accuracy=0.755, val_loss=1.63, val_accuracy=0.571, lr=0.1] 58%|█████▊    | 54/93 [22:20<15:42, 24.18s/epoch, loss=1.11, accuracy=0.756, val_loss=1.8, val_accuracy=0.564, lr=0.1]  59%|█████▉    | 55/93 [22:44<15:17, 24.14s/epoch, loss=1.12, accuracy=0.756, val_loss=2.52, val_accuracy=0.464, lr=0.0316] 60%|██████    | 56/93 [23:08<14:50, 24.06s/epoch, loss=1.12, accuracy=0.756, val_loss=1.5, val_accuracy=0.628, lr=0.1]     61%|██████▏   | 57/93 [23:33<14:32, 24.24s/epoch, loss=1.12, accuracy=0.755, val_loss=1.94, val_accuracy=0.51, lr=0.1] 62%|██████▏   | 58/93 [23:58<14:15, 24.44s/epoch, loss=1.11, accuracy=0.756, val_loss=2.2, val_accuracy=0.436, lr=0.1] 63%|██████▎   | 59/93 [24:22<13:49, 24.40s/epoch, loss=1.12, accuracy=0.755, val_loss=2.21, val_accuracy=0.421, lr=0.1] 65%|██████▍   | 60/93 [24:47<13:27, 24.48s/epoch, loss=1.11, accuracy=0.76, val_loss=2.09, val_accuracy=0.498, lr=0.0316] 66%|██████▌   | 61/93 [25:10<12:51, 24.11s/epoch, loss=1.12, accuracy=0.755, val_loss=2.13, val_accuracy=0.435, lr=0.1]   67%|██████▋   | 62/93 [25:34<12:23, 23.97s/epoch, loss=1.12, accuracy=0.757, val_loss=1.41, val_accuracy=0.661, lr=0.1] 68%|██████▊   | 63/93 [25:57<11:53, 23.79s/epoch, loss=1.1, accuracy=0.758, val_loss=2.91, val_accuracy=0.366, lr=0.1]  69%|██████▉   | 64/93 [26:20<11:22, 23.53s/epoch, loss=1.11, accuracy=0.758, val_loss=1.52, val_accuracy=0.616, lr=0.1] 70%|██████▉   | 65/93 [26:44<11:02, 23.66s/epoch, loss=1.12, accuracy=0.757, val_loss=1.58, val_accuracy=0.59, lr=0.0316] 71%|███████   | 66/93 [27:09<10:50, 24.09s/epoch, loss=1.11, accuracy=0.758, val_loss=2.08, val_accuracy=0.434, lr=0.1]   72%|███████▏  | 67/93 [27:33<10:29, 24.20s/epoch, loss=1.11, accuracy=0.757, val_loss=2.54, val_accuracy=0.323, lr=0.1] 73%|███████▎  | 68/93 [27:56<09:55, 23.81s/epoch, loss=1.11, accuracy=0.757, val_loss=1.98, val_accuracy=0.524, lr=0.1] 74%|███████▍  | 69/93 [28:20<09:32, 23.86s/epoch, loss=1.11, accuracy=0.757, val_loss=2.19, val_accuracy=0.404, lr=0.1] 75%|███████▌  | 70/93 [28:44<09:04, 23.67s/epoch, loss=1.11, accuracy=0.758, val_loss=2.44, val_accuracy=0.473, lr=0.0316] 76%|███████▋  | 71/93 [29:07<08:39, 23.62s/epoch, loss=1.11, accuracy=0.758, val_loss=2.83, val_accuracy=0.372, lr=0.1]    77%|███████▋  | 72/93 [29:30<08:10, 23.37s/epoch, loss=1.12, accuracy=0.756, val_loss=2.06, val_accuracy=0.497, lr=0.1] 78%|███████▊  | 73/93 [29:54<07:54, 23.74s/epoch, loss=1.11, accuracy=0.756, val_loss=2.15, val_accuracy=0.488, lr=0.1] 80%|███████▉  | 74/93 [30:19<07:37, 24.08s/epoch, loss=1.11, accuracy=0.758, val_loss=1.74, val_accuracy=0.58, lr=0.1]  81%|████████  | 75/93 [30:44<07:15, 24.21s/epoch, loss=1.1, accuracy=0.759, val_loss=3.26, val_accuracy=0.372, lr=0.0316] 82%|████████▏ | 76/93 [31:09<06:55, 24.45s/epoch, loss=1.1, accuracy=0.759, val_loss=2.37, val_accuracy=0.414, lr=0.1]    83%|████████▎ | 77/93 [31:34<06:32, 24.50s/epoch, loss=1.11, accuracy=0.758, val_loss=2.36, val_accuracy=0.436, lr=0.1] 84%|████████▍ | 78/93 [31:58<06:05, 24.39s/epoch, loss=1.11, accuracy=0.758, val_loss=1.34, val_accuracy=0.683, lr=0.1] 85%|████████▍ | 79/93 [32:21<05:38, 24.21s/epoch, loss=1.11, accuracy=0.759, val_loss=2.26, val_accuracy=0.487, lr=0.1] 86%|████████▌ | 80/93 [32:45<05:10, 23.91s/epoch, loss=1.11, accuracy=0.759, val_loss=4.56, val_accuracy=0.287, lr=0.1] 87%|████████▋ | 81/93 [33:08<04:45, 23.76s/epoch, loss=1.11, accuracy=0.757, val_loss=3.06, val_accuracy=0.311, lr=0.1] 88%|████████▊ | 82/93 [33:32<04:20, 23.69s/epoch, loss=0.901, accuracy=0.818, val_loss=0.92, val_accuracy=0.793, lr=0.01] 89%|████████▉ | 83/93 [33:56<03:59, 23.93s/epoch, loss=0.727, accuracy=0.847, val_loss=0.785, val_accuracy=0.811, lr=0.01] 90%|█████████ | 84/93 [34:19<03:32, 23.57s/epoch, loss=0.65, accuracy=0.854, val_loss=0.779, val_accuracy=0.803, lr=0.01]  91%|█████████▏| 85/93 [34:44<03:11, 23.92s/epoch, loss=0.603, accuracy=0.862, val_loss=0.766, val_accuracy=0.81, lr=0.01] 92%|█████████▏| 86/93 [35:08<02:48, 24.10s/epoch, loss=0.585, accuracy=0.861, val_loss=0.706, val_accuracy=0.821, lr=0.01] 94%|█████████▎| 87/93 [35:32<02:24, 24.02s/epoch, loss=0.571, accuracy=0.863, val_loss=0.805, val_accuracy=0.786, lr=0.01] 95%|█████████▍| 88/93 [35:56<02:00, 24.03s/epoch, loss=0.566, accuracy=0.863, val_loss=0.983, val_accuracy=0.734, lr=0.01] 96%|█████████▌| 89/93 [36:21<01:37, 24.26s/epoch, loss=0.564, accuracy=0.864, val_loss=0.882, val_accuracy=0.764, lr=0.01] 97%|█████████▋| 90/93 [36:45<01:13, 24.34s/epoch, loss=0.558, accuracy=0.867, val_loss=0.974, val_accuracy=0.742, lr=0.01] 98%|█████████▊| 91/93 [37:09<00:48, 24.30s/epoch, loss=0.554, accuracy=0.869, val_loss=0.747, val_accuracy=0.804, lr=0.00316] 99%|█████████▉| 92/93 [37:34<00:24, 24.24s/epoch, loss=0.558, accuracy=0.868, val_loss=1.26, val_accuracy=0.691, lr=0.01]    100%|██████████| 93/93 [37:58<00:00, 24.29s/epoch, loss=0.561, accuracy=0.868, val_loss=0.848, val_accuracy=0.779, lr=0.01]100%|██████████| 93/93 [37:58<00:00, 24.50s/epoch, loss=0.561, accuracy=0.868, val_loss=0.848, val_accuracy=0.779, lr=0.01]
Using real-time data augmentation.
Test loss: 0.8484657406806946
Test accuracy: 0.7785000205039978


* * * Run SGD for ID = 16_6. * * *


2024-02-15 16:48:23.497105: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 16:48:26.438987: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 16:48:26.440218: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-15 16:48:26.477906: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 16:48:26.477938: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 16:48:26.480816: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 16:48:26.480859: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 16:48:26.483087: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 16:48:26.483846: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 16:48:26.486321: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 16:48:26.487859: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 16:48:26.492646: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 16:48:26.493143: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 16:48:26.493224: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 16:48:27.829632: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-15 16:48:27.830828: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 16:48:27.831831: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 16:48:27.831865: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 16:48:27.831901: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 16:48:27.831920: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 16:48:27.831938: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 16:48:27.831955: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 16:48:27.831973: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 16:48:27.831990: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 16:48:27.832008: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 16:48:27.832445: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 16:48:27.832482: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 16:48:28.526490: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-15 16:48:28.526548: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-15 16:48:28.526558: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-15 16:48:28.527872: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': 166, 'batch_size': 128, 'epochs': 93, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/93 [00:00<?, ?epoch/s]2024-02-15 16:48:29.349016: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-15 16:48:29.349568: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2200060000 Hz
2024-02-15 16:48:31.453030: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 16:48:31.729382: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 16:48:32.450946: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-15 16:48:32.502447: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/93 [00:58<1:29:16, 58.23s/epoch, loss=3.29, accuracy=0.271, val_loss=2.29, val_accuracy=0.289, lr=0.1]  2%|▏         | 2/93 [01:23<58:30, 38.58s/epoch, loss=1.69, accuracy=0.464, val_loss=2.27, val_accuracy=0.276, lr=0.1]    3%|▎         | 3/93 [01:46<47:41, 31.80s/epoch, loss=1.53, accuracy=0.544, val_loss=1.68, val_accuracy=0.513, lr=0.1]  4%|▍         | 4/93 [02:10<42:35, 28.72s/epoch, loss=1.45, accuracy=0.6, val_loss=2.52, val_accuracy=0.366, lr=0.1]    5%|▌         | 5/93 [02:35<40:01, 27.29s/epoch, loss=1.39, accuracy=0.637, val_loss=1.72, val_accuracy=0.537, lr=0.1]  6%|▋         | 6/93 [02:58<37:26, 25.82s/epoch, loss=1.34, accuracy=0.67, val_loss=2.54, val_accuracy=0.39, lr=0.1]    8%|▊         | 7/93 [03:21<35:43, 24.92s/epoch, loss=1.3, accuracy=0.689, val_loss=1.81, val_accuracy=0.547, lr=0.1]  9%|▊         | 8/93 [03:45<34:56, 24.67s/epoch, loss=1.28, accuracy=0.703, val_loss=1.41, val_accuracy=0.652, lr=0.1] 10%|▉         | 9/93 [04:10<34:23, 24.56s/epoch, loss=1.27, accuracy=0.711, val_loss=2.07, val_accuracy=0.466, lr=0.1] 11%|█         | 10/93 [04:34<33:44, 24.40s/epoch, loss=1.25, accuracy=0.714, val_loss=2.74, val_accuracy=0.431, lr=0.1] 12%|█▏        | 11/93 [04:56<32:43, 23.94s/epoch, loss=1.24, accuracy=0.72, val_loss=1.68, val_accuracy=0.573, lr=0.1]  13%|█▎        | 12/93 [05:21<32:28, 24.06s/epoch, loss=1.24, accuracy=0.724, val_loss=1.8, val_accuracy=0.579, lr=0.1] 14%|█▍        | 13/93 [05:44<31:49, 23.87s/epoch, loss=1.23, accuracy=0.728, val_loss=2.12, val_accuracy=0.444, lr=0.0316] 15%|█▌        | 14/93 [06:08<31:26, 23.88s/epoch, loss=1.23, accuracy=0.727, val_loss=1.98, val_accuracy=0.527, lr=0.1]    16%|█▌        | 15/93 [06:33<31:33, 24.28s/epoch, loss=1.23, accuracy=0.726, val_loss=1.99, val_accuracy=0.509, lr=0.1] 17%|█▋        | 16/93 [06:56<30:42, 23.93s/epoch, loss=1.21, accuracy=0.731, val_loss=2.66, val_accuracy=0.292, lr=0.1] 18%|█▊        | 17/93 [07:21<30:36, 24.17s/epoch, loss=1.2, accuracy=0.735, val_loss=1.77, val_accuracy=0.557, lr=0.1]  19%|█▉        | 18/93 [07:44<29:40, 23.74s/epoch, loss=1.21, accuracy=0.735, val_loss=1.79, val_accuracy=0.534, lr=0.0316] 20%|██        | 19/93 [08:09<29:38, 24.04s/epoch, loss=1.2, accuracy=0.736, val_loss=3.91, val_accuracy=0.309, lr=0.1]     22%|██▏       | 20/93 [08:33<29:29, 24.23s/epoch, loss=1.2, accuracy=0.732, val_loss=1.53, val_accuracy=0.628, lr=0.1] 23%|██▎       | 21/93 [08:56<28:39, 23.88s/epoch, loss=1.2, accuracy=0.739, val_loss=1.81, val_accuracy=0.539, lr=0.1] 24%|██▎       | 22/93 [09:21<28:33, 24.14s/epoch, loss=1.2, accuracy=0.736, val_loss=2.43, val_accuracy=0.502, lr=0.1] 25%|██▍       | 23/93 [09:45<28:10, 24.15s/epoch, loss=1.19, accuracy=0.739, val_loss=1.91, val_accuracy=0.535, lr=0.0316] 26%|██▌       | 24/93 [10:08<27:14, 23.69s/epoch, loss=1.19, accuracy=0.738, val_loss=1.7, val_accuracy=0.552, lr=0.1]     27%|██▋       | 25/93 [10:33<27:10, 23.97s/epoch, loss=1.19, accuracy=0.741, val_loss=3.22, val_accuracy=0.351, lr=0.1] 28%|██▊       | 26/93 [10:56<26:29, 23.73s/epoch, loss=1.18, accuracy=0.744, val_loss=7.12, val_accuracy=0.223, lr=0.1] 29%|██▉       | 27/93 [11:18<25:43, 23.38s/epoch, loss=1.19, accuracy=0.742, val_loss=2.51, val_accuracy=0.363, lr=0.1] 30%|███       | 28/93 [11:42<25:34, 23.61s/epoch, loss=1.18, accuracy=0.744, val_loss=2.32, val_accuracy=0.45, lr=0.0316] 31%|███       | 29/93 [12:07<25:29, 23.90s/epoch, loss=1.18, accuracy=0.744, val_loss=1.42, val_accuracy=0.661, lr=0.1]   32%|███▏      | 30/93 [12:32<25:20, 24.14s/epoch, loss=1.18, accuracy=0.746, val_loss=1.88, val_accuracy=0.534, lr=0.1] 33%|███▎      | 31/93 [12:56<25:07, 24.32s/epoch, loss=1.18, accuracy=0.743, val_loss=1.83, val_accuracy=0.531, lr=0.1] 34%|███▍      | 32/93 [13:21<24:50, 24.44s/epoch, loss=1.18, accuracy=0.743, val_loss=2.57, val_accuracy=0.408, lr=0.1] 35%|███▌      | 33/93 [13:45<24:06, 24.11s/epoch, loss=1.17, accuracy=0.748, val_loss=1.58, val_accuracy=0.608, lr=0.0316] 37%|███▋      | 34/93 [14:08<23:22, 23.78s/epoch, loss=1.18, accuracy=0.742, val_loss=2.43, val_accuracy=0.477, lr=0.1]    38%|███▊      | 35/93 [14:30<22:41, 23.47s/epoch, loss=1.17, accuracy=0.746, val_loss=3.23, val_accuracy=0.426, lr=0.1] 39%|███▊      | 36/93 [14:55<22:36, 23.80s/epoch, loss=1.17, accuracy=0.745, val_loss=1.86, val_accuracy=0.516, lr=0.1] 40%|███▉      | 37/93 [15:20<22:30, 24.12s/epoch, loss=1.17, accuracy=0.744, val_loss=1.77, val_accuracy=0.582, lr=0.1] 41%|████      | 38/93 [15:44<22:09, 24.17s/epoch, loss=1.17, accuracy=0.745, val_loss=1.97, val_accuracy=0.493, lr=0.0316] 42%|████▏     | 39/93 [16:08<21:50, 24.27s/epoch, loss=1.17, accuracy=0.745, val_loss=1.75, val_accuracy=0.566, lr=0.1]    43%|████▎     | 40/93 [16:33<21:29, 24.32s/epoch, loss=1.17, accuracy=0.748, val_loss=2.09, val_accuracy=0.483, lr=0.1] 44%|████▍     | 41/93 [16:55<20:36, 23.77s/epoch, loss=1.16, accuracy=0.75, val_loss=1.87, val_accuracy=0.518, lr=0.1]  45%|████▌     | 42/93 [17:18<19:53, 23.41s/epoch, loss=1.16, accuracy=0.748, val_loss=1.83, val_accuracy=0.529, lr=0.1] 46%|████▌     | 43/93 [17:42<19:36, 23.53s/epoch, loss=1.16, accuracy=0.75, val_loss=3.03, val_accuracy=0.429, lr=0.0316] 47%|████▋     | 44/93 [18:05<19:09, 23.46s/epoch, loss=1.16, accuracy=0.751, val_loss=3.49, val_accuracy=0.331, lr=0.1]   48%|████▊     | 45/93 [18:28<18:34, 23.21s/epoch, loss=1.16, accuracy=0.749, val_loss=1.78, val_accuracy=0.56, lr=0.1]  49%|████▉     | 46/93 [18:52<18:27, 23.56s/epoch, loss=1.16, accuracy=0.749, val_loss=1.67, val_accuracy=0.573, lr=0.1] 51%|█████     | 47/93 [19:17<18:16, 23.84s/epoch, loss=1.16, accuracy=0.746, val_loss=1.57, val_accuracy=0.593, lr=0.1] 52%|█████▏    | 48/93 [19:41<18:00, 24.02s/epoch, loss=1.16, accuracy=0.747, val_loss=5.18, val_accuracy=0.242, lr=0.0316] 53%|█████▎    | 49/93 [20:05<17:35, 24.00s/epoch, loss=1.16, accuracy=0.749, val_loss=1.82, val_accuracy=0.542, lr=0.1]    54%|█████▍    | 50/93 [20:29<17:10, 23.97s/epoch, loss=1.15, accuracy=0.75, val_loss=1.38, val_accuracy=0.674, lr=0.1]  55%|█████▍    | 51/93 [20:52<16:41, 23.86s/epoch, loss=1.16, accuracy=0.748, val_loss=1.47, val_accuracy=0.62, lr=0.1] 56%|█████▌    | 52/93 [21:17<16:26, 24.06s/epoch, loss=1.15, accuracy=0.751, val_loss=2.61, val_accuracy=0.385, lr=0.1] 57%|█████▋    | 53/93 [21:40<15:54, 23.87s/epoch, loss=1.15, accuracy=0.753, val_loss=2.57, val_accuracy=0.477, lr=0.1] 58%|█████▊    | 54/93 [22:05<15:36, 24.01s/epoch, loss=1.15, accuracy=0.752, val_loss=1.57, val_accuracy=0.596, lr=0.1] 59%|█████▉    | 55/93 [22:29<15:15, 24.10s/epoch, loss=1.15, accuracy=0.753, val_loss=1.77, val_accuracy=0.531, lr=0.0316] 60%|██████    | 56/93 [22:53<14:47, 23.98s/epoch, loss=1.15, accuracy=0.751, val_loss=1.94, val_accuracy=0.501, lr=0.1]    61%|██████▏   | 57/93 [23:16<14:16, 23.79s/epoch, loss=1.15, accuracy=0.751, val_loss=2, val_accuracy=0.495, lr=0.1]    62%|██████▏   | 58/93 [23:40<13:53, 23.82s/epoch, loss=1.15, accuracy=0.752, val_loss=2.11, val_accuracy=0.423, lr=0.1] 63%|██████▎   | 59/93 [24:05<13:37, 24.04s/epoch, loss=1.15, accuracy=0.751, val_loss=1.98, val_accuracy=0.47, lr=0.1]  65%|██████▍   | 60/93 [24:29<13:18, 24.18s/epoch, loss=1.15, accuracy=0.751, val_loss=2.02, val_accuracy=0.483, lr=0.0316] 66%|██████▌   | 61/93 [24:54<12:56, 24.26s/epoch, loss=1.15, accuracy=0.753, val_loss=1.75, val_accuracy=0.587, lr=0.1]    67%|██████▋   | 62/93 [25:16<12:19, 23.86s/epoch, loss=1.15, accuracy=0.75, val_loss=3.59, val_accuracy=0.386, lr=0.1]  68%|██████▊   | 63/93 [25:40<11:49, 23.66s/epoch, loss=1.15, accuracy=0.752, val_loss=1.49, val_accuracy=0.64, lr=0.1] 69%|██████▉   | 64/93 [26:03<11:23, 23.56s/epoch, loss=1.16, accuracy=0.751, val_loss=1.67, val_accuracy=0.555, lr=0.1] 70%|██████▉   | 65/93 [26:26<10:55, 23.41s/epoch, loss=1.15, accuracy=0.75, val_loss=2.47, val_accuracy=0.363, lr=0.0316] 71%|███████   | 66/93 [26:49<10:25, 23.18s/epoch, loss=1.15, accuracy=0.751, val_loss=2.07, val_accuracy=0.418, lr=0.1]   72%|███████▏  | 67/93 [27:13<10:13, 23.59s/epoch, loss=1.15, accuracy=0.751, val_loss=1.59, val_accuracy=0.591, lr=0.1] 73%|███████▎  | 68/93 [27:38<09:55, 23.81s/epoch, loss=1.15, accuracy=0.751, val_loss=2.08, val_accuracy=0.445, lr=0.1] 74%|███████▍  | 69/93 [28:02<09:33, 23.90s/epoch, loss=1.15, accuracy=0.754, val_loss=1.68, val_accuracy=0.601, lr=0.1] 75%|███████▌  | 70/93 [28:26<09:11, 23.96s/epoch, loss=1.15, accuracy=0.75, val_loss=2.4, val_accuracy=0.46, lr=0.0316] 76%|███████▋  | 71/93 [28:50<08:45, 23.90s/epoch, loss=1.15, accuracy=0.751, val_loss=1.53, val_accuracy=0.615, lr=0.1] 77%|███████▋  | 72/93 [29:13<08:21, 23.90s/epoch, loss=1.15, accuracy=0.752, val_loss=1.98, val_accuracy=0.539, lr=0.1] 78%|███████▊  | 73/93 [29:38<08:00, 24.01s/epoch, loss=1.14, accuracy=0.755, val_loss=3.13, val_accuracy=0.458, lr=0.1] 80%|███████▉  | 74/93 [30:02<07:35, 23.97s/epoch, loss=1.16, accuracy=0.749, val_loss=2.95, val_accuracy=0.271, lr=0.1] 81%|████████  | 75/93 [30:25<07:08, 23.79s/epoch, loss=1.15, accuracy=0.751, val_loss=1.59, val_accuracy=0.6, lr=0.0316] 82%|████████▏ | 76/93 [30:49<06:47, 23.97s/epoch, loss=1.15, accuracy=0.754, val_loss=1.51, val_accuracy=0.632, lr=0.1]  83%|████████▎ | 77/93 [31:13<06:24, 24.01s/epoch, loss=1.15, accuracy=0.753, val_loss=1.55, val_accuracy=0.618, lr=0.1] 84%|████████▍ | 78/93 [31:37<05:57, 23.85s/epoch, loss=1.14, accuracy=0.752, val_loss=2.01, val_accuracy=0.505, lr=0.1] 85%|████████▍ | 79/93 [32:01<05:34, 23.87s/epoch, loss=1.14, accuracy=0.755, val_loss=2.27, val_accuracy=0.476, lr=0.1] 86%|████████▌ | 80/93 [32:25<05:13, 24.08s/epoch, loss=1.15, accuracy=0.753, val_loss=2.45, val_accuracy=0.409, lr=0.0316] 87%|████████▋ | 81/93 [32:49<04:47, 23.99s/epoch, loss=1.15, accuracy=0.752, val_loss=2.42, val_accuracy=0.37, lr=0.1]     88%|████████▊ | 82/93 [33:12<04:20, 23.67s/epoch, loss=0.936, accuracy=0.812, val_loss=0.878, val_accuracy=0.819, lr=0.01] 89%|████████▉ | 83/93 [33:36<03:56, 23.70s/epoch, loss=0.746, accuracy=0.847, val_loss=0.779, val_accuracy=0.823, lr=0.01] 90%|█████████ | 84/93 [33:58<03:30, 23.36s/epoch, loss=0.665, accuracy=0.854, val_loss=0.784, val_accuracy=0.818, lr=0.01] 91%|█████████▏| 85/93 [34:22<03:08, 23.51s/epoch, loss=0.617, accuracy=0.858, val_loss=0.803, val_accuracy=0.795, lr=0.01] 92%|█████████▏| 86/93 [34:45<02:43, 23.33s/epoch, loss=0.594, accuracy=0.859, val_loss=0.988, val_accuracy=0.722, lr=0.01] 94%|█████████▎| 87/93 [35:09<02:21, 23.58s/epoch, loss=0.587, accuracy=0.859, val_loss=0.753, val_accuracy=0.803, lr=0.01] 95%|█████████▍| 88/93 [35:33<01:58, 23.73s/epoch, loss=0.575, accuracy=0.862, val_loss=0.904, val_accuracy=0.754, lr=0.01] 96%|█████████▌| 89/93 [35:58<01:35, 23.96s/epoch, loss=0.573, accuracy=0.863, val_loss=0.709, val_accuracy=0.817, lr=0.01] 97%|█████████▋| 90/93 [36:22<01:12, 24.04s/epoch, loss=0.573, accuracy=0.866, val_loss=0.8, val_accuracy=0.783, lr=0.01]   98%|█████████▊| 91/93 [36:47<00:48, 24.20s/epoch, loss=0.576, accuracy=0.866, val_loss=0.823, val_accuracy=0.786, lr=0.01] 99%|█████████▉| 92/93 [37:10<00:23, 23.81s/epoch, loss=0.569, accuracy=0.868, val_loss=0.758, val_accuracy=0.803, lr=0.01]100%|██████████| 93/93 [37:33<00:00, 23.74s/epoch, loss=0.565, accuracy=0.871, val_loss=0.757, val_accuracy=0.809, lr=0.01]100%|██████████| 93/93 [37:33<00:00, 24.23s/epoch, loss=0.565, accuracy=0.871, val_loss=0.757, val_accuracy=0.809, lr=0.01]
Using real-time data augmentation.
Test loss: 0.7567836046218872
Test accuracy: 0.8094000220298767


* * * Run SGD for ID = 16_7. * * *


2024-02-15 17:26:07.785048: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 17:26:11.304937: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 17:26:11.306109: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-15 17:26:11.344349: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 17:26:11.344382: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 17:26:11.347356: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 17:26:11.347399: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 17:26:11.349667: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 17:26:11.350410: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 17:26:11.352867: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 17:26:11.354357: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 17:26:11.359237: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 17:26:11.359755: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 17:26:11.359836: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 17:26:12.658569: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-15 17:26:12.659709: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 17:26:12.660187: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 17:26:12.660218: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 17:26:12.660251: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 17:26:12.660269: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 17:26:12.660287: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 17:26:12.660304: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 17:26:12.660322: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 17:26:12.660339: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 17:26:12.660357: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 17:26:12.660856: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 17:26:12.660916: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 17:26:13.354768: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-15 17:26:13.354846: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-15 17:26:13.354857: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-15 17:26:13.356158: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': 167, 'batch_size': 128, 'epochs': 93, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/93 [00:00<?, ?epoch/s]2024-02-15 17:26:14.178937: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-15 17:26:14.190711: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2200060000 Hz
2024-02-15 17:26:16.250497: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 17:26:16.529377: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 17:26:17.350810: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-15 17:26:17.400832: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/93 [01:03<1:37:39, 63.69s/epoch, loss=3.45, accuracy=0.283, val_loss=2.73, val_accuracy=0.229, lr=0.1]  2%|▏         | 2/93 [01:28<1:01:40, 40.67s/epoch, loss=1.62, accuracy=0.508, val_loss=2.25, val_accuracy=0.431, lr=0.1]  3%|▎         | 3/93 [01:52<49:41, 33.12s/epoch, loss=1.36, accuracy=0.63, val_loss=1.98, val_accuracy=0.469, lr=0.1]     4%|▍         | 4/93 [02:15<43:17, 29.18s/epoch, loss=1.28, accuracy=0.68, val_loss=2.18, val_accuracy=0.382, lr=0.1]  5%|▌         | 5/93 [02:40<40:23, 27.54s/epoch, loss=1.25, accuracy=0.697, val_loss=2.38, val_accuracy=0.412, lr=0.1]  6%|▋         | 6/93 [03:03<38:01, 26.23s/epoch, loss=1.24, accuracy=0.709, val_loss=1.76, val_accuracy=0.54, lr=0.1]   8%|▊         | 7/93 [03:27<36:27, 25.44s/epoch, loss=1.23, accuracy=0.717, val_loss=1.56, val_accuracy=0.605, lr=0.1]  9%|▊         | 8/93 [03:51<35:15, 24.89s/epoch, loss=1.23, accuracy=0.723, val_loss=2.67, val_accuracy=0.386, lr=0.1] 10%|▉         | 9/93 [04:15<34:32, 24.67s/epoch, loss=1.21, accuracy=0.728, val_loss=2.74, val_accuracy=0.4, lr=0.1]   11%|█         | 10/93 [04:40<34:11, 24.72s/epoch, loss=1.21, accuracy=0.733, val_loss=2.97, val_accuracy=0.373, lr=0.1] 12%|█▏        | 11/93 [05:05<33:56, 24.84s/epoch, loss=1.2, accuracy=0.736, val_loss=1.88, val_accuracy=0.532, lr=0.1]  13%|█▎        | 12/93 [05:30<33:29, 24.80s/epoch, loss=1.2, accuracy=0.737, val_loss=1.62, val_accuracy=0.566, lr=0.0316] 14%|█▍        | 13/93 [05:53<32:30, 24.38s/epoch, loss=1.19, accuracy=0.74, val_loss=2.05, val_accuracy=0.462, lr=0.1]    15%|█▌        | 14/93 [06:18<32:13, 24.48s/epoch, loss=1.19, accuracy=0.739, val_loss=1.69, val_accuracy=0.593, lr=0.1] 16%|█▌        | 15/93 [06:43<31:55, 24.56s/epoch, loss=1.18, accuracy=0.745, val_loss=1.82, val_accuracy=0.547, lr=0.1] 17%|█▋        | 16/93 [07:07<31:36, 24.63s/epoch, loss=1.18, accuracy=0.744, val_loss=2.39, val_accuracy=0.46, lr=0.1]  18%|█▊        | 17/93 [07:32<31:03, 24.53s/epoch, loss=1.18, accuracy=0.744, val_loss=2.06, val_accuracy=0.477, lr=0.0316] 19%|█▉        | 18/93 [07:56<30:31, 24.42s/epoch, loss=1.18, accuracy=0.746, val_loss=1.66, val_accuracy=0.581, lr=0.1]    20%|██        | 19/93 [08:19<29:34, 23.98s/epoch, loss=1.17, accuracy=0.749, val_loss=1.48, val_accuracy=0.654, lr=0.1] 22%|██▏       | 20/93 [08:43<29:26, 24.20s/epoch, loss=1.18, accuracy=0.746, val_loss=1.39, val_accuracy=0.67, lr=0.1]  23%|██▎       | 21/93 [09:07<28:57, 24.13s/epoch, loss=1.18, accuracy=0.747, val_loss=1.61, val_accuracy=0.605, lr=0.1] 24%|██▎       | 22/93 [09:32<28:44, 24.28s/epoch, loss=1.17, accuracy=0.749, val_loss=1.86, val_accuracy=0.552, lr=0.1] 25%|██▍       | 23/93 [09:57<28:28, 24.40s/epoch, loss=1.18, accuracy=0.744, val_loss=1.71, val_accuracy=0.562, lr=0.1] 26%|██▌       | 24/93 [10:21<28:07, 24.46s/epoch, loss=1.17, accuracy=0.748, val_loss=1.69, val_accuracy=0.596, lr=0.1] 27%|██▋       | 25/93 [10:46<27:54, 24.63s/epoch, loss=1.17, accuracy=0.748, val_loss=2.02, val_accuracy=0.522, lr=0.0316] 28%|██▊       | 26/93 [11:11<27:28, 24.61s/epoch, loss=1.17, accuracy=0.75, val_loss=1.74, val_accuracy=0.54, lr=0.1]      29%|██▉       | 27/93 [11:34<26:31, 24.12s/epoch, loss=1.17, accuracy=0.75, val_loss=2.37, val_accuracy=0.412, lr=0.1] 30%|███       | 28/93 [11:59<26:17, 24.28s/epoch, loss=1.16, accuracy=0.753, val_loss=4.1, val_accuracy=0.296, lr=0.1] 31%|███       | 29/93 [12:22<25:33, 23.97s/epoch, loss=1.17, accuracy=0.752, val_loss=1.51, val_accuracy=0.66, lr=0.1] 32%|███▏      | 30/93 [12:47<25:33, 24.34s/epoch, loss=1.16, accuracy=0.752, val_loss=1.4, val_accuracy=0.661, lr=0.0316] 33%|███▎      | 31/93 [13:11<24:57, 24.15s/epoch, loss=1.16, accuracy=0.75, val_loss=1.88, val_accuracy=0.493, lr=0.1]    34%|███▍      | 32/93 [13:36<24:46, 24.38s/epoch, loss=1.16, accuracy=0.749, val_loss=2.52, val_accuracy=0.407, lr=0.1] 35%|███▌      | 33/93 [13:59<24:08, 24.14s/epoch, loss=1.16, accuracy=0.751, val_loss=1.96, val_accuracy=0.512, lr=0.1] 37%|███▋      | 34/93 [14:24<23:48, 24.21s/epoch, loss=1.16, accuracy=0.75, val_loss=1.48, val_accuracy=0.638, lr=0.1]  38%|███▊      | 35/93 [14:47<23:13, 24.02s/epoch, loss=1.15, accuracy=0.755, val_loss=1.46, val_accuracy=0.64, lr=0.0316] 39%|███▊      | 36/93 [15:12<23:05, 24.31s/epoch, loss=1.15, accuracy=0.752, val_loss=1.91, val_accuracy=0.479, lr=0.1]   40%|███▉      | 37/93 [15:36<22:26, 24.04s/epoch, loss=1.15, accuracy=0.752, val_loss=2.27, val_accuracy=0.494, lr=0.1] 41%|████      | 38/93 [16:00<22:03, 24.07s/epoch, loss=1.16, accuracy=0.752, val_loss=1.68, val_accuracy=0.625, lr=0.1] 42%|████▏     | 39/93 [16:24<21:47, 24.20s/epoch, loss=1.15, accuracy=0.75, val_loss=2.54, val_accuracy=0.48, lr=0.1]   43%|████▎     | 40/93 [16:49<21:27, 24.30s/epoch, loss=1.16, accuracy=0.752, val_loss=2.1, val_accuracy=0.448, lr=0.0316] 44%|████▍     | 41/93 [17:13<20:57, 24.18s/epoch, loss=1.15, accuracy=0.754, val_loss=2.2, val_accuracy=0.463, lr=0.1]    45%|████▌     | 42/93 [17:36<20:16, 23.86s/epoch, loss=1.15, accuracy=0.753, val_loss=1.48, val_accuracy=0.65, lr=0.1] 46%|████▌     | 43/93 [18:01<20:08, 24.18s/epoch, loss=1.15, accuracy=0.753, val_loss=1.84, val_accuracy=0.551, lr=0.1] 47%|████▋     | 44/93 [18:24<19:34, 23.96s/epoch, loss=1.15, accuracy=0.753, val_loss=2.66, val_accuracy=0.467, lr=0.1] 48%|████▊     | 45/93 [18:47<18:56, 23.67s/epoch, loss=1.15, accuracy=0.756, val_loss=1.86, val_accuracy=0.537, lr=0.0316] 49%|████▉     | 46/93 [19:11<18:36, 23.75s/epoch, loss=1.15, accuracy=0.752, val_loss=1.46, val_accuracy=0.648, lr=0.1]    51%|█████     | 47/93 [19:36<18:22, 23.96s/epoch, loss=1.14, accuracy=0.755, val_loss=2.21, val_accuracy=0.491, lr=0.1] 52%|█████▏    | 48/93 [20:00<18:00, 24.02s/epoch, loss=1.14, accuracy=0.755, val_loss=1.64, val_accuracy=0.596, lr=0.1] 53%|█████▎    | 49/93 [20:24<17:41, 24.12s/epoch, loss=1.15, accuracy=0.755, val_loss=2.99, val_accuracy=0.397, lr=0.1] 54%|█████▍    | 50/93 [20:47<17:04, 23.83s/epoch, loss=1.15, accuracy=0.754, val_loss=1.69, val_accuracy=0.561, lr=0.0316] 55%|█████▍    | 51/93 [21:12<16:48, 24.02s/epoch, loss=1.14, accuracy=0.757, val_loss=2.01, val_accuracy=0.523, lr=0.1]    56%|█████▌    | 52/93 [21:35<16:12, 23.72s/epoch, loss=1.15, accuracy=0.754, val_loss=1.87, val_accuracy=0.555, lr=0.1] 57%|█████▋    | 53/93 [21:59<16:01, 24.04s/epoch, loss=1.14, accuracy=0.756, val_loss=2.61, val_accuracy=0.294, lr=0.1] 58%|█████▊    | 54/93 [22:23<15:35, 23.98s/epoch, loss=1.14, accuracy=0.753, val_loss=1.75, val_accuracy=0.578, lr=0.1] 59%|█████▉    | 55/93 [22:48<15:16, 24.12s/epoch, loss=1.14, accuracy=0.756, val_loss=1.87, val_accuracy=0.529, lr=0.0316] 60%|██████    | 56/93 [23:13<14:59, 24.32s/epoch, loss=1.14, accuracy=0.757, val_loss=1.42, val_accuracy=0.65, lr=0.1]     61%|██████▏   | 57/93 [23:37<14:35, 24.31s/epoch, loss=1.14, accuracy=0.755, val_loss=2.71, val_accuracy=0.472, lr=0.1] 62%|██████▏   | 58/93 [24:01<14:06, 24.20s/epoch, loss=1.15, accuracy=0.756, val_loss=1.69, val_accuracy=0.58, lr=0.1]  63%|██████▎   | 59/93 [24:25<13:47, 24.34s/epoch, loss=1.14, accuracy=0.756, val_loss=2.41, val_accuracy=0.382, lr=0.1] 65%|██████▍   | 60/93 [24:50<13:25, 24.41s/epoch, loss=1.14, accuracy=0.756, val_loss=1.37, val_accuracy=0.667, lr=0.1] 66%|██████▌   | 61/93 [25:14<13:02, 24.44s/epoch, loss=1.14, accuracy=0.757, val_loss=1.63, val_accuracy=0.609, lr=0.1] 67%|██████▋   | 62/93 [25:38<12:27, 24.10s/epoch, loss=1.14, accuracy=0.753, val_loss=4.81, val_accuracy=0.213, lr=0.1] 68%|██████▊   | 63/93 [26:02<12:05, 24.20s/epoch, loss=1.14, accuracy=0.757, val_loss=2.08, val_accuracy=0.432, lr=0.1] 69%|██████▉   | 64/93 [26:27<11:43, 24.27s/epoch, loss=1.13, accuracy=0.752, val_loss=2.35, val_accuracy=0.409, lr=0.1] 70%|██████▉   | 65/93 [26:51<11:17, 24.18s/epoch, loss=1.13, accuracy=0.756, val_loss=2.11, val_accuracy=0.456, lr=0.0316] 71%|███████   | 66/93 [27:15<10:53, 24.19s/epoch, loss=1.13, accuracy=0.757, val_loss=1.83, val_accuracy=0.557, lr=0.1]    72%|███████▏  | 67/93 [27:39<10:30, 24.27s/epoch, loss=1.13, accuracy=0.756, val_loss=1.62, val_accuracy=0.577, lr=0.1] 73%|███████▎  | 68/93 [28:04<10:07, 24.31s/epoch, loss=1.13, accuracy=0.758, val_loss=1.98, val_accuracy=0.491, lr=0.1] 74%|███████▍  | 69/93 [28:27<09:38, 24.12s/epoch, loss=1.13, accuracy=0.758, val_loss=2.31, val_accuracy=0.461, lr=0.1] 75%|███████▌  | 70/93 [28:51<09:12, 24.03s/epoch, loss=1.13, accuracy=0.756, val_loss=1.71, val_accuracy=0.58, lr=0.0316] 76%|███████▋  | 71/93 [29:16<08:52, 24.20s/epoch, loss=1.14, accuracy=0.755, val_loss=1.72, val_accuracy=0.58, lr=0.1]    77%|███████▋  | 72/93 [29:39<08:21, 23.89s/epoch, loss=1.12, accuracy=0.757, val_loss=1.55, val_accuracy=0.615, lr=0.1] 78%|███████▊  | 73/93 [30:02<07:53, 23.66s/epoch, loss=1.13, accuracy=0.756, val_loss=1.89, val_accuracy=0.544, lr=0.1] 80%|███████▉  | 74/93 [30:25<07:25, 23.42s/epoch, loss=1.13, accuracy=0.756, val_loss=2.14, val_accuracy=0.447, lr=0.1] 81%|████████  | 75/93 [30:49<07:06, 23.68s/epoch, loss=1.13, accuracy=0.758, val_loss=2.11, val_accuracy=0.507, lr=0.0316] 82%|████████▏ | 76/93 [31:12<06:38, 23.45s/epoch, loss=1.13, accuracy=0.758, val_loss=5.49, val_accuracy=0.187, lr=0.1]    83%|████████▎ | 77/93 [31:36<06:17, 23.62s/epoch, loss=1.13, accuracy=0.758, val_loss=3.87, val_accuracy=0.343, lr=0.1] 84%|████████▍ | 78/93 [32:00<05:54, 23.65s/epoch, loss=1.13, accuracy=0.758, val_loss=2.38, val_accuracy=0.422, lr=0.1] 85%|████████▍ | 79/93 [32:23<05:30, 23.58s/epoch, loss=1.12, accuracy=0.756, val_loss=1.97, val_accuracy=0.524, lr=0.1] 86%|████████▌ | 80/93 [32:48<05:10, 23.85s/epoch, loss=1.13, accuracy=0.759, val_loss=1.85, val_accuracy=0.559, lr=0.0316] 87%|████████▋ | 81/93 [33:12<04:49, 24.09s/epoch, loss=1.14, accuracy=0.754, val_loss=2.21, val_accuracy=0.428, lr=0.1]    88%|████████▊ | 82/93 [33:37<04:26, 24.26s/epoch, loss=0.92, accuracy=0.817, val_loss=1.02, val_accuracy=0.76, lr=0.01] 89%|████████▉ | 83/93 [34:02<04:03, 24.37s/epoch, loss=0.739, accuracy=0.848, val_loss=0.828, val_accuracy=0.801, lr=0.01] 90%|█████████ | 84/93 [34:26<03:39, 24.34s/epoch, loss=0.657, accuracy=0.854, val_loss=0.835, val_accuracy=0.785, lr=0.01] 91%|█████████▏| 85/93 [34:51<03:15, 24.50s/epoch, loss=0.612, accuracy=0.858, val_loss=0.819, val_accuracy=0.786, lr=0.01] 92%|█████████▏| 86/93 [35:15<02:51, 24.51s/epoch, loss=0.59, accuracy=0.859, val_loss=0.813, val_accuracy=0.791, lr=0.01]  94%|█████████▎| 87/93 [35:40<02:27, 24.61s/epoch, loss=0.573, accuracy=0.864, val_loss=1.09, val_accuracy=0.679, lr=0.01] 95%|█████████▍| 88/93 [36:05<02:03, 24.62s/epoch, loss=0.571, accuracy=0.864, val_loss=0.812, val_accuracy=0.791, lr=0.01] 96%|█████████▌| 89/93 [36:29<01:37, 24.43s/epoch, loss=0.567, accuracy=0.866, val_loss=0.788, val_accuracy=0.798, lr=0.01] 97%|█████████▋| 90/93 [36:53<01:12, 24.26s/epoch, loss=0.567, accuracy=0.866, val_loss=0.827, val_accuracy=0.781, lr=0.01] 98%|█████████▊| 91/93 [37:16<00:47, 23.83s/epoch, loss=0.561, accuracy=0.868, val_loss=0.753, val_accuracy=0.809, lr=0.01] 99%|█████████▉| 92/93 [37:39<00:23, 23.74s/epoch, loss=0.564, accuracy=0.869, val_loss=1.05, val_accuracy=0.742, lr=0.01] 100%|██████████| 93/93 [38:04<00:00, 23.96s/epoch, loss=0.557, accuracy=0.872, val_loss=0.877, val_accuracy=0.772, lr=0.01]100%|██████████| 93/93 [38:04<00:00, 24.56s/epoch, loss=0.557, accuracy=0.872, val_loss=0.877, val_accuracy=0.772, lr=0.01]
Using real-time data augmentation.
Test loss: 0.8765526413917542
Test accuracy: 0.7720999717712402


* * * Run SGD for ID = 16_8. * * *


2024-02-15 18:04:20.571675: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 18:04:22.928392: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 18:04:22.929463: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-15 18:04:22.955083: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 18:04:22.955120: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 18:04:22.957734: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 18:04:22.957775: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 18:04:22.959881: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 18:04:22.960499: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 18:04:22.962657: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 18:04:22.964027: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 18:04:22.968313: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 18:04:22.969924: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 18:04:22.970002: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 18:04:24.209569: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-15 18:04:24.210094: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 18:04:24.212200: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 18:04:24.212236: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 18:04:24.212290: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 18:04:24.212312: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 18:04:24.212333: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 18:04:24.212353: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 18:04:24.212373: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 18:04:24.212393: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 18:04:24.212422: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 18:04:24.212907: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 18:04:24.212943: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 18:04:24.867705: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-15 18:04:24.867761: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-15 18:04:24.867772: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-15 18:04:24.868685: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': 168, 'batch_size': 128, 'epochs': 93, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/93 [00:00<?, ?epoch/s]2024-02-15 18:04:25.694276: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-15 18:04:25.706725: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2200060000 Hz
2024-02-15 18:04:27.811826: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 18:04:28.067220: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 18:04:28.870072: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-15 18:04:28.916132: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/93 [00:56<1:26:13, 56.24s/epoch, loss=3.45, accuracy=0.289, val_loss=2.28, val_accuracy=0.293, lr=0.1]  2%|▏         | 2/93 [01:19<55:55, 36.87s/epoch, loss=1.61, accuracy=0.513, val_loss=2.56, val_accuracy=0.244, lr=0.1]    3%|▎         | 3/93 [01:44<47:10, 31.45s/epoch, loss=1.45, accuracy=0.59, val_loss=3.78, val_accuracy=0.211, lr=0.1]   4%|▍         | 4/93 [02:09<42:43, 28.80s/epoch, loss=1.35, accuracy=0.652, val_loss=1.75, val_accuracy=0.504, lr=0.1]  5%|▌         | 5/93 [02:32<39:31, 26.95s/epoch, loss=1.29, accuracy=0.685, val_loss=1.55, val_accuracy=0.591, lr=0.1]  6%|▋         | 6/93 [02:57<37:40, 25.99s/epoch, loss=1.25, accuracy=0.7, val_loss=2.47, val_accuracy=0.377, lr=0.1]    8%|▊         | 7/93 [03:20<36:11, 25.25s/epoch, loss=1.24, accuracy=0.71, val_loss=1.89, val_accuracy=0.549, lr=0.1]  9%|▊         | 8/93 [03:45<35:23, 24.99s/epoch, loss=1.22, accuracy=0.718, val_loss=2.67, val_accuracy=0.358, lr=0.1] 10%|▉         | 9/93 [04:08<34:15, 24.48s/epoch, loss=1.21, accuracy=0.723, val_loss=1.71, val_accuracy=0.558, lr=0.1] 11%|█         | 10/93 [04:33<34:05, 24.64s/epoch, loss=1.21, accuracy=0.727, val_loss=1.55, val_accuracy=0.606, lr=0.1] 12%|█▏        | 11/93 [04:58<33:39, 24.63s/epoch, loss=1.2, accuracy=0.729, val_loss=2.72, val_accuracy=0.403, lr=0.1]  13%|█▎        | 12/93 [05:22<33:15, 24.64s/epoch, loss=1.19, accuracy=0.732, val_loss=2.34, val_accuracy=0.493, lr=0.1] 14%|█▍        | 13/93 [05:47<32:44, 24.56s/epoch, loss=1.19, accuracy=0.736, val_loss=2.62, val_accuracy=0.351, lr=0.1] 15%|█▌        | 14/93 [06:11<32:21, 24.57s/epoch, loss=1.2, accuracy=0.736, val_loss=1.83, val_accuracy=0.54, lr=0.1]   16%|█▌        | 15/93 [06:35<31:32, 24.26s/epoch, loss=1.18, accuracy=0.736, val_loss=1.77, val_accuracy=0.532, lr=0.0316] 17%|█▋        | 16/93 [07:00<31:19, 24.41s/epoch, loss=1.19, accuracy=0.739, val_loss=2.69, val_accuracy=0.417, lr=0.1]    18%|█▊        | 17/93 [07:23<30:25, 24.03s/epoch, loss=1.18, accuracy=0.74, val_loss=2.2, val_accuracy=0.477, lr=0.1]   19%|█▉        | 18/93 [07:46<29:39, 23.73s/epoch, loss=1.19, accuracy=0.739, val_loss=3.85, val_accuracy=0.364, lr=0.1] 20%|██        | 19/93 [08:10<29:19, 23.78s/epoch, loss=1.18, accuracy=0.742, val_loss=2.28, val_accuracy=0.491, lr=0.1] 22%|██▏       | 20/93 [08:34<29:11, 24.00s/epoch, loss=1.17, accuracy=0.74, val_loss=2.22, val_accuracy=0.474, lr=0.0316] 23%|██▎       | 21/93 [08:57<28:28, 23.73s/epoch, loss=1.17, accuracy=0.743, val_loss=1.82, val_accuracy=0.557, lr=0.1]   24%|██▎       | 22/93 [09:22<28:22, 23.98s/epoch, loss=1.17, accuracy=0.744, val_loss=1.63, val_accuracy=0.618, lr=0.1] 25%|██▍       | 23/93 [09:45<27:43, 23.76s/epoch, loss=1.17, accuracy=0.741, val_loss=2.06, val_accuracy=0.551, lr=0.1] 26%|██▌       | 24/93 [10:09<27:16, 23.72s/epoch, loss=1.17, accuracy=0.745, val_loss=1.68, val_accuracy=0.587, lr=0.1] 27%|██▋       | 25/93 [10:32<26:41, 23.55s/epoch, loss=1.17, accuracy=0.742, val_loss=1.71, val_accuracy=0.607, lr=0.0316] 28%|██▊       | 26/93 [10:55<26:12, 23.47s/epoch, loss=1.16, accuracy=0.746, val_loss=1.44, val_accuracy=0.643, lr=0.1]    29%|██▉       | 27/93 [11:20<26:24, 24.01s/epoch, loss=1.17, accuracy=0.745, val_loss=2.02, val_accuracy=0.471, lr=0.1] 30%|███       | 28/93 [11:46<26:28, 24.43s/epoch, loss=1.16, accuracy=0.75, val_loss=1.93, val_accuracy=0.545, lr=0.1]  31%|███       | 29/93 [12:11<26:12, 24.58s/epoch, loss=1.16, accuracy=0.747, val_loss=3.25, val_accuracy=0.223, lr=0.1] 32%|███▏      | 30/93 [12:35<25:48, 24.57s/epoch, loss=1.15, accuracy=0.748, val_loss=1.68, val_accuracy=0.566, lr=0.1] 33%|███▎      | 31/93 [13:00<25:31, 24.70s/epoch, loss=1.16, accuracy=0.748, val_loss=2.35, val_accuracy=0.396, lr=0.0316] 34%|███▍      | 32/93 [13:25<25:08, 24.73s/epoch, loss=1.15, accuracy=0.749, val_loss=1.89, val_accuracy=0.534, lr=0.1]    35%|███▌      | 33/93 [13:50<24:49, 24.82s/epoch, loss=1.15, accuracy=0.75, val_loss=2.33, val_accuracy=0.433, lr=0.1]  37%|███▋      | 34/93 [14:14<23:58, 24.38s/epoch, loss=1.15, accuracy=0.75, val_loss=2.34, val_accuracy=0.433, lr=0.1] 38%|███▊      | 35/93 [14:37<23:21, 24.16s/epoch, loss=1.15, accuracy=0.75, val_loss=1.91, val_accuracy=0.502, lr=0.1] 39%|███▊      | 36/93 [15:01<22:55, 24.14s/epoch, loss=1.15, accuracy=0.748, val_loss=2.33, val_accuracy=0.344, lr=0.0316] 40%|███▉      | 37/93 [15:26<22:46, 24.41s/epoch, loss=1.14, accuracy=0.749, val_loss=2.34, val_accuracy=0.461, lr=0.1]    41%|████      | 38/93 [15:51<22:28, 24.52s/epoch, loss=1.14, accuracy=0.751, val_loss=5.16, val_accuracy=0.279, lr=0.1] 42%|████▏     | 39/93 [16:16<22:08, 24.59s/epoch, loss=1.14, accuracy=0.749, val_loss=2.35, val_accuracy=0.388, lr=0.1] 43%|████▎     | 40/93 [16:41<21:44, 24.61s/epoch, loss=1.14, accuracy=0.752, val_loss=1.47, val_accuracy=0.623, lr=0.1] 44%|████▍     | 41/93 [17:05<21:15, 24.53s/epoch, loss=1.14, accuracy=0.752, val_loss=2, val_accuracy=0.501, lr=0.0316] 45%|████▌     | 42/93 [17:30<20:53, 24.58s/epoch, loss=1.14, accuracy=0.749, val_loss=1.62, val_accuracy=0.595, lr=0.1] 46%|████▌     | 43/93 [17:54<20:31, 24.63s/epoch, loss=1.13, accuracy=0.753, val_loss=1.93, val_accuracy=0.479, lr=0.1] 47%|████▋     | 44/93 [18:19<20:12, 24.75s/epoch, loss=1.13, accuracy=0.752, val_loss=2.31, val_accuracy=0.404, lr=0.1] 48%|████▊     | 45/93 [18:45<19:54, 24.89s/epoch, loss=1.13, accuracy=0.753, val_loss=2.26, val_accuracy=0.488, lr=0.1] 49%|████▉     | 46/93 [19:09<19:23, 24.76s/epoch, loss=1.13, accuracy=0.751, val_loss=1.83, val_accuracy=0.572, lr=0.0316] 51%|█████     | 47/93 [19:34<19:01, 24.82s/epoch, loss=1.13, accuracy=0.752, val_loss=1.67, val_accuracy=0.599, lr=0.1]    52%|█████▏    | 48/93 [19:59<18:42, 24.95s/epoch, loss=1.13, accuracy=0.754, val_loss=2.53, val_accuracy=0.471, lr=0.1] 53%|█████▎    | 49/93 [20:24<18:11, 24.81s/epoch, loss=1.13, accuracy=0.753, val_loss=3.38, val_accuracy=0.4, lr=0.1]   54%|█████▍    | 50/93 [20:49<17:48, 24.84s/epoch, loss=1.14, accuracy=0.752, val_loss=4.7, val_accuracy=0.352, lr=0.1] 55%|█████▍    | 51/93 [21:14<17:30, 25.00s/epoch, loss=1.13, accuracy=0.755, val_loss=2.37, val_accuracy=0.455, lr=0.0316] 56%|█████▌    | 52/93 [21:39<17:03, 24.97s/epoch, loss=1.13, accuracy=0.756, val_loss=1.56, val_accuracy=0.594, lr=0.1]    57%|█████▋    | 53/93 [22:02<16:18, 24.46s/epoch, loss=1.12, accuracy=0.756, val_loss=1.42, val_accuracy=0.661, lr=0.1] 58%|█████▊    | 54/93 [22:26<15:45, 24.24s/epoch, loss=1.13, accuracy=0.755, val_loss=1.47, val_accuracy=0.646, lr=0.1] 59%|█████▉    | 55/93 [22:50<15:16, 24.11s/epoch, loss=1.13, accuracy=0.754, val_loss=1.96, val_accuracy=0.508, lr=0.1] 60%|██████    | 56/93 [23:15<15:00, 24.35s/epoch, loss=1.14, accuracy=0.75, val_loss=1.66, val_accuracy=0.555, lr=0.1]  61%|██████▏   | 57/93 [23:40<14:45, 24.60s/epoch, loss=1.13, accuracy=0.751, val_loss=2.69, val_accuracy=0.389, lr=0.1] 62%|██████▏   | 58/93 [24:05<14:26, 24.75s/epoch, loss=1.13, accuracy=0.753, val_loss=2.54, val_accuracy=0.415, lr=0.0316] 63%|██████▎   | 59/93 [24:29<13:56, 24.59s/epoch, loss=1.13, accuracy=0.751, val_loss=1.58, val_accuracy=0.59, lr=0.1]     65%|██████▍   | 60/93 [24:52<13:17, 24.17s/epoch, loss=1.12, accuracy=0.754, val_loss=2.38, val_accuracy=0.427, lr=0.1] 66%|██████▌   | 61/93 [25:16<12:49, 24.06s/epoch, loss=1.13, accuracy=0.753, val_loss=2.26, val_accuracy=0.526, lr=0.1] 67%|██████▋   | 62/93 [25:41<12:34, 24.35s/epoch, loss=1.12, accuracy=0.753, val_loss=2.58, val_accuracy=0.416, lr=0.1] 68%|██████▊   | 63/93 [26:05<12:05, 24.17s/epoch, loss=1.12, accuracy=0.754, val_loss=1.69, val_accuracy=0.591, lr=0.0316] 69%|██████▉   | 64/93 [26:30<11:48, 24.43s/epoch, loss=1.12, accuracy=0.757, val_loss=3.22, val_accuracy=0.296, lr=0.1]    70%|██████▉   | 65/93 [26:54<11:20, 24.31s/epoch, loss=1.12, accuracy=0.754, val_loss=2.09, val_accuracy=0.512, lr=0.1] 71%|███████   | 66/93 [27:18<10:57, 24.34s/epoch, loss=1.12, accuracy=0.755, val_loss=3.89, val_accuracy=0.256, lr=0.1] 72%|███████▏  | 67/93 [27:42<10:30, 24.26s/epoch, loss=1.13, accuracy=0.753, val_loss=1.92, val_accuracy=0.528, lr=0.1] 73%|███████▎  | 68/93 [28:07<10:08, 24.35s/epoch, loss=1.12, accuracy=0.753, val_loss=2.14, val_accuracy=0.499, lr=0.0316] 74%|███████▍  | 69/93 [28:30<09:35, 23.98s/epoch, loss=1.11, accuracy=0.755, val_loss=2.09, val_accuracy=0.5, lr=0.1]      75%|███████▌  | 70/93 [28:54<09:08, 23.86s/epoch, loss=1.12, accuracy=0.756, val_loss=1.87, val_accuracy=0.543, lr=0.1] 76%|███████▋  | 71/93 [29:18<08:48, 24.04s/epoch, loss=1.11, accuracy=0.757, val_loss=2.49, val_accuracy=0.42, lr=0.1]  77%|███████▋  | 72/93 [29:43<08:31, 24.36s/epoch, loss=1.12, accuracy=0.754, val_loss=1.96, val_accuracy=0.501, lr=0.1] 78%|███████▊  | 73/93 [30:08<08:11, 24.56s/epoch, loss=1.12, accuracy=0.756, val_loss=2.5, val_accuracy=0.428, lr=0.0316] 80%|███████▉  | 74/93 [30:33<07:48, 24.68s/epoch, loss=1.12, accuracy=0.756, val_loss=2.08, val_accuracy=0.49, lr=0.1]    81%|████████  | 75/93 [30:57<07:20, 24.47s/epoch, loss=1.12, accuracy=0.755, val_loss=3.38, val_accuracy=0.427, lr=0.1] 82%|████████▏ | 76/93 [31:22<06:59, 24.70s/epoch, loss=1.12, accuracy=0.755, val_loss=1.96, val_accuracy=0.594, lr=0.1] 83%|████████▎ | 77/93 [31:48<06:37, 24.84s/epoch, loss=1.12, accuracy=0.755, val_loss=1.48, val_accuracy=0.627, lr=0.1] 84%|████████▍ | 78/93 [32:11<06:07, 24.48s/epoch, loss=1.12, accuracy=0.755, val_loss=3.25, val_accuracy=0.376, lr=0.0316] 85%|████████▍ | 79/93 [32:36<05:45, 24.71s/epoch, loss=1.12, accuracy=0.755, val_loss=2.35, val_accuracy=0.468, lr=0.1]    86%|████████▌ | 80/93 [33:02<05:23, 24.92s/epoch, loss=1.11, accuracy=0.757, val_loss=2.31, val_accuracy=0.428, lr=0.1] 87%|████████▋ | 81/93 [33:27<05:00, 25.05s/epoch, loss=1.12, accuracy=0.754, val_loss=2.6, val_accuracy=0.412, lr=0.1]  88%|████████▊ | 82/93 [33:52<04:34, 24.98s/epoch, loss=0.911, accuracy=0.814, val_loss=0.931, val_accuracy=0.787, lr=0.01] 89%|████████▉ | 83/93 [34:15<04:05, 24.50s/epoch, loss=0.736, accuracy=0.844, val_loss=0.814, val_accuracy=0.807, lr=0.01] 90%|█████████ | 84/93 [34:39<03:38, 24.25s/epoch, loss=0.654, accuracy=0.854, val_loss=0.772, val_accuracy=0.803, lr=0.01] 91%|█████████▏| 85/93 [35:04<03:15, 24.48s/epoch, loss=0.613, accuracy=0.855, val_loss=0.946, val_accuracy=0.739, lr=0.01] 92%|█████████▏| 86/93 [35:27<02:48, 24.07s/epoch, loss=0.589, accuracy=0.858, val_loss=0.82, val_accuracy=0.788, lr=0.01]  94%|█████████▎| 87/93 [35:52<02:25, 24.32s/epoch, loss=0.581, accuracy=0.859, val_loss=0.731, val_accuracy=0.811, lr=0.01] 95%|█████████▍| 88/93 [36:16<02:01, 24.32s/epoch, loss=0.579, accuracy=0.86, val_loss=0.693, val_accuracy=0.823, lr=0.01]  96%|█████████▌| 89/93 [36:41<01:37, 24.31s/epoch, loss=0.569, accuracy=0.862, val_loss=0.816, val_accuracy=0.791, lr=0.01] 97%|█████████▋| 90/93 [37:05<01:12, 24.29s/epoch, loss=0.566, accuracy=0.865, val_loss=0.802, val_accuracy=0.792, lr=0.01] 98%|█████████▊| 91/93 [37:30<00:48, 24.45s/epoch, loss=0.565, accuracy=0.864, val_loss=0.837, val_accuracy=0.783, lr=0.01] 99%|█████████▉| 92/93 [37:55<00:24, 24.63s/epoch, loss=0.563, accuracy=0.866, val_loss=0.701, val_accuracy=0.822, lr=0.01]100%|██████████| 93/93 [38:19<00:00, 24.55s/epoch, loss=0.56, accuracy=0.87, val_loss=0.873, val_accuracy=0.762, lr=0.00316]100%|██████████| 93/93 [38:19<00:00, 24.73s/epoch, loss=0.56, accuracy=0.87, val_loss=0.873, val_accuracy=0.762, lr=0.00316]
Using real-time data augmentation.
Test loss: 0.8732359409332275
Test accuracy: 0.7616999745368958


* * * Run SGD for ID = 16_9. * * *


2024-02-15 18:42:47.907343: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 18:42:50.734864: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 18:42:50.736361: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-15 18:42:50.774063: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 18:42:50.774115: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 18:42:50.777063: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 18:42:50.777107: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 18:42:50.779406: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 18:42:50.780480: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 18:42:50.782833: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 18:42:50.784287: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 18:42:50.788945: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 18:42:50.789436: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 18:42:50.789554: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 18:42:52.024306: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-15 18:42:52.024893: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 18:42:52.025315: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 18:42:52.025349: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 18:42:52.025384: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 18:42:52.025402: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 18:42:52.025419: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 18:42:52.025436: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 18:42:52.025453: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 18:42:52.025470: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 18:42:52.025487: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 18:42:52.025898: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 18:42:52.025935: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 18:42:52.679961: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-15 18:42:52.680030: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-15 18:42:52.680040: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-15 18:42:52.680899: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': 169, 'batch_size': 128, 'epochs': 93, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/93 [00:00<?, ?epoch/s]2024-02-15 18:42:53.479449: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-15 18:42:53.491830: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2200060000 Hz
2024-02-15 18:42:55.638774: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 18:42:55.917388: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 18:42:56.680709: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-15 18:42:56.726410: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/93 [00:56<1:26:12, 56.22s/epoch, loss=3.28, accuracy=0.271, val_loss=2.47, val_accuracy=0.236, lr=0.1]  2%|▏         | 2/93 [01:21<57:30, 37.92s/epoch, loss=1.65, accuracy=0.487, val_loss=2.2, val_accuracy=0.409, lr=0.1]     3%|▎         | 3/93 [01:46<48:08, 32.09s/epoch, loss=1.41, accuracy=0.609, val_loss=2.07, val_accuracy=0.441, lr=0.1]  4%|▍         | 4/93 [02:11<43:23, 29.25s/epoch, loss=1.29, accuracy=0.675, val_loss=2.54, val_accuracy=0.394, lr=0.1]  5%|▌         | 5/93 [02:35<40:17, 27.47s/epoch, loss=1.25, accuracy=0.695, val_loss=1.98, val_accuracy=0.484, lr=0.1]  6%|▋         | 6/93 [03:00<38:36, 26.62s/epoch, loss=1.23, accuracy=0.711, val_loss=2.88, val_accuracy=0.41, lr=0.1]   8%|▊         | 7/93 [03:23<36:34, 25.52s/epoch, loss=1.22, accuracy=0.722, val_loss=2.2, val_accuracy=0.431, lr=0.1]  9%|▊         | 8/93 [03:49<36:00, 25.41s/epoch, loss=1.21, accuracy=0.724, val_loss=2.01, val_accuracy=0.447, lr=0.1] 10%|▉         | 9/93 [04:12<34:50, 24.89s/epoch, loss=1.2, accuracy=0.729, val_loss=1.51, val_accuracy=0.619, lr=0.1]  11%|█         | 10/93 [04:37<34:29, 24.93s/epoch, loss=1.19, accuracy=0.734, val_loss=1.86, val_accuracy=0.544, lr=0.1] 12%|█▏        | 11/93 [05:02<34:02, 24.91s/epoch, loss=1.18, accuracy=0.733, val_loss=2.26, val_accuracy=0.449, lr=0.1] 13%|█▎        | 12/93 [05:26<33:15, 24.63s/epoch, loss=1.18, accuracy=0.737, val_loss=1.84, val_accuracy=0.567, lr=0.1] 14%|█▍        | 13/93 [05:49<32:15, 24.19s/epoch, loss=1.17, accuracy=0.738, val_loss=2.16, val_accuracy=0.464, lr=0.1] 15%|█▌        | 14/93 [06:15<32:17, 24.52s/epoch, loss=1.17, accuracy=0.743, val_loss=1.79, val_accuracy=0.557, lr=0.0316] 16%|█▌        | 15/93 [06:39<31:52, 24.52s/epoch, loss=1.17, accuracy=0.743, val_loss=2.69, val_accuracy=0.389, lr=0.1]    17%|█▋        | 16/93 [07:04<31:43, 24.72s/epoch, loss=1.15, accuracy=0.745, val_loss=2.99, val_accuracy=0.316, lr=0.1] 18%|█▊        | 17/93 [07:29<31:10, 24.61s/epoch, loss=1.15, accuracy=0.745, val_loss=3.69, val_accuracy=0.399, lr=0.1] 19%|█▉        | 18/93 [07:53<30:46, 24.62s/epoch, loss=1.16, accuracy=0.743, val_loss=1.54, val_accuracy=0.608, lr=0.1] 20%|██        | 19/93 [08:18<30:25, 24.67s/epoch, loss=1.15, accuracy=0.746, val_loss=2.01, val_accuracy=0.556, lr=0.0316] 22%|██▏       | 20/93 [08:43<30:01, 24.67s/epoch, loss=1.15, accuracy=0.745, val_loss=2.13, val_accuracy=0.49, lr=0.1]     23%|██▎       | 21/93 [09:08<29:37, 24.69s/epoch, loss=1.14, accuracy=0.747, val_loss=1.74, val_accuracy=0.556, lr=0.1] 24%|██▎       | 22/93 [09:31<28:52, 24.41s/epoch, loss=1.14, accuracy=0.75, val_loss=6.16, val_accuracy=0.194, lr=0.1]  25%|██▍       | 23/93 [09:56<28:34, 24.49s/epoch, loss=1.15, accuracy=0.748, val_loss=2.48, val_accuracy=0.358, lr=0.1] 26%|██▌       | 24/93 [10:21<28:21, 24.66s/epoch, loss=1.14, accuracy=0.748, val_loss=2.28, val_accuracy=0.408, lr=0.0316] 27%|██▋       | 25/93 [10:46<27:59, 24.70s/epoch, loss=1.14, accuracy=0.75, val_loss=2.16, val_accuracy=0.487, lr=0.1]     28%|██▊       | 26/93 [11:11<27:49, 24.91s/epoch, loss=1.14, accuracy=0.749, val_loss=1.69, val_accuracy=0.559, lr=0.1] 29%|██▉       | 27/93 [11:36<27:25, 24.93s/epoch, loss=1.14, accuracy=0.75, val_loss=3.21, val_accuracy=0.312, lr=0.1]  30%|███       | 28/93 [12:00<26:46, 24.72s/epoch, loss=1.14, accuracy=0.75, val_loss=2.57, val_accuracy=0.375, lr=0.1] 31%|███       | 29/93 [12:25<26:26, 24.79s/epoch, loss=1.13, accuracy=0.749, val_loss=2.03, val_accuracy=0.484, lr=0.0316] 32%|███▏      | 30/93 [12:50<26:03, 24.82s/epoch, loss=1.13, accuracy=0.751, val_loss=4.67, val_accuracy=0.252, lr=0.1]    33%|███▎      | 31/93 [13:14<25:16, 24.46s/epoch, loss=1.13, accuracy=0.752, val_loss=1.67, val_accuracy=0.571, lr=0.1] 34%|███▍      | 32/93 [13:40<25:13, 24.81s/epoch, loss=1.13, accuracy=0.75, val_loss=1.94, val_accuracy=0.509, lr=0.1]  35%|███▌      | 33/93 [14:03<24:31, 24.53s/epoch, loss=1.13, accuracy=0.753, val_loss=2.18, val_accuracy=0.512, lr=0.1] 37%|███▋      | 34/93 [14:28<24:09, 24.56s/epoch, loss=1.13, accuracy=0.754, val_loss=2.43, val_accuracy=0.37, lr=0.0316] 38%|███▊      | 35/93 [14:53<23:45, 24.58s/epoch, loss=1.13, accuracy=0.752, val_loss=2.94, val_accuracy=0.263, lr=0.1]   39%|███▊      | 36/93 [15:17<23:17, 24.52s/epoch, loss=1.13, accuracy=0.751, val_loss=1.47, val_accuracy=0.641, lr=0.1] 40%|███▉      | 37/93 [15:42<22:58, 24.62s/epoch, loss=1.13, accuracy=0.755, val_loss=1.63, val_accuracy=0.587, lr=0.1] 41%|████      | 38/93 [16:07<22:36, 24.65s/epoch, loss=1.13, accuracy=0.752, val_loss=2.48, val_accuracy=0.456, lr=0.1] 42%|████▏     | 39/93 [16:32<22:18, 24.79s/epoch, loss=1.13, accuracy=0.753, val_loss=1.79, val_accuracy=0.546, lr=0.1] 43%|████▎     | 40/93 [16:56<21:50, 24.73s/epoch, loss=1.13, accuracy=0.753, val_loss=2.19, val_accuracy=0.437, lr=0.1] 44%|████▍     | 41/93 [17:22<21:36, 24.93s/epoch, loss=1.13, accuracy=0.758, val_loss=1.62, val_accuracy=0.622, lr=0.0316] 45%|████▌     | 42/93 [17:47<21:23, 25.17s/epoch, loss=1.13, accuracy=0.755, val_loss=1.94, val_accuracy=0.501, lr=0.1]    46%|████▌     | 43/93 [18:12<20:49, 25.00s/epoch, loss=1.12, accuracy=0.754, val_loss=4.34, val_accuracy=0.269, lr=0.1] 47%|████▋     | 44/93 [18:36<20:06, 24.63s/epoch, loss=1.13, accuracy=0.756, val_loss=2.31, val_accuracy=0.43, lr=0.1]  48%|████▊     | 45/93 [19:01<19:47, 24.74s/epoch, loss=1.13, accuracy=0.754, val_loss=1.77, val_accuracy=0.555, lr=0.1] 49%|████▉     | 46/93 [19:26<19:28, 24.86s/epoch, loss=1.13, accuracy=0.756, val_loss=1.73, val_accuracy=0.58, lr=0.0316] 51%|█████     | 47/93 [19:50<18:53, 24.65s/epoch, loss=1.12, accuracy=0.754, val_loss=3.22, val_accuracy=0.314, lr=0.1]   52%|█████▏    | 48/93 [20:14<18:17, 24.39s/epoch, loss=1.13, accuracy=0.755, val_loss=2.74, val_accuracy=0.362, lr=0.1] 53%|█████▎    | 49/93 [20:39<18:08, 24.74s/epoch, loss=1.12, accuracy=0.755, val_loss=2.49, val_accuracy=0.416, lr=0.1] 54%|█████▍    | 50/93 [21:05<17:49, 24.87s/epoch, loss=1.12, accuracy=0.756, val_loss=2.74, val_accuracy=0.342, lr=0.1] 55%|█████▍    | 51/93 [21:30<17:26, 24.92s/epoch, loss=1.12, accuracy=0.754, val_loss=2.48, val_accuracy=0.419, lr=0.0316] 56%|█████▌    | 52/93 [21:55<17:04, 24.98s/epoch, loss=1.12, accuracy=0.756, val_loss=4.39, val_accuracy=0.275, lr=0.1]    57%|█████▋    | 53/93 [22:19<16:24, 24.61s/epoch, loss=1.12, accuracy=0.755, val_loss=3.41, val_accuracy=0.366, lr=0.1] 58%|█████▊    | 54/93 [22:44<16:06, 24.78s/epoch, loss=1.12, accuracy=0.757, val_loss=2.05, val_accuracy=0.511, lr=0.1] 59%|█████▉    | 55/93 [23:09<15:45, 24.87s/epoch, loss=1.12, accuracy=0.757, val_loss=1.87, val_accuracy=0.504, lr=0.1] 60%|██████    | 56/93 [23:34<15:23, 24.96s/epoch, loss=1.12, accuracy=0.756, val_loss=2.99, val_accuracy=0.245, lr=0.0316] 61%|██████▏   | 57/93 [23:59<14:59, 25.00s/epoch, loss=1.12, accuracy=0.758, val_loss=1.87, val_accuracy=0.503, lr=0.1]    62%|██████▏   | 58/93 [24:22<14:17, 24.49s/epoch, loss=1.13, accuracy=0.756, val_loss=2.12, val_accuracy=0.444, lr=0.1] 63%|██████▎   | 59/93 [24:46<13:47, 24.35s/epoch, loss=1.12, accuracy=0.757, val_loss=2.6, val_accuracy=0.407, lr=0.1]  65%|██████▍   | 60/93 [25:10<13:16, 24.13s/epoch, loss=1.11, accuracy=0.757, val_loss=2.82, val_accuracy=0.363, lr=0.1] 66%|██████▌   | 61/93 [25:35<13:04, 24.50s/epoch, loss=1.12, accuracy=0.757, val_loss=1.85, val_accuracy=0.509, lr=0.0316] 67%|██████▋   | 62/93 [25:59<12:35, 24.38s/epoch, loss=1.11, accuracy=0.758, val_loss=2.11, val_accuracy=0.462, lr=0.1]    68%|██████▊   | 63/93 [26:24<12:13, 24.44s/epoch, loss=1.12, accuracy=0.758, val_loss=2.3, val_accuracy=0.47, lr=0.1]   69%|██████▉   | 64/93 [26:49<11:56, 24.70s/epoch, loss=1.11, accuracy=0.757, val_loss=5.32, val_accuracy=0.309, lr=0.1] 70%|██████▉   | 65/93 [27:14<11:32, 24.75s/epoch, loss=1.12, accuracy=0.756, val_loss=2.11, val_accuracy=0.433, lr=0.1] 71%|███████   | 66/93 [27:39<11:06, 24.67s/epoch, loss=1.12, accuracy=0.756, val_loss=2.56, val_accuracy=0.395, lr=0.0316] 72%|███████▏  | 67/93 [28:03<10:38, 24.54s/epoch, loss=1.11, accuracy=0.758, val_loss=2.24, val_accuracy=0.464, lr=0.1]    73%|███████▎  | 68/93 [28:26<10:02, 24.12s/epoch, loss=1.11, accuracy=0.757, val_loss=1.6, val_accuracy=0.605, lr=0.1]  74%|███████▍  | 69/93 [28:50<09:36, 24.02s/epoch, loss=1.12, accuracy=0.755, val_loss=1.5, val_accuracy=0.63, lr=0.1]  75%|███████▌  | 70/93 [29:15<09:16, 24.21s/epoch, loss=1.11, accuracy=0.757, val_loss=1.8, val_accuracy=0.535, lr=0.1] 76%|███████▋  | 71/93 [29:39<08:52, 24.22s/epoch, loss=1.11, accuracy=0.758, val_loss=3.63, val_accuracy=0.269, lr=0.0316] 77%|███████▋  | 72/93 [30:04<08:34, 24.51s/epoch, loss=1.11, accuracy=0.757, val_loss=1.64, val_accuracy=0.569, lr=0.1]    78%|███████▊  | 73/93 [30:29<08:10, 24.54s/epoch, loss=1.11, accuracy=0.757, val_loss=2.6, val_accuracy=0.33, lr=0.1]   80%|███████▉  | 74/93 [30:54<07:48, 24.67s/epoch, loss=1.11, accuracy=0.757, val_loss=2.11, val_accuracy=0.505, lr=0.1] 81%|████████  | 75/93 [31:18<07:25, 24.74s/epoch, loss=1.12, accuracy=0.755, val_loss=2.42, val_accuracy=0.423, lr=0.1] 82%|████████▏ | 76/93 [31:44<07:04, 24.96s/epoch, loss=1.12, accuracy=0.757, val_loss=2.18, val_accuracy=0.446, lr=0.0316] 83%|████████▎ | 77/93 [32:08<06:37, 24.82s/epoch, loss=1.11, accuracy=0.758, val_loss=3.49, val_accuracy=0.38, lr=0.1]     84%|████████▍ | 78/93 [32:33<06:12, 24.81s/epoch, loss=1.11, accuracy=0.754, val_loss=3.89, val_accuracy=0.241, lr=0.1] 85%|████████▍ | 79/93 [32:58<05:45, 24.70s/epoch, loss=1.11, accuracy=0.758, val_loss=2.34, val_accuracy=0.509, lr=0.1] 86%|████████▌ | 80/93 [33:21<05:16, 24.38s/epoch, loss=1.11, accuracy=0.758, val_loss=4.08, val_accuracy=0.288, lr=0.1] 87%|████████▋ | 81/93 [33:46<04:54, 24.51s/epoch, loss=1.11, accuracy=0.754, val_loss=2.88, val_accuracy=0.322, lr=0.0316] 88%|████████▊ | 82/93 [34:10<04:26, 24.25s/epoch, loss=0.919, accuracy=0.813, val_loss=0.863, val_accuracy=0.812, lr=0.01] 89%|████████▉ | 83/93 [34:33<03:58, 23.90s/epoch, loss=0.733, accuracy=0.847, val_loss=0.78, val_accuracy=0.821, lr=0.01]  90%|█████████ | 84/93 [34:58<03:38, 24.26s/epoch, loss=0.648, accuracy=0.858, val_loss=0.941, val_accuracy=0.745, lr=0.01] 91%|█████████▏| 85/93 [35:22<03:13, 24.22s/epoch, loss=0.606, accuracy=0.859, val_loss=0.807, val_accuracy=0.791, lr=0.01] 92%|█████████▏| 86/93 [35:47<02:50, 24.42s/epoch, loss=0.584, accuracy=0.863, val_loss=0.775, val_accuracy=0.788, lr=0.01] 94%|█████████▎| 87/93 [36:12<02:26, 24.49s/epoch, loss=0.57, accuracy=0.863, val_loss=0.861, val_accuracy=0.77, lr=0.01]   95%|█████████▍| 88/93 [36:37<02:03, 24.66s/epoch, loss=0.567, accuracy=0.863, val_loss=0.86, val_accuracy=0.776, lr=0.01] 96%|█████████▌| 89/93 [37:01<01:38, 24.65s/epoch, loss=0.561, accuracy=0.865, val_loss=0.797, val_accuracy=0.791, lr=0.01] 97%|█████████▋| 90/93 [37:25<01:13, 24.46s/epoch, loss=0.559, accuracy=0.866, val_loss=0.903, val_accuracy=0.756, lr=0.01] 98%|█████████▊| 91/93 [37:50<00:49, 24.53s/epoch, loss=0.556, accuracy=0.869, val_loss=0.713, val_accuracy=0.816, lr=0.01] 99%|█████████▉| 92/93 [38:14<00:24, 24.51s/epoch, loss=0.553, accuracy=0.87, val_loss=0.731, val_accuracy=0.812, lr=0.01] 100%|██████████| 93/93 [38:39<00:00, 24.63s/epoch, loss=0.552, accuracy=0.871, val_loss=0.719, val_accuracy=0.815, lr=0.01]100%|██████████| 93/93 [38:39<00:00, 24.94s/epoch, loss=0.552, accuracy=0.871, val_loss=0.719, val_accuracy=0.815, lr=0.01]
Using real-time data augmentation.
Test loss: 0.7191587686538696
Test accuracy: 0.8151000142097473


* * * Run SGD for ID = 16_10. * * *


2024-02-15 19:21:35.795532: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 19:21:38.849869: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 19:21:38.851064: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-15 19:21:38.895680: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 19:21:38.895717: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 19:21:38.899121: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 19:21:38.899165: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 19:21:38.901472: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 19:21:38.902360: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 19:21:38.904824: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 19:21:38.906441: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 19:21:38.911382: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 19:21:38.911876: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 19:21:38.912146: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 19:21:40.153046: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-15 19:21:40.154158: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 19:21:40.154644: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 19:21:40.154680: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 19:21:40.154715: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 19:21:40.154733: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 19:21:40.154750: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 19:21:40.154766: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 19:21:40.154783: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 19:21:40.154800: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 19:21:40.154816: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 19:21:40.155279: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 19:21:40.155314: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 19:21:40.815788: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-15 19:21:40.815845: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-15 19:21:40.815856: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-15 19:21:40.816778: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': 1610, 'batch_size': 128, 'epochs': 93, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/93 [00:00<?, ?epoch/s]2024-02-15 19:21:41.634102: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-15 19:21:41.634726: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2200060000 Hz
2024-02-15 19:21:43.792021: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 19:21:44.065767: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 19:21:44.884934: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-15 19:21:44.930607: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/93 [01:00<1:32:06, 60.07s/epoch, loss=3.21, accuracy=0.258, val_loss=2.16, val_accuracy=0.254, lr=0.1]  2%|▏         | 2/93 [01:23<58:04, 38.29s/epoch, loss=1.64, accuracy=0.486, val_loss=1.93, val_accuracy=0.402, lr=0.1]    3%|▎         | 3/93 [01:47<48:10, 32.12s/epoch, loss=1.42, accuracy=0.604, val_loss=1.6, val_accuracy=0.563, lr=0.1]   4%|▍         | 4/93 [02:12<43:10, 29.11s/epoch, loss=1.31, accuracy=0.661, val_loss=4.2, val_accuracy=0.301, lr=0.1]  5%|▌         | 5/93 [02:37<40:22, 27.53s/epoch, loss=1.27, accuracy=0.69, val_loss=2.17, val_accuracy=0.436, lr=0.1]  6%|▋         | 6/93 [03:01<38:13, 26.36s/epoch, loss=1.24, accuracy=0.703, val_loss=3.37, val_accuracy=0.274, lr=0.1]  8%|▊         | 7/93 [03:26<37:05, 25.87s/epoch, loss=1.23, accuracy=0.713, val_loss=1.72, val_accuracy=0.576, lr=0.1]  9%|▊         | 8/93 [03:50<35:58, 25.39s/epoch, loss=1.22, accuracy=0.721, val_loss=2, val_accuracy=0.488, lr=0.0316] 10%|▉         | 9/93 [04:14<35:05, 25.07s/epoch, loss=1.21, accuracy=0.725, val_loss=2.31, val_accuracy=0.419, lr=0.1] 11%|█         | 10/93 [04:38<34:10, 24.71s/epoch, loss=1.2, accuracy=0.728, val_loss=2.03, val_accuracy=0.535, lr=0.1] 12%|█▏        | 11/93 [05:02<33:25, 24.46s/epoch, loss=1.2, accuracy=0.731, val_loss=2.2, val_accuracy=0.39, lr=0.1]   13%|█▎        | 12/93 [05:26<32:45, 24.27s/epoch, loss=1.18, accuracy=0.735, val_loss=1.64, val_accuracy=0.563, lr=0.1] 14%|█▍        | 13/93 [05:49<31:49, 23.87s/epoch, loss=1.19, accuracy=0.732, val_loss=3.42, val_accuracy=0.368, lr=0.0316] 15%|█▌        | 14/93 [06:13<31:23, 23.84s/epoch, loss=1.18, accuracy=0.735, val_loss=1.73, val_accuracy=0.586, lr=0.1]    16%|█▌        | 15/93 [06:37<31:03, 23.89s/epoch, loss=1.18, accuracy=0.738, val_loss=1.64, val_accuracy=0.627, lr=0.1] 17%|█▋        | 16/93 [07:01<30:57, 24.13s/epoch, loss=1.18, accuracy=0.737, val_loss=2.1, val_accuracy=0.47, lr=0.1]   18%|█▊        | 17/93 [07:26<30:54, 24.41s/epoch, loss=1.18, accuracy=0.739, val_loss=3.31, val_accuracy=0.309, lr=0.1] 19%|█▉        | 18/93 [07:52<30:47, 24.63s/epoch, loss=1.18, accuracy=0.741, val_loss=1.89, val_accuracy=0.48, lr=0.0316] 20%|██        | 19/93 [08:16<30:29, 24.72s/epoch, loss=1.18, accuracy=0.74, val_loss=1.78, val_accuracy=0.563, lr=0.1]    22%|██▏       | 20/93 [08:41<29:49, 24.51s/epoch, loss=1.18, accuracy=0.742, val_loss=1.77, val_accuracy=0.558, lr=0.1] 23%|██▎       | 21/93 [09:04<28:59, 24.15s/epoch, loss=1.16, accuracy=0.743, val_loss=2.64, val_accuracy=0.316, lr=0.1] 24%|██▎       | 22/93 [09:29<28:47, 24.34s/epoch, loss=1.17, accuracy=0.743, val_loss=1.75, val_accuracy=0.592, lr=0.1] 25%|██▍       | 23/93 [09:53<28:35, 24.51s/epoch, loss=1.17, accuracy=0.743, val_loss=2.08, val_accuracy=0.438, lr=0.0316] 26%|██▌       | 24/93 [10:18<28:20, 24.64s/epoch, loss=1.17, accuracy=0.744, val_loss=1.88, val_accuracy=0.53, lr=0.1]     27%|██▋       | 25/93 [10:42<27:32, 24.30s/epoch, loss=1.16, accuracy=0.745, val_loss=2.02, val_accuracy=0.507, lr=0.1] 28%|██▊       | 26/93 [11:07<27:18, 24.46s/epoch, loss=1.16, accuracy=0.747, val_loss=1.81, val_accuracy=0.551, lr=0.1] 29%|██▉       | 27/93 [11:30<26:30, 24.09s/epoch, loss=1.17, accuracy=0.743, val_loss=2.05, val_accuracy=0.494, lr=0.1] 30%|███       | 28/93 [11:54<25:59, 23.99s/epoch, loss=1.16, accuracy=0.747, val_loss=1.8, val_accuracy=0.61, lr=0.0316] 31%|███       | 29/93 [12:19<25:56, 24.33s/epoch, loss=1.16, accuracy=0.744, val_loss=3.96, val_accuracy=0.335, lr=0.1]  32%|███▏      | 30/93 [12:43<25:22, 24.16s/epoch, loss=1.16, accuracy=0.748, val_loss=4.28, val_accuracy=0.342, lr=0.1] 33%|███▎      | 31/93 [13:07<25:04, 24.26s/epoch, loss=1.15, accuracy=0.749, val_loss=1.66, val_accuracy=0.552, lr=0.1] 34%|███▍      | 32/93 [13:32<24:44, 24.33s/epoch, loss=1.16, accuracy=0.746, val_loss=1.58, val_accuracy=0.608, lr=0.1] 35%|███▌      | 33/93 [13:55<24:08, 24.14s/epoch, loss=1.15, accuracy=0.75, val_loss=2.35, val_accuracy=0.497, lr=0.1]  37%|███▋      | 34/93 [14:20<23:57, 24.36s/epoch, loss=1.14, accuracy=0.749, val_loss=1.92, val_accuracy=0.531, lr=0.1] 38%|███▊      | 35/93 [14:44<23:26, 24.25s/epoch, loss=1.15, accuracy=0.751, val_loss=2.9, val_accuracy=0.423, lr=0.1]  39%|███▊      | 36/93 [15:09<23:10, 24.40s/epoch, loss=1.14, accuracy=0.749, val_loss=2.28, val_accuracy=0.482, lr=0.1] 40%|███▉      | 37/93 [15:33<22:46, 24.41s/epoch, loss=1.15, accuracy=0.749, val_loss=2.12, val_accuracy=0.46, lr=0.0316] 41%|████      | 38/93 [15:57<22:09, 24.18s/epoch, loss=1.15, accuracy=0.75, val_loss=2.96, val_accuracy=0.425, lr=0.1]    42%|████▏     | 39/93 [16:22<21:54, 24.35s/epoch, loss=1.15, accuracy=0.75, val_loss=2.23, val_accuracy=0.52, lr=0.1]  43%|████▎     | 40/93 [16:46<21:28, 24.31s/epoch, loss=1.14, accuracy=0.749, val_loss=2.17, val_accuracy=0.399, lr=0.1] 44%|████▍     | 41/93 [17:09<20:50, 24.05s/epoch, loss=1.14, accuracy=0.751, val_loss=2.35, val_accuracy=0.399, lr=0.1] 45%|████▌     | 42/93 [17:34<20:31, 24.14s/epoch, loss=1.14, accuracy=0.752, val_loss=1.59, val_accuracy=0.605, lr=0.0316] 46%|████▌     | 43/93 [17:57<19:52, 23.86s/epoch, loss=1.14, accuracy=0.75, val_loss=2.21, val_accuracy=0.42, lr=0.1]      47%|████▋     | 44/93 [18:21<19:37, 24.03s/epoch, loss=1.14, accuracy=0.75, val_loss=2.29, val_accuracy=0.46, lr=0.1] 48%|████▊     | 45/93 [18:45<19:04, 23.85s/epoch, loss=1.14, accuracy=0.749, val_loss=2.06, val_accuracy=0.505, lr=0.1] 49%|████▉     | 46/93 [19:08<18:27, 23.57s/epoch, loss=1.14, accuracy=0.75, val_loss=2.3, val_accuracy=0.482, lr=0.1]   51%|█████     | 47/93 [19:30<17:52, 23.31s/epoch, loss=1.13, accuracy=0.753, val_loss=2.85, val_accuracy=0.374, lr=0.0316] 52%|█████▏    | 48/93 [19:55<17:51, 23.81s/epoch, loss=1.14, accuracy=0.753, val_loss=1.91, val_accuracy=0.538, lr=0.1]    53%|█████▎    | 49/93 [20:20<17:31, 23.89s/epoch, loss=1.13, accuracy=0.753, val_loss=1.95, val_accuracy=0.502, lr=0.1] 54%|█████▍    | 50/93 [20:44<17:15, 24.08s/epoch, loss=1.14, accuracy=0.753, val_loss=2.74, val_accuracy=0.354, lr=0.1] 55%|█████▍    | 51/93 [21:08<16:49, 24.03s/epoch, loss=1.14, accuracy=0.751, val_loss=3.65, val_accuracy=0.36, lr=0.1]  56%|█████▌    | 52/93 [21:32<16:25, 24.04s/epoch, loss=1.13, accuracy=0.753, val_loss=1.67, val_accuracy=0.562, lr=0.0316] 57%|█████▋    | 53/93 [21:57<16:09, 24.24s/epoch, loss=1.13, accuracy=0.754, val_loss=3.11, val_accuracy=0.408, lr=0.1]    58%|█████▊    | 54/93 [22:21<15:45, 24.24s/epoch, loss=1.13, accuracy=0.753, val_loss=4.09, val_accuracy=0.208, lr=0.1] 59%|█████▉    | 55/93 [22:45<15:14, 24.06s/epoch, loss=1.13, accuracy=0.752, val_loss=3.47, val_accuracy=0.384, lr=0.1] 60%|██████    | 56/93 [23:09<14:56, 24.22s/epoch, loss=1.13, accuracy=0.754, val_loss=1.96, val_accuracy=0.484, lr=0.1] 61%|██████▏   | 57/93 [23:32<14:19, 23.89s/epoch, loss=1.13, accuracy=0.753, val_loss=4.22, val_accuracy=0.378, lr=0.0316] 62%|██████▏   | 58/93 [23:56<13:55, 23.87s/epoch, loss=1.13, accuracy=0.752, val_loss=2.18, val_accuracy=0.437, lr=0.1]    63%|██████▎   | 59/93 [24:20<13:36, 24.01s/epoch, loss=1.13, accuracy=0.753, val_loss=2.66, val_accuracy=0.295, lr=0.1] 65%|██████▍   | 60/93 [24:44<13:08, 23.89s/epoch, loss=1.13, accuracy=0.753, val_loss=2.67, val_accuracy=0.431, lr=0.1] 66%|██████▌   | 61/93 [25:07<12:36, 23.64s/epoch, loss=1.13, accuracy=0.751, val_loss=4.79, val_accuracy=0.217, lr=0.1] 67%|██████▋   | 62/93 [25:31<12:11, 23.59s/epoch, loss=1.14, accuracy=0.751, val_loss=2.22, val_accuracy=0.415, lr=0.0316] 68%|██████▊   | 63/93 [25:56<11:59, 24.00s/epoch, loss=1.13, accuracy=0.753, val_loss=1.59, val_accuracy=0.625, lr=0.1]    69%|██████▉   | 64/93 [26:20<11:42, 24.22s/epoch, loss=1.13, accuracy=0.752, val_loss=2.61, val_accuracy=0.488, lr=0.1] 70%|██████▉   | 65/93 [26:45<11:22, 24.37s/epoch, loss=1.13, accuracy=0.758, val_loss=4.78, val_accuracy=0.237, lr=0.1] 71%|███████   | 66/93 [27:10<11:02, 24.54s/epoch, loss=1.13, accuracy=0.755, val_loss=2.22, val_accuracy=0.448, lr=0.1] 72%|███████▏  | 67/93 [27:35<10:40, 24.64s/epoch, loss=1.13, accuracy=0.753, val_loss=1.97, val_accuracy=0.491, lr=0.0316] 73%|███████▎  | 68/93 [28:00<10:18, 24.73s/epoch, loss=1.13, accuracy=0.755, val_loss=3.14, val_accuracy=0.308, lr=0.1]    74%|███████▍  | 69/93 [28:24<09:52, 24.70s/epoch, loss=1.13, accuracy=0.757, val_loss=1.78, val_accuracy=0.521, lr=0.1] 75%|███████▌  | 70/93 [28:48<09:18, 24.29s/epoch, loss=1.13, accuracy=0.754, val_loss=2.23, val_accuracy=0.442, lr=0.1] 76%|███████▋  | 71/93 [29:12<08:51, 24.14s/epoch, loss=1.13, accuracy=0.755, val_loss=4.11, val_accuracy=0.3, lr=0.1]   77%|███████▋  | 72/93 [29:36<08:28, 24.23s/epoch, loss=1.13, accuracy=0.755, val_loss=2.11, val_accuracy=0.519, lr=0.0316] 78%|███████▊  | 73/93 [30:00<08:02, 24.15s/epoch, loss=1.13, accuracy=0.752, val_loss=1.75, val_accuracy=0.584, lr=0.1]    80%|███████▉  | 74/93 [30:24<07:36, 24.02s/epoch, loss=1.13, accuracy=0.755, val_loss=2.84, val_accuracy=0.293, lr=0.1] 81%|████████  | 75/93 [30:48<07:14, 24.15s/epoch, loss=1.12, accuracy=0.756, val_loss=2.32, val_accuracy=0.381, lr=0.1] 82%|████████▏ | 76/93 [31:13<06:53, 24.34s/epoch, loss=1.12, accuracy=0.756, val_loss=1.56, val_accuracy=0.601, lr=0.1] 83%|████████▎ | 77/93 [31:37<06:30, 24.39s/epoch, loss=1.12, accuracy=0.758, val_loss=2.52, val_accuracy=0.482, lr=0.1] 84%|████████▍ | 78/93 [32:02<06:05, 24.38s/epoch, loss=1.12, accuracy=0.756, val_loss=1.77, val_accuracy=0.532, lr=0.1] 85%|████████▍ | 79/93 [32:25<05:34, 23.93s/epoch, loss=1.13, accuracy=0.755, val_loss=2.24, val_accuracy=0.449, lr=0.1] 86%|████████▌ | 80/93 [32:48<05:07, 23.62s/epoch, loss=1.12, accuracy=0.754, val_loss=1.77, val_accuracy=0.568, lr=0.1] 87%|████████▋ | 81/93 [33:11<04:44, 23.71s/epoch, loss=1.13, accuracy=0.754, val_loss=4.75, val_accuracy=0.257, lr=0.0316] 88%|████████▊ | 82/93 [33:36<04:23, 23.99s/epoch, loss=0.946, accuracy=0.809, val_loss=0.89, val_accuracy=0.812, lr=0.01]  89%|████████▉ | 83/93 [34:00<04:00, 24.00s/epoch, loss=0.756, accuracy=0.844, val_loss=0.894, val_accuracy=0.779, lr=0.01] 90%|█████████ | 84/93 [34:23<03:33, 23.74s/epoch, loss=0.672, accuracy=0.85, val_loss=0.856, val_accuracy=0.776, lr=0.01]  91%|█████████▏| 85/93 [34:48<03:11, 23.93s/epoch, loss=0.622, accuracy=0.857, val_loss=0.816, val_accuracy=0.784, lr=0.01] 92%|█████████▏| 86/93 [35:12<02:48, 24.14s/epoch, loss=0.597, accuracy=0.858, val_loss=0.735, val_accuracy=0.813, lr=0.01] 94%|█████████▎| 87/93 [35:36<02:23, 23.94s/epoch, loss=0.585, accuracy=0.86, val_loss=0.829, val_accuracy=0.776, lr=0.01]  95%|█████████▍| 88/93 [36:00<02:00, 24.15s/epoch, loss=0.58, accuracy=0.86, val_loss=0.79, val_accuracy=0.785, lr=0.01]   96%|█████████▌| 89/93 [36:23<01:35, 23.76s/epoch, loss=0.576, accuracy=0.86, val_loss=0.737, val_accuracy=0.811, lr=0.01] 97%|█████████▋| 90/93 [36:48<01:12, 24.08s/epoch, loss=0.573, accuracy=0.863, val_loss=1.15, val_accuracy=0.697, lr=0.01] 98%|█████████▊| 91/93 [37:12<00:48, 24.12s/epoch, loss=0.57, accuracy=0.863, val_loss=0.81, val_accuracy=0.796, lr=0.00316] 99%|█████████▉| 92/93 [37:37<00:24, 24.32s/epoch, loss=0.566, accuracy=0.867, val_loss=0.849, val_accuracy=0.774, lr=0.01] 100%|██████████| 93/93 [38:00<00:00, 23.82s/epoch, loss=0.573, accuracy=0.866, val_loss=0.683, val_accuracy=0.832, lr=0.01]100%|██████████| 93/93 [38:00<00:00, 24.52s/epoch, loss=0.573, accuracy=0.866, val_loss=0.683, val_accuracy=0.832, lr=0.01]
Using real-time data augmentation.
Test loss: 0.6833729147911072
Test accuracy: 0.8320000171661377


* * * Run SGD for ID = 16_11. * * *


2024-02-15 19:59:44.351653: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 19:59:47.259556: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 19:59:47.260707: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-15 19:59:47.300028: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 19:59:47.300062: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 19:59:47.303180: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 19:59:47.303221: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 19:59:47.305564: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 19:59:47.306276: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 19:59:47.311568: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 19:59:47.313665: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 19:59:47.318476: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 19:59:47.319084: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 19:59:47.319337: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 19:59:48.579241: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-15 19:59:48.579871: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 19:59:48.580301: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 19:59:48.580336: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 19:59:48.580372: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 19:59:48.580391: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 19:59:48.580409: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 19:59:48.580426: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 19:59:48.580444: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 19:59:48.580462: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 19:59:48.580480: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 19:59:48.580902: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 19:59:48.580935: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 19:59:49.247561: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-15 19:59:49.247630: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-15 19:59:49.247641: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-15 19:59:49.248449: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': 1611, 'batch_size': 128, 'epochs': 93, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/93 [00:00<?, ?epoch/s]2024-02-15 19:59:50.047189: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-15 19:59:50.047868: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2200060000 Hz
2024-02-15 19:59:52.184421: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 19:59:52.482299: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 19:59:53.460677: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-15 19:59:53.506107: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/93 [01:06<1:41:56, 66.49s/epoch, loss=3.28, accuracy=0.291, val_loss=2.1, val_accuracy=0.34, lr=0.1]  2%|▏         | 2/93 [01:29<1:02:23, 41.14s/epoch, loss=1.66, accuracy=0.474, val_loss=1.9, val_accuracy=0.426, lr=0.1]  3%|▎         | 3/93 [01:54<50:27, 33.64s/epoch, loss=1.41, accuracy=0.596, val_loss=2.7, val_accuracy=0.229, lr=0.1]    4%|▍         | 4/93 [02:19<44:48, 30.21s/epoch, loss=1.3, accuracy=0.661, val_loss=2.95, val_accuracy=0.279, lr=0.1]  5%|▌         | 5/93 [02:44<41:21, 28.20s/epoch, loss=1.25, accuracy=0.693, val_loss=2.19, val_accuracy=0.387, lr=0.1]  6%|▋         | 6/93 [03:09<39:20, 27.13s/epoch, loss=1.23, accuracy=0.707, val_loss=2.19, val_accuracy=0.415, lr=0.1]  8%|▊         | 7/93 [03:34<38:01, 26.53s/epoch, loss=1.22, accuracy=0.714, val_loss=1.66, val_accuracy=0.565, lr=0.1]  9%|▊         | 8/93 [03:59<36:45, 25.95s/epoch, loss=1.2, accuracy=0.724, val_loss=3.15, val_accuracy=0.406, lr=0.1]  10%|▉         | 9/93 [04:23<35:43, 25.52s/epoch, loss=1.19, accuracy=0.726, val_loss=1.62, val_accuracy=0.578, lr=0.1] 11%|█         | 10/93 [04:48<35:02, 25.33s/epoch, loss=1.19, accuracy=0.731, val_loss=2.32, val_accuracy=0.47, lr=0.1] 12%|█▏        | 11/93 [05:13<34:31, 25.26s/epoch, loss=1.19, accuracy=0.732, val_loss=1.55, val_accuracy=0.604, lr=0.1] 13%|█▎        | 12/93 [05:37<33:29, 24.81s/epoch, loss=1.19, accuracy=0.731, val_loss=2.19, val_accuracy=0.456, lr=0.1] 14%|█▍        | 13/93 [06:00<32:24, 24.30s/epoch, loss=1.18, accuracy=0.739, val_loss=3.32, val_accuracy=0.273, lr=0.1] 15%|█▌        | 14/93 [06:25<32:04, 24.36s/epoch, loss=1.18, accuracy=0.74, val_loss=2.24, val_accuracy=0.476, lr=0.1]  16%|█▌        | 15/93 [06:50<31:55, 24.56s/epoch, loss=1.18, accuracy=0.74, val_loss=1.82, val_accuracy=0.495, lr=0.1] 17%|█▋        | 16/93 [07:14<31:14, 24.34s/epoch, loss=1.18, accuracy=0.74, val_loss=1.82, val_accuracy=0.534, lr=0.0316] 18%|█▊        | 17/93 [07:38<30:53, 24.39s/epoch, loss=1.18, accuracy=0.742, val_loss=1.99, val_accuracy=0.488, lr=0.1]   19%|█▉        | 18/93 [08:03<30:48, 24.65s/epoch, loss=1.16, accuracy=0.746, val_loss=4.74, val_accuracy=0.289, lr=0.1] 20%|██        | 19/93 [08:28<30:29, 24.72s/epoch, loss=1.17, accuracy=0.742, val_loss=1.55, val_accuracy=0.634, lr=0.1] 22%|██▏       | 20/93 [08:51<29:30, 24.26s/epoch, loss=1.18, accuracy=0.743, val_loss=1.91, val_accuracy=0.478, lr=0.1] 23%|██▎       | 21/93 [09:16<29:20, 24.45s/epoch, loss=1.17, accuracy=0.745, val_loss=2.04, val_accuracy=0.462, lr=0.0316] 24%|██▎       | 22/93 [09:40<28:43, 24.28s/epoch, loss=1.16, accuracy=0.749, val_loss=1.86, val_accuracy=0.476, lr=0.1]    25%|██▍       | 23/93 [10:05<28:35, 24.51s/epoch, loss=1.16, accuracy=0.747, val_loss=2.87, val_accuracy=0.404, lr=0.1] 26%|██▌       | 24/93 [10:29<28:02, 24.38s/epoch, loss=1.16, accuracy=0.748, val_loss=2.04, val_accuracy=0.42, lr=0.1]  27%|██▋       | 25/93 [10:54<27:48, 24.53s/epoch, loss=1.16, accuracy=0.747, val_loss=1.73, val_accuracy=0.551, lr=0.1] 28%|██▊       | 26/93 [11:19<27:30, 24.63s/epoch, loss=1.16, accuracy=0.75, val_loss=1.94, val_accuracy=0.539, lr=0.0316] 29%|██▉       | 27/93 [11:43<26:55, 24.48s/epoch, loss=1.15, accuracy=0.751, val_loss=2.37, val_accuracy=0.486, lr=0.1]   30%|███       | 28/93 [12:07<26:11, 24.18s/epoch, loss=1.15, accuracy=0.75, val_loss=1.71, val_accuracy=0.558, lr=0.1]  31%|███       | 29/93 [12:30<25:29, 23.90s/epoch, loss=1.16, accuracy=0.751, val_loss=2.14, val_accuracy=0.516, lr=0.1] 32%|███▏      | 30/93 [12:54<25:13, 24.02s/epoch, loss=1.15, accuracy=0.752, val_loss=3.29, val_accuracy=0.331, lr=0.1] 33%|███▎      | 31/93 [13:17<24:33, 23.76s/epoch, loss=1.15, accuracy=0.751, val_loss=2.91, val_accuracy=0.424, lr=0.0316] 34%|███▍      | 32/93 [13:41<24:04, 23.68s/epoch, loss=1.14, accuracy=0.752, val_loss=1.75, val_accuracy=0.594, lr=0.1]    35%|███▌      | 33/93 [14:06<24:05, 24.10s/epoch, loss=1.15, accuracy=0.751, val_loss=1.71, val_accuracy=0.58, lr=0.1]  37%|███▋      | 34/93 [14:30<23:41, 24.09s/epoch, loss=1.15, accuracy=0.751, val_loss=2.74, val_accuracy=0.348, lr=0.1] 38%|███▊      | 35/93 [14:54<23:16, 24.08s/epoch, loss=1.15, accuracy=0.751, val_loss=2.2, val_accuracy=0.46, lr=0.1]   39%|███▊      | 36/93 [15:19<23:06, 24.32s/epoch, loss=1.14, accuracy=0.752, val_loss=2.46, val_accuracy=0.393, lr=0.0316] 40%|███▉      | 37/93 [15:44<22:53, 24.52s/epoch, loss=1.14, accuracy=0.751, val_loss=1.72, val_accuracy=0.567, lr=0.1]    41%|████      | 38/93 [16:08<22:21, 24.40s/epoch, loss=1.14, accuracy=0.756, val_loss=2.07, val_accuracy=0.501, lr=0.1] 42%|████▏     | 39/93 [16:34<22:15, 24.73s/epoch, loss=1.14, accuracy=0.751, val_loss=3.12, val_accuracy=0.353, lr=0.1] 43%|████▎     | 40/93 [16:57<21:37, 24.48s/epoch, loss=1.14, accuracy=0.751, val_loss=2.31, val_accuracy=0.419, lr=0.1] 44%|████▍     | 41/93 [17:22<21:13, 24.48s/epoch, loss=1.14, accuracy=0.755, val_loss=1.73, val_accuracy=0.557, lr=0.0316] 45%|████▌     | 42/93 [17:45<20:31, 24.15s/epoch, loss=1.14, accuracy=0.753, val_loss=1.8, val_accuracy=0.537, lr=0.1]     46%|████▌     | 43/93 [18:09<20:06, 24.14s/epoch, loss=1.14, accuracy=0.755, val_loss=1.98, val_accuracy=0.523, lr=0.1] 47%|████▋     | 44/93 [18:33<19:31, 23.92s/epoch, loss=1.14, accuracy=0.752, val_loss=1.97, val_accuracy=0.471, lr=0.1] 48%|████▊     | 45/93 [18:58<19:22, 24.23s/epoch, loss=1.14, accuracy=0.752, val_loss=2.65, val_accuracy=0.354, lr=0.1] 49%|████▉     | 46/93 [19:23<19:07, 24.42s/epoch, loss=1.13, accuracy=0.755, val_loss=2.34, val_accuracy=0.465, lr=0.0316] 51%|█████     | 47/93 [19:48<18:50, 24.58s/epoch, loss=1.14, accuracy=0.753, val_loss=1.85, val_accuracy=0.573, lr=0.1]    52%|█████▏    | 48/93 [20:11<18:16, 24.37s/epoch, loss=1.13, accuracy=0.754, val_loss=1.75, val_accuracy=0.537, lr=0.1] 53%|█████▎    | 49/93 [20:36<17:58, 24.51s/epoch, loss=1.14, accuracy=0.752, val_loss=2.89, val_accuracy=0.273, lr=0.1] 54%|█████▍    | 50/93 [21:01<17:38, 24.62s/epoch, loss=1.14, accuracy=0.751, val_loss=1.57, val_accuracy=0.602, lr=0.1] 55%|█████▍    | 51/93 [21:25<17:02, 24.33s/epoch, loss=1.13, accuracy=0.754, val_loss=2.46, val_accuracy=0.398, lr=0.0316] 56%|█████▌    | 52/93 [21:48<16:27, 24.09s/epoch, loss=1.13, accuracy=0.752, val_loss=2.64, val_accuracy=0.383, lr=0.1]    57%|█████▋    | 53/93 [22:12<15:52, 23.82s/epoch, loss=1.14, accuracy=0.754, val_loss=1.97, val_accuracy=0.489, lr=0.1] 58%|█████▊    | 54/93 [22:35<15:28, 23.81s/epoch, loss=1.14, accuracy=0.753, val_loss=2.98, val_accuracy=0.358, lr=0.1] 59%|█████▉    | 55/93 [22:59<15:01, 23.73s/epoch, loss=1.13, accuracy=0.756, val_loss=2.1, val_accuracy=0.468, lr=0.1]  60%|██████    | 56/93 [23:24<14:51, 24.11s/epoch, loss=1.13, accuracy=0.754, val_loss=7.47, val_accuracy=0.178, lr=0.0316] 61%|██████▏   | 57/93 [23:49<14:39, 24.44s/epoch, loss=1.13, accuracy=0.757, val_loss=1.51, val_accuracy=0.63, lr=0.1]     62%|██████▏   | 58/93 [24:14<14:16, 24.46s/epoch, loss=1.12, accuracy=0.757, val_loss=1.97, val_accuracy=0.513, lr=0.1] 63%|██████▎   | 59/93 [24:38<13:56, 24.59s/epoch, loss=1.13, accuracy=0.754, val_loss=2.11, val_accuracy=0.485, lr=0.1] 65%|██████▍   | 60/93 [25:03<13:27, 24.47s/epoch, loss=1.13, accuracy=0.756, val_loss=2.34, val_accuracy=0.335, lr=0.1] 66%|██████▌   | 61/93 [25:27<12:57, 24.31s/epoch, loss=1.13, accuracy=0.756, val_loss=1.72, val_accuracy=0.559, lr=0.1] 67%|██████▋   | 62/93 [25:51<12:37, 24.44s/epoch, loss=1.12, accuracy=0.756, val_loss=3.09, val_accuracy=0.356, lr=0.0316] 68%|██████▊   | 63/93 [26:15<12:02, 24.09s/epoch, loss=1.13, accuracy=0.755, val_loss=2.07, val_accuracy=0.527, lr=0.1]    69%|██████▉   | 64/93 [26:38<11:34, 23.93s/epoch, loss=1.13, accuracy=0.752, val_loss=2.61, val_accuracy=0.377, lr=0.1] 70%|██████▉   | 65/93 [27:03<11:18, 24.23s/epoch, loss=1.13, accuracy=0.755, val_loss=1.81, val_accuracy=0.529, lr=0.1] 71%|███████   | 66/93 [27:26<10:45, 23.90s/epoch, loss=1.13, accuracy=0.754, val_loss=1.65, val_accuracy=0.582, lr=0.1] 72%|███████▏  | 67/93 [27:51<10:25, 24.06s/epoch, loss=1.13, accuracy=0.754, val_loss=2.52, val_accuracy=0.438, lr=0.0316] 73%|███████▎  | 68/93 [28:16<10:09, 24.39s/epoch, loss=1.13, accuracy=0.756, val_loss=1.8, val_accuracy=0.574, lr=0.1]     74%|███████▍  | 69/93 [28:40<09:41, 24.24s/epoch, loss=1.12, accuracy=0.756, val_loss=2.37, val_accuracy=0.37, lr=0.1] 75%|███████▌  | 70/93 [29:03<09:12, 24.03s/epoch, loss=1.13, accuracy=0.755, val_loss=1.85, val_accuracy=0.539, lr=0.1] 76%|███████▋  | 71/93 [29:28<08:53, 24.26s/epoch, loss=1.12, accuracy=0.757, val_loss=2.78, val_accuracy=0.377, lr=0.1] 77%|███████▋  | 72/93 [29:51<08:22, 23.93s/epoch, loss=1.12, accuracy=0.757, val_loss=1.96, val_accuracy=0.484, lr=0.0316] 78%|███████▊  | 73/93 [30:16<08:03, 24.17s/epoch, loss=1.12, accuracy=0.754, val_loss=1.72, val_accuracy=0.565, lr=0.1]    80%|███████▉  | 74/93 [30:41<07:42, 24.37s/epoch, loss=1.13, accuracy=0.754, val_loss=2.96, val_accuracy=0.407, lr=0.1] 81%|████████  | 75/93 [31:05<07:17, 24.31s/epoch, loss=1.12, accuracy=0.756, val_loss=2.11, val_accuracy=0.516, lr=0.1] 82%|████████▏ | 76/93 [31:30<06:57, 24.55s/epoch, loss=1.12, accuracy=0.758, val_loss=1.98, val_accuracy=0.465, lr=0.1] 83%|████████▎ | 77/93 [31:55<06:35, 24.71s/epoch, loss=1.13, accuracy=0.755, val_loss=2.04, val_accuracy=0.493, lr=0.0316] 84%|████████▍ | 78/93 [32:20<06:09, 24.63s/epoch, loss=1.12, accuracy=0.756, val_loss=1.98, val_accuracy=0.467, lr=0.1]    85%|████████▍ | 79/93 [32:43<05:37, 24.12s/epoch, loss=1.13, accuracy=0.753, val_loss=1.87, val_accuracy=0.494, lr=0.1] 86%|████████▌ | 80/93 [33:07<05:13, 24.10s/epoch, loss=1.12, accuracy=0.757, val_loss=2.62, val_accuracy=0.439, lr=0.1] 87%|████████▋ | 81/93 [33:31<04:49, 24.11s/epoch, loss=1.13, accuracy=0.755, val_loss=1.54, val_accuracy=0.622, lr=0.1] 88%|████████▊ | 82/93 [33:54<04:23, 23.98s/epoch, loss=0.92, accuracy=0.816, val_loss=0.952, val_accuracy=0.787, lr=0.01] 89%|████████▉ | 83/93 [34:17<03:57, 23.71s/epoch, loss=0.734, accuracy=0.849, val_loss=0.82, val_accuracy=0.807, lr=0.01] 90%|█████████ | 84/93 [34:42<03:35, 23.91s/epoch, loss=0.656, accuracy=0.857, val_loss=0.739, val_accuracy=0.817, lr=0.01] 91%|█████████▏| 85/93 [35:05<03:09, 23.63s/epoch, loss=0.61, accuracy=0.86, val_loss=0.887, val_accuracy=0.765, lr=0.01]   92%|█████████▏| 86/93 [35:30<02:48, 24.09s/epoch, loss=0.585, accuracy=0.862, val_loss=0.734, val_accuracy=0.803, lr=0.01] 94%|█████████▎| 87/93 [35:54<02:24, 24.05s/epoch, loss=0.574, accuracy=0.861, val_loss=0.769, val_accuracy=0.8, lr=0.01]   95%|█████████▍| 88/93 [36:19<02:01, 24.23s/epoch, loss=0.572, accuracy=0.862, val_loss=0.799, val_accuracy=0.795, lr=0.01] 96%|█████████▌| 89/93 [36:42<01:35, 23.86s/epoch, loss=0.564, accuracy=0.864, val_loss=0.847, val_accuracy=0.78, lr=0.01]  97%|█████████▋| 90/93 [37:06<01:12, 24.09s/epoch, loss=0.567, accuracy=0.865, val_loss=1.11, val_accuracy=0.692, lr=0.01] 98%|█████████▊| 91/93 [37:29<00:47, 23.76s/epoch, loss=0.565, accuracy=0.867, val_loss=0.812, val_accuracy=0.781, lr=0.00316] 99%|█████████▉| 92/93 [37:53<00:23, 23.83s/epoch, loss=0.559, accuracy=0.868, val_loss=0.817, val_accuracy=0.788, lr=0.01]   100%|██████████| 93/93 [38:18<00:00, 24.18s/epoch, loss=0.558, accuracy=0.871, val_loss=0.915, val_accuracy=0.748, lr=0.01]100%|██████████| 93/93 [38:18<00:00, 24.72s/epoch, loss=0.558, accuracy=0.871, val_loss=0.915, val_accuracy=0.748, lr=0.01]
Using real-time data augmentation.
Test loss: 0.9149165749549866
Test accuracy: 0.7476000189781189


* * * Run SGD for ID = 16_12. * * *


2024-02-15 20:38:11.229447: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 20:38:14.215246: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 20:38:14.216493: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-15 20:38:14.257534: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 20:38:14.257572: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 20:38:14.260573: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 20:38:14.260638: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 20:38:14.263169: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 20:38:14.263851: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 20:38:14.266292: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 20:38:14.267800: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 20:38:14.272358: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 20:38:14.272915: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 20:38:14.272999: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 20:38:15.546291: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-15 20:38:15.546947: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 20:38:15.547384: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 20:38:15.547414: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 20:38:15.547448: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 20:38:15.547466: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 20:38:15.547483: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 20:38:15.547499: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 20:38:15.547517: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 20:38:15.547533: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 20:38:15.547551: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 20:38:15.548032: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 20:38:15.548065: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 20:38:16.216742: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-15 20:38:16.216794: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-15 20:38:16.216804: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-15 20:38:16.217678: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': 1612, 'batch_size': 128, 'epochs': 93, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/93 [00:00<?, ?epoch/s]2024-02-15 20:38:17.016124: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-15 20:38:17.016653: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2200060000 Hz
2024-02-15 20:38:19.097647: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 20:38:19.344108: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 20:38:20.104197: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-15 20:38:20.160293: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/93 [00:59<1:31:06, 59.42s/epoch, loss=3.15, accuracy=0.289, val_loss=2.21, val_accuracy=0.297, lr=0.1]  2%|▏         | 2/93 [01:23<58:17, 38.44s/epoch, loss=1.55, accuracy=0.531, val_loss=2.11, val_accuracy=0.408, lr=0.1]    3%|▎         | 3/93 [01:45<46:57, 31.31s/epoch, loss=1.34, accuracy=0.634, val_loss=1.81, val_accuracy=0.468, lr=0.1]  4%|▍         | 4/93 [02:10<42:27, 28.62s/epoch, loss=1.27, accuracy=0.679, val_loss=2.53, val_accuracy=0.329, lr=0.1]  5%|▌         | 5/93 [02:35<39:57, 27.25s/epoch, loss=1.24, accuracy=0.695, val_loss=1.8, val_accuracy=0.507, lr=0.1]   6%|▋         | 6/93 [02:58<37:44, 26.03s/epoch, loss=1.22, accuracy=0.708, val_loss=3.62, val_accuracy=0.27, lr=0.1]  8%|▊         | 7/93 [03:23<36:49, 25.70s/epoch, loss=1.22, accuracy=0.714, val_loss=1.81, val_accuracy=0.507, lr=0.1]  9%|▊         | 8/93 [03:48<35:46, 25.25s/epoch, loss=1.21, accuracy=0.719, val_loss=1.58, val_accuracy=0.609, lr=0.1] 10%|▉         | 9/93 [04:12<34:51, 24.90s/epoch, loss=1.2, accuracy=0.724, val_loss=3.26, val_accuracy=0.293, lr=0.1]  11%|█         | 10/93 [04:37<34:21, 24.84s/epoch, loss=1.19, accuracy=0.727, val_loss=1.91, val_accuracy=0.489, lr=0.1] 12%|█▏        | 11/93 [05:01<33:49, 24.75s/epoch, loss=1.19, accuracy=0.732, val_loss=2.05, val_accuracy=0.407, lr=0.1] 13%|█▎        | 12/93 [05:26<33:35, 24.88s/epoch, loss=1.19, accuracy=0.732, val_loss=4.47, val_accuracy=0.184, lr=0.1] 14%|█▍        | 13/93 [05:51<32:54, 24.68s/epoch, loss=1.19, accuracy=0.733, val_loss=1.76, val_accuracy=0.576, lr=0.0316] 15%|█▌        | 14/93 [06:16<32:39, 24.80s/epoch, loss=1.18, accuracy=0.737, val_loss=1.72, val_accuracy=0.562, lr=0.1]    16%|█▌        | 15/93 [06:40<31:53, 24.54s/epoch, loss=1.18, accuracy=0.735, val_loss=3.04, val_accuracy=0.361, lr=0.1] 17%|█▋        | 16/93 [07:04<31:26, 24.50s/epoch, loss=1.17, accuracy=0.739, val_loss=1.83, val_accuracy=0.51, lr=0.1]  18%|█▊        | 17/93 [07:28<30:39, 24.21s/epoch, loss=1.18, accuracy=0.737, val_loss=1.99, val_accuracy=0.492, lr=0.1] 19%|█▉        | 18/93 [07:51<30:04, 24.06s/epoch, loss=1.17, accuracy=0.743, val_loss=1.87, val_accuracy=0.543, lr=0.0316] 20%|██        | 19/93 [08:15<29:24, 23.84s/epoch, loss=1.17, accuracy=0.739, val_loss=1.64, val_accuracy=0.592, lr=0.1]    22%|██▏       | 20/93 [08:40<29:31, 24.27s/epoch, loss=1.17, accuracy=0.745, val_loss=1.4, val_accuracy=0.668, lr=0.1]  23%|██▎       | 21/93 [09:05<29:18, 24.43s/epoch, loss=1.17, accuracy=0.742, val_loss=2.15, val_accuracy=0.484, lr=0.1] 24%|██▎       | 22/93 [09:29<29:00, 24.51s/epoch, loss=1.16, accuracy=0.744, val_loss=3.23, val_accuracy=0.317, lr=0.1] 25%|██▍       | 23/93 [09:53<28:22, 24.33s/epoch, loss=1.16, accuracy=0.745, val_loss=2.03, val_accuracy=0.477, lr=0.1] 26%|██▌       | 24/93 [10:16<27:36, 24.01s/epoch, loss=1.15, accuracy=0.747, val_loss=1.73, val_accuracy=0.531, lr=0.1] 27%|██▋       | 25/93 [10:40<27:09, 23.97s/epoch, loss=1.15, accuracy=0.747, val_loss=2.01, val_accuracy=0.444, lr=0.0316] 28%|██▊       | 26/93 [11:05<27:03, 24.23s/epoch, loss=1.15, accuracy=0.746, val_loss=1.52, val_accuracy=0.613, lr=0.1]    29%|██▉       | 27/93 [11:29<26:30, 24.11s/epoch, loss=1.15, accuracy=0.746, val_loss=1.77, val_accuracy=0.542, lr=0.1] 30%|███       | 28/93 [11:53<25:57, 23.96s/epoch, loss=1.15, accuracy=0.752, val_loss=1.85, val_accuracy=0.57, lr=0.1]  31%|███       | 29/93 [12:18<25:55, 24.30s/epoch, loss=1.14, accuracy=0.749, val_loss=2.08, val_accuracy=0.532, lr=0.1] 32%|███▏      | 30/93 [12:41<25:12, 24.01s/epoch, loss=1.14, accuracy=0.748, val_loss=2.86, val_accuracy=0.276, lr=0.0316] 33%|███▎      | 31/93 [13:05<24:43, 23.93s/epoch, loss=1.14, accuracy=0.749, val_loss=1.59, val_accuracy=0.608, lr=0.1]    34%|███▍      | 32/93 [13:30<24:38, 24.24s/epoch, loss=1.14, accuracy=0.748, val_loss=2.14, val_accuracy=0.475, lr=0.1] 35%|███▌      | 33/93 [13:55<24:29, 24.49s/epoch, loss=1.14, accuracy=0.749, val_loss=1.83, val_accuracy=0.544, lr=0.1] 37%|███▋      | 34/93 [14:18<23:47, 24.20s/epoch, loss=1.14, accuracy=0.75, val_loss=1.96, val_accuracy=0.498, lr=0.1]  38%|███▊      | 35/93 [14:42<23:10, 23.98s/epoch, loss=1.14, accuracy=0.751, val_loss=1.77, val_accuracy=0.558, lr=0.0316] 39%|███▊      | 36/93 [15:06<22:48, 24.00s/epoch, loss=1.14, accuracy=0.749, val_loss=2.43, val_accuracy=0.456, lr=0.1]    40%|███▉      | 37/93 [15:31<22:41, 24.31s/epoch, loss=1.13, accuracy=0.752, val_loss=1.6, val_accuracy=0.591, lr=0.1]  41%|████      | 38/93 [15:55<22:11, 24.22s/epoch, loss=1.14, accuracy=0.75, val_loss=2.35, val_accuracy=0.432, lr=0.1] 42%|████▏     | 39/93 [16:19<21:53, 24.32s/epoch, loss=1.14, accuracy=0.749, val_loss=2.08, val_accuracy=0.474, lr=0.1] 43%|████▎     | 40/93 [16:44<21:24, 24.25s/epoch, loss=1.13, accuracy=0.754, val_loss=1.7, val_accuracy=0.561, lr=0.0316] 44%|████▍     | 41/93 [17:08<21:06, 24.36s/epoch, loss=1.12, accuracy=0.752, val_loss=3.67, val_accuracy=0.36, lr=0.1]    45%|████▌     | 42/93 [17:33<20:56, 24.65s/epoch, loss=1.13, accuracy=0.753, val_loss=2.01, val_accuracy=0.51, lr=0.1] 46%|████▌     | 43/93 [17:58<20:35, 24.72s/epoch, loss=1.13, accuracy=0.752, val_loss=2.22, val_accuracy=0.541, lr=0.1] 47%|████▋     | 44/93 [18:24<20:17, 24.84s/epoch, loss=1.12, accuracy=0.756, val_loss=1.56, val_accuracy=0.622, lr=0.1] 48%|████▊     | 45/93 [18:49<19:54, 24.89s/epoch, loss=1.13, accuracy=0.755, val_loss=1.98, val_accuracy=0.534, lr=0.0316] 49%|████▉     | 46/93 [19:14<19:35, 25.01s/epoch, loss=1.12, accuracy=0.754, val_loss=3.88, val_accuracy=0.293, lr=0.1]    51%|█████     | 47/93 [19:39<19:08, 24.96s/epoch, loss=1.12, accuracy=0.755, val_loss=1.31, val_accuracy=0.685, lr=0.1] 52%|█████▏    | 48/93 [20:04<18:50, 25.13s/epoch, loss=1.12, accuracy=0.756, val_loss=3.03, val_accuracy=0.266, lr=0.1] 53%|█████▎    | 49/93 [20:29<18:24, 25.11s/epoch, loss=1.11, accuracy=0.756, val_loss=1.48, val_accuracy=0.626, lr=0.1] 54%|█████▍    | 50/93 [20:54<17:56, 25.05s/epoch, loss=1.12, accuracy=0.754, val_loss=1.63, val_accuracy=0.562, lr=0.1] 55%|█████▍    | 51/93 [21:19<17:29, 24.99s/epoch, loss=1.12, accuracy=0.755, val_loss=1.97, val_accuracy=0.454, lr=0.1] 56%|█████▌    | 52/93 [21:44<17:01, 24.92s/epoch, loss=1.12, accuracy=0.757, val_loss=2.38, val_accuracy=0.421, lr=0.0316] 57%|█████▋    | 53/93 [22:09<16:43, 25.09s/epoch, loss=1.12, accuracy=0.755, val_loss=1.73, val_accuracy=0.586, lr=0.1]    58%|█████▊    | 54/93 [22:34<16:13, 24.96s/epoch, loss=1.12, accuracy=0.757, val_loss=1.61, val_accuracy=0.578, lr=0.1] 59%|█████▉    | 55/93 [22:57<15:30, 24.49s/epoch, loss=1.12, accuracy=0.754, val_loss=1.92, val_accuracy=0.525, lr=0.1] 60%|██████    | 56/93 [23:22<15:12, 24.67s/epoch, loss=1.12, accuracy=0.754, val_loss=2, val_accuracy=0.486, lr=0.1]    61%|██████▏   | 57/93 [23:48<14:53, 24.81s/epoch, loss=1.12, accuracy=0.757, val_loss=1.72, val_accuracy=0.572, lr=0.0316] 62%|██████▏   | 58/93 [24:12<14:23, 24.68s/epoch, loss=1.13, accuracy=0.751, val_loss=1.41, val_accuracy=0.655, lr=0.1]    63%|██████▎   | 59/93 [24:36<13:55, 24.57s/epoch, loss=1.12, accuracy=0.754, val_loss=2.14, val_accuracy=0.493, lr=0.1] 65%|██████▍   | 60/93 [24:59<13:17, 24.15s/epoch, loss=1.12, accuracy=0.754, val_loss=3.03, val_accuracy=0.349, lr=0.1] 66%|██████▌   | 61/93 [25:24<12:59, 24.37s/epoch, loss=1.12, accuracy=0.756, val_loss=2.33, val_accuracy=0.356, lr=0.1] 67%|██████▋   | 62/93 [25:49<12:40, 24.54s/epoch, loss=1.12, accuracy=0.756, val_loss=2.4, val_accuracy=0.456, lr=0.0316] 68%|██████▊   | 63/93 [26:14<12:16, 24.57s/epoch, loss=1.12, accuracy=0.756, val_loss=2.11, val_accuracy=0.506, lr=0.1]   69%|██████▉   | 64/93 [26:38<11:50, 24.49s/epoch, loss=1.11, accuracy=0.757, val_loss=1.82, val_accuracy=0.545, lr=0.1] 70%|██████▉   | 65/93 [27:03<11:27, 24.56s/epoch, loss=1.11, accuracy=0.757, val_loss=1.44, val_accuracy=0.653, lr=0.1] 71%|███████   | 66/93 [27:27<10:58, 24.38s/epoch, loss=1.11, accuracy=0.758, val_loss=1.49, val_accuracy=0.615, lr=0.1] 72%|███████▏  | 67/93 [27:51<10:35, 24.43s/epoch, loss=1.12, accuracy=0.756, val_loss=1.61, val_accuracy=0.59, lr=0.0316] 73%|███████▎  | 68/93 [28:15<10:07, 24.29s/epoch, loss=1.11, accuracy=0.758, val_loss=7.56, val_accuracy=0.142, lr=0.1]   74%|███████▍  | 69/93 [28:39<09:41, 24.24s/epoch, loss=1.11, accuracy=0.759, val_loss=1.9, val_accuracy=0.528, lr=0.1]  75%|███████▌  | 70/93 [29:03<09:13, 24.04s/epoch, loss=1.12, accuracy=0.757, val_loss=3.93, val_accuracy=0.318, lr=0.1] 76%|███████▋  | 71/93 [29:28<08:54, 24.31s/epoch, loss=1.11, accuracy=0.758, val_loss=1.59, val_accuracy=0.63, lr=0.1]  77%|███████▋  | 72/93 [29:52<08:31, 24.34s/epoch, loss=1.11, accuracy=0.758, val_loss=2.38, val_accuracy=0.409, lr=0.0316] 78%|███████▊  | 73/93 [30:16<08:02, 24.13s/epoch, loss=1.11, accuracy=0.757, val_loss=2.03, val_accuracy=0.474, lr=0.1]    80%|███████▉  | 74/93 [30:41<07:41, 24.31s/epoch, loss=1.11, accuracy=0.758, val_loss=3.07, val_accuracy=0.423, lr=0.1] 81%|████████  | 75/93 [31:05<07:16, 24.26s/epoch, loss=1.12, accuracy=0.756, val_loss=1.52, val_accuracy=0.637, lr=0.1] 82%|████████▏ | 76/93 [31:29<06:51, 24.22s/epoch, loss=1.11, accuracy=0.759, val_loss=1.46, val_accuracy=0.645, lr=0.1] 83%|████████▎ | 77/93 [31:53<06:26, 24.14s/epoch, loss=1.11, accuracy=0.756, val_loss=1.5, val_accuracy=0.621, lr=0.0316] 84%|████████▍ | 78/93 [32:18<06:05, 24.35s/epoch, loss=1.11, accuracy=0.757, val_loss=1.64, val_accuracy=0.61, lr=0.1]    85%|████████▍ | 79/93 [32:41<05:36, 24.03s/epoch, loss=1.11, accuracy=0.757, val_loss=1.71, val_accuracy=0.532, lr=0.1] 86%|████████▌ | 80/93 [33:06<05:15, 24.29s/epoch, loss=1.11, accuracy=0.757, val_loss=2.92, val_accuracy=0.332, lr=0.1] 87%|████████▋ | 81/93 [33:31<04:52, 24.39s/epoch, loss=1.12, accuracy=0.756, val_loss=3.11, val_accuracy=0.365, lr=0.1] 88%|████████▊ | 82/93 [33:55<04:29, 24.48s/epoch, loss=0.909, accuracy=0.814, val_loss=0.848, val_accuracy=0.821, lr=0.01] 89%|████████▉ | 83/93 [34:19<04:03, 24.33s/epoch, loss=0.729, accuracy=0.846, val_loss=0.765, val_accuracy=0.826, lr=0.01] 90%|█████████ | 84/93 [34:43<03:37, 24.13s/epoch, loss=0.654, accuracy=0.855, val_loss=0.812, val_accuracy=0.797, lr=0.01] 91%|█████████▏| 85/93 [35:07<03:13, 24.23s/epoch, loss=0.607, accuracy=0.859, val_loss=0.803, val_accuracy=0.787, lr=0.01] 92%|█████████▏| 86/93 [35:32<02:50, 24.34s/epoch, loss=0.584, accuracy=0.86, val_loss=0.834, val_accuracy=0.769, lr=0.01]  94%|█████████▎| 87/93 [35:55<02:23, 23.95s/epoch, loss=0.575, accuracy=0.859, val_loss=0.813, val_accuracy=0.791, lr=0.01] 95%|█████████▍| 88/93 [36:19<01:59, 23.98s/epoch, loss=0.572, accuracy=0.86, val_loss=0.817, val_accuracy=0.782, lr=0.00316] 96%|█████████▌| 89/93 [36:44<01:36, 24.23s/epoch, loss=0.564, accuracy=0.862, val_loss=0.921, val_accuracy=0.751, lr=0.01]   97%|█████████▋| 90/93 [37:09<01:13, 24.42s/epoch, loss=0.566, accuracy=0.864, val_loss=1.08, val_accuracy=0.72, lr=0.01]   98%|█████████▊| 91/93 [37:32<00:48, 24.00s/epoch, loss=0.563, accuracy=0.866, val_loss=0.791, val_accuracy=0.785, lr=0.01] 99%|█████████▉| 92/93 [37:57<00:24, 24.22s/epoch, loss=0.562, accuracy=0.867, val_loss=0.684, val_accuracy=0.83, lr=0.01] 100%|██████████| 93/93 [38:22<00:00, 24.47s/epoch, loss=0.56, accuracy=0.868, val_loss=0.997, val_accuracy=0.736, lr=0.01]100%|██████████| 93/93 [38:22<00:00, 24.75s/epoch, loss=0.56, accuracy=0.868, val_loss=0.997, val_accuracy=0.736, lr=0.01]
Using real-time data augmentation.
Test loss: 0.996605396270752
Test accuracy: 0.736299991607666


* * * Run SGD for ID = 16_13. * * *


2024-02-15 21:16:41.757042: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 21:16:46.387917: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 21:16:46.389250: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-15 21:16:46.427593: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 21:16:46.427632: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 21:16:46.430577: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 21:16:46.430643: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 21:16:46.437654: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 21:16:46.439704: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 21:16:46.445318: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 21:16:46.447007: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 21:16:46.451820: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 21:16:46.452358: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 21:16:46.452436: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 21:16:47.820553: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-15 21:16:47.821651: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 21:16:47.822120: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 21:16:47.822160: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 21:16:47.822194: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 21:16:47.822213: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 21:16:47.822229: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 21:16:47.822246: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 21:16:47.822263: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 21:16:47.822279: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 21:16:47.822297: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 21:16:47.822756: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 21:16:47.822792: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 21:16:48.505459: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-15 21:16:48.505513: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-15 21:16:48.505523: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-15 21:16:48.506428: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': 1613, 'batch_size': 128, 'epochs': 93, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/93 [00:00<?, ?epoch/s]2024-02-15 21:16:49.308230: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-15 21:16:49.320718: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2200060000 Hz
2024-02-15 21:16:51.342268: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 21:16:51.575060: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 21:16:52.386086: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-15 21:16:52.488412: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/93 [00:59<1:31:25, 59.62s/epoch, loss=3.01, accuracy=0.358, val_loss=2.62, val_accuracy=0.175, lr=0.1]  2%|▏         | 2/93 [01:23<58:28, 38.55s/epoch, loss=1.49, accuracy=0.572, val_loss=1.64, val_accuracy=0.549, lr=0.1]    3%|▎         | 3/93 [01:47<48:13, 32.15s/epoch, loss=1.3, accuracy=0.66, val_loss=2.51, val_accuracy=0.384, lr=0.1]    4%|▍         | 4/93 [02:12<42:56, 28.95s/epoch, loss=1.25, accuracy=0.691, val_loss=1.45, val_accuracy=0.615, lr=0.1]  5%|▌         | 5/93 [02:36<40:15, 27.45s/epoch, loss=1.23, accuracy=0.706, val_loss=1.89, val_accuracy=0.492, lr=0.1]  6%|▋         | 6/93 [03:01<38:24, 26.48s/epoch, loss=1.22, accuracy=0.715, val_loss=1.93, val_accuracy=0.508, lr=0.1]  8%|▊         | 7/93 [03:25<36:59, 25.81s/epoch, loss=1.21, accuracy=0.721, val_loss=2.47, val_accuracy=0.389, lr=0.1]  9%|▊         | 8/93 [03:49<35:45, 25.24s/epoch, loss=1.19, accuracy=0.728, val_loss=1.38, val_accuracy=0.668, lr=0.1] 10%|▉         | 9/93 [04:13<34:30, 24.65s/epoch, loss=1.19, accuracy=0.732, val_loss=2.19, val_accuracy=0.488, lr=0.1] 11%|█         | 10/93 [04:38<34:11, 24.72s/epoch, loss=1.18, accuracy=0.735, val_loss=2.55, val_accuracy=0.416, lr=0.1] 12%|█▏        | 11/93 [05:02<33:47, 24.72s/epoch, loss=1.17, accuracy=0.738, val_loss=2.72, val_accuracy=0.433, lr=0.1] 13%|█▎        | 12/93 [05:27<33:12, 24.60s/epoch, loss=1.17, accuracy=0.736, val_loss=2.44, val_accuracy=0.372, lr=0.1] 14%|█▍        | 13/93 [05:51<32:49, 24.62s/epoch, loss=1.16, accuracy=0.742, val_loss=2.15, val_accuracy=0.526, lr=0.0316] 15%|█▌        | 14/93 [06:14<31:44, 24.11s/epoch, loss=1.17, accuracy=0.742, val_loss=1.75, val_accuracy=0.534, lr=0.1]    16%|█▌        | 15/93 [06:39<31:37, 24.33s/epoch, loss=1.15, accuracy=0.746, val_loss=2.05, val_accuracy=0.515, lr=0.1] 17%|█▋        | 16/93 [07:04<31:34, 24.60s/epoch, loss=1.15, accuracy=0.745, val_loss=3.16, val_accuracy=0.279, lr=0.1] 18%|█▊        | 17/93 [07:29<31:14, 24.66s/epoch, loss=1.15, accuracy=0.744, val_loss=3.37, val_accuracy=0.364, lr=0.1] 19%|█▉        | 18/93 [07:53<30:43, 24.58s/epoch, loss=1.14, accuracy=0.747, val_loss=1.44, val_accuracy=0.632, lr=0.0316] 20%|██        | 19/93 [08:17<30:06, 24.41s/epoch, loss=1.15, accuracy=0.747, val_loss=1.68, val_accuracy=0.538, lr=0.1]    22%|██▏       | 20/93 [08:41<29:26, 24.20s/epoch, loss=1.15, accuracy=0.746, val_loss=2.31, val_accuracy=0.342, lr=0.1] 23%|██▎       | 21/93 [09:06<29:11, 24.33s/epoch, loss=1.15, accuracy=0.749, val_loss=1.8, val_accuracy=0.526, lr=0.1]  24%|██▎       | 22/93 [09:30<28:49, 24.36s/epoch, loss=1.14, accuracy=0.75, val_loss=1.5, val_accuracy=0.639, lr=0.1]  25%|██▍       | 23/93 [09:53<27:56, 23.95s/epoch, loss=1.14, accuracy=0.75, val_loss=1.46, val_accuracy=0.642, lr=0.0316] 26%|██▌       | 24/93 [10:17<27:33, 23.96s/epoch, loss=1.13, accuracy=0.749, val_loss=1.89, val_accuracy=0.513, lr=0.1]   27%|██▋       | 25/93 [10:41<26:58, 23.80s/epoch, loss=1.13, accuracy=0.753, val_loss=1.67, val_accuracy=0.597, lr=0.1] 28%|██▊       | 26/93 [11:05<26:45, 23.97s/epoch, loss=1.13, accuracy=0.753, val_loss=1.65, val_accuracy=0.587, lr=0.1] 29%|██▉       | 27/93 [11:29<26:20, 23.94s/epoch, loss=1.13, accuracy=0.752, val_loss=2.54, val_accuracy=0.39, lr=0.1]  30%|███       | 28/93 [11:53<25:56, 23.95s/epoch, loss=1.13, accuracy=0.753, val_loss=2.45, val_accuracy=0.377, lr=0.0316] 31%|███       | 29/93 [12:18<25:48, 24.20s/epoch, loss=1.13, accuracy=0.751, val_loss=2.35, val_accuracy=0.394, lr=0.1]    32%|███▏      | 30/93 [12:42<25:33, 24.34s/epoch, loss=1.12, accuracy=0.752, val_loss=2.56, val_accuracy=0.425, lr=0.1] 33%|███▎      | 31/93 [13:05<24:44, 23.94s/epoch, loss=1.12, accuracy=0.752, val_loss=1.45, val_accuracy=0.642, lr=0.1] 34%|███▍      | 32/93 [13:29<24:22, 23.98s/epoch, loss=1.11, accuracy=0.755, val_loss=2.2, val_accuracy=0.493, lr=0.1]  35%|███▌      | 33/93 [13:53<23:54, 23.91s/epoch, loss=1.13, accuracy=0.752, val_loss=2.33, val_accuracy=0.464, lr=0.0316] 37%|███▋      | 34/93 [14:16<23:17, 23.68s/epoch, loss=1.13, accuracy=0.753, val_loss=2.64, val_accuracy=0.421, lr=0.1]    38%|███▊      | 35/93 [14:41<23:03, 23.85s/epoch, loss=1.12, accuracy=0.755, val_loss=1.58, val_accuracy=0.609, lr=0.1] 39%|███▊      | 36/93 [15:05<22:56, 24.14s/epoch, loss=1.13, accuracy=0.754, val_loss=2.82, val_accuracy=0.479, lr=0.1] 40%|███▉      | 37/93 [15:30<22:44, 24.36s/epoch, loss=1.12, accuracy=0.756, val_loss=1.62, val_accuracy=0.582, lr=0.1] 41%|████      | 38/93 [15:55<22:21, 24.39s/epoch, loss=1.12, accuracy=0.755, val_loss=2.12, val_accuracy=0.495, lr=0.0316] 42%|████▏     | 39/93 [16:19<21:58, 24.42s/epoch, loss=1.12, accuracy=0.755, val_loss=1.93, val_accuracy=0.522, lr=0.1]    43%|████▎     | 40/93 [16:44<21:41, 24.56s/epoch, loss=1.12, accuracy=0.756, val_loss=2.43, val_accuracy=0.391, lr=0.1] 44%|████▍     | 41/93 [17:07<20:54, 24.12s/epoch, loss=1.12, accuracy=0.755, val_loss=2.25, val_accuracy=0.46, lr=0.1]  45%|████▌     | 42/93 [17:32<20:38, 24.28s/epoch, loss=1.11, accuracy=0.755, val_loss=2.4, val_accuracy=0.423, lr=0.1] 46%|████▌     | 43/93 [17:56<20:05, 24.12s/epoch, loss=1.12, accuracy=0.755, val_loss=1.38, val_accuracy=0.663, lr=0.0316] 47%|████▋     | 44/93 [18:20<19:53, 24.36s/epoch, loss=1.11, accuracy=0.757, val_loss=2.88, val_accuracy=0.362, lr=0.1]    48%|████▊     | 45/93 [18:44<19:21, 24.19s/epoch, loss=1.11, accuracy=0.756, val_loss=3.5, val_accuracy=0.404, lr=0.1]  49%|████▉     | 46/93 [19:09<19:00, 24.27s/epoch, loss=1.12, accuracy=0.757, val_loss=1.65, val_accuracy=0.604, lr=0.1] 51%|█████     | 47/93 [19:34<18:46, 24.49s/epoch, loss=1.12, accuracy=0.757, val_loss=2.17, val_accuracy=0.435, lr=0.1] 52%|█████▏    | 48/93 [19:58<18:13, 24.31s/epoch, loss=1.11, accuracy=0.758, val_loss=3.06, val_accuracy=0.434, lr=0.0316] 53%|█████▎    | 49/93 [20:21<17:42, 24.16s/epoch, loss=1.11, accuracy=0.758, val_loss=1.92, val_accuracy=0.549, lr=0.1]    54%|█████▍    | 50/93 [20:45<17:16, 24.11s/epoch, loss=1.11, accuracy=0.756, val_loss=2.54, val_accuracy=0.485, lr=0.1] 55%|█████▍    | 51/93 [21:10<16:57, 24.21s/epoch, loss=1.12, accuracy=0.757, val_loss=3.68, val_accuracy=0.226, lr=0.1] 56%|█████▌    | 52/93 [21:35<16:38, 24.34s/epoch, loss=1.11, accuracy=0.757, val_loss=3.55, val_accuracy=0.288, lr=0.1] 57%|█████▋    | 53/93 [21:59<16:18, 24.46s/epoch, loss=1.11, accuracy=0.757, val_loss=6.3, val_accuracy=0.21, lr=0.0316] 58%|█████▊    | 54/93 [22:23<15:50, 24.37s/epoch, loss=1.11, accuracy=0.758, val_loss=3.07, val_accuracy=0.328, lr=0.1]  59%|█████▉    | 55/93 [22:47<15:19, 24.19s/epoch, loss=1.11, accuracy=0.757, val_loss=3.73, val_accuracy=0.295, lr=0.1] 60%|██████    | 56/93 [23:12<15:01, 24.36s/epoch, loss=1.11, accuracy=0.757, val_loss=2.5, val_accuracy=0.379, lr=0.1]  61%|██████▏   | 57/93 [23:36<14:28, 24.13s/epoch, loss=1.1, accuracy=0.758, val_loss=1.69, val_accuracy=0.569, lr=0.1] 62%|██████▏   | 58/93 [24:00<14:11, 24.32s/epoch, loss=1.1, accuracy=0.758, val_loss=1.77, val_accuracy=0.575, lr=0.0316] 63%|██████▎   | 59/93 [24:24<13:38, 24.09s/epoch, loss=1.11, accuracy=0.758, val_loss=2.68, val_accuracy=0.468, lr=0.1]   65%|██████▍   | 60/93 [24:48<13:18, 24.20s/epoch, loss=1.11, accuracy=0.756, val_loss=2, val_accuracy=0.528, lr=0.1]    66%|██████▌   | 61/93 [25:12<12:52, 24.13s/epoch, loss=1.1, accuracy=0.757, val_loss=1.25, val_accuracy=0.716, lr=0.1] 67%|██████▋   | 62/93 [25:35<12:14, 23.71s/epoch, loss=1.1, accuracy=0.759, val_loss=1.6, val_accuracy=0.614, lr=0.1]  68%|██████▊   | 63/93 [25:58<11:41, 23.39s/epoch, loss=1.1, accuracy=0.759, val_loss=2.27, val_accuracy=0.51, lr=0.1] 69%|██████▉   | 64/93 [26:22<11:29, 23.76s/epoch, loss=1.1, accuracy=0.759, val_loss=1.69, val_accuracy=0.569, lr=0.1] 70%|██████▉   | 65/93 [26:47<11:09, 23.91s/epoch, loss=1.1, accuracy=0.761, val_loss=1.69, val_accuracy=0.567, lr=0.1] 71%|███████   | 66/93 [27:10<10:44, 23.86s/epoch, loss=1.1, accuracy=0.76, val_loss=3.22, val_accuracy=0.249, lr=0.0316] 72%|███████▏  | 67/93 [27:34<10:20, 23.86s/epoch, loss=1.11, accuracy=0.76, val_loss=2.33, val_accuracy=0.471, lr=0.1]   73%|███████▎  | 68/93 [27:59<10:00, 24.03s/epoch, loss=1.1, accuracy=0.76, val_loss=2.68, val_accuracy=0.457, lr=0.1]  74%|███████▍  | 69/93 [28:22<09:32, 23.85s/epoch, loss=1.11, accuracy=0.759, val_loss=3.49, val_accuracy=0.292, lr=0.1] 75%|███████▌  | 70/93 [28:45<09:01, 23.54s/epoch, loss=1.1, accuracy=0.76, val_loss=2.05, val_accuracy=0.477, lr=0.1]   76%|███████▋  | 71/93 [29:09<08:44, 23.82s/epoch, loss=1.1, accuracy=0.758, val_loss=2.02, val_accuracy=0.47, lr=0.0316] 77%|███████▋  | 72/93 [29:32<08:14, 23.53s/epoch, loss=1.1, accuracy=0.76, val_loss=1.74, val_accuracy=0.56, lr=0.1]     78%|███████▊  | 73/93 [29:55<07:45, 23.29s/epoch, loss=1.1, accuracy=0.76, val_loss=4.82, val_accuracy=0.294, lr=0.1] 80%|███████▉  | 74/93 [30:19<07:26, 23.50s/epoch, loss=1.11, accuracy=0.759, val_loss=1.71, val_accuracy=0.556, lr=0.1] 81%|████████  | 75/93 [30:43<07:09, 23.84s/epoch, loss=1.1, accuracy=0.758, val_loss=2.55, val_accuracy=0.392, lr=0.1]  82%|████████▏ | 76/93 [31:08<06:47, 23.99s/epoch, loss=1.1, accuracy=0.756, val_loss=1.82, val_accuracy=0.529, lr=0.0316] 83%|████████▎ | 77/93 [31:31<06:19, 23.70s/epoch, loss=1.11, accuracy=0.759, val_loss=3.67, val_accuracy=0.245, lr=0.1]   84%|████████▍ | 78/93 [31:55<05:59, 23.94s/epoch, loss=1.1, accuracy=0.758, val_loss=3.49, val_accuracy=0.269, lr=0.1]  85%|████████▍ | 79/93 [32:19<05:33, 23.84s/epoch, loss=1.11, accuracy=0.757, val_loss=1.68, val_accuracy=0.599, lr=0.1] 86%|████████▌ | 80/93 [32:43<05:09, 23.81s/epoch, loss=1.1, accuracy=0.758, val_loss=7.11, val_accuracy=0.184, lr=0.1]  87%|████████▋ | 81/93 [33:07<04:47, 23.94s/epoch, loss=1.1, accuracy=0.759, val_loss=3.04, val_accuracy=0.391, lr=0.0316] 88%|████████▊ | 82/93 [33:30<04:21, 23.81s/epoch, loss=0.882, accuracy=0.82, val_loss=0.971, val_accuracy=0.769, lr=0.01] 89%|████████▉ | 83/93 [33:55<04:00, 24.01s/epoch, loss=0.72, accuracy=0.847, val_loss=0.769, val_accuracy=0.824, lr=0.01] 90%|█████████ | 84/93 [34:19<03:36, 24.02s/epoch, loss=0.64, accuracy=0.858, val_loss=0.823, val_accuracy=0.786, lr=0.01] 91%|█████████▏| 85/93 [34:42<03:10, 23.77s/epoch, loss=0.598, accuracy=0.861, val_loss=0.81, val_accuracy=0.785, lr=0.01] 92%|█████████▏| 86/93 [35:05<02:44, 23.43s/epoch, loss=0.578, accuracy=0.86, val_loss=0.859, val_accuracy=0.769, lr=0.01] 94%|█████████▎| 87/93 [35:29<02:22, 23.74s/epoch, loss=0.573, accuracy=0.859, val_loss=0.848, val_accuracy=0.754, lr=0.01] 95%|█████████▍| 88/93 [35:54<01:59, 23.96s/epoch, loss=0.564, accuracy=0.862, val_loss=0.859, val_accuracy=0.764, lr=0.00316] 96%|█████████▌| 89/93 [36:17<01:35, 23.84s/epoch, loss=0.564, accuracy=0.864, val_loss=0.715, val_accuracy=0.809, lr=0.01]    97%|█████████▋| 90/93 [36:40<01:10, 23.48s/epoch, loss=0.557, accuracy=0.867, val_loss=0.924, val_accuracy=0.751, lr=0.01] 98%|█████████▊| 91/93 [37:02<00:46, 23.20s/epoch, loss=0.558, accuracy=0.867, val_loss=1.07, val_accuracy=0.724, lr=0.01]  99%|█████████▉| 92/93 [37:27<00:23, 23.60s/epoch, loss=0.56, accuracy=0.868, val_loss=0.754, val_accuracy=0.804, lr=0.01]100%|██████████| 93/93 [37:50<00:00, 23.45s/epoch, loss=0.557, accuracy=0.869, val_loss=0.808, val_accuracy=0.794, lr=0.01]100%|██████████| 93/93 [37:50<00:00, 24.42s/epoch, loss=0.557, accuracy=0.869, val_loss=0.808, val_accuracy=0.794, lr=0.01]
Using real-time data augmentation.
Test loss: 0.807765543460846
Test accuracy: 0.7940000295639038


* * * Run SGD for ID = 16_14. * * *


2024-02-15 21:54:42.517531: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 21:54:45.513190: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 21:54:45.514437: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-15 21:54:45.553536: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 21:54:45.553571: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 21:54:45.556272: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 21:54:45.556316: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 21:54:45.558446: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 21:54:45.559121: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 21:54:45.561530: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 21:54:45.563092: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 21:54:45.567669: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 21:54:45.568196: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 21:54:45.568276: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 21:54:46.867780: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-15 21:54:46.868357: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 21:54:46.868804: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-02-15 21:54:46.868837: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 21:54:46.868889: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 21:54:46.868908: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 21:54:46.868925: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 21:54:46.868942: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 21:54:46.868959: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 21:54:46.868976: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 21:54:46.868993: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 21:54:46.869425: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 21:54:46.869469: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 21:54:47.552619: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-15 21:54:47.552678: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-15 21:54:47.552688: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-15 21:54:47.553964: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': 1614, 'batch_size': 128, 'epochs': 93, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/93 [00:00<?, ?epoch/s]2024-02-15 21:54:48.363645: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-15 21:54:48.375715: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2200060000 Hz
2024-02-15 21:54:50.460044: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 21:54:50.684637: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 21:54:51.612095: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-15 21:54:51.659375: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/93 [00:56<1:26:56, 56.70s/epoch, loss=3.34, accuracy=0.29, val_loss=2.64, val_accuracy=0.206, lr=0.1]  2%|▏         | 2/93 [01:21<57:53, 38.17s/epoch, loss=1.69, accuracy=0.462, val_loss=2.24, val_accuracy=0.314, lr=0.1]   3%|▎         | 3/93 [01:46<48:01, 32.01s/epoch, loss=1.45, accuracy=0.58, val_loss=1.52, val_accuracy=0.592, lr=0.1]   4%|▍         | 4/93 [02:11<43:28, 29.31s/epoch, loss=1.32, accuracy=0.664, val_loss=4.24, val_accuracy=0.145, lr=0.1]  5%|▌         | 5/93 [02:36<40:21, 27.51s/epoch, loss=1.28, accuracy=0.691, val_loss=1.88, val_accuracy=0.539, lr=0.1]  6%|▋         | 6/93 [03:01<38:39, 26.67s/epoch, loss=1.25, accuracy=0.706, val_loss=1.57, val_accuracy=0.597, lr=0.1]  8%|▊         | 7/93 [03:24<36:42, 25.61s/epoch, loss=1.24, accuracy=0.714, val_loss=1.53, val_accuracy=0.617, lr=0.1]  9%|▊         | 8/93 [03:49<35:55, 25.36s/epoch, loss=1.23, accuracy=0.717, val_loss=2.17, val_accuracy=0.458, lr=0.0316] 10%|▉         | 9/93 [04:13<35:10, 25.12s/epoch, loss=1.23, accuracy=0.722, val_loss=1.66, val_accuracy=0.574, lr=0.1]    11%|█         | 10/93 [04:39<34:51, 25.19s/epoch, loss=1.22, accuracy=0.729, val_loss=2.17, val_accuracy=0.437, lr=0.1] 12%|█▏        | 11/93 [05:04<34:32, 25.28s/epoch, loss=1.22, accuracy=0.728, val_loss=2.56, val_accuracy=0.371, lr=0.1] 13%|█▎        | 12/93 [05:29<34:04, 25.24s/epoch, loss=1.21, accuracy=0.731, val_loss=2.12, val_accuracy=0.463, lr=0.1] 14%|█▍        | 13/93 [05:55<33:46, 25.33s/epoch, loss=1.21, accuracy=0.734, val_loss=2.31, val_accuracy=0.461, lr=0.0316] 15%|█▌        | 14/93 [06:20<33:22, 25.34s/epoch, loss=1.21, accuracy=0.733, val_loss=3.99, val_accuracy=0.331, lr=0.1]    16%|█▌        | 15/93 [06:45<32:42, 25.16s/epoch, loss=1.2, accuracy=0.735, val_loss=1.65, val_accuracy=0.552, lr=0.1]  17%|█▋        | 16/93 [07:09<31:49, 24.80s/epoch, loss=1.2, accuracy=0.736, val_loss=1.54, val_accuracy=0.619, lr=0.1] 18%|█▊        | 17/93 [07:34<31:33, 24.92s/epoch, loss=1.19, accuracy=0.739, val_loss=2.1, val_accuracy=0.53, lr=0.1]  19%|█▉        | 18/93 [07:59<30:58, 24.78s/epoch, loss=1.18, accuracy=0.74, val_loss=3.01, val_accuracy=0.371, lr=0.0316] 20%|██        | 19/93 [08:22<30:07, 24.43s/epoch, loss=1.18, accuracy=0.741, val_loss=1.79, val_accuracy=0.601, lr=0.1]   22%|██▏       | 20/93 [08:48<30:05, 24.74s/epoch, loss=1.18, accuracy=0.744, val_loss=3.9, val_accuracy=0.273, lr=0.1]  23%|██▎       | 21/93 [09:12<29:22, 24.48s/epoch, loss=1.18, accuracy=0.743, val_loss=1.72, val_accuracy=0.554, lr=0.1] 24%|██▎       | 22/93 [09:36<28:53, 24.41s/epoch, loss=1.19, accuracy=0.742, val_loss=3.07, val_accuracy=0.419, lr=0.1] 25%|██▍       | 23/93 [10:00<28:32, 24.46s/epoch, loss=1.19, accuracy=0.743, val_loss=1.51, val_accuracy=0.627, lr=0.1] 26%|██▌       | 24/93 [10:25<28:00, 24.35s/epoch, loss=1.18, accuracy=0.745, val_loss=1.96, val_accuracy=0.507, lr=0.1] 27%|██▋       | 25/93 [10:50<28:04, 24.77s/epoch, loss=1.18, accuracy=0.744, val_loss=1.49, val_accuracy=0.648, lr=0.1] 28%|██▊       | 26/93 [11:15<27:45, 24.86s/epoch, loss=1.17, accuracy=0.743, val_loss=1.49, val_accuracy=0.631, lr=0.1] 29%|██▉       | 27/93 [11:41<27:38, 25.13s/epoch, loss=1.18, accuracy=0.746, val_loss=1.85, val_accuracy=0.53, lr=0.1]  30%|███       | 28/93 [12:06<27:17, 25.18s/epoch, loss=1.17, accuracy=0.747, val_loss=2.18, val_accuracy=0.426, lr=0.1] 31%|███       | 29/93 [12:32<27:05, 25.40s/epoch, loss=1.17, accuracy=0.747, val_loss=1.97, val_accuracy=0.491, lr=0.1] 32%|███▏      | 30/93 [12:57<26:33, 25.30s/epoch, loss=1.17, accuracy=0.747, val_loss=2.65, val_accuracy=0.315, lr=0.1] 33%|███▎      | 31/93 [13:22<25:59, 25.16s/epoch, loss=1.17, accuracy=0.747, val_loss=1.88, val_accuracy=0.548, lr=0.0316] 34%|███▍      | 32/93 [13:47<25:30, 25.09s/epoch, loss=1.16, accuracy=0.748, val_loss=1.57, val_accuracy=0.612, lr=0.1]    35%|███▌      | 33/93 [14:12<25:03, 25.06s/epoch, loss=1.16, accuracy=0.751, val_loss=2, val_accuracy=0.531, lr=0.1]    37%|███▋      | 34/93 [14:37<24:42, 25.13s/epoch, loss=1.16, accuracy=0.751, val_loss=2.57, val_accuracy=0.375, lr=0.1] 38%|███▊      | 35/93 [15:02<24:07, 24.96s/epoch, loss=1.16, accuracy=0.749, val_loss=3.1, val_accuracy=0.396, lr=0.1]  39%|███▊      | 36/93 [15:27<23:41, 24.95s/epoch, loss=1.15, accuracy=0.753, val_loss=1.93, val_accuracy=0.507, lr=0.0316] 40%|███▉      | 37/93 [15:52<23:26, 25.12s/epoch, loss=1.15, accuracy=0.753, val_loss=2.71, val_accuracy=0.373, lr=0.1]    41%|████      | 38/93 [16:18<23:00, 25.10s/epoch, loss=1.15, accuracy=0.753, val_loss=1.63, val_accuracy=0.604, lr=0.1] 42%|████▏     | 39/93 [16:42<22:27, 24.95s/epoch, loss=1.15, accuracy=0.752, val_loss=1.73, val_accuracy=0.535, lr=0.1] 43%|████▎     | 40/93 [17:07<22:03, 24.97s/epoch, loss=1.15, accuracy=0.752, val_loss=1.55, val_accuracy=0.62, lr=0.1]  44%|████▍     | 41/93 [17:32<21:39, 24.99s/epoch, loss=1.15, accuracy=0.754, val_loss=1.65, val_accuracy=0.608, lr=0.0316] 45%|████▌     | 42/93 [17:57<21:07, 24.84s/epoch, loss=1.14, accuracy=0.752, val_loss=5.31, val_accuracy=0.264, lr=0.1]    46%|████▌     | 43/93 [18:21<20:26, 24.53s/epoch, loss=1.15, accuracy=0.754, val_loss=2.34, val_accuracy=0.44, lr=0.1]  47%|████▋     | 44/93 [18:46<20:11, 24.72s/epoch, loss=1.14, accuracy=0.754, val_loss=2.71, val_accuracy=0.337, lr=0.1] 48%|████▊     | 45/93 [19:09<19:28, 24.34s/epoch, loss=1.14, accuracy=0.756, val_loss=1.62, val_accuracy=0.58, lr=0.1]  49%|████▉     | 46/93 [19:32<18:49, 24.04s/epoch, loss=1.15, accuracy=0.753, val_loss=1.95, val_accuracy=0.507, lr=0.0316] 51%|█████     | 47/93 [19:56<18:14, 23.78s/epoch, loss=1.14, accuracy=0.757, val_loss=1.66, val_accuracy=0.582, lr=0.1]    52%|█████▏    | 48/93 [20:21<18:07, 24.16s/epoch, loss=1.14, accuracy=0.754, val_loss=2.11, val_accuracy=0.435, lr=0.1] 53%|█████▎    | 49/93 [20:46<17:53, 24.40s/epoch, loss=1.14, accuracy=0.752, val_loss=2.55, val_accuracy=0.32, lr=0.1]  54%|█████▍    | 50/93 [21:10<17:33, 24.49s/epoch, loss=1.13, accuracy=0.757, val_loss=1.56, val_accuracy=0.638, lr=0.1] 55%|█████▍    | 51/93 [21:35<17:11, 24.57s/epoch, loss=1.14, accuracy=0.753, val_loss=1.7, val_accuracy=0.577, lr=0.0316] 56%|█████▌    | 52/93 [21:59<16:33, 24.23s/epoch, loss=1.14, accuracy=0.754, val_loss=2.39, val_accuracy=0.446, lr=0.1]   57%|█████▋    | 53/93 [22:24<16:20, 24.51s/epoch, loss=1.14, accuracy=0.753, val_loss=1.82, val_accuracy=0.564, lr=0.1] 58%|█████▊    | 54/93 [22:49<16:03, 24.71s/epoch, loss=1.14, accuracy=0.755, val_loss=1.71, val_accuracy=0.556, lr=0.1] 59%|█████▉    | 55/93 [23:13<15:37, 24.68s/epoch, loss=1.13, accuracy=0.761, val_loss=1.43, val_accuracy=0.654, lr=0.1] 60%|██████    | 56/93 [23:39<15:20, 24.88s/epoch, loss=1.13, accuracy=0.756, val_loss=2.6, val_accuracy=0.459, lr=0.1]  61%|██████▏   | 57/93 [24:04<14:58, 24.96s/epoch, loss=1.13, accuracy=0.754, val_loss=1.55, val_accuracy=0.612, lr=0.1] 62%|██████▏   | 58/93 [24:27<14:16, 24.46s/epoch, loss=1.13, accuracy=0.755, val_loss=1.92, val_accuracy=0.521, lr=0.1] 63%|██████▎   | 59/93 [24:52<13:56, 24.60s/epoch, loss=1.13, accuracy=0.755, val_loss=6.08, val_accuracy=0.176, lr=0.1] 65%|██████▍   | 60/93 [25:17<13:33, 24.66s/epoch, loss=1.13, accuracy=0.756, val_loss=2.77, val_accuracy=0.401, lr=0.0316] 66%|██████▌   | 61/93 [25:42<13:12, 24.76s/epoch, loss=1.13, accuracy=0.756, val_loss=1.68, val_accuracy=0.573, lr=0.1]    67%|██████▋   | 62/93 [26:06<12:40, 24.52s/epoch, loss=1.13, accuracy=0.757, val_loss=1.72, val_accuracy=0.56, lr=0.1]  68%|██████▊   | 63/93 [26:31<12:22, 24.73s/epoch, loss=1.13, accuracy=0.756, val_loss=1.87, val_accuracy=0.591, lr=0.1] 69%|██████▉   | 64/93 [26:56<11:59, 24.82s/epoch, loss=1.13, accuracy=0.755, val_loss=1.49, val_accuracy=0.632, lr=0.1] 70%|██████▉   | 65/93 [27:21<11:34, 24.80s/epoch, loss=1.13, accuracy=0.757, val_loss=1.7, val_accuracy=0.584, lr=0.0316] 71%|███████   | 66/93 [27:46<11:11, 24.88s/epoch, loss=1.12, accuracy=0.759, val_loss=3.07, val_accuracy=0.342, lr=0.1]   72%|███████▏  | 67/93 [28:10<10:42, 24.71s/epoch, loss=1.13, accuracy=0.759, val_loss=1.58, val_accuracy=0.588, lr=0.1] 73%|███████▎  | 68/93 [28:34<10:08, 24.33s/epoch, loss=1.13, accuracy=0.755, val_loss=1.53, val_accuracy=0.599, lr=0.1] 74%|███████▍  | 69/93 [28:58<09:42, 24.26s/epoch, loss=1.12, accuracy=0.757, val_loss=1.89, val_accuracy=0.519, lr=0.1] 75%|███████▌  | 70/93 [29:22<09:16, 24.19s/epoch, loss=1.13, accuracy=0.756, val_loss=2.1, val_accuracy=0.474, lr=0.0316] 76%|███████▋  | 71/93 [29:47<08:58, 24.47s/epoch, loss=1.12, accuracy=0.758, val_loss=3.43, val_accuracy=0.293, lr=0.1]   77%|███████▋  | 72/93 [30:10<08:26, 24.12s/epoch, loss=1.13, accuracy=0.756, val_loss=1.74, val_accuracy=0.586, lr=0.1] 78%|███████▊  | 73/93 [30:34<07:59, 23.99s/epoch, loss=1.13, accuracy=0.756, val_loss=2.45, val_accuracy=0.39, lr=0.1] 