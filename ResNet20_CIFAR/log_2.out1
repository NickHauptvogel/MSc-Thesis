Mon Mar 18 15:22:42 2024       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 545.23.08              Driver Version: 545.23.08    CUDA Version: 12.3     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA TITAN Xp                Off | 00000000:AF:00.0 Off |                  N/A |
| 23%   30C    P8               9W / 250W |      0MiB / 12288MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|  No running processes found                                                           |
+---------------------------------------------------------------------------------------+


* * * Run SGD for ID = 2. * * *


2024-03-18 15:22:50.210320: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-18 15:23:09.989587: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-18 15:23:09.990860: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-18 15:23:10.027176: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:af:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-18 15:23:10.027221: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-18 15:23:10.104378: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-18 15:23:10.104502: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-18 15:23:10.131005: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-18 15:23:10.226331: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-18 15:23:10.304851: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-18 15:23:10.351850: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-18 15:23:10.474696: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-18 15:23:10.476002: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-18 15:23:10.476110: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-18 15:24:18.834287: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-18 15:24:18.835372: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-18 15:24:18.858629: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:af:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-18 15:24:18.858668: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-18 15:24:18.858708: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-18 15:24:18.858720: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-18 15:24:18.858733: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-18 15:24:18.858745: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-18 15:24:18.858757: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-18 15:24:18.858770: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-18 15:24:18.858782: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-18 15:24:18.859333: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-18 15:24:18.859375: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-18 15:24:19.903825: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-18 15:24:19.903887: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-18 15:24:19.903897: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-18 15:24:19.904925: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:af:00.0, compute capability: 6.1)
{'id': '02', 'seed': 2, 'out_folder': 'results/retinopathy/resnet50/10_independent_smalllr_full_val', 'batch_size': 32, 'epochs': 90, 'validation_split': 0.1, 'checkpointing': False, 'checkpoint_every': -1, 'hold_out_validation_split': 0.0, 'model_type': 'ResNet50v1', 'data_augmentation': False, 'augm_shift': 4, 'initial_lr': 0.0023072, 'l2_reg': 0.00010674, 'optimizer': 'sgd', 'momentum': 0.9901533, 'nesterov': True, 'bootstrapping': False, 'use_case': 'retinopathy', 'lr_schedule': 'retinopathy', 'test_time_augmentation': False, 'store_models': False, 'debug': False, 'model': 'ResNet50v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Found 35126 images belonging to 2 classes.
Found 10906 images belonging to 2 classes.
Found 10906 images belonging to 2 classes.
Found 42670 images belonging to 2 classes.
Found 42670 images belonging to 2 classes.
x_train samples: 35126
x_val samples: 10906
x_test samples: 42670
x_train shape: (32, 256, 256, 3)
y_train shape: (32,)
ResNet50v1
0epoch [00:00, ?epoch/s]  0%|          | 0/90 [00:00<?, ?epoch/s]2024-03-18 15:24:20.962125: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-18 15:24:20.962614: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2100000000 Hz
WARNING:tensorflow:AutoGraph could not transform <function weighted_binary_cross_entropy.<locals>.weighted_cross_entropy_fn at 0x7f55f0fd5040> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: module 'gast' has no attribute 'Index'
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
2024-03-18 15:24:26.225116: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-18 15:24:26.530739: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-18 15:24:28.488316: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-18 15:24:28.540225: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1797s vs `on_train_batch_end` time: 0.2789s). Check your callbacks.
  1%|          | 1/90 [13:37<20:13:12, 817.89s/epoch, loss=1.68, accuracy=0.56, auc=0.457, precision=0.17, recall=0.321, val_loss=1.67, val_accuracy=0.561, val_auc=0.452, val_precision=0.16, val_recall=0.312, lr=0]  2%|▏         | 2/90 [24:32<17:38:39, 721.81s/epoch, loss=1.23, accuracy=0.51, auc=0.547, precision=0.217, recall=0.577, val_loss=1.11, val_accuracy=0.716, val_auc=0.581, val_precision=0.261, val_recall=0.278, lr=0.00231]  3%|▎         | 3/90 [35:26<16:41:45, 690.86s/epoch, loss=1.07, accuracy=0.549, auc=0.585, precision=0.236, recall=0.584, val_loss=1.04, val_accuracy=0.468, val_auc=0.58, val_precision=0.215, val_recall=0.688, lr=0.00231]  4%|▍         | 4/90 [46:21<16:09:55, 676.69s/epoch, loss=0.99, accuracy=0.635, auc=0.678, precision=0.293, recall=0.614, val_loss=8.3, val_accuracy=0.194, val_auc=0.513, val_precision=0.188, val_recall=0.987, lr=0.00231]  6%|▌         | 5/90 [57:11<15:45:15, 667.25s/epoch, loss=0.887, accuracy=0.774, auc=0.77, precision=0.442, recall=0.589, val_loss=0.857, val_accuracy=0.8, val_auc=0.792, val_precision=0.476, val_recall=0.587, lr=0.00231]  7%|▋         | 6/90 [1:08:10<15:29:54, 664.22s/epoch, loss=0.828, accuracy=0.789, auc=0.798, precision=0.471, recall=0.625, val_loss=0.82, val_accuracy=0.828, val_auc=0.789, val_precision=0.545, val_recall=0.531, lr=0.00231]  8%|▊         | 7/90 [1:19:00<15:12:35, 659.70s/epoch, loss=0.786, accuracy=0.791, auc=0.809, precision=0.475, recall=0.645, val_loss=0.9, val_accuracy=0.831, val_auc=0.723, val_precision=0.588, val_recall=0.346, lr=0.00231]   9%|▉         | 8/90 [1:29:50<14:57:24, 656.64s/epoch, loss=0.76, accuracy=0.79, auc=0.812, precision=0.473, recall=0.653, val_loss=0.963, val_accuracy=0.83, val_auc=0.677, val_precision=0.83, val_recall=0.124, lr=0.00231]   10%|█         | 9/90 [1:40:50<14:47:37, 657.50s/epoch, loss=0.727, accuracy=0.794, auc=0.821, precision=0.48, recall=0.671, val_loss=1.01, val_accuracy=0.535, val_auc=0.805, val_precision=0.273, val_recall=0.879, lr=0.00231] 11%|█         | 10/90 [1:51:40<14:33:49, 655.37s/epoch, loss=0.711, accuracy=0.79, auc=0.818, precision=0.473, recall=0.665, val_loss=1.16, val_accuracy=0.812, val_auc=0.644, val_precision=0.75, val_recall=0.00146, lr=0.00231] 12%|█▏        | 11/90 [2:02:29<14:20:23, 653.46s/epoch, loss=0.679, accuracy=0.796, auc=0.83, precision=0.484, recall=0.683, val_loss=0.7, val_accuracy=0.796, val_auc=0.804, val_precision=0.469, val_recall=0.634, lr=0.00231]   13%|█▎        | 12/90 [2:13:18<14:07:41, 652.07s/epoch, loss=0.66, accuracy=0.796, auc=0.832, precision=0.485, recall=0.69, val_loss=0.876, val_accuracy=0.816, val_auc=0.641, val_precision=0.695, val_recall=0.0443, lr=0.00231] 14%|█▍        | 13/90 [2:24:03<13:54:08, 649.98s/epoch, loss=0.639, accuracy=0.799, auc=0.838, precision=0.491, recall=0.695, val_loss=0.995, val_accuracy=0.835, val_auc=0.726, val_precision=0.696, val_recall=0.225, lr=0.00231] 16%|█▌        | 14/90 [2:34:55<13:43:45, 650.34s/epoch, loss=0.62, accuracy=0.803, auc=0.843, precision=0.497, recall=0.698, val_loss=0.648, val_accuracy=0.84, val_auc=0.825, val_precision=0.574, val_recall=0.586, lr=0.00231]   17%|█▋        | 15/90 [2:45:43<13:32:12, 649.77s/epoch, loss=0.605, accuracy=0.802, auc=0.846, precision=0.495, recall=0.707, val_loss=0.853, val_accuracy=0.856, val_auc=0.797, val_precision=0.822, val_recall=0.303, lr=0.00231] 18%|█▊        | 16/90 [2:56:30<13:20:28, 649.03s/epoch, loss=0.597, accuracy=0.805, auc=0.847, precision=0.501, recall=0.709, val_loss=1.19, val_accuracy=0.812, val_auc=0.615, val_precision=0.529, val_recall=0.00438, lr=0.00231] 19%|█▉        | 17/90 [3:07:21<13:10:07, 649.41s/epoch, loss=0.581, accuracy=0.806, auc=0.852, precision=0.502, recall=0.721, val_loss=0.694, val_accuracy=0.821, val_auc=0.773, val_precision=0.529, val_recall=0.477, lr=0.00231]  20%|██        | 18/90 [3:18:09<12:58:50, 649.04s/epoch, loss=0.57, accuracy=0.806, auc=0.854, precision=0.504, recall=0.72, val_loss=0.67, val_accuracy=0.743, val_auc=0.802, val_precision=0.399, val_recall=0.723, lr=0.00231]    21%|██        | 19/90 [3:29:21<12:56:17, 656.02s/epoch, loss=0.559, accuracy=0.807, auc=0.858, precision=0.504, recall=0.727, val_loss=0.964, val_accuracy=0.804, val_auc=0.654, val_precision=0.449, val_recall=0.173, lr=0.00231] 22%|██▏       | 20/90 [3:40:09<12:42:34, 653.63s/epoch, loss=0.557, accuracy=0.808, auc=0.856, precision=0.507, recall=0.724, val_loss=1.19, val_accuracy=0.839, val_auc=0.77, val_precision=0.871, val_recall=0.174, lr=0.00231]   23%|██▎       | 21/90 [3:50:57<12:29:35, 651.82s/epoch, loss=0.54, accuracy=0.812, auc=0.866, precision=0.514, recall=0.742, val_loss=0.702, val_accuracy=0.676, val_auc=0.743, val_precision=0.323, val_recall=0.653, lr=0.00231] 24%|██▍       | 22/90 [4:01:43<12:16:49, 650.14s/epoch, loss=0.535, accuracy=0.811, auc=0.866, precision=0.512, recall=0.741, val_loss=3.12, val_accuracy=0.814, val_auc=0.576, val_precision=0.939, val_recall=0.0151, lr=0.00231] 26%|██▌       | 23/90 [4:12:27<12:03:51, 648.22s/epoch, loss=0.531, accuracy=0.811, auc=0.868, precision=0.511, recall=0.744, val_loss=1.92, val_accuracy=0.819, val_auc=0.65, val_precision=0.887, val_recall=0.0457, lr=0.00231]  27%|██▋       | 24/90 [4:23:14<11:52:33, 647.78s/epoch, loss=0.515, accuracy=0.821, auc=0.876, precision=0.53, recall=0.752, val_loss=0.691, val_accuracy=0.749, val_auc=0.697, val_precision=0.37, val_recall=0.474, lr=0.00231]  28%|██▊       | 25/90 [4:34:07<11:43:43, 649.59s/epoch, loss=0.507, accuracy=0.823, auc=0.881, precision=0.534, recall=0.76, val_loss=0.744, val_accuracy=0.837, val_auc=0.784, val_precision=0.581, val_recall=0.487, lr=0.00231] 29%|██▉       | 26/90 [4:44:56<11:32:42, 649.41s/epoch, loss=0.505, accuracy=0.818, auc=0.881, precision=0.524, recall=0.759, val_loss=0.727, val_accuracy=0.492, val_auc=0.815, val_precision=0.257, val_recall=0.895, lr=0.00231] 30%|███       | 27/90 [4:55:45<11:21:43, 649.26s/epoch, loss=0.494, accuracy=0.824, auc=0.887, precision=0.535, recall=0.765, val_loss=0.791, val_accuracy=0.835, val_auc=0.745, val_precision=0.652, val_recall=0.27, lr=0.00231]  31%|███       | 28/90 [5:06:34<11:10:42, 649.07s/epoch, loss=0.485, accuracy=0.827, auc=0.893, precision=0.541, recall=0.78, val_loss=2.57, val_accuracy=0.213, val_auc=0.699, val_precision=0.192, val_recall=0.989, lr=0.00231]  32%|███▏      | 29/90 [5:17:23<10:59:49, 649.02s/epoch, loss=0.482, accuracy=0.827, auc=0.895, precision=0.541, recall=0.781, val_loss=1.18, val_accuracy=0.852, val_auc=0.769, val_precision=0.767, val_recall=0.31, lr=0.00231] 33%|███▎      | 30/90 [5:28:14<10:49:47, 649.80s/epoch, loss=0.471, accuracy=0.832, auc=0.903, precision=0.55, recall=0.795, val_loss=0.697, val_accuracy=0.648, val_auc=0.825, val_precision=0.329, val_recall=0.834, lr=0.00231] 34%|███▍      | 31/90 [5:39:06<10:39:31, 650.36s/epoch, loss=0.417, accuracy=0.861, auc=0.93, precision=0.606, recall=0.832, val_loss=0.639, val_accuracy=0.845, val_auc=0.833, val_precision=0.583, val_recall=0.614, lr=0.000461] 36%|███▌      | 32/90 [5:49:56<10:28:26, 650.12s/epoch, loss=0.358, accuracy=0.884, auc=0.953, precision=0.652, recall=0.871, val_loss=0.63, val_accuracy=0.805, val_auc=0.833, val_precision=0.487, val_recall=0.678, lr=0.000461] 37%|███▋      | 33/90 [6:00:45<10:17:23, 649.89s/epoch, loss=0.33, accuracy=0.898, auc=0.962, precision=0.681, recall=0.896, val_loss=0.71, val_accuracy=0.796, val_auc=0.832, val_precision=0.473, val_recall=0.696, lr=0.000461]  38%|███▊      | 34/90 [6:11:33<10:06:02, 649.32s/epoch, loss=0.3, accuracy=0.905, auc=0.97, precision=0.698, recall=0.908, val_loss=0.893, val_accuracy=0.84, val_auc=0.803, val_precision=0.585, val_recall=0.529, lr=0.000461]   39%|███▉      | 35/90 [6:22:20<9:54:41, 648.75s/epoch, loss=0.274, accuracy=0.918, auc=0.976, precision=0.731, recall=0.923, val_loss=0.832, val_accuracy=0.82, val_auc=0.805, val_precision=0.52, val_recall=0.575, lr=0.000461] 40%|████      | 36/90 [6:33:09<9:43:44, 648.61s/epoch, loss=0.253, accuracy=0.926, auc=0.981, precision=0.748, recall=0.939, val_loss=0.904, val_accuracy=0.827, val_auc=0.822, val_precision=0.536, val_recall=0.61, lr=0.000461] 41%|████      | 37/90 [6:43:58<9:33:06, 648.81s/epoch, loss=0.234, accuracy=0.935, auc=0.984, precision=0.772, recall=0.946, val_loss=0.863, val_accuracy=0.795, val_auc=0.804, val_precision=0.467, val_recall=0.636, lr=0.000461] 42%|████▏     | 38/90 [6:54:46<9:22:06, 648.59s/epoch, loss=0.221, accuracy=0.942, auc=0.987, precision=0.791, recall=0.953, val_loss=1.21, val_accuracy=0.523, val_auc=0.796, val_precision=0.269, val_recall=0.892, lr=0.000461]  43%|████▎     | 39/90 [7:05:35<9:11:16, 648.57s/epoch, loss=0.214, accuracy=0.946, auc=0.988, precision=0.804, recall=0.955, val_loss=0.955, val_accuracy=0.71, val_auc=0.82, val_precision=0.372, val_recall=0.785, lr=0.000461]  44%|████▍     | 40/90 [7:16:23<9:00:25, 648.50s/epoch, loss=0.209, accuracy=0.948, auc=0.989, precision=0.812, recall=0.956, val_loss=0.982, val_accuracy=0.793, val_auc=0.791, val_precision=0.463, val_recall=0.597, lr=0.000461] 46%|████▌     | 41/90 [7:27:11<8:49:32, 648.41s/epoch, loss=0.193, accuracy=0.955, auc=0.992, precision=0.835, recall=0.962, val_loss=0.997, val_accuracy=0.732, val_auc=0.814, val_precision=0.391, val_recall=0.752, lr=0.000461] 47%|████▋     | 42/90 [7:38:02<8:39:26, 649.30s/epoch, loss=0.19, accuracy=0.956, auc=0.992, precision=0.839, recall=0.96, val_loss=1.25, val_accuracy=0.844, val_auc=0.796, val_precision=0.598, val_recall=0.523, lr=0.000461]    48%|████▊     | 43/90 [7:48:50<8:28:15, 648.84s/epoch, loss=0.166, accuracy=0.966, auc=0.996, precision=0.87, recall=0.972, val_loss=1.33, val_accuracy=0.655, val_auc=0.799, val_precision=0.331, val_recall=0.814, lr=0.000461] 49%|████▉     | 44/90 [7:59:39<8:17:19, 648.68s/epoch, loss=0.183, accuracy=0.96, auc=0.994, precision=0.851, recall=0.966, val_loss=1.15, val_accuracy=0.811, val_auc=0.818, val_precision=0.499, val_recall=0.652, lr=0.000461] 50%|█████     | 45/90 [8:10:28<8:06:41, 648.93s/epoch, loss=0.178, accuracy=0.963, auc=0.994, precision=0.86, recall=0.968, val_loss=1.57, val_accuracy=0.845, val_auc=0.782, val_precision=0.611, val_recall=0.497, lr=0.000461] 51%|█████     | 46/90 [8:21:21<7:56:50, 650.23s/epoch, loss=0.16, accuracy=0.971, auc=0.996, precision=0.887, recall=0.975, val_loss=1.32, val_accuracy=0.821, val_auc=0.793, val_precision=0.523, val_recall=0.586, lr=0.000461] 52%|█████▏    | 47/90 [8:32:10<7:45:39, 649.75s/epoch, loss=0.162, accuracy=0.97, auc=0.996, precision=0.882, recall=0.975, val_loss=1.28, val_accuracy=0.809, val_auc=0.795, val_precision=0.494, val_recall=0.591, lr=0.000461] 53%|█████▎    | 48/90 [8:42:59<7:34:46, 649.68s/epoch, loss=0.171, accuracy=0.967, auc=0.995, precision=0.875, recall=0.971, val_loss=1.3, val_accuracy=0.781, val_auc=0.801, val_precision=0.447, val_recall=0.676, lr=0.000461] 54%|█████▍    | 49/90 [8:53:49<7:23:53, 649.59s/epoch, loss=0.164, accuracy=0.972, auc=0.996, precision=0.891, recall=0.975, val_loss=1.63, val_accuracy=0.84, val_auc=0.778, val_precision=0.591, val_recall=0.487, lr=0.000461] 56%|█████▌    | 50/90 [9:04:37<7:12:52, 649.31s/epoch, loss=0.145, accuracy=0.979, auc=0.998, precision=0.916, recall=0.982, val_loss=1.68, val_accuracy=0.836, val_auc=0.775, val_precision=0.578, val_recall=0.475, lr=0.000461] 57%|█████▋    | 51/90 [9:15:24<7:01:31, 648.49s/epoch, loss=0.163, accuracy=0.972, auc=0.997, precision=0.891, recall=0.975, val_loss=1.35, val_accuracy=0.826, val_auc=0.79, val_precision=0.537, val_recall=0.569, lr=0.000461]  58%|█████▊    | 52/90 [9:26:18<6:51:50, 650.27s/epoch, loss=0.154, accuracy=0.976, auc=0.997, precision=0.906, recall=0.977, val_loss=1.25, val_accuracy=0.771, val_auc=0.805, val_precision=0.433, val_recall=0.701, lr=0.000461] 59%|█████▉    | 53/90 [9:37:10<6:41:15, 650.68s/epoch, loss=0.136, accuracy=0.983, auc=0.999, precision=0.93, recall=0.987, val_loss=1.36, val_accuracy=0.817, val_auc=0.789, val_precision=0.514, val_recall=0.569, lr=0.000461]  60%|██████    | 54/90 [9:47:59<6:30:08, 650.25s/epoch, loss=0.141, accuracy=0.981, auc=0.998, precision=0.925, recall=0.984, val_loss=2.16, val_accuracy=0.835, val_auc=0.742, val_precision=0.592, val_recall=0.402, lr=0.000461] 61%|██████    | 55/90 [9:58:50<6:19:17, 650.22s/epoch, loss=0.163, accuracy=0.973, auc=0.996, precision=0.897, recall=0.973, val_loss=2.58, val_accuracy=0.859, val_auc=0.745, val_precision=0.743, val_recall=0.389, lr=0.000461] 62%|██████▏   | 56/90 [10:09:38<6:08:13, 649.81s/epoch, loss=0.152, accuracy=0.978, auc=0.998, precision=0.916, recall=0.98, val_loss=1.71, val_accuracy=0.83, val_auc=0.767, val_precision=0.556, val_recall=0.478, lr=0.000461]  63%|██████▎   | 57/90 [10:20:26<5:56:58, 649.05s/epoch, loss=0.139, accuracy=0.984, auc=0.999, precision=0.935, recall=0.985, val_loss=1.49, val_accuracy=0.707, val_auc=0.801, val_precision=0.37, val_recall=0.782, lr=0.000461] 64%|██████▍   | 58/90 [10:31:30<5:48:39, 653.72s/epoch, loss=0.124, accuracy=0.989, auc=0.999, precision=0.954, recall=0.991, val_loss=2.6, val_accuracy=0.844, val_auc=0.732, val_precision=0.649, val_recall=0.373, lr=0.000461] 66%|██████▌   | 59/90 [10:42:19<5:37:00, 652.27s/epoch, loss=0.134, accuracy=0.985, auc=0.999, precision=0.942, recall=0.986, val_loss=1.44, val_accuracy=0.764, val_auc=0.776, val_precision=0.419, val_recall=0.658, lr=0.000461] 67%|██████▋   | 60/90 [10:53:07<5:25:32, 651.08s/epoch, loss=0.149, accuracy=0.978, auc=0.998, precision=0.915, recall=0.981, val_loss=3.46, val_accuracy=0.837, val_auc=0.665, val_precision=0.776, val_recall=0.191, lr=0.000461] 68%|██████▊   | 61/90 [11:03:54<5:13:59, 649.64s/epoch, loss=0.127, accuracy=0.99, auc=0.999, precision=0.958, recall=0.99, val_loss=1.71, val_accuracy=0.839, val_auc=0.786, val_precision=0.583, val_recall=0.516, lr=9.23e-5]    69%|██████▉   | 62/90 [11:14:41<5:02:46, 648.82s/epoch, loss=0.101, accuracy=0.999, auc=1, precision=0.996, recall=1, val_loss=1.81, val_accuracy=0.844, val_auc=0.787, val_precision=0.599, val_recall=0.513, lr=9.23e-5]       70%|███████   | 63/90 [11:25:29<4:51:51, 648.58s/epoch, loss=0.0984, accuracy=1, auc=1, precision=0.999, recall=1, val_loss=1.87, val_accuracy=0.843, val_auc=0.787, val_precision=0.599, val_recall=0.508, lr=9.23e-5]    71%|███████   | 64/90 [11:36:29<4:42:37, 652.22s/epoch, loss=0.0977, accuracy=1, auc=1, precision=0.999, recall=1, val_loss=2, val_accuracy=0.849, val_auc=0.78, val_precision=0.624, val_recall=0.493, lr=9.23e-5]     72%|███████▏  | 65/90 [11:47:19<4:31:24, 651.39s/epoch, loss=0.096, accuracy=1, auc=1, precision=1, recall=1, val_loss=1.99, val_accuracy=0.845, val_auc=0.782, val_precision=0.609, val_recall=0.5, lr=9.23e-5]    73%|███████▎  | 66/90 [11:58:07<4:20:11, 650.49s/epoch, loss=0.0954, accuracy=1, auc=1, precision=1, recall=1, val_loss=2.02, val_accuracy=0.844, val_auc=0.779, val_precision=0.605, val_recall=0.497, lr=9.23e-5] 74%|███████▍  | 67/90 [12:08:56<4:09:12, 650.10s/epoch, loss=0.0947, accuracy=1, auc=1, precision=1, recall=1, val_loss=1.92, val_accuracy=0.841, val_auc=0.787, val_precision=0.589, val_recall=0.523, lr=9.23e-5] 76%|███████▌  | 68/90 [12:19:43<3:57:55, 648.90s/epoch, loss=0.0939, accuracy=1, auc=1, precision=1, recall=1, val_loss=1.95, val_accuracy=0.842, val_auc=0.786, val_precision=0.593, val_recall=0.518, lr=9.23e-5] 77%|███████▋  | 69/90 [12:30:29<3:46:54, 648.29s/epoch, loss=0.0933, accuracy=1, auc=1, precision=1, recall=1, val_loss=2.02, val_accuracy=0.843, val_auc=0.783, val_precision=0.599, val_recall=0.513, lr=9.23e-5] 78%|███████▊  | 70/90 [12:41:18<3:36:07, 648.36s/epoch, loss=0.0927, accuracy=1, auc=1, precision=1, recall=1, val_loss=2.07, val_accuracy=0.845, val_auc=0.781, val_precision=0.604, val_recall=0.51, lr=9.23e-5]  79%|███████▉  | 71/90 [12:52:06<3:25:16, 648.24s/epoch, loss=0.0922, accuracy=1, auc=1, precision=1, recall=1, val_loss=2.09, val_accuracy=0.845, val_auc=0.78, val_precision=0.605, val_recall=0.508, lr=9.23e-5] 80%|████████  | 72/90 [13:02:53<3:14:20, 647.82s/epoch, loss=0.0917, accuracy=1, auc=1, precision=1, recall=1, val_loss=2.07, val_accuracy=0.843, val_auc=0.782, val_precision=0.599, val_recall=0.516, lr=9.23e-5] 81%|████████  | 73/90 [13:13:53<3:04:35, 651.48s/epoch, loss=0.0912, accuracy=1, auc=1, precision=1, recall=1, val_loss=2.25, val_accuracy=0.849, val_auc=0.773, val_precision=0.626, val_recall=0.487, lr=9.23e-5] 82%|████████▏ | 74/90 [13:24:41<2:53:29, 650.59s/epoch, loss=0.0909, accuracy=1, auc=1, precision=1, recall=1, val_loss=2.15, val_accuracy=0.845, val_auc=0.779, val_precision=0.608, val_recall=0.507, lr=9.23e-5] 83%|████████▎ | 75/90 [13:35:30<2:42:31, 650.12s/epoch, loss=0.0903, accuracy=1, auc=1, precision=1, recall=1, val_loss=2.11, val_accuracy=0.844, val_auc=0.783, val_precision=0.599, val_recall=0.518, lr=9.23e-5] 84%|████████▍ | 76/90 [13:46:19<2:31:34, 649.60s/epoch, loss=0.0899, accuracy=1, auc=1, precision=1, recall=1, val_loss=2.19, val_accuracy=0.844, val_auc=0.778, val_precision=0.604, val_recall=0.504, lr=9.23e-5] 86%|████████▌ | 77/90 [13:57:05<2:20:32, 648.63s/epoch, loss=0.0895, accuracy=1, auc=1, precision=1, recall=1, val_loss=2.15, val_accuracy=0.845, val_auc=0.782, val_precision=0.602, val_recall=0.518, lr=9.23e-5] 87%|████████▋ | 78/90 [14:07:54<2:09:44, 648.68s/epoch, loss=0.0891, accuracy=1, auc=1, precision=1, recall=1, val_loss=2.21, val_accuracy=0.844, val_auc=0.779, val_precision=0.603, val_recall=0.502, lr=9.23e-5] 88%|████████▊ | 79/90 [14:18:39<1:58:44, 647.72s/epoch, loss=0.0886, accuracy=1, auc=1, precision=1, recall=1, val_loss=2.22, val_accuracy=0.844, val_auc=0.779, val_precision=0.603, val_recall=0.503, lr=9.23e-5] 89%|████████▉ | 80/90 [14:29:29<1:48:01, 648.18s/epoch, loss=0.0882, accuracy=1, auc=1, precision=1, recall=1, val_loss=2.2, val_accuracy=0.845, val_auc=0.779, val_precision=0.604, val_recall=0.511, lr=9.23e-5]  90%|█████████ | 81/90 [14:40:15<1:37:09, 647.68s/epoch, loss=0.0878, accuracy=1, auc=1, precision=1, recall=1, val_loss=2.25, val_accuracy=0.845, val_auc=0.777, val_precision=0.607, val_recall=0.505, lr=9.23e-5] 91%|█████████ | 82/90 [14:51:04<1:26:23, 647.96s/epoch, loss=0.0874, accuracy=1, auc=1, precision=1, recall=1, val_loss=2.38, val_accuracy=0.848, val_auc=0.769, val_precision=0.626, val_recall=0.482, lr=9.23e-5] 92%|█████████▏| 83/90 [15:01:52<1:15:37, 648.15s/epoch, loss=0.087, accuracy=1, auc=1, precision=1, recall=1, val_loss=2.25, val_accuracy=0.845, val_auc=0.777, val_precision=0.606, val_recall=0.506, lr=9.23e-5]  93%|█████████▎| 84/90 [15:12:40<1:04:47, 647.99s/epoch, loss=0.0866, accuracy=1, auc=1, precision=1, recall=1, val_loss=2.27, val_accuracy=0.846, val_auc=0.777, val_precision=0.61, val_recall=0.505, lr=9.23e-5] 94%|█████████▍| 85/90 [15:23:29<54:01, 648.24s/epoch, loss=0.0862, accuracy=1, auc=1, precision=1, recall=1, val_loss=2.19, val_accuracy=0.844, val_auc=0.779, val_precision=0.599, val_recall=0.523, lr=9.23e-5]  96%|█████████▌| 86/90 [15:34:16<43:11, 647.88s/epoch, loss=0.0857, accuracy=1, auc=1, precision=1, recall=1, val_loss=2.25, val_accuracy=0.845, val_auc=0.778, val_precision=0.605, val_recall=0.515, lr=9.23e-5] 97%|█████████▋| 87/90 [15:45:04<32:24, 648.13s/epoch, loss=0.0855, accuracy=1, auc=1, precision=1, recall=1, val_loss=2.06, val_accuracy=0.837, val_auc=0.788, val_precision=0.568, val_recall=0.57, lr=9.23e-5]  98%|█████████▊| 88/90 [15:55:55<21:37, 648.95s/epoch, loss=0.0851, accuracy=1, auc=1, precision=1, recall=1, val_loss=2.3, val_accuracy=0.844, val_auc=0.774, val_precision=0.602, val_recall=0.505, lr=9.23e-5] 99%|█████████▉| 89/90 [16:06:44<10:49, 649.01s/epoch, loss=0.0847, accuracy=1, auc=1, precision=1, recall=1, val_loss=2.35, val_accuracy=0.846, val_auc=0.773, val_precision=0.613, val_recall=0.498, lr=9.23e-5]100%|██████████| 90/90 [16:17:30<00:00, 648.04s/epoch, loss=0.0843, accuracy=1, auc=1, precision=1, recall=1, val_loss=2.29, val_accuracy=0.845, val_auc=0.777, val_precision=0.605, val_recall=0.515, lr=9.23e-5]100%|██████████| 90/90 [16:17:30<00:00, 651.68s/epoch, loss=0.0843, accuracy=1, auc=1, precision=1, recall=1, val_loss=2.29, val_accuracy=0.845, val_auc=0.777, val_precision=0.605, val_recall=0.515, lr=9.23e-5]
Traceback (most recent call last):
  File "/home/gkb738/.conda/envs/TF_KERAS_GPU/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/gkb738/.conda/envs/TF_KERAS_GPU/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/gkb738/MSc-Thesis/ResNet20_CIFAR/sgd_baseline.py", line 378, in <module>
    score, acc = model.evaluate(test_loader, verbose=0)
ValueError: too many values to unpack (expected 2)
Only one model saved

Loading model: 02_retinopathy_ResNet50v1.h5
