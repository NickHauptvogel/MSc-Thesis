Mon Mar 18 15:24:42 2024       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 545.23.08              Driver Version: 545.23.08    CUDA Version: 12.3     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA TITAN Xp                Off | 00000000:3B:00.0 Off |                  N/A |
| 29%   44C    P8              10W / 250W |      0MiB / 12288MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|  No running processes found                                                           |
+---------------------------------------------------------------------------------------+


* * * Run SGD for ID = 8. * * *


2024-03-18 15:24:42.870083: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-18 15:24:49.889302: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-18 15:24:49.891613: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-18 15:24:49.924610: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:3b:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-18 15:24:49.924645: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-18 15:24:49.929610: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-18 15:24:49.929672: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-18 15:24:49.932955: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-18 15:24:49.934100: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-18 15:24:49.936967: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-18 15:24:49.939014: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-18 15:24:49.944488: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-18 15:24:49.945255: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-18 15:24:49.945338: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-18 15:25:03.128286: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-18 15:25:03.132092: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-18 15:25:03.132574: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:3b:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-18 15:25:03.132608: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-18 15:25:03.132640: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-18 15:25:03.132653: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-18 15:25:03.132665: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-18 15:25:03.132677: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-18 15:25:03.132690: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-18 15:25:03.132702: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-18 15:25:03.132715: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-18 15:25:03.133243: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-18 15:25:03.133276: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-18 15:25:03.884787: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-18 15:25:03.884842: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-18 15:25:03.884861: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-18 15:25:03.891658: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:3b:00.0, compute capability: 6.1)
{'id': '08', 'seed': 8, 'out_folder': 'results/retinopathy/resnet50/10_independent_smalllr_full_val', 'batch_size': 32, 'epochs': 90, 'validation_split': 0.1, 'checkpointing': False, 'checkpoint_every': -1, 'hold_out_validation_split': 0.0, 'model_type': 'ResNet50v1', 'data_augmentation': False, 'augm_shift': 4, 'initial_lr': 0.0023072, 'l2_reg': 0.00010674, 'optimizer': 'sgd', 'momentum': 0.9901533, 'nesterov': True, 'bootstrapping': False, 'use_case': 'retinopathy', 'lr_schedule': 'retinopathy', 'test_time_augmentation': False, 'store_models': False, 'debug': False, 'model': 'ResNet50v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Found 35126 images belonging to 2 classes.
Found 10906 images belonging to 2 classes.
Found 10906 images belonging to 2 classes.
Found 42670 images belonging to 2 classes.
Found 42670 images belonging to 2 classes.
x_train samples: 35126
x_val samples: 10906
x_test samples: 42670
x_train shape: (32, 256, 256, 3)
y_train shape: (32,)
ResNet50v1
0epoch [00:00, ?epoch/s]  0%|          | 0/90 [00:00<?, ?epoch/s]2024-03-18 15:25:05.055619: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-18 15:25:05.056186: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2100000000 Hz
WARNING:tensorflow:AutoGraph could not transform <function weighted_binary_cross_entropy.<locals>.weighted_cross_entropy_fn at 0x7fc805a53ee0> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: module 'gast' has no attribute 'Index'
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
2024-03-18 15:25:19.673135: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-18 15:25:21.044703: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-18 15:25:21.913749: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-18 15:25:22.043687: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1820s vs `on_train_batch_end` time: 0.2793s). Check your callbacks.
  1%|          | 1/90 [12:53<19:07:30, 773.60s/epoch, loss=4.76, accuracy=0.196, auc=0.494, precision=0.196, recall=1, val_loss=4.81, val_accuracy=0.189, val_auc=0.49, val_precision=0.189, val_recall=1, lr=0]  2%|▏         | 2/90 [24:01<17:23:36, 711.55s/epoch, loss=1.29, accuracy=0.511, auc=0.536, precision=0.213, recall=0.558, val_loss=1.11, val_accuracy=0.615, val_auc=0.554, val_precision=0.218, val_recall=0.402, lr=0.00231]  3%|▎         | 3/90 [35:10<16:43:26, 692.03s/epoch, loss=1.1, accuracy=0.575, auc=0.567, precision=0.231, recall=0.503, val_loss=1.06, val_accuracy=0.45, val_auc=0.593, val_precision=0.218, val_recall=0.742, lr=0.00231]    4%|▍         | 4/90 [46:20<16:19:23, 683.30s/epoch, loss=1.05, accuracy=0.58, auc=0.6, precision=0.247, recall=0.558, val_loss=1.01, val_accuracy=0.565, val_auc=0.619, val_precision=0.243, val_recall=0.617, lr=0.00231]   6%|▌         | 5/90 [57:24<15:58:09, 676.35s/epoch, loss=0.979, accuracy=0.643, auc=0.665, precision=0.292, recall=0.578, val_loss=1.11, val_accuracy=0.811, val_auc=0.598, val_precision=0.5, val_recall=0.00389, lr=0.00231]  7%|▋         | 6/90 [1:08:35<15:44:33, 674.68s/epoch, loss=0.881, accuracy=0.766, auc=0.761, precision=0.428, recall=0.574, val_loss=0.89, val_accuracy=0.832, val_auc=0.736, val_precision=0.591, val_recall=0.346, lr=0.00231]  8%|▊         | 7/90 [1:19:41<15:29:25, 671.87s/epoch, loss=0.824, accuracy=0.787, auc=0.786, precision=0.466, recall=0.608, val_loss=1.08, val_accuracy=0.812, val_auc=0.593, val_precision=0.643, val_recall=0.00875, lr=0.00231]  9%|▉         | 8/90 [1:30:47<15:15:37, 669.97s/epoch, loss=0.781, accuracy=0.797, auc=0.802, precision=0.485, recall=0.63, val_loss=0.772, val_accuracy=0.798, val_auc=0.788, val_precision=0.471, val_recall=0.589, lr=0.00231]   10%|█         | 9/90 [1:41:53<15:02:25, 668.46s/epoch, loss=0.752, accuracy=0.795, auc=0.805, precision=0.482, recall=0.635, val_loss=1.18, val_accuracy=0.813, val_auc=0.614, val_precision=0.714, val_recall=0.0122, lr=0.00231] 11%|█         | 10/90 [1:52:56<14:49:23, 667.05s/epoch, loss=0.722, accuracy=0.8, auc=0.815, precision=0.491, recall=0.653, val_loss=0.876, val_accuracy=0.837, val_auc=0.731, val_precision=0.797, val_recall=0.184, lr=0.00231]  12%|█▏        | 11/90 [2:04:00<14:36:55, 666.03s/epoch, loss=0.705, accuracy=0.798, auc=0.812, precision=0.487, recall=0.647, val_loss=0.729, val_accuracy=0.849, val_auc=0.804, val_precision=0.64, val_recall=0.455, lr=0.00231] 13%|█▎        | 12/90 [2:15:03<14:24:40, 665.14s/epoch, loss=0.682, accuracy=0.803, auc=0.818, precision=0.498, recall=0.65, val_loss=0.87, val_accuracy=0.827, val_auc=0.672, val_precision=0.647, val_recall=0.186, lr=0.00231]  14%|█▍        | 13/90 [2:26:05<14:12:14, 664.08s/epoch, loss=0.663, accuracy=0.801, auc=0.822, precision=0.494, recall=0.657, val_loss=0.702, val_accuracy=0.796, val_auc=0.767, val_precision=0.466, val_recall=0.552, lr=0.00231] 16%|█▌        | 14/90 [2:37:06<14:00:09, 663.28s/epoch, loss=0.646, accuracy=0.801, auc=0.825, precision=0.494, recall=0.665, val_loss=1.19, val_accuracy=0.81, val_auc=0.577, val_precision=0.42, val_recall=0.0165, lr=0.00231]   17%|█▋        | 15/90 [2:48:09<13:48:46, 663.02s/epoch, loss=0.629, accuracy=0.804, auc=0.829, precision=0.5, recall=0.67, val_loss=1.38, val_accuracy=0.319, val_auc=0.77, val_precision=0.212, val_recall=0.962, lr=0.00231]    18%|█▊        | 16/90 [2:59:11<13:37:29, 662.84s/epoch, loss=0.619, accuracy=0.803, auc=0.829, precision=0.498, recall=0.669, val_loss=0.81, val_accuracy=0.632, val_auc=0.793, val_precision=0.315, val_recall=0.807, lr=0.00231] 19%|█▉        | 17/90 [3:10:14<13:26:20, 662.75s/epoch, loss=0.604, accuracy=0.805, auc=0.834, precision=0.502, recall=0.678, val_loss=0.633, val_accuracy=0.753, val_auc=0.811, val_precision=0.411, val_recall=0.716, lr=0.00231] 20%|██        | 18/90 [3:21:16<13:15:14, 662.70s/epoch, loss=0.594, accuracy=0.805, auc=0.836, precision=0.501, recall=0.682, val_loss=0.712, val_accuracy=0.849, val_auc=0.765, val_precision=0.71, val_recall=0.338, lr=0.00231]  21%|██        | 19/90 [3:32:23<13:05:33, 663.85s/epoch, loss=0.578, accuracy=0.808, auc=0.841, precision=0.506, recall=0.691, val_loss=0.859, val_accuracy=0.834, val_auc=0.722, val_precision=0.851, val_recall=0.144, lr=0.00231] 22%|██▏       | 20/90 [3:43:26<12:54:12, 663.61s/epoch, loss=0.571, accuracy=0.809, auc=0.842, precision=0.508, recall=0.694, val_loss=0.674, val_accuracy=0.846, val_auc=0.771, val_precision=0.64, val_recall=0.417, lr=0.00231]  23%|██▎       | 21/90 [3:54:29<12:42:50, 663.34s/epoch, loss=0.564, accuracy=0.808, auc=0.845, precision=0.508, recall=0.695, val_loss=0.744, val_accuracy=0.835, val_auc=0.721, val_precision=0.625, val_recall=0.307, lr=0.00231] 24%|██▍       | 22/90 [4:05:32<12:31:44, 663.31s/epoch, loss=0.551, accuracy=0.813, auc=0.851, precision=0.517, recall=0.706, val_loss=0.757, val_accuracy=0.598, val_auc=0.78, val_precision=0.298, val_recall=0.835, lr=0.00231]  26%|██▌       | 23/90 [4:16:34<12:20:11, 662.86s/epoch, loss=0.547, accuracy=0.814, auc=0.85, precision=0.518, recall=0.705, val_loss=0.735, val_accuracy=0.848, val_auc=0.77, val_precision=0.827, val_recall=0.244, lr=0.00231]  27%|██▋       | 24/90 [4:27:36<12:08:53, 662.63s/epoch, loss=0.535, accuracy=0.814, auc=0.856, precision=0.518, recall=0.715, val_loss=0.654, val_accuracy=0.676, val_auc=0.81, val_precision=0.345, val_recall=0.799, lr=0.00231] 28%|██▊       | 25/90 [4:38:39<11:58:12, 662.96s/epoch, loss=0.531, accuracy=0.816, auc=0.858, precision=0.522, recall=0.718, val_loss=0.702, val_accuracy=0.837, val_auc=0.765, val_precision=0.626, val_recall=0.334, lr=0.00231] 29%|██▉       | 26/90 [4:49:42<11:47:05, 662.90s/epoch, loss=0.528, accuracy=0.816, auc=0.858, precision=0.523, recall=0.715, val_loss=0.739, val_accuracy=0.497, val_auc=0.789, val_precision=0.258, val_recall=0.887, lr=0.00231] 30%|███       | 27/90 [5:00:42<11:35:11, 662.09s/epoch, loss=0.523, accuracy=0.815, auc=0.861, precision=0.519, recall=0.722, val_loss=0.714, val_accuracy=0.838, val_auc=0.754, val_precision=0.625, val_recall=0.35, lr=0.00231]  31%|███       | 28/90 [5:11:44<11:24:06, 662.04s/epoch, loss=0.514, accuracy=0.818, auc=0.865, precision=0.526, recall=0.724, val_loss=0.569, val_accuracy=0.802, val_auc=0.818, val_precision=0.482, val_recall=0.649, lr=0.00231] 32%|███▏      | 29/90 [5:22:44<11:12:16, 661.26s/epoch, loss=0.511, accuracy=0.819, auc=0.867, precision=0.528, recall=0.734, val_loss=0.626, val_accuracy=0.741, val_auc=0.792, val_precision=0.396, val_recall=0.71, lr=0.00231]  33%|███▎      | 30/90 [5:33:56<11:04:38, 664.64s/epoch, loss=0.502, accuracy=0.821, auc=0.872, precision=0.53, recall=0.734, val_loss=0.671, val_accuracy=0.667, val_auc=0.816, val_precision=0.339, val_recall=0.805, lr=0.00231] 34%|███▍      | 31/90 [5:45:01<10:53:42, 664.79s/epoch, loss=0.478, accuracy=0.832, auc=0.887, precision=0.551, recall=0.764, val_loss=0.578, val_accuracy=0.727, val_auc=0.831, val_precision=0.388, val_recall=0.78, lr=0.000461] 36%|███▌      | 32/90 [5:56:04<10:42:02, 664.19s/epoch, loss=0.444, accuracy=0.847, auc=0.905, precision=0.58, recall=0.787, val_loss=0.565, val_accuracy=0.807, val_auc=0.822, val_precision=0.492, val_recall=0.68, lr=0.000461]  37%|███▋      | 33/90 [6:07:04<10:29:45, 662.90s/epoch, loss=0.431, accuracy=0.85, auc=0.912, precision=0.585, recall=0.796, val_loss=0.67, val_accuracy=0.636, val_auc=0.837, val_precision=0.324, val_recall=0.859, lr=0.000461] 38%|███▊      | 34/90 [6:18:06<10:18:32, 662.72s/epoch, loss=0.422, accuracy=0.853, auc=0.917, precision=0.592, recall=0.807, val_loss=0.598, val_accuracy=0.749, val_auc=0.824, val_precision=0.408, val_recall=0.744, lr=0.000461] 39%|███▉      | 35/90 [6:29:09<10:07:24, 662.63s/epoch, loss=0.413, accuracy=0.855, auc=0.921, precision=0.596, recall=0.811, val_loss=0.57, val_accuracy=0.778, val_auc=0.829, val_precision=0.445, val_recall=0.717, lr=0.000461]  40%|████      | 36/90 [6:40:25<10:00:00, 666.68s/epoch, loss=0.399, accuracy=0.86, auc=0.927, precision=0.604, recall=0.826, val_loss=0.61, val_accuracy=0.749, val_auc=0.809, val_precision=0.406, val_recall=0.715, lr=0.000461]  41%|████      | 37/90 [6:51:28<9:47:59, 665.65s/epoch, loss=0.388, accuracy=0.863, auc=0.932, precision=0.61, recall=0.833, val_loss=0.628, val_accuracy=0.835, val_auc=0.819, val_precision=0.558, val_recall=0.607, lr=0.000461] 42%|████▏     | 38/90 [7:02:30<9:36:00, 664.63s/epoch, loss=0.377, accuracy=0.869, auc=0.937, precision=0.621, recall=0.842, val_loss=1.01, val_accuracy=0.444, val_auc=0.822, val_precision=0.244, val_recall=0.931, lr=0.000461] 43%|████▎     | 39/90 [7:13:33<9:24:26, 664.05s/epoch, loss=0.363, accuracy=0.875, auc=0.943, precision=0.635, recall=0.854, val_loss=0.648, val_accuracy=0.773, val_auc=0.81, val_precision=0.437, val_recall=0.695, lr=0.000461] 44%|████▍     | 40/90 [7:24:35<9:12:54, 663.49s/epoch, loss=0.355, accuracy=0.877, auc=0.946, precision=0.638, recall=0.86, val_loss=0.781, val_accuracy=0.855, val_auc=0.809, val_precision=0.654, val_recall=0.493, lr=0.000461] 46%|████▌     | 41/90 [7:35:39<9:01:49, 663.47s/epoch, loss=0.339, accuracy=0.883, auc=0.952, precision=0.65, recall=0.874, val_loss=0.947, val_accuracy=0.837, val_auc=0.769, val_precision=0.589, val_recall=0.441, lr=0.000461] 47%|████▋     | 42/90 [7:46:54<8:53:37, 667.03s/epoch, loss=0.333, accuracy=0.888, auc=0.955, precision=0.66, recall=0.879, val_loss=0.877, val_accuracy=0.841, val_auc=0.788, val_precision=0.597, val_recall=0.476, lr=0.000461] 48%|████▊     | 43/90 [7:57:56<8:41:22, 665.59s/epoch, loss=0.326, accuracy=0.889, auc=0.957, precision=0.664, recall=0.879, val_loss=1.15, val_accuracy=0.456, val_auc=0.789, val_precision=0.244, val_recall=0.9, lr=0.000461]   49%|████▉     | 44/90 [8:08:59<8:29:43, 664.85s/epoch, loss=0.299, accuracy=0.901, auc=0.966, precision=0.689, recall=0.899, val_loss=0.728, val_accuracy=0.803, val_auc=0.789, val_precision=0.481, val_recall=0.59, lr=0.000461] 50%|█████     | 45/90 [8:20:08<8:19:22, 665.83s/epoch, loss=0.299, accuracy=0.903, auc=0.966, precision=0.693, recall=0.902, val_loss=0.814, val_accuracy=0.833, val_auc=0.792, val_precision=0.564, val_recall=0.51, lr=0.000461] 51%|█████     | 46/90 [8:31:11<8:07:44, 665.11s/epoch, loss=0.279, accuracy=0.912, auc=0.972, precision=0.715, recall=0.91, val_loss=1.14, val_accuracy=0.51, val_auc=0.79, val_precision=0.261, val_recall=0.877, lr=0.000461]    52%|█████▏    | 47/90 [8:42:17<7:56:45, 665.23s/epoch, loss=0.268, accuracy=0.919, auc=0.975, precision=0.734, recall=0.919, val_loss=1.3, val_accuracy=0.84, val_auc=0.761, val_precision=0.63, val_recall=0.367, lr=0.000461] 53%|█████▎    | 48/90 [8:53:14<7:43:57, 662.79s/epoch, loss=0.258, accuracy=0.923, auc=0.978, precision=0.742, recall=0.928, val_loss=0.872, val_accuracy=0.626, val_auc=0.786, val_precision=0.308, val_recall=0.787, lr=0.000461] 54%|█████▍    | 49/90 [9:04:18<7:33:13, 663.27s/epoch, loss=0.237, accuracy=0.933, auc=0.983, precision=0.768, recall=0.94, val_loss=1.11, val_accuracy=0.837, val_auc=0.779, val_precision=0.582, val_recall=0.483, lr=0.000461]   56%|█████▌    | 50/90 [9:15:22<7:22:19, 663.49s/epoch, loss=0.232, accuracy=0.935, auc=0.984, precision=0.775, recall=0.941, val_loss=1.59, val_accuracy=0.855, val_auc=0.769, val_precision=0.713, val_recall=0.389, lr=0.000461] 57%|█████▋    | 51/90 [9:26:24<7:11:02, 663.14s/epoch, loss=0.233, accuracy=0.935, auc=0.984, precision=0.776, recall=0.94, val_loss=0.884, val_accuracy=0.697, val_auc=0.802, val_precision=0.356, val_recall=0.754, lr=0.000461] 58%|█████▊    | 52/90 [9:37:29<7:00:17, 663.63s/epoch, loss=0.216, accuracy=0.945, auc=0.988, precision=0.804, recall=0.95, val_loss=1.13, val_accuracy=0.821, val_auc=0.766, val_precision=0.528, val_recall=0.489, lr=0.000461]  59%|█████▉    | 53/90 [9:48:32<6:49:04, 663.37s/epoch, loss=0.212, accuracy=0.946, auc=0.989, precision=0.806, recall=0.952, val_loss=0.98, val_accuracy=0.757, val_auc=0.8, val_precision=0.415, val_recall=0.707, lr=0.000461]  60%|██████    | 54/90 [9:59:35<6:37:58, 663.29s/epoch, loss=0.193, accuracy=0.955, auc=0.992, precision=0.836, recall=0.96, val_loss=1.68, val_accuracy=0.846, val_auc=0.762, val_precision=0.66, val_recall=0.382, lr=0.000461] 61%|██████    | 55/90 [10:10:37<6:26:45, 663.02s/epoch, loss=0.208, accuracy=0.949, auc=0.99, precision=0.818, recall=0.953, val_loss=1.76, val_accuracy=0.851, val_auc=0.753, val_precision=0.735, val_recall=0.33, lr=0.000461] 62%|██████▏   | 56/90 [10:21:40<6:15:37, 662.87s/epoch, loss=0.192, accuracy=0.956, auc=0.993, precision=0.841, recall=0.959, val_loss=1.1, val_accuracy=0.8, val_auc=0.788, val_precision=0.475, val_recall=0.594, lr=0.000461]  63%|██████▎   | 57/90 [10:32:41<6:04:14, 662.27s/epoch, loss=0.19, accuracy=0.959, auc=0.993, precision=0.849, recall=0.964, val_loss=1.47, val_accuracy=0.817, val_auc=0.767, val_precision=0.514, val_recall=0.535, lr=0.000461] 64%|██████▍   | 58/90 [10:43:43<5:53:15, 662.37s/epoch, loss=0.187, accuracy=0.961, auc=0.994, precision=0.857, recall=0.962, val_loss=1.55, val_accuracy=0.837, val_auc=0.752, val_precision=0.601, val_recall=0.397, lr=0.000461] 66%|██████▌   | 59/90 [10:54:44<5:41:56, 661.81s/epoch, loss=0.184, accuracy=0.962, auc=0.994, precision=0.858, recall=0.964, val_loss=1.26, val_accuracy=0.629, val_auc=0.789, val_precision=0.314, val_recall=0.813, lr=0.000461] 67%|██████▋   | 60/90 [11:05:46<5:31:00, 662.01s/epoch, loss=0.175, accuracy=0.968, auc=0.995, precision=0.88, recall=0.97, val_loss=1.22, val_accuracy=0.763, val_auc=0.798, val_precision=0.423, val_recall=0.699, lr=0.000461]   68%|██████▊   | 61/90 [11:16:44<5:19:20, 660.71s/epoch, loss=0.145, accuracy=0.981, auc=0.998, precision=0.921, recall=0.985, val_loss=1.54, val_accuracy=0.848, val_auc=0.79, val_precision=0.617, val_recall=0.506, lr=9.23e-5] 69%|██████▉   | 62/90 [11:27:45<5:08:25, 660.92s/epoch, loss=0.105, accuracy=0.997, auc=1, precision=0.985, recall=0.999, val_loss=1.61, val_accuracy=0.843, val_auc=0.793, val_precision=0.593, val_recall=0.536, lr=9.23e-5]    70%|███████   | 63/90 [11:38:50<4:57:52, 661.95s/epoch, loss=0.0978, accuracy=0.999, auc=1, precision=0.995, recall=1, val_loss=1.7, val_accuracy=0.843, val_auc=0.792, val_precision=0.591, val_recall=0.539, lr=9.23e-5]     71%|███████   | 64/90 [11:49:53<4:46:58, 662.26s/epoch, loss=0.0951, accuracy=0.999, auc=1, precision=0.996, recall=1, val_loss=1.83, val_accuracy=0.846, val_auc=0.788, val_precision=0.608, val_recall=0.521, lr=9.23e-5] 72%|███████▏  | 65/90 [12:00:55<4:35:54, 662.20s/epoch, loss=0.0936, accuracy=0.999, auc=1, precision=0.997, recall=1, val_loss=1.94, val_accuracy=0.848, val_auc=0.785, val_precision=0.617, val_recall=0.51, lr=9.23e-5]  73%|███████▎  | 66/90 [12:11:57<4:24:54, 662.27s/epoch, loss=0.0919, accuracy=1, auc=1, precision=0.999, recall=1, val_loss=2.11, val_accuracy=0.852, val_auc=0.78, val_precision=0.637, val_recall=0.494, lr=9.23e-5]     74%|███████▍  | 67/90 [12:22:58<4:13:38, 661.68s/epoch, loss=0.0912, accuracy=1, auc=1, precision=0.999, recall=1, val_loss=2.05, val_accuracy=0.848, val_auc=0.783, val_precision=0.616, val_recall=0.52, lr=9.23e-5] 76%|███████▌  | 68/90 [12:34:00<4:02:44, 662.00s/epoch, loss=0.0901, accuracy=1, auc=1, precision=0.999, recall=1, val_loss=2.04, val_accuracy=0.846, val_auc=0.784, val_precision=0.602, val_recall=0.537, lr=9.23e-5] 77%|███████▋  | 69/90 [12:45:02<3:51:41, 661.99s/epoch, loss=0.0894, accuracy=1, auc=1, precision=0.999, recall=1, val_loss=2.08, val_accuracy=0.847, val_auc=0.787, val_precision=0.609, val_recall=0.535, lr=9.23e-5] 78%|███████▊  | 70/90 [12:56:01<3:40:23, 661.16s/epoch, loss=0.0889, accuracy=1, auc=1, precision=0.999, recall=1, val_loss=2.16, val_accuracy=0.845, val_auc=0.781, val_precision=0.602, val_recall=0.523, lr=9.23e-5] 79%|███████▉  | 71/90 [13:07:04<3:29:28, 661.48s/epoch, loss=0.0883, accuracy=1, auc=1, precision=1, recall=1, val_loss=2.02, val_accuracy=0.839, val_auc=0.788, val_precision=0.576, val_recall=0.565, lr=9.23e-5]     80%|████████  | 72/90 [13:18:06<3:18:31, 661.77s/epoch, loss=0.088, accuracy=1, auc=1, precision=0.999, recall=1, val_loss=2.13, val_accuracy=0.843, val_auc=0.784, val_precision=0.59, val_recall=0.547, lr=9.23e-5] 81%|████████  | 73/90 [13:29:09<3:07:35, 662.08s/epoch, loss=0.0873, accuracy=1, auc=1, precision=0.999, recall=1, val_loss=2.19, val_accuracy=0.844, val_auc=0.782, val_precision=0.597, val_recall=0.539, lr=9.23e-5] 82%|████████▏ | 74/90 [13:40:10<2:56:28, 661.77s/epoch, loss=0.0869, accuracy=1, auc=1, precision=1, recall=1, val_loss=2.16, val_accuracy=0.842, val_auc=0.781, val_precision=0.586, val_recall=0.552, lr=9.23e-5]     83%|████████▎ | 75/90 [13:51:12<2:45:27, 661.86s/epoch, loss=0.0863, accuracy=1, auc=1, precision=0.999, recall=1, val_loss=2.34, val_accuracy=0.849, val_auc=0.777, val_precision=0.618, val_recall=0.518, lr=9.23e-5] 84%|████████▍ | 76/90 [14:02:14<2:34:26, 661.90s/epoch, loss=0.0862, accuracy=1, auc=1, precision=0.999, recall=1, val_loss=2.27, val_accuracy=0.848, val_auc=0.78, val_precision=0.61, val_recall=0.531, lr=9.23e-5]   86%|████████▌ | 77/90 [14:13:12<2:23:09, 660.74s/epoch, loss=0.0853, accuracy=1, auc=1, precision=1, recall=1, val_loss=2.28, val_accuracy=0.846, val_auc=0.781, val_precision=0.604, val_recall=0.535, lr=9.23e-5]   87%|████████▋ | 78/90 [14:24:26<2:12:55, 664.63s/epoch, loss=0.085, accuracy=1, auc=1, precision=1, recall=1, val_loss=2.21, val_accuracy=0.844, val_auc=0.786, val_precision=0.591, val_recall=0.561, lr=9.23e-5]  88%|████████▊ | 79/90 [14:35:29<2:01:47, 664.28s/epoch, loss=0.0845, accuracy=1, auc=1, precision=1, recall=1, val_loss=2.37, val_accuracy=0.847, val_auc=0.776, val_precision=0.611, val_recall=0.524, lr=9.23e-5] 89%|████████▉ | 80/90 [14:46:31<1:50:34, 663.48s/epoch, loss=0.0841, accuracy=1, auc=1, precision=1, recall=1, val_loss=2.54, val_accuracy=0.85, val_auc=0.77, val_precision=0.631, val_recall=0.492, lr=9.23e-5]   90%|█████████ | 81/90 [14:57:28<1:39:14, 661.65s/epoch, loss=0.0838, accuracy=1, auc=1, precision=1, recall=1, val_loss=2.61, val_accuracy=0.851, val_auc=0.771, val_precision=0.637, val_recall=0.487, lr=9.23e-5] 91%|█████████ | 82/90 [15:08:31<1:28:16, 662.02s/epoch, loss=0.0833, accuracy=1, auc=1, precision=1, recall=1, val_loss=2.65, val_accuracy=0.85, val_auc=0.766, val_precision=0.637, val_recall=0.475, lr=9.23e-5]  92%|█████████▏| 83/90 [15:19:34<1:17:15, 662.25s/epoch, loss=0.0832, accuracy=1, auc=1, precision=1, recall=1, val_loss=2.6, val_accuracy=0.852, val_auc=0.771, val_precision=0.636, val_recall=0.496, lr=9.23e-5] 93%|█████████▎| 84/90 [15:31:00<1:06:56, 669.36s/epoch, loss=0.0827, accuracy=1, auc=1, precision=1, recall=1, val_loss=2.42, val_accuracy=0.844, val_auc=0.774, val_precision=0.597, val_recall=0.532, lr=9.23e-5] 94%|█████████▍| 85/90 [15:42:04<55:38, 667.64s/epoch, loss=0.082, accuracy=1, auc=1, precision=1, recall=1, val_loss=2.49, val_accuracy=0.848, val_auc=0.774, val_precision=0.612, val_recall=0.53, lr=9.23e-5]     96%|█████████▌| 86/90 [15:53:03<44:20, 665.09s/epoch, loss=0.0819, accuracy=1, auc=1, precision=1, recall=1, val_loss=2.38, val_accuracy=0.845, val_auc=0.782, val_precision=0.595, val_recall=0.557, lr=9.23e-5] 97%|█████████▋| 87/90 [16:04:05<33:13, 664.37s/epoch, loss=0.0814, accuracy=1, auc=1, precision=1, recall=1, val_loss=2.59, val_accuracy=0.85, val_auc=0.769, val_precision=0.623, val_recall=0.511, lr=9.23e-5]  98%|█████████▊| 88/90 [16:15:08<22:07, 663.74s/epoch, loss=0.081, accuracy=1, auc=1, precision=1, recall=1, val_loss=2.59, val_accuracy=0.849, val_auc=0.772, val_precision=0.62, val_recall=0.511, lr=9.23e-5]  99%|█████████▉| 89/90 [16:26:38<11:11, 671.72s/epoch, loss=0.0809, accuracy=1, auc=1, precision=0.999, recall=1, val_loss=2.59, val_accuracy=0.848, val_auc=0.773, val_precision=0.619, val_recall=0.509, lr=9.23e-5]100%|██████████| 90/90 [16:37:50<00:00, 671.93s/epoch, loss=0.0803, accuracy=1, auc=1, precision=1, recall=1, val_loss=2.53, val_accuracy=0.848, val_auc=0.775, val_precision=0.612, val_recall=0.524, lr=9.23e-5]    100%|██████████| 90/90 [16:37:50<00:00, 665.23s/epoch, loss=0.0803, accuracy=1, auc=1, precision=1, recall=1, val_loss=2.53, val_accuracy=0.848, val_auc=0.775, val_precision=0.612, val_recall=0.524, lr=9.23e-5]
Traceback (most recent call last):
  File "/home/gkb738/.conda/envs/TF_KERAS_GPU/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/gkb738/.conda/envs/TF_KERAS_GPU/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/gkb738/MSc-Thesis/ResNet20_CIFAR/sgd_baseline.py", line 378, in <module>
    score, acc = model.evaluate(test_loader, verbose=0)
ValueError: too many values to unpack (expected 2)
Only one model saved

Loading model: 08_retinopathy_ResNet50v1.h5
