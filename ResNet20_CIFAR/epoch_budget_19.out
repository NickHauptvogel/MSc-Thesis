Mon Feb 19 23:18:49 2024       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 545.23.08              Driver Version: 545.23.08    CUDA Version: 12.3     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA TITAN X (Pascal)        Off | 00000000:83:00.0 Off |                  N/A |
| 50%   75C    P0              85W / 250W |      0MiB / 12288MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|  No running processes found                                                           |
+---------------------------------------------------------------------------------------+


* * * Run SGD for cluster size = 19. * * *


Budget: 78


* * * Run SGD for ID = 19_1. * * *


2024-02-19 23:18:50.343587: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-19 23:18:53.512620: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-19 23:18:53.513565: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-19 23:18:53.549232: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-19 23:18:53.549261: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-19 23:18:53.552354: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-19 23:18:53.552390: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-19 23:18:53.554684: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-19 23:18:53.555512: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-19 23:18:53.557889: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-19 23:18:53.559484: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-19 23:18:53.566213: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-19 23:18:53.566685: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-19 23:18:53.566764: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-19 23:18:54.964467: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-19 23:18:54.966102: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-19 23:18:54.966805: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-19 23:18:54.966834: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-19 23:18:54.966870: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-19 23:18:54.966886: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-19 23:18:54.966902: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-19 23:18:54.966932: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-19 23:18:54.966947: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-19 23:18:54.966973: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-19 23:18:54.966990: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-19 23:18:54.967433: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-19 23:18:54.967462: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-19 23:18:55.587321: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-19 23:18:55.587374: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-19 23:18:55.587382: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-19 23:18:55.588296: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': '19_01', 'batch_size': 128, 'epochs': 78, 'validation_split': 0.1, 'checkpointing': True, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
x_train shape: (45000, 32, 32, 3)
45000 train samples
5000 validation samples
10000 test samples
y_train shape: (45000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/78 [00:00<?, ?epoch/s]2024-02-19 23:18:56.378247: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-19 23:18:56.390089: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600020000 Hz
2024-02-19 23:18:58.269853: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-19 23:18:58.493377: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-19 23:18:59.158718: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-19 23:18:59.190541: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|▏         | 1/78 [00:48<1:02:14, 48.50s/epoch, loss=3.27, accuracy=0.288, val_loss=2.83, val_accuracy=0.217, lr=0.1]  3%|▎         | 2/78 [01:05<38:18, 30.25s/epoch, loss=1.6, accuracy=0.516, val_loss=2.33, val_accuracy=0.351, lr=0.1]     4%|▍         | 3/78 [01:22<30:10, 24.14s/epoch, loss=1.34, accuracy=0.631, val_loss=4.69, val_accuracy=0.191, lr=0.1]  5%|▌         | 4/78 [01:39<26:21, 21.38s/epoch, loss=1.28, accuracy=0.672, val_loss=1.84, val_accuracy=0.493, lr=0.1]  6%|▋         | 5/78 [01:57<24:06, 19.82s/epoch, loss=1.23, accuracy=0.698, val_loss=1.82, val_accuracy=0.545, lr=0.1]  8%|▊         | 6/78 [02:13<22:31, 18.78s/epoch, loss=1.23, accuracy=0.707, val_loss=2.16, val_accuracy=0.431, lr=0.1]  9%|▉         | 7/78 [02:31<21:38, 18.28s/epoch, loss=1.21, accuracy=0.714, val_loss=2.74, val_accuracy=0.383, lr=0.1] 10%|█         | 8/78 [02:48<20:59, 17.99s/epoch, loss=1.21, accuracy=0.72, val_loss=1.9, val_accuracy=0.549, lr=0.1]   12%|█▏        | 9/78 [03:05<20:18, 17.66s/epoch, loss=1.2, accuracy=0.724, val_loss=1.74, val_accuracy=0.553, lr=0.1] 13%|█▎        | 10/78 [03:22<19:43, 17.40s/epoch, loss=1.19, accuracy=0.729, val_loss=3.32, val_accuracy=0.21, lr=0.1] 14%|█▍        | 11/78 [03:38<19:11, 17.19s/epoch, loss=1.19, accuracy=0.728, val_loss=1.73, val_accuracy=0.53, lr=0.1] 15%|█▌        | 12/78 [03:55<18:45, 17.05s/epoch, loss=1.19, accuracy=0.731, val_loss=2.07, val_accuracy=0.485, lr=0.1] 17%|█▋        | 13/78 [04:12<18:25, 17.01s/epoch, loss=1.19, accuracy=0.734, val_loss=1.45, val_accuracy=0.634, lr=0.1] 18%|█▊        | 14/78 [04:29<18:05, 16.95s/epoch, loss=1.18, accuracy=0.732, val_loss=1.52, val_accuracy=0.616, lr=0.1] 19%|█▉        | 15/78 [04:46<17:42, 16.86s/epoch, loss=1.17, accuracy=0.738, val_loss=3.79, val_accuracy=0.333, lr=0.1] 21%|██        | 16/78 [05:03<17:31, 16.95s/epoch, loss=1.18, accuracy=0.739, val_loss=2.68, val_accuracy=0.412, lr=0.1] 22%|██▏       | 17/78 [05:20<17:14, 16.96s/epoch, loss=1.18, accuracy=0.739, val_loss=1.76, val_accuracy=0.6, lr=0.1]   23%|██▎       | 18/78 [05:37<16:56, 16.94s/epoch, loss=1.17, accuracy=0.741, val_loss=3.11, val_accuracy=0.363, lr=0.0316] 24%|██▍       | 19/78 [05:54<16:40, 16.96s/epoch, loss=1.17, accuracy=0.741, val_loss=1.71, val_accuracy=0.558, lr=0.1]    26%|██▌       | 20/78 [06:11<16:24, 16.98s/epoch, loss=1.16, accuracy=0.743, val_loss=2.59, val_accuracy=0.432, lr=0.1] 27%|██▋       | 21/78 [06:28<16:11, 17.05s/epoch, loss=1.17, accuracy=0.743, val_loss=1.47, val_accuracy=0.637, lr=0.1] 28%|██▊       | 22/78 [06:45<15:51, 16.99s/epoch, loss=1.17, accuracy=0.745, val_loss=1.93, val_accuracy=0.494, lr=0.1] 29%|██▉       | 23/78 [07:02<15:34, 16.99s/epoch, loss=1.16, accuracy=0.743, val_loss=2.21, val_accuracy=0.422, lr=0.0316] 31%|███       | 24/78 [07:18<15:14, 16.93s/epoch, loss=1.15, accuracy=0.747, val_loss=2.31, val_accuracy=0.394, lr=0.1]    32%|███▏      | 25/78 [07:36<14:59, 16.98s/epoch, loss=1.15, accuracy=0.746, val_loss=2.06, val_accuracy=0.518, lr=0.1] 33%|███▎      | 26/78 [07:53<14:44, 17.01s/epoch, loss=1.16, accuracy=0.743, val_loss=1.56, val_accuracy=0.628, lr=0.1] 35%|███▍      | 27/78 [08:10<14:28, 17.04s/epoch, loss=1.16, accuracy=0.747, val_loss=1.74, val_accuracy=0.543, lr=0.1] 36%|███▌      | 28/78 [08:27<14:14, 17.08s/epoch, loss=1.16, accuracy=0.745, val_loss=1.49, val_accuracy=0.634, lr=0.0316] 37%|███▋      | 29/78 [08:44<13:59, 17.13s/epoch, loss=1.15, accuracy=0.751, val_loss=2.73, val_accuracy=0.372, lr=0.1]    38%|███▊      | 30/78 [09:01<13:40, 17.09s/epoch, loss=1.15, accuracy=0.75, val_loss=3.36, val_accuracy=0.311, lr=0.1]  40%|███▉      | 31/78 [09:18<13:16, 16.94s/epoch, loss=1.15, accuracy=0.749, val_loss=1.72, val_accuracy=0.542, lr=0.1] 41%|████      | 32/78 [09:34<12:55, 16.87s/epoch, loss=1.14, accuracy=0.749, val_loss=1.86, val_accuracy=0.537, lr=0.1] 42%|████▏     | 33/78 [09:51<12:37, 16.83s/epoch, loss=1.14, accuracy=0.749, val_loss=2.17, val_accuracy=0.504, lr=0.0316] 44%|████▎     | 34/78 [10:08<12:17, 16.75s/epoch, loss=1.14, accuracy=0.75, val_loss=1.62, val_accuracy=0.613, lr=0.1]     45%|████▍     | 35/78 [10:24<12:00, 16.75s/epoch, loss=1.14, accuracy=0.751, val_loss=2.05, val_accuracy=0.447, lr=0.1] 46%|████▌     | 36/78 [10:41<11:43, 16.76s/epoch, loss=1.14, accuracy=0.75, val_loss=2.13, val_accuracy=0.491, lr=0.1]  47%|████▋     | 37/78 [10:58<11:26, 16.74s/epoch, loss=1.15, accuracy=0.747, val_loss=1.52, val_accuracy=0.626, lr=0.1] 49%|████▊     | 38/78 [11:15<11:07, 16.70s/epoch, loss=1.14, accuracy=0.752, val_loss=1.75, val_accuracy=0.545, lr=0.0316] 50%|█████     | 39/78 [11:31<10:51, 16.71s/epoch, loss=1.14, accuracy=0.752, val_loss=2.08, val_accuracy=0.466, lr=0.1]    51%|█████▏    | 40/78 [11:48<10:38, 16.80s/epoch, loss=1.14, accuracy=0.752, val_loss=1.82, val_accuracy=0.539, lr=0.1] 53%|█████▎    | 41/78 [12:05<10:19, 16.73s/epoch, loss=1.14, accuracy=0.751, val_loss=2.11, val_accuracy=0.527, lr=0.1] 54%|█████▍    | 42/78 [12:22<10:02, 16.73s/epoch, loss=1.14, accuracy=0.753, val_loss=2.21, val_accuracy=0.444, lr=0.1] 55%|█████▌    | 43/78 [12:38<09:42, 16.65s/epoch, loss=1.13, accuracy=0.751, val_loss=1.95, val_accuracy=0.527, lr=0.0316] 56%|█████▋    | 44/78 [12:55<09:27, 16.70s/epoch, loss=1.13, accuracy=0.753, val_loss=2, val_accuracy=0.509, lr=0.1]       58%|█████▊    | 45/78 [13:12<09:11, 16.71s/epoch, loss=1.14, accuracy=0.753, val_loss=1.79, val_accuracy=0.566, lr=0.1] 59%|█████▉    | 46/78 [13:28<08:52, 16.63s/epoch, loss=1.13, accuracy=0.755, val_loss=1.94, val_accuracy=0.481, lr=0.1] 60%|██████    | 47/78 [13:45<08:41, 16.82s/epoch, loss=1.14, accuracy=0.752, val_loss=1.46, val_accuracy=0.652, lr=0.1] 62%|██████▏   | 48/78 [14:02<08:22, 16.74s/epoch, loss=1.13, accuracy=0.753, val_loss=2.09, val_accuracy=0.509, lr=0.0316] 63%|██████▎   | 49/78 [14:19<08:04, 16.72s/epoch, loss=1.14, accuracy=0.751, val_loss=2.6, val_accuracy=0.416, lr=0.1]     64%|██████▍   | 50/78 [14:35<07:49, 16.79s/epoch, loss=1.14, accuracy=0.752, val_loss=5.42, val_accuracy=0.235, lr=0.1] 65%|██████▌   | 51/78 [14:52<07:30, 16.67s/epoch, loss=1.13, accuracy=0.754, val_loss=2.36, val_accuracy=0.449, lr=0.1] 67%|██████▋   | 52/78 [15:09<07:13, 16.68s/epoch, loss=1.14, accuracy=0.752, val_loss=2.68, val_accuracy=0.402, lr=0.1] 68%|██████▊   | 53/78 [15:25<06:58, 16.75s/epoch, loss=1.13, accuracy=0.755, val_loss=3.21, val_accuracy=0.336, lr=0.0316] 69%|██████▉   | 54/78 [15:42<06:42, 16.77s/epoch, loss=1.13, accuracy=0.752, val_loss=2.26, val_accuracy=0.448, lr=0.1]    71%|███████   | 55/78 [15:59<06:25, 16.74s/epoch, loss=1.14, accuracy=0.752, val_loss=2.81, val_accuracy=0.413, lr=0.1] 72%|███████▏  | 56/78 [16:16<06:09, 16.78s/epoch, loss=1.13, accuracy=0.755, val_loss=1.34, val_accuracy=0.691, lr=0.1] 73%|███████▎  | 57/78 [16:32<05:50, 16.67s/epoch, loss=1.13, accuracy=0.754, val_loss=3.06, val_accuracy=0.369, lr=0.1] 74%|███████▍  | 58/78 [16:49<05:35, 16.78s/epoch, loss=1.13, accuracy=0.754, val_loss=2.35, val_accuracy=0.436, lr=0.1] 76%|███████▌  | 59/78 [17:06<05:19, 16.79s/epoch, loss=1.13, accuracy=0.754, val_loss=3.22, val_accuracy=0.311, lr=0.1] 77%|███████▋  | 60/78 [17:23<05:01, 16.72s/epoch, loss=1.13, accuracy=0.751, val_loss=1.85, val_accuracy=0.563, lr=0.1] 78%|███████▊  | 61/78 [17:39<04:44, 16.75s/epoch, loss=1.13, accuracy=0.755, val_loss=4.03, val_accuracy=0.242, lr=0.0316] 79%|███████▉  | 62/78 [17:56<04:26, 16.66s/epoch, loss=1.13, accuracy=0.754, val_loss=2.09, val_accuracy=0.486, lr=0.1]    81%|████████  | 63/78 [18:13<04:09, 16.66s/epoch, loss=1.13, accuracy=0.754, val_loss=1.7, val_accuracy=0.559, lr=0.1]  82%|████████▏ | 64/78 [18:29<03:53, 16.71s/epoch, loss=1.13, accuracy=0.757, val_loss=1.74, val_accuracy=0.561, lr=0.1] 83%|████████▎ | 65/78 [18:46<03:37, 16.70s/epoch, loss=1.14, accuracy=0.753, val_loss=2.65, val_accuracy=0.437, lr=0.1] 85%|████████▍ | 66/78 [19:03<03:20, 16.70s/epoch, loss=1.14, accuracy=0.753, val_loss=1.66, val_accuracy=0.569, lr=0.0316] 86%|████████▌ | 67/78 [19:19<03:03, 16.65s/epoch, loss=1.13, accuracy=0.754, val_loss=1.84, val_accuracy=0.535, lr=0.1]    87%|████████▋ | 68/78 [19:36<02:46, 16.60s/epoch, loss=1.13, accuracy=0.756, val_loss=1.67, val_accuracy=0.566, lr=0.1] 88%|████████▊ | 69/78 [19:53<02:29, 16.66s/epoch, loss=1.13, accuracy=0.755, val_loss=1.56, val_accuracy=0.579, lr=0.1] 90%|████████▉ | 70/78 [20:09<02:12, 16.56s/epoch, loss=1.13, accuracy=0.754, val_loss=2.12, val_accuracy=0.444, lr=0.1] 91%|█████████ | 71/78 [20:25<01:55, 16.54s/epoch, loss=1.12, accuracy=0.753, val_loss=3.51, val_accuracy=0.309, lr=0.0316] 92%|█████████▏| 72/78 [20:42<01:39, 16.53s/epoch, loss=1.13, accuracy=0.756, val_loss=2.29, val_accuracy=0.444, lr=0.1]    94%|█████████▎| 73/78 [20:59<01:22, 16.55s/epoch, loss=1.12, accuracy=0.759, val_loss=1.89, val_accuracy=0.539, lr=0.1] 95%|█████████▍| 74/78 [21:15<01:06, 16.56s/epoch, loss=1.13, accuracy=0.756, val_loss=2, val_accuracy=0.525, lr=0.1]    96%|█████████▌| 75/78 [21:32<00:49, 16.63s/epoch, loss=1.13, accuracy=0.755, val_loss=1.83, val_accuracy=0.53, lr=0.1] 97%|█████████▋| 76/78 [21:49<00:33, 16.69s/epoch, loss=1.13, accuracy=0.755, val_loss=1.64, val_accuracy=0.596, lr=0.0316] 99%|█████████▊| 77/78 [22:06<00:16, 16.71s/epoch, loss=1.12, accuracy=0.756, val_loss=2.54, val_accuracy=0.407, lr=0.1]   100%|██████████| 78/78 [22:22<00:00, 16.68s/epoch, loss=1.13, accuracy=0.752, val_loss=1.84, val_accuracy=0.508, lr=0.1]100%|██████████| 78/78 [22:22<00:00, 17.21s/epoch, loss=1.13, accuracy=0.752, val_loss=1.84, val_accuracy=0.508, lr=0.1]
Using real-time data augmentation.
Test score: 1.3607836961746216
Test accuracy: 0.6776999831199646


* * * Run SGD for ID = 19_2. * * *


2024-02-19 23:41:23.964696: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-19 23:41:28.164192: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-19 23:41:28.165146: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-19 23:41:28.201155: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-19 23:41:28.201186: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-19 23:41:28.205308: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-19 23:41:28.205346: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-19 23:41:28.208875: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-19 23:41:28.210501: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-19 23:41:28.214055: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-19 23:41:28.216093: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-19 23:41:28.222153: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-19 23:41:28.222677: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-19 23:41:28.222752: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-19 23:41:29.621689: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-19 23:41:29.622674: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-19 23:41:29.623433: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-19 23:41:29.623461: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-19 23:41:29.623496: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-19 23:41:29.623512: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-19 23:41:29.623527: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-19 23:41:29.623543: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-19 23:41:29.623557: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-19 23:41:29.623571: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-19 23:41:29.623585: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-19 23:41:29.624026: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-19 23:41:29.624063: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-19 23:41:30.220470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-19 23:41:30.220522: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-19 23:41:30.220531: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-19 23:41:30.221449: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': '19_02', 'batch_size': 128, 'epochs': 78, 'validation_split': 0.1, 'checkpointing': True, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
x_train shape: (45000, 32, 32, 3)
45000 train samples
5000 validation samples
10000 test samples
y_train shape: (45000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/78 [00:00<?, ?epoch/s]2024-02-19 23:41:31.005247: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-19 23:41:31.017091: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600020000 Hz
2024-02-19 23:41:32.874300: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-19 23:41:33.123137: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-19 23:41:33.756703: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-19 23:41:33.794631: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|▏         | 1/78 [00:45<58:53, 45.89s/epoch, loss=3.35, accuracy=0.307, val_loss=2.25, val_accuracy=0.315, lr=0.1]  3%|▎         | 2/78 [01:02<36:35, 28.88s/epoch, loss=1.65, accuracy=0.503, val_loss=2.29, val_accuracy=0.356, lr=0.1]  4%|▍         | 3/78 [01:19<29:05, 23.28s/epoch, loss=1.45, accuracy=0.593, val_loss=1.69, val_accuracy=0.518, lr=0.1]  5%|▌         | 4/78 [01:35<25:24, 20.61s/epoch, loss=1.34, accuracy=0.658, val_loss=2.12, val_accuracy=0.472, lr=0.1]  6%|▋         | 5/78 [01:52<23:22, 19.22s/epoch, loss=1.29, accuracy=0.687, val_loss=3.38, val_accuracy=0.31, lr=0.1]   8%|▊         | 6/78 [02:09<22:05, 18.41s/epoch, loss=1.26, accuracy=0.701, val_loss=1.77, val_accuracy=0.572, lr=0.1]  9%|▉         | 7/78 [02:26<21:08, 17.87s/epoch, loss=1.24, accuracy=0.712, val_loss=1.87, val_accuracy=0.51, lr=0.1]  10%|█         | 8/78 [02:43<20:31, 17.60s/epoch, loss=1.23, accuracy=0.717, val_loss=1.57, val_accuracy=0.597, lr=0.1] 12%|█▏        | 9/78 [03:00<19:55, 17.32s/epoch, loss=1.22, accuracy=0.72, val_loss=1.54, val_accuracy=0.615, lr=0.1]  13%|█▎        | 10/78 [03:16<19:24, 17.13s/epoch, loss=1.2, accuracy=0.729, val_loss=1.71, val_accuracy=0.549, lr=0.1] 14%|█▍        | 11/78 [03:33<18:51, 16.89s/epoch, loss=1.2, accuracy=0.732, val_loss=2.37, val_accuracy=0.402, lr=0.1] 15%|█▌        | 12/78 [03:49<18:33, 16.88s/epoch, loss=1.19, accuracy=0.734, val_loss=1.53, val_accuracy=0.62, lr=0.1] 17%|█▋        | 13/78 [04:06<18:10, 16.78s/epoch, loss=1.19, accuracy=0.738, val_loss=1.56, val_accuracy=0.605, lr=0.1] 18%|█▊        | 14/78 [04:23<17:51, 16.74s/epoch, loss=1.19, accuracy=0.737, val_loss=2.94, val_accuracy=0.249, lr=0.1] 19%|█▉        | 15/78 [04:39<17:33, 16.72s/epoch, loss=1.19, accuracy=0.736, val_loss=2.79, val_accuracy=0.374, lr=0.1] 21%|██        | 16/78 [04:56<17:20, 16.78s/epoch, loss=1.19, accuracy=0.739, val_loss=2.11, val_accuracy=0.523, lr=0.1] 22%|██▏       | 17/78 [05:13<17:06, 16.82s/epoch, loss=1.18, accuracy=0.741, val_loss=2.14, val_accuracy=0.454, lr=0.0316] 23%|██▎       | 18/78 [05:30<16:50, 16.85s/epoch, loss=1.18, accuracy=0.742, val_loss=2.12, val_accuracy=0.488, lr=0.1]    24%|██▍       | 19/78 [05:47<16:30, 16.80s/epoch, loss=1.18, accuracy=0.745, val_loss=1.99, val_accuracy=0.492, lr=0.1] 26%|██▌       | 20/78 [06:04<16:14, 16.80s/epoch, loss=1.18, accuracy=0.744, val_loss=3.7, val_accuracy=0.326, lr=0.1]  27%|██▋       | 21/78 [06:21<16:03, 16.91s/epoch, loss=1.18, accuracy=0.743, val_loss=2.42, val_accuracy=0.419, lr=0.1] 28%|██▊       | 22/78 [06:37<15:42, 16.82s/epoch, loss=1.16, accuracy=0.747, val_loss=1.68, val_accuracy=0.576, lr=0.0316] 29%|██▉       | 23/78 [06:54<15:26, 16.85s/epoch, loss=1.17, accuracy=0.749, val_loss=1.7, val_accuracy=0.584, lr=0.1]     31%|███       | 24/78 [07:12<15:23, 17.10s/epoch, loss=1.17, accuracy=0.743, val_loss=1.55, val_accuracy=0.644, lr=0.1] 32%|███▏      | 25/78 [07:29<15:06, 17.10s/epoch, loss=1.16, accuracy=0.75, val_loss=1.67, val_accuracy=0.582, lr=0.1]  33%|███▎      | 26/78 [07:46<14:46, 17.05s/epoch, loss=1.16, accuracy=0.747, val_loss=2.05, val_accuracy=0.47, lr=0.1] 35%|███▍      | 27/78 [08:03<14:28, 17.03s/epoch, loss=1.16, accuracy=0.75, val_loss=1.58, val_accuracy=0.595, lr=0.0316] 36%|███▌      | 28/78 [08:20<14:08, 16.96s/epoch, loss=1.16, accuracy=0.749, val_loss=1.55, val_accuracy=0.622, lr=0.1]   37%|███▋      | 29/78 [08:37<13:54, 17.03s/epoch, loss=1.17, accuracy=0.747, val_loss=2.32, val_accuracy=0.338, lr=0.1] 38%|███▊      | 30/78 [08:54<13:40, 17.10s/epoch, loss=1.16, accuracy=0.749, val_loss=1.67, val_accuracy=0.572, lr=0.1] 40%|███▉      | 31/78 [09:11<13:22, 17.07s/epoch, loss=1.17, accuracy=0.749, val_loss=1.5, val_accuracy=0.629, lr=0.1]  41%|████      | 32/78 [09:29<13:08, 17.15s/epoch, loss=1.16, accuracy=0.751, val_loss=1.78, val_accuracy=0.592, lr=0.1] 42%|████▏     | 33/78 [09:45<12:48, 17.08s/epoch, loss=1.16, accuracy=0.748, val_loss=2.63, val_accuracy=0.374, lr=0.1] 44%|████▎     | 34/78 [10:02<12:29, 17.03s/epoch, loss=1.15, accuracy=0.749, val_loss=1.68, val_accuracy=0.579, lr=0.1] 45%|████▍     | 35/78 [10:19<12:09, 16.96s/epoch, loss=1.16, accuracy=0.749, val_loss=1.79, val_accuracy=0.547, lr=0.1] 46%|████▌     | 36/78 [10:36<11:49, 16.90s/epoch, loss=1.15, accuracy=0.749, val_loss=1.64, val_accuracy=0.6, lr=0.0316] 47%|████▋     | 37/78 [10:53<11:31, 16.87s/epoch, loss=1.16, accuracy=0.749, val_loss=1.99, val_accuracy=0.441, lr=0.1]  49%|████▊     | 38/78 [11:10<11:17, 16.94s/epoch, loss=1.15, accuracy=0.752, val_loss=2.14, val_accuracy=0.457, lr=0.1] 50%|█████     | 39/78 [11:27<11:04, 17.04s/epoch, loss=1.15, accuracy=0.752, val_loss=1.99, val_accuracy=0.539, lr=0.1] 51%|█████▏    | 40/78 [11:44<10:46, 17.01s/epoch, loss=1.15, accuracy=0.751, val_loss=2.29, val_accuracy=0.429, lr=0.1] 53%|█████▎    | 41/78 [12:01<10:28, 16.98s/epoch, loss=1.15, accuracy=0.752, val_loss=1.73, val_accuracy=0.556, lr=0.0316] 54%|█████▍    | 42/78 [12:18<10:14, 17.06s/epoch, loss=1.15, accuracy=0.751, val_loss=2.25, val_accuracy=0.438, lr=0.1]    55%|█████▌    | 43/78 [12:35<09:55, 17.02s/epoch, loss=1.15, accuracy=0.752, val_loss=2.11, val_accuracy=0.474, lr=0.1] 56%|█████▋    | 44/78 [12:52<09:36, 16.95s/epoch, loss=1.15, accuracy=0.752, val_loss=2.23, val_accuracy=0.464, lr=0.1] 58%|█████▊    | 45/78 [13:09<09:22, 17.06s/epoch, loss=1.15, accuracy=0.752, val_loss=1.58, val_accuracy=0.586, lr=0.1] 59%|█████▉    | 46/78 [13:26<09:04, 17.02s/epoch, loss=1.14, accuracy=0.753, val_loss=1.7, val_accuracy=0.559, lr=0.0316] 60%|██████    | 47/78 [13:43<08:46, 16.98s/epoch, loss=1.14, accuracy=0.752, val_loss=2.57, val_accuracy=0.445, lr=0.1]   62%|██████▏   | 48/78 [14:00<08:31, 17.05s/epoch, loss=1.14, accuracy=0.755, val_loss=2.41, val_accuracy=0.427, lr=0.1] 63%|██████▎   | 49/78 [14:17<08:13, 17.03s/epoch, loss=1.14, accuracy=0.752, val_loss=2.36, val_accuracy=0.366, lr=0.1] 64%|██████▍   | 50/78 [14:34<07:57, 17.06s/epoch, loss=1.14, accuracy=0.755, val_loss=1.47, val_accuracy=0.648, lr=0.1] 65%|██████▌   | 51/78 [14:51<07:38, 16.98s/epoch, loss=1.14, accuracy=0.752, val_loss=2, val_accuracy=0.503, lr=0.1]    67%|██████▋   | 52/78 [15:08<07:21, 17.00s/epoch, loss=1.14, accuracy=0.756, val_loss=2.09, val_accuracy=0.51, lr=0.1] 68%|██████▊   | 53/78 [15:25<07:05, 17.03s/epoch, loss=1.14, accuracy=0.756, val_loss=1.8, val_accuracy=0.528, lr=0.1] 69%|██████▉   | 54/78 [15:42<06:49, 17.05s/epoch, loss=1.14, accuracy=0.753, val_loss=1.54, val_accuracy=0.605, lr=0.1] 71%|███████   | 55/78 [16:00<06:32, 17.07s/epoch, loss=1.15, accuracy=0.751, val_loss=2.16, val_accuracy=0.494, lr=0.0316] 72%|███████▏  | 56/78 [16:16<06:13, 16.98s/epoch, loss=1.14, accuracy=0.754, val_loss=1.54, val_accuracy=0.612, lr=0.1]    73%|███████▎  | 57/78 [16:33<05:56, 16.96s/epoch, loss=1.14, accuracy=0.754, val_loss=1.94, val_accuracy=0.518, lr=0.1] 74%|███████▍  | 58/78 [16:50<05:39, 16.97s/epoch, loss=1.14, accuracy=0.754, val_loss=1.56, val_accuracy=0.613, lr=0.1] 76%|███████▌  | 59/78 [17:07<05:21, 16.93s/epoch, loss=1.14, accuracy=0.753, val_loss=1.73, val_accuracy=0.542, lr=0.1] 77%|███████▋  | 60/78 [17:24<05:04, 16.94s/epoch, loss=1.14, accuracy=0.749, val_loss=1.57, val_accuracy=0.605, lr=0.0316] 78%|███████▊  | 61/78 [17:41<04:48, 16.96s/epoch, loss=1.13, accuracy=0.755, val_loss=1.86, val_accuracy=0.512, lr=0.1]    79%|███████▉  | 62/78 [17:58<04:31, 16.97s/epoch, loss=1.14, accuracy=0.753, val_loss=1.97, val_accuracy=0.493, lr=0.1] 81%|████████  | 63/78 [18:15<04:15, 17.01s/epoch, loss=1.14, accuracy=0.751, val_loss=2.58, val_accuracy=0.401, lr=0.1] 82%|████████▏ | 64/78 [18:32<03:58, 17.03s/epoch, loss=1.13, accuracy=0.757, val_loss=2.91, val_accuracy=0.397, lr=0.1] 83%|████████▎ | 65/78 [18:49<03:40, 16.95s/epoch, loss=1.13, accuracy=0.757, val_loss=8.05, val_accuracy=0.169, lr=0.0316] 85%|████████▍ | 66/78 [19:06<03:22, 16.90s/epoch, loss=1.14, accuracy=0.754, val_loss=1.72, val_accuracy=0.571, lr=0.1]    86%|████████▌ | 67/78 [19:23<03:06, 16.92s/epoch, loss=1.13, accuracy=0.755, val_loss=4.98, val_accuracy=0.27, lr=0.1]  87%|████████▋ | 68/78 [19:40<02:49, 16.97s/epoch, loss=1.13, accuracy=0.752, val_loss=1.64, val_accuracy=0.598, lr=0.1] 88%|████████▊ | 69/78 [19:57<02:32, 16.98s/epoch, loss=1.14, accuracy=0.754, val_loss=1.96, val_accuracy=0.484, lr=0.1] 90%|████████▉ | 70/78 [20:14<02:15, 16.97s/epoch, loss=1.14, accuracy=0.754, val_loss=2.37, val_accuracy=0.442, lr=0.0316] 91%|█████████ | 71/78 [20:31<01:58, 16.93s/epoch, loss=1.14, accuracy=0.755, val_loss=1.55, val_accuracy=0.622, lr=0.1]    92%|█████████▏| 72/78 [20:48<01:41, 16.97s/epoch, loss=1.14, accuracy=0.756, val_loss=2.83, val_accuracy=0.377, lr=0.1] 94%|█████████▎| 73/78 [21:04<01:24, 16.91s/epoch, loss=1.13, accuracy=0.755, val_loss=4.22, val_accuracy=0.216, lr=0.1] 95%|█████████▍| 74/78 [21:21<01:07, 16.94s/epoch, loss=1.14, accuracy=0.752, val_loss=2.11, val_accuracy=0.473, lr=0.1] 96%|█████████▌| 75/78 [21:38<00:50, 16.89s/epoch, loss=1.13, accuracy=0.751, val_loss=2.42, val_accuracy=0.413, lr=0.0316] 97%|█████████▋| 76/78 [21:55<00:33, 16.85s/epoch, loss=1.13, accuracy=0.757, val_loss=2.23, val_accuracy=0.493, lr=0.1]    99%|█████████▊| 77/78 [22:12<00:16, 16.96s/epoch, loss=1.13, accuracy=0.755, val_loss=2.59, val_accuracy=0.358, lr=0.1]100%|██████████| 78/78 [22:29<00:00, 16.96s/epoch, loss=1.13, accuracy=0.757, val_loss=3.83, val_accuracy=0.28, lr=0.1] 100%|██████████| 78/78 [22:29<00:00, 17.30s/epoch, loss=1.13, accuracy=0.757, val_loss=3.83, val_accuracy=0.28, lr=0.1]
Using real-time data augmentation.
Test score: 1.4622950553894043
Test accuracy: 0.6557999849319458


* * * Run SGD for ID = 19_3. * * *


2024-02-20 00:04:07.402671: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 00:04:09.805729: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 00:04:09.806564: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-20 00:04:09.841576: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-20 00:04:09.841611: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 00:04:09.844021: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 00:04:09.844066: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-20 00:04:09.846001: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-20 00:04:09.846588: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-20 00:04:09.848701: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-20 00:04:09.850008: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-20 00:04:09.854115: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 00:04:09.854617: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-20 00:04:09.854692: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 00:04:11.281727: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-20 00:04:11.282734: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 00:04:11.283446: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-20 00:04:11.283476: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 00:04:11.283509: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 00:04:11.283525: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-20 00:04:11.283540: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-20 00:04:11.283557: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-20 00:04:11.283572: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-20 00:04:11.283590: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-20 00:04:11.283605: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 00:04:11.284033: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-20 00:04:11.284064: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 00:04:11.881157: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-20 00:04:11.881210: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-20 00:04:11.881218: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-20 00:04:11.882057: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': '19_03', 'batch_size': 128, 'epochs': 78, 'validation_split': 0.1, 'checkpointing': True, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
x_train shape: (45000, 32, 32, 3)
45000 train samples
5000 validation samples
10000 test samples
y_train shape: (45000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/78 [00:00<?, ?epoch/s]2024-02-20 00:04:12.662207: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-20 00:04:12.674086: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600020000 Hz
2024-02-20 00:04:14.512577: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 00:04:14.788121: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 00:04:15.395711: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-20 00:04:15.431313: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|▏         | 1/78 [00:44<57:39, 44.93s/epoch, loss=3.33, accuracy=0.289, val_loss=2.79, val_accuracy=0.199, lr=0.1]  3%|▎         | 2/78 [01:02<36:46, 29.04s/epoch, loss=1.68, accuracy=0.475, val_loss=2.15, val_accuracy=0.305, lr=0.1]  4%|▍         | 3/78 [01:20<29:53, 23.91s/epoch, loss=1.44, accuracy=0.592, val_loss=1.6, val_accuracy=0.541, lr=0.1]   5%|▌         | 4/78 [01:37<26:03, 21.13s/epoch, loss=1.32, accuracy=0.664, val_loss=3.87, val_accuracy=0.199, lr=0.1]  6%|▋         | 5/78 [01:55<24:08, 19.84s/epoch, loss=1.27, accuracy=0.691, val_loss=1.49, val_accuracy=0.621, lr=0.1]  8%|▊         | 6/78 [02:12<22:46, 18.97s/epoch, loss=1.25, accuracy=0.707, val_loss=2.02, val_accuracy=0.458, lr=0.1]  9%|▉         | 7/78 [02:29<21:47, 18.41s/epoch, loss=1.23, accuracy=0.717, val_loss=1.63, val_accuracy=0.564, lr=0.1] 10%|█         | 8/78 [02:46<20:54, 17.92s/epoch, loss=1.22, accuracy=0.723, val_loss=1.62, val_accuracy=0.589, lr=0.1] 12%|█▏        | 9/78 [03:03<20:20, 17.69s/epoch, loss=1.22, accuracy=0.728, val_loss=1.65, val_accuracy=0.57, lr=0.1]  13%|█▎        | 10/78 [03:20<19:48, 17.48s/epoch, loss=1.21, accuracy=0.732, val_loss=2.06, val_accuracy=0.458, lr=0.0316] 14%|█▍        | 11/78 [03:37<19:17, 17.28s/epoch, loss=1.21, accuracy=0.732, val_loss=1.67, val_accuracy=0.539, lr=0.1]    15%|█▌        | 12/78 [03:54<18:58, 17.25s/epoch, loss=1.2, accuracy=0.735, val_loss=1.54, val_accuracy=0.611, lr=0.1]  17%|█▋        | 13/78 [04:12<18:47, 17.35s/epoch, loss=1.2, accuracy=0.737, val_loss=5.2, val_accuracy=0.205, lr=0.1]  18%|█▊        | 14/78 [04:28<18:17, 17.15s/epoch, loss=1.2, accuracy=0.74, val_loss=1.76, val_accuracy=0.554, lr=0.1] 19%|█▉        | 15/78 [04:45<17:54, 17.06s/epoch, loss=1.19, accuracy=0.737, val_loss=2.23, val_accuracy=0.497, lr=0.0316] 21%|██        | 16/78 [05:02<17:32, 16.97s/epoch, loss=1.19, accuracy=0.741, val_loss=1.73, val_accuracy=0.579, lr=0.1]    22%|██▏       | 17/78 [05:19<17:12, 16.93s/epoch, loss=1.19, accuracy=0.74, val_loss=2.69, val_accuracy=0.433, lr=0.1]  23%|██▎       | 18/78 [05:36<16:50, 16.84s/epoch, loss=1.18, accuracy=0.742, val_loss=1.89, val_accuracy=0.506, lr=0.1] 24%|██▍       | 19/78 [05:52<16:35, 16.87s/epoch, loss=1.18, accuracy=0.744, val_loss=1.95, val_accuracy=0.563, lr=0.1] 26%|██▌       | 20/78 [06:10<16:25, 16.99s/epoch, loss=1.17, accuracy=0.744, val_loss=2.96, val_accuracy=0.411, lr=0.0316] 27%|██▋       | 21/78 [06:27<16:06, 16.95s/epoch, loss=1.17, accuracy=0.744, val_loss=1.59, val_accuracy=0.606, lr=0.1]    28%|██▊       | 22/78 [06:43<15:47, 16.92s/epoch, loss=1.16, accuracy=0.748, val_loss=1.58, val_accuracy=0.587, lr=0.1] 29%|██▉       | 23/78 [07:01<15:32, 16.96s/epoch, loss=1.17, accuracy=0.746, val_loss=2.72, val_accuracy=0.465, lr=0.1] 31%|███       | 24/78 [07:17<15:14, 16.94s/epoch, loss=1.16, accuracy=0.747, val_loss=1.78, val_accuracy=0.595, lr=0.1] 32%|███▏      | 25/78 [07:34<14:59, 16.98s/epoch, loss=1.17, accuracy=0.743, val_loss=1.59, val_accuracy=0.615, lr=0.0316] 33%|███▎      | 26/78 [07:52<14:44, 17.00s/epoch, loss=1.16, accuracy=0.75, val_loss=2.13, val_accuracy=0.481, lr=0.1]     35%|███▍      | 27/78 [08:08<14:25, 16.97s/epoch, loss=1.16, accuracy=0.748, val_loss=3.61, val_accuracy=0.328, lr=0.1] 36%|███▌      | 28/78 [08:25<14:08, 16.98s/epoch, loss=1.17, accuracy=0.748, val_loss=2.37, val_accuracy=0.444, lr=0.1] 37%|███▋      | 29/78 [08:43<13:56, 17.06s/epoch, loss=1.15, accuracy=0.751, val_loss=1.46, val_accuracy=0.648, lr=0.1] 38%|███▊      | 30/78 [08:59<13:34, 16.98s/epoch, loss=1.16, accuracy=0.75, val_loss=1.75, val_accuracy=0.585, lr=0.1]  40%|███▉      | 31/78 [09:17<13:20, 17.02s/epoch, loss=1.15, accuracy=0.752, val_loss=1.98, val_accuracy=0.513, lr=0.1] 41%|████      | 32/78 [09:34<13:02, 17.01s/epoch, loss=1.16, accuracy=0.75, val_loss=1.93, val_accuracy=0.521, lr=0.1]  42%|████▏     | 33/78 [09:51<12:48, 17.08s/epoch, loss=1.14, accuracy=0.754, val_loss=1.53, val_accuracy=0.619, lr=0.1] 44%|████▎     | 34/78 [10:08<12:31, 17.07s/epoch, loss=1.15, accuracy=0.751, val_loss=3.43, val_accuracy=0.368, lr=0.0316] 45%|████▍     | 35/78 [10:25<12:14, 17.08s/epoch, loss=1.14, accuracy=0.753, val_loss=1.71, val_accuracy=0.594, lr=0.1]    46%|████▌     | 36/78 [10:42<11:58, 17.11s/epoch, loss=1.15, accuracy=0.751, val_loss=1.85, val_accuracy=0.486, lr=0.1] 47%|████▋     | 37/78 [10:59<11:41, 17.11s/epoch, loss=1.14, accuracy=0.752, val_loss=1.95, val_accuracy=0.519, lr=0.1] 49%|████▊     | 38/78 [11:16<11:21, 17.04s/epoch, loss=1.14, accuracy=0.756, val_loss=1.71, val_accuracy=0.584, lr=0.1] 50%|█████     | 39/78 [11:33<11:04, 17.03s/epoch, loss=1.14, accuracy=0.758, val_loss=2.89, val_accuracy=0.389, lr=0.0316] 51%|█████▏    | 40/78 [11:50<10:50, 17.11s/epoch, loss=1.15, accuracy=0.752, val_loss=1.66, val_accuracy=0.612, lr=0.1]    53%|█████▎    | 41/78 [12:08<10:33, 17.12s/epoch, loss=1.14, accuracy=0.756, val_loss=1.76, val_accuracy=0.545, lr=0.1] 54%|█████▍    | 42/78 [12:25<10:19, 17.21s/epoch, loss=1.13, accuracy=0.755, val_loss=1.68, val_accuracy=0.563, lr=0.1] 55%|█████▌    | 43/78 [12:42<10:03, 17.25s/epoch, loss=1.13, accuracy=0.757, val_loss=1.55, val_accuracy=0.637, lr=0.1] 56%|█████▋    | 44/78 [12:59<09:44, 17.18s/epoch, loss=1.14, accuracy=0.754, val_loss=2.47, val_accuracy=0.367, lr=0.0316] 58%|█████▊    | 45/78 [13:17<09:27, 17.20s/epoch, loss=1.14, accuracy=0.752, val_loss=1.85, val_accuracy=0.51, lr=0.1]     59%|█████▉    | 46/78 [13:34<09:12, 17.25s/epoch, loss=1.14, accuracy=0.753, val_loss=1.88, val_accuracy=0.541, lr=0.1] 60%|██████    | 47/78 [13:51<08:53, 17.22s/epoch, loss=1.13, accuracy=0.756, val_loss=1.77, val_accuracy=0.535, lr=0.1] 62%|██████▏   | 48/78 [14:08<08:33, 17.12s/epoch, loss=1.14, accuracy=0.754, val_loss=2.19, val_accuracy=0.486, lr=0.1] 63%|██████▎   | 49/78 [14:25<08:15, 17.10s/epoch, loss=1.14, accuracy=0.756, val_loss=1.64, val_accuracy=0.586, lr=0.0316] 64%|██████▍   | 50/78 [14:42<07:55, 16.99s/epoch, loss=1.13, accuracy=0.756, val_loss=1.47, val_accuracy=0.636, lr=0.1]    65%|██████▌   | 51/78 [14:59<07:38, 16.99s/epoch, loss=1.13, accuracy=0.755, val_loss=1.72, val_accuracy=0.575, lr=0.1] 67%|██████▋   | 52/78 [15:16<07:22, 17.01s/epoch, loss=1.13, accuracy=0.76, val_loss=1.76, val_accuracy=0.526, lr=0.1]  68%|██████▊   | 53/78 [15:33<07:07, 17.11s/epoch, loss=1.13, accuracy=0.754, val_loss=2.04, val_accuracy=0.49, lr=0.1] 69%|██████▉   | 54/78 [15:50<06:49, 17.05s/epoch, loss=1.15, accuracy=0.756, val_loss=2.14, val_accuracy=0.435, lr=0.0316] 71%|███████   | 55/78 [16:07<06:31, 17.01s/epoch, loss=1.13, accuracy=0.759, val_loss=1.5, val_accuracy=0.62, lr=0.1]      72%|███████▏  | 56/78 [16:24<06:13, 16.99s/epoch, loss=1.13, accuracy=0.757, val_loss=1.57, val_accuracy=0.611, lr=0.1] 73%|███████▎  | 57/78 [16:41<05:56, 16.95s/epoch, loss=1.13, accuracy=0.757, val_loss=3.21, val_accuracy=0.411, lr=0.1] 74%|███████▍  | 58/78 [16:58<05:40, 17.02s/epoch, loss=1.13, accuracy=0.758, val_loss=2.97, val_accuracy=0.401, lr=0.1] 76%|███████▌  | 59/78 [17:15<05:22, 16.99s/epoch, loss=1.13, accuracy=0.756, val_loss=3.9, val_accuracy=0.33, lr=0.0316] 77%|███████▋  | 60/78 [17:32<05:07, 17.06s/epoch, loss=1.14, accuracy=0.754, val_loss=1.99, val_accuracy=0.476, lr=0.1]  78%|███████▊  | 61/78 [17:49<04:50, 17.11s/epoch, loss=1.12, accuracy=0.758, val_loss=1.91, val_accuracy=0.512, lr=0.1] 79%|███████▉  | 62/78 [18:06<04:33, 17.07s/epoch, loss=1.13, accuracy=0.758, val_loss=1.79, val_accuracy=0.529, lr=0.1] 81%|████████  | 63/78 [18:23<04:15, 17.03s/epoch, loss=1.14, accuracy=0.756, val_loss=2.08, val_accuracy=0.53, lr=0.1]  82%|████████▏ | 64/78 [18:40<03:58, 17.02s/epoch, loss=1.12, accuracy=0.757, val_loss=1.82, val_accuracy=0.505, lr=0.0316] 83%|████████▎ | 65/78 [18:57<03:40, 16.97s/epoch, loss=1.13, accuracy=0.757, val_loss=1.75, val_accuracy=0.557, lr=0.1]    85%|████████▍ | 66/78 [19:15<03:25, 17.09s/epoch, loss=1.13, accuracy=0.757, val_loss=1.71, val_accuracy=0.564, lr=0.1] 86%|████████▌ | 67/78 [19:32<03:07, 17.08s/epoch, loss=1.12, accuracy=0.757, val_loss=2.08, val_accuracy=0.408, lr=0.1] 87%|████████▋ | 68/78 [19:48<02:49, 16.97s/epoch, loss=1.12, accuracy=0.757, val_loss=2.27, val_accuracy=0.462, lr=0.1] 88%|████████▊ | 69/78 [20:05<02:32, 16.97s/epoch, loss=1.13, accuracy=0.755, val_loss=2.38, val_accuracy=0.439, lr=0.0316] 90%|████████▉ | 70/78 [20:22<02:15, 16.94s/epoch, loss=1.13, accuracy=0.759, val_loss=1.58, val_accuracy=0.628, lr=0.1]    91%|█████████ | 71/78 [20:39<01:58, 16.93s/epoch, loss=1.12, accuracy=0.758, val_loss=4.71, val_accuracy=0.259, lr=0.1] 92%|█████████▏| 72/78 [20:56<01:41, 16.93s/epoch, loss=1.12, accuracy=0.76, val_loss=2.87, val_accuracy=0.383, lr=0.1]  94%|█████████▎| 73/78 [21:13<01:24, 16.99s/epoch, loss=1.13, accuracy=0.756, val_loss=2.96, val_accuracy=0.392, lr=0.1] 95%|█████████▍| 74/78 [21:30<01:08, 17.04s/epoch, loss=1.12, accuracy=0.76, val_loss=4.72, val_accuracy=0.274, lr=0.0316] 96%|█████████▌| 75/78 [21:47<00:51, 17.03s/epoch, loss=1.12, accuracy=0.758, val_loss=1.75, val_accuracy=0.579, lr=0.1]   97%|█████████▋| 76/78 [22:04<00:34, 17.04s/epoch, loss=1.12, accuracy=0.757, val_loss=2.12, val_accuracy=0.503, lr=0.1] 99%|█████████▊| 77/78 [22:21<00:17, 17.05s/epoch, loss=1.13, accuracy=0.759, val_loss=3.43, val_accuracy=0.359, lr=0.1]100%|██████████| 78/78 [22:38<00:00, 17.03s/epoch, loss=1.12, accuracy=0.759, val_loss=1.76, val_accuracy=0.538, lr=0.1]100%|██████████| 78/78 [22:38<00:00, 17.42s/epoch, loss=1.12, accuracy=0.759, val_loss=1.76, val_accuracy=0.538, lr=0.1]
Using real-time data augmentation.
Test score: 1.457371711730957
Test accuracy: 0.6437000036239624


* * * Run SGD for ID = 19_4. * * *


2024-02-20 00:26:58.480388: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 00:27:00.883733: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 00:27:00.884717: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-20 00:27:00.921099: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-20 00:27:00.921136: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 00:27:00.923730: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 00:27:00.923768: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-20 00:27:00.925783: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-20 00:27:00.926422: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-20 00:27:00.928566: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-20 00:27:00.929925: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-20 00:27:00.934152: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 00:27:00.934623: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-20 00:27:00.934698: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 00:27:02.332608: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-20 00:27:02.333606: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 00:27:02.334343: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-20 00:27:02.334373: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 00:27:02.334406: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 00:27:02.334422: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-20 00:27:02.334436: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-20 00:27:02.334452: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-20 00:27:02.334467: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-20 00:27:02.334481: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-20 00:27:02.334495: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 00:27:02.334931: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-20 00:27:02.334972: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 00:27:02.935570: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-20 00:27:02.935618: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-20 00:27:02.935626: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-20 00:27:02.936556: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': '19_04', 'batch_size': 128, 'epochs': 78, 'validation_split': 0.1, 'checkpointing': True, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
x_train shape: (45000, 32, 32, 3)
45000 train samples
5000 validation samples
10000 test samples
y_train shape: (45000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/78 [00:00<?, ?epoch/s]2024-02-20 00:27:03.706113: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-20 00:27:03.718080: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600020000 Hz
2024-02-20 00:27:05.560394: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 00:27:05.749801: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 00:27:06.382112: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-20 00:27:06.427550: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|▏         | 1/78 [00:52<1:07:35, 52.67s/epoch, loss=3.26, accuracy=0.285, val_loss=2.81, val_accuracy=0.25, lr=0.1]  3%|▎         | 2/78 [01:09<40:19, 31.84s/epoch, loss=1.71, accuracy=0.464, val_loss=3.07, val_accuracy=0.222, lr=0.1]   4%|▍         | 3/78 [01:27<31:34, 25.25s/epoch, loss=1.45, accuracy=0.578, val_loss=1.95, val_accuracy=0.478, lr=0.1]  5%|▌         | 4/78 [01:44<27:09, 22.02s/epoch, loss=1.32, accuracy=0.646, val_loss=3.14, val_accuracy=0.274, lr=0.1]  6%|▋         | 5/78 [02:01<24:44, 20.34s/epoch, loss=1.28, accuracy=0.679, val_loss=2.34, val_accuracy=0.425, lr=0.1]  8%|▊         | 6/78 [02:18<23:08, 19.28s/epoch, loss=1.25, accuracy=0.699, val_loss=2.9, val_accuracy=0.379, lr=0.1]   9%|▉         | 7/78 [02:36<22:05, 18.67s/epoch, loss=1.24, accuracy=0.708, val_loss=2.21, val_accuracy=0.487, lr=0.1] 10%|█         | 8/78 [02:53<21:10, 18.15s/epoch, loss=1.24, accuracy=0.712, val_loss=1.9, val_accuracy=0.47, lr=0.1]   12%|█▏        | 9/78 [03:10<20:39, 17.96s/epoch, loss=1.23, accuracy=0.721, val_loss=2.13, val_accuracy=0.512, lr=0.1] 13%|█▎        | 10/78 [03:27<20:01, 17.67s/epoch, loss=1.21, accuracy=0.727, val_loss=3.02, val_accuracy=0.326, lr=0.1] 14%|█▍        | 11/78 [03:44<19:29, 17.46s/epoch, loss=1.22, accuracy=0.727, val_loss=2.05, val_accuracy=0.449, lr=0.1] 15%|█▌        | 12/78 [04:02<19:07, 17.39s/epoch, loss=1.22, accuracy=0.728, val_loss=1.61, val_accuracy=0.591, lr=0.1] 17%|█▋        | 13/78 [04:19<18:50, 17.39s/epoch, loss=1.2, accuracy=0.732, val_loss=3.67, val_accuracy=0.277, lr=0.1]  18%|█▊        | 14/78 [04:36<18:27, 17.31s/epoch, loss=1.21, accuracy=0.737, val_loss=2.3, val_accuracy=0.421, lr=0.1] 19%|█▉        | 15/78 [04:53<18:06, 17.24s/epoch, loss=1.2, accuracy=0.733, val_loss=2.51, val_accuracy=0.443, lr=0.1] 21%|██        | 16/78 [05:10<17:46, 17.20s/epoch, loss=1.2, accuracy=0.739, val_loss=2.08, val_accuracy=0.443, lr=0.1] 22%|██▏       | 17/78 [05:28<17:32, 17.25s/epoch, loss=1.2, accuracy=0.739, val_loss=1.88, val_accuracy=0.541, lr=0.0316] 23%|██▎       | 18/78 [05:45<17:17, 17.29s/epoch, loss=1.19, accuracy=0.741, val_loss=2.07, val_accuracy=0.491, lr=0.1]   24%|██▍       | 19/78 [06:03<17:02, 17.33s/epoch, loss=1.19, accuracy=0.742, val_loss=1.42, val_accuracy=0.67, lr=0.1]  26%|██▌       | 20/78 [06:20<16:41, 17.27s/epoch, loss=1.19, accuracy=0.741, val_loss=1.53, val_accuracy=0.653, lr=0.1] 27%|██▋       | 21/78 [06:37<16:20, 17.20s/epoch, loss=1.19, accuracy=0.742, val_loss=1.47, val_accuracy=0.647, lr=0.1] 28%|██▊       | 22/78 [06:54<16:04, 17.23s/epoch, loss=1.19, accuracy=0.742, val_loss=1.59, val_accuracy=0.648, lr=0.1] 29%|██▉       | 23/78 [07:11<15:45, 17.19s/epoch, loss=1.18, accuracy=0.745, val_loss=1.67, val_accuracy=0.6, lr=0.1]   31%|███       | 24/78 [07:28<15:28, 17.19s/epoch, loss=1.19, accuracy=0.744, val_loss=1.71, val_accuracy=0.536, lr=0.0316] 32%|███▏      | 25/78 [07:46<15:14, 17.25s/epoch, loss=1.18, accuracy=0.744, val_loss=1.68, val_accuracy=0.581, lr=0.1]    33%|███▎      | 26/78 [08:03<15:00, 17.31s/epoch, loss=1.18, accuracy=0.747, val_loss=1.85, val_accuracy=0.542, lr=0.1] 35%|███▍      | 27/78 [08:20<14:42, 17.30s/epoch, loss=1.19, accuracy=0.744, val_loss=1.89, val_accuracy=0.513, lr=0.1] 36%|███▌      | 28/78 [08:38<14:26, 17.33s/epoch, loss=1.18, accuracy=0.747, val_loss=2.18, val_accuracy=0.467, lr=0.1] 37%|███▋      | 29/78 [08:55<14:11, 17.38s/epoch, loss=1.17, accuracy=0.747, val_loss=2.13, val_accuracy=0.424, lr=0.0316] 38%|███▊      | 30/78 [09:13<13:51, 17.33s/epoch, loss=1.17, accuracy=0.748, val_loss=4.06, val_accuracy=0.31, lr=0.1]     40%|███▉      | 31/78 [09:30<13:30, 17.25s/epoch, loss=1.17, accuracy=0.749, val_loss=1.6, val_accuracy=0.57, lr=0.1]  41%|████      | 32/78 [09:47<13:10, 17.19s/epoch, loss=1.17, accuracy=0.747, val_loss=1.67, val_accuracy=0.569, lr=0.1] 42%|████▏     | 33/78 [10:04<12:56, 17.26s/epoch, loss=1.18, accuracy=0.747, val_loss=2.33, val_accuracy=0.417, lr=0.1] 44%|████▎     | 34/78 [10:21<12:38, 17.24s/epoch, loss=1.17, accuracy=0.749, val_loss=2.04, val_accuracy=0.439, lr=0.0316] 45%|████▍     | 35/78 [10:39<12:22, 17.27s/epoch, loss=1.17, accuracy=0.748, val_loss=2.77, val_accuracy=0.413, lr=0.1]    46%|████▌     | 36/78 [10:56<12:05, 17.28s/epoch, loss=1.16, accuracy=0.751, val_loss=1.43, val_accuracy=0.643, lr=0.1] 47%|████▋     | 37/78 [11:13<11:48, 17.27s/epoch, loss=1.16, accuracy=0.752, val_loss=1.55, val_accuracy=0.604, lr=0.1] 49%|████▊     | 38/78 [11:31<11:38, 17.45s/epoch, loss=1.16, accuracy=0.75, val_loss=1.59, val_accuracy=0.597, lr=0.1]  50%|█████     | 39/78 [11:48<11:16, 17.35s/epoch, loss=1.16, accuracy=0.752, val_loss=2.24, val_accuracy=0.463, lr=0.0316] 51%|█████▏    | 40/78 [12:05<10:58, 17.32s/epoch, loss=1.16, accuracy=0.753, val_loss=2.01, val_accuracy=0.438, lr=0.1]    53%|█████▎    | 41/78 [12:23<10:40, 17.31s/epoch, loss=1.16, accuracy=0.751, val_loss=1.67, val_accuracy=0.606, lr=0.1] 54%|█████▍    | 42/78 [12:41<10:31, 17.53s/epoch, loss=1.16, accuracy=0.751, val_loss=1.59, val_accuracy=0.602, lr=0.1] 55%|█████▌    | 43/78 [12:58<10:13, 17.52s/epoch, loss=1.17, accuracy=0.751, val_loss=2.49, val_accuracy=0.357, lr=0.1] 56%|█████▋    | 44/78 [13:16<09:54, 17.48s/epoch, loss=1.15, accuracy=0.751, val_loss=1.85, val_accuracy=0.584, lr=0.0316] 58%|█████▊    | 45/78 [13:33<09:37, 17.50s/epoch, loss=1.16, accuracy=0.752, val_loss=2.72, val_accuracy=0.42, lr=0.1]     59%|█████▉    | 46/78 [13:50<09:17, 17.42s/epoch, loss=1.16, accuracy=0.753, val_loss=1.74, val_accuracy=0.55, lr=0.1] 60%|██████    | 47/78 [14:07<08:54, 17.25s/epoch, loss=1.15, accuracy=0.754, val_loss=2.1, val_accuracy=0.477, lr=0.1] 62%|██████▏   | 48/78 [14:24<08:34, 17.16s/epoch, loss=1.16, accuracy=0.751, val_loss=1.67, val_accuracy=0.571, lr=0.1] 63%|██████▎   | 49/78 [14:42<08:24, 17.38s/epoch, loss=1.15, accuracy=0.755, val_loss=1.49, val_accuracy=0.619, lr=0.0316] 64%|██████▍   | 50/78 [14:59<08:06, 17.36s/epoch, loss=1.16, accuracy=0.753, val_loss=2.02, val_accuracy=0.478, lr=0.1]    65%|██████▌   | 51/78 [15:17<07:46, 17.29s/epoch, loss=1.15, accuracy=0.752, val_loss=2.17, val_accuracy=0.503, lr=0.1] 67%|██████▋   | 52/78 [15:34<07:27, 17.22s/epoch, loss=1.15, accuracy=0.755, val_loss=1.58, val_accuracy=0.623, lr=0.1] 68%|██████▊   | 53/78 [15:51<07:10, 17.21s/epoch, loss=1.16, accuracy=0.754, val_loss=2.49, val_accuracy=0.394, lr=0.1] 69%|██████▉   | 54/78 [16:08<06:52, 17.18s/epoch, loss=1.14, accuracy=0.752, val_loss=1.53, val_accuracy=0.633, lr=0.0316] 71%|███████   | 55/78 [16:25<06:34, 17.16s/epoch, loss=1.15, accuracy=0.753, val_loss=1.97, val_accuracy=0.477, lr=0.1]    72%|███████▏  | 56/78 [16:42<06:18, 17.20s/epoch, loss=1.16, accuracy=0.754, val_loss=1.65, val_accuracy=0.582, lr=0.1] 73%|███████▎  | 57/78 [17:00<06:01, 17.21s/epoch, loss=1.14, accuracy=0.754, val_loss=2.4, val_accuracy=0.455, lr=0.1]  74%|███████▍  | 58/78 [17:17<05:44, 17.20s/epoch, loss=1.15, accuracy=0.756, val_loss=1.77, val_accuracy=0.614, lr=0.1] 76%|███████▌  | 59/78 [17:34<05:25, 17.11s/epoch, loss=1.15, accuracy=0.755, val_loss=2.2, val_accuracy=0.441, lr=0.0316] 77%|███████▋  | 60/78 [17:51<05:08, 17.13s/epoch, loss=1.15, accuracy=0.755, val_loss=2.34, val_accuracy=0.477, lr=0.1]   78%|███████▊  | 61/78 [18:08<04:50, 17.06s/epoch, loss=1.14, accuracy=0.756, val_loss=1.46, val_accuracy=0.645, lr=0.1] 79%|███████▉  | 62/78 [18:25<04:32, 17.02s/epoch, loss=1.15, accuracy=0.754, val_loss=1.89, val_accuracy=0.527, lr=0.1] 81%|████████  | 63/78 [18:42<04:14, 17.00s/epoch, loss=1.14, accuracy=0.757, val_loss=1.7, val_accuracy=0.574, lr=0.1]  82%|████████▏ | 64/78 [18:58<03:57, 16.97s/epoch, loss=1.14, accuracy=0.755, val_loss=2.43, val_accuracy=0.458, lr=0.0316] 83%|████████▎ | 65/78 [19:16<03:40, 17.00s/epoch, loss=1.14, accuracy=0.757, val_loss=1.9, val_accuracy=0.516, lr=0.1]     85%|████████▍ | 66/78 [19:33<03:24, 17.00s/epoch, loss=1.14, accuracy=0.757, val_loss=1.67, val_accuracy=0.575, lr=0.1] 86%|████████▌ | 67/78 [19:50<03:08, 17.10s/epoch, loss=1.14, accuracy=0.758, val_loss=1.98, val_accuracy=0.468, lr=0.1] 87%|████████▋ | 68/78 [20:07<02:51, 17.10s/epoch, loss=1.14, accuracy=0.756, val_loss=1.87, val_accuracy=0.545, lr=0.1] 88%|████████▊ | 69/78 [20:24<02:34, 17.14s/epoch, loss=1.14, accuracy=0.757, val_loss=2.17, val_accuracy=0.515, lr=0.0316] 90%|████████▉ | 70/78 [20:41<02:16, 17.08s/epoch, loss=1.14, accuracy=0.756, val_loss=1.52, val_accuracy=0.644, lr=0.1]    91%|█████████ | 71/78 [20:59<02:00, 17.16s/epoch, loss=1.14, accuracy=0.754, val_loss=2.23, val_accuracy=0.511, lr=0.1] 92%|█████████▏| 72/78 [21:16<01:42, 17.11s/epoch, loss=1.14, accuracy=0.755, val_loss=1.6, val_accuracy=0.605, lr=0.1]  94%|█████████▎| 73/78 [21:32<01:25, 17.04s/epoch, loss=1.14, accuracy=0.759, val_loss=1.42, val_accuracy=0.643, lr=0.1] 95%|█████████▍| 74/78 [21:49<01:08, 17.02s/epoch, loss=1.14, accuracy=0.755, val_loss=2.8, val_accuracy=0.409, lr=0.1]  96%|█████████▌| 75/78 [22:06<00:50, 16.97s/epoch, loss=1.14, accuracy=0.756, val_loss=1.54, val_accuracy=0.613, lr=0.1] 97%|█████████▋| 76/78 [22:23<00:33, 16.95s/epoch, loss=1.13, accuracy=0.756, val_loss=1.93, val_accuracy=0.529, lr=0.1] 99%|█████████▊| 77/78 [22:40<00:16, 16.90s/epoch, loss=1.15, accuracy=0.754, val_loss=2.58, val_accuracy=0.365, lr=0.1]100%|██████████| 78/78 [22:57<00:00, 16.87s/epoch, loss=1.14, accuracy=0.756, val_loss=3.49, val_accuracy=0.34, lr=0.0316]100%|██████████| 78/78 [22:57<00:00, 17.66s/epoch, loss=1.14, accuracy=0.756, val_loss=3.49, val_accuracy=0.34, lr=0.0316]
Using real-time data augmentation.
Test score: 1.424054741859436
Test accuracy: 0.6725000143051147


* * * Run SGD for ID = 19_5. * * *


2024-02-20 00:50:06.667608: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 00:50:09.070628: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 00:50:09.071514: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-20 00:50:09.107490: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-20 00:50:09.107523: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 00:50:09.110052: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 00:50:09.110089: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-20 00:50:09.112138: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-20 00:50:09.113198: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-20 00:50:09.115344: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-20 00:50:09.116693: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-20 00:50:09.121017: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 00:50:09.121520: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-20 00:50:09.121595: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 00:50:10.542868: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-20 00:50:10.544365: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 00:50:10.547381: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-20 00:50:10.547426: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 00:50:10.547468: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 00:50:10.547485: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-20 00:50:10.547502: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-20 00:50:10.547519: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-20 00:50:10.547534: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-20 00:50:10.547559: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-20 00:50:10.547575: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 00:50:10.548004: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-20 00:50:10.548041: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 00:50:11.169300: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-20 00:50:11.169353: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-20 00:50:11.169362: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-20 00:50:11.170213: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': '19_05', 'batch_size': 128, 'epochs': 78, 'validation_split': 0.1, 'checkpointing': True, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
x_train shape: (45000, 32, 32, 3)
45000 train samples
5000 validation samples
10000 test samples
y_train shape: (45000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/78 [00:00<?, ?epoch/s]2024-02-20 00:50:11.952190: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-20 00:50:11.952708: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600020000 Hz
2024-02-20 00:50:13.815318: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 00:50:14.032078: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 00:50:14.634582: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-20 00:50:14.678209: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|▏         | 1/78 [00:47<1:00:37, 47.25s/epoch, loss=3.5, accuracy=0.265, val_loss=2.66, val_accuracy=0.191, lr=0.1]  3%|▎         | 2/78 [01:04<37:38, 29.72s/epoch, loss=1.69, accuracy=0.474, val_loss=2.05, val_accuracy=0.421, lr=0.1]   4%|▍         | 3/78 [01:22<30:05, 24.07s/epoch, loss=1.44, accuracy=0.592, val_loss=1.85, val_accuracy=0.508, lr=0.1]  5%|▌         | 4/78 [01:38<26:10, 21.23s/epoch, loss=1.32, accuracy=0.66, val_loss=2.27, val_accuracy=0.427, lr=0.1]   6%|▋         | 5/78 [01:55<24:00, 19.73s/epoch, loss=1.27, accuracy=0.687, val_loss=2.12, val_accuracy=0.456, lr=0.1]  8%|▊         | 6/78 [02:13<22:33, 18.81s/epoch, loss=1.25, accuracy=0.702, val_loss=1.79, val_accuracy=0.478, lr=0.1]  9%|▉         | 7/78 [02:30<21:39, 18.31s/epoch, loss=1.23, accuracy=0.71, val_loss=1.97, val_accuracy=0.482, lr=0.1]  10%|█         | 8/78 [02:47<20:58, 17.97s/epoch, loss=1.22, accuracy=0.72, val_loss=1.57, val_accuracy=0.625, lr=0.1] 12%|█▏        | 9/78 [03:04<20:14, 17.60s/epoch, loss=1.22, accuracy=0.724, val_loss=1.76, val_accuracy=0.568, lr=0.1] 13%|█▎        | 10/78 [03:21<19:43, 17.41s/epoch, loss=1.22, accuracy=0.725, val_loss=2.1, val_accuracy=0.505, lr=0.1] 14%|█▍        | 11/78 [03:38<19:13, 17.22s/epoch, loss=1.21, accuracy=0.732, val_loss=1.64, val_accuracy=0.611, lr=0.1] 15%|█▌        | 12/78 [03:55<18:50, 17.13s/epoch, loss=1.2, accuracy=0.73, val_loss=1.76, val_accuracy=0.507, lr=0.1]   17%|█▋        | 13/78 [04:11<18:28, 17.05s/epoch, loss=1.21, accuracy=0.733, val_loss=1.76, val_accuracy=0.576, lr=0.0316] 18%|█▊        | 14/78 [04:28<18:05, 16.96s/epoch, loss=1.2, accuracy=0.735, val_loss=1.65, val_accuracy=0.562, lr=0.1]     19%|█▉        | 15/78 [04:45<17:41, 16.85s/epoch, loss=1.2, accuracy=0.736, val_loss=1.67, val_accuracy=0.579, lr=0.1] 21%|██        | 16/78 [05:02<17:27, 16.89s/epoch, loss=1.2, accuracy=0.737, val_loss=1.68, val_accuracy=0.607, lr=0.1] 22%|██▏       | 17/78 [05:19<17:11, 16.92s/epoch, loss=1.19, accuracy=0.739, val_loss=1.85, val_accuracy=0.573, lr=0.1] 23%|██▎       | 18/78 [05:36<17:01, 17.03s/epoch, loss=1.19, accuracy=0.741, val_loss=1.4, val_accuracy=0.682, lr=0.1]  24%|██▍       | 19/78 [05:53<16:42, 16.99s/epoch, loss=1.19, accuracy=0.737, val_loss=1.89, val_accuracy=0.538, lr=0.1] 26%|██▌       | 20/78 [06:09<16:18, 16.86s/epoch, loss=1.19, accuracy=0.743, val_loss=4.07, val_accuracy=0.236, lr=0.1] 27%|██▋       | 21/78 [06:26<16:02, 16.88s/epoch, loss=1.2, accuracy=0.74, val_loss=2.12, val_accuracy=0.425, lr=0.1]   28%|██▊       | 22/78 [06:43<15:47, 16.92s/epoch, loss=1.18, accuracy=0.743, val_loss=2.06, val_accuracy=0.54, lr=0.1] 29%|██▉       | 23/78 [07:00<15:33, 16.97s/epoch, loss=1.18, accuracy=0.743, val_loss=1.73, val_accuracy=0.564, lr=0.0316] 31%|███       | 24/78 [07:18<15:27, 17.17s/epoch, loss=1.18, accuracy=0.743, val_loss=1.92, val_accuracy=0.545, lr=0.1]    32%|███▏      | 25/78 [07:35<15:10, 17.18s/epoch, loss=1.18, accuracy=0.744, val_loss=1.81, val_accuracy=0.562, lr=0.1] 33%|███▎      | 26/78 [07:52<14:49, 17.10s/epoch, loss=1.18, accuracy=0.745, val_loss=2.23, val_accuracy=0.52, lr=0.1]  35%|███▍      | 27/78 [08:09<14:33, 17.12s/epoch, loss=1.17, accuracy=0.745, val_loss=1.7, val_accuracy=0.59, lr=0.1]  36%|███▌      | 28/78 [08:27<14:16, 17.12s/epoch, loss=1.18, accuracy=0.741, val_loss=2.05, val_accuracy=0.46, lr=0.0316] 37%|███▋      | 29/78 [08:43<13:56, 17.07s/epoch, loss=1.18, accuracy=0.743, val_loss=1.72, val_accuracy=0.592, lr=0.1]   38%|███▊      | 30/78 [09:01<13:45, 17.20s/epoch, loss=1.18, accuracy=0.743, val_loss=1.52, val_accuracy=0.619, lr=0.1] 40%|███▉      | 31/78 [09:18<13:26, 17.16s/epoch, loss=1.17, accuracy=0.745, val_loss=2.18, val_accuracy=0.487, lr=0.1] 41%|████      | 32/78 [09:35<13:10, 17.18s/epoch, loss=1.18, accuracy=0.745, val_loss=1.67, val_accuracy=0.581, lr=0.1] 42%|████▏     | 33/78 [09:52<12:49, 17.09s/epoch, loss=1.17, accuracy=0.749, val_loss=3.36, val_accuracy=0.321, lr=0.0316] 44%|████▎     | 34/78 [10:09<12:31, 17.09s/epoch, loss=1.18, accuracy=0.745, val_loss=1.58, val_accuracy=0.642, lr=0.1]    45%|████▍     | 35/78 [10:26<12:15, 17.12s/epoch, loss=1.17, accuracy=0.75, val_loss=1.84, val_accuracy=0.553, lr=0.1]  46%|████▌     | 36/78 [10:43<11:56, 17.06s/epoch, loss=1.17, accuracy=0.747, val_loss=2.16, val_accuracy=0.438, lr=0.1] 47%|████▋     | 37/78 [11:01<11:47, 17.25s/epoch, loss=1.16, accuracy=0.749, val_loss=2.43, val_accuracy=0.358, lr=0.1] 49%|████▊     | 38/78 [11:18<11:26, 17.17s/epoch, loss=1.18, accuracy=0.747, val_loss=1.68, val_accuracy=0.585, lr=0.0316] 50%|█████     | 39/78 [11:35<11:10, 17.19s/epoch, loss=1.17, accuracy=0.748, val_loss=1.47, val_accuracy=0.643, lr=0.1]    51%|█████▏    | 40/78 [11:52<10:50, 17.12s/epoch, loss=1.16, accuracy=0.751, val_loss=1.46, val_accuracy=0.648, lr=0.1] 53%|█████▎    | 41/78 [12:10<10:37, 17.23s/epoch, loss=1.17, accuracy=0.749, val_loss=2.59, val_accuracy=0.341, lr=0.1] 54%|█████▍    | 42/78 [12:27<10:19, 17.20s/epoch, loss=1.16, accuracy=0.749, val_loss=1.8, val_accuracy=0.523, lr=0.1]  55%|█████▌    | 43/78 [12:44<10:04, 17.26s/epoch, loss=1.16, accuracy=0.749, val_loss=2.4, val_accuracy=0.485, lr=0.0316] 56%|█████▋    | 44/78 [13:01<09:45, 17.23s/epoch, loss=1.16, accuracy=0.746, val_loss=3.75, val_accuracy=0.376, lr=0.1]   58%|█████▊    | 45/78 [13:19<09:27, 17.20s/epoch, loss=1.16, accuracy=0.747, val_loss=1.85, val_accuracy=0.511, lr=0.1] 59%|█████▉    | 46/78 [13:36<09:09, 17.19s/epoch, loss=1.16, accuracy=0.749, val_loss=2.69, val_accuracy=0.381, lr=0.1] 60%|██████    | 47/78 [13:53<08:52, 17.18s/epoch, loss=1.16, accuracy=0.751, val_loss=1.82, val_accuracy=0.573, lr=0.1] 62%|██████▏   | 48/78 [14:10<08:33, 17.12s/epoch, loss=1.16, accuracy=0.749, val_loss=1.61, val_accuracy=0.581, lr=0.0316] 63%|██████▎   | 49/78 [14:27<08:17, 17.16s/epoch, loss=1.16, accuracy=0.752, val_loss=1.54, val_accuracy=0.614, lr=0.1]    64%|██████▍   | 50/78 [14:44<08:01, 17.18s/epoch, loss=1.16, accuracy=0.75, val_loss=1.51, val_accuracy=0.628, lr=0.1]  65%|██████▌   | 51/78 [15:02<07:44, 17.21s/epoch, loss=1.16, accuracy=0.747, val_loss=1.67, val_accuracy=0.588, lr=0.1] 67%|██████▋   | 52/78 [15:19<07:28, 17.24s/epoch, loss=1.16, accuracy=0.75, val_loss=2.49, val_accuracy=0.418, lr=0.1]  68%|██████▊   | 53/78 [15:36<07:12, 17.31s/epoch, loss=1.16, accuracy=0.75, val_loss=2.45, val_accuracy=0.404, lr=0.0316] 69%|██████▉   | 54/78 [15:54<06:56, 17.34s/epoch, loss=1.16, accuracy=0.752, val_loss=2.14, val_accuracy=0.505, lr=0.1]   71%|███████   | 55/78 [16:12<06:41, 17.47s/epoch, loss=1.16, accuracy=0.753, val_loss=2.56, val_accuracy=0.429, lr=0.1] 72%|███████▏  | 56/78 [16:29<06:24, 17.47s/epoch, loss=1.16, accuracy=0.75, val_loss=3.87, val_accuracy=0.271, lr=0.1]  73%|███████▎  | 57/78 [16:46<06:05, 17.39s/epoch, loss=1.16, accuracy=0.752, val_loss=2.4, val_accuracy=0.403, lr=0.1] 74%|███████▍  | 58/78 [17:04<05:47, 17.39s/epoch, loss=1.16, accuracy=0.75, val_loss=2, val_accuracy=0.535, lr=0.0316] 76%|███████▌  | 59/78 [17:21<05:30, 17.38s/epoch, loss=1.16, accuracy=0.747, val_loss=2.7, val_accuracy=0.427, lr=0.1] 77%|███████▋  | 60/78 [17:38<05:11, 17.29s/epoch, loss=1.15, accuracy=0.752, val_loss=1.62, val_accuracy=0.587, lr=0.1] 78%|███████▊  | 61/78 [17:55<04:52, 17.22s/epoch, loss=1.15, accuracy=0.753, val_loss=3.31, val_accuracy=0.369, lr=0.1] 79%|███████▉  | 62/78 [18:12<04:35, 17.19s/epoch, loss=1.16, accuracy=0.751, val_loss=2.48, val_accuracy=0.432, lr=0.1] 81%|████████  | 63/78 [18:29<04:17, 17.19s/epoch, loss=1.15, accuracy=0.753, val_loss=2.03, val_accuracy=0.504, lr=0.0316] 82%|████████▏ | 64/78 [18:46<03:59, 17.13s/epoch, loss=1.15, accuracy=0.752, val_loss=1.59, val_accuracy=0.59, lr=0.1]     83%|████████▎ | 65/78 [19:04<03:43, 17.18s/epoch, loss=1.16, accuracy=0.751, val_loss=4.07, val_accuracy=0.303, lr=0.1] 85%|████████▍ | 66/78 [19:21<03:25, 17.13s/epoch, loss=1.15, accuracy=0.75, val_loss=3.71, val_accuracy=0.293, lr=0.1]  86%|████████▌ | 67/78 [19:38<03:09, 17.18s/epoch, loss=1.16, accuracy=0.751, val_loss=1.98, val_accuracy=0.511, lr=0.1] 87%|████████▋ | 68/78 [19:55<02:51, 17.11s/epoch, loss=1.15, accuracy=0.75, val_loss=2.56, val_accuracy=0.353, lr=0.0316] 88%|████████▊ | 69/78 [20:12<02:34, 17.16s/epoch, loss=1.15, accuracy=0.751, val_loss=3.61, val_accuracy=0.366, lr=0.1]   90%|████████▉ | 70/78 [20:29<02:17, 17.14s/epoch, loss=1.16, accuracy=0.749, val_loss=1.66, val_accuracy=0.564, lr=0.1] 91%|█████████ | 71/78 [20:46<01:59, 17.08s/epoch, loss=1.16, accuracy=0.751, val_loss=2.17, val_accuracy=0.451, lr=0.1] 92%|█████████▏| 72/78 [21:03<01:42, 17.09s/epoch, loss=1.15, accuracy=0.754, val_loss=1.58, val_accuracy=0.619, lr=0.1] 94%|█████████▎| 73/78 [21:20<01:25, 17.01s/epoch, loss=1.15, accuracy=0.752, val_loss=2.7, val_accuracy=0.356, lr=0.0316] 95%|█████████▍| 74/78 [21:37<01:08, 17.09s/epoch, loss=1.15, accuracy=0.752, val_loss=1.74, val_accuracy=0.575, lr=0.1]   96%|█████████▌| 75/78 [21:55<00:51, 17.13s/epoch, loss=1.15, accuracy=0.749, val_loss=2.13, val_accuracy=0.441, lr=0.1] 97%|█████████▋| 76/78 [22:12<00:34, 17.15s/epoch, loss=1.15, accuracy=0.754, val_loss=1.87, val_accuracy=0.541, lr=0.1] 99%|█████████▊| 77/78 [22:29<00:17, 17.18s/epoch, loss=1.14, accuracy=0.755, val_loss=2.05, val_accuracy=0.464, lr=0.1]100%|██████████| 78/78 [22:47<00:00, 17.24s/epoch, loss=1.15, accuracy=0.754, val_loss=1.83, val_accuracy=0.545, lr=0.0316]100%|██████████| 78/78 [22:47<00:00, 17.53s/epoch, loss=1.15, accuracy=0.754, val_loss=1.83, val_accuracy=0.545, lr=0.0316]
Using real-time data augmentation.
Test score: 1.4332679510116577
Test accuracy: 0.670199990272522


* * * Run SGD for ID = 19_6. * * *


2024-02-20 01:13:06.341414: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 01:13:08.763077: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 01:13:08.764041: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-20 01:13:08.801160: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-20 01:13:08.801190: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 01:13:08.803790: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 01:13:08.803827: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-20 01:13:08.805916: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-20 01:13:08.806588: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-20 01:13:08.808775: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-20 01:13:08.810111: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-20 01:13:08.814435: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 01:13:08.814912: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-20 01:13:08.815012: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 01:13:10.207382: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-20 01:13:10.208365: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 01:13:10.209096: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-20 01:13:10.209126: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 01:13:10.209169: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 01:13:10.209186: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-20 01:13:10.209202: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-20 01:13:10.209217: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-20 01:13:10.209231: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-20 01:13:10.209245: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-20 01:13:10.209275: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 01:13:10.209684: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-20 01:13:10.209718: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 01:13:10.802523: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-20 01:13:10.802572: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-20 01:13:10.802580: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-20 01:13:10.803479: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': '19_06', 'batch_size': 128, 'epochs': 78, 'validation_split': 0.1, 'checkpointing': True, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
x_train shape: (45000, 32, 32, 3)
45000 train samples
5000 validation samples
10000 test samples
y_train shape: (45000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/78 [00:00<?, ?epoch/s]2024-02-20 01:13:11.584200: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-20 01:13:11.596087: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600020000 Hz
2024-02-20 01:13:13.479035: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 01:13:13.726045: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 01:13:14.411622: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-20 01:13:14.460868: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|▏         | 1/78 [00:49<1:03:23, 49.40s/epoch, loss=3.37, accuracy=0.264, val_loss=2.65, val_accuracy=0.227, lr=0.1]  3%|▎         | 2/78 [01:06<38:49, 30.65s/epoch, loss=1.65, accuracy=0.488, val_loss=4, val_accuracy=0.214, lr=0.1]       4%|▍         | 3/78 [01:24<30:40, 24.54s/epoch, loss=1.39, accuracy=0.613, val_loss=1.58, val_accuracy=0.554, lr=0.1]  5%|▌         | 4/78 [01:41<26:32, 21.52s/epoch, loss=1.29, accuracy=0.668, val_loss=2.38, val_accuracy=0.357, lr=0.1]  6%|▋         | 5/78 [01:57<24:06, 19.82s/epoch, loss=1.24, accuracy=0.695, val_loss=1.8, val_accuracy=0.512, lr=0.1]   8%|▊         | 6/78 [02:14<22:36, 18.83s/epoch, loss=1.22, accuracy=0.709, val_loss=1.93, val_accuracy=0.497, lr=0.1]  9%|▉         | 7/78 [02:31<21:35, 18.24s/epoch, loss=1.21, accuracy=0.72, val_loss=5.53, val_accuracy=0.257, lr=0.1]  10%|█         | 8/78 [02:48<20:50, 17.86s/epoch, loss=1.2, accuracy=0.724, val_loss=1.8, val_accuracy=0.511, lr=0.0316] 12%|█▏        | 9/78 [03:05<20:14, 17.60s/epoch, loss=1.19, accuracy=0.73, val_loss=2.21, val_accuracy=0.42, lr=0.1]    13%|█▎        | 10/78 [03:22<19:44, 17.42s/epoch, loss=1.19, accuracy=0.731, val_loss=2.17, val_accuracy=0.445, lr=0.1] 14%|█▍        | 11/78 [03:40<19:23, 17.36s/epoch, loss=1.18, accuracy=0.734, val_loss=1.81, val_accuracy=0.556, lr=0.1] 15%|█▌        | 12/78 [03:57<19:07, 17.38s/epoch, loss=1.18, accuracy=0.736, val_loss=2, val_accuracy=0.542, lr=0.1]    17%|█▋        | 13/78 [04:14<18:40, 17.24s/epoch, loss=1.17, accuracy=0.742, val_loss=2.2, val_accuracy=0.464, lr=0.0316] 18%|█▊        | 14/78 [04:31<18:17, 17.15s/epoch, loss=1.17, accuracy=0.74, val_loss=1.83, val_accuracy=0.532, lr=0.1]    19%|█▉        | 15/78 [04:48<17:57, 17.11s/epoch, loss=1.16, accuracy=0.744, val_loss=2.22, val_accuracy=0.412, lr=0.1] 21%|██        | 16/78 [05:05<17:38, 17.08s/epoch, loss=1.17, accuracy=0.741, val_loss=2.35, val_accuracy=0.416, lr=0.1] 22%|██▏       | 17/78 [05:22<17:21, 17.08s/epoch, loss=1.17, accuracy=0.743, val_loss=1.95, val_accuracy=0.525, lr=0.1] 23%|██▎       | 18/78 [05:39<17:00, 17.00s/epoch, loss=1.17, accuracy=0.744, val_loss=4.59, val_accuracy=0.151, lr=0.0316] 24%|██▍       | 19/78 [05:56<16:40, 16.96s/epoch, loss=1.15, accuracy=0.748, val_loss=3.56, val_accuracy=0.301, lr=0.1]    26%|██▌       | 20/78 [06:13<16:28, 17.03s/epoch, loss=1.16, accuracy=0.746, val_loss=2.17, val_accuracy=0.527, lr=0.1] 27%|██▋       | 21/78 [06:30<16:09, 17.00s/epoch, loss=1.16, accuracy=0.748, val_loss=1.85, val_accuracy=0.518, lr=0.1] 28%|██▊       | 22/78 [06:47<15:56, 17.07s/epoch, loss=1.16, accuracy=0.748, val_loss=1.96, val_accuracy=0.556, lr=0.1] 29%|██▉       | 23/78 [07:04<15:36, 17.04s/epoch, loss=1.16, accuracy=0.747, val_loss=1.42, val_accuracy=0.657, lr=0.1] 31%|███       | 24/78 [07:21<15:16, 16.96s/epoch, loss=1.15, accuracy=0.746, val_loss=1.89, val_accuracy=0.521, lr=0.1] 32%|███▏      | 25/78 [07:38<15:03, 17.04s/epoch, loss=1.15, accuracy=0.751, val_loss=1.97, val_accuracy=0.471, lr=0.1] 33%|███▎      | 26/78 [07:55<14:41, 16.95s/epoch, loss=1.15, accuracy=0.752, val_loss=1.98, val_accuracy=0.546, lr=0.1] 35%|███▍      | 27/78 [08:12<14:28, 17.02s/epoch, loss=1.15, accuracy=0.75, val_loss=1.55, val_accuracy=0.624, lr=0.1]  36%|███▌      | 28/78 [08:29<14:13, 17.07s/epoch, loss=1.15, accuracy=0.754, val_loss=2.55, val_accuracy=0.406, lr=0.0316] 37%|███▋      | 29/78 [08:46<13:53, 17.01s/epoch, loss=1.15, accuracy=0.752, val_loss=1.92, val_accuracy=0.47, lr=0.1]     38%|███▊      | 30/78 [09:03<13:36, 17.01s/epoch, loss=1.14, accuracy=0.75, val_loss=1.71, val_accuracy=0.55, lr=0.1]  40%|███▉      | 31/78 [09:20<13:23, 17.09s/epoch, loss=1.14, accuracy=0.752, val_loss=2.92, val_accuracy=0.402, lr=0.1] 41%|████      | 32/78 [09:37<13:02, 17.01s/epoch, loss=1.14, accuracy=0.751, val_loss=3.58, val_accuracy=0.21, lr=0.1]  42%|████▏     | 33/78 [09:54<12:46, 17.04s/epoch, loss=1.15, accuracy=0.75, val_loss=1.78, val_accuracy=0.583, lr=0.0316] 44%|████▎     | 34/78 [10:11<12:28, 17.01s/epoch, loss=1.14, accuracy=0.75, val_loss=3.89, val_accuracy=0.32, lr=0.1]     45%|████▍     | 35/78 [10:28<12:14, 17.08s/epoch, loss=1.14, accuracy=0.752, val_loss=1.91, val_accuracy=0.499, lr=0.1] 46%|████▌     | 36/78 [10:45<11:53, 16.98s/epoch, loss=1.13, accuracy=0.753, val_loss=1.58, val_accuracy=0.601, lr=0.1] 47%|████▋     | 37/78 [11:02<11:37, 17.02s/epoch, loss=1.14, accuracy=0.754, val_loss=1.83, val_accuracy=0.509, lr=0.1] 49%|████▊     | 38/78 [11:19<11:21, 17.03s/epoch, loss=1.14, accuracy=0.752, val_loss=1.93, val_accuracy=0.529, lr=0.0316] 50%|█████     | 39/78 [11:36<11:05, 17.06s/epoch, loss=1.13, accuracy=0.753, val_loss=2.56, val_accuracy=0.302, lr=0.1]    51%|█████▏    | 40/78 [11:53<10:43, 16.94s/epoch, loss=1.14, accuracy=0.751, val_loss=2.34, val_accuracy=0.424, lr=0.1] 53%|█████▎    | 41/78 [12:10<10:23, 16.84s/epoch, loss=1.13, accuracy=0.755, val_loss=2.99, val_accuracy=0.355, lr=0.1] 54%|█████▍    | 42/78 [12:27<10:06, 16.84s/epoch, loss=1.14, accuracy=0.755, val_loss=2.43, val_accuracy=0.378, lr=0.1] 55%|█████▌    | 43/78 [12:43<09:48, 16.81s/epoch, loss=1.12, accuracy=0.756, val_loss=2.21, val_accuracy=0.439, lr=0.0316] 56%|█████▋    | 44/78 [13:00<09:32, 16.85s/epoch, loss=1.13, accuracy=0.755, val_loss=1.78, val_accuracy=0.553, lr=0.1]    58%|█████▊    | 45/78 [13:17<09:17, 16.90s/epoch, loss=1.12, accuracy=0.756, val_loss=2.58, val_accuracy=0.318, lr=0.1] 59%|█████▉    | 46/78 [13:34<08:57, 16.81s/epoch, loss=1.13, accuracy=0.754, val_loss=1.64, val_accuracy=0.577, lr=0.1] 60%|██████    | 47/78 [13:51<08:40, 16.81s/epoch, loss=1.12, accuracy=0.759, val_loss=2.18, val_accuracy=0.437, lr=0.1] 62%|██████▏   | 48/78 [14:07<08:22, 16.76s/epoch, loss=1.12, accuracy=0.757, val_loss=2.62, val_accuracy=0.364, lr=0.0316] 63%|██████▎   | 49/78 [14:24<08:07, 16.80s/epoch, loss=1.12, accuracy=0.759, val_loss=1.87, val_accuracy=0.538, lr=0.1]    64%|██████▍   | 50/78 [14:41<07:52, 16.89s/epoch, loss=1.12, accuracy=0.755, val_loss=1.97, val_accuracy=0.534, lr=0.1] 65%|██████▌   | 51/78 [14:58<07:35, 16.87s/epoch, loss=1.12, accuracy=0.755, val_loss=2.31, val_accuracy=0.518, lr=0.1] 67%|██████▋   | 52/78 [15:15<07:19, 16.88s/epoch, loss=1.12, accuracy=0.754, val_loss=2.76, val_accuracy=0.38, lr=0.1]  68%|██████▊   | 53/78 [15:32<07:05, 17.00s/epoch, loss=1.12, accuracy=0.755, val_loss=1.85, val_accuracy=0.522, lr=0.0316] 69%|██████▉   | 54/78 [15:49<06:47, 16.98s/epoch, loss=1.12, accuracy=0.755, val_loss=1.96, val_accuracy=0.51, lr=0.1]     71%|███████   | 55/78 [16:06<06:29, 16.93s/epoch, loss=1.12, accuracy=0.758, val_loss=2.24, val_accuracy=0.432, lr=0.1] 72%|███████▏  | 56/78 [16:23<06:12, 16.92s/epoch, loss=1.12, accuracy=0.756, val_loss=3.69, val_accuracy=0.315, lr=0.1] 73%|███████▎  | 57/78 [16:40<05:55, 16.94s/epoch, loss=1.11, accuracy=0.759, val_loss=1.69, val_accuracy=0.57, lr=0.1]  74%|███████▍  | 58/78 [16:57<05:36, 16.84s/epoch, loss=1.11, accuracy=0.757, val_loss=1.76, val_accuracy=0.538, lr=0.0316] 76%|███████▌  | 59/78 [17:13<05:19, 16.81s/epoch, loss=1.11, accuracy=0.758, val_loss=3.17, val_accuracy=0.435, lr=0.1]    77%|███████▋  | 60/78 [17:30<05:03, 16.85s/epoch, loss=1.11, accuracy=0.757, val_loss=2.66, val_accuracy=0.432, lr=0.1] 78%|███████▊  | 61/78 [17:47<04:45, 16.82s/epoch, loss=1.11, accuracy=0.758, val_loss=3.22, val_accuracy=0.399, lr=0.1] 79%|███████▉  | 62/78 [18:04<04:30, 16.91s/epoch, loss=1.12, accuracy=0.757, val_loss=3.44, val_accuracy=0.323, lr=0.1] 81%|████████  | 63/78 [18:21<04:11, 16.76s/epoch, loss=1.11, accuracy=0.758, val_loss=2.91, val_accuracy=0.251, lr=0.0316] 82%|████████▏ | 64/78 [18:37<03:55, 16.80s/epoch, loss=1.12, accuracy=0.759, val_loss=2.34, val_accuracy=0.403, lr=0.1]    83%|████████▎ | 65/78 [18:54<03:37, 16.72s/epoch, loss=1.11, accuracy=0.758, val_loss=4.38, val_accuracy=0.248, lr=0.1] 85%|████████▍ | 66/78 [19:11<03:19, 16.67s/epoch, loss=1.11, accuracy=0.76, val_loss=2.22, val_accuracy=0.473, lr=0.1]  86%|████████▌ | 67/78 [19:27<03:03, 16.72s/epoch, loss=1.11, accuracy=0.758, val_loss=2.77, val_accuracy=0.278, lr=0.1] 87%|████████▋ | 68/78 [19:44<02:46, 16.60s/epoch, loss=1.1, accuracy=0.76, val_loss=2.03, val_accuracy=0.474, lr=0.0316] 88%|████████▊ | 69/78 [20:01<02:30, 16.69s/epoch, loss=1.11, accuracy=0.758, val_loss=2.58, val_accuracy=0.391, lr=0.1]  90%|████████▉ | 70/78 [20:18<02:14, 16.82s/epoch, loss=1.11, accuracy=0.762, val_loss=1.8, val_accuracy=0.554, lr=0.1]  91%|█████████ | 71/78 [20:35<01:57, 16.83s/epoch, loss=1.11, accuracy=0.759, val_loss=2.39, val_accuracy=0.466, lr=0.1] 92%|█████████▏| 72/78 [20:51<01:41, 16.85s/epoch, loss=1.11, accuracy=0.758, val_loss=1.68, val_accuracy=0.537, lr=0.1] 94%|█████████▎| 73/78 [21:08<01:24, 16.89s/epoch, loss=1.11, accuracy=0.759, val_loss=1.63, val_accuracy=0.556, lr=0.0316] 95%|█████████▍| 74/78 [21:25<01:07, 16.77s/epoch, loss=1.11, accuracy=0.759, val_loss=1.81, val_accuracy=0.545, lr=0.1]    96%|█████████▌| 75/78 [21:41<00:50, 16.69s/epoch, loss=1.1, accuracy=0.761, val_loss=2.96, val_accuracy=0.39, lr=0.1]   97%|█████████▋| 76/78 [21:58<00:33, 16.72s/epoch, loss=1.12, accuracy=0.758, val_loss=1.76, val_accuracy=0.574, lr=0.1] 99%|█████████▊| 77/78 [22:15<00:16, 16.78s/epoch, loss=1.1, accuracy=0.76, val_loss=2.13, val_accuracy=0.47, lr=0.1]   100%|██████████| 78/78 [22:32<00:00, 16.83s/epoch, loss=1.11, accuracy=0.758, val_loss=2.82, val_accuracy=0.316, lr=0.0316]100%|██████████| 78/78 [22:32<00:00, 17.34s/epoch, loss=1.11, accuracy=0.758, val_loss=2.82, val_accuracy=0.316, lr=0.0316]
Using real-time data augmentation.
Test score: 1.4273993968963623
Test accuracy: 0.6549999713897705


* * * Run SGD for ID = 19_7. * * *


2024-02-20 01:35:51.648954: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 01:35:54.287081: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 01:35:54.288097: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-20 01:35:54.323870: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-20 01:35:54.323899: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 01:35:54.326706: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 01:35:54.326744: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-20 01:35:54.329009: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-20 01:35:54.329734: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-20 01:35:54.332098: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-20 01:35:54.333549: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-20 01:35:54.338166: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 01:35:54.338634: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-20 01:35:54.338711: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 01:35:55.730495: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-20 01:35:55.731511: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 01:35:55.732278: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-20 01:35:55.732315: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 01:35:55.732351: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 01:35:55.732368: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-20 01:35:55.732384: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-20 01:35:55.732399: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-20 01:35:55.732414: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-20 01:35:55.732428: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-20 01:35:55.732443: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 01:35:55.732855: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-20 01:35:55.732886: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 01:35:56.318763: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-20 01:35:56.318817: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-20 01:35:56.318825: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-20 01:35:56.319711: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': '19_07', 'batch_size': 128, 'epochs': 78, 'validation_split': 0.1, 'checkpointing': True, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
x_train shape: (45000, 32, 32, 3)
45000 train samples
5000 validation samples
10000 test samples
y_train shape: (45000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/78 [00:00<?, ?epoch/s]2024-02-20 01:35:57.092357: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-20 01:35:57.104071: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600020000 Hz
2024-02-20 01:35:58.976119: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 01:35:59.174014: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 01:35:59.852967: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-20 01:35:59.901909: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|▏         | 1/78 [00:50<1:04:13, 50.05s/epoch, loss=3.18, accuracy=0.327, val_loss=3.03, val_accuracy=0.179, lr=0.1]  3%|▎         | 2/78 [01:08<39:37, 31.28s/epoch, loss=1.57, accuracy=0.538, val_loss=3.38, val_accuracy=0.289, lr=0.1]    4%|▍         | 3/78 [01:25<31:05, 24.87s/epoch, loss=1.33, accuracy=0.653, val_loss=2.19, val_accuracy=0.443, lr=0.1]  5%|▌         | 4/78 [01:42<26:54, 21.82s/epoch, loss=1.27, accuracy=0.689, val_loss=2.17, val_accuracy=0.429, lr=0.1]  6%|▋         | 5/78 [01:59<24:35, 20.21s/epoch, loss=1.24, accuracy=0.703, val_loss=1.98, val_accuracy=0.472, lr=0.1]  8%|▊         | 6/78 [02:17<23:05, 19.24s/epoch, loss=1.22, accuracy=0.712, val_loss=1.57, val_accuracy=0.571, lr=0.1]  9%|▉         | 7/78 [02:34<21:57, 18.55s/epoch, loss=1.21, accuracy=0.722, val_loss=2.24, val_accuracy=0.457, lr=0.1] 10%|█         | 8/78 [02:51<21:11, 18.17s/epoch, loss=1.21, accuracy=0.725, val_loss=3.04, val_accuracy=0.356, lr=0.1] 12%|█▏        | 9/78 [03:09<20:35, 17.90s/epoch, loss=1.2, accuracy=0.727, val_loss=3.59, val_accuracy=0.364, lr=0.1]  13%|█▎        | 10/78 [03:26<19:58, 17.63s/epoch, loss=1.19, accuracy=0.731, val_loss=3.03, val_accuracy=0.297, lr=0.1] 14%|█▍        | 11/78 [03:43<19:36, 17.56s/epoch, loss=1.19, accuracy=0.736, val_loss=1.57, val_accuracy=0.6, lr=0.0316] 15%|█▌        | 12/78 [04:00<19:09, 17.41s/epoch, loss=1.19, accuracy=0.737, val_loss=2.24, val_accuracy=0.444, lr=0.1]  17%|█▋        | 13/78 [04:17<18:48, 17.36s/epoch, loss=1.17, accuracy=0.738, val_loss=1.78, val_accuracy=0.543, lr=0.1] 18%|█▊        | 14/78 [04:34<18:24, 17.25s/epoch, loss=1.18, accuracy=0.738, val_loss=2.29, val_accuracy=0.39, lr=0.1]  19%|█▉        | 15/78 [04:51<18:04, 17.21s/epoch, loss=1.17, accuracy=0.742, val_loss=1.92, val_accuracy=0.54, lr=0.1] 21%|██        | 16/78 [05:09<17:47, 17.21s/epoch, loss=1.17, accuracy=0.743, val_loss=1.82, val_accuracy=0.596, lr=0.0316] 22%|██▏       | 17/78 [05:26<17:36, 17.32s/epoch, loss=1.17, accuracy=0.742, val_loss=1.51, val_accuracy=0.637, lr=0.1]    23%|██▎       | 18/78 [05:43<17:14, 17.24s/epoch, loss=1.16, accuracy=0.746, val_loss=1.71, val_accuracy=0.566, lr=0.1] 24%|██▍       | 19/78 [06:01<17:01, 17.32s/epoch, loss=1.16, accuracy=0.745, val_loss=1.44, val_accuracy=0.646, lr=0.1] 26%|██▌       | 20/78 [06:18<16:37, 17.20s/epoch, loss=1.16, accuracy=0.747, val_loss=1.97, val_accuracy=0.582, lr=0.1] 27%|██▋       | 21/78 [06:35<16:23, 17.25s/epoch, loss=1.15, accuracy=0.746, val_loss=1.42, val_accuracy=0.667, lr=0.1] 28%|██▊       | 22/78 [06:52<16:03, 17.20s/epoch, loss=1.15, accuracy=0.748, val_loss=1.41, val_accuracy=0.671, lr=0.1] 29%|██▉       | 23/78 [07:09<15:43, 17.16s/epoch, loss=1.16, accuracy=0.747, val_loss=3.09, val_accuracy=0.434, lr=0.1] 31%|███       | 24/78 [07:27<15:29, 17.21s/epoch, loss=1.15, accuracy=0.749, val_loss=2.29, val_accuracy=0.491, lr=0.1] 32%|███▏      | 25/78 [07:44<15:15, 17.28s/epoch, loss=1.15, accuracy=0.747, val_loss=2.06, val_accuracy=0.527, lr=0.1] 33%|███▎      | 26/78 [08:01<15:01, 17.33s/epoch, loss=1.15, accuracy=0.748, val_loss=1.7, val_accuracy=0.551, lr=0.1]  35%|███▍      | 27/78 [08:18<14:39, 17.24s/epoch, loss=1.14, accuracy=0.751, val_loss=2.27, val_accuracy=0.518, lr=0.0316] 36%|███▌      | 28/78 [08:36<14:28, 17.36s/epoch, loss=1.15, accuracy=0.748, val_loss=2.19, val_accuracy=0.485, lr=0.1]    37%|███▋      | 29/78 [08:53<14:06, 17.28s/epoch, loss=1.15, accuracy=0.749, val_loss=2.33, val_accuracy=0.438, lr=0.1] 38%|███▊      | 30/78 [09:11<13:49, 17.29s/epoch, loss=1.13, accuracy=0.753, val_loss=1.55, val_accuracy=0.598, lr=0.1] 40%|███▉      | 31/78 [09:28<13:32, 17.28s/epoch, loss=1.14, accuracy=0.753, val_loss=3.33, val_accuracy=0.288, lr=0.1] 41%|████      | 32/78 [09:45<13:16, 17.32s/epoch, loss=1.14, accuracy=0.749, val_loss=2.14, val_accuracy=0.387, lr=0.0316] 42%|████▏     | 33/78 [10:03<13:00, 17.34s/epoch, loss=1.14, accuracy=0.751, val_loss=2.53, val_accuracy=0.492, lr=0.1]    44%|████▎     | 34/78 [10:20<12:39, 17.27s/epoch, loss=1.13, accuracy=0.75, val_loss=1.79, val_accuracy=0.54, lr=0.1]   45%|████▍     | 35/78 [10:37<12:19, 17.21s/epoch, loss=1.14, accuracy=0.75, val_loss=2.24, val_accuracy=0.472, lr=0.1] 46%|████▌     | 36/78 [10:54<12:01, 17.19s/epoch, loss=1.13, accuracy=0.752, val_loss=1.98, val_accuracy=0.499, lr=0.1] 47%|████▋     | 37/78 [11:11<11:45, 17.21s/epoch, loss=1.13, accuracy=0.752, val_loss=1.81, val_accuracy=0.556, lr=0.0316] 49%|████▊     | 38/78 [11:28<11:29, 17.25s/epoch, loss=1.14, accuracy=0.751, val_loss=1.89, val_accuracy=0.487, lr=0.1]    50%|█████     | 39/78 [11:46<11:11, 17.22s/epoch, loss=1.14, accuracy=0.751, val_loss=1.98, val_accuracy=0.488, lr=0.1] 51%|█████▏    | 40/78 [12:03<10:54, 17.23s/epoch, loss=1.12, accuracy=0.754, val_loss=2.79, val_accuracy=0.351, lr=0.1] 53%|█████▎    | 41/78 [12:20<10:36, 17.21s/epoch, loss=1.13, accuracy=0.75, val_loss=1.63, val_accuracy=0.583, lr=0.1]  54%|█████▍    | 42/78 [12:37<10:18, 17.18s/epoch, loss=1.12, accuracy=0.753, val_loss=1.8, val_accuracy=0.594, lr=0.0316] 55%|█████▌    | 43/78 [12:55<10:03, 17.25s/epoch, loss=1.13, accuracy=0.755, val_loss=2.52, val_accuracy=0.369, lr=0.1]   56%|█████▋    | 44/78 [13:12<09:45, 17.22s/epoch, loss=1.13, accuracy=0.755, val_loss=2.12, val_accuracy=0.452, lr=0.1] 58%|█████▊    | 45/78 [13:29<09:28, 17.23s/epoch, loss=1.12, accuracy=0.757, val_loss=1.88, val_accuracy=0.568, lr=0.1] 59%|█████▉    | 46/78 [13:46<09:12, 17.26s/epoch, loss=1.13, accuracy=0.753, val_loss=2.09, val_accuracy=0.477, lr=0.1] 60%|██████    | 47/78 [14:04<08:54, 17.25s/epoch, loss=1.12, accuracy=0.755, val_loss=1.8, val_accuracy=0.512, lr=0.0316] 62%|██████▏   | 48/78 [14:21<08:37, 17.24s/epoch, loss=1.13, accuracy=0.756, val_loss=1.51, val_accuracy=0.61, lr=0.1]    63%|██████▎   | 49/78 [14:38<08:19, 17.23s/epoch, loss=1.13, accuracy=0.753, val_loss=2.06, val_accuracy=0.453, lr=0.1] 64%|██████▍   | 50/78 [14:55<08:02, 17.23s/epoch, loss=1.12, accuracy=0.754, val_loss=3.51, val_accuracy=0.25, lr=0.1]  65%|██████▌   | 51/78 [15:12<07:42, 17.12s/epoch, loss=1.12, accuracy=0.757, val_loss=1.59, val_accuracy=0.586, lr=0.1] 67%|██████▋   | 52/78 [15:29<07:25, 17.15s/epoch, loss=1.12, accuracy=0.756, val_loss=1.73, val_accuracy=0.542, lr=0.0316] 68%|██████▊   | 53/78 [15:47<07:11, 17.25s/epoch, loss=1.12, accuracy=0.756, val_loss=2.29, val_accuracy=0.462, lr=0.1]    69%|██████▉   | 54/78 [16:04<06:53, 17.22s/epoch, loss=1.12, accuracy=0.755, val_loss=4.17, val_accuracy=0.285, lr=0.1] 71%|███████   | 55/78 [16:22<06:38, 17.33s/epoch, loss=1.13, accuracy=0.756, val_loss=1.59, val_accuracy=0.597, lr=0.1] 72%|███████▏  | 56/78 [16:39<06:19, 17.27s/epoch, loss=1.13, accuracy=0.757, val_loss=1.62, val_accuracy=0.586, lr=0.1] 73%|███████▎  | 57/78 [16:56<06:03, 17.29s/epoch, loss=1.12, accuracy=0.759, val_loss=2.22, val_accuracy=0.426, lr=0.0316] 74%|███████▍  | 58/78 [17:13<05:45, 17.27s/epoch, loss=1.12, accuracy=0.755, val_loss=2.09, val_accuracy=0.539, lr=0.1]    76%|███████▌  | 59/78 [17:31<05:28, 17.29s/epoch, loss=1.12, accuracy=0.754, val_loss=2.21, val_accuracy=0.438, lr=0.1] 77%|███████▋  | 60/78 [17:48<05:10, 17.25s/epoch, loss=1.12, accuracy=0.756, val_loss=1.51, val_accuracy=0.63, lr=0.1]  78%|███████▊  | 61/78 [18:05<04:53, 17.24s/epoch, loss=1.12, accuracy=0.754, val_loss=1.77, val_accuracy=0.563, lr=0.1] 79%|███████▉  | 62/78 [18:22<04:37, 17.33s/epoch, loss=1.12, accuracy=0.757, val_loss=1.67, val_accuracy=0.58, lr=0.0316] 81%|████████  | 63/78 [18:40<04:20, 17.34s/epoch, loss=1.13, accuracy=0.757, val_loss=2.31, val_accuracy=0.463, lr=0.1]   82%|████████▏ | 64/78 [18:57<04:03, 17.38s/epoch, loss=1.12, accuracy=0.756, val_loss=1.78, val_accuracy=0.565, lr=0.1] 83%|████████▎ | 65/78 [19:14<03:44, 17.26s/epoch, loss=1.12, accuracy=0.755, val_loss=1.45, val_accuracy=0.641, lr=0.1] 85%|████████▍ | 66/78 [19:32<03:27, 17.26s/epoch, loss=1.12, accuracy=0.757, val_loss=3.03, val_accuracy=0.373, lr=0.1] 86%|████████▌ | 67/78 [19:49<03:10, 17.30s/epoch, loss=1.12, accuracy=0.754, val_loss=1.97, val_accuracy=0.469, lr=0.0316] 87%|████████▋ | 68/78 [20:07<02:54, 17.45s/epoch, loss=1.12, accuracy=0.755, val_loss=1.71, val_accuracy=0.573, lr=0.1]    88%|████████▊ | 69/78 [20:24<02:37, 17.49s/epoch, loss=1.12, accuracy=0.756, val_loss=2.37, val_accuracy=0.475, lr=0.1] 90%|████████▉ | 70/78 [20:42<02:19, 17.43s/epoch, loss=1.12, accuracy=0.754, val_loss=1.85, val_accuracy=0.531, lr=0.1] 91%|█████████ | 71/78 [20:59<02:01, 17.41s/epoch, loss=1.12, accuracy=0.755, val_loss=2.29, val_accuracy=0.466, lr=0.1] 92%|█████████▏| 72/78 [21:16<01:43, 17.33s/epoch, loss=1.12, accuracy=0.757, val_loss=3.11, val_accuracy=0.277, lr=0.0316] 94%|█████████▎| 73/78 [21:33<01:26, 17.23s/epoch, loss=1.12, accuracy=0.756, val_loss=1.87, val_accuracy=0.554, lr=0.1]    95%|█████████▍| 74/78 [21:50<01:08, 17.21s/epoch, loss=1.12, accuracy=0.756, val_loss=1.97, val_accuracy=0.541, lr=0.1] 96%|█████████▌| 75/78 [22:08<00:51, 17.29s/epoch, loss=1.12, accuracy=0.754, val_loss=2.71, val_accuracy=0.331, lr=0.1] 97%|█████████▋| 76/78 [22:25<00:34, 17.23s/epoch, loss=1.12, accuracy=0.757, val_loss=1.68, val_accuracy=0.6, lr=0.1]   99%|█████████▊| 77/78 [22:42<00:17, 17.25s/epoch, loss=1.12, accuracy=0.755, val_loss=1.85, val_accuracy=0.535, lr=0.0316]100%|██████████| 78/78 [22:59<00:00, 17.16s/epoch, loss=1.13, accuracy=0.754, val_loss=2.24, val_accuracy=0.445, lr=0.1]   100%|██████████| 78/78 [22:59<00:00, 17.69s/epoch, loss=1.13, accuracy=0.754, val_loss=2.24, val_accuracy=0.445, lr=0.1]
Using real-time data augmentation.
Test score: 1.4201170206069946
Test accuracy: 0.6561999917030334


* * * Run SGD for ID = 19_8. * * *


2024-02-20 01:59:03.151692: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 01:59:05.641669: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 01:59:05.642634: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-20 01:59:05.679843: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-20 01:59:05.679882: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 01:59:05.682334: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 01:59:05.682371: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-20 01:59:05.684410: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-20 01:59:05.685430: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-20 01:59:05.687485: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-20 01:59:05.688754: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-20 01:59:05.692933: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 01:59:05.693507: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-20 01:59:05.693582: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 01:59:07.107266: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-20 01:59:07.108279: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 01:59:07.108998: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-20 01:59:07.109029: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 01:59:07.109064: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 01:59:07.109081: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-20 01:59:07.109098: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-20 01:59:07.109114: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-20 01:59:07.109130: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-20 01:59:07.109145: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-20 01:59:07.109160: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 01:59:07.109589: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-20 01:59:07.109621: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 01:59:07.722328: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-20 01:59:07.722382: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-20 01:59:07.722392: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-20 01:59:07.723260: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': '19_08', 'batch_size': 128, 'epochs': 78, 'validation_split': 0.1, 'checkpointing': True, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
x_train shape: (45000, 32, 32, 3)
45000 train samples
5000 validation samples
10000 test samples
y_train shape: (45000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/78 [00:00<?, ?epoch/s]2024-02-20 01:59:08.503229: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-20 01:59:08.515091: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600020000 Hz
2024-02-20 01:59:10.348193: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 01:59:10.547194: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 01:59:11.152120: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-20 01:59:11.201512: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|▏         | 1/78 [00:47<1:01:34, 47.98s/epoch, loss=3.47, accuracy=0.293, val_loss=2.81, val_accuracy=0.217, lr=0.1]  3%|▎         | 2/78 [01:06<38:37, 30.49s/epoch, loss=1.67, accuracy=0.498, val_loss=2.53, val_accuracy=0.299, lr=0.1]    4%|▍         | 3/78 [01:23<30:32, 24.43s/epoch, loss=1.45, accuracy=0.59, val_loss=2.32, val_accuracy=0.372, lr=0.1]   5%|▌         | 4/78 [01:40<26:44, 21.68s/epoch, loss=1.37, accuracy=0.642, val_loss=2.11, val_accuracy=0.459, lr=0.1]  6%|▋         | 5/78 [01:58<24:25, 20.07s/epoch, loss=1.3, accuracy=0.677, val_loss=2.12, val_accuracy=0.452, lr=0.1]   8%|▊         | 6/78 [02:15<23:02, 19.19s/epoch, loss=1.26, accuracy=0.699, val_loss=1.86, val_accuracy=0.486, lr=0.1]  9%|▉         | 7/78 [02:32<21:58, 18.57s/epoch, loss=1.24, accuracy=0.708, val_loss=1.58, val_accuracy=0.593, lr=0.1] 10%|█         | 8/78 [02:50<21:15, 18.22s/epoch, loss=1.23, accuracy=0.719, val_loss=2.02, val_accuracy=0.543, lr=0.1] 12%|█▏        | 9/78 [03:07<20:33, 17.88s/epoch, loss=1.23, accuracy=0.718, val_loss=1.88, val_accuracy=0.565, lr=0.1] 13%|█▎        | 10/78 [03:24<20:02, 17.68s/epoch, loss=1.21, accuracy=0.725, val_loss=2.16, val_accuracy=0.498, lr=0.1] 14%|█▍        | 11/78 [03:41<19:34, 17.52s/epoch, loss=1.2, accuracy=0.729, val_loss=3.01, val_accuracy=0.324, lr=0.1]  15%|█▌        | 12/78 [03:59<19:09, 17.42s/epoch, loss=1.2, accuracy=0.731, val_loss=1.82, val_accuracy=0.491, lr=0.0316] 17%|█▋        | 13/78 [04:16<18:45, 17.32s/epoch, loss=1.19, accuracy=0.733, val_loss=1.98, val_accuracy=0.484, lr=0.1]   18%|█▊        | 14/78 [04:33<18:27, 17.31s/epoch, loss=1.19, accuracy=0.736, val_loss=1.79, val_accuracy=0.521, lr=0.1] 19%|█▉        | 15/78 [04:50<18:14, 17.38s/epoch, loss=1.18, accuracy=0.737, val_loss=2.4, val_accuracy=0.381, lr=0.1]  21%|██        | 16/78 [05:08<18:00, 17.43s/epoch, loss=1.18, accuracy=0.737, val_loss=2.08, val_accuracy=0.425, lr=0.1] 22%|██▏       | 17/78 [05:25<17:40, 17.38s/epoch, loss=1.17, accuracy=0.739, val_loss=1.93, val_accuracy=0.541, lr=0.0316] 23%|██▎       | 18/78 [05:43<17:24, 17.41s/epoch, loss=1.17, accuracy=0.738, val_loss=2.3, val_accuracy=0.39, lr=0.1]      24%|██▍       | 19/78 [06:00<17:04, 17.37s/epoch, loss=1.17, accuracy=0.742, val_loss=2.61, val_accuracy=0.348, lr=0.1] 26%|██▌       | 20/78 [06:17<16:42, 17.29s/epoch, loss=1.17, accuracy=0.741, val_loss=1.91, val_accuracy=0.545, lr=0.1] 27%|██▋       | 21/78 [06:35<16:27, 17.32s/epoch, loss=1.16, accuracy=0.743, val_loss=1.81, val_accuracy=0.554, lr=0.1] 28%|██▊       | 22/78 [06:52<16:10, 17.34s/epoch, loss=1.16, accuracy=0.745, val_loss=2.24, val_accuracy=0.422, lr=0.0316] 29%|██▉       | 23/78 [07:10<16:00, 17.46s/epoch, loss=1.16, accuracy=0.743, val_loss=2.09, val_accuracy=0.459, lr=0.1]    31%|███       | 24/78 [07:27<15:39, 17.39s/epoch, loss=1.15, accuracy=0.744, val_loss=1.67, val_accuracy=0.579, lr=0.1] 32%|███▏      | 25/78 [07:45<15:25, 17.46s/epoch, loss=1.16, accuracy=0.746, val_loss=2.01, val_accuracy=0.477, lr=0.1] 33%|███▎      | 26/78 [08:02<15:07, 17.44s/epoch, loss=1.15, accuracy=0.746, val_loss=2.59, val_accuracy=0.44, lr=0.1]  35%|███▍      | 27/78 [08:19<14:46, 17.39s/epoch, loss=1.15, accuracy=0.745, val_loss=2.6, val_accuracy=0.406, lr=0.0316] 36%|███▌      | 28/78 [08:37<14:35, 17.51s/epoch, loss=1.14, accuracy=0.746, val_loss=2.38, val_accuracy=0.405, lr=0.1]   37%|███▋      | 29/78 [08:55<14:27, 17.71s/epoch, loss=1.14, accuracy=0.748, val_loss=2.18, val_accuracy=0.392, lr=0.1] 38%|███▊      | 30/78 [09:13<14:08, 17.68s/epoch, loss=1.15, accuracy=0.749, val_loss=2.63, val_accuracy=0.431, lr=0.1] 40%|███▉      | 31/78 [09:30<13:47, 17.61s/epoch, loss=1.14, accuracy=0.75, val_loss=1.67, val_accuracy=0.563, lr=0.1]  41%|████      | 32/78 [09:48<13:32, 17.66s/epoch, loss=1.14, accuracy=0.748, val_loss=1.5, val_accuracy=0.613, lr=0.1] 42%|████▏     | 33/78 [10:06<13:13, 17.63s/epoch, loss=1.14, accuracy=0.749, val_loss=3.94, val_accuracy=0.301, lr=0.1] 44%|████▎     | 34/78 [10:23<12:55, 17.63s/epoch, loss=1.13, accuracy=0.749, val_loss=2.62, val_accuracy=0.395, lr=0.1] 45%|████▍     | 35/78 [10:41<12:34, 17.55s/epoch, loss=1.13, accuracy=0.749, val_loss=2.02, val_accuracy=0.471, lr=0.1] 46%|████▌     | 36/78 [10:58<12:14, 17.49s/epoch, loss=1.13, accuracy=0.751, val_loss=2.31, val_accuracy=0.474, lr=0.1] 47%|████▋     | 37/78 [11:15<11:57, 17.50s/epoch, loss=1.13, accuracy=0.753, val_loss=2.82, val_accuracy=0.485, lr=0.0316] 49%|████▊     | 38/78 [11:33<11:39, 17.49s/epoch, loss=1.13, accuracy=0.75, val_loss=3.27, val_accuracy=0.283, lr=0.1]     50%|█████     | 39/78 [11:51<11:24, 17.56s/epoch, loss=1.13, accuracy=0.751, val_loss=2.84, val_accuracy=0.348, lr=0.1] 51%|█████▏    | 40/78 [12:08<11:04, 17.48s/epoch, loss=1.13, accuracy=0.751, val_loss=1.72, val_accuracy=0.541, lr=0.1] 53%|█████▎    | 41/78 [12:25<10:47, 17.49s/epoch, loss=1.13, accuracy=0.754, val_loss=2.62, val_accuracy=0.419, lr=0.1] 54%|█████▍    | 42/78 [12:43<10:28, 17.47s/epoch, loss=1.13, accuracy=0.751, val_loss=2.4, val_accuracy=0.409, lr=0.0316] 55%|█████▌    | 43/78 [13:00<10:10, 17.45s/epoch, loss=1.13, accuracy=0.75, val_loss=4.94, val_accuracy=0.228, lr=0.1]    56%|█████▋    | 44/78 [13:18<09:51, 17.39s/epoch, loss=1.12, accuracy=0.755, val_loss=2.93, val_accuracy=0.316, lr=0.1] 58%|█████▊    | 45/78 [13:35<09:34, 17.40s/epoch, loss=1.13, accuracy=0.752, val_loss=6.04, val_accuracy=0.224, lr=0.1] 59%|█████▉    | 46/78 [13:52<09:16, 17.40s/epoch, loss=1.13, accuracy=0.752, val_loss=2.86, val_accuracy=0.43, lr=0.1]  60%|██████    | 47/78 [14:10<09:03, 17.53s/epoch, loss=1.12, accuracy=0.755, val_loss=2.6, val_accuracy=0.416, lr=0.0316] 62%|██████▏   | 48/78 [14:28<08:44, 17.49s/epoch, loss=1.13, accuracy=0.754, val_loss=3.46, val_accuracy=0.316, lr=0.1]   63%|██████▎   | 49/78 [14:45<08:25, 17.45s/epoch, loss=1.13, accuracy=0.755, val_loss=2.11, val_accuracy=0.426, lr=0.1] 64%|██████▍   | 50/78 [15:02<08:07, 17.42s/epoch, loss=1.12, accuracy=0.755, val_loss=1.74, val_accuracy=0.581, lr=0.1] 65%|██████▌   | 51/78 [15:20<07:51, 17.45s/epoch, loss=1.12, accuracy=0.754, val_loss=2.23, val_accuracy=0.409, lr=0.1] 67%|██████▋   | 52/78 [15:37<07:33, 17.46s/epoch, loss=1.13, accuracy=0.753, val_loss=2.11, val_accuracy=0.52, lr=0.0316] 68%|██████▊   | 53/78 [15:55<07:16, 17.46s/epoch, loss=1.12, accuracy=0.754, val_loss=1.44, val_accuracy=0.642, lr=0.1]   69%|██████▉   | 54/78 [16:12<06:59, 17.47s/epoch, loss=1.12, accuracy=0.756, val_loss=1.92, val_accuracy=0.505, lr=0.1] 71%|███████   | 55/78 [16:29<06:40, 17.40s/epoch, loss=1.12, accuracy=0.753, val_loss=3.61, val_accuracy=0.328, lr=0.1] 72%|███████▏  | 56/78 [16:47<06:24, 17.46s/epoch, loss=1.12, accuracy=0.755, val_loss=1.44, val_accuracy=0.637, lr=0.1] 73%|███████▎  | 57/78 [17:04<06:05, 17.41s/epoch, loss=1.12, accuracy=0.754, val_loss=2.26, val_accuracy=0.385, lr=0.1] 74%|███████▍  | 58/78 [17:22<05:48, 17.44s/epoch, loss=1.11, accuracy=0.756, val_loss=1.45, val_accuracy=0.643, lr=0.1] 76%|███████▌  | 59/78 [17:39<05:29, 17.34s/epoch, loss=1.12, accuracy=0.752, val_loss=1.55, val_accuracy=0.622, lr=0.1] 77%|███████▋  | 60/78 [17:56<05:11, 17.30s/epoch, loss=1.12, accuracy=0.756, val_loss=2.17, val_accuracy=0.462, lr=0.1] 78%|███████▊  | 61/78 [18:14<04:55, 17.38s/epoch, loss=1.12, accuracy=0.754, val_loss=1.43, val_accuracy=0.641, lr=0.1] 79%|███████▉  | 62/78 [18:31<04:38, 17.39s/epoch, loss=1.11, accuracy=0.754, val_loss=2.2, val_accuracy=0.476, lr=0.1]  81%|████████  | 63/78 [18:48<04:20, 17.36s/epoch, loss=1.11, accuracy=0.754, val_loss=2.07, val_accuracy=0.506, lr=0.1] 82%|████████▏ | 64/78 [19:06<04:04, 17.48s/epoch, loss=1.11, accuracy=0.753, val_loss=2.35, val_accuracy=0.38, lr=0.1]  83%|████████▎ | 65/78 [19:24<03:46, 17.46s/epoch, loss=1.11, accuracy=0.756, val_loss=2.14, val_accuracy=0.463, lr=0.1] 85%|████████▍ | 66/78 [19:41<03:28, 17.36s/epoch, loss=1.11, accuracy=0.757, val_loss=1.58, val_accuracy=0.582, lr=0.0316] 86%|████████▌ | 67/78 [19:58<03:10, 17.33s/epoch, loss=1.12, accuracy=0.754, val_loss=2.41, val_accuracy=0.318, lr=0.1]    87%|████████▋ | 68/78 [20:16<02:54, 17.45s/epoch, loss=1.11, accuracy=0.753, val_loss=1.92, val_accuracy=0.524, lr=0.1] 88%|████████▊ | 69/78 [20:33<02:36, 17.43s/epoch, loss=1.12, accuracy=0.757, val_loss=3.12, val_accuracy=0.291, lr=0.1] 90%|████████▉ | 70/78 [20:50<02:18, 17.33s/epoch, loss=1.12, accuracy=0.754, val_loss=2.67, val_accuracy=0.48, lr=0.1]  91%|█████████ | 71/78 [21:07<02:01, 17.31s/epoch, loss=1.11, accuracy=0.752, val_loss=2.58, val_accuracy=0.29, lr=0.0316] 92%|█████████▏| 72/78 [21:25<01:44, 17.35s/epoch, loss=1.12, accuracy=0.754, val_loss=3.05, val_accuracy=0.339, lr=0.1]   94%|█████████▎| 73/78 [21:42<01:26, 17.38s/epoch, loss=1.12, accuracy=0.756, val_loss=2.77, val_accuracy=0.332, lr=0.1] 95%|█████████▍| 74/78 [21:59<01:09, 17.31s/epoch, loss=1.11, accuracy=0.758, val_loss=3.04, val_accuracy=0.351, lr=0.1] 96%|█████████▌| 75/78 [22:17<00:52, 17.48s/epoch, loss=1.12, accuracy=0.755, val_loss=1.61, val_accuracy=0.571, lr=0.1] 97%|█████████▋| 76/78 [22:35<00:34, 17.44s/epoch, loss=1.12, accuracy=0.755, val_loss=3.25, val_accuracy=0.289, lr=0.0316] 99%|█████████▊| 77/78 [22:52<00:17, 17.48s/epoch, loss=1.12, accuracy=0.755, val_loss=2.17, val_accuracy=0.398, lr=0.1]   100%|██████████| 78/78 [23:10<00:00, 17.56s/epoch, loss=1.11, accuracy=0.756, val_loss=3.44, val_accuracy=0.389, lr=0.1]100%|██████████| 78/78 [23:10<00:00, 17.83s/epoch, loss=1.11, accuracy=0.756, val_loss=3.44, val_accuracy=0.389, lr=0.1]
Using real-time data augmentation.
Test score: 1.4631905555725098
Test accuracy: 0.6348999738693237


* * * Run SGD for ID = 19_9. * * *


2024-02-20 02:22:26.249847: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 02:22:28.748510: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 02:22:28.749482: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-20 02:22:28.785200: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-20 02:22:28.785227: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 02:22:28.788023: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 02:22:28.788067: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-20 02:22:28.790288: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-20 02:22:28.791048: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-20 02:22:28.793385: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-20 02:22:28.794801: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-20 02:22:28.799430: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 02:22:28.799910: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-20 02:22:28.800007: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 02:22:30.191831: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-20 02:22:30.192816: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 02:22:30.193551: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-20 02:22:30.193582: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 02:22:30.193617: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 02:22:30.193634: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-20 02:22:30.193650: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-20 02:22:30.193665: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-20 02:22:30.193680: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-20 02:22:30.193695: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-20 02:22:30.193710: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 02:22:30.195195: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-20 02:22:30.195234: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 02:22:30.792783: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-20 02:22:30.792833: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-20 02:22:30.792841: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-20 02:22:30.793715: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': '19_09', 'batch_size': 128, 'epochs': 78, 'validation_split': 0.1, 'checkpointing': True, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
x_train shape: (45000, 32, 32, 3)
45000 train samples
5000 validation samples
10000 test samples
y_train shape: (45000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/78 [00:00<?, ?epoch/s]2024-02-20 02:22:31.568669: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-20 02:22:31.581083: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600020000 Hz
2024-02-20 02:22:33.452702: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 02:22:33.677918: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 02:22:34.326912: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-20 02:22:34.367090: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|▏         | 1/78 [00:47<1:01:15, 47.74s/epoch, loss=4.04, accuracy=0.283, val_loss=2.96, val_accuracy=0.184, lr=0.1]  3%|▎         | 2/78 [01:05<37:52, 29.91s/epoch, loss=1.82, accuracy=0.422, val_loss=2.08, val_accuracy=0.351, lr=0.1]    4%|▍         | 3/78 [01:21<29:50, 23.88s/epoch, loss=1.6, accuracy=0.485, val_loss=3.5, val_accuracy=0.187, lr=0.1]    5%|▌         | 4/78 [01:39<26:11, 21.24s/epoch, loss=1.48, accuracy=0.561, val_loss=2.13, val_accuracy=0.384, lr=0.1]  6%|▋         | 5/78 [01:56<24:04, 19.78s/epoch, loss=1.39, accuracy=0.616, val_loss=2.01, val_accuracy=0.386, lr=0.1]  8%|▊         | 6/78 [02:12<22:28, 18.73s/epoch, loss=1.34, accuracy=0.644, val_loss=2.43, val_accuracy=0.301, lr=0.1]  9%|▉         | 7/78 [02:29<21:27, 18.13s/epoch, loss=1.27, accuracy=0.677, val_loss=3.46, val_accuracy=0.267, lr=0.1] 10%|█         | 8/78 [02:47<20:52, 17.90s/epoch, loss=1.25, accuracy=0.689, val_loss=2.22, val_accuracy=0.459, lr=0.1] 12%|█▏        | 9/78 [03:04<20:14, 17.60s/epoch, loss=1.24, accuracy=0.698, val_loss=2.41, val_accuracy=0.328, lr=0.1] 13%|█▎        | 10/78 [03:21<19:41, 17.37s/epoch, loss=1.23, accuracy=0.704, val_loss=2.52, val_accuracy=0.388, lr=0.0316] 14%|█▍        | 11/78 [03:37<19:12, 17.21s/epoch, loss=1.23, accuracy=0.709, val_loss=10.3, val_accuracy=0.117, lr=0.1]    15%|█▌        | 12/78 [03:54<18:46, 17.07s/epoch, loss=1.22, accuracy=0.712, val_loss=4.32, val_accuracy=0.257, lr=0.1] 17%|█▋        | 13/78 [04:11<18:24, 16.99s/epoch, loss=1.21, accuracy=0.718, val_loss=3.89, val_accuracy=0.175, lr=0.1] 18%|█▊        | 14/78 [04:28<18:07, 17.00s/epoch, loss=1.2, accuracy=0.725, val_loss=4.1, val_accuracy=0.27, lr=0.1]    19%|█▉        | 15/78 [04:45<17:51, 17.01s/epoch, loss=1.21, accuracy=0.72, val_loss=1.89, val_accuracy=0.541, lr=0.1] 21%|██        | 16/78 [05:02<17:35, 17.02s/epoch, loss=1.2, accuracy=0.725, val_loss=1.68, val_accuracy=0.589, lr=0.1] 22%|██▏       | 17/78 [05:19<17:14, 16.96s/epoch, loss=1.19, accuracy=0.732, val_loss=3.88, val_accuracy=0.309, lr=0.1] 23%|██▎       | 18/78 [05:36<16:54, 16.90s/epoch, loss=1.19, accuracy=0.73, val_loss=3.2, val_accuracy=0.357, lr=0.1]   24%|██▍       | 19/78 [05:52<16:35, 16.87s/epoch, loss=1.19, accuracy=0.732, val_loss=6.13, val_accuracy=0.22, lr=0.1] 26%|██▌       | 20/78 [06:09<16:16, 16.83s/epoch, loss=1.18, accuracy=0.734, val_loss=2.2, val_accuracy=0.462, lr=0.1] 27%|██▋       | 21/78 [06:26<15:58, 16.82s/epoch, loss=1.19, accuracy=0.733, val_loss=6.46, val_accuracy=0.229, lr=0.0316] 28%|██▊       | 22/78 [06:43<15:41, 16.81s/epoch, loss=1.18, accuracy=0.735, val_loss=2.96, val_accuracy=0.281, lr=0.1]    29%|██▉       | 23/78 [07:00<15:26, 16.85s/epoch, loss=1.17, accuracy=0.739, val_loss=2.03, val_accuracy=0.47, lr=0.1]  31%|███       | 24/78 [07:17<15:09, 16.85s/epoch, loss=1.17, accuracy=0.737, val_loss=4.24, val_accuracy=0.231, lr=0.1] 32%|███▏      | 25/78 [07:34<14:56, 16.92s/epoch, loss=1.18, accuracy=0.738, val_loss=5.49, val_accuracy=0.184, lr=0.1] 33%|███▎      | 26/78 [07:51<14:40, 16.94s/epoch, loss=1.17, accuracy=0.741, val_loss=1.82, val_accuracy=0.486, lr=0.0316] 35%|███▍      | 27/78 [08:07<14:21, 16.89s/epoch, loss=1.17, accuracy=0.741, val_loss=2, val_accuracy=0.441, lr=0.1]       36%|███▌      | 28/78 [08:24<14:06, 16.92s/epoch, loss=1.17, accuracy=0.738, val_loss=1.75, val_accuracy=0.508, lr=0.1] 37%|███▋      | 29/78 [08:41<13:49, 16.92s/epoch, loss=1.16, accuracy=0.742, val_loss=2.79, val_accuracy=0.287, lr=0.1] 38%|███▊      | 30/78 [08:58<13:30, 16.88s/epoch, loss=1.16, accuracy=0.744, val_loss=2.41, val_accuracy=0.377, lr=0.1] 40%|███▉      | 31/78 [09:15<13:13, 16.89s/epoch, loss=1.16, accuracy=0.743, val_loss=2.09, val_accuracy=0.476, lr=0.0316] 41%|████      | 32/78 [09:32<12:54, 16.83s/epoch, loss=1.17, accuracy=0.744, val_loss=2.38, val_accuracy=0.44, lr=0.1]     42%|████▏     | 33/78 [09:49<12:37, 16.84s/epoch, loss=1.17, accuracy=0.741, val_loss=1.88, val_accuracy=0.448, lr=0.1] 44%|████▎     | 34/78 [10:05<12:16, 16.73s/epoch, loss=1.17, accuracy=0.743, val_loss=2.83, val_accuracy=0.435, lr=0.1] 45%|████▍     | 35/78 [10:21<11:52, 16.58s/epoch, loss=1.16, accuracy=0.744, val_loss=2.46, val_accuracy=0.483, lr=0.1] 46%|████▌     | 36/78 [10:37<11:28, 16.40s/epoch, loss=1.16, accuracy=0.743, val_loss=2.73, val_accuracy=0.421, lr=0.0316] 47%|████▋     | 37/78 [10:53<11:06, 16.27s/epoch, loss=1.15, accuracy=0.747, val_loss=1.63, val_accuracy=0.586, lr=0.1]    49%|████▊     | 38/78 [11:10<11:01, 16.54s/epoch, loss=1.15, accuracy=0.748, val_loss=4.58, val_accuracy=0.217, lr=0.1] 50%|█████     | 39/78 [11:27<10:49, 16.66s/epoch, loss=1.15, accuracy=0.748, val_loss=2.01, val_accuracy=0.514, lr=0.1] 51%|█████▏    | 40/78 [11:44<10:32, 16.65s/epoch, loss=1.16, accuracy=0.747, val_loss=3.91, val_accuracy=0.289, lr=0.1] 53%|█████▎    | 41/78 [12:01<10:17, 16.68s/epoch, loss=1.15, accuracy=0.747, val_loss=1.48, val_accuracy=0.625, lr=0.1] 54%|█████▍    | 42/78 [12:17<09:56, 16.56s/epoch, loss=1.16, accuracy=0.746, val_loss=2.42, val_accuracy=0.355, lr=0.1] 55%|█████▌    | 43/78 [12:33<09:35, 16.46s/epoch, loss=1.15, accuracy=0.746, val_loss=2.44, val_accuracy=0.39, lr=0.1]  56%|█████▋    | 44/78 [12:49<09:16, 16.36s/epoch, loss=1.14, accuracy=0.748, val_loss=2.41, val_accuracy=0.466, lr=0.1] 58%|█████▊    | 45/78 [13:06<09:02, 16.43s/epoch, loss=1.15, accuracy=0.748, val_loss=3.56, val_accuracy=0.275, lr=0.1] 59%|█████▉    | 46/78 [13:22<08:44, 16.40s/epoch, loss=1.15, accuracy=0.746, val_loss=2.68, val_accuracy=0.274, lr=0.0316] 60%|██████    | 47/78 [13:38<08:26, 16.33s/epoch, loss=1.15, accuracy=0.751, val_loss=5.85, val_accuracy=0.241, lr=0.1]    62%|██████▏   | 48/78 [13:55<08:10, 16.35s/epoch, loss=1.15, accuracy=0.747, val_loss=3.43, val_accuracy=0.323, lr=0.1] 63%|██████▎   | 49/78 [14:11<07:54, 16.38s/epoch, loss=1.14, accuracy=0.751, val_loss=2.61, val_accuracy=0.432, lr=0.1] 64%|██████▍   | 50/78 [14:28<07:39, 16.42s/epoch, loss=1.15, accuracy=0.748, val_loss=2.08, val_accuracy=0.415, lr=0.1] 65%|██████▌   | 51/78 [14:44<07:24, 16.45s/epoch, loss=1.14, accuracy=0.752, val_loss=2.08, val_accuracy=0.398, lr=0.0316] 67%|██████▋   | 52/78 [15:01<07:07, 16.46s/epoch, loss=1.14, accuracy=0.751, val_loss=4.97, val_accuracy=0.214, lr=0.1]    68%|██████▊   | 53/78 [15:17<06:51, 16.44s/epoch, loss=1.15, accuracy=0.749, val_loss=1.75, val_accuracy=0.521, lr=0.1] 69%|██████▉   | 54/78 [15:34<06:35, 16.47s/epoch, loss=1.14, accuracy=0.751, val_loss=2.71, val_accuracy=0.389, lr=0.1] 71%|███████   | 55/78 [15:50<06:18, 16.48s/epoch, loss=1.14, accuracy=0.75, val_loss=2.92, val_accuracy=0.33, lr=0.1]   72%|███████▏  | 56/78 [16:06<06:01, 16.43s/epoch, loss=1.14, accuracy=0.751, val_loss=3.1, val_accuracy=0.19, lr=0.0316] 73%|███████▎  | 57/78 [16:23<05:43, 16.38s/epoch, loss=1.14, accuracy=0.751, val_loss=1.94, val_accuracy=0.482, lr=0.1]  74%|███████▍  | 58/78 [16:39<05:27, 16.35s/epoch, loss=1.14, accuracy=0.75, val_loss=2.14, val_accuracy=0.426, lr=0.1]  76%|███████▌  | 59/78 [16:56<05:11, 16.41s/epoch, loss=1.15, accuracy=0.75, val_loss=4.37, val_accuracy=0.288, lr=0.1] 77%|███████▋  | 60/78 [17:12<04:55, 16.40s/epoch, loss=1.14, accuracy=0.753, val_loss=2.72, val_accuracy=0.332, lr=0.1] 78%|███████▊  | 61/78 [17:28<04:38, 16.41s/epoch, loss=1.14, accuracy=0.752, val_loss=3.05, val_accuracy=0.459, lr=0.0316] 79%|███████▉  | 62/78 [17:45<04:24, 16.50s/epoch, loss=1.14, accuracy=0.754, val_loss=3.99, val_accuracy=0.375, lr=0.1]    81%|████████  | 63/78 [18:02<04:09, 16.61s/epoch, loss=1.14, accuracy=0.751, val_loss=1.8, val_accuracy=0.54, lr=0.1]   82%|████████▏ | 64/78 [18:18<03:51, 16.54s/epoch, loss=1.13, accuracy=0.753, val_loss=2.59, val_accuracy=0.368, lr=0.1] 83%|████████▎ | 65/78 [18:35<03:34, 16.53s/epoch, loss=1.14, accuracy=0.753, val_loss=1.94, val_accuracy=0.526, lr=0.1] 85%|████████▍ | 66/78 [18:51<03:18, 16.51s/epoch, loss=1.14, accuracy=0.753, val_loss=6.38, val_accuracy=0.263, lr=0.0316] 86%|████████▌ | 67/78 [19:08<03:01, 16.50s/epoch, loss=1.13, accuracy=0.752, val_loss=4.05, val_accuracy=0.249, lr=0.1]    87%|████████▋ | 68/78 [19:24<02:45, 16.50s/epoch, loss=1.13, accuracy=0.751, val_loss=2.13, val_accuracy=0.41, lr=0.1]  88%|████████▊ | 69/78 [19:41<02:28, 16.45s/epoch, loss=1.14, accuracy=0.754, val_loss=4.17, val_accuracy=0.209, lr=0.1] 90%|████████▉ | 70/78 [19:57<02:11, 16.42s/epoch, loss=1.14, accuracy=0.753, val_loss=1.53, val_accuracy=0.594, lr=0.1] 91%|█████████ | 71/78 [20:13<01:54, 16.42s/epoch, loss=1.14, accuracy=0.754, val_loss=1.74, val_accuracy=0.548, lr=0.0316] 92%|█████████▏| 72/78 [20:30<01:38, 16.43s/epoch, loss=1.14, accuracy=0.752, val_loss=2.43, val_accuracy=0.349, lr=0.1]    94%|█████████▎| 73/78 [20:47<01:22, 16.50s/epoch, loss=1.14, accuracy=0.751, val_loss=5.32, val_accuracy=0.164, lr=0.1] 95%|█████████▍| 74/78 [21:03<01:06, 16.55s/epoch, loss=1.14, accuracy=0.753, val_loss=2.87, val_accuracy=0.349, lr=0.1] 96%|█████████▌| 75/78 [21:20<00:49, 16.56s/epoch, loss=1.14, accuracy=0.751, val_loss=2.14, val_accuracy=0.459, lr=0.1] 97%|█████████▋| 76/78 [21:36<00:33, 16.51s/epoch, loss=1.13, accuracy=0.753, val_loss=2.65, val_accuracy=0.389, lr=0.0316] 99%|█████████▊| 77/78 [21:52<00:16, 16.28s/epoch, loss=1.13, accuracy=0.754, val_loss=2.06, val_accuracy=0.463, lr=0.1]   100%|██████████| 78/78 [22:08<00:00, 16.29s/epoch, loss=1.12, accuracy=0.757, val_loss=3.85, val_accuracy=0.246, lr=0.1]100%|██████████| 78/78 [22:08<00:00, 17.04s/epoch, loss=1.12, accuracy=0.757, val_loss=3.85, val_accuracy=0.246, lr=0.1]
Using real-time data augmentation.
Test score: 1.4880263805389404
Test accuracy: 0.6226000189781189


* * * Run SGD for ID = 19_10. * * *


2024-02-20 02:44:47.920668: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 02:44:50.269436: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 02:44:50.270438: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-20 02:44:50.306709: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-20 02:44:50.306747: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 02:44:50.309683: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 02:44:50.309718: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-20 02:44:50.312123: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-20 02:44:50.312771: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-20 02:44:50.315164: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-20 02:44:50.316697: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-20 02:44:50.321111: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 02:44:50.321647: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-20 02:44:50.321741: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 02:44:51.746717: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-20 02:44:51.747723: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 02:44:51.748540: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-20 02:44:51.748570: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 02:44:51.748603: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 02:44:51.748620: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-20 02:44:51.748636: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-20 02:44:51.748653: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-20 02:44:51.748668: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-20 02:44:51.748683: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-20 02:44:51.748699: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 02:44:51.749146: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-20 02:44:51.749176: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 02:44:52.368589: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-20 02:44:52.368628: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-20 02:44:52.368644: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-20 02:44:52.369577: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': '19_10', 'batch_size': 128, 'epochs': 78, 'validation_split': 0.1, 'checkpointing': True, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
x_train shape: (45000, 32, 32, 3)
45000 train samples
5000 validation samples
10000 test samples
y_train shape: (45000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/78 [00:00<?, ?epoch/s]2024-02-20 02:44:53.153136: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-20 02:44:53.165094: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600020000 Hz
2024-02-20 02:44:55.005153: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 02:44:55.190829: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 02:44:55.861236: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-20 02:44:55.895510: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|▏         | 1/78 [00:47<1:01:16, 47.74s/epoch, loss=3.38, accuracy=0.296, val_loss=2.25, val_accuracy=0.275, lr=0.1]  3%|▎         | 2/78 [01:04<37:20, 29.48s/epoch, loss=1.72, accuracy=0.457, val_loss=2.66, val_accuracy=0.22, lr=0.1]     4%|▍         | 3/78 [01:21<29:35, 23.68s/epoch, loss=1.55, accuracy=0.533, val_loss=2.12, val_accuracy=0.366, lr=0.1]  5%|▌         | 4/78 [01:38<25:51, 20.97s/epoch, loss=1.45, accuracy=0.59, val_loss=1.69, val_accuracy=0.509, lr=0.1]   6%|▋         | 5/78 [01:54<23:33, 19.36s/epoch, loss=1.41, accuracy=0.625, val_loss=2.16, val_accuracy=0.354, lr=0.1]  8%|▊         | 6/78 [02:11<22:07, 18.43s/epoch, loss=1.36, accuracy=0.658, val_loss=1.64, val_accuracy=0.569, lr=0.1]  9%|▉         | 7/78 [02:27<21:05, 17.82s/epoch, loss=1.32, accuracy=0.68, val_loss=1.79, val_accuracy=0.533, lr=0.1]  10%|█         | 8/78 [02:44<20:23, 17.48s/epoch, loss=1.3, accuracy=0.691, val_loss=2.21, val_accuracy=0.455, lr=0.1] 12%|█▏        | 9/78 [03:00<19:44, 17.17s/epoch, loss=1.28, accuracy=0.703, val_loss=2.94, val_accuracy=0.314, lr=0.1] 13%|█▎        | 10/78 [03:17<19:17, 17.02s/epoch, loss=1.27, accuracy=0.708, val_loss=1.69, val_accuracy=0.562, lr=0.1] 14%|█▍        | 11/78 [03:34<18:50, 16.88s/epoch, loss=1.26, accuracy=0.713, val_loss=2.38, val_accuracy=0.457, lr=0.0316] 15%|█▌        | 12/78 [03:50<18:24, 16.74s/epoch, loss=1.25, accuracy=0.722, val_loss=1.87, val_accuracy=0.562, lr=0.1]    17%|█▋        | 13/78 [04:07<18:04, 16.69s/epoch, loss=1.25, accuracy=0.723, val_loss=3.52, val_accuracy=0.377, lr=0.1] 18%|█▊        | 14/78 [04:23<17:45, 16.64s/epoch, loss=1.25, accuracy=0.722, val_loss=1.82, val_accuracy=0.537, lr=0.1] 19%|█▉        | 15/78 [04:40<17:26, 16.60s/epoch, loss=1.24, accuracy=0.724, val_loss=1.98, val_accuracy=0.539, lr=0.1] 21%|██        | 16/78 [04:56<17:06, 16.56s/epoch, loss=1.23, accuracy=0.73, val_loss=1.86, val_accuracy=0.491, lr=0.0316] 22%|██▏       | 17/78 [05:13<16:52, 16.59s/epoch, loss=1.23, accuracy=0.729, val_loss=1.96, val_accuracy=0.535, lr=0.1]   23%|██▎       | 18/78 [05:30<16:36, 16.60s/epoch, loss=1.22, accuracy=0.729, val_loss=2.2, val_accuracy=0.482, lr=0.1]  24%|██▍       | 19/78 [05:46<16:21, 16.64s/epoch, loss=1.22, accuracy=0.735, val_loss=1.95, val_accuracy=0.512, lr=0.1] 26%|██▌       | 20/78 [06:03<16:10, 16.74s/epoch, loss=1.21, accuracy=0.734, val_loss=2.26, val_accuracy=0.494, lr=0.1] 27%|██▋       | 21/78 [06:20<15:58, 16.81s/epoch, loss=1.22, accuracy=0.731, val_loss=1.87, val_accuracy=0.518, lr=0.0316] 28%|██▊       | 22/78 [06:37<15:39, 16.77s/epoch, loss=1.22, accuracy=0.735, val_loss=1.93, val_accuracy=0.5, lr=0.1]      29%|██▉       | 23/78 [06:53<15:15, 16.65s/epoch, loss=1.22, accuracy=0.734, val_loss=2.75, val_accuracy=0.456, lr=0.1] 31%|███       | 24/78 [07:10<14:58, 16.63s/epoch, loss=1.2, accuracy=0.737, val_loss=2.78, val_accuracy=0.403, lr=0.1]  32%|███▏      | 25/78 [07:27<14:46, 16.72s/epoch, loss=1.21, accuracy=0.736, val_loss=1.83, val_accuracy=0.593, lr=0.1] 33%|███▎      | 26/78 [07:43<14:28, 16.70s/epoch, loss=1.2, accuracy=0.735, val_loss=1.56, val_accuracy=0.63, lr=0.1]   35%|███▍      | 27/78 [08:00<14:14, 16.75s/epoch, loss=1.2, accuracy=0.738, val_loss=1.73, val_accuracy=0.593, lr=0.1] 36%|███▌      | 28/78 [08:17<13:55, 16.71s/epoch, loss=1.2, accuracy=0.737, val_loss=2.04, val_accuracy=0.498, lr=0.1] 37%|███▋      | 29/78 [08:33<13:36, 16.67s/epoch, loss=1.2, accuracy=0.738, val_loss=2.35, val_accuracy=0.442, lr=0.1] 38%|███▊      | 30/78 [08:50<13:19, 16.66s/epoch, loss=1.19, accuracy=0.738, val_loss=2.1, val_accuracy=0.502, lr=0.1] 40%|███▉      | 31/78 [09:07<13:01, 16.62s/epoch, loss=1.2, accuracy=0.74, val_loss=1.96, val_accuracy=0.535, lr=0.0316] 41%|████      | 32/78 [09:23<12:44, 16.63s/epoch, loss=1.2, accuracy=0.74, val_loss=1.98, val_accuracy=0.534, lr=0.1]    42%|████▏     | 33/78 [09:40<12:26, 16.60s/epoch, loss=1.19, accuracy=0.74, val_loss=2.7, val_accuracy=0.367, lr=0.1] 44%|████▎     | 34/78 [09:56<12:10, 16.60s/epoch, loss=1.18, accuracy=0.741, val_loss=2.35, val_accuracy=0.472, lr=0.1] 45%|████▍     | 35/78 [10:13<11:54, 16.62s/epoch, loss=1.18, accuracy=0.742, val_loss=2.31, val_accuracy=0.408, lr=0.1] 46%|████▌     | 36/78 [10:30<11:39, 16.66s/epoch, loss=1.19, accuracy=0.742, val_loss=1.81, val_accuracy=0.551, lr=0.0316] 47%|████▋     | 37/78 [10:46<11:20, 16.60s/epoch, loss=1.19, accuracy=0.74, val_loss=1.64, val_accuracy=0.56, lr=0.1]      49%|████▊     | 38/78 [11:03<11:02, 16.56s/epoch, loss=1.18, accuracy=0.743, val_loss=1.9, val_accuracy=0.533, lr=0.1] 50%|█████     | 39/78 [11:19<10:45, 16.54s/epoch, loss=1.19, accuracy=0.744, val_loss=2.75, val_accuracy=0.449, lr=0.1] 51%|█████▏    | 40/78 [11:36<10:33, 16.66s/epoch, loss=1.18, accuracy=0.743, val_loss=1.52, val_accuracy=0.627, lr=0.1] 53%|█████▎    | 41/78 [11:53<10:19, 16.73s/epoch, loss=1.18, accuracy=0.745, val_loss=1.57, val_accuracy=0.631, lr=0.1] 54%|█████▍    | 42/78 [12:10<10:04, 16.78s/epoch, loss=1.18, accuracy=0.743, val_loss=1.54, val_accuracy=0.623, lr=0.1] 55%|█████▌    | 43/78 [12:27<09:44, 16.71s/epoch, loss=1.18, accuracy=0.744, val_loss=1.69, val_accuracy=0.544, lr=0.1] 56%|█████▋    | 44/78 [12:43<09:27, 16.69s/epoch, loss=1.17, accuracy=0.747, val_loss=2.04, val_accuracy=0.528, lr=0.1] 58%|█████▊    | 45/78 [13:00<09:10, 16.70s/epoch, loss=1.18, accuracy=0.745, val_loss=2.77, val_accuracy=0.42, lr=0.0316] 59%|█████▉    | 46/78 [13:17<08:56, 16.75s/epoch, loss=1.17, accuracy=0.746, val_loss=1.69, val_accuracy=0.545, lr=0.1]   60%|██████    | 47/78 [13:34<08:40, 16.79s/epoch, loss=1.17, accuracy=0.748, val_loss=2.75, val_accuracy=0.324, lr=0.1] 62%|██████▏   | 48/78 [13:50<08:23, 16.79s/epoch, loss=1.17, accuracy=0.746, val_loss=1.77, val_accuracy=0.549, lr=0.1] 63%|██████▎   | 49/78 [14:07<08:08, 16.85s/epoch, loss=1.17, accuracy=0.746, val_loss=2.43, val_accuracy=0.39, lr=0.1]  64%|██████▍   | 50/78 [14:24<07:50, 16.81s/epoch, loss=1.16, accuracy=0.747, val_loss=2.25, val_accuracy=0.521, lr=0.0316] 65%|██████▌   | 51/78 [14:41<07:34, 16.82s/epoch, loss=1.17, accuracy=0.745, val_loss=2.22, val_accuracy=0.48, lr=0.1]     67%|██████▋   | 52/78 [14:58<07:15, 16.75s/epoch, loss=1.17, accuracy=0.744, val_loss=2.01, val_accuracy=0.512, lr=0.1] 68%|██████▊   | 53/78 [15:14<06:58, 16.74s/epoch, loss=1.16, accuracy=0.747, val_loss=2.11, val_accuracy=0.44, lr=0.1]  69%|██████▉   | 54/78 [15:31<06:40, 16.68s/epoch, loss=1.16, accuracy=0.748, val_loss=4.14, val_accuracy=0.282, lr=0.1] 71%|███████   | 55/78 [15:47<06:23, 16.66s/epoch, loss=1.16, accuracy=0.751, val_loss=2.49, val_accuracy=0.495, lr=0.0316] 72%|███████▏  | 56/78 [16:05<06:10, 16.86s/epoch, loss=1.17, accuracy=0.748, val_loss=1.67, val_accuracy=0.552, lr=0.1]    73%|███████▎  | 57/78 [16:21<05:51, 16.76s/epoch, loss=1.16, accuracy=0.748, val_loss=3.03, val_accuracy=0.441, lr=0.1] 74%|███████▍  | 58/78 [16:38<05:34, 16.74s/epoch, loss=1.16, accuracy=0.749, val_loss=2.25, val_accuracy=0.46, lr=0.1]  76%|███████▌  | 59/78 [16:55<05:17, 16.70s/epoch, loss=1.17, accuracy=0.747, val_loss=1.91, val_accuracy=0.522, lr=0.1] 77%|███████▋  | 60/78 [17:11<04:59, 16.64s/epoch, loss=1.16, accuracy=0.75, val_loss=2.02, val_accuracy=0.518, lr=0.0316] 78%|███████▊  | 61/78 [17:28<04:44, 16.71s/epoch, loss=1.16, accuracy=0.752, val_loss=1.88, val_accuracy=0.538, lr=0.1]   79%|███████▉  | 62/78 [17:45<04:27, 16.74s/epoch, loss=1.17, accuracy=0.747, val_loss=4.49, val_accuracy=0.261, lr=0.1] 81%|████████  | 63/78 [18:01<04:10, 16.72s/epoch, loss=1.16, accuracy=0.75, val_loss=2.24, val_accuracy=0.44, lr=0.1]   82%|████████▏ | 64/78 [18:18<03:53, 16.70s/epoch, loss=1.16, accuracy=0.749, val_loss=2.17, val_accuracy=0.527, lr=0.1] 83%|████████▎ | 65/78 [18:35<03:36, 16.67s/epoch, loss=1.15, accuracy=0.75, val_loss=1.87, val_accuracy=0.516, lr=0.0316] 85%|████████▍ | 66/78 [18:52<03:20, 16.71s/epoch, loss=1.16, accuracy=0.752, val_loss=3.24, val_accuracy=0.306, lr=0.1]   86%|████████▌ | 67/78 [19:08<03:03, 16.69s/epoch, loss=1.16, accuracy=0.75, val_loss=1.97, val_accuracy=0.515, lr=0.1]  87%|████████▋ | 68/78 [19:25<02:47, 16.74s/epoch, loss=1.16, accuracy=0.751, val_loss=2.82, val_accuracy=0.432, lr=0.1] 88%|████████▊ | 69/78 [19:42<02:31, 16.79s/epoch, loss=1.15, accuracy=0.752, val_loss=2.33, val_accuracy=0.414, lr=0.1] 90%|████████▉ | 70/78 [19:59<02:14, 16.79s/epoch, loss=1.16, accuracy=0.751, val_loss=2.37, val_accuracy=0.453, lr=0.0316] 91%|█████████ | 71/78 [20:16<01:57, 16.80s/epoch, loss=1.15, accuracy=0.752, val_loss=6.17, val_accuracy=0.217, lr=0.1]    92%|█████████▏| 72/78 [20:32<01:40, 16.83s/epoch, loss=1.16, accuracy=0.75, val_loss=2.21, val_accuracy=0.363, lr=0.1]  94%|█████████▎| 73/78 [20:49<01:24, 16.85s/epoch, loss=1.15, accuracy=0.752, val_loss=1.68, val_accuracy=0.565, lr=0.1] 95%|█████████▍| 74/78 [21:07<01:08, 17.01s/epoch, loss=1.15, accuracy=0.75, val_loss=2.19, val_accuracy=0.414, lr=0.1]  96%|█████████▌| 75/78 [21:24<00:51, 17.15s/epoch, loss=1.16, accuracy=0.749, val_loss=1.76, val_accuracy=0.537, lr=0.0316] 97%|█████████▋| 76/78 [21:41<00:34, 17.04s/epoch, loss=1.15, accuracy=0.751, val_loss=2.09, val_accuracy=0.499, lr=0.1]    99%|█████████▊| 77/78 [21:58<00:16, 16.95s/epoch, loss=1.16, accuracy=0.751, val_loss=3.45, val_accuracy=0.374, lr=0.1]100%|██████████| 78/78 [22:14<00:00, 16.84s/epoch, loss=1.15, accuracy=0.75, val_loss=2.62, val_accuracy=0.43, lr=0.1]  100%|██████████| 78/78 [22:14<00:00, 17.11s/epoch, loss=1.15, accuracy=0.75, val_loss=2.62, val_accuracy=0.43, lr=0.1]
Using real-time data augmentation.
Test score: 1.5724431276321411
Test accuracy: 0.6226000189781189


* * * Run SGD for ID = 19_11. * * *


2024-02-20 03:07:15.133141: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 03:07:17.991843: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 03:07:17.992833: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-20 03:07:18.029351: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-20 03:07:18.029383: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 03:07:18.032298: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 03:07:18.032341: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-20 03:07:18.034384: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-20 03:07:18.035452: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-20 03:07:18.037607: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-20 03:07:18.038903: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-20 03:07:18.043453: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 03:07:18.043952: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-20 03:07:18.044049: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 03:07:19.406085: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-20 03:07:19.408173: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 03:07:19.408893: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-20 03:07:19.408923: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 03:07:19.408965: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 03:07:19.408983: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-20 03:07:19.408999: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-20 03:07:19.409015: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-20 03:07:19.409029: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-20 03:07:19.409052: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-20 03:07:19.409067: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 03:07:19.409488: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-20 03:07:19.409521: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 03:07:19.987454: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-20 03:07:19.987506: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-20 03:07:19.987514: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-20 03:07:19.988359: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': '19_11', 'batch_size': 128, 'epochs': 78, 'validation_split': 0.1, 'checkpointing': True, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
x_train shape: (45000, 32, 32, 3)
45000 train samples
5000 validation samples
10000 test samples
y_train shape: (45000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/78 [00:00<?, ?epoch/s]2024-02-20 03:07:20.723690: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-20 03:07:20.724099: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600020000 Hz
2024-02-20 03:07:22.436070: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 03:07:22.623497: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 03:07:23.337445: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-20 03:07:23.381536: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|▏         | 1/78 [00:47<1:00:46, 47.35s/epoch, loss=3.28, accuracy=0.304, val_loss=2.44, val_accuracy=0.235, lr=0.1]  3%|▎         | 2/78 [01:04<37:43, 29.78s/epoch, loss=1.61, accuracy=0.522, val_loss=2.03, val_accuracy=0.442, lr=0.1]    4%|▍         | 3/78 [01:21<29:35, 23.68s/epoch, loss=1.41, accuracy=0.612, val_loss=1.98, val_accuracy=0.411, lr=0.1]  5%|▌         | 4/78 [01:37<25:36, 20.76s/epoch, loss=1.31, accuracy=0.668, val_loss=2.26, val_accuracy=0.437, lr=0.1]  6%|▋         | 5/78 [01:53<23:17, 19.14s/epoch, loss=1.27, accuracy=0.689, val_loss=1.67, val_accuracy=0.578, lr=0.1]  8%|▊         | 6/78 [02:10<21:49, 18.19s/epoch, loss=1.25, accuracy=0.706, val_loss=1.52, val_accuracy=0.635, lr=0.1]  9%|▉         | 7/78 [02:25<20:36, 17.42s/epoch, loss=1.23, accuracy=0.714, val_loss=2.11, val_accuracy=0.462, lr=0.1] 10%|█         | 8/78 [02:41<19:46, 16.95s/epoch, loss=1.23, accuracy=0.717, val_loss=2.01, val_accuracy=0.526, lr=0.1] 12%|█▏        | 9/78 [02:57<19:08, 16.64s/epoch, loss=1.22, accuracy=0.723, val_loss=1.73, val_accuracy=0.57, lr=0.1]  13%|█▎        | 10/78 [03:14<18:41, 16.49s/epoch, loss=1.21, accuracy=0.727, val_loss=1.85, val_accuracy=0.518, lr=0.1] 14%|█▍        | 11/78 [03:30<18:31, 16.60s/epoch, loss=1.2, accuracy=0.729, val_loss=2.04, val_accuracy=0.533, lr=0.0316] 15%|█▌        | 12/78 [03:47<18:08, 16.50s/epoch, loss=1.19, accuracy=0.732, val_loss=1.98, val_accuracy=0.544, lr=0.1]   17%|█▋        | 13/78 [04:03<17:47, 16.42s/epoch, loss=1.19, accuracy=0.733, val_loss=1.53, val_accuracy=0.648, lr=0.1] 18%|█▊        | 14/78 [04:19<17:16, 16.19s/epoch, loss=1.18, accuracy=0.736, val_loss=3.14, val_accuracy=0.409, lr=0.1] 19%|█▉        | 15/78 [04:35<16:57, 16.14s/epoch, loss=1.19, accuracy=0.734, val_loss=1.76, val_accuracy=0.567, lr=0.1] 21%|██        | 16/78 [04:51<16:41, 16.16s/epoch, loss=1.17, accuracy=0.738, val_loss=1.65, val_accuracy=0.575, lr=0.0316] 22%|██▏       | 17/78 [05:07<16:28, 16.20s/epoch, loss=1.17, accuracy=0.739, val_loss=2.13, val_accuracy=0.468, lr=0.1]    23%|██▎       | 18/78 [05:23<16:12, 16.21s/epoch, loss=1.18, accuracy=0.74, val_loss=1.56, val_accuracy=0.613, lr=0.1]  24%|██▍       | 19/78 [05:39<15:55, 16.20s/epoch, loss=1.17, accuracy=0.741, val_loss=5.53, val_accuracy=0.272, lr=0.1] 26%|██▌       | 20/78 [05:56<15:38, 16.18s/epoch, loss=1.17, accuracy=0.741, val_loss=2.15, val_accuracy=0.494, lr=0.1] 27%|██▋       | 21/78 [06:11<15:16, 16.07s/epoch, loss=1.17, accuracy=0.742, val_loss=2.43, val_accuracy=0.395, lr=0.0316] 28%|██▊       | 22/78 [06:27<14:55, 15.99s/epoch, loss=1.16, accuracy=0.744, val_loss=1.67, val_accuracy=0.587, lr=0.1]    29%|██▉       | 23/78 [06:44<14:50, 16.19s/epoch, loss=1.16, accuracy=0.744, val_loss=1.76, val_accuracy=0.555, lr=0.1] 31%|███       | 24/78 [07:00<14:34, 16.19s/epoch, loss=1.16, accuracy=0.744, val_loss=2.02, val_accuracy=0.518, lr=0.1] 32%|███▏      | 25/78 [07:16<14:08, 16.02s/epoch, loss=1.15, accuracy=0.747, val_loss=2.09, val_accuracy=0.481, lr=0.1] 33%|███▎      | 26/78 [07:32<13:56, 16.08s/epoch, loss=1.15, accuracy=0.748, val_loss=1.6, val_accuracy=0.584, lr=0.0316] 35%|███▍      | 27/78 [07:48<13:45, 16.19s/epoch, loss=1.15, accuracy=0.748, val_loss=2.55, val_accuracy=0.465, lr=0.1]   36%|███▌      | 28/78 [08:05<13:30, 16.22s/epoch, loss=1.15, accuracy=0.747, val_loss=2.23, val_accuracy=0.462, lr=0.1] 37%|███▋      | 29/78 [08:21<13:13, 16.19s/epoch, loss=1.15, accuracy=0.744, val_loss=1.58, val_accuracy=0.604, lr=0.1] 38%|███▊      | 30/78 [08:37<12:56, 16.17s/epoch, loss=1.14, accuracy=0.75, val_loss=2.38, val_accuracy=0.435, lr=0.1]  40%|███▉      | 31/78 [08:54<12:46, 16.30s/epoch, loss=1.15, accuracy=0.748, val_loss=1.4, val_accuracy=0.657, lr=0.1] 41%|████      | 32/78 [09:10<12:26, 16.22s/epoch, loss=1.14, accuracy=0.752, val_loss=1.63, val_accuracy=0.572, lr=0.1] 42%|████▏     | 33/78 [09:25<12:03, 16.09s/epoch, loss=1.14, accuracy=0.747, val_loss=1.58, val_accuracy=0.614, lr=0.1] 44%|████▎     | 34/78 [09:42<11:54, 16.24s/epoch, loss=1.14, accuracy=0.751, val_loss=2.25, val_accuracy=0.477, lr=0.1] 45%|████▍     | 35/78 [09:58<11:35, 16.18s/epoch, loss=1.14, accuracy=0.747, val_loss=1.94, val_accuracy=0.519, lr=0.1] 46%|████▌     | 36/78 [10:15<11:24, 16.29s/epoch, loss=1.13, accuracy=0.752, val_loss=2.55, val_accuracy=0.464, lr=0.0316] 47%|████▋     | 37/78 [10:31<11:09, 16.33s/epoch, loss=1.14, accuracy=0.749, val_loss=1.64, val_accuracy=0.613, lr=0.1]    49%|████▊     | 38/78 [10:47<10:55, 16.38s/epoch, loss=1.13, accuracy=0.753, val_loss=1.98, val_accuracy=0.454, lr=0.1] 50%|█████     | 39/78 [11:03<10:32, 16.22s/epoch, loss=1.13, accuracy=0.75, val_loss=2.15, val_accuracy=0.482, lr=0.1]  51%|█████▏    | 40/78 [11:20<10:16, 16.22s/epoch, loss=1.13, accuracy=0.752, val_loss=1.89, val_accuracy=0.511, lr=0.1] 53%|█████▎    | 41/78 [11:36<10:03, 16.31s/epoch, loss=1.14, accuracy=0.752, val_loss=2.15, val_accuracy=0.489, lr=0.0316] 54%|█████▍    | 42/78 [11:52<09:48, 16.34s/epoch, loss=1.12, accuracy=0.754, val_loss=2.06, val_accuracy=0.489, lr=0.1]    55%|█████▌    | 43/78 [12:09<09:32, 16.35s/epoch, loss=1.13, accuracy=0.754, val_loss=3.05, val_accuracy=0.338, lr=0.1] 56%|█████▋    | 44/78 [12:25<09:17, 16.38s/epoch, loss=1.13, accuracy=0.753, val_loss=2.76, val_accuracy=0.391, lr=0.1] 58%|█████▊    | 45/78 [12:41<08:58, 16.31s/epoch, loss=1.13, accuracy=0.753, val_loss=1.64, val_accuracy=0.604, lr=0.1] 59%|█████▉    | 46/78 [12:57<08:39, 16.23s/epoch, loss=1.12, accuracy=0.753, val_loss=1.95, val_accuracy=0.514, lr=0.0316] 60%|██████    | 47/78 [13:13<08:18, 16.07s/epoch, loss=1.12, accuracy=0.757, val_loss=2.6, val_accuracy=0.386, lr=0.1]     62%|██████▏   | 48/78 [13:29<08:00, 16.01s/epoch, loss=1.12, accuracy=0.757, val_loss=2.24, val_accuracy=0.487, lr=0.1] 63%|██████▎   | 49/78 [13:45<07:44, 16.00s/epoch, loss=1.13, accuracy=0.752, val_loss=2.5, val_accuracy=0.418, lr=0.1]  64%|██████▍   | 50/78 [14:01<07:25, 15.91s/epoch, loss=1.13, accuracy=0.755, val_loss=2.32, val_accuracy=0.53, lr=0.1] 65%|██████▌   | 51/78 [14:16<07:08, 15.85s/epoch, loss=1.12, accuracy=0.756, val_loss=1.69, val_accuracy=0.586, lr=0.0316] 67%|██████▋   | 52/78 [14:33<06:56, 16.03s/epoch, loss=1.12, accuracy=0.756, val_loss=3.04, val_accuracy=0.305, lr=0.1]    68%|██████▊   | 53/78 [14:49<06:39, 15.99s/epoch, loss=1.12, accuracy=0.755, val_loss=2.27, val_accuracy=0.482, lr=0.1] 69%|██████▉   | 54/78 [15:05<06:23, 15.98s/epoch, loss=1.13, accuracy=0.751, val_loss=2, val_accuracy=0.483, lr=0.1]    71%|███████   | 55/78 [15:21<06:07, 15.98s/epoch, loss=1.12, accuracy=0.756, val_loss=1.83, val_accuracy=0.585, lr=0.1] 72%|███████▏  | 56/78 [15:37<05:51, 15.99s/epoch, loss=1.12, accuracy=0.756, val_loss=1.89, val_accuracy=0.569, lr=0.0316] 73%|███████▎  | 57/78 [15:53<05:37, 16.06s/epoch, loss=1.12, accuracy=0.753, val_loss=2.08, val_accuracy=0.514, lr=0.1]    74%|███████▍  | 58/78 [16:09<05:20, 16.04s/epoch, loss=1.12, accuracy=0.757, val_loss=2.38, val_accuracy=0.37, lr=0.1]  76%|███████▌  | 59/78 [16:24<05:02, 15.90s/epoch, loss=1.12, accuracy=0.756, val_loss=2.16, val_accuracy=0.45, lr=0.1] 77%|███████▋  | 60/78 [16:40<04:45, 15.87s/epoch, loss=1.11, accuracy=0.756, val_loss=2.54, val_accuracy=0.355, lr=0.1] 78%|███████▊  | 61/78 [16:57<04:32, 16.01s/epoch, loss=1.12, accuracy=0.754, val_loss=4.36, val_accuracy=0.385, lr=0.0316] 79%|███████▉  | 62/78 [17:13<04:16, 16.04s/epoch, loss=1.11, accuracy=0.758, val_loss=1.98, val_accuracy=0.526, lr=0.1]    81%|████████  | 63/78 [17:29<04:00, 16.04s/epoch, loss=1.12, accuracy=0.758, val_loss=2.38, val_accuracy=0.333, lr=0.1] 82%|████████▏ | 64/78 [17:45<03:44, 16.01s/epoch, loss=1.12, accuracy=0.756, val_loss=1.73, val_accuracy=0.513, lr=0.1] 83%|████████▎ | 65/78 [18:01<03:27, 15.96s/epoch, loss=1.11, accuracy=0.759, val_loss=2.06, val_accuracy=0.465, lr=0.1] 85%|████████▍ | 66/78 [18:17<03:12, 16.06s/epoch, loss=1.12, accuracy=0.754, val_loss=2.05, val_accuracy=0.487, lr=0.0316] 86%|████████▌ | 67/78 [18:34<02:59, 16.27s/epoch, loss=1.11, accuracy=0.759, val_loss=2.02, val_accuracy=0.5, lr=0.1]      87%|████████▋ | 68/78 [18:50<02:43, 16.34s/epoch, loss=1.12, accuracy=0.755, val_loss=3.01, val_accuracy=0.268, lr=0.1] 88%|████████▊ | 69/78 [19:07<02:27, 16.44s/epoch, loss=1.11, accuracy=0.756, val_loss=2.24, val_accuracy=0.372, lr=0.1] 90%|████████▉ | 70/78 [19:23<02:11, 16.45s/epoch, loss=1.11, accuracy=0.757, val_loss=3.47, val_accuracy=0.251, lr=0.1] 91%|█████████ | 71/78 [19:39<01:54, 16.37s/epoch, loss=1.12, accuracy=0.756, val_loss=1.76, val_accuracy=0.579, lr=0.0316] 92%|█████████▏| 72/78 [19:56<01:37, 16.31s/epoch, loss=1.11, accuracy=0.758, val_loss=2.01, val_accuracy=0.482, lr=0.1]    94%|█████████▎| 73/78 [20:12<01:21, 16.27s/epoch, loss=1.11, accuracy=0.758, val_loss=1.84, val_accuracy=0.543, lr=0.1] 95%|█████████▍| 74/78 [20:28<01:05, 16.29s/epoch, loss=1.11, accuracy=0.756, val_loss=2.96, val_accuracy=0.372, lr=0.1] 96%|█████████▌| 75/78 [20:44<00:48, 16.25s/epoch, loss=1.11, accuracy=0.757, val_loss=2.41, val_accuracy=0.417, lr=0.1] 97%|█████████▋| 76/78 [21:00<00:32, 16.23s/epoch, loss=1.11, accuracy=0.759, val_loss=2.29, val_accuracy=0.421, lr=0.0316] 99%|█████████▊| 77/78 [21:17<00:16, 16.20s/epoch, loss=1.11, accuracy=0.757, val_loss=2.19, val_accuracy=0.477, lr=0.1]   100%|██████████| 78/78 [21:33<00:00, 16.18s/epoch, loss=1.11, accuracy=0.757, val_loss=2.12, val_accuracy=0.494, lr=0.1]100%|██████████| 78/78 [21:33<00:00, 16.58s/epoch, loss=1.11, accuracy=0.757, val_loss=2.12, val_accuracy=0.494, lr=0.1]
Using real-time data augmentation.
Test score: 1.4080930948257446
Test accuracy: 0.6520000100135803


* * * Run SGD for ID = 19_12. * * *


2024-02-20 03:28:59.626251: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 03:29:02.169677: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 03:29:02.170744: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-20 03:29:02.204676: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-20 03:29:02.204701: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 03:29:02.207265: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 03:29:02.207300: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-20 03:29:02.209405: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-20 03:29:02.210009: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-20 03:29:02.212242: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-20 03:29:02.213636: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-20 03:29:02.217987: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 03:29:02.218533: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-20 03:29:02.218607: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 03:29:03.586889: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-20 03:29:03.588327: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 03:29:03.589102: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-20 03:29:03.589132: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 03:29:03.589176: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 03:29:03.589193: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-20 03:29:03.589208: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-20 03:29:03.589224: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-20 03:29:03.589253: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-20 03:29:03.589268: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-20 03:29:03.589300: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 03:29:03.589703: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-20 03:29:03.589731: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 03:29:04.159173: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-20 03:29:04.159220: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-20 03:29:04.159228: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-20 03:29:04.160110: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': '19_12', 'batch_size': 128, 'epochs': 78, 'validation_split': 0.1, 'checkpointing': True, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
x_train shape: (45000, 32, 32, 3)
45000 train samples
5000 validation samples
10000 test samples
y_train shape: (45000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/78 [00:00<?, ?epoch/s]2024-02-20 03:29:04.920268: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-20 03:29:04.932072: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600020000 Hz
2024-02-20 03:29:06.736991: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 03:29:06.961893: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 03:29:07.610718: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-20 03:29:07.646176: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|▏         | 1/78 [00:44<56:45, 44.23s/epoch, loss=3.37, accuracy=0.258, val_loss=2.49, val_accuracy=0.234, lr=0.1]  3%|▎         | 2/78 [01:01<35:41, 28.18s/epoch, loss=1.66, accuracy=0.49, val_loss=1.93, val_accuracy=0.453, lr=0.1]   4%|▍         | 3/78 [01:18<28:49, 23.06s/epoch, loss=1.37, accuracy=0.615, val_loss=1.87, val_accuracy=0.509, lr=0.1]  5%|▌         | 4/78 [01:35<25:27, 20.64s/epoch, loss=1.29, accuracy=0.665, val_loss=1.91, val_accuracy=0.469, lr=0.1]  6%|▋         | 5/78 [01:52<23:35, 19.39s/epoch, loss=1.26, accuracy=0.692, val_loss=1.7, val_accuracy=0.58, lr=0.1]    8%|▊         | 6/78 [02:09<22:13, 18.53s/epoch, loss=1.25, accuracy=0.704, val_loss=1.92, val_accuracy=0.514, lr=0.1]  9%|▉         | 7/78 [02:26<21:20, 18.03s/epoch, loss=1.24, accuracy=0.709, val_loss=1.51, val_accuracy=0.607, lr=0.1] 10%|█         | 8/78 [02:43<20:40, 17.72s/epoch, loss=1.22, accuracy=0.718, val_loss=1.89, val_accuracy=0.514, lr=0.1] 12%|█▏        | 9/78 [02:59<20:01, 17.41s/epoch, loss=1.21, accuracy=0.724, val_loss=1.9, val_accuracy=0.493, lr=0.1]  13%|█▎        | 10/78 [03:16<19:25, 17.14s/epoch, loss=1.21, accuracy=0.727, val_loss=1.54, val_accuracy=0.62, lr=0.1] 14%|█▍        | 11/78 [03:33<19:10, 17.17s/epoch, loss=1.2, accuracy=0.732, val_loss=1.53, val_accuracy=0.619, lr=0.1] 15%|█▌        | 12/78 [03:51<19:01, 17.30s/epoch, loss=1.19, accuracy=0.734, val_loss=1.76, val_accuracy=0.558, lr=0.0316] 17%|█▋        | 13/78 [04:08<18:41, 17.25s/epoch, loss=1.19, accuracy=0.737, val_loss=1.9, val_accuracy=0.514, lr=0.1]     18%|█▊        | 14/78 [04:25<18:24, 17.26s/epoch, loss=1.18, accuracy=0.74, val_loss=4.07, val_accuracy=0.239, lr=0.1] 19%|█▉        | 15/78 [04:42<17:49, 16.98s/epoch, loss=1.17, accuracy=0.741, val_loss=1.87, val_accuracy=0.477, lr=0.1] 21%|██        | 16/78 [04:57<17:14, 16.68s/epoch, loss=1.18, accuracy=0.742, val_loss=1.68, val_accuracy=0.575, lr=0.1] 22%|██▏       | 17/78 [05:14<16:56, 16.67s/epoch, loss=1.18, accuracy=0.74, val_loss=1.42, val_accuracy=0.657, lr=0.1]  23%|██▎       | 18/78 [05:30<16:31, 16.53s/epoch, loss=1.17, accuracy=0.744, val_loss=2.2, val_accuracy=0.451, lr=0.1] 24%|██▍       | 19/78 [05:47<16:15, 16.53s/epoch, loss=1.17, accuracy=0.741, val_loss=2.56, val_accuracy=0.446, lr=0.1] 26%|██▌       | 20/78 [06:03<15:55, 16.47s/epoch, loss=1.17, accuracy=0.744, val_loss=4.36, val_accuracy=0.283, lr=0.1] 27%|██▋       | 21/78 [06:20<15:47, 16.63s/epoch, loss=1.16, accuracy=0.744, val_loss=1.75, val_accuracy=0.611, lr=0.1] 28%|██▊       | 22/78 [06:37<15:26, 16.54s/epoch, loss=1.16, accuracy=0.748, val_loss=1.85, val_accuracy=0.539, lr=0.0316] 29%|██▉       | 23/78 [06:53<15:15, 16.64s/epoch, loss=1.15, accuracy=0.748, val_loss=3.37, val_accuracy=0.339, lr=0.1]    31%|███       | 24/78 [07:10<14:55, 16.58s/epoch, loss=1.17, accuracy=0.745, val_loss=2.58, val_accuracy=0.421, lr=0.1] 32%|███▏      | 25/78 [07:26<14:39, 16.59s/epoch, loss=1.16, accuracy=0.746, val_loss=1.5, val_accuracy=0.636, lr=0.1]  33%|███▎      | 26/78 [07:43<14:22, 16.59s/epoch, loss=1.15, accuracy=0.751, val_loss=2, val_accuracy=0.52, lr=0.1]    35%|███▍      | 27/78 [08:00<14:05, 16.58s/epoch, loss=1.15, accuracy=0.75, val_loss=2.78, val_accuracy=0.417, lr=0.0316] 36%|███▌      | 28/78 [08:16<13:41, 16.43s/epoch, loss=1.15, accuracy=0.751, val_loss=1.83, val_accuracy=0.54, lr=0.1]    37%|███▋      | 29/78 [08:32<13:19, 16.32s/epoch, loss=1.15, accuracy=0.75, val_loss=2.45, val_accuracy=0.427, lr=0.1] 38%|███▊      | 30/78 [08:48<13:07, 16.40s/epoch, loss=1.14, accuracy=0.75, val_loss=2.83, val_accuracy=0.331, lr=0.1] 40%|███▉      | 31/78 [09:05<12:52, 16.43s/epoch, loss=1.15, accuracy=0.75, val_loss=1.54, val_accuracy=0.621, lr=0.1] 41%|████      | 32/78 [09:21<12:35, 16.42s/epoch, loss=1.14, accuracy=0.752, val_loss=1.75, val_accuracy=0.582, lr=0.0316] 42%|████▏     | 33/78 [09:37<12:15, 16.34s/epoch, loss=1.14, accuracy=0.751, val_loss=1.51, val_accuracy=0.609, lr=0.1]    44%|████▎     | 34/78 [09:54<11:56, 16.29s/epoch, loss=1.14, accuracy=0.752, val_loss=1.46, val_accuracy=0.627, lr=0.1] 45%|████▍     | 35/78 [10:09<11:35, 16.17s/epoch, loss=1.14, accuracy=0.754, val_loss=2.3, val_accuracy=0.432, lr=0.1]  46%|████▌     | 36/78 [10:26<11:18, 16.14s/epoch, loss=1.14, accuracy=0.753, val_loss=1.63, val_accuracy=0.59, lr=0.1] 47%|████▋     | 37/78 [10:42<11:07, 16.28s/epoch, loss=1.14, accuracy=0.75, val_loss=3.12, val_accuracy=0.381, lr=0.0316] 49%|████▊     | 38/78 [10:59<10:55, 16.39s/epoch, loss=1.13, accuracy=0.754, val_loss=2.65, val_accuracy=0.36, lr=0.1]    50%|█████     | 39/78 [11:15<10:39, 16.40s/epoch, loss=1.13, accuracy=0.754, val_loss=1.68, val_accuracy=0.575, lr=0.1] 51%|█████▏    | 40/78 [11:32<10:25, 16.47s/epoch, loss=1.13, accuracy=0.753, val_loss=1.74, val_accuracy=0.546, lr=0.1] 53%|█████▎    | 41/78 [11:49<10:13, 16.59s/epoch, loss=1.13, accuracy=0.754, val_loss=1.99, val_accuracy=0.562, lr=0.1] 54%|█████▍    | 42/78 [12:05<09:54, 16.51s/epoch, loss=1.13, accuracy=0.756, val_loss=1.98, val_accuracy=0.518, lr=0.0316] 55%|█████▌    | 43/78 [12:21<09:33, 16.39s/epoch, loss=1.14, accuracy=0.752, val_loss=1.81, val_accuracy=0.534, lr=0.1]    56%|█████▋    | 44/78 [12:37<09:13, 16.28s/epoch, loss=1.13, accuracy=0.754, val_loss=2.12, val_accuracy=0.514, lr=0.1] 58%|█████▊    | 45/78 [12:54<09:02, 16.44s/epoch, loss=1.13, accuracy=0.755, val_loss=1.59, val_accuracy=0.599, lr=0.1] 59%|█████▉    | 46/78 [13:10<08:44, 16.39s/epoch, loss=1.13, accuracy=0.752, val_loss=2.22, val_accuracy=0.502, lr=0.1] 60%|██████    | 47/78 [13:26<08:25, 16.31s/epoch, loss=1.13, accuracy=0.753, val_loss=3.13, val_accuracy=0.483, lr=0.0316] 62%|██████▏   | 48/78 [13:43<08:12, 16.42s/epoch, loss=1.13, accuracy=0.755, val_loss=1.81, val_accuracy=0.571, lr=0.1]    63%|██████▎   | 49/78 [13:59<07:54, 16.37s/epoch, loss=1.13, accuracy=0.754, val_loss=1.54, val_accuracy=0.605, lr=0.1] 64%|██████▍   | 50/78 [14:16<07:42, 16.51s/epoch, loss=1.12, accuracy=0.757, val_loss=1.51, val_accuracy=0.62, lr=0.1]  65%|██████▌   | 51/78 [14:33<07:25, 16.50s/epoch, loss=1.13, accuracy=0.754, val_loss=2.84, val_accuracy=0.396, lr=0.1] 67%|██████▋   | 52/78 [14:49<07:11, 16.60s/epoch, loss=1.12, accuracy=0.758, val_loss=1.74, val_accuracy=0.576, lr=0.0316] 68%|██████▊   | 53/78 [15:06<06:52, 16.50s/epoch, loss=1.13, accuracy=0.754, val_loss=2.65, val_accuracy=0.302, lr=0.1]    69%|██████▉   | 54/78 [15:22<06:34, 16.43s/epoch, loss=1.13, accuracy=0.753, val_loss=1.5, val_accuracy=0.625, lr=0.1]  71%|███████   | 55/78 [15:38<06:14, 16.27s/epoch, loss=1.13, accuracy=0.756, val_loss=2.93, val_accuracy=0.301, lr=0.1] 72%|███████▏  | 56/78 [15:54<05:55, 16.17s/epoch, loss=1.13, accuracy=0.756, val_loss=1.84, val_accuracy=0.532, lr=0.1] 73%|███████▎  | 57/78 [16:10<05:40, 16.23s/epoch, loss=1.12, accuracy=0.756, val_loss=1.77, val_accuracy=0.569, lr=0.0316] 74%|███████▍  | 58/78 [16:26<05:23, 16.19s/epoch, loss=1.13, accuracy=0.756, val_loss=2.08, val_accuracy=0.515, lr=0.1]    76%|███████▌  | 59/78 [16:43<05:08, 16.25s/epoch, loss=1.12, accuracy=0.757, val_loss=1.69, val_accuracy=0.598, lr=0.1] 77%|███████▋  | 60/78 [16:59<04:54, 16.34s/epoch, loss=1.13, accuracy=0.756, val_loss=2, val_accuracy=0.517, lr=0.1]    78%|███████▊  | 61/78 [17:16<04:39, 16.43s/epoch, loss=1.12, accuracy=0.756, val_loss=1.9, val_accuracy=0.538, lr=0.1] 79%|███████▉  | 62/78 [17:32<04:20, 16.28s/epoch, loss=1.12, accuracy=0.757, val_loss=1.92, val_accuracy=0.527, lr=0.0316] 81%|████████  | 63/78 [17:48<04:02, 16.18s/epoch, loss=1.12, accuracy=0.757, val_loss=1.55, val_accuracy=0.626, lr=0.1]    82%|████████▏ | 64/78 [18:04<03:47, 16.25s/epoch, loss=1.12, accuracy=0.756, val_loss=2.32, val_accuracy=0.409, lr=0.1] 83%|████████▎ | 65/78 [18:21<03:35, 16.56s/epoch, loss=1.12, accuracy=0.754, val_loss=2.77, val_accuracy=0.327, lr=0.1] 85%|████████▍ | 66/78 [18:37<03:16, 16.37s/epoch, loss=1.12, accuracy=0.756, val_loss=1.68, val_accuracy=0.556, lr=0.1] 86%|████████▌ | 67/78 [18:54<02:59, 16.35s/epoch, loss=1.12, accuracy=0.759, val_loss=2.05, val_accuracy=0.521, lr=0.0316] 87%|████████▋ | 68/78 [19:10<02:42, 16.30s/epoch, loss=1.12, accuracy=0.757, val_loss=1.64, val_accuracy=0.615, lr=0.1]    88%|████████▊ | 69/78 [19:26<02:27, 16.37s/epoch, loss=1.12, accuracy=0.753, val_loss=3.11, val_accuracy=0.385, lr=0.1] 90%|████████▉ | 70/78 [19:42<02:09, 16.24s/epoch, loss=1.12, accuracy=0.757, val_loss=1.51, val_accuracy=0.633, lr=0.1] 91%|█████████ | 71/78 [19:58<01:53, 16.21s/epoch, loss=1.12, accuracy=0.757, val_loss=1.7, val_accuracy=0.563, lr=0.1]  92%|█████████▏| 72/78 [20:15<01:38, 16.38s/epoch, loss=1.12, accuracy=0.755, val_loss=2.38, val_accuracy=0.347, lr=0.0316] 94%|█████████▎| 73/78 [20:32<01:22, 16.57s/epoch, loss=1.12, accuracy=0.757, val_loss=2.62, val_accuracy=0.36, lr=0.1]     95%|█████████▍| 74/78 [20:49<01:07, 16.75s/epoch, loss=1.12, accuracy=0.757, val_loss=2.82, val_accuracy=0.404, lr=0.1] 96%|█████████▌| 75/78 [21:06<00:49, 16.65s/epoch, loss=1.12, accuracy=0.757, val_loss=1.51, val_accuracy=0.633, lr=0.1] 97%|█████████▋| 76/78 [21:22<00:33, 16.58s/epoch, loss=1.12, accuracy=0.755, val_loss=2.56, val_accuracy=0.439, lr=0.1] 99%|█████████▊| 77/78 [21:39<00:16, 16.60s/epoch, loss=1.12, accuracy=0.757, val_loss=2.09, val_accuracy=0.442, lr=0.0316]100%|██████████| 78/78 [21:55<00:00, 16.53s/epoch, loss=1.12, accuracy=0.76, val_loss=1.55, val_accuracy=0.617, lr=0.1]    100%|██████████| 78/78 [21:55<00:00, 16.87s/epoch, loss=1.12, accuracy=0.76, val_loss=1.55, val_accuracy=0.617, lr=0.1]
Using real-time data augmentation.
Test score: 1.4135042428970337
Test accuracy: 0.661899983882904


* * * Run SGD for ID = 19_13. * * *


2024-02-20 03:51:07.641735: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 03:51:15.682491: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 03:51:15.683451: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-20 03:51:15.718927: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-20 03:51:15.718954: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 03:51:15.725056: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 03:51:15.725094: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-20 03:51:15.728835: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-20 03:51:15.731743: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-20 03:51:15.735311: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-20 03:51:15.737913: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-20 03:51:15.743582: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 03:51:15.744109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-20 03:51:15.744181: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 03:51:17.128423: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-20 03:51:17.129406: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 03:51:17.130128: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-20 03:51:17.130158: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 03:51:17.130193: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 03:51:17.130210: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-20 03:51:17.130226: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-20 03:51:17.130242: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-20 03:51:17.130295: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-20 03:51:17.130309: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-20 03:51:17.130323: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 03:51:17.130730: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-20 03:51:17.130764: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 03:51:17.712827: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-20 03:51:17.712878: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-20 03:51:17.712887: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-20 03:51:17.713766: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': '19_13', 'batch_size': 128, 'epochs': 78, 'validation_split': 0.1, 'checkpointing': True, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
x_train shape: (45000, 32, 32, 3)
45000 train samples
5000 validation samples
10000 test samples
y_train shape: (45000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/78 [00:00<?, ?epoch/s]2024-02-20 03:51:18.479303: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-20 03:51:18.491075: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600020000 Hz
2024-02-20 03:51:20.341765: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 03:51:20.571807: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 03:51:21.175691: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-20 03:51:21.217732: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|▏         | 1/78 [00:44<57:11, 44.56s/epoch, loss=3.91, accuracy=0.322, val_loss=3.45, val_accuracy=0.171, lr=0.1]  3%|▎         | 2/78 [01:01<36:05, 28.49s/epoch, loss=1.66, accuracy=0.517, val_loss=1.95, val_accuracy=0.374, lr=0.1]  4%|▍         | 3/78 [01:19<29:17, 23.43s/epoch, loss=1.48, accuracy=0.579, val_loss=2.36, val_accuracy=0.336, lr=0.1]  5%|▌         | 4/78 [01:36<25:50, 20.96s/epoch, loss=1.42, accuracy=0.612, val_loss=1.59, val_accuracy=0.559, lr=0.1]  6%|▋         | 5/78 [01:53<23:43, 19.50s/epoch, loss=1.38, accuracy=0.638, val_loss=2.48, val_accuracy=0.373, lr=0.1]  8%|▊         | 6/78 [02:11<22:40, 18.90s/epoch, loss=1.36, accuracy=0.651, val_loss=1.91, val_accuracy=0.464, lr=0.1]  9%|▉         | 7/78 [02:29<22:02, 18.62s/epoch, loss=1.34, accuracy=0.663, val_loss=1.87, val_accuracy=0.488, lr=0.1] 10%|█         | 8/78 [02:46<21:08, 18.12s/epoch, loss=1.32, accuracy=0.67, val_loss=2.25, val_accuracy=0.406, lr=0.1]  12%|█▏        | 9/78 [03:03<20:28, 17.80s/epoch, loss=1.31, accuracy=0.678, val_loss=2.09, val_accuracy=0.491, lr=0.0316] 13%|█▎        | 10/78 [03:20<19:58, 17.62s/epoch, loss=1.29, accuracy=0.686, val_loss=1.61, val_accuracy=0.567, lr=0.1]   14%|█▍        | 11/78 [03:37<19:22, 17.35s/epoch, loss=1.27, accuracy=0.695, val_loss=2.46, val_accuracy=0.412, lr=0.1] 15%|█▌        | 12/78 [03:54<18:57, 17.23s/epoch, loss=1.26, accuracy=0.698, val_loss=1.93, val_accuracy=0.492, lr=0.1] 17%|█▋        | 13/78 [04:11<18:38, 17.21s/epoch, loss=1.26, accuracy=0.705, val_loss=2.04, val_accuracy=0.479, lr=0.1] 18%|█▊        | 14/78 [04:28<18:29, 17.34s/epoch, loss=1.25, accuracy=0.707, val_loss=3.51, val_accuracy=0.237, lr=0.0316] 19%|█▉        | 15/78 [04:46<18:09, 17.29s/epoch, loss=1.24, accuracy=0.712, val_loss=1.98, val_accuracy=0.554, lr=0.1]    21%|██        | 16/78 [05:03<17:54, 17.33s/epoch, loss=1.24, accuracy=0.714, val_loss=1.94, val_accuracy=0.486, lr=0.1] 22%|██▏       | 17/78 [05:21<17:43, 17.44s/epoch, loss=1.23, accuracy=0.719, val_loss=1.91, val_accuracy=0.528, lr=0.1] 23%|██▎       | 18/78 [05:39<17:35, 17.59s/epoch, loss=1.22, accuracy=0.719, val_loss=2.14, val_accuracy=0.445, lr=0.1] 24%|██▍       | 19/78 [05:56<17:12, 17.49s/epoch, loss=1.21, accuracy=0.724, val_loss=2.77, val_accuracy=0.406, lr=0.0316] 26%|██▌       | 20/78 [06:14<16:59, 17.57s/epoch, loss=1.21, accuracy=0.724, val_loss=2.37, val_accuracy=0.355, lr=0.1]    27%|██▋       | 21/78 [06:31<16:40, 17.55s/epoch, loss=1.2, accuracy=0.729, val_loss=1.54, val_accuracy=0.631, lr=0.1]  28%|██▊       | 22/78 [06:48<16:13, 17.38s/epoch, loss=1.21, accuracy=0.728, val_loss=1.58, val_accuracy=0.618, lr=0.1] 29%|██▉       | 23/78 [07:06<15:57, 17.41s/epoch, loss=1.2, accuracy=0.73, val_loss=1.66, val_accuracy=0.588, lr=0.1]   31%|███       | 24/78 [07:24<15:52, 17.64s/epoch, loss=1.2, accuracy=0.733, val_loss=2.68, val_accuracy=0.413, lr=0.1] 32%|███▏      | 25/78 [07:41<15:29, 17.53s/epoch, loss=1.18, accuracy=0.736, val_loss=2.18, val_accuracy=0.42, lr=0.1] 33%|███▎      | 26/78 [07:59<15:10, 17.51s/epoch, loss=1.18, accuracy=0.733, val_loss=1.68, val_accuracy=0.556, lr=0.0316] 35%|███▍      | 27/78 [08:16<14:44, 17.34s/epoch, loss=1.17, accuracy=0.737, val_loss=1.82, val_accuracy=0.528, lr=0.1]    36%|███▌      | 28/78 [08:33<14:34, 17.49s/epoch, loss=1.18, accuracy=0.737, val_loss=2.03, val_accuracy=0.514, lr=0.1] 37%|███▋      | 29/78 [08:51<14:17, 17.50s/epoch, loss=1.17, accuracy=0.74, val_loss=2.44, val_accuracy=0.329, lr=0.1]  38%|███▊      | 30/78 [09:08<13:55, 17.41s/epoch, loss=1.17, accuracy=0.74, val_loss=1.73, val_accuracy=0.546, lr=0.1] 40%|███▉      | 31/78 [09:26<13:42, 17.51s/epoch, loss=1.16, accuracy=0.744, val_loss=1.63, val_accuracy=0.595, lr=0.0316] 41%|████      | 32/78 [09:43<13:22, 17.46s/epoch, loss=1.16, accuracy=0.741, val_loss=1.94, val_accuracy=0.536, lr=0.1]    42%|████▏     | 33/78 [10:01<13:08, 17.51s/epoch, loss=1.16, accuracy=0.741, val_loss=2.69, val_accuracy=0.441, lr=0.1] 44%|████▎     | 34/78 [10:18<12:50, 17.50s/epoch, loss=1.16, accuracy=0.744, val_loss=1.75, val_accuracy=0.542, lr=0.1] 45%|████▍     | 35/78 [10:36<12:34, 17.54s/epoch, loss=1.17, accuracy=0.741, val_loss=1.44, val_accuracy=0.661, lr=0.1] 46%|████▌     | 36/78 [10:53<12:12, 17.44s/epoch, loss=1.15, accuracy=0.744, val_loss=3.59, val_accuracy=0.3, lr=0.1]   47%|████▋     | 37/78 [11:10<11:51, 17.36s/epoch, loss=1.16, accuracy=0.745, val_loss=1.88, val_accuracy=0.5, lr=0.1] 49%|████▊     | 38/78 [11:28<11:42, 17.57s/epoch, loss=1.16, accuracy=0.744, val_loss=2.37, val_accuracy=0.45, lr=0.1] 50%|█████     | 39/78 [11:46<11:20, 17.46s/epoch, loss=1.15, accuracy=0.751, val_loss=2.14, val_accuracy=0.505, lr=0.1] 51%|█████▏    | 40/78 [12:03<11:04, 17.49s/epoch, loss=1.15, accuracy=0.75, val_loss=1.72, val_accuracy=0.576, lr=0.0316] 53%|█████▎    | 41/78 [12:21<10:50, 17.58s/epoch, loss=1.15, accuracy=0.747, val_loss=2.47, val_accuracy=0.429, lr=0.1]   54%|█████▍    | 42/78 [12:38<10:31, 17.54s/epoch, loss=1.15, accuracy=0.747, val_loss=4.5, val_accuracy=0.333, lr=0.1]  55%|█████▌    | 43/78 [12:56<10:13, 17.52s/epoch, loss=1.14, accuracy=0.751, val_loss=2.51, val_accuracy=0.295, lr=0.1] 56%|█████▋    | 44/78 [13:13<09:53, 17.47s/epoch, loss=1.14, accuracy=0.753, val_loss=3.29, val_accuracy=0.268, lr=0.1] 58%|█████▊    | 45/78 [13:31<09:38, 17.54s/epoch, loss=1.16, accuracy=0.747, val_loss=1.83, val_accuracy=0.518, lr=0.0316] 59%|█████▉    | 46/78 [13:49<09:22, 17.59s/epoch, loss=1.15, accuracy=0.75, val_loss=2.62, val_accuracy=0.344, lr=0.1]     60%|██████    | 47/78 [14:06<09:00, 17.43s/epoch, loss=1.14, accuracy=0.75, val_loss=3.38, val_accuracy=0.354, lr=0.1] 62%|██████▏   | 48/78 [14:23<08:40, 17.35s/epoch, loss=1.14, accuracy=0.748, val_loss=2.53, val_accuracy=0.395, lr=0.1] 63%|██████▎   | 49/78 [14:40<08:24, 17.40s/epoch, loss=1.14, accuracy=0.751, val_loss=3.67, val_accuracy=0.237, lr=0.1] 64%|██████▍   | 50/78 [14:58<08:06, 17.39s/epoch, loss=1.14, accuracy=0.751, val_loss=1.94, val_accuracy=0.467, lr=0.0316] 65%|██████▌   | 51/78 [15:15<07:48, 17.36s/epoch, loss=1.14, accuracy=0.751, val_loss=2.38, val_accuracy=0.354, lr=0.1]    67%|██████▋   | 52/78 [15:32<07:29, 17.30s/epoch, loss=1.14, accuracy=0.753, val_loss=2.62, val_accuracy=0.34, lr=0.1]  68%|██████▊   | 53/78 [15:49<07:11, 17.27s/epoch, loss=1.13, accuracy=0.753, val_loss=1.83, val_accuracy=0.549, lr=0.1] 69%|██████▉   | 54/78 [16:07<06:54, 17.27s/epoch, loss=1.14, accuracy=0.752, val_loss=3.54, val_accuracy=0.283, lr=0.1] 71%|███████   | 55/78 [16:24<06:40, 17.43s/epoch, loss=1.14, accuracy=0.745, val_loss=2.23, val_accuracy=0.441, lr=0.0316] 72%|███████▏  | 56/78 [16:42<06:21, 17.36s/epoch, loss=1.14, accuracy=0.751, val_loss=2.43, val_accuracy=0.454, lr=0.1]    73%|███████▎  | 57/78 [16:59<06:04, 17.36s/epoch, loss=1.13, accuracy=0.754, val_loss=2.84, val_accuracy=0.406, lr=0.1] 74%|███████▍  | 58/78 [17:17<05:50, 17.50s/epoch, loss=1.13, accuracy=0.751, val_loss=8.38, val_accuracy=0.171, lr=0.1] 76%|███████▌  | 59/78 [17:34<05:31, 17.47s/epoch, loss=1.13, accuracy=0.754, val_loss=5.14, val_accuracy=0.223, lr=0.1] 77%|███████▋  | 60/78 [17:52<05:14, 17.46s/epoch, loss=1.13, accuracy=0.755, val_loss=3.03, val_accuracy=0.426, lr=0.0316] 78%|███████▊  | 61/78 [18:09<04:54, 17.32s/epoch, loss=1.13, accuracy=0.753, val_loss=4.67, val_accuracy=0.243, lr=0.1]    79%|███████▉  | 62/78 [18:26<04:38, 17.40s/epoch, loss=1.14, accuracy=0.754, val_loss=3.76, val_accuracy=0.296, lr=0.1] 81%|████████  | 63/78 [18:44<04:20, 17.37s/epoch, loss=1.14, accuracy=0.753, val_loss=2.27, val_accuracy=0.334, lr=0.1] 82%|████████▏ | 64/78 [19:01<04:03, 17.38s/epoch, loss=1.14, accuracy=0.752, val_loss=2.08, val_accuracy=0.5, lr=0.1]   83%|████████▎ | 65/78 [19:18<03:46, 17.42s/epoch, loss=1.13, accuracy=0.754, val_loss=5.99, val_accuracy=0.211, lr=0.0316] 85%|████████▍ | 66/78 [19:36<03:29, 17.43s/epoch, loss=1.14, accuracy=0.753, val_loss=3.48, val_accuracy=0.316, lr=0.1]    86%|████████▌ | 67/78 [19:53<03:12, 17.45s/epoch, loss=1.13, accuracy=0.753, val_loss=4.12, val_accuracy=0.26, lr=0.1]  87%|████████▋ | 68/78 [20:11<02:54, 17.44s/epoch, loss=1.13, accuracy=0.753, val_loss=5.49, val_accuracy=0.296, lr=0.1] 88%|████████▊ | 69/78 [20:28<02:37, 17.46s/epoch, loss=1.14, accuracy=0.753, val_loss=4.76, val_accuracy=0.256, lr=0.1] 90%|████████▉ | 70/78 [20:46<02:19, 17.41s/epoch, loss=1.13, accuracy=0.753, val_loss=5.95, val_accuracy=0.187, lr=0.0316] 91%|█████████ | 71/78 [21:03<02:02, 17.55s/epoch, loss=1.13, accuracy=0.755, val_loss=2.49, val_accuracy=0.309, lr=0.1]    92%|█████████▏| 72/78 [21:21<01:45, 17.58s/epoch, loss=1.13, accuracy=0.754, val_loss=2.1, val_accuracy=0.496, lr=0.1]  94%|█████████▎| 73/78 [21:39<01:28, 17.63s/epoch, loss=1.13, accuracy=0.755, val_loss=2.1, val_accuracy=0.459, lr=0.1] 95%|█████████▍| 74/78 [21:56<01:09, 17.49s/epoch, loss=1.14, accuracy=0.752, val_loss=2.97, val_accuracy=0.358, lr=0.1] 96%|█████████▌| 75/78 [22:13<00:52, 17.46s/epoch, loss=1.13, accuracy=0.754, val_loss=6.31, val_accuracy=0.226, lr=0.0316] 97%|█████████▋| 76/78 [22:31<00:34, 17.41s/epoch, loss=1.13, accuracy=0.753, val_loss=3.27, val_accuracy=0.399, lr=0.1]    99%|█████████▊| 77/78 [22:48<00:17, 17.39s/epoch, loss=1.13, accuracy=0.756, val_loss=2.35, val_accuracy=0.519, lr=0.1]100%|██████████| 78/78 [23:06<00:00, 17.42s/epoch, loss=1.13, accuracy=0.754, val_loss=1.93, val_accuracy=0.483, lr=0.1]100%|██████████| 78/78 [23:06<00:00, 17.77s/epoch, loss=1.13, accuracy=0.754, val_loss=1.93, val_accuracy=0.483, lr=0.1]
Using real-time data augmentation.
Test score: 1.4284001588821411
Test accuracy: 0.6662999987602234


* * * Run SGD for ID = 19_14. * * *


2024-02-20 04:14:30.376159: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 04:14:33.275786: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 04:14:33.276765: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-20 04:14:33.313214: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-20 04:14:33.313249: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 04:14:33.316065: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 04:14:33.316101: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-20 04:14:33.318475: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-20 04:14:33.319240: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-20 04:14:33.321693: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-20 04:14:33.323178: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-20 04:14:33.327486: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 04:14:33.327995: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-20 04:14:33.328068: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 04:14:34.692591: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-20 04:14:34.693084: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 04:14:34.693793: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-20 04:14:34.693820: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 04:14:34.693853: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 04:14:34.693868: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-20 04:14:34.693882: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-20 04:14:34.693897: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-20 04:14:34.693911: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-20 04:14:34.693924: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-20 04:14:34.693938: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 04:14:34.694425: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-20 04:14:34.694454: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 04:14:35.266279: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-20 04:14:35.266328: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-20 04:14:35.266335: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-20 04:14:35.267224: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': '19_14', 'batch_size': 128, 'epochs': 78, 'validation_split': 0.1, 'checkpointing': True, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
x_train shape: (45000, 32, 32, 3)
45000 train samples
5000 validation samples
10000 test samples
y_train shape: (45000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/78 [00:00<?, ?epoch/s]2024-02-20 04:14:36.020576: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-20 04:14:36.033073: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600020000 Hz
2024-02-20 04:14:37.877856: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 04:14:38.050686: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 04:14:38.724137: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-20 04:14:38.777286: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|▏         | 1/78 [00:43<56:03, 43.69s/epoch, loss=3.37, accuracy=0.311, val_loss=2.18, val_accuracy=0.352, lr=0.1]  3%|▎         | 2/78 [01:01<35:41, 28.18s/epoch, loss=1.65, accuracy=0.508, val_loss=2.19, val_accuracy=0.363, lr=0.1]  4%|▍         | 3/78 [01:17<28:42, 22.97s/epoch, loss=1.46, accuracy=0.591, val_loss=1.72, val_accuracy=0.487, lr=0.1]  5%|▌         | 4/78 [01:34<25:19, 20.54s/epoch, loss=1.4, accuracy=0.632, val_loss=1.58, val_accuracy=0.569, lr=0.1]   6%|▋         | 5/78 [01:51<23:14, 19.10s/epoch, loss=1.35, accuracy=0.663, val_loss=2.12, val_accuracy=0.452, lr=0.1]  8%|▊         | 6/78 [02:07<21:55, 18.27s/epoch, loss=1.31, accuracy=0.683, val_loss=2.18, val_accuracy=0.4, lr=0.1]    9%|▉         | 7/78 [02:24<21:01, 17.76s/epoch, loss=1.28, accuracy=0.699, val_loss=2.4, val_accuracy=0.411, lr=0.1] 10%|█         | 8/78 [02:41<20:16, 17.38s/epoch, loss=1.26, accuracy=0.709, val_loss=2.67, val_accuracy=0.355, lr=0.1] 12%|█▏        | 9/78 [02:58<19:49, 17.24s/epoch, loss=1.24, accuracy=0.713, val_loss=1.59, val_accuracy=0.61, lr=0.0316] 13%|█▎        | 10/78 [03:14<19:15, 16.99s/epoch, loss=1.23, accuracy=0.719, val_loss=2.43, val_accuracy=0.458, lr=0.1]  14%|█▍        | 11/78 [03:31<18:58, 16.99s/epoch, loss=1.22, accuracy=0.723, val_loss=1.96, val_accuracy=0.443, lr=0.1] 15%|█▌        | 12/78 [03:47<18:31, 16.84s/epoch, loss=1.21, accuracy=0.728, val_loss=1.64, val_accuracy=0.584, lr=0.1] 17%|█▋        | 13/78 [04:04<18:10, 16.77s/epoch, loss=1.21, accuracy=0.733, val_loss=1.71, val_accuracy=0.591, lr=0.1] 18%|█▊        | 14/78 [04:21<17:51, 16.74s/epoch, loss=1.2, accuracy=0.735, val_loss=2.12, val_accuracy=0.491, lr=0.0316] 19%|█▉        | 15/78 [04:37<17:34, 16.73s/epoch, loss=1.21, accuracy=0.736, val_loss=2.51, val_accuracy=0.331, lr=0.1]   21%|██        | 16/78 [04:54<17:22, 16.81s/epoch, loss=1.2, accuracy=0.736, val_loss=1.4, val_accuracy=0.658, lr=0.1]   22%|██▏       | 17/78 [05:11<17:05, 16.82s/epoch, loss=1.2, accuracy=0.736, val_loss=1.74, val_accuracy=0.563, lr=0.1] 23%|██▎       | 18/78 [05:29<16:58, 16.97s/epoch, loss=1.18, accuracy=0.74, val_loss=1.46, val_accuracy=0.631, lr=0.1] 24%|██▍       | 19/78 [05:46<16:43, 17.00s/epoch, loss=1.2, accuracy=0.735, val_loss=3.14, val_accuracy=0.345, lr=0.1] 26%|██▌       | 20/78 [06:02<16:20, 16.90s/epoch, loss=1.18, accuracy=0.742, val_loss=2.29, val_accuracy=0.386, lr=0.1] 27%|██▋       | 21/78 [06:19<15:58, 16.82s/epoch, loss=1.18, accuracy=0.743, val_loss=1.54, val_accuracy=0.615, lr=0.0316] 28%|██▊       | 22/78 [06:36<15:37, 16.75s/epoch, loss=1.18, accuracy=0.744, val_loss=4.72, val_accuracy=0.243, lr=0.1]    29%|██▉       | 23/78 [06:52<15:22, 16.77s/epoch, loss=1.18, accuracy=0.745, val_loss=1.6, val_accuracy=0.602, lr=0.1]  31%|███       | 24/78 [07:09<15:09, 16.84s/epoch, loss=1.18, accuracy=0.744, val_loss=1.85, val_accuracy=0.54, lr=0.1] 32%|███▏      | 25/78 [07:26<14:50, 16.80s/epoch, loss=1.17, accuracy=0.747, val_loss=2.04, val_accuracy=0.518, lr=0.1] 33%|███▎      | 26/78 [07:43<14:31, 16.75s/epoch, loss=1.16, accuracy=0.749, val_loss=2.22, val_accuracy=0.524, lr=0.0316] 35%|███▍      | 27/78 [07:59<14:10, 16.67s/epoch, loss=1.17, accuracy=0.751, val_loss=1.42, val_accuracy=0.647, lr=0.1]    36%|███▌      | 28/78 [08:16<13:49, 16.58s/epoch, loss=1.17, accuracy=0.747, val_loss=1.75, val_accuracy=0.526, lr=0.1] 37%|███▋      | 29/78 [08:32<13:37, 16.68s/epoch, loss=1.17, accuracy=0.753, val_loss=2.21, val_accuracy=0.491, lr=0.1] 38%|███▊      | 30/78 [08:49<13:15, 16.58s/epoch, loss=1.16, accuracy=0.749, val_loss=2.73, val_accuracy=0.431, lr=0.1] 40%|███▉      | 31/78 [09:06<13:00, 16.61s/epoch, loss=1.16, accuracy=0.75, val_loss=2.16, val_accuracy=0.484, lr=0.0316] 41%|████      | 32/78 [09:22<12:44, 16.63s/epoch, loss=1.16, accuracy=0.752, val_loss=2.56, val_accuracy=0.348, lr=0.1]   42%|████▏     | 33/78 [09:39<12:27, 16.60s/epoch, loss=1.16, accuracy=0.753, val_loss=1.67, val_accuracy=0.589, lr=0.1] 44%|████▎     | 34/78 [09:55<12:11, 16.63s/epoch, loss=1.16, accuracy=0.751, val_loss=2.09, val_accuracy=0.496, lr=0.1] 45%|████▍     | 35/78 [10:12<11:56, 16.67s/epoch, loss=1.16, accuracy=0.753, val_loss=1.7, val_accuracy=0.552, lr=0.1]  46%|████▌     | 36/78 [10:29<11:39, 16.65s/epoch, loss=1.16, accuracy=0.751, val_loss=2.11, val_accuracy=0.497, lr=0.0316] 47%|████▋     | 37/78 [10:45<11:21, 16.61s/epoch, loss=1.15, accuracy=0.751, val_loss=3.26, val_accuracy=0.399, lr=0.1]    49%|████▊     | 38/78 [11:02<11:02, 16.56s/epoch, loss=1.16, accuracy=0.752, val_loss=3.09, val_accuracy=0.357, lr=0.1] 50%|█████     | 39/78 [11:18<10:46, 16.58s/epoch, loss=1.15, accuracy=0.752, val_loss=1.65, val_accuracy=0.598, lr=0.1] 51%|█████▏    | 40/78 [11:35<10:29, 16.56s/epoch, loss=1.15, accuracy=0.753, val_loss=1.3, val_accuracy=0.714, lr=0.1]  53%|█████▎    | 41/78 [11:51<10:11, 16.52s/epoch, loss=1.15, accuracy=0.753, val_loss=1.96, val_accuracy=0.508, lr=0.1] 54%|█████▍    | 42/78 [12:08<09:56, 16.57s/epoch, loss=1.15, accuracy=0.756, val_loss=2.58, val_accuracy=0.467, lr=0.1] 55%|█████▌    | 43/78 [12:24<09:38, 16.53s/epoch, loss=1.15, accuracy=0.755, val_loss=1.68, val_accuracy=0.604, lr=0.1] 56%|█████▋    | 44/78 [12:41<09:20, 16.48s/epoch, loss=1.15, accuracy=0.753, val_loss=1.67, val_accuracy=0.577, lr=0.1] 58%|█████▊    | 45/78 [12:57<09:04, 16.49s/epoch, loss=1.15, accuracy=0.753, val_loss=1.57, val_accuracy=0.608, lr=0.0316] 59%|█████▉    | 46/78 [13:14<08:49, 16.54s/epoch, loss=1.15, accuracy=0.753, val_loss=2.38, val_accuracy=0.471, lr=0.1]    60%|██████    | 47/78 [13:30<08:31, 16.51s/epoch, loss=1.14, accuracy=0.752, val_loss=1.76, val_accuracy=0.58, lr=0.1]  62%|██████▏   | 48/78 [13:47<08:14, 16.49s/epoch, loss=1.14, accuracy=0.755, val_loss=2.32, val_accuracy=0.407, lr=0.1] 63%|██████▎   | 49/78 [14:03<07:56, 16.43s/epoch, loss=1.15, accuracy=0.753, val_loss=2.25, val_accuracy=0.46, lr=0.1]  64%|██████▍   | 50/78 [14:20<07:42, 16.53s/epoch, loss=1.14, accuracy=0.756, val_loss=2.68, val_accuracy=0.341, lr=0.0316] 65%|██████▌   | 51/78 [14:36<07:23, 16.44s/epoch, loss=1.14, accuracy=0.754, val_loss=1.6, val_accuracy=0.602, lr=0.1]     67%|██████▋   | 52/78 [14:53<07:06, 16.42s/epoch, loss=1.15, accuracy=0.755, val_loss=3.28, val_accuracy=0.367, lr=0.1] 68%|██████▊   | 53/78 [15:09<06:52, 16.52s/epoch, loss=1.14, accuracy=0.757, val_loss=1.54, val_accuracy=0.616, lr=0.1] 69%|██████▉   | 54/78 [15:26<06:38, 16.60s/epoch, loss=1.14, accuracy=0.755, val_loss=2.02, val_accuracy=0.552, lr=0.1] 71%|███████   | 55/78 [15:42<06:19, 16.52s/epoch, loss=1.14, accuracy=0.754, val_loss=1.79, val_accuracy=0.518, lr=0.0316] 72%|███████▏  | 56/78 [15:59<06:05, 16.60s/epoch, loss=1.14, accuracy=0.756, val_loss=1.53, val_accuracy=0.616, lr=0.1]    73%|███████▎  | 57/78 [16:15<05:46, 16.51s/epoch, loss=1.14, accuracy=0.755, val_loss=2.78, val_accuracy=0.394, lr=0.1] 74%|███████▍  | 58/78 [16:32<05:31, 16.56s/epoch, loss=1.14, accuracy=0.755, val_loss=9.85, val_accuracy=0.164, lr=0.1] 76%|███████▌  | 59/78 [16:48<05:13, 16.48s/epoch, loss=1.13, accuracy=0.756, val_loss=3.26, val_accuracy=0.358, lr=0.1] 77%|███████▋  | 60/78 [17:05<04:56, 16.47s/epoch, loss=1.13, accuracy=0.757, val_loss=1.5, val_accuracy=0.64, lr=0.0316] 78%|███████▊  | 61/78 [17:21<04:40, 16.49s/epoch, loss=1.14, accuracy=0.758, val_loss=5.04, val_accuracy=0.239, lr=0.1]  79%|███████▉  | 62/78 [17:38<04:23, 16.49s/epoch, loss=1.14, accuracy=0.758, val_loss=1.73, val_accuracy=0.596, lr=0.1] 81%|████████  | 63/78 [17:54<04:06, 16.44s/epoch, loss=1.13, accuracy=0.759, val_loss=2.77, val_accuracy=0.459, lr=0.1] 82%|████████▏ | 64/78 [18:11<03:50, 16.43s/epoch, loss=1.13, accuracy=0.757, val_loss=2.48, val_accuracy=0.479, lr=0.1] 83%|████████▎ | 65/78 [18:27<03:33, 16.40s/epoch, loss=1.13, accuracy=0.757, val_loss=1.91, val_accuracy=0.492, lr=0.0316] 85%|████████▍ | 66/78 [18:43<03:16, 16.35s/epoch, loss=1.13, accuracy=0.758, val_loss=2.11, val_accuracy=0.499, lr=0.1]    86%|████████▌ | 67/78 [19:00<03:00, 16.38s/epoch, loss=1.13, accuracy=0.757, val_loss=1.59, val_accuracy=0.585, lr=0.1] 87%|████████▋ | 68/78 [19:16<02:43, 16.40s/epoch, loss=1.13, accuracy=0.756, val_loss=1.71, val_accuracy=0.566, lr=0.1] 88%|████████▊ | 69/78 [19:32<02:26, 16.32s/epoch, loss=1.13, accuracy=0.759, val_loss=1.56, val_accuracy=0.599, lr=0.1] 90%|████████▉ | 70/78 [19:48<02:10, 16.28s/epoch, loss=1.12, accuracy=0.758, val_loss=1.65, val_accuracy=0.561, lr=0.0316] 91%|█████████ | 71/78 [20:05<01:54, 16.33s/epoch, loss=1.12, accuracy=0.757, val_loss=2.33, val_accuracy=0.482, lr=0.1]    92%|█████████▏| 72/78 [20:21<01:37, 16.29s/epoch, loss=1.13, accuracy=0.757, val_loss=1.84, val_accuracy=0.545, lr=0.1] 94%|█████████▎| 73/78 [20:37<01:21, 16.25s/epoch, loss=1.13, accuracy=0.755, val_loss=2.1, val_accuracy=0.437, lr=0.1]  95%|█████████▍| 74/78 [20:53<01:04, 16.19s/epoch, loss=1.12, accuracy=0.756, val_loss=2.17, val_accuracy=0.532, lr=0.1] 96%|█████████▌| 75/78 [21:10<00:48, 16.27s/epoch, loss=1.12, accuracy=0.758, val_loss=3.07, val_accuracy=0.375, lr=0.0316] 97%|█████████▋| 76/78 [21:26<00:32, 16.30s/epoch, loss=1.13, accuracy=0.755, val_loss=1.79, val_accuracy=0.52, lr=0.1]     99%|█████████▊| 77/78 [21:43<00:16, 16.35s/epoch, loss=1.12, accuracy=0.758, val_loss=2.27, val_accuracy=0.43, lr=0.1]100%|██████████| 78/78 [21:59<00:00, 16.41s/epoch, loss=1.13, accuracy=0.757, val_loss=2.13, val_accuracy=0.462, lr=0.1]100%|██████████| 78/78 [21:59<00:00, 16.92s/epoch, loss=1.13, accuracy=0.757, val_loss=2.13, val_accuracy=0.462, lr=0.1]
Using real-time data augmentation.
Test score: 1.347427487373352
Test accuracy: 0.6947000026702881


* * * Run SGD for ID = 19_15. * * *


2024-02-20 04:36:40.811536: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 04:36:43.163620: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 04:36:43.164505: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-20 04:36:43.199854: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-20 04:36:43.199882: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 04:36:43.202545: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 04:36:43.202588: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-20 04:36:43.204628: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-20 04:36:43.205756: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-20 04:36:43.207912: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-20 04:36:43.209287: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-20 04:36:43.213742: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 04:36:43.214237: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-20 04:36:43.214309: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 04:36:44.552702: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-20 04:36:44.554257: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 04:36:44.554685: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-20 04:36:44.554714: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 04:36:44.554744: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 04:36:44.554759: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-20 04:36:44.554773: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-20 04:36:44.554787: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-20 04:36:44.554800: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-20 04:36:44.554814: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-20 04:36:44.554828: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 04:36:44.555261: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-20 04:36:44.555295: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 04:36:45.139093: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-20 04:36:45.139163: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-20 04:36:45.139172: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-20 04:36:45.140342: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': '19_15', 'batch_size': 128, 'epochs': 78, 'validation_split': 0.1, 'checkpointing': True, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
x_train shape: (45000, 32, 32, 3)
45000 train samples
5000 validation samples
10000 test samples
y_train shape: (45000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/78 [00:00<?, ?epoch/s]2024-02-20 04:36:45.892676: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-20 04:36:45.905066: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600020000 Hz
2024-02-20 04:36:47.667985: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 04:36:47.837358: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 04:36:48.500072: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-20 04:36:48.543629: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|▏         | 1/78 [00:46<59:46, 46.58s/epoch, loss=3.27, accuracy=0.327, val_loss=2.3, val_accuracy=0.282, lr=0.1]  3%|▎         | 2/78 [01:03<37:05, 29.29s/epoch, loss=1.53, accuracy=0.561, val_loss=2.01, val_accuracy=0.446, lr=0.1]  4%|▍         | 3/78 [01:20<29:35, 23.67s/epoch, loss=1.33, accuracy=0.652, val_loss=1.89, val_accuracy=0.501, lr=0.1]  5%|▌         | 4/78 [01:37<25:58, 21.05s/epoch, loss=1.27, accuracy=0.685, val_loss=1.76, val_accuracy=0.519, lr=0.1]  6%|▋         | 5/78 [01:55<23:56, 19.68s/epoch, loss=1.24, accuracy=0.705, val_loss=1.59, val_accuracy=0.573, lr=0.1]  8%|▊         | 6/78 [02:11<22:25, 18.69s/epoch, loss=1.23, accuracy=0.711, val_loss=2.31, val_accuracy=0.363, lr=0.1]  9%|▉         | 7/78 [02:28<21:24, 18.10s/epoch, loss=1.23, accuracy=0.717, val_loss=2.37, val_accuracy=0.396, lr=0.1] 10%|█         | 8/78 [02:45<20:38, 17.69s/epoch, loss=1.21, accuracy=0.726, val_loss=3.33, val_accuracy=0.357, lr=0.1] 12%|█▏        | 9/78 [03:02<20:01, 17.42s/epoch, loss=1.2, accuracy=0.726, val_loss=1.88, val_accuracy=0.515, lr=0.1]  13%|█▎        | 10/78 [03:19<19:29, 17.20s/epoch, loss=1.22, accuracy=0.728, val_loss=2.26, val_accuracy=0.436, lr=0.0316] 14%|█▍        | 11/78 [03:35<19:04, 17.08s/epoch, loss=1.2, accuracy=0.734, val_loss=1.96, val_accuracy=0.497, lr=0.1]     15%|█▌        | 12/78 [03:52<18:44, 17.04s/epoch, loss=1.2, accuracy=0.735, val_loss=2.44, val_accuracy=0.405, lr=0.1] 17%|█▋        | 13/78 [04:10<18:32, 17.12s/epoch, loss=1.2, accuracy=0.736, val_loss=1.96, val_accuracy=0.505, lr=0.1] 18%|█▊        | 14/78 [04:27<18:19, 17.17s/epoch, loss=1.19, accuracy=0.738, val_loss=1.63, val_accuracy=0.607, lr=0.1] 19%|█▉        | 15/78 [04:44<17:52, 17.02s/epoch, loss=1.19, accuracy=0.74, val_loss=1.97, val_accuracy=0.501, lr=0.0316] 21%|██        | 16/78 [05:00<17:31, 16.95s/epoch, loss=1.18, accuracy=0.74, val_loss=2.28, val_accuracy=0.439, lr=0.1]    22%|██▏       | 17/78 [05:17<17:10, 16.90s/epoch, loss=1.19, accuracy=0.743, val_loss=1.86, val_accuracy=0.577, lr=0.1] 23%|██▎       | 18/78 [05:34<16:49, 16.82s/epoch, loss=1.18, accuracy=0.742, val_loss=1.57, val_accuracy=0.593, lr=0.1] 24%|██▍       | 19/78 [05:51<16:35, 16.87s/epoch, loss=1.18, accuracy=0.744, val_loss=1.74, val_accuracy=0.588, lr=0.1] 26%|██▌       | 20/78 [06:07<16:13, 16.79s/epoch, loss=1.18, accuracy=0.741, val_loss=1.93, val_accuracy=0.462, lr=0.1] 27%|██▋       | 21/78 [06:24<15:56, 16.79s/epoch, loss=1.17, accuracy=0.745, val_loss=2.36, val_accuracy=0.476, lr=0.1] 28%|██▊       | 22/78 [06:41<15:40, 16.80s/epoch, loss=1.17, accuracy=0.746, val_loss=1.69, val_accuracy=0.57, lr=0.1]  29%|██▉       | 23/78 [06:58<15:20, 16.74s/epoch, loss=1.16, accuracy=0.749, val_loss=2.16, val_accuracy=0.465, lr=0.0316] 31%|███       | 24/78 [07:14<15:01, 16.69s/epoch, loss=1.17, accuracy=0.745, val_loss=1.6, val_accuracy=0.619, lr=0.1]     32%|███▏      | 25/78 [07:31<14:52, 16.84s/epoch, loss=1.16, accuracy=0.747, val_loss=1.92, val_accuracy=0.531, lr=0.1] 33%|███▎      | 26/78 [07:48<14:26, 16.67s/epoch, loss=1.16, accuracy=0.747, val_loss=2.17, val_accuracy=0.515, lr=0.1] 35%|███▍      | 27/78 [08:05<14:14, 16.76s/epoch, loss=1.15, accuracy=0.75, val_loss=1.54, val_accuracy=0.643, lr=0.1]  36%|███▌      | 28/78 [08:22<14:00, 16.82s/epoch, loss=1.17, accuracy=0.745, val_loss=2.39, val_accuracy=0.397, lr=0.1] 37%|███▋      | 29/78 [08:39<13:49, 16.93s/epoch, loss=1.15, accuracy=0.75, val_loss=2.68, val_accuracy=0.384, lr=0.1]  38%|███▊      | 30/78 [08:55<13:30, 16.88s/epoch, loss=1.15, accuracy=0.751, val_loss=1.62, val_accuracy=0.58, lr=0.1] 40%|███▉      | 31/78 [09:12<13:02, 16.65s/epoch, loss=1.15, accuracy=0.752, val_loss=3.44, val_accuracy=0.271, lr=0.1] 41%|████      | 32/78 [09:28<12:40, 16.53s/epoch, loss=1.15, accuracy=0.752, val_loss=2, val_accuracy=0.544, lr=0.0316] 42%|████▏     | 33/78 [09:44<12:18, 16.42s/epoch, loss=1.15, accuracy=0.75, val_loss=2.47, val_accuracy=0.43, lr=0.1]   44%|████▎     | 34/78 [10:00<11:56, 16.29s/epoch, loss=1.14, accuracy=0.752, val_loss=1.89, val_accuracy=0.516, lr=0.1] 45%|████▍     | 35/78 [10:16<11:38, 16.25s/epoch, loss=1.15, accuracy=0.752, val_loss=1.94, val_accuracy=0.545, lr=0.1] 46%|████▌     | 36/78 [10:32<11:17, 16.13s/epoch, loss=1.14, accuracy=0.751, val_loss=4.46, val_accuracy=0.333, lr=0.1] 47%|████▋     | 37/78 [10:48<11:03, 16.18s/epoch, loss=1.14, accuracy=0.753, val_loss=3.51, val_accuracy=0.377, lr=0.0316] 49%|████▊     | 38/78 [11:05<10:48, 16.22s/epoch, loss=1.14, accuracy=0.755, val_loss=2.13, val_accuracy=0.443, lr=0.1]    50%|█████     | 39/78 [11:21<10:33, 16.24s/epoch, loss=1.13, accuracy=0.755, val_loss=1.83, val_accuracy=0.568, lr=0.1] 51%|█████▏    | 40/78 [11:37<10:14, 16.18s/epoch, loss=1.14, accuracy=0.75, val_loss=1.56, val_accuracy=0.618, lr=0.1]  53%|█████▎    | 41/78 [11:53<10:01, 16.25s/epoch, loss=1.14, accuracy=0.752, val_loss=2.05, val_accuracy=0.469, lr=0.1] 54%|█████▍    | 42/78 [12:10<09:44, 16.25s/epoch, loss=1.14, accuracy=0.755, val_loss=3.16, val_accuracy=0.388, lr=0.0316] 55%|█████▌    | 43/78 [12:26<09:30, 16.29s/epoch, loss=1.14, accuracy=0.756, val_loss=1.83, val_accuracy=0.55, lr=0.1]     56%|█████▋    | 44/78 [12:42<09:14, 16.32s/epoch, loss=1.14, accuracy=0.752, val_loss=1.97, val_accuracy=0.525, lr=0.1] 58%|█████▊    | 45/78 [12:58<08:55, 16.23s/epoch, loss=1.14, accuracy=0.755, val_loss=1.96, val_accuracy=0.532, lr=0.1] 59%|█████▉    | 46/78 [13:14<08:37, 16.19s/epoch, loss=1.14, accuracy=0.752, val_loss=2.44, val_accuracy=0.35, lr=0.1]  60%|██████    | 47/78 [13:31<08:20, 16.16s/epoch, loss=1.13, accuracy=0.753, val_loss=1.53, val_accuracy=0.613, lr=0.1] 62%|██████▏   | 48/78 [13:47<08:05, 16.18s/epoch, loss=1.13, accuracy=0.756, val_loss=1.6, val_accuracy=0.58, lr=0.1]   63%|██████▎   | 49/78 [14:03<07:50, 16.22s/epoch, loss=1.13, accuracy=0.755, val_loss=1.7, val_accuracy=0.595, lr=0.1] 64%|██████▍   | 50/78 [14:19<07:32, 16.15s/epoch, loss=1.13, accuracy=0.754, val_loss=2.64, val_accuracy=0.459, lr=0.1] 65%|██████▌   | 51/78 [14:35<07:13, 16.05s/epoch, loss=1.13, accuracy=0.753, val_loss=3.14, val_accuracy=0.377, lr=0.1] 67%|██████▋   | 52/78 [14:51<06:56, 16.04s/epoch, loss=1.13, accuracy=0.755, val_loss=3.32, val_accuracy=0.304, lr=0.0316] 68%|██████▊   | 53/78 [15:07<06:43, 16.14s/epoch, loss=1.12, accuracy=0.754, val_loss=1.42, val_accuracy=0.631, lr=0.1]    69%|██████▉   | 54/78 [15:24<06:28, 16.19s/epoch, loss=1.13, accuracy=0.755, val_loss=1.82, val_accuracy=0.573, lr=0.1] 71%|███████   | 55/78 [15:39<06:09, 16.07s/epoch, loss=1.13, accuracy=0.757, val_loss=2.44, val_accuracy=0.488, lr=0.1] 72%|███████▏  | 56/78 [15:55<05:53, 16.06s/epoch, loss=1.14, accuracy=0.751, val_loss=1.34, val_accuracy=0.689, lr=0.1] 73%|███████▎  | 57/78 [16:11<05:35, 15.99s/epoch, loss=1.13, accuracy=0.755, val_loss=1.62, val_accuracy=0.614, lr=0.1] 74%|███████▍  | 58/78 [16:28<05:22, 16.14s/epoch, loss=1.13, accuracy=0.755, val_loss=1.92, val_accuracy=0.515, lr=0.1] 76%|███████▌  | 59/78 [16:44<05:09, 16.28s/epoch, loss=1.13, accuracy=0.757, val_loss=2.58, val_accuracy=0.45, lr=0.1]  77%|███████▋  | 60/78 [17:01<04:54, 16.37s/epoch, loss=1.13, accuracy=0.754, val_loss=1.81, val_accuracy=0.544, lr=0.1] 78%|███████▊  | 61/78 [17:17<04:35, 16.21s/epoch, loss=1.12, accuracy=0.757, val_loss=1.87, val_accuracy=0.543, lr=0.0316] 79%|███████▉  | 62/78 [17:33<04:21, 16.34s/epoch, loss=1.12, accuracy=0.756, val_loss=3.26, val_accuracy=0.314, lr=0.1]    81%|████████  | 63/78 [17:49<04:02, 16.20s/epoch, loss=1.12, accuracy=0.755, val_loss=1.75, val_accuracy=0.547, lr=0.1] 82%|████████▏ | 64/78 [18:05<03:45, 16.14s/epoch, loss=1.12, accuracy=0.756, val_loss=4.49, val_accuracy=0.216, lr=0.1] 83%|████████▎ | 65/78 [18:22<03:31, 16.27s/epoch, loss=1.12, accuracy=0.755, val_loss=2.05, val_accuracy=0.49, lr=0.1]  85%|████████▍ | 66/78 [18:38<03:14, 16.18s/epoch, loss=1.12, accuracy=0.759, val_loss=1.95, val_accuracy=0.532, lr=0.0316] 86%|████████▌ | 67/78 [18:54<02:59, 16.32s/epoch, loss=1.12, accuracy=0.755, val_loss=1.91, val_accuracy=0.503, lr=0.1]    87%|████████▋ | 68/78 [19:11<02:43, 16.34s/epoch, loss=1.11, accuracy=0.76, val_loss=2.36, val_accuracy=0.445, lr=0.1]  88%|████████▊ | 69/78 [19:27<02:26, 16.23s/epoch, loss=1.12, accuracy=0.759, val_loss=1.5, val_accuracy=0.642, lr=0.1] 90%|████████▉ | 70/78 [19:43<02:09, 16.15s/epoch, loss=1.12, accuracy=0.755, val_loss=2.05, val_accuracy=0.494, lr=0.1] 91%|█████████ | 71/78 [19:59<01:52, 16.13s/epoch, loss=1.12, accuracy=0.755, val_loss=1.96, val_accuracy=0.486, lr=0.0316] 92%|█████████▏| 72/78 [20:15<01:37, 16.17s/epoch, loss=1.12, accuracy=0.756, val_loss=1.93, val_accuracy=0.536, lr=0.1]    94%|█████████▎| 73/78 [20:31<01:20, 16.17s/epoch, loss=1.12, accuracy=0.757, val_loss=1.84, val_accuracy=0.523, lr=0.1] 95%|█████████▍| 74/78 [20:48<01:04, 16.25s/epoch, loss=1.12, accuracy=0.757, val_loss=4.46, val_accuracy=0.302, lr=0.1] 96%|█████████▌| 75/78 [21:04<00:48, 16.13s/epoch, loss=1.12, accuracy=0.757, val_loss=3.22, val_accuracy=0.337, lr=0.1] 97%|█████████▋| 76/78 [21:20<00:32, 16.14s/epoch, loss=1.12, accuracy=0.757, val_loss=1.76, val_accuracy=0.52, lr=0.0316] 99%|█████████▊| 77/78 [21:36<00:16, 16.18s/epoch, loss=1.12, accuracy=0.759, val_loss=2.3, val_accuracy=0.467, lr=0.1]   100%|██████████| 78/78 [21:52<00:00, 16.09s/epoch, loss=1.12, accuracy=0.755, val_loss=3.22, val_accuracy=0.367, lr=0.1]100%|██████████| 78/78 [21:52<00:00, 16.83s/epoch, loss=1.12, accuracy=0.755, val_loss=3.22, val_accuracy=0.367, lr=0.1]
Using real-time data augmentation.
Test score: 1.3495539426803589
Test accuracy: 0.6912999749183655


* * * Run SGD for ID = 19_16. * * *


2024-02-20 04:58:43.155688: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 04:58:45.746739: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 04:58:45.747690: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-20 04:58:45.783469: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-20 04:58:45.783497: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 04:58:45.786382: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 04:58:45.786418: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-20 04:58:45.788741: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-20 04:58:45.789412: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-20 04:58:45.791737: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-20 04:58:45.793151: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-20 04:58:45.797520: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 04:58:45.798049: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-20 04:58:45.798125: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 04:58:47.214871: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-20 04:58:47.215831: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 04:58:47.216587: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-20 04:58:47.216617: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 04:58:47.216653: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 04:58:47.216671: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-20 04:58:47.216688: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-20 04:58:47.216704: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-20 04:58:47.216719: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-20 04:58:47.216733: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-20 04:58:47.216748: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 04:58:47.217203: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-20 04:58:47.217240: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 04:58:47.815236: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-20 04:58:47.815303: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-20 04:58:47.815313: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-20 04:58:47.816264: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': '19_16', 'batch_size': 128, 'epochs': 78, 'validation_split': 0.1, 'checkpointing': True, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
x_train shape: (45000, 32, 32, 3)
45000 train samples
5000 validation samples
10000 test samples
y_train shape: (45000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/78 [00:00<?, ?epoch/s]2024-02-20 04:58:48.588394: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-20 04:58:48.600193: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600020000 Hz
2024-02-20 04:58:50.410197: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 04:58:50.604487: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 04:58:51.247314: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-20 04:58:51.290220: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|▏         | 1/78 [00:47<1:01:25, 47.86s/epoch, loss=3.36, accuracy=0.278, val_loss=2.88, val_accuracy=0.225, lr=0.1]  3%|▎         | 2/78 [01:04<37:29, 29.60s/epoch, loss=1.62, accuracy=0.515, val_loss=2.04, val_accuracy=0.39, lr=0.1]     4%|▍         | 3/78 [01:20<29:18, 23.45s/epoch, loss=1.36, accuracy=0.628, val_loss=3.66, val_accuracy=0.227, lr=0.1]  5%|▌         | 4/78 [01:37<25:24, 20.61s/epoch, loss=1.29, accuracy=0.669, val_loss=1.84, val_accuracy=0.53, lr=0.1]   6%|▋         | 5/78 [01:53<23:12, 19.08s/epoch, loss=1.26, accuracy=0.693, val_loss=1.63, val_accuracy=0.581, lr=0.1]  8%|▊         | 6/78 [02:09<21:43, 18.11s/epoch, loss=1.24, accuracy=0.708, val_loss=1.5, val_accuracy=0.62, lr=0.1]    9%|▉         | 7/78 [02:26<20:47, 17.56s/epoch, loss=1.23, accuracy=0.713, val_loss=2.03, val_accuracy=0.519, lr=0.1] 10%|█         | 8/78 [02:41<19:50, 17.01s/epoch, loss=1.22, accuracy=0.72, val_loss=2.14, val_accuracy=0.475, lr=0.1]  12%|█▏        | 9/78 [02:57<19:12, 16.70s/epoch, loss=1.22, accuracy=0.721, val_loss=1.61, val_accuracy=0.582, lr=0.1] 13%|█▎        | 10/78 [03:14<18:42, 16.51s/epoch, loss=1.22, accuracy=0.725, val_loss=1.52, val_accuracy=0.617, lr=0.1] 14%|█▍        | 11/78 [03:30<18:19, 16.41s/epoch, loss=1.21, accuracy=0.729, val_loss=2.61, val_accuracy=0.434, lr=0.0316] 15%|█▌        | 12/78 [03:46<17:58, 16.34s/epoch, loss=1.2, accuracy=0.734, val_loss=2.18, val_accuracy=0.417, lr=0.1]     17%|█▋        | 13/78 [04:02<17:38, 16.29s/epoch, loss=1.2, accuracy=0.734, val_loss=2.62, val_accuracy=0.436, lr=0.1] 18%|█▊        | 14/78 [04:19<17:26, 16.36s/epoch, loss=1.2, accuracy=0.738, val_loss=2.42, val_accuracy=0.444, lr=0.1] 19%|█▉        | 15/78 [04:35<17:05, 16.28s/epoch, loss=1.19, accuracy=0.736, val_loss=2.21, val_accuracy=0.434, lr=0.1] 21%|██        | 16/78 [04:51<16:48, 16.27s/epoch, loss=1.18, accuracy=0.742, val_loss=2.65, val_accuracy=0.437, lr=0.0316] 22%|██▏       | 17/78 [05:07<16:33, 16.28s/epoch, loss=1.19, accuracy=0.741, val_loss=1.93, val_accuracy=0.49, lr=0.1]     23%|██▎       | 18/78 [05:23<16:14, 16.24s/epoch, loss=1.18, accuracy=0.744, val_loss=1.9, val_accuracy=0.507, lr=0.1] 24%|██▍       | 19/78 [05:40<16:01, 16.29s/epoch, loss=1.19, accuracy=0.741, val_loss=1.72, val_accuracy=0.595, lr=0.1] 26%|██▌       | 20/78 [05:56<15:46, 16.32s/epoch, loss=1.19, accuracy=0.743, val_loss=2.34, val_accuracy=0.48, lr=0.1]  27%|██▋       | 21/78 [06:13<15:33, 16.38s/epoch, loss=1.17, accuracy=0.746, val_loss=2.7, val_accuracy=0.351, lr=0.0316] 28%|██▊       | 22/78 [06:29<15:20, 16.44s/epoch, loss=1.17, accuracy=0.743, val_loss=1.73, val_accuracy=0.553, lr=0.1]   29%|██▉       | 23/78 [06:46<15:04, 16.44s/epoch, loss=1.17, accuracy=0.745, val_loss=1.67, val_accuracy=0.586, lr=0.1] 31%|███       | 24/78 [07:02<14:49, 16.47s/epoch, loss=1.16, accuracy=0.75, val_loss=1.67, val_accuracy=0.579, lr=0.1]  32%|███▏      | 25/78 [07:19<14:45, 16.70s/epoch, loss=1.16, accuracy=0.747, val_loss=1.79, val_accuracy=0.535, lr=0.1] 33%|███▎      | 26/78 [07:36<14:20, 16.56s/epoch, loss=1.16, accuracy=0.749, val_loss=3.43, val_accuracy=0.334, lr=0.0316] 35%|███▍      | 27/78 [07:52<13:58, 16.44s/epoch, loss=1.17, accuracy=0.747, val_loss=2.03, val_accuracy=0.509, lr=0.1]    36%|███▌      | 28/78 [08:09<13:58, 16.77s/epoch, loss=1.16, accuracy=0.75, val_loss=1.66, val_accuracy=0.609, lr=0.1]  37%|███▋      | 29/78 [08:26<13:45, 16.84s/epoch, loss=1.16, accuracy=0.75, val_loss=1.37, val_accuracy=0.679, lr=0.1] 38%|███▊      | 30/78 [08:43<13:23, 16.74s/epoch, loss=1.15, accuracy=0.751, val_loss=1.48, val_accuracy=0.624, lr=0.1] 40%|███▉      | 31/78 [08:59<13:00, 16.62s/epoch, loss=1.15, accuracy=0.753, val_loss=1.77, val_accuracy=0.521, lr=0.1] 41%|████      | 32/78 [09:17<12:56, 16.87s/epoch, loss=1.15, accuracy=0.751, val_loss=2.55, val_accuracy=0.458, lr=0.1] 42%|████▏     | 33/78 [09:34<12:38, 16.85s/epoch, loss=1.15, accuracy=0.75, val_loss=1.6, val_accuracy=0.581, lr=0.1]   44%|████▎     | 34/78 [09:50<12:18, 16.78s/epoch, loss=1.15, accuracy=0.752, val_loss=2.24, val_accuracy=0.386, lr=0.0316] 45%|████▍     | 35/78 [10:07<11:58, 16.71s/epoch, loss=1.15, accuracy=0.751, val_loss=1.69, val_accuracy=0.598, lr=0.1]    46%|████▌     | 36/78 [10:23<11:37, 16.61s/epoch, loss=1.14, accuracy=0.752, val_loss=1.87, val_accuracy=0.462, lr=0.1] 47%|████▋     | 37/78 [10:40<11:24, 16.71s/epoch, loss=1.15, accuracy=0.751, val_loss=1.91, val_accuracy=0.551, lr=0.1] 49%|████▊     | 38/78 [10:57<11:13, 16.84s/epoch, loss=1.14, accuracy=0.753, val_loss=2.09, val_accuracy=0.428, lr=0.1] 50%|█████     | 39/78 [11:13<10:50, 16.69s/epoch, loss=1.13, accuracy=0.753, val_loss=2.04, val_accuracy=0.508, lr=0.0316] 51%|█████▏    | 40/78 [11:30<10:31, 16.63s/epoch, loss=1.14, accuracy=0.753, val_loss=1.9, val_accuracy=0.555, lr=0.1]     53%|█████▎    | 41/78 [11:46<10:07, 16.43s/epoch, loss=1.14, accuracy=0.754, val_loss=1.63, val_accuracy=0.57, lr=0.1] 54%|█████▍    | 42/78 [12:03<09:53, 16.48s/epoch, loss=1.13, accuracy=0.753, val_loss=3.6, val_accuracy=0.237, lr=0.1] 55%|█████▌    | 43/78 [12:19<09:41, 16.61s/epoch, loss=1.13, accuracy=0.754, val_loss=1.61, val_accuracy=0.582, lr=0.1] 56%|█████▋    | 44/78 [12:36<09:23, 16.56s/epoch, loss=1.13, accuracy=0.754, val_loss=1.65, val_accuracy=0.579, lr=0.0316] 58%|█████▊    | 45/78 [12:52<09:03, 16.46s/epoch, loss=1.13, accuracy=0.755, val_loss=1.87, val_accuracy=0.529, lr=0.1]    59%|█████▉    | 46/78 [13:08<08:44, 16.38s/epoch, loss=1.13, accuracy=0.756, val_loss=1.98, val_accuracy=0.499, lr=0.1] 60%|██████    | 47/78 [13:24<08:23, 16.23s/epoch, loss=1.13, accuracy=0.755, val_loss=3.44, val_accuracy=0.306, lr=0.1] 62%|██████▏   | 48/78 [13:40<08:04, 16.14s/epoch, loss=1.13, accuracy=0.755, val_loss=2.23, val_accuracy=0.449, lr=0.1] 63%|██████▎   | 49/78 [13:57<07:51, 16.25s/epoch, loss=1.13, accuracy=0.755, val_loss=1.48, val_accuracy=0.638, lr=0.0316] 64%|██████▍   | 50/78 [14:13<07:33, 16.18s/epoch, loss=1.13, accuracy=0.756, val_loss=2.4, val_accuracy=0.463, lr=0.1]     65%|██████▌   | 51/78 [14:29<07:14, 16.10s/epoch, loss=1.13, accuracy=0.754, val_loss=2.46, val_accuracy=0.432, lr=0.1] 67%|██████▋   | 52/78 [14:45<06:59, 16.15s/epoch, loss=1.13, accuracy=0.757, val_loss=1.53, val_accuracy=0.611, lr=0.1] 68%|██████▊   | 53/78 [15:02<06:48, 16.33s/epoch, loss=1.13, accuracy=0.758, val_loss=2.16, val_accuracy=0.457, lr=0.1] 69%|██████▉   | 54/78 [15:17<06:28, 16.20s/epoch, loss=1.12, accuracy=0.755, val_loss=1.89, val_accuracy=0.518, lr=0.0316] 71%|███████   | 55/78 [15:34<06:13, 16.23s/epoch, loss=1.12, accuracy=0.759, val_loss=2.78, val_accuracy=0.415, lr=0.1]    72%|███████▏  | 56/78 [15:50<05:54, 16.10s/epoch, loss=1.12, accuracy=0.757, val_loss=5.65, val_accuracy=0.152, lr=0.1] 73%|███████▎  | 57/78 [16:06<05:37, 16.06s/epoch, loss=1.13, accuracy=0.755, val_loss=1.77, val_accuracy=0.541, lr=0.1] 74%|███████▍  | 58/78 [16:21<05:20, 16.02s/epoch, loss=1.13, accuracy=0.755, val_loss=2.3, val_accuracy=0.471, lr=0.1]  76%|███████▌  | 59/78 [16:37<05:04, 16.01s/epoch, loss=1.12, accuracy=0.758, val_loss=2.29, val_accuracy=0.497, lr=0.0316] 77%|███████▋  | 60/78 [16:54<04:49, 16.06s/epoch, loss=1.12, accuracy=0.755, val_loss=2.3, val_accuracy=0.473, lr=0.1]     78%|███████▊  | 61/78 [17:10<04:35, 16.20s/epoch, loss=1.12, accuracy=0.756, val_loss=1.93, val_accuracy=0.517, lr=0.1] 79%|███████▉  | 62/78 [17:26<04:18, 16.18s/epoch, loss=1.11, accuracy=0.754, val_loss=2.04, val_accuracy=0.488, lr=0.1] 81%|████████  | 63/78 [17:43<04:03, 16.22s/epoch, loss=1.12, accuracy=0.757, val_loss=2.32, val_accuracy=0.379, lr=0.1] 82%|████████▏ | 64/78 [17:58<03:45, 16.13s/epoch, loss=1.11, accuracy=0.759, val_loss=1.91, val_accuracy=0.469, lr=0.0316] 83%|████████▎ | 65/78 [18:15<03:30, 16.18s/epoch, loss=1.12, accuracy=0.756, val_loss=2.37, val_accuracy=0.437, lr=0.1]    85%|████████▍ | 66/78 [18:30<03:12, 16.03s/epoch, loss=1.11, accuracy=0.76, val_loss=1.83, val_accuracy=0.525, lr=0.1]  86%|████████▌ | 67/78 [18:46<02:55, 15.95s/epoch, loss=1.11, accuracy=0.757, val_loss=1.8, val_accuracy=0.56, lr=0.1]  87%|████████▋ | 68/78 [19:02<02:39, 15.92s/epoch, loss=1.12, accuracy=0.759, val_loss=1.63, val_accuracy=0.582, lr=0.1] 88%|████████▊ | 69/78 [19:18<02:23, 15.90s/epoch, loss=1.11, accuracy=0.76, val_loss=2.18, val_accuracy=0.484, lr=0.0316] 90%|████████▉ | 70/78 [19:34<02:08, 16.05s/epoch, loss=1.11, accuracy=0.758, val_loss=1.67, val_accuracy=0.555, lr=0.1]   91%|█████████ | 71/78 [19:51<01:53, 16.25s/epoch, loss=1.11, accuracy=0.759, val_loss=2.1, val_accuracy=0.429, lr=0.1]  92%|█████████▏| 72/78 [20:07<01:36, 16.09s/epoch, loss=1.12, accuracy=0.756, val_loss=2.08, val_accuracy=0.434, lr=0.1] 94%|█████████▎| 73/78 [20:23<01:21, 16.21s/epoch, loss=1.12, accuracy=0.758, val_loss=5.71, val_accuracy=0.261, lr=0.1] 95%|█████████▍| 74/78 [20:40<01:05, 16.25s/epoch, loss=1.1, accuracy=0.757, val_loss=2.04, val_accuracy=0.49, lr=0.0316] 96%|█████████▌| 75/78 [20:55<00:48, 16.07s/epoch, loss=1.12, accuracy=0.757, val_loss=1.86, val_accuracy=0.562, lr=0.1]  97%|█████████▋| 76/78 [21:11<00:32, 16.00s/epoch, loss=1.11, accuracy=0.758, val_loss=2.05, val_accuracy=0.414, lr=0.1] 99%|█████████▊| 77/78 [21:27<00:16, 16.10s/epoch, loss=1.12, accuracy=0.756, val_loss=4.23, val_accuracy=0.315, lr=0.1]100%|██████████| 78/78 [21:44<00:00, 16.12s/epoch, loss=1.12, accuracy=0.757, val_loss=2.1, val_accuracy=0.47, lr=0.1]  100%|██████████| 78/78 [21:44<00:00, 16.72s/epoch, loss=1.12, accuracy=0.757, val_loss=2.1, val_accuracy=0.47, lr=0.1]
Using real-time data augmentation.
Test score: 1.3668338060379028
Test accuracy: 0.6872000098228455


* * * Run SGD for ID = 19_17. * * *


2024-02-20 05:20:39.097815: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 05:20:51.860407: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 05:20:51.861320: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-20 05:20:51.896868: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-20 05:20:51.896898: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 05:20:51.902192: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 05:20:51.902230: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-20 05:20:51.905887: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-20 05:20:51.907795: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-20 05:20:51.910941: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-20 05:20:51.913491: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-20 05:20:51.919084: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 05:20:51.919593: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-20 05:20:51.919668: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 05:20:53.246018: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-20 05:20:53.247012: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 05:20:53.247720: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-20 05:20:53.247748: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 05:20:53.247782: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 05:20:53.247798: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-20 05:20:53.247814: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-20 05:20:53.247830: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-20 05:20:53.247845: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-20 05:20:53.247868: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-20 05:20:53.247884: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 05:20:53.248317: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-20 05:20:53.248346: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 05:20:53.808114: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-20 05:20:53.808172: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-20 05:20:53.808188: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-20 05:20:53.809060: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': '19_17', 'batch_size': 128, 'epochs': 78, 'validation_split': 0.1, 'checkpointing': True, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
x_train shape: (45000, 32, 32, 3)
45000 train samples
5000 validation samples
10000 test samples
y_train shape: (45000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/78 [00:00<?, ?epoch/s]2024-02-20 05:20:54.540829: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-20 05:20:54.553199: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600020000 Hz
2024-02-20 05:20:56.285728: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 05:20:56.580612: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 05:20:57.150274: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-20 05:20:57.185143: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|▏         | 1/78 [00:43<55:34, 43.30s/epoch, loss=3.84, accuracy=0.272, val_loss=2.34, val_accuracy=0.282, lr=0.1]  3%|▎         | 2/78 [00:59<34:58, 27.62s/epoch, loss=1.77, accuracy=0.444, val_loss=1.94, val_accuracy=0.368, lr=0.1]  4%|▍         | 3/78 [01:16<28:11, 22.56s/epoch, loss=1.57, accuracy=0.52, val_loss=1.77, val_accuracy=0.448, lr=0.1]   5%|▌         | 4/78 [01:33<25:00, 20.27s/epoch, loss=1.45, accuracy=0.593, val_loss=1.82, val_accuracy=0.46, lr=0.1]  6%|▋         | 5/78 [01:50<23:11, 19.07s/epoch, loss=1.35, accuracy=0.654, val_loss=2.13, val_accuracy=0.471, lr=0.1]  8%|▊         | 6/78 [02:07<21:59, 18.33s/epoch, loss=1.29, accuracy=0.687, val_loss=1.6, val_accuracy=0.593, lr=0.1]   9%|▉         | 7/78 [02:23<21:08, 17.86s/epoch, loss=1.27, accuracy=0.698, val_loss=3.86, val_accuracy=0.27, lr=0.1] 10%|█         | 8/78 [02:40<20:24, 17.50s/epoch, loss=1.26, accuracy=0.706, val_loss=1.65, val_accuracy=0.566, lr=0.1] 12%|█▏        | 9/78 [02:57<19:43, 17.16s/epoch, loss=1.25, accuracy=0.714, val_loss=2.54, val_accuracy=0.393, lr=0.1] 13%|█▎        | 10/78 [03:13<19:14, 16.98s/epoch, loss=1.24, accuracy=0.718, val_loss=3.18, val_accuracy=0.317, lr=0.1] 14%|█▍        | 11/78 [03:30<18:48, 16.84s/epoch, loss=1.23, accuracy=0.723, val_loss=1.94, val_accuracy=0.504, lr=0.0316] 15%|█▌        | 12/78 [03:46<18:29, 16.80s/epoch, loss=1.23, accuracy=0.726, val_loss=1.67, val_accuracy=0.601, lr=0.1]    17%|█▋        | 13/78 [04:03<18:04, 16.69s/epoch, loss=1.22, accuracy=0.73, val_loss=1.68, val_accuracy=0.581, lr=0.1]  18%|█▊        | 14/78 [04:19<17:42, 16.60s/epoch, loss=1.21, accuracy=0.733, val_loss=1.83, val_accuracy=0.549, lr=0.1] 19%|█▉        | 15/78 [04:36<17:28, 16.64s/epoch, loss=1.21, accuracy=0.732, val_loss=2.5, val_accuracy=0.44, lr=0.1]   21%|██        | 16/78 [04:53<17:13, 16.66s/epoch, loss=1.21, accuracy=0.737, val_loss=1.81, val_accuracy=0.508, lr=0.0316] 22%|██▏       | 17/78 [05:09<16:49, 16.55s/epoch, loss=1.2, accuracy=0.735, val_loss=2.09, val_accuracy=0.528, lr=0.1]     23%|██▎       | 18/78 [05:25<16:28, 16.47s/epoch, loss=1.21, accuracy=0.734, val_loss=1.69, val_accuracy=0.6, lr=0.1]  24%|██▍       | 19/78 [05:42<16:12, 16.49s/epoch, loss=1.2, accuracy=0.736, val_loss=1.52, val_accuracy=0.611, lr=0.1] 26%|██▌       | 20/78 [05:58<15:54, 16.46s/epoch, loss=1.2, accuracy=0.739, val_loss=2.02, val_accuracy=0.49, lr=0.1]  27%|██▋       | 21/78 [06:15<15:45, 16.60s/epoch, loss=1.19, accuracy=0.741, val_loss=1.48, val_accuracy=0.647, lr=0.1] 28%|██▊       | 22/78 [06:32<15:28, 16.58s/epoch, loss=1.19, accuracy=0.74, val_loss=1.76, val_accuracy=0.531, lr=0.1]  29%|██▉       | 23/78 [06:48<15:13, 16.61s/epoch, loss=1.19, accuracy=0.742, val_loss=2.48, val_accuracy=0.476, lr=0.1] 31%|███       | 24/78 [07:05<14:59, 16.65s/epoch, loss=1.18, accuracy=0.741, val_loss=2, val_accuracy=0.449, lr=0.1]    32%|███▏      | 25/78 [07:22<14:42, 16.64s/epoch, loss=1.19, accuracy=0.741, val_loss=1.8, val_accuracy=0.541, lr=0.1] 33%|███▎      | 26/78 [07:38<14:25, 16.64s/epoch, loss=1.18, accuracy=0.745, val_loss=4.23, val_accuracy=0.311, lr=0.0316] 35%|███▍      | 27/78 [07:55<14:08, 16.63s/epoch, loss=1.18, accuracy=0.745, val_loss=1.62, val_accuracy=0.594, lr=0.1]    36%|███▌      | 28/78 [08:12<13:53, 16.67s/epoch, loss=1.18, accuracy=0.743, val_loss=2.83, val_accuracy=0.335, lr=0.1] 37%|███▋      | 29/78 [08:28<13:38, 16.70s/epoch, loss=1.18, accuracy=0.747, val_loss=2.75, val_accuracy=0.281, lr=0.1] 38%|███▊      | 30/78 [08:45<13:15, 16.58s/epoch, loss=1.18, accuracy=0.744, val_loss=1.71, val_accuracy=0.581, lr=0.1] 40%|███▉      | 31/78 [09:01<12:59, 16.59s/epoch, loss=1.18, accuracy=0.745, val_loss=1.73, val_accuracy=0.592, lr=0.0316] 41%|████      | 32/78 [09:18<12:41, 16.56s/epoch, loss=1.17, accuracy=0.747, val_loss=2.68, val_accuracy=0.433, lr=0.1]    42%|████▏     | 33/78 [09:34<12:22, 16.49s/epoch, loss=1.17, accuracy=0.748, val_loss=2.01, val_accuracy=0.49, lr=0.1]  44%|████▎     | 34/78 [09:51<12:05, 16.48s/epoch, loss=1.18, accuracy=0.744, val_loss=2.15, val_accuracy=0.458, lr=0.1] 45%|████▍     | 35/78 [10:07<11:48, 16.48s/epoch, loss=1.17, accuracy=0.748, val_loss=2.95, val_accuracy=0.371, lr=0.1] 46%|████▌     | 36/78 [10:23<11:30, 16.44s/epoch, loss=1.18, accuracy=0.744, val_loss=2.35, val_accuracy=0.463, lr=0.0316] 47%|████▋     | 37/78 [10:40<11:17, 16.54s/epoch, loss=1.17, accuracy=0.746, val_loss=1.45, val_accuracy=0.664, lr=0.1]    49%|████▊     | 38/78 [10:57<11:04, 16.60s/epoch, loss=1.17, accuracy=0.746, val_loss=1.42, val_accuracy=0.675, lr=0.1] 50%|█████     | 39/78 [11:13<10:45, 16.56s/epoch, loss=1.17, accuracy=0.748, val_loss=1.78, val_accuracy=0.548, lr=0.1] 51%|█████▏    | 40/78 [11:30<10:33, 16.66s/epoch, loss=1.16, accuracy=0.753, val_loss=1.72, val_accuracy=0.561, lr=0.1] 53%|█████▎    | 41/78 [11:47<10:14, 16.62s/epoch, loss=1.16, accuracy=0.75, val_loss=3.47, val_accuracy=0.259, lr=0.1]  54%|█████▍    | 42/78 [12:04<10:00, 16.69s/epoch, loss=1.16, accuracy=0.752, val_loss=1.75, val_accuracy=0.544, lr=0.1] 55%|█████▌    | 43/78 [12:21<09:48, 16.81s/epoch, loss=1.16, accuracy=0.751, val_loss=1.35, val_accuracy=0.674, lr=0.1] 56%|█████▋    | 44/78 [12:37<09:24, 16.59s/epoch, loss=1.16, accuracy=0.751, val_loss=1.87, val_accuracy=0.542, lr=0.1] 58%|█████▊    | 45/78 [12:54<09:07, 16.59s/epoch, loss=1.16, accuracy=0.75, val_loss=2.42, val_accuracy=0.398, lr=0.1]  59%|█████▉    | 46/78 [13:10<08:50, 16.59s/epoch, loss=1.15, accuracy=0.751, val_loss=2.67, val_accuracy=0.441, lr=0.1] 60%|██████    | 47/78 [13:26<08:25, 16.31s/epoch, loss=1.16, accuracy=0.751, val_loss=2.22, val_accuracy=0.433, lr=0.1] 62%|██████▏   | 48/78 [13:41<08:03, 16.13s/epoch, loss=1.16, accuracy=0.753, val_loss=1.71, val_accuracy=0.547, lr=0.0316] 63%|██████▎   | 49/78 [13:57<07:42, 15.95s/epoch, loss=1.16, accuracy=0.752, val_loss=1.45, val_accuracy=0.647, lr=0.1]    64%|██████▍   | 50/78 [14:13<07:25, 15.91s/epoch, loss=1.16, accuracy=0.752, val_loss=1.52, val_accuracy=0.633, lr=0.1] 65%|██████▌   | 51/78 [14:29<07:12, 16.01s/epoch, loss=1.15, accuracy=0.754, val_loss=1.93, val_accuracy=0.534, lr=0.1] 67%|██████▋   | 52/78 [14:45<06:53, 15.91s/epoch, loss=1.15, accuracy=0.753, val_loss=1.43, val_accuracy=0.652, lr=0.1] 68%|██████▊   | 53/78 [15:01<06:37, 15.91s/epoch, loss=1.16, accuracy=0.751, val_loss=1.64, val_accuracy=0.593, lr=0.0316] 69%|██████▉   | 54/78 [15:16<06:18, 15.79s/epoch, loss=1.15, accuracy=0.755, val_loss=1.56, val_accuracy=0.622, lr=0.1]    71%|███████   | 55/78 [15:32<06:02, 15.75s/epoch, loss=1.16, accuracy=0.754, val_loss=3.56, val_accuracy=0.263, lr=0.1] 72%|███████▏  | 56/78 [15:48<05:48, 15.84s/epoch, loss=1.16, accuracy=0.752, val_loss=2.13, val_accuracy=0.462, lr=0.1] 73%|███████▎  | 57/78 [16:04<05:33, 15.89s/epoch, loss=1.14, accuracy=0.753, val_loss=1.99, val_accuracy=0.557, lr=0.1] 74%|███████▍  | 58/78 [16:19<05:15, 15.79s/epoch, loss=1.15, accuracy=0.751, val_loss=4.69, val_accuracy=0.255, lr=0.0316] 76%|███████▌  | 59/78 [16:35<05:01, 15.87s/epoch, loss=1.16, accuracy=0.751, val_loss=1.71, val_accuracy=0.571, lr=0.1]    77%|███████▋  | 60/78 [16:51<04:44, 15.81s/epoch, loss=1.14, accuracy=0.752, val_loss=1.8, val_accuracy=0.56, lr=0.1]   78%|███████▊  | 61/78 [17:07<04:28, 15.77s/epoch, loss=1.15, accuracy=0.751, val_loss=1.72, val_accuracy=0.548, lr=0.1] 79%|███████▉  | 62/78 [17:23<04:14, 15.93s/epoch, loss=1.15, accuracy=0.752, val_loss=1.77, val_accuracy=0.532, lr=0.1] 81%|████████  | 63/78 [17:39<03:58, 15.88s/epoch, loss=1.15, accuracy=0.754, val_loss=2.19, val_accuracy=0.47, lr=0.0316] 82%|████████▏ | 64/78 [17:55<03:43, 15.93s/epoch, loss=1.15, accuracy=0.755, val_loss=1.61, val_accuracy=0.614, lr=0.1]   83%|████████▎ | 65/78 [18:11<03:26, 15.88s/epoch, loss=1.15, accuracy=0.754, val_loss=1.54, val_accuracy=0.634, lr=0.1] 85%|████████▍ | 66/78 [18:26<03:09, 15.77s/epoch, loss=1.15, accuracy=0.752, val_loss=2.14, val_accuracy=0.437, lr=0.1] 86%|████████▌ | 67/78 [18:42<02:52, 15.70s/epoch, loss=1.14, accuracy=0.755, val_loss=1.9, val_accuracy=0.497, lr=0.1]  87%|████████▋ | 68/78 [18:58<02:37, 15.71s/epoch, loss=1.15, accuracy=0.751, val_loss=2.32, val_accuracy=0.322, lr=0.0316] 88%|████████▊ | 69/78 [19:13<02:20, 15.64s/epoch, loss=1.15, accuracy=0.752, val_loss=1.78, val_accuracy=0.542, lr=0.1]    90%|████████▉ | 70/78 [19:29<02:06, 15.87s/epoch, loss=1.14, accuracy=0.753, val_loss=1.53, val_accuracy=0.621, lr=0.1] 91%|█████████ | 71/78 [19:45<01:50, 15.81s/epoch, loss=1.14, accuracy=0.754, val_loss=2.39, val_accuracy=0.464, lr=0.1] 92%|█████████▏| 72/78 [20:02<01:36, 16.09s/epoch, loss=1.14, accuracy=0.755, val_loss=2.31, val_accuracy=0.424, lr=0.1] 94%|█████████▎| 73/78 [20:18<01:20, 16.07s/epoch, loss=1.14, accuracy=0.756, val_loss=1.75, val_accuracy=0.603, lr=0.0316] 95%|█████████▍| 74/78 [20:34<01:04, 16.11s/epoch, loss=1.14, accuracy=0.755, val_loss=1.71, val_accuracy=0.601, lr=0.1]    96%|█████████▌| 75/78 [20:50<00:47, 15.94s/epoch, loss=1.14, accuracy=0.753, val_loss=1.9, val_accuracy=0.537, lr=0.1]  97%|█████████▋| 76/78 [21:06<00:31, 15.99s/epoch, loss=1.14, accuracy=0.755, val_loss=11.1, val_accuracy=0.141, lr=0.1] 99%|█████████▊| 77/78 [21:23<00:16, 16.27s/epoch, loss=1.14, accuracy=0.756, val_loss=3.42, val_accuracy=0.28, lr=0.1] 100%|██████████| 78/78 [21:38<00:00, 16.06s/epoch, loss=1.14, accuracy=0.755, val_loss=1.63, val_accuracy=0.578, lr=0.0316]100%|██████████| 78/78 [21:38<00:00, 16.65s/epoch, loss=1.14, accuracy=0.755, val_loss=1.63, val_accuracy=0.578, lr=0.0316]
Using real-time data augmentation.
Test score: 1.4768242835998535
Test accuracy: 0.6579999923706055


* * * Run SGD for ID = 19_18. * * *


2024-02-20 05:42:38.691332: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 05:42:41.186565: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 05:42:41.187558: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-20 05:42:41.223676: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-20 05:42:41.223704: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 05:42:41.226464: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 05:42:41.226501: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-20 05:42:41.228620: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-20 05:42:41.229254: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-20 05:42:41.231581: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-20 05:42:41.232930: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-20 05:42:41.237480: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 05:42:41.237943: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-20 05:42:41.238023: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 05:42:42.589523: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-20 05:42:42.590533: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 05:42:42.591282: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-20 05:42:42.591311: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 05:42:42.591349: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 05:42:42.591366: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-20 05:42:42.591381: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-20 05:42:42.591397: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-20 05:42:42.591412: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-20 05:42:42.591426: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-20 05:42:42.591440: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 05:42:42.591843: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-20 05:42:42.591872: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 05:42:43.173669: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-20 05:42:43.173719: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-20 05:42:43.173728: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-20 05:42:43.174594: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': '19_18', 'batch_size': 128, 'epochs': 78, 'validation_split': 0.1, 'checkpointing': True, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
x_train shape: (45000, 32, 32, 3)
45000 train samples
5000 validation samples
10000 test samples
y_train shape: (45000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/78 [00:00<?, ?epoch/s]2024-02-20 05:42:43.915919: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-20 05:42:43.928175: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600020000 Hz
2024-02-20 05:42:45.670348: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 05:42:45.907226: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 05:42:46.591142: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-20 05:42:46.626913: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|▏         | 1/78 [00:44<57:18, 44.66s/epoch, loss=3.3, accuracy=0.292, val_loss=3.22, val_accuracy=0.126, lr=0.1]  3%|▎         | 2/78 [01:02<36:14, 28.62s/epoch, loss=1.61, accuracy=0.512, val_loss=2.8, val_accuracy=0.299, lr=0.1]  4%|▍         | 3/78 [01:18<28:41, 22.96s/epoch, loss=1.35, accuracy=0.632, val_loss=2.19, val_accuracy=0.387, lr=0.1]  5%|▌         | 4/78 [01:34<25:02, 20.30s/epoch, loss=1.27, accuracy=0.68, val_loss=2.32, val_accuracy=0.415, lr=0.1]   6%|▋         | 5/78 [01:51<23:06, 19.00s/epoch, loss=1.24, accuracy=0.7, val_loss=1.56, val_accuracy=0.594, lr=0.1]   8%|▊         | 6/78 [02:07<21:34, 17.98s/epoch, loss=1.23, accuracy=0.712, val_loss=2.56, val_accuracy=0.336, lr=0.1]  9%|▉         | 7/78 [02:23<20:30, 17.33s/epoch, loss=1.23, accuracy=0.718, val_loss=2.73, val_accuracy=0.414, lr=0.1] 10%|█         | 8/78 [02:38<19:37, 16.83s/epoch, loss=1.21, accuracy=0.724, val_loss=2.43, val_accuracy=0.442, lr=0.1] 12%|█▏        | 9/78 [02:55<19:08, 16.65s/epoch, loss=1.21, accuracy=0.726, val_loss=2.32, val_accuracy=0.327, lr=0.1] 13%|█▎        | 10/78 [03:11<18:45, 16.55s/epoch, loss=1.21, accuracy=0.73, val_loss=1.63, val_accuracy=0.585, lr=0.0316] 14%|█▍        | 11/78 [03:27<18:27, 16.53s/epoch, loss=1.2, accuracy=0.731, val_loss=2.11, val_accuracy=0.453, lr=0.1]    15%|█▌        | 12/78 [03:44<18:05, 16.45s/epoch, loss=1.19, accuracy=0.735, val_loss=1.64, val_accuracy=0.578, lr=0.1] 17%|█▋        | 13/78 [04:00<17:44, 16.38s/epoch, loss=1.19, accuracy=0.738, val_loss=3.89, val_accuracy=0.348, lr=0.1] 18%|█▊        | 14/78 [04:16<17:28, 16.38s/epoch, loss=1.19, accuracy=0.736, val_loss=2.02, val_accuracy=0.451, lr=0.1] 19%|█▉        | 15/78 [04:32<17:06, 16.29s/epoch, loss=1.18, accuracy=0.739, val_loss=2.08, val_accuracy=0.492, lr=0.0316] 21%|██        | 16/78 [04:48<16:44, 16.20s/epoch, loss=1.18, accuracy=0.74, val_loss=1.65, val_accuracy=0.56, lr=0.1]      22%|██▏       | 17/78 [05:04<16:24, 16.13s/epoch, loss=1.18, accuracy=0.741, val_loss=2.02, val_accuracy=0.516, lr=0.1] 23%|██▎       | 18/78 [05:21<16:15, 16.26s/epoch, loss=1.18, accuracy=0.743, val_loss=1.61, val_accuracy=0.632, lr=0.1] 24%|██▍       | 19/78 [05:37<16:02, 16.32s/epoch, loss=1.17, accuracy=0.743, val_loss=1.77, val_accuracy=0.556, lr=0.1] 26%|██▌       | 20/78 [05:54<15:45, 16.30s/epoch, loss=1.17, accuracy=0.743, val_loss=1.89, val_accuracy=0.555, lr=0.0316] 27%|██▋       | 21/78 [06:10<15:28, 16.29s/epoch, loss=1.17, accuracy=0.748, val_loss=5.2, val_accuracy=0.281, lr=0.1]     28%|██▊       | 22/78 [06:26<15:13, 16.31s/epoch, loss=1.17, accuracy=0.746, val_loss=2.17, val_accuracy=0.451, lr=0.1] 29%|██▉       | 23/78 [06:42<14:50, 16.20s/epoch, loss=1.17, accuracy=0.746, val_loss=2.77, val_accuracy=0.309, lr=0.1] 31%|███       | 24/78 [06:58<14:32, 16.16s/epoch, loss=1.17, accuracy=0.745, val_loss=2.39, val_accuracy=0.452, lr=0.1] 32%|███▏      | 25/78 [07:15<14:17, 16.19s/epoch, loss=1.16, accuracy=0.749, val_loss=2.44, val_accuracy=0.472, lr=0.0316] 33%|███▎      | 26/78 [07:31<14:04, 16.23s/epoch, loss=1.17, accuracy=0.744, val_loss=1.7, val_accuracy=0.57, lr=0.1]      35%|███▍      | 27/78 [07:47<13:49, 16.27s/epoch, loss=1.16, accuracy=0.748, val_loss=1.62, val_accuracy=0.605, lr=0.1] 36%|███▌      | 28/78 [08:03<13:33, 16.26s/epoch, loss=1.16, accuracy=0.748, val_loss=3.08, val_accuracy=0.362, lr=0.1] 37%|███▋      | 29/78 [08:20<13:13, 16.20s/epoch, loss=1.16, accuracy=0.748, val_loss=2.08, val_accuracy=0.517, lr=0.1] 38%|███▊      | 30/78 [08:36<12:58, 16.22s/epoch, loss=1.15, accuracy=0.751, val_loss=1.61, val_accuracy=0.596, lr=0.0316] 40%|███▉      | 31/78 [08:52<12:42, 16.23s/epoch, loss=1.15, accuracy=0.753, val_loss=2.53, val_accuracy=0.383, lr=0.1]    41%|████      | 32/78 [09:08<12:27, 16.26s/epoch, loss=1.14, accuracy=0.752, val_loss=1.64, val_accuracy=0.574, lr=0.1] 42%|████▏     | 33/78 [09:25<12:10, 16.22s/epoch, loss=1.15, accuracy=0.75, val_loss=2.36, val_accuracy=0.427, lr=0.1]  44%|████▎     | 34/78 [09:41<11:54, 16.23s/epoch, loss=1.16, accuracy=0.75, val_loss=1.73, val_accuracy=0.554, lr=0.1] 45%|████▍     | 35/78 [09:57<11:38, 16.24s/epoch, loss=1.15, accuracy=0.751, val_loss=2.73, val_accuracy=0.4, lr=0.0316] 46%|████▌     | 36/78 [10:13<11:22, 16.24s/epoch, loss=1.15, accuracy=0.752, val_loss=3.89, val_accuracy=0.36, lr=0.1]   47%|████▋     | 37/78 [10:30<11:10, 16.36s/epoch, loss=1.14, accuracy=0.753, val_loss=2.29, val_accuracy=0.476, lr=0.1] 49%|████▊     | 38/78 [10:46<10:50, 16.26s/epoch, loss=1.14, accuracy=0.753, val_loss=2.58, val_accuracy=0.366, lr=0.1] 50%|█████     | 39/78 [11:02<10:32, 16.22s/epoch, loss=1.14, accuracy=0.754, val_loss=2.18, val_accuracy=0.485, lr=0.1] 51%|█████▏    | 40/78 [11:18<10:12, 16.13s/epoch, loss=1.14, accuracy=0.754, val_loss=2.11, val_accuracy=0.468, lr=0.0316] 53%|█████▎    | 41/78 [11:34<09:57, 16.14s/epoch, loss=1.14, accuracy=0.755, val_loss=3.71, val_accuracy=0.375, lr=0.1]    54%|█████▍    | 42/78 [11:50<09:42, 16.18s/epoch, loss=1.14, accuracy=0.753, val_loss=1.57, val_accuracy=0.605, lr=0.1] 55%|█████▌    | 43/78 [12:07<09:27, 16.21s/epoch, loss=1.14, accuracy=0.755, val_loss=1.9, val_accuracy=0.548, lr=0.1]  56%|█████▋    | 44/78 [12:23<09:09, 16.17s/epoch, loss=1.14, accuracy=0.756, val_loss=2.24, val_accuracy=0.453, lr=0.1] 58%|█████▊    | 45/78 [12:39<08:55, 16.22s/epoch, loss=1.13, accuracy=0.757, val_loss=2.31, val_accuracy=0.369, lr=0.0316] 59%|█████▉    | 46/78 [12:55<08:39, 16.23s/epoch, loss=1.14, accuracy=0.754, val_loss=1.67, val_accuracy=0.559, lr=0.1]    60%|██████    | 47/78 [13:12<08:21, 16.19s/epoch, loss=1.13, accuracy=0.757, val_loss=2.56, val_accuracy=0.398, lr=0.1] 62%|██████▏   | 48/78 [13:28<08:11, 16.37s/epoch, loss=1.13, accuracy=0.755, val_loss=2.34, val_accuracy=0.416, lr=0.1] 63%|██████▎   | 49/78 [13:45<07:56, 16.44s/epoch, loss=1.13, accuracy=0.753, val_loss=1.72, val_accuracy=0.576, lr=0.1] 64%|██████▍   | 50/78 [14:01<07:39, 16.40s/epoch, loss=1.13, accuracy=0.754, val_loss=2.45, val_accuracy=0.417, lr=0.0316] 65%|██████▌   | 51/78 [14:17<07:18, 16.26s/epoch, loss=1.13, accuracy=0.756, val_loss=2.93, val_accuracy=0.419, lr=0.1]    67%|██████▋   | 52/78 [14:33<07:00, 16.17s/epoch, loss=1.13, accuracy=0.754, val_loss=2.08, val_accuracy=0.506, lr=0.1] 68%|██████▊   | 53/78 [14:49<06:43, 16.16s/epoch, loss=1.13, accuracy=0.757, val_loss=1.92, val_accuracy=0.518, lr=0.1] 69%|██████▉   | 54/78 [15:05<06:27, 16.15s/epoch, loss=1.13, accuracy=0.756, val_loss=2.21, val_accuracy=0.469, lr=0.1] 71%|███████   | 55/78 [15:22<06:12, 16.21s/epoch, loss=1.13, accuracy=0.756, val_loss=2.41, val_accuracy=0.411, lr=0.0316] 72%|███████▏  | 56/78 [15:37<05:52, 16.03s/epoch, loss=1.12, accuracy=0.761, val_loss=1.6, val_accuracy=0.607, lr=0.1]     73%|███████▎  | 57/78 [15:53<05:35, 15.97s/epoch, loss=1.12, accuracy=0.759, val_loss=2.62, val_accuracy=0.317, lr=0.1] 74%|███████▍  | 58/78 [16:09<05:19, 15.99s/epoch, loss=1.13, accuracy=0.757, val_loss=1.66, val_accuracy=0.604, lr=0.1] 76%|███████▌  | 59/78 [16:25<05:02, 15.94s/epoch, loss=1.12, accuracy=0.76, val_loss=4.39, val_accuracy=0.258, lr=0.1]  77%|███████▋  | 60/78 [16:41<04:48, 16.04s/epoch, loss=1.12, accuracy=0.757, val_loss=5.98, val_accuracy=0.188, lr=0.0316] 78%|███████▊  | 61/78 [16:57<04:32, 16.03s/epoch, loss=1.13, accuracy=0.757, val_loss=1.77, val_accuracy=0.528, lr=0.1]    79%|███████▉  | 62/78 [17:13<04:16, 16.05s/epoch, loss=1.13, accuracy=0.757, val_loss=2.99, val_accuracy=0.307, lr=0.1] 81%|████████  | 63/78 [17:30<04:01, 16.11s/epoch, loss=1.13, accuracy=0.755, val_loss=2.55, val_accuracy=0.432, lr=0.1] 82%|████████▏ | 64/78 [17:46<03:45, 16.11s/epoch, loss=1.13, accuracy=0.757, val_loss=3.71, val_accuracy=0.261, lr=0.1] 83%|████████▎ | 65/78 [18:02<03:31, 16.24s/epoch, loss=1.12, accuracy=0.758, val_loss=2.11, val_accuracy=0.491, lr=0.0316] 85%|████████▍ | 66/78 [18:19<03:15, 16.28s/epoch, loss=1.12, accuracy=0.758, val_loss=2.43, val_accuracy=0.415, lr=0.1]    86%|████████▌ | 67/78 [18:35<02:58, 16.22s/epoch, loss=1.13, accuracy=0.755, val_loss=2.35, val_accuracy=0.438, lr=0.1] 87%|████████▋ | 68/78 [18:51<02:40, 16.09s/epoch, loss=1.12, accuracy=0.757, val_loss=2.48, val_accuracy=0.402, lr=0.1] 88%|████████▊ | 69/78 [19:06<02:24, 16.02s/epoch, loss=1.13, accuracy=0.756, val_loss=1.91, val_accuracy=0.51, lr=0.1]  90%|████████▉ | 70/78 [19:22<02:07, 15.98s/epoch, loss=1.12, accuracy=0.758, val_loss=3.09, val_accuracy=0.426, lr=0.0316] 91%|█████████ | 71/78 [19:39<01:52, 16.13s/epoch, loss=1.12, accuracy=0.756, val_loss=1.58, val_accuracy=0.602, lr=0.1]    92%|█████████▏| 72/78 [19:55<01:36, 16.06s/epoch, loss=1.12, accuracy=0.756, val_loss=1.96, val_accuracy=0.539, lr=0.1] 94%|█████████▎| 73/78 [20:11<01:20, 16.08s/epoch, loss=1.12, accuracy=0.758, val_loss=3.94, val_accuracy=0.252, lr=0.1] 95%|█████████▍| 74/78 [20:27<01:04, 16.02s/epoch, loss=1.11, accuracy=0.759, val_loss=2.6, val_accuracy=0.426, lr=0.1]  96%|█████████▌| 75/78 [20:43<00:48, 16.10s/epoch, loss=1.11, accuracy=0.76, val_loss=1.76, val_accuracy=0.585, lr=0.0316] 97%|█████████▋| 76/78 [20:59<00:31, 16.00s/epoch, loss=1.11, accuracy=0.762, val_loss=4.09, val_accuracy=0.299, lr=0.1]   99%|█████████▊| 77/78 [21:15<00:16, 16.02s/epoch, loss=1.11, accuracy=0.758, val_loss=1.79, val_accuracy=0.577, lr=0.1]100%|██████████| 78/78 [21:31<00:00, 16.04s/epoch, loss=1.12, accuracy=0.755, val_loss=2.32, val_accuracy=0.465, lr=0.1]100%|██████████| 78/78 [21:31<00:00, 16.56s/epoch, loss=1.12, accuracy=0.755, val_loss=2.32, val_accuracy=0.465, lr=0.1]
Using real-time data augmentation.
Test score: 1.618476152420044
Test accuracy: 0.6205999851226807


* * * Run SGD for ID = 19_19. * * *


2024-02-20 06:04:21.057600: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 06:04:23.592649: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 06:04:23.593657: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-20 06:04:23.628835: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-20 06:04:23.628871: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 06:04:23.631537: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 06:04:23.631574: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-20 06:04:23.633570: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-20 06:04:23.634674: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-20 06:04:23.636927: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-20 06:04:23.638406: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-20 06:04:23.642881: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 06:04:23.643424: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-20 06:04:23.643493: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 06:04:24.974545: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-20 06:04:24.975964: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-20 06:04:24.976697: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-20 06:04:24.976727: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 06:04:24.976761: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 06:04:24.976776: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-20 06:04:24.976792: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-20 06:04:24.976807: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-20 06:04:24.976822: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-20 06:04:24.976836: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-20 06:04:24.976851: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 06:04:24.977267: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-20 06:04:24.977301: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-20 06:04:25.558817: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-20 06:04:25.558868: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-20 06:04:25.558875: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-20 06:04:25.559733: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': '19_19', 'batch_size': 128, 'epochs': 78, 'validation_split': 0.1, 'checkpointing': True, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
x_train shape: (45000, 32, 32, 3)
45000 train samples
5000 validation samples
10000 test samples
y_train shape: (45000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/78 [00:00<?, ?epoch/s]2024-02-20 06:04:26.309538: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-20 06:04:26.322095: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600020000 Hz
2024-02-20 06:04:28.056118: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-20 06:04:28.263463: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-20 06:04:28.823926: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-20 06:04:28.857411: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|▏         | 1/78 [00:42<54:01, 42.09s/epoch, loss=3.41, accuracy=0.255, val_loss=2.36, val_accuracy=0.241, lr=0.1]  3%|▎         | 2/78 [00:59<35:02, 27.67s/epoch, loss=1.66, accuracy=0.487, val_loss=2.53, val_accuracy=0.277, lr=0.1]  4%|▍         | 3/78 [01:16<28:35, 22.87s/epoch, loss=1.37, accuracy=0.619, val_loss=1.99, val_accuracy=0.478, lr=0.1]  5%|▌         | 4/78 [01:33<25:03, 20.31s/epoch, loss=1.28, accuracy=0.672, val_loss=1.47, val_accuracy=0.613, lr=0.1]  6%|▋         | 5/78 [01:49<22:55, 18.84s/epoch, loss=1.25, accuracy=0.698, val_loss=1.8, val_accuracy=0.52, lr=0.1]    8%|▊         | 6/78 [02:05<21:30, 17.93s/epoch, loss=1.24, accuracy=0.711, val_loss=3.41, val_accuracy=0.309, lr=0.1]  9%|▉         | 7/78 [02:21<20:29, 17.31s/epoch, loss=1.22, accuracy=0.717, val_loss=1.61, val_accuracy=0.604, lr=0.1] 10%|█         | 8/78 [02:37<19:44, 16.93s/epoch, loss=1.21, accuracy=0.723, val_loss=1.75, val_accuracy=0.55, lr=0.1]  12%|█▏        | 9/78 [02:53<19:09, 16.66s/epoch, loss=1.2, accuracy=0.727, val_loss=2.01, val_accuracy=0.486, lr=0.0316] 13%|█▎        | 10/78 [03:09<18:35, 16.40s/epoch, loss=1.2, accuracy=0.732, val_loss=1.78, val_accuracy=0.562, lr=0.1]   14%|█▍        | 11/78 [03:25<18:13, 16.32s/epoch, loss=1.19, accuracy=0.734, val_loss=2.5, val_accuracy=0.442, lr=0.1] 15%|█▌        | 12/78 [03:41<17:44, 16.13s/epoch, loss=1.18, accuracy=0.736, val_loss=3.48, val_accuracy=0.279, lr=0.1] 17%|█▋        | 13/78 [03:57<17:19, 16.00s/epoch, loss=1.18, accuracy=0.737, val_loss=3.38, val_accuracy=0.304, lr=0.1] 18%|█▊        | 14/78 [04:12<16:59, 15.93s/epoch, loss=1.18, accuracy=0.737, val_loss=1.75, val_accuracy=0.571, lr=0.0316] 19%|█▉        | 15/78 [04:28<16:40, 15.88s/epoch, loss=1.17, accuracy=0.744, val_loss=1.76, val_accuracy=0.561, lr=0.1]    21%|██        | 16/78 [04:44<16:26, 15.91s/epoch, loss=1.17, accuracy=0.743, val_loss=2.29, val_accuracy=0.411, lr=0.1] 22%|██▏       | 17/78 [05:00<16:12, 15.94s/epoch, loss=1.17, accuracy=0.744, val_loss=2.12, val_accuracy=0.493, lr=0.1] 23%|██▎       | 18/78 [05:17<16:07, 16.13s/epoch, loss=1.17, accuracy=0.748, val_loss=1.87, val_accuracy=0.571, lr=0.1] 24%|██▍       | 19/78 [05:33<15:55, 16.20s/epoch, loss=1.17, accuracy=0.745, val_loss=2.29, val_accuracy=0.462, lr=0.0316] 26%|██▌       | 20/78 [05:49<15:35, 16.13s/epoch, loss=1.17, accuracy=0.743, val_loss=2.29, val_accuracy=0.487, lr=0.1]    27%|██▋       | 21/78 [06:05<15:13, 16.02s/epoch, loss=1.16, accuracy=0.746, val_loss=1.73, val_accuracy=0.579, lr=0.1] 28%|██▊       | 22/78 [06:22<15:08, 16.22s/epoch, loss=1.16, accuracy=0.747, val_loss=3.02, val_accuracy=0.382, lr=0.1] 29%|██▉       | 23/78 [06:37<14:44, 16.08s/epoch, loss=1.16, accuracy=0.749, val_loss=2.55, val_accuracy=0.407, lr=0.1] 31%|███       | 24/78 [06:53<14:25, 16.02s/epoch, loss=1.15, accuracy=0.751, val_loss=3.48, val_accuracy=0.281, lr=0.0316] 32%|███▏      | 25/78 [07:09<14:09, 16.03s/epoch, loss=1.16, accuracy=0.75, val_loss=1.78, val_accuracy=0.55, lr=0.1]      33%|███▎      | 26/78 [07:26<14:03, 16.22s/epoch, loss=1.16, accuracy=0.752, val_loss=2.75, val_accuracy=0.337, lr=0.1] 35%|███▍      | 27/78 [07:42<13:41, 16.11s/epoch, loss=1.16, accuracy=0.749, val_loss=1.68, val_accuracy=0.592, lr=0.1] 36%|███▌      | 28/78 [07:58<13:30, 16.21s/epoch, loss=1.16, accuracy=0.751, val_loss=1.45, val_accuracy=0.664, lr=0.1] 37%|███▋      | 29/78 [08:15<13:22, 16.37s/epoch, loss=1.15, accuracy=0.751, val_loss=1.79, val_accuracy=0.563, lr=0.1] 38%|███▊      | 30/78 [08:31<13:05, 16.36s/epoch, loss=1.15, accuracy=0.751, val_loss=2.1, val_accuracy=0.416, lr=0.1]  40%|███▉      | 31/78 [08:47<12:42, 16.22s/epoch, loss=1.15, accuracy=0.753, val_loss=1.47, val_accuracy=0.629, lr=0.1] 41%|████      | 32/78 [09:03<12:24, 16.18s/epoch, loss=1.15, accuracy=0.752, val_loss=3.29, val_accuracy=0.371, lr=0.1] 42%|████▏     | 33/78 [09:19<12:03, 16.08s/epoch, loss=1.15, accuracy=0.752, val_loss=2.33, val_accuracy=0.448, lr=0.0316] 44%|████▎     | 34/78 [09:36<11:57, 16.30s/epoch, loss=1.15, accuracy=0.752, val_loss=6.79, val_accuracy=0.13, lr=0.1]     45%|████▍     | 35/78 [09:52<11:37, 16.22s/epoch, loss=1.14, accuracy=0.753, val_loss=1.88, val_accuracy=0.509, lr=0.1] 46%|████▌     | 36/78 [10:08<11:22, 16.25s/epoch, loss=1.15, accuracy=0.752, val_loss=2.3, val_accuracy=0.416, lr=0.1]  47%|████▋     | 37/78 [10:24<11:05, 16.23s/epoch, loss=1.14, accuracy=0.754, val_loss=1.82, val_accuracy=0.534, lr=0.1] 49%|████▊     | 38/78 [10:41<10:48, 16.21s/epoch, loss=1.14, accuracy=0.755, val_loss=1.96, val_accuracy=0.499, lr=0.0316] 50%|█████     | 39/78 [10:57<10:30, 16.16s/epoch, loss=1.15, accuracy=0.753, val_loss=1.65, val_accuracy=0.586, lr=0.1]    51%|█████▏    | 40/78 [11:12<10:10, 16.06s/epoch, loss=1.14, accuracy=0.756, val_loss=2.12, val_accuracy=0.531, lr=0.1] 53%|█████▎    | 41/78 [11:29<09:57, 16.14s/epoch, loss=1.14, accuracy=0.753, val_loss=1.51, val_accuracy=0.637, lr=0.1] 54%|█████▍    | 42/78 [11:45<09:42, 16.18s/epoch, loss=1.13, accuracy=0.758, val_loss=2.1, val_accuracy=0.453, lr=0.1]  55%|█████▌    | 43/78 [12:01<09:26, 16.17s/epoch, loss=1.14, accuracy=0.753, val_loss=1.76, val_accuracy=0.567, lr=0.0316] 56%|█████▋    | 44/78 [12:17<09:10, 16.18s/epoch, loss=1.13, accuracy=0.754, val_loss=2.17, val_accuracy=0.411, lr=0.1]    58%|█████▊    | 45/78 [12:34<08:55, 16.23s/epoch, loss=1.13, accuracy=0.756, val_loss=5.68, val_accuracy=0.186, lr=0.1] 59%|█████▉    | 46/78 [12:50<08:34, 16.09s/epoch, loss=1.13, accuracy=0.755, val_loss=2.7, val_accuracy=0.363, lr=0.1]  60%|██████    | 47/78 [13:06<08:20, 16.16s/epoch, loss=1.12, accuracy=0.755, val_loss=2.27, val_accuracy=0.388, lr=0.1] 62%|██████▏   | 48/78 [13:22<08:00, 16.03s/epoch, loss=1.13, accuracy=0.755, val_loss=1.57, val_accuracy=0.622, lr=0.0316] 63%|██████▎   | 49/78 [13:38<07:45, 16.05s/epoch, loss=1.13, accuracy=0.756, val_loss=1.51, val_accuracy=0.639, lr=0.1]    64%|██████▍   | 50/78 [13:53<07:26, 15.96s/epoch, loss=1.13, accuracy=0.756, val_loss=2.52, val_accuracy=0.426, lr=0.1] 65%|██████▌   | 51/78 [14:09<07:10, 15.94s/epoch, loss=1.13, accuracy=0.756, val_loss=2.15, val_accuracy=0.422, lr=0.1] 67%|██████▋   | 52/78 [14:25<06:54, 15.93s/epoch, loss=1.13, accuracy=0.757, val_loss=1.47, val_accuracy=0.645, lr=0.1] 68%|██████▊   | 53/78 [14:42<06:44, 16.16s/epoch, loss=1.12, accuracy=0.758, val_loss=1.87, val_accuracy=0.556, lr=0.0316] 69%|██████▉   | 54/78 [14:59<06:35, 16.48s/epoch, loss=1.12, accuracy=0.759, val_loss=1.48, val_accuracy=0.644, lr=0.1]    71%|███████   | 55/78 [15:16<06:19, 16.48s/epoch, loss=1.13, accuracy=0.755, val_loss=2.13, val_accuracy=0.438, lr=0.1] 72%|███████▏  | 56/78 [15:32<06:04, 16.58s/epoch, loss=1.12, accuracy=0.759, val_loss=1.93, val_accuracy=0.541, lr=0.1] 73%|███████▎  | 57/78 [15:49<05:50, 16.68s/epoch, loss=1.13, accuracy=0.755, val_loss=1.93, val_accuracy=0.506, lr=0.1] 74%|███████▍  | 58/78 [16:05<05:29, 16.48s/epoch, loss=1.13, accuracy=0.754, val_loss=2.18, val_accuracy=0.451, lr=0.0316] 76%|███████▌  | 59/78 [16:22<05:13, 16.49s/epoch, loss=1.12, accuracy=0.757, val_loss=1.65, val_accuracy=0.563, lr=0.1]    77%|███████▋  | 60/78 [16:38<04:53, 16.28s/epoch, loss=1.13, accuracy=0.757, val_loss=1.77, val_accuracy=0.522, lr=0.1] 78%|███████▊  | 61/78 [16:54<04:37, 16.33s/epoch, loss=1.12, accuracy=0.759, val_loss=2.8, val_accuracy=0.38, lr=0.1]   79%|███████▉  | 62/78 [17:10<04:18, 16.14s/epoch, loss=1.12, accuracy=0.759, val_loss=2.13, val_accuracy=0.514, lr=0.1] 81%|████████  | 63/78 [17:26<04:03, 16.23s/epoch, loss=1.12, accuracy=0.76, val_loss=2.19, val_accuracy=0.402, lr=0.0316] 82%|████████▏ | 64/78 [17:43<03:47, 16.23s/epoch, loss=1.12, accuracy=0.757, val_loss=2.85, val_accuracy=0.364, lr=0.1]   83%|████████▎ | 65/78 [17:59<03:33, 16.39s/epoch, loss=1.12, accuracy=0.757, val_loss=1.92, val_accuracy=0.464, lr=0.1] 85%|████████▍ | 66/78 [18:16<03:17, 16.46s/epoch, loss=1.12, accuracy=0.761, val_loss=1.79, val_accuracy=0.55, lr=0.1]  86%|████████▌ | 67/78 [18:32<02:59, 16.35s/epoch, loss=1.12, accuracy=0.76, val_loss=1.71, val_accuracy=0.573, lr=0.1] 87%|████████▋ | 68/78 [18:48<02:41, 16.17s/epoch, loss=1.13, accuracy=0.755, val_loss=1.69, val_accuracy=0.566, lr=0.0316] 88%|████████▊ | 69/78 [19:04<02:24, 16.11s/epoch, loss=1.12, accuracy=0.758, val_loss=2, val_accuracy=0.502, lr=0.1]       90%|████████▉ | 70/78 [19:20<02:09, 16.17s/epoch, loss=1.12, accuracy=0.757, val_loss=2.68, val_accuracy=0.423, lr=0.1] 91%|█████████ | 71/78 [19:36<01:53, 16.26s/epoch, loss=1.12, accuracy=0.757, val_loss=2.37, val_accuracy=0.42, lr=0.1]  92%|█████████▏| 72/78 [19:53<01:37, 16.24s/epoch, loss=1.12, accuracy=0.756, val_loss=1.83, val_accuracy=0.548, lr=0.1] 94%|█████████▎| 73/78 [20:09<01:21, 16.36s/epoch, loss=1.12, accuracy=0.757, val_loss=2.53, val_accuracy=0.403, lr=0.0316] 95%|█████████▍| 74/78 [20:26<01:05, 16.33s/epoch, loss=1.12, accuracy=0.76, val_loss=2.07, val_accuracy=0.524, lr=0.1]     96%|█████████▌| 75/78 [20:42<00:49, 16.43s/epoch, loss=1.12, accuracy=0.758, val_loss=1.91, val_accuracy=0.501, lr=0.1] 97%|█████████▋| 76/78 [20:58<00:32, 16.25s/epoch, loss=1.12, accuracy=0.756, val_loss=2.36, val_accuracy=0.426, lr=0.1] 99%|█████████▊| 77/78 [21:14<00:16, 16.01s/epoch, loss=1.11, accuracy=0.759, val_loss=1.62, val_accuracy=0.587, lr=0.1]100%|██████████| 78/78 [21:29<00:00, 15.89s/epoch, loss=1.12, accuracy=0.756, val_loss=2.82, val_accuracy=0.419, lr=0.0316]100%|██████████| 78/78 [21:29<00:00, 16.53s/epoch, loss=1.12, accuracy=0.756, val_loss=2.82, val_accuracy=0.419, lr=0.0316]
Using real-time data augmentation.
Test score: 1.4359955787658691
Test accuracy: 0.6600000262260437
