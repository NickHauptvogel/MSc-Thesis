Mon Mar 18 15:22:47 2024       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 545.23.08              Driver Version: 545.23.08    CUDA Version: 12.3     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA TITAN Xp                Off | 00000000:02:00.0 Off |                  N/A |
| 23%   26C    P8               8W / 250W |      0MiB / 12288MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|  No running processes found                                                           |
+---------------------------------------------------------------------------------------+


* * * Run SGD for ID = 5. * * *


2024-03-18 15:22:52.135330: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-18 15:23:07.379853: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-18 15:23:07.380843: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-18 15:23:07.457332: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-18 15:23:07.457398: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-18 15:23:07.490947: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-18 15:23:07.490989: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-18 15:23:07.512159: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-18 15:23:07.570790: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-18 15:23:07.615874: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-18 15:23:07.649634: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-18 15:23:07.725279: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-18 15:23:07.726804: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-18 15:23:07.726909: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-18 15:23:56.369046: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-18 15:23:56.369721: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-18 15:23:56.418784: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s
2024-03-18 15:23:56.418823: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-18 15:23:56.418857: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-18 15:23:56.418875: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-18 15:23:56.418890: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-18 15:23:56.418906: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-18 15:23:56.418922: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-18 15:23:56.418938: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-18 15:23:56.418954: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-18 15:23:56.503952: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-18 15:23:56.504048: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-18 15:23:57.853649: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-18 15:23:57.853701: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-18 15:23:57.853710: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-18 15:23:57.854691: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11217 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:02:00.0, compute capability: 6.1)
{'id': '05', 'seed': 5, 'out_folder': 'results/retinopathy/resnet50/10_independent_smalllr_full_val', 'batch_size': 32, 'epochs': 90, 'validation_split': 0.1, 'checkpointing': False, 'checkpoint_every': -1, 'hold_out_validation_split': 0.0, 'model_type': 'ResNet50v1', 'data_augmentation': False, 'augm_shift': 4, 'initial_lr': 0.0023072, 'l2_reg': 0.00010674, 'optimizer': 'sgd', 'momentum': 0.9901533, 'nesterov': True, 'bootstrapping': False, 'use_case': 'retinopathy', 'lr_schedule': 'retinopathy', 'test_time_augmentation': False, 'store_models': False, 'debug': False, 'model': 'ResNet50v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN Xp'}
Found 35126 images belonging to 2 classes.
Found 10906 images belonging to 2 classes.
Found 10906 images belonging to 2 classes.
Found 42670 images belonging to 2 classes.
Found 42670 images belonging to 2 classes.
x_train samples: 35126
x_val samples: 10906
x_test samples: 42670
x_train shape: (32, 256, 256, 3)
y_train shape: (32,)
ResNet50v1
0epoch [00:00, ?epoch/s]  0%|          | 0/90 [00:00<?, ?epoch/s]2024-03-18 15:23:59.036668: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-18 15:23:59.037132: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199825000 Hz
WARNING:tensorflow:AutoGraph could not transform <function weighted_binary_cross_entropy.<locals>.weighted_cross_entropy_fn at 0x7f3420b6e040> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: module 'gast' has no attribute 'Index'
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
2024-03-18 15:24:04.857760: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-18 15:24:05.065637: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-18 15:24:06.255860: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-18 15:24:06.301497: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1772s vs `on_train_batch_end` time: 0.2784s). Check your callbacks.
  1%|          | 1/90 [13:18<19:44:56, 798.84s/epoch, loss=2.18, accuracy=0.546, auc=0.491, precision=0.184, recall=0.383, val_loss=2.17, val_accuracy=0.549, val_auc=0.488, val_precision=0.177, val_recall=0.381, lr=0]  2%|▏         | 2/90 [23:49<17:06:34, 699.94s/epoch, loss=1.33, accuracy=0.523, auc=0.535, precision=0.211, recall=0.524, val_loss=1.12, val_accuracy=0.66, val_auc=0.576, val_precision=0.236, val_recall=0.36, lr=0.00231]  3%|▎         | 3/90 [34:20<16:09:16, 668.47s/epoch, loss=1.1, accuracy=0.565, auc=0.581, precision=0.236, recall=0.545, val_loss=1.07, val_accuracy=0.497, val_auc=0.589, val_precision=0.22, val_recall=0.654, lr=0.00231]  4%|▍         | 4/90 [44:53<15:37:45, 654.24s/epoch, loss=1.02, accuracy=0.666, auc=0.674, precision=0.307, recall=0.562, val_loss=2.35, val_accuracy=0.2, val_auc=0.614, val_precision=0.19, val_recall=0.995, lr=0.00231]   6%|▌         | 5/90 [55:25<15:15:29, 646.23s/epoch, loss=0.916, accuracy=0.767, auc=0.766, precision=0.431, recall=0.596, val_loss=1.09, val_accuracy=0.818, val_auc=0.644, val_precision=0.899, val_recall=0.0389, lr=0.00231]  7%|▋         | 6/90 [1:05:59<14:59:15, 642.32s/epoch, loss=0.857, accuracy=0.791, auc=0.789, precision=0.472, recall=0.605, val_loss=4.3, val_accuracy=0.245, val_auc=0.564, val_precision=0.195, val_recall=0.96, lr=0.00231]   8%|▊         | 7/90 [1:16:34<14:45:03, 639.80s/epoch, loss=0.82, accuracy=0.794, auc=0.797, precision=0.48, recall=0.624, val_loss=0.804, val_accuracy=0.816, val_auc=0.792, val_precision=0.512, val_recall=0.581, lr=0.00231]  9%|▉         | 8/90 [1:27:06<14:30:52, 637.23s/epoch, loss=0.789, accuracy=0.792, auc=0.798, precision=0.476, recall=0.625, val_loss=0.949, val_accuracy=0.828, val_auc=0.665, val_precision=0.707, val_recall=0.151, lr=0.00231] 10%|█         | 9/90 [1:37:39<14:18:38, 636.03s/epoch, loss=0.758, accuracy=0.798, auc=0.808, precision=0.488, recall=0.639, val_loss=0.876, val_accuracy=0.827, val_auc=0.701, val_precision=0.581, val_recall=0.289, lr=0.00231] 11%|█         | 10/90 [1:48:12<14:06:57, 635.22s/epoch, loss=0.723, accuracy=0.799, auc=0.817, precision=0.49, recall=0.651, val_loss=0.733, val_accuracy=0.743, val_auc=0.81, val_precision=0.401, val_recall=0.738, lr=0.00231]  12%|█▏        | 11/90 [1:58:44<13:55:02, 634.21s/epoch, loss=0.697, accuracy=0.797, auc=0.823, precision=0.487, recall=0.666, val_loss=0.972, val_accuracy=0.813, val_auc=0.592, val_precision=0.534, val_recall=0.0613, lr=0.00231] 13%|█▎        | 12/90 [2:09:17<13:43:57, 633.82s/epoch, loss=0.676, accuracy=0.801, auc=0.827, precision=0.493, recall=0.67, val_loss=0.784, val_accuracy=0.835, val_auc=0.734, val_precision=0.602, val_recall=0.374, lr=0.00231]   14%|█▍        | 13/90 [2:19:53<13:34:00, 634.29s/epoch, loss=0.655, accuracy=0.799, auc=0.831, precision=0.491, recall=0.682, val_loss=1.44, val_accuracy=0.817, val_auc=0.686, val_precision=0.86, val_recall=0.036, lr=0.00231]  16%|█▌        | 14/90 [2:30:27<13:23:17, 634.18s/epoch, loss=0.637, accuracy=0.797, auc=0.835, precision=0.487, recall=0.685, val_loss=0.781, val_accuracy=0.776, val_auc=0.658, val_precision=0.392, val_recall=0.344, lr=0.00231] 17%|█▋        | 15/90 [2:40:59<13:12:00, 633.60s/epoch, loss=0.622, accuracy=0.805, auc=0.839, precision=0.501, recall=0.688, val_loss=0.717, val_accuracy=0.845, val_auc=0.792, val_precision=0.633, val_recall=0.427, lr=0.00231] 18%|█▊        | 16/90 [2:51:37<13:03:10, 635.01s/epoch, loss=0.608, accuracy=0.804, auc=0.841, precision=0.499, recall=0.698, val_loss=0.738, val_accuracy=0.792, val_auc=0.699, val_precision=0.445, val_recall=0.427, lr=0.00231] 19%|█▉        | 17/90 [3:02:11<12:52:06, 634.61s/epoch, loss=0.59, accuracy=0.807, auc=0.847, precision=0.504, recall=0.7, val_loss=0.676, val_accuracy=0.811, val_auc=0.788, val_precision=0.499, val_recall=0.582, lr=0.00231]    20%|██        | 18/90 [3:12:44<12:40:51, 634.05s/epoch, loss=0.576, accuracy=0.805, auc=0.852, precision=0.501, recall=0.716, val_loss=0.905, val_accuracy=0.844, val_auc=0.752, val_precision=0.677, val_recall=0.329, lr=0.00231] 21%|██        | 19/90 [3:23:18<12:30:34, 634.29s/epoch, loss=0.568, accuracy=0.806, auc=0.853, precision=0.504, recall=0.715, val_loss=0.635, val_accuracy=0.829, val_auc=0.797, val_precision=0.548, val_recall=0.537, lr=0.00231] 22%|██▏       | 20/90 [3:33:52<12:19:53, 634.20s/epoch, loss=0.556, accuracy=0.808, auc=0.857, precision=0.506, recall=0.716, val_loss=0.775, val_accuracy=0.58, val_auc=0.801, val_precision=0.29, val_recall=0.852, lr=0.00231]   23%|██▎       | 21/90 [3:44:26<12:09:05, 633.99s/epoch, loss=0.55, accuracy=0.808, auc=0.858, precision=0.506, recall=0.726, val_loss=0.903, val_accuracy=0.485, val_auc=0.703, val_precision=0.243, val_recall=0.821, lr=0.00231] 24%|██▍       | 22/90 [3:55:01<11:58:55, 634.35s/epoch, loss=0.543, accuracy=0.812, auc=0.86, precision=0.513, recall=0.72, val_loss=0.726, val_accuracy=0.838, val_auc=0.775, val_precision=0.595, val_recall=0.439, lr=0.00231]  26%|██▌       | 23/90 [4:05:35<11:48:06, 634.12s/epoch, loss=0.526, accuracy=0.815, auc=0.868, precision=0.519, recall=0.741, val_loss=0.647, val_accuracy=0.821, val_auc=0.798, val_precision=0.523, val_recall=0.57, lr=0.00231] 27%|██▋       | 24/90 [4:16:08<11:37:22, 633.97s/epoch, loss=0.524, accuracy=0.813, auc=0.868, precision=0.516, recall=0.737, val_loss=0.704, val_accuracy=0.647, val_auc=0.786, val_precision=0.321, val_recall=0.786, lr=0.00231] 28%|██▊       | 25/90 [4:26:42<11:26:52, 634.04s/epoch, loss=0.515, accuracy=0.819, auc=0.873, precision=0.526, recall=0.746, val_loss=1.08, val_accuracy=0.839, val_auc=0.752, val_precision=0.779, val_recall=0.2, lr=0.00231]    29%|██▉       | 26/90 [4:37:15<11:15:56, 633.70s/epoch, loss=0.509, accuracy=0.816, auc=0.875, precision=0.52, recall=0.742, val_loss=1.16, val_accuracy=0.825, val_auc=0.727, val_precision=0.856, val_recall=0.0837, lr=0.00231] 30%|███       | 27/90 [4:47:47<11:04:40, 633.02s/epoch, loss=0.499, accuracy=0.818, auc=0.88, precision=0.525, recall=0.753, val_loss=0.811, val_accuracy=0.848, val_auc=0.768, val_precision=0.708, val_recall=0.329, lr=0.00231] 31%|███       | 28/90 [4:58:32<10:57:57, 636.73s/epoch, loss=0.488, accuracy=0.827, auc=0.887, precision=0.541, recall=0.767, val_loss=0.609, val_accuracy=0.743, val_auc=0.8, val_precision=0.396, val_recall=0.699, lr=0.00231]  32%|███▏      | 29/90 [5:09:08<10:47:09, 636.55s/epoch, loss=0.482, accuracy=0.828, auc=0.891, precision=0.542, recall=0.771, val_loss=0.698, val_accuracy=0.576, val_auc=0.745, val_precision=0.275, val_recall=0.764, lr=0.00231] 33%|███▎      | 30/90 [5:19:41<10:35:30, 635.51s/epoch, loss=0.48, accuracy=0.828, auc=0.892, precision=0.542, recall=0.775, val_loss=0.891, val_accuracy=0.761, val_auc=0.704, val_precision=0.387, val_recall=0.455, lr=0.00231]  34%|███▍      | 31/90 [5:30:15<10:24:25, 635.01s/epoch, loss=0.425, accuracy=0.851, auc=0.922, precision=0.586, recall=0.818, val_loss=0.616, val_accuracy=0.793, val_auc=0.82, val_precision=0.467, val_recall=0.676, lr=0.000461] 36%|███▌      | 32/90 [5:40:49<10:13:32, 634.69s/epoch, loss=0.383, accuracy=0.871, auc=0.94, precision=0.625, recall=0.847, val_loss=0.869, val_accuracy=0.864, val_auc=0.816, val_precision=0.735, val_recall=0.44, lr=0.000461]  37%|███▋      | 33/90 [5:51:24<10:03:05, 634.83s/epoch, loss=0.361, accuracy=0.877, auc=0.948, precision=0.638, recall=0.864, val_loss=0.667, val_accuracy=0.826, val_auc=0.814, val_precision=0.535, val_recall=0.592, lr=0.000461] 38%|███▊      | 34/90 [6:01:58<9:52:13, 634.53s/epoch, loss=0.343, accuracy=0.885, auc=0.954, precision=0.654, recall=0.877, val_loss=0.876, val_accuracy=0.855, val_auc=0.802, val_precision=0.663, val_recall=0.469, lr=0.000461]  39%|███▉      | 35/90 [6:12:32<9:41:27, 634.32s/epoch, loss=0.321, accuracy=0.895, auc=0.961, precision=0.675, recall=0.89, val_loss=0.774, val_accuracy=0.835, val_auc=0.804, val_precision=0.564, val_recall=0.555, lr=0.000461]  40%|████      | 36/90 [6:23:06<9:30:45, 634.18s/epoch, loss=0.303, accuracy=0.902, auc=0.966, precision=0.692, recall=0.901, val_loss=0.775, val_accuracy=0.82, val_auc=0.824, val_precision=0.518, val_recall=0.633, lr=0.000461] 41%|████      | 37/90 [6:33:38<9:19:36, 633.53s/epoch, loss=0.282, accuracy=0.912, auc=0.972, precision=0.714, recall=0.914, val_loss=1.21, val_accuracy=0.841, val_auc=0.755, val_precision=0.646, val_recall=0.344, lr=0.000461] 42%|████▏     | 38/90 [6:44:11<9:08:52, 633.32s/epoch, loss=0.271, accuracy=0.916, auc=0.975, precision=0.725, recall=0.923, val_loss=0.966, val_accuracy=0.843, val_auc=0.803, val_precision=0.599, val_recall=0.506, lr=0.000461] 43%|████▎     | 39/90 [6:54:46<8:58:45, 633.83s/epoch, loss=0.256, accuracy=0.923, auc=0.979, precision=0.74, recall=0.933, val_loss=0.875, val_accuracy=0.814, val_auc=0.805, val_precision=0.505, val_recall=0.61, lr=0.000461]   44%|████▍     | 40/90 [7:05:26<8:49:43, 635.67s/epoch, loss=0.245, accuracy=0.926, auc=0.981, precision=0.751, recall=0.931, val_loss=0.919, val_accuracy=0.828, val_auc=0.802, val_precision=0.544, val_recall=0.557, lr=0.000461] 46%|████▌     | 41/90 [7:15:57<8:38:06, 634.41s/epoch, loss=0.235, accuracy=0.931, auc=0.983, precision=0.765, recall=0.938, val_loss=0.961, val_accuracy=0.832, val_auc=0.794, val_precision=0.556, val_recall=0.547, lr=0.000461] 47%|████▋     | 42/90 [7:26:31<8:27:30, 634.38s/epoch, loss=0.219, accuracy=0.94, auc=0.986, precision=0.79, recall=0.947, val_loss=0.956, val_accuracy=0.786, val_auc=0.808, val_precision=0.454, val_recall=0.669, lr=0.000461]   48%|████▊     | 43/90 [7:37:03<8:16:14, 633.50s/epoch, loss=0.214, accuracy=0.944, auc=0.987, precision=0.801, recall=0.948, val_loss=1.1, val_accuracy=0.636, val_auc=0.791, val_precision=0.317, val_recall=0.804, lr=0.000461] 49%|████▉     | 44/90 [7:47:38<8:05:56, 633.84s/epoch, loss=0.202, accuracy=0.948, auc=0.989, precision=0.81, recall=0.957, val_loss=0.972, val_accuracy=0.823, val_auc=0.813, val_precision=0.526, val_recall=0.61, lr=0.000461] 50%|█████     | 45/90 [7:58:11<7:55:16, 633.71s/epoch, loss=0.186, accuracy=0.955, auc=0.992, precision=0.833, recall=0.962, val_loss=1.01, val_accuracy=0.8, val_auc=0.802, val_precision=0.476, val_recall=0.632, lr=0.000461]  51%|█████     | 46/90 [8:08:45<7:44:51, 633.90s/epoch, loss=0.189, accuracy=0.955, auc=0.992, precision=0.835, recall=0.958, val_loss=1.2, val_accuracy=0.81, val_auc=0.778, val_precision=0.496, val_recall=0.531, lr=0.000461] 52%|█████▏    | 47/90 [8:19:18<7:33:57, 633.44s/epoch, loss=0.187, accuracy=0.955, auc=0.992, precision=0.834, recall=0.961, val_loss=1.09, val_accuracy=0.803, val_auc=0.808, val_precision=0.483, val_recall=0.627, lr=0.000461] 53%|█████▎    | 48/90 [8:29:52<7:23:33, 633.66s/epoch, loss=0.175, accuracy=0.962, auc=0.994, precision=0.857, recall=0.966, val_loss=2.13, val_accuracy=0.835, val_auc=0.714, val_precision=0.644, val_recall=0.28, lr=0.000461]  54%|█████▍    | 49/90 [8:40:25<7:12:56, 633.58s/epoch, loss=0.169, accuracy=0.965, auc=0.995, precision=0.87, recall=0.968, val_loss=1.53, val_accuracy=0.839, val_auc=0.779, val_precision=0.594, val_recall=0.468, lr=0.000461] 56%|█████▌    | 50/90 [8:50:58<7:02:13, 633.34s/epoch, loss=0.153, accuracy=0.971, auc=0.997, precision=0.888, recall=0.976, val_loss=1.11, val_accuracy=0.771, val_auc=0.774, val_precision=0.424, val_recall=0.602, lr=0.000461] 57%|█████▋    | 51/90 [9:01:34<6:52:10, 634.11s/epoch, loss=0.152, accuracy=0.973, auc=0.997, precision=0.895, recall=0.977, val_loss=1.92, val_accuracy=0.854, val_auc=0.767, val_precision=0.687, val_recall=0.414, lr=0.000461] 58%|█████▊    | 52/90 [9:12:08<6:41:40, 634.23s/epoch, loss=0.15, accuracy=0.973, auc=0.997, precision=0.898, recall=0.975, val_loss=1.27, val_accuracy=0.733, val_auc=0.798, val_precision=0.389, val_recall=0.729, lr=0.000461]  59%|█████▉    | 53/90 [9:22:43<6:31:12, 634.39s/epoch, loss=0.158, accuracy=0.971, auc=0.996, precision=0.889, recall=0.974, val_loss=1.2, val_accuracy=0.762, val_auc=0.783, val_precision=0.415, val_recall=0.643, lr=0.000461] 60%|██████    | 54/90 [9:33:18<6:20:40, 634.46s/epoch, loss=0.157, accuracy=0.973, auc=0.996, precision=0.895, recall=0.976, val_loss=1.3, val_accuracy=0.805, val_auc=0.789, val_precision=0.486, val_recall=0.602, lr=0.000461] 61%|██████    | 55/90 [9:43:52<6:10:03, 634.39s/epoch, loss=0.16, accuracy=0.97, auc=0.996, precision=0.885, recall=0.973, val_loss=1.21, val_accuracy=0.796, val_auc=0.798, val_precision=0.468, val_recall=0.62, lr=0.000461]   62%|██████▏   | 56/90 [9:54:26<5:59:20, 634.13s/epoch, loss=0.142, accuracy=0.979, auc=0.998, precision=0.918, recall=0.982, val_loss=1.57, val_accuracy=0.838, val_auc=0.783, val_precision=0.58, val_recall=0.513, lr=0.000461] 63%|██████▎   | 57/90 [10:04:59<5:48:42, 634.03s/epoch, loss=0.134, accuracy=0.983, auc=0.999, precision=0.932, recall=0.983, val_loss=1.44, val_accuracy=0.828, val_auc=0.798, val_precision=0.543, val_recall=0.565, lr=0.000461] 64%|██████▍   | 58/90 [10:15:33<5:38:09, 634.04s/epoch, loss=0.129, accuracy=0.985, auc=0.999, precision=0.939, recall=0.988, val_loss=2.64, val_accuracy=0.853, val_auc=0.729, val_precision=0.771, val_recall=0.317, lr=0.000461] 66%|██████▌   | 59/90 [10:26:07<5:27:33, 633.99s/epoch, loss=0.136, accuracy=0.982, auc=0.998, precision=0.928, recall=0.984, val_loss=1.29, val_accuracy=0.773, val_auc=0.796, val_precision=0.433, val_recall=0.668, lr=0.000461] 67%|██████▋   | 60/90 [10:36:41<5:16:58, 633.95s/epoch, loss=0.135, accuracy=0.982, auc=0.998, precision=0.929, recall=0.984, val_loss=1.56, val_accuracy=0.839, val_auc=0.794, val_precision=0.577, val_recall=0.557, lr=0.000461] 68%|██████▊   | 61/90 [10:47:27<5:08:08, 637.52s/epoch, loss=0.118, accuracy=0.99, auc=0.999, precision=0.958, recall=0.991, val_loss=1.56, val_accuracy=0.836, val_auc=0.793, val_precision=0.568, val_recall=0.554, lr=9.23e-5]   69%|██████▉   | 62/90 [10:58:09<4:58:04, 638.74s/epoch, loss=0.0937, accuracy=0.999, auc=1, precision=0.996, recall=1, val_loss=1.67, val_accuracy=0.847, val_auc=0.791, val_precision=0.606, val_recall=0.54, lr=9.23e-5]        70%|███████   | 63/90 [11:08:42<4:46:39, 637.00s/epoch, loss=0.0907, accuracy=1, auc=1, precision=0.999, recall=1, val_loss=1.79, val_accuracy=0.852, val_auc=0.784, val_precision=0.628, val_recall=0.522, lr=9.23e-5]    71%|███████   | 64/90 [11:19:15<4:35:33, 635.90s/epoch, loss=0.0895, accuracy=1, auc=1, precision=0.998, recall=1, val_loss=1.76, val_accuracy=0.847, val_auc=0.786, val_precision=0.606, val_recall=0.535, lr=9.23e-5] 72%|███████▏  | 65/90 [11:29:50<4:24:49, 635.59s/epoch, loss=0.0885, accuracy=1, auc=1, precision=0.999, recall=1, val_loss=1.78, val_accuracy=0.844, val_auc=0.785, val_precision=0.599, val_recall=0.528, lr=9.23e-5] 73%|███████▎  | 66/90 [11:40:23<4:13:57, 634.88s/epoch, loss=0.0873, accuracy=1, auc=1, precision=0.999, recall=1, val_loss=1.84, val_accuracy=0.847, val_auc=0.782, val_precision=0.611, val_recall=0.519, lr=9.23e-5] 74%|███████▍  | 67/90 [11:50:56<4:03:11, 634.43s/epoch, loss=0.0865, accuracy=1, auc=1, precision=1, recall=1, val_loss=1.88, val_accuracy=0.849, val_auc=0.782, val_precision=0.62, val_recall=0.512, lr=9.23e-5]      76%|███████▌  | 68/90 [12:01:30<3:52:35, 634.35s/epoch, loss=0.086, accuracy=1, auc=1, precision=1, recall=1, val_loss=1.98, val_accuracy=0.853, val_auc=0.779, val_precision=0.642, val_recall=0.496, lr=9.23e-5] 77%|███████▋  | 69/90 [12:12:06<3:42:06, 634.57s/epoch, loss=0.0857, accuracy=1, auc=1, precision=1, recall=1, val_loss=1.88, val_accuracy=0.848, val_auc=0.783, val_precision=0.615, val_recall=0.521, lr=9.23e-5] 78%|███████▊  | 70/90 [12:22:37<3:31:14, 633.71s/epoch, loss=0.0849, accuracy=1, auc=1, precision=1, recall=1, val_loss=1.85, val_accuracy=0.846, val_auc=0.787, val_precision=0.605, val_recall=0.533, lr=9.23e-5] 79%|███████▉  | 71/90 [12:33:11<3:20:41, 633.77s/epoch, loss=0.0843, accuracy=1, auc=1, precision=1, recall=1, val_loss=1.93, val_accuracy=0.85, val_auc=0.783, val_precision=0.624, val_recall=0.518, lr=9.23e-5]  80%|████████  | 72/90 [12:44:03<3:11:44, 639.13s/epoch, loss=0.0839, accuracy=1, auc=1, precision=1, recall=1, val_loss=1.93, val_accuracy=0.85, val_auc=0.785, val_precision=0.622, val_recall=0.52, lr=9.23e-5]  81%|████████  | 73/90 [12:54:37<3:00:39, 637.63s/epoch, loss=0.0837, accuracy=1, auc=1, precision=0.999, recall=1, val_loss=1.95, val_accuracy=0.848, val_auc=0.782, val_precision=0.615, val_recall=0.51, lr=9.23e-5] 82%|████████▏ | 74/90 [13:05:12<2:49:49, 636.82s/epoch, loss=0.083, accuracy=1, auc=1, precision=1, recall=1, val_loss=1.93, val_accuracy=0.849, val_auc=0.785, val_precision=0.616, val_recall=0.525, lr=9.23e-5]     83%|████████▎ | 75/90 [13:15:45<2:38:56, 635.77s/epoch, loss=0.0826, accuracy=1, auc=1, precision=1, recall=1, val_loss=2.04, val_accuracy=0.852, val_auc=0.777, val_precision=0.636, val_recall=0.5, lr=9.23e-5]  84%|████████▍ | 76/90 [13:26:18<2:28:08, 634.88s/epoch, loss=0.0822, accuracy=1, auc=1, precision=1, recall=1, val_loss=1.9, val_accuracy=0.846, val_auc=0.787, val_precision=0.602, val_recall=0.536, lr=9.23e-5] 86%|████████▌ | 77/90 [13:36:50<2:17:24, 634.17s/epoch, loss=0.0817, accuracy=1, auc=1, precision=1, recall=1, val_loss=2.01, val_accuracy=0.85, val_auc=0.781, val_precision=0.624, val_recall=0.51, lr=9.23e-5]  87%|████████▋ | 78/90 [13:47:25<2:06:49, 634.14s/epoch, loss=0.0815, accuracy=1, auc=1, precision=1, recall=1, val_loss=2, val_accuracy=0.849, val_auc=0.783, val_precision=0.619, val_recall=0.517, lr=9.23e-5]  88%|████████▊ | 79/90 [13:57:58<1:56:12, 633.90s/epoch, loss=0.0811, accuracy=1, auc=1, precision=1, recall=1, val_loss=2.01, val_accuracy=0.85, val_auc=0.78, val_precision=0.623, val_recall=0.51, lr=9.23e-5] 89%|████████▉ | 80/90 [14:08:31<1:45:37, 633.78s/epoch, loss=0.0805, accuracy=1, auc=1, precision=1, recall=1, val_loss=1.98, val_accuracy=0.849, val_auc=0.784, val_precision=0.616, val_recall=0.524, lr=9.23e-5] 90%|█████████ | 81/90 [14:19:07<1:35:09, 634.43s/epoch, loss=0.0801, accuracy=1, auc=1, precision=1, recall=1, val_loss=2.02, val_accuracy=0.849, val_auc=0.782, val_precision=0.62, val_recall=0.515, lr=9.23e-5]  91%|█████████ | 82/90 [14:29:53<1:25:01, 637.70s/epoch, loss=0.0797, accuracy=1, auc=1, precision=1, recall=1, val_loss=2.07, val_accuracy=0.85, val_auc=0.779, val_precision=0.627, val_recall=0.505, lr=9.23e-5] 92%|█████████▏| 83/90 [14:40:26<1:14:15, 636.48s/epoch, loss=0.0794, accuracy=1, auc=1, precision=1, recall=1, val_loss=2.15, val_accuracy=0.851, val_auc=0.771, val_precision=0.64, val_recall=0.484, lr=9.23e-5] 93%|█████████▎| 84/90 [14:51:04<1:03:40, 636.78s/epoch, loss=0.0789, accuracy=1, auc=1, precision=1, recall=1, val_loss=2.07, val_accuracy=0.85, val_auc=0.78, val_precision=0.624, val_recall=0.51, lr=9.23e-5]   94%|█████████▍| 85/90 [15:01:37<52:59, 635.84s/epoch, loss=0.0786, accuracy=1, auc=1, precision=1, recall=1, val_loss=2.03, val_accuracy=0.848, val_auc=0.781, val_precision=0.615, val_recall=0.518, lr=9.23e-5] 96%|█████████▌| 86/90 [15:12:11<42:21, 635.25s/epoch, loss=0.0783, accuracy=1, auc=1, precision=1, recall=1, val_loss=2.1, val_accuracy=0.851, val_auc=0.776, val_precision=0.63, val_recall=0.504, lr=9.23e-5]   97%|█████████▋| 87/90 [15:22:45<31:44, 634.77s/epoch, loss=0.0778, accuracy=1, auc=1, precision=1, recall=1, val_loss=2.11, val_accuracy=0.85, val_auc=0.776, val_precision=0.628, val_recall=0.5, lr=9.23e-5]  98%|█████████▊| 88/90 [15:33:19<21:09, 634.68s/epoch, loss=0.0775, accuracy=1, auc=1, precision=1, recall=1, val_loss=2.13, val_accuracy=0.852, val_auc=0.775, val_precision=0.637, val_recall=0.501, lr=9.23e-5] 99%|█████████▉| 89/90 [15:43:53<10:34, 634.48s/epoch, loss=0.0772, accuracy=1, auc=1, precision=1, recall=1, val_loss=2.09, val_accuracy=0.849, val_auc=0.779, val_precision=0.621, val_recall=0.513, lr=9.23e-5]100%|██████████| 90/90 [15:54:29<00:00, 634.77s/epoch, loss=0.0768, accuracy=1, auc=1, precision=1, recall=1, val_loss=2.09, val_accuracy=0.849, val_auc=0.778, val_precision=0.622, val_recall=0.511, lr=9.23e-5]100%|██████████| 90/90 [15:54:29<00:00, 636.33s/epoch, loss=0.0768, accuracy=1, auc=1, precision=1, recall=1, val_loss=2.09, val_accuracy=0.849, val_auc=0.778, val_precision=0.622, val_recall=0.511, lr=9.23e-5]
Traceback (most recent call last):
  File "/home/gkb738/.conda/envs/TF_KERAS_GPU/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/gkb738/.conda/envs/TF_KERAS_GPU/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/gkb738/MSc-Thesis/ResNet20_CIFAR/sgd_baseline.py", line 378, in <module>
    score, acc = model.evaluate(test_loader, verbose=0)
ValueError: too many values to unpack (expected 2)
Only one model saved

Loading model: 05_retinopathy_ResNet50v1.h5
