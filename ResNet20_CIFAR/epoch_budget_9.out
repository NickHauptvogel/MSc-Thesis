Thu Feb 15 11:10:31 2024       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA TITAN X (Pascal)        Off | 00000000:83:00.0 Off |                  N/A |
| 23%   32C    P8               9W / 250W |      0MiB / 12288MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|  No running processes found                                                           |
+---------------------------------------------------------------------------------------+


* * * Run SGD for cluster size = 9. * * *


Budget: 166


* * * Run SGD for ID = 9_1. * * *


2024-02-15 11:10:32.074807: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 11:10:35.780189: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 11:10:35.781245: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-15 11:10:35.811226: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-15 11:10:35.811274: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 11:10:35.814123: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 11:10:35.814161: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 11:10:35.816316: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 11:10:35.817085: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 11:10:35.819330: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 11:10:35.820805: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 11:10:35.825496: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 11:10:35.826077: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 11:10:35.826151: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 11:10:36.997954: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-15 11:10:36.999303: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 11:10:36.999888: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-15 11:10:36.999919: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 11:10:36.999967: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 11:10:36.999988: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 11:10:37.000007: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 11:10:37.000026: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 11:10:37.000045: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 11:10:37.000065: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 11:10:37.000084: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 11:10:37.000528: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 11:10:37.000561: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 11:10:37.620909: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-15 11:10:37.620967: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-15 11:10:37.620976: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-15 11:10:37.621849: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': 91, 'batch_size': 128, 'epochs': 166, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/166 [00:00<?, ?epoch/s]2024-02-15 11:10:38.372633: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-15 11:10:38.384401: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2599900000 Hz
2024-02-15 11:10:40.160012: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 11:10:40.368880: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 11:10:41.070893: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-15 11:10:41.112041: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/166 [00:51<2:22:14, 51.73s/epoch, loss=3.3, accuracy=0.313, val_loss=2.36, val_accuracy=0.24, lr=0.1]  1%|          | 2/166 [01:12<1:31:19, 33.41s/epoch, loss=1.58, accuracy=0.527, val_loss=2.02, val_accuracy=0.44, lr=0.1]  2%|▏         | 3/166 [01:34<1:17:17, 28.45s/epoch, loss=1.35, accuracy=0.647, val_loss=1.81, val_accuracy=0.504, lr=0.1]  2%|▏         | 4/166 [01:57<1:10:27, 26.09s/epoch, loss=1.29, accuracy=0.683, val_loss=3.2, val_accuracy=0.369, lr=0.1]   3%|▎         | 5/166 [02:19<1:06:02, 24.61s/epoch, loss=1.26, accuracy=0.699, val_loss=2.23, val_accuracy=0.446, lr=0.1]  4%|▎         | 6/166 [02:41<1:03:32, 23.83s/epoch, loss=1.24, accuracy=0.712, val_loss=2.06, val_accuracy=0.487, lr=0.1]  4%|▍         | 7/166 [03:03<1:01:40, 23.27s/epoch, loss=1.23, accuracy=0.718, val_loss=1.58, val_accuracy=0.614, lr=0.1]  5%|▍         | 8/166 [03:24<59:21, 22.54s/epoch, loss=1.22, accuracy=0.724, val_loss=1.68, val_accuracy=0.599, lr=0.1]    5%|▌         | 9/166 [03:45<57:39, 22.04s/epoch, loss=1.22, accuracy=0.729, val_loss=1.53, val_accuracy=0.623, lr=0.1]  6%|▌         | 10/166 [04:06<55:56, 21.51s/epoch, loss=1.21, accuracy=0.73, val_loss=1.84, val_accuracy=0.555, lr=0.1]  7%|▋         | 11/166 [04:27<55:45, 21.58s/epoch, loss=1.2, accuracy=0.732, val_loss=2.09, val_accuracy=0.487, lr=0.1]  7%|▋         | 12/166 [04:49<55:12, 21.51s/epoch, loss=1.2, accuracy=0.732, val_loss=1.63, val_accuracy=0.61, lr=0.1]   8%|▊         | 13/166 [05:10<54:58, 21.56s/epoch, loss=1.21, accuracy=0.734, val_loss=1.7, val_accuracy=0.59, lr=0.1]  8%|▊         | 14/166 [05:32<54:24, 21.48s/epoch, loss=1.2, accuracy=0.739, val_loss=2.15, val_accuracy=0.452, lr=0.0316]  9%|▉         | 15/166 [05:52<53:21, 21.20s/epoch, loss=1.2, accuracy=0.737, val_loss=2.02, val_accuracy=0.519, lr=0.1]    10%|▉         | 16/166 [06:12<52:04, 20.83s/epoch, loss=1.2, accuracy=0.738, val_loss=1.87, val_accuracy=0.577, lr=0.1] 10%|█         | 17/166 [06:33<52:00, 20.94s/epoch, loss=1.19, accuracy=0.74, val_loss=1.68, val_accuracy=0.597, lr=0.1] 11%|█         | 18/166 [06:55<52:17, 21.20s/epoch, loss=1.19, accuracy=0.74, val_loss=2.28, val_accuracy=0.463, lr=0.1] 11%|█▏        | 19/166 [07:16<51:36, 21.06s/epoch, loss=1.18, accuracy=0.743, val_loss=1.79, val_accuracy=0.535, lr=0.0316] 12%|█▏        | 20/166 [07:38<51:44, 21.27s/epoch, loss=1.18, accuracy=0.745, val_loss=2.14, val_accuracy=0.499, lr=0.1]    13%|█▎        | 21/166 [07:59<51:39, 21.38s/epoch, loss=1.19, accuracy=0.742, val_loss=4.1, val_accuracy=0.348, lr=0.1]  13%|█▎        | 22/166 [08:21<51:20, 21.39s/epoch, loss=1.18, accuracy=0.745, val_loss=2.48, val_accuracy=0.377, lr=0.1] 14%|█▍        | 23/166 [08:42<50:49, 21.32s/epoch, loss=1.18, accuracy=0.745, val_loss=1.9, val_accuracy=0.559, lr=0.1]  14%|█▍        | 24/166 [09:03<50:09, 21.19s/epoch, loss=1.18, accuracy=0.745, val_loss=2.58, val_accuracy=0.449, lr=0.0316] 15%|█▌        | 25/166 [09:23<49:16, 20.97s/epoch, loss=1.18, accuracy=0.748, val_loss=1.88, val_accuracy=0.514, lr=0.1]    16%|█▌        | 26/166 [09:43<48:17, 20.70s/epoch, loss=1.17, accuracy=0.747, val_loss=1.97, val_accuracy=0.547, lr=0.1] 16%|█▋        | 27/166 [10:05<48:39, 21.00s/epoch, loss=1.16, accuracy=0.751, val_loss=1.66, val_accuracy=0.585, lr=0.1] 17%|█▋        | 28/166 [10:27<49:02, 21.32s/epoch, loss=1.17, accuracy=0.745, val_loss=4.16, val_accuracy=0.328, lr=0.1] 17%|█▋        | 29/166 [10:49<49:07, 21.51s/epoch, loss=1.16, accuracy=0.751, val_loss=2.83, val_accuracy=0.44, lr=0.0316] 18%|█▊        | 30/166 [11:10<48:44, 21.50s/epoch, loss=1.16, accuracy=0.751, val_loss=2.41, val_accuracy=0.426, lr=0.1]   19%|█▊        | 31/166 [11:31<47:54, 21.29s/epoch, loss=1.17, accuracy=0.747, val_loss=2.36, val_accuracy=0.518, lr=0.1] 19%|█▉        | 32/166 [11:51<46:30, 20.82s/epoch, loss=1.16, accuracy=0.749, val_loss=3.96, val_accuracy=0.369, lr=0.1] 20%|█▉        | 33/166 [12:13<46:56, 21.18s/epoch, loss=1.16, accuracy=0.747, val_loss=1.8, val_accuracy=0.558, lr=0.1]  20%|██        | 34/166 [12:35<46:50, 21.29s/epoch, loss=1.15, accuracy=0.751, val_loss=1.62, val_accuracy=0.603, lr=0.0316] 21%|██        | 35/166 [12:55<46:13, 21.17s/epoch, loss=1.16, accuracy=0.749, val_loss=1.66, val_accuracy=0.584, lr=0.1]    22%|██▏       | 36/166 [13:17<46:11, 21.32s/epoch, loss=1.15, accuracy=0.753, val_loss=2, val_accuracy=0.488, lr=0.1]    22%|██▏       | 37/166 [13:39<46:07, 21.46s/epoch, loss=1.16, accuracy=0.749, val_loss=2.19, val_accuracy=0.469, lr=0.1] 23%|██▎       | 38/166 [14:00<45:48, 21.47s/epoch, loss=1.15, accuracy=0.751, val_loss=1.86, val_accuracy=0.528, lr=0.1] 23%|██▎       | 39/166 [14:22<45:37, 21.55s/epoch, loss=1.15, accuracy=0.752, val_loss=1.74, val_accuracy=0.543, lr=0.0316] 24%|██▍       | 40/166 [14:42<44:06, 21.01s/epoch, loss=1.15, accuracy=0.75, val_loss=2.84, val_accuracy=0.391, lr=0.1]     25%|██▍       | 41/166 [15:02<43:29, 20.88s/epoch, loss=1.15, accuracy=0.752, val_loss=2.27, val_accuracy=0.457, lr=0.1] 25%|██▌       | 42/166 [15:23<43:16, 20.94s/epoch, loss=1.15, accuracy=0.751, val_loss=2.2, val_accuracy=0.485, lr=0.1]  26%|██▌       | 43/166 [15:45<43:28, 21.21s/epoch, loss=1.15, accuracy=0.752, val_loss=1.73, val_accuracy=0.58, lr=0.1] 27%|██▋       | 44/166 [16:07<43:17, 21.29s/epoch, loss=1.14, accuracy=0.755, val_loss=3, val_accuracy=0.361, lr=0.0316] 27%|██▋       | 45/166 [16:28<42:52, 21.26s/epoch, loss=1.15, accuracy=0.752, val_loss=1.35, val_accuracy=0.683, lr=0.1] 28%|██▊       | 46/166 [16:50<42:53, 21.44s/epoch, loss=1.15, accuracy=0.754, val_loss=2.8, val_accuracy=0.397, lr=0.1]  28%|██▊       | 47/166 [17:11<42:25, 21.39s/epoch, loss=1.15, accuracy=0.753, val_loss=1.7, val_accuracy=0.557, lr=0.1] 29%|██▉       | 48/166 [17:31<41:03, 20.88s/epoch, loss=1.15, accuracy=0.752, val_loss=2.29, val_accuracy=0.513, lr=0.1] 30%|██▉       | 49/166 [17:53<41:11, 21.13s/epoch, loss=1.15, accuracy=0.751, val_loss=2, val_accuracy=0.452, lr=0.1]    30%|███       | 50/166 [18:14<41:02, 21.23s/epoch, loss=1.14, accuracy=0.755, val_loss=1.72, val_accuracy=0.554, lr=0.0316] 31%|███       | 51/166 [18:36<40:59, 21.38s/epoch, loss=1.14, accuracy=0.754, val_loss=2.64, val_accuracy=0.406, lr=0.1]    31%|███▏      | 52/166 [18:58<40:52, 21.52s/epoch, loss=1.14, accuracy=0.751, val_loss=3.28, val_accuracy=0.268, lr=0.1] 32%|███▏      | 53/166 [19:19<40:31, 21.52s/epoch, loss=1.14, accuracy=0.753, val_loss=1.73, val_accuracy=0.579, lr=0.1] 33%|███▎      | 54/166 [19:40<39:42, 21.27s/epoch, loss=1.14, accuracy=0.755, val_loss=2.89, val_accuracy=0.391, lr=0.1] 33%|███▎      | 55/166 [20:00<38:54, 21.03s/epoch, loss=1.14, accuracy=0.753, val_loss=2.37, val_accuracy=0.459, lr=0.0316] 34%|███▎      | 56/166 [20:21<38:32, 21.02s/epoch, loss=1.14, accuracy=0.756, val_loss=2.52, val_accuracy=0.405, lr=0.1]    34%|███▍      | 57/166 [20:42<38:13, 21.05s/epoch, loss=1.14, accuracy=0.755, val_loss=1.97, val_accuracy=0.525, lr=0.1] 35%|███▍      | 58/166 [21:03<37:42, 20.95s/epoch, loss=1.14, accuracy=0.754, val_loss=1.59, val_accuracy=0.597, lr=0.1] 36%|███▌      | 59/166 [21:24<37:10, 20.85s/epoch, loss=1.13, accuracy=0.755, val_loss=2.11, val_accuracy=0.41, lr=0.1]  36%|███▌      | 60/166 [21:45<37:03, 20.98s/epoch, loss=1.13, accuracy=0.756, val_loss=1.65, val_accuracy=0.582, lr=0.0316] 37%|███▋      | 61/166 [22:06<36:52, 21.07s/epoch, loss=1.13, accuracy=0.755, val_loss=2.16, val_accuracy=0.41, lr=0.1]     37%|███▋      | 62/166 [22:27<36:27, 21.03s/epoch, loss=1.13, accuracy=0.754, val_loss=2.83, val_accuracy=0.423, lr=0.1] 38%|███▊      | 63/166 [22:48<35:58, 20.95s/epoch, loss=1.14, accuracy=0.754, val_loss=6.6, val_accuracy=0.196, lr=0.1]  39%|███▊      | 64/166 [23:08<35:23, 20.82s/epoch, loss=1.14, accuracy=0.755, val_loss=4.9, val_accuracy=0.221, lr=0.1] 39%|███▉      | 65/166 [23:30<35:09, 20.88s/epoch, loss=1.13, accuracy=0.755, val_loss=1.88, val_accuracy=0.499, lr=0.0316] 40%|███▉      | 66/166 [23:51<35:01, 21.01s/epoch, loss=1.13, accuracy=0.756, val_loss=1.37, val_accuracy=0.678, lr=0.1]    40%|████      | 67/166 [24:11<34:27, 20.88s/epoch, loss=1.13, accuracy=0.754, val_loss=1.9, val_accuracy=0.498, lr=0.1]  41%|████      | 68/166 [24:33<34:14, 20.96s/epoch, loss=1.13, accuracy=0.756, val_loss=2.5, val_accuracy=0.413, lr=0.1] 42%|████▏     | 69/166 [24:52<33:12, 20.54s/epoch, loss=1.13, accuracy=0.756, val_loss=1.73, val_accuracy=0.542, lr=0.1] 42%|████▏     | 70/166 [25:13<33:15, 20.79s/epoch, loss=1.13, accuracy=0.756, val_loss=2.69, val_accuracy=0.31, lr=0.0316] 43%|████▎     | 71/166 [25:35<33:20, 21.06s/epoch, loss=1.13, accuracy=0.757, val_loss=2.44, val_accuracy=0.451, lr=0.1]   43%|████▎     | 72/166 [25:57<33:10, 21.17s/epoch, loss=1.13, accuracy=0.754, val_loss=2.09, val_accuracy=0.42, lr=0.1]  44%|████▍     | 73/166 [26:18<33:00, 21.30s/epoch, loss=1.14, accuracy=0.753, val_loss=2.84, val_accuracy=0.158, lr=0.1] 45%|████▍     | 74/166 [26:39<32:21, 21.10s/epoch, loss=1.13, accuracy=0.757, val_loss=2.85, val_accuracy=0.319, lr=0.1] 45%|████▌     | 75/166 [27:01<32:19, 21.31s/epoch, loss=1.13, accuracy=0.757, val_loss=1.81, val_accuracy=0.562, lr=0.0316] 46%|████▌     | 76/166 [27:21<31:38, 21.09s/epoch, loss=1.12, accuracy=0.757, val_loss=1.72, val_accuracy=0.572, lr=0.1]    46%|████▋     | 77/166 [27:42<31:20, 21.13s/epoch, loss=1.13, accuracy=0.759, val_loss=1.34, val_accuracy=0.69, lr=0.1]  47%|████▋     | 78/166 [28:04<31:14, 21.30s/epoch, loss=1.13, accuracy=0.756, val_loss=3.92, val_accuracy=0.216, lr=0.1] 48%|████▊     | 79/166 [28:25<30:42, 21.18s/epoch, loss=1.13, accuracy=0.754, val_loss=2.28, val_accuracy=0.503, lr=0.1] 48%|████▊     | 80/166 [28:47<30:39, 21.39s/epoch, loss=1.13, accuracy=0.754, val_loss=1.59, val_accuracy=0.604, lr=0.1] 49%|████▉     | 81/166 [29:07<29:44, 20.99s/epoch, loss=1.13, accuracy=0.756, val_loss=2.53, val_accuracy=0.316, lr=0.1] 49%|████▉     | 82/166 [29:28<29:31, 21.09s/epoch, loss=0.922, accuracy=0.813, val_loss=0.944, val_accuracy=0.79, lr=0.01] 50%|█████     | 83/166 [29:50<29:24, 21.26s/epoch, loss=0.741, accuracy=0.846, val_loss=0.792, val_accuracy=0.815, lr=0.01] 51%|█████     | 84/166 [30:10<28:36, 20.93s/epoch, loss=0.654, accuracy=0.857, val_loss=0.785, val_accuracy=0.805, lr=0.01] 51%|█████     | 85/166 [30:32<28:33, 21.15s/epoch, loss=0.612, accuracy=0.859, val_loss=0.805, val_accuracy=0.794, lr=0.01] 52%|█████▏    | 86/166 [30:53<28:24, 21.31s/epoch, loss=0.59, accuracy=0.86, val_loss=0.784, val_accuracy=0.796, lr=0.01]   52%|█████▏    | 87/166 [31:15<28:04, 21.32s/epoch, loss=0.579, accuracy=0.861, val_loss=0.73, val_accuracy=0.81, lr=0.01] 53%|█████▎    | 88/166 [31:36<27:46, 21.37s/epoch, loss=0.576, accuracy=0.861, val_loss=0.8, val_accuracy=0.789, lr=0.01] 54%|█████▎    | 89/166 [31:58<27:31, 21.45s/epoch, loss=0.568, accuracy=0.864, val_loss=1.12, val_accuracy=0.703, lr=0.01] 54%|█████▍    | 90/166 [32:18<26:42, 21.08s/epoch, loss=0.562, accuracy=0.867, val_loss=0.774, val_accuracy=0.801, lr=0.01] 55%|█████▍    | 91/166 [32:39<26:25, 21.14s/epoch, loss=0.563, accuracy=0.869, val_loss=1.11, val_accuracy=0.723, lr=0.01]  55%|█████▌    | 92/166 [33:00<26:02, 21.11s/epoch, loss=0.567, accuracy=0.867, val_loss=0.816, val_accuracy=0.803, lr=0.00316] 56%|█████▌    | 93/166 [33:22<25:47, 21.20s/epoch, loss=0.56, accuracy=0.871, val_loss=0.787, val_accuracy=0.797, lr=0.01]     57%|█████▋    | 94/166 [33:43<25:28, 21.23s/epoch, loss=0.559, accuracy=0.873, val_loss=0.852, val_accuracy=0.788, lr=0.01] 57%|█████▋    | 95/166 [34:05<25:09, 21.26s/epoch, loss=0.557, accuracy=0.874, val_loss=0.779, val_accuracy=0.802, lr=0.01] 58%|█████▊    | 96/166 [34:26<24:43, 21.19s/epoch, loss=0.562, accuracy=0.872, val_loss=0.812, val_accuracy=0.792, lr=0.01] 58%|█████▊    | 97/166 [34:47<24:22, 21.19s/epoch, loss=0.562, accuracy=0.872, val_loss=0.783, val_accuracy=0.802, lr=0.00316] 59%|█████▉    | 98/166 [35:08<24:01, 21.20s/epoch, loss=0.556, accuracy=0.875, val_loss=0.785, val_accuracy=0.812, lr=0.01]    60%|█████▉    | 99/166 [35:29<23:28, 21.02s/epoch, loss=0.559, accuracy=0.873, val_loss=0.888, val_accuracy=0.771, lr=0.01] 60%|██████    | 100/166 [35:50<23:19, 21.21s/epoch, loss=0.559, accuracy=0.876, val_loss=0.799, val_accuracy=0.8, lr=0.01]  61%|██████    | 101/166 [36:12<23:01, 21.25s/epoch, loss=0.554, accuracy=0.879, val_loss=0.748, val_accuracy=0.819, lr=0.01] 61%|██████▏   | 102/166 [36:32<22:20, 20.95s/epoch, loss=0.556, accuracy=0.877, val_loss=0.807, val_accuracy=0.804, lr=0.00316] 62%|██████▏   | 103/166 [36:53<22:01, 20.97s/epoch, loss=0.557, accuracy=0.879, val_loss=1.2, val_accuracy=0.695, lr=0.01]      63%|██████▎   | 104/166 [37:14<21:50, 21.13s/epoch, loss=0.561, accuracy=0.878, val_loss=0.8, val_accuracy=0.8, lr=0.01]   63%|██████▎   | 105/166 [37:35<21:19, 20.98s/epoch, loss=0.556, accuracy=0.88, val_loss=1.05, val_accuracy=0.731, lr=0.01] 64%|██████▍   | 106/166 [37:55<20:47, 20.79s/epoch, loss=0.554, accuracy=0.882, val_loss=0.815, val_accuracy=0.802, lr=0.01] 64%|██████▍   | 107/166 [38:17<20:34, 20.93s/epoch, loss=0.556, accuracy=0.88, val_loss=0.936, val_accuracy=0.772, lr=0.00316] 65%|██████▌   | 108/166 [38:38<20:17, 20.99s/epoch, loss=0.556, accuracy=0.88, val_loss=1.03, val_accuracy=0.755, lr=0.01]     66%|██████▌   | 109/166 [38:58<19:52, 20.93s/epoch, loss=0.558, accuracy=0.881, val_loss=0.841, val_accuracy=0.796, lr=0.01] 66%|██████▋   | 110/166 [39:20<19:36, 21.01s/epoch, loss=0.553, accuracy=0.882, val_loss=0.88, val_accuracy=0.794, lr=0.01]  67%|██████▋   | 111/166 [39:41<19:27, 21.22s/epoch, loss=0.558, accuracy=0.882, val_loss=0.792, val_accuracy=0.809, lr=0.01] 67%|██████▋   | 112/166 [40:03<19:10, 21.31s/epoch, loss=0.557, accuracy=0.881, val_loss=0.822, val_accuracy=0.797, lr=0.00316] 68%|██████▊   | 113/166 [40:24<18:46, 21.25s/epoch, loss=0.552, accuracy=0.885, val_loss=0.915, val_accuracy=0.773, lr=0.01]    69%|██████▊   | 114/166 [40:44<18:04, 20.86s/epoch, loss=0.557, accuracy=0.883, val_loss=1.02, val_accuracy=0.757, lr=0.01]  69%|██████▉   | 115/166 [41:04<17:34, 20.67s/epoch, loss=0.557, accuracy=0.883, val_loss=0.886, val_accuracy=0.779, lr=0.01] 70%|██████▉   | 116/166 [41:24<16:57, 20.34s/epoch, loss=0.558, accuracy=0.882, val_loss=1.07, val_accuracy=0.746, lr=0.01]  70%|███████   | 117/166 [41:45<16:56, 20.74s/epoch, loss=0.552, accuracy=0.884, val_loss=0.887, val_accuracy=0.787, lr=0.00316] 71%|███████   | 118/166 [42:06<16:29, 20.62s/epoch, loss=0.555, accuracy=0.884, val_loss=1.24, val_accuracy=0.692, lr=0.01]     72%|███████▏  | 119/166 [42:25<15:47, 20.16s/epoch, loss=0.559, accuracy=0.884, val_loss=0.927, val_accuracy=0.772, lr=0.01] 72%|███████▏  | 120/166 [42:45<15:29, 20.21s/epoch, loss=0.56, accuracy=0.882, val_loss=1.91, val_accuracy=0.603, lr=0.01]   73%|███████▎  | 121/166 [43:04<14:54, 19.88s/epoch, loss=0.562, accuracy=0.884, val_loss=0.74, val_accuracy=0.824, lr=0.01] 73%|███████▎  | 122/166 [43:23<14:23, 19.63s/epoch, loss=0.483, accuracy=0.911, val_loss=0.535, val_accuracy=0.893, lr=0.001] 74%|███████▍  | 123/166 [43:43<14:04, 19.64s/epoch, loss=0.427, accuracy=0.929, val_loss=0.523, val_accuracy=0.898, lr=0.001] 75%|███████▍  | 124/166 [44:03<13:45, 19.66s/epoch, loss=0.407, accuracy=0.934, val_loss=0.52, val_accuracy=0.896, lr=0.001]  75%|███████▌  | 125/166 [44:22<13:17, 19.44s/epoch, loss=0.39, accuracy=0.937, val_loss=0.507, val_accuracy=0.901, lr=0.001] 76%|███████▌  | 126/166 [44:41<12:55, 19.38s/epoch, loss=0.375, accuracy=0.941, val_loss=0.509, val_accuracy=0.898, lr=0.001] 77%|███████▋  | 127/166 [45:01<12:40, 19.49s/epoch, loss=0.364, accuracy=0.942, val_loss=0.494, val_accuracy=0.9, lr=0.001]   77%|███████▋  | 128/166 [45:20<12:18, 19.44s/epoch, loss=0.354, accuracy=0.945, val_loss=0.491, val_accuracy=0.899, lr=0.001] 78%|███████▊  | 129/166 [45:39<11:54, 19.31s/epoch, loss=0.34, accuracy=0.947, val_loss=0.507, val_accuracy=0.894, lr=0.001]  78%|███████▊  | 130/166 [45:59<11:38, 19.40s/epoch, loss=0.331, accuracy=0.948, val_loss=0.491, val_accuracy=0.899, lr=0.001] 79%|███████▉  | 131/166 [46:18<11:16, 19.33s/epoch, loss=0.324, accuracy=0.949, val_loss=0.489, val_accuracy=0.899, lr=0.001] 80%|███████▉  | 132/166 [46:37<10:55, 19.28s/epoch, loss=0.313, accuracy=0.95, val_loss=0.475, val_accuracy=0.9, lr=0.001]    80%|████████  | 133/166 [46:56<10:32, 19.16s/epoch, loss=0.309, accuracy=0.952, val_loss=0.471, val_accuracy=0.9, lr=0.001] 81%|████████  | 134/166 [47:15<10:10, 19.09s/epoch, loss=0.301, accuracy=0.953, val_loss=0.48, val_accuracy=0.897, lr=0.001] 81%|████████▏ | 135/166 [47:34<09:52, 19.12s/epoch, loss=0.293, accuracy=0.955, val_loss=0.472, val_accuracy=0.9, lr=0.001]  82%|████████▏ | 136/166 [47:54<09:43, 19.46s/epoch, loss=0.287, accuracy=0.955, val_loss=0.483, val_accuracy=0.897, lr=0.001] 83%|████████▎ | 137/166 [48:15<09:34, 19.81s/epoch, loss=0.278, accuracy=0.958, val_loss=0.476, val_accuracy=0.897, lr=0.001] 83%|████████▎ | 138/166 [48:35<09:14, 19.82s/epoch, loss=0.276, accuracy=0.956, val_loss=0.475, val_accuracy=0.897, lr=0.000316] 84%|████████▎ | 139/166 [48:55<09:02, 20.10s/epoch, loss=0.269, accuracy=0.958, val_loss=0.488, val_accuracy=0.89, lr=0.001]     84%|████████▍ | 140/166 [49:17<08:54, 20.54s/epoch, loss=0.264, accuracy=0.959, val_loss=0.483, val_accuracy=0.895, lr=0.001] 85%|████████▍ | 141/166 [49:38<08:38, 20.74s/epoch, loss=0.259, accuracy=0.959, val_loss=0.471, val_accuracy=0.898, lr=0.001] 86%|████████▌ | 142/166 [49:57<08:07, 20.31s/epoch, loss=0.256, accuracy=0.959, val_loss=0.462, val_accuracy=0.899, lr=0.001] 86%|████████▌ | 143/166 [50:18<07:47, 20.33s/epoch, loss=0.251, accuracy=0.96, val_loss=0.463, val_accuracy=0.896, lr=0.001]  87%|████████▋ | 144/166 [50:38<07:27, 20.32s/epoch, loss=0.25, accuracy=0.959, val_loss=0.451, val_accuracy=0.896, lr=0.001] 87%|████████▋ | 145/166 [50:58<07:05, 20.26s/epoch, loss=0.245, accuracy=0.96, val_loss=0.474, val_accuracy=0.893, lr=0.001] 88%|████████▊ | 146/166 [51:19<06:45, 20.30s/epoch, loss=0.24, accuracy=0.959, val_loss=0.493, val_accuracy=0.892, lr=0.001] 89%|████████▊ | 147/166 [51:40<06:30, 20.56s/epoch, loss=0.235, accuracy=0.963, val_loss=0.479, val_accuracy=0.891, lr=0.001] 89%|████████▉ | 148/166 [52:01<06:11, 20.66s/epoch, loss=0.237, accuracy=0.96, val_loss=0.477, val_accuracy=0.891, lr=0.001]  90%|████████▉ | 149/166 [52:22<05:53, 20.81s/epoch, loss=0.235, accuracy=0.96, val_loss=0.491, val_accuracy=0.888, lr=0.000316] 90%|█████████ | 150/166 [52:42<05:28, 20.53s/epoch, loss=0.23, accuracy=0.961, val_loss=0.443, val_accuracy=0.9, lr=0.001]      91%|█████████ | 151/166 [53:02<05:08, 20.54s/epoch, loss=0.229, accuracy=0.961, val_loss=0.507, val_accuracy=0.881, lr=0.001] 92%|█████████▏| 152/166 [53:23<04:46, 20.45s/epoch, loss=0.226, accuracy=0.961, val_loss=0.457, val_accuracy=0.893, lr=0.001] 92%|█████████▏| 153/166 [53:42<04:20, 20.05s/epoch, loss=0.225, accuracy=0.961, val_loss=0.475, val_accuracy=0.889, lr=0.001] 93%|█████████▎| 154/166 [54:01<03:57, 19.77s/epoch, loss=0.223, accuracy=0.961, val_loss=0.475, val_accuracy=0.89, lr=0.001]  93%|█████████▎| 155/166 [54:21<03:39, 19.92s/epoch, loss=0.223, accuracy=0.961, val_loss=0.497, val_accuracy=0.885, lr=0.000316] 94%|█████████▍| 156/166 [54:41<03:19, 20.00s/epoch, loss=0.22, accuracy=0.963, val_loss=0.496, val_accuracy=0.887, lr=0.001]     95%|█████████▍| 157/166 [55:00<02:56, 19.65s/epoch, loss=0.218, accuracy=0.963, val_loss=0.474, val_accuracy=0.888, lr=0.001] 95%|█████████▌| 158/166 [55:19<02:35, 19.41s/epoch, loss=0.219, accuracy=0.961, val_loss=0.499, val_accuracy=0.886, lr=0.001] 96%|█████████▌| 159/166 [55:38<02:15, 19.40s/epoch, loss=0.213, accuracy=0.963, val_loss=0.486, val_accuracy=0.884, lr=0.001] 96%|█████████▋| 160/166 [55:57<01:55, 19.32s/epoch, loss=0.215, accuracy=0.964, val_loss=0.477, val_accuracy=0.887, lr=0.000316] 97%|█████████▋| 161/166 [56:17<01:36, 19.25s/epoch, loss=0.211, accuracy=0.963, val_loss=0.5, val_accuracy=0.887, lr=0.001]      98%|█████████▊| 162/166 [56:37<01:18, 19.63s/epoch, loss=0.196, accuracy=0.97, val_loss=0.414, val_accuracy=0.906, lr=1e-04] 98%|█████████▊| 163/166 [56:56<00:58, 19.43s/epoch, loss=0.181, accuracy=0.976, val_loss=0.413, val_accuracy=0.906, lr=1e-04] 99%|█████████▉| 164/166 [57:16<00:39, 19.54s/epoch, loss=0.174, accuracy=0.978, val_loss=0.414, val_accuracy=0.907, lr=1e-04] 99%|█████████▉| 165/166 [57:36<00:19, 19.71s/epoch, loss=0.171, accuracy=0.979, val_loss=0.415, val_accuracy=0.906, lr=1e-04]100%|██████████| 166/166 [57:56<00:00, 19.83s/epoch, loss=0.168, accuracy=0.98, val_loss=0.411, val_accuracy=0.908, lr=1e-04] 100%|██████████| 166/166 [57:56<00:00, 20.94s/epoch, loss=0.168, accuracy=0.98, val_loss=0.411, val_accuracy=0.908, lr=1e-04]
Using real-time data augmentation.
Test loss: 0.410966157913208
Test accuracy: 0.9082000255584717


* * * Run SGD for ID = 9_2. * * *


2024-02-15 12:08:37.028802: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 12:08:39.610358: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 12:08:39.611486: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-15 12:08:39.645487: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-15 12:08:39.645518: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 12:08:39.648312: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 12:08:39.648350: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 12:08:39.650681: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 12:08:39.651326: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 12:08:39.653489: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 12:08:39.654885: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 12:08:39.659274: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 12:08:39.659774: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 12:08:39.659846: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 12:08:40.795412: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-15 12:08:40.796344: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 12:08:40.796920: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-15 12:08:40.796951: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 12:08:40.796999: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 12:08:40.797019: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 12:08:40.797036: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 12:08:40.797054: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 12:08:40.797072: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 12:08:40.797090: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 12:08:40.797108: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 12:08:40.797512: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 12:08:40.797549: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 12:08:41.404267: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-15 12:08:41.404321: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-15 12:08:41.404330: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-15 12:08:41.405183: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': 92, 'batch_size': 128, 'epochs': 166, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/166 [00:00<?, ?epoch/s]2024-02-15 12:08:42.129721: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-15 12:08:42.141401: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2599900000 Hz
2024-02-15 12:08:43.868049: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 12:08:44.058391: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 12:08:44.752950: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-15 12:08:44.784738: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/166 [00:50<2:19:57, 50.89s/epoch, loss=3.29, accuracy=0.314, val_loss=2.57, val_accuracy=0.237, lr=0.1]  1%|          | 2/166 [01:12<1:32:18, 33.77s/epoch, loss=1.59, accuracy=0.525, val_loss=1.86, val_accuracy=0.446, lr=0.1]  2%|▏         | 3/166 [01:32<1:14:11, 27.31s/epoch, loss=1.41, accuracy=0.614, val_loss=2.12, val_accuracy=0.424, lr=0.1]  2%|▏         | 4/166 [01:52<1:05:50, 24.39s/epoch, loss=1.33, accuracy=0.663, val_loss=1.71, val_accuracy=0.577, lr=0.1]  3%|▎         | 5/166 [02:12<1:01:52, 23.06s/epoch, loss=1.28, accuracy=0.689, val_loss=1.99, val_accuracy=0.428, lr=0.1]  4%|▎         | 6/166 [02:32<58:38, 21.99s/epoch, loss=1.25, accuracy=0.705, val_loss=1.46, val_accuracy=0.633, lr=0.1]    4%|▍         | 7/166 [02:53<57:08, 21.56s/epoch, loss=1.23, accuracy=0.712, val_loss=1.61, val_accuracy=0.595, lr=0.1]  5%|▍         | 8/166 [03:15<57:11, 21.72s/epoch, loss=1.22, accuracy=0.716, val_loss=1.76, val_accuracy=0.554, lr=0.1]  5%|▌         | 9/166 [03:36<55:48, 21.33s/epoch, loss=1.21, accuracy=0.72, val_loss=1.68, val_accuracy=0.557, lr=0.1]   6%|▌         | 10/166 [03:56<54:32, 20.98s/epoch, loss=1.2, accuracy=0.725, val_loss=1.53, val_accuracy=0.62, lr=0.1]  7%|▋         | 11/166 [04:18<54:57, 21.28s/epoch, loss=1.19, accuracy=0.731, val_loss=2.1, val_accuracy=0.431, lr=0.0316]  7%|▋         | 12/166 [04:37<53:05, 20.68s/epoch, loss=1.19, accuracy=0.733, val_loss=3.11, val_accuracy=0.261, lr=0.1]    8%|▊         | 13/166 [04:59<53:33, 21.00s/epoch, loss=1.19, accuracy=0.735, val_loss=2.78, val_accuracy=0.331, lr=0.1]  8%|▊         | 14/166 [05:18<52:03, 20.55s/epoch, loss=1.18, accuracy=0.736, val_loss=1.78, val_accuracy=0.528, lr=0.1]  9%|▉         | 15/166 [05:38<51:07, 20.31s/epoch, loss=1.19, accuracy=0.737, val_loss=2.62, val_accuracy=0.411, lr=0.1] 10%|▉         | 16/166 [05:57<50:04, 20.03s/epoch, loss=1.17, accuracy=0.74, val_loss=2.08, val_accuracy=0.464, lr=0.0316] 10%|█         | 17/166 [06:18<49:58, 20.12s/epoch, loss=1.18, accuracy=0.737, val_loss=1.86, val_accuracy=0.537, lr=0.1]   11%|█         | 18/166 [06:39<50:35, 20.51s/epoch, loss=1.17, accuracy=0.744, val_loss=1.45, val_accuracy=0.639, lr=0.1] 11%|█▏        | 19/166 [07:01<51:11, 20.89s/epoch, loss=1.16, accuracy=0.743, val_loss=2.15, val_accuracy=0.459, lr=0.1] 12%|█▏        | 20/166 [07:22<50:55, 20.93s/epoch, loss=1.16, accuracy=0.741, val_loss=1.37, val_accuracy=0.663, lr=0.1] 13%|█▎        | 21/166 [07:44<51:13, 21.20s/epoch, loss=1.16, accuracy=0.746, val_loss=2.04, val_accuracy=0.445, lr=0.1] 13%|█▎        | 22/166 [08:05<50:34, 21.07s/epoch, loss=1.16, accuracy=0.748, val_loss=1.8, val_accuracy=0.546, lr=0.1]  14%|█▍        | 23/166 [08:26<50:36, 21.23s/epoch, loss=1.15, accuracy=0.747, val_loss=2.75, val_accuracy=0.406, lr=0.1] 14%|█▍        | 24/166 [08:48<50:32, 21.35s/epoch, loss=1.15, accuracy=0.747, val_loss=2.45, val_accuracy=0.51, lr=0.1]  15%|█▌        | 25/166 [09:09<50:02, 21.30s/epoch, loss=1.15, accuracy=0.746, val_loss=1.87, val_accuracy=0.543, lr=0.0316] 16%|█▌        | 26/166 [09:30<49:46, 21.33s/epoch, loss=1.15, accuracy=0.746, val_loss=2.66, val_accuracy=0.429, lr=0.1]    16%|█▋        | 27/166 [09:52<49:18, 21.29s/epoch, loss=1.15, accuracy=0.75, val_loss=2.12, val_accuracy=0.497, lr=0.1]  17%|█▋        | 28/166 [10:13<49:09, 21.37s/epoch, loss=1.15, accuracy=0.748, val_loss=3.93, val_accuracy=0.325, lr=0.1] 17%|█▋        | 29/166 [10:35<49:17, 21.59s/epoch, loss=1.14, accuracy=0.75, val_loss=2.17, val_accuracy=0.448, lr=0.1]  18%|█▊        | 30/166 [10:56<48:41, 21.48s/epoch, loss=1.14, accuracy=0.746, val_loss=1.68, val_accuracy=0.546, lr=0.0316] 19%|█▊        | 31/166 [11:18<48:35, 21.60s/epoch, loss=1.14, accuracy=0.751, val_loss=2, val_accuracy=0.508, lr=0.1]       19%|█▉        | 32/166 [11:40<48:24, 21.67s/epoch, loss=1.15, accuracy=0.75, val_loss=2.33, val_accuracy=0.41, lr=0.1] 20%|█▉        | 33/166 [12:02<48:10, 21.74s/epoch, loss=1.15, accuracy=0.749, val_loss=2.41, val_accuracy=0.411, lr=0.1] 20%|██        | 34/166 [12:24<47:57, 21.80s/epoch, loss=1.15, accuracy=0.749, val_loss=2.56, val_accuracy=0.409, lr=0.1] 21%|██        | 35/166 [12:45<47:10, 21.61s/epoch, loss=1.15, accuracy=0.751, val_loss=2.57, val_accuracy=0.449, lr=0.0316] 22%|██▏       | 36/166 [13:06<46:39, 21.53s/epoch, loss=1.14, accuracy=0.752, val_loss=1.79, val_accuracy=0.567, lr=0.1]    22%|██▏       | 37/166 [13:28<46:33, 21.66s/epoch, loss=1.14, accuracy=0.749, val_loss=2.16, val_accuracy=0.519, lr=0.1] 23%|██▎       | 38/166 [13:48<44:57, 21.07s/epoch, loss=1.14, accuracy=0.755, val_loss=2.77, val_accuracy=0.41, lr=0.1]  23%|██▎       | 39/166 [14:10<45:02, 21.28s/epoch, loss=1.14, accuracy=0.752, val_loss=1.6, val_accuracy=0.6, lr=0.1]   24%|██▍       | 40/166 [14:32<45:12, 21.52s/epoch, loss=1.15, accuracy=0.748, val_loss=1.67, val_accuracy=0.565, lr=0.0316] 25%|██▍       | 41/166 [14:52<43:48, 21.03s/epoch, loss=1.14, accuracy=0.751, val_loss=2.79, val_accuracy=0.466, lr=0.1]    25%|██▌       | 42/166 [15:12<42:50, 20.73s/epoch, loss=1.15, accuracy=0.75, val_loss=2.04, val_accuracy=0.535, lr=0.1]  26%|██▌       | 43/166 [15:34<43:04, 21.01s/epoch, loss=1.14, accuracy=0.751, val_loss=1.61, val_accuracy=0.599, lr=0.1] 27%|██▋       | 44/166 [15:55<43:02, 21.17s/epoch, loss=1.15, accuracy=0.749, val_loss=1.55, val_accuracy=0.616, lr=0.1] 27%|██▋       | 45/166 [16:17<42:50, 21.24s/epoch, loss=1.14, accuracy=0.751, val_loss=2, val_accuracy=0.485, lr=0.0316] 28%|██▊       | 46/166 [16:39<43:09, 21.58s/epoch, loss=1.14, accuracy=0.751, val_loss=2.07, val_accuracy=0.514, lr=0.1] 28%|██▊       | 47/166 [17:01<42:55, 21.64s/epoch, loss=1.14, accuracy=0.752, val_loss=1.99, val_accuracy=0.559, lr=0.1] 29%|██▉       | 48/166 [17:23<42:56, 21.84s/epoch, loss=1.14, accuracy=0.752, val_loss=1.55, val_accuracy=0.603, lr=0.1] 30%|██▉       | 49/166 [17:45<42:46, 21.93s/epoch, loss=1.13, accuracy=0.754, val_loss=1.69, val_accuracy=0.583, lr=0.1] 30%|███       | 50/166 [18:07<42:20, 21.90s/epoch, loss=1.13, accuracy=0.752, val_loss=2.2, val_accuracy=0.462, lr=0.0316] 31%|███       | 51/166 [18:29<42:12, 22.02s/epoch, loss=1.14, accuracy=0.753, val_loss=1.78, val_accuracy=0.516, lr=0.1]   31%|███▏      | 52/166 [18:50<41:21, 21.76s/epoch, loss=1.13, accuracy=0.751, val_loss=2.04, val_accuracy=0.504, lr=0.1] 32%|███▏      | 53/166 [19:12<41:06, 21.83s/epoch, loss=1.14, accuracy=0.754, val_loss=1.57, val_accuracy=0.59, lr=0.1]  33%|███▎      | 54/166 [19:35<41:00, 21.97s/epoch, loss=1.15, accuracy=0.75, val_loss=3.36, val_accuracy=0.343, lr=0.1] 33%|███▎      | 55/166 [19:55<39:53, 21.56s/epoch, loss=1.14, accuracy=0.751, val_loss=1.55, val_accuracy=0.627, lr=0.0316] 34%|███▎      | 56/166 [20:18<40:03, 21.85s/epoch, loss=1.14, accuracy=0.752, val_loss=1.5, val_accuracy=0.636, lr=0.1]     34%|███▍      | 57/166 [20:40<40:01, 22.03s/epoch, loss=1.14, accuracy=0.752, val_loss=1.28, val_accuracy=0.707, lr=0.1] 35%|███▍      | 58/166 [21:01<39:08, 21.75s/epoch, loss=1.14, accuracy=0.753, val_loss=1.74, val_accuracy=0.541, lr=0.1] 36%|███▌      | 59/166 [21:24<39:10, 21.97s/epoch, loss=1.14, accuracy=0.753, val_loss=1.9, val_accuracy=0.498, lr=0.1]  36%|███▌      | 60/166 [21:46<38:42, 21.92s/epoch, loss=1.13, accuracy=0.753, val_loss=2.19, val_accuracy=0.495, lr=0.1] 37%|███▋      | 61/166 [22:08<38:32, 22.02s/epoch, loss=1.14, accuracy=0.753, val_loss=1.95, val_accuracy=0.525, lr=0.1] 37%|███▋      | 62/166 [22:30<38:14, 22.06s/epoch, loss=1.14, accuracy=0.75, val_loss=2.03, val_accuracy=0.458, lr=0.0316] 38%|███▊      | 63/166 [22:51<37:28, 21.83s/epoch, loss=1.13, accuracy=0.753, val_loss=1.68, val_accuracy=0.577, lr=0.1]   39%|███▊      | 64/166 [23:14<37:18, 21.95s/epoch, loss=1.14, accuracy=0.75, val_loss=1.96, val_accuracy=0.494, lr=0.1]  39%|███▉      | 65/166 [23:35<36:39, 21.77s/epoch, loss=1.13, accuracy=0.755, val_loss=3.31, val_accuracy=0.314, lr=0.1] 40%|███▉      | 66/166 [23:57<36:29, 21.89s/epoch, loss=1.13, accuracy=0.751, val_loss=3.23, val_accuracy=0.356, lr=0.1] 40%|████      | 67/166 [24:20<36:25, 22.07s/epoch, loss=1.13, accuracy=0.753, val_loss=3.1, val_accuracy=0.277, lr=0.0316] 41%|████      | 68/166 [24:40<35:25, 21.69s/epoch, loss=1.14, accuracy=0.753, val_loss=2.51, val_accuracy=0.491, lr=0.1]   42%|████▏     | 69/166 [25:02<34:55, 21.60s/epoch, loss=1.14, accuracy=0.756, val_loss=2.66, val_accuracy=0.422, lr=0.1] 42%|████▏     | 70/166 [25:23<34:28, 21.55s/epoch, loss=1.14, accuracy=0.754, val_loss=1.97, val_accuracy=0.479, lr=0.1] 43%|████▎     | 71/166 [25:45<34:21, 21.70s/epoch, loss=1.13, accuracy=0.753, val_loss=2.01, val_accuracy=0.492, lr=0.1] 43%|████▎     | 72/166 [26:08<34:18, 21.90s/epoch, loss=1.13, accuracy=0.753, val_loss=2.11, val_accuracy=0.48, lr=0.0316] 44%|████▍     | 73/166 [26:30<34:13, 22.08s/epoch, loss=1.14, accuracy=0.752, val_loss=1.94, val_accuracy=0.53, lr=0.1]    45%|████▍     | 74/166 [26:52<33:41, 21.98s/epoch, loss=1.13, accuracy=0.756, val_loss=2.65, val_accuracy=0.41, lr=0.1] 45%|████▌     | 75/166 [27:13<33:02, 21.78s/epoch, loss=1.13, accuracy=0.754, val_loss=4.84, val_accuracy=0.215, lr=0.1] 46%|████▌     | 76/166 [27:36<32:55, 21.95s/epoch, loss=1.14, accuracy=0.753, val_loss=2.46, val_accuracy=0.45, lr=0.1]  46%|████▋     | 77/166 [27:58<32:47, 22.11s/epoch, loss=1.13, accuracy=0.752, val_loss=4.03, val_accuracy=0.348, lr=0.0316] 47%|████▋     | 78/166 [28:20<32:18, 22.03s/epoch, loss=1.13, accuracy=0.753, val_loss=2.07, val_accuracy=0.469, lr=0.1]    48%|████▊     | 79/166 [28:42<32:03, 22.11s/epoch, loss=1.13, accuracy=0.754, val_loss=2.95, val_accuracy=0.423, lr=0.1] 48%|████▊     | 80/166 [29:04<31:41, 22.11s/epoch, loss=1.13, accuracy=0.753, val_loss=2.17, val_accuracy=0.419, lr=0.1] 49%|████▉     | 81/166 [29:25<30:48, 21.75s/epoch, loss=1.13, accuracy=0.754, val_loss=2.15, val_accuracy=0.42, lr=0.1]  49%|████▉     | 82/166 [29:47<30:40, 21.91s/epoch, loss=0.914, accuracy=0.813, val_loss=0.86, val_accuracy=0.818, lr=0.01] 50%|█████     | 83/166 [30:09<30:09, 21.80s/epoch, loss=0.734, accuracy=0.846, val_loss=0.771, val_accuracy=0.822, lr=0.01] 51%|█████     | 84/166 [30:31<29:53, 21.88s/epoch, loss=0.656, accuracy=0.854, val_loss=0.714, val_accuracy=0.826, lr=0.01] 51%|█████     | 85/166 [30:54<29:45, 22.05s/epoch, loss=0.611, accuracy=0.859, val_loss=0.731, val_accuracy=0.811, lr=0.01] 52%|█████▏    | 86/166 [31:15<29:01, 21.77s/epoch, loss=0.586, accuracy=0.861, val_loss=0.869, val_accuracy=0.77, lr=0.01]  52%|█████▏    | 87/166 [31:36<28:38, 21.76s/epoch, loss=0.574, accuracy=0.862, val_loss=0.923, val_accuracy=0.761, lr=0.01] 53%|█████▎    | 88/166 [31:58<28:04, 21.60s/epoch, loss=0.577, accuracy=0.859, val_loss=0.941, val_accuracy=0.757, lr=0.01] 54%|█████▎    | 89/166 [32:20<27:56, 21.77s/epoch, loss=0.571, accuracy=0.861, val_loss=0.738, val_accuracy=0.804, lr=0.00316] 54%|█████▍    | 90/166 [32:42<27:34, 21.77s/epoch, loss=0.564, accuracy=0.865, val_loss=0.87, val_accuracy=0.775, lr=0.01]     55%|█████▍    | 91/166 [33:03<27:13, 21.79s/epoch, loss=0.568, accuracy=0.865, val_loss=0.769, val_accuracy=0.798, lr=0.01] 55%|█████▌    | 92/166 [33:25<26:58, 21.87s/epoch, loss=0.563, accuracy=0.869, val_loss=0.966, val_accuracy=0.741, lr=0.01] 56%|█████▌    | 93/166 [33:47<26:38, 21.90s/epoch, loss=0.56, accuracy=0.869, val_loss=0.884, val_accuracy=0.769, lr=0.01]  57%|█████▋    | 94/166 [34:09<26:09, 21.80s/epoch, loss=0.563, accuracy=0.87, val_loss=0.859, val_accuracy=0.775, lr=0.00316] 57%|█████▋    | 95/166 [34:31<25:43, 21.75s/epoch, loss=0.558, accuracy=0.873, val_loss=0.804, val_accuracy=0.796, lr=0.01]   58%|█████▊    | 96/166 [34:53<25:26, 21.81s/epoch, loss=0.559, accuracy=0.873, val_loss=0.72, val_accuracy=0.816, lr=0.01]  58%|█████▊    | 97/166 [35:15<25:09, 21.88s/epoch, loss=0.562, accuracy=0.872, val_loss=0.794, val_accuracy=0.796, lr=0.01] 59%|█████▉    | 98/166 [35:37<24:54, 21.98s/epoch, loss=0.558, accuracy=0.873, val_loss=0.924, val_accuracy=0.771, lr=0.01] 60%|█████▉    | 99/166 [35:59<24:32, 21.97s/epoch, loss=0.561, accuracy=0.874, val_loss=0.856, val_accuracy=0.771, lr=0.00316] 60%|██████    | 100/166 [36:21<24:14, 22.03s/epoch, loss=0.555, accuracy=0.876, val_loss=0.784, val_accuracy=0.807, lr=0.01]   61%|██████    | 101/166 [36:43<23:45, 21.93s/epoch, loss=0.556, accuracy=0.877, val_loss=1.05, val_accuracy=0.717, lr=0.01]  61%|██████▏   | 102/166 [37:04<23:03, 21.61s/epoch, loss=0.555, accuracy=0.876, val_loss=0.77, val_accuracy=0.808, lr=0.01] 62%|██████▏   | 103/166 [37:25<22:32, 21.47s/epoch, loss=0.555, accuracy=0.879, val_loss=0.977, val_accuracy=0.761, lr=0.01] 63%|██████▎   | 104/166 [37:46<22:08, 21.42s/epoch, loss=0.558, accuracy=0.877, val_loss=1, val_accuracy=0.753, lr=0.00316]  63%|██████▎   | 105/166 [38:08<21:58, 21.62s/epoch, loss=0.558, accuracy=0.879, val_loss=0.719, val_accuracy=0.827, lr=0.01] 64%|██████▍   | 106/166 [38:29<21:28, 21.47s/epoch, loss=0.556, accuracy=0.878, val_loss=0.94, val_accuracy=0.763, lr=0.01]  64%|██████▍   | 107/166 [38:50<20:48, 21.16s/epoch, loss=0.558, accuracy=0.881, val_loss=1.06, val_accuracy=0.731, lr=0.01] 65%|██████▌   | 108/166 [39:11<20:34, 21.28s/epoch, loss=0.556, accuracy=0.881, val_loss=0.885, val_accuracy=0.78, lr=0.01] 66%|██████▌   | 109/166 [39:33<20:28, 21.56s/epoch, loss=0.555, accuracy=0.882, val_loss=1.01, val_accuracy=0.752, lr=0.00316] 66%|██████▋   | 110/166 [39:55<20:04, 21.51s/epoch, loss=0.556, accuracy=0.879, val_loss=0.759, val_accuracy=0.823, lr=0.01]   67%|██████▋   | 111/166 [40:16<19:31, 21.30s/epoch, loss=0.556, accuracy=0.88, val_loss=0.803, val_accuracy=0.801, lr=0.01]  67%|██████▋   | 112/166 [40:38<19:25, 21.59s/epoch, loss=0.553, accuracy=0.882, val_loss=0.761, val_accuracy=0.813, lr=0.01] 68%|██████▊   | 113/166 [40:59<19:03, 21.58s/epoch, loss=0.554, accuracy=0.882, val_loss=0.864, val_accuracy=0.788, lr=0.01] 69%|██████▊   | 114/166 [41:21<18:43, 21.60s/epoch, loss=0.556, accuracy=0.881, val_loss=0.72, val_accuracy=0.828, lr=0.00316] 69%|██████▉   | 115/166 [41:43<18:21, 21.60s/epoch, loss=0.554, accuracy=0.883, val_loss=1.05, val_accuracy=0.747, lr=0.01]    70%|██████▉   | 116/166 [42:05<18:07, 21.74s/epoch, loss=0.554, accuracy=0.883, val_loss=0.81, val_accuracy=0.801, lr=0.01] 70%|███████   | 117/166 [42:25<17:26, 21.36s/epoch, loss=0.554, accuracy=0.884, val_loss=0.725, val_accuracy=0.828, lr=0.01] 71%|███████   | 118/166 [42:47<17:09, 21.44s/epoch, loss=0.554, accuracy=0.884, val_loss=0.944, val_accuracy=0.771, lr=0.01] 72%|███████▏  | 119/166 [43:09<16:51, 21.53s/epoch, loss=0.554, accuracy=0.883, val_loss=0.822, val_accuracy=0.805, lr=0.00316] 72%|███████▏  | 120/166 [43:30<16:35, 21.64s/epoch, loss=0.555, accuracy=0.884, val_loss=0.971, val_accuracy=0.745, lr=0.01]    73%|███████▎  | 121/166 [43:52<16:19, 21.76s/epoch, loss=0.551, accuracy=0.885, val_loss=0.716, val_accuracy=0.835, lr=0.01] 73%|███████▎  | 122/166 [44:15<16:04, 21.92s/epoch, loss=0.47, accuracy=0.912, val_loss=0.538, val_accuracy=0.887, lr=0.001] 74%|███████▍  | 123/166 [44:36<15:39, 21.85s/epoch, loss=0.421, accuracy=0.928, val_loss=0.519, val_accuracy=0.895, lr=0.001] 75%|███████▍  | 124/166 [44:58<15:15, 21.80s/epoch, loss=0.398, accuracy=0.936, val_loss=0.506, val_accuracy=0.895, lr=0.001] 75%|███████▌  | 125/166 [45:20<14:56, 21.87s/epoch, loss=0.382, accuracy=0.938, val_loss=0.495, val_accuracy=0.897, lr=0.001] 76%|███████▌  | 126/166 [45:42<14:39, 21.98s/epoch, loss=0.369, accuracy=0.94, val_loss=0.493, val_accuracy=0.898, lr=0.001]  77%|███████▋  | 127/166 [46:03<14:02, 21.62s/epoch, loss=0.357, accuracy=0.942, val_loss=0.486, val_accuracy=0.899, lr=0.001] 77%|███████▋  | 128/166 [46:25<13:44, 21.69s/epoch, loss=0.345, accuracy=0.946, val_loss=0.483, val_accuracy=0.9, lr=0.001]   78%|███████▊  | 129/166 [46:47<13:23, 21.72s/epoch, loss=0.336, accuracy=0.947, val_loss=0.476, val_accuracy=0.903, lr=0.001] 78%|███████▊  | 130/166 [47:09<13:02, 21.73s/epoch, loss=0.326, accuracy=0.948, val_loss=0.475, val_accuracy=0.9, lr=0.001]   79%|███████▉  | 131/166 [47:31<12:44, 21.84s/epoch, loss=0.32, accuracy=0.949, val_loss=0.476, val_accuracy=0.901, lr=0.001] 80%|███████▉  | 132/166 [47:52<12:21, 21.82s/epoch, loss=0.309, accuracy=0.951, val_loss=0.468, val_accuracy=0.9, lr=0.001]  80%|████████  | 133/166 [48:15<12:03, 21.92s/epoch, loss=0.301, accuracy=0.953, val_loss=0.474, val_accuracy=0.896, lr=0.001] 81%|████████  | 134/166 [48:36<11:34, 21.72s/epoch, loss=0.297, accuracy=0.952, val_loss=0.48, val_accuracy=0.895, lr=0.001]  81%|████████▏ | 135/166 [48:58<11:14, 21.74s/epoch, loss=0.29, accuracy=0.954, val_loss=0.461, val_accuracy=0.9, lr=0.001]   82%|████████▏ | 136/166 [49:20<10:53, 21.79s/epoch, loss=0.284, accuracy=0.954, val_loss=0.476, val_accuracy=0.896, lr=0.001] 83%|████████▎ | 137/166 [49:41<10:33, 21.83s/epoch, loss=0.278, accuracy=0.956, val_loss=0.462, val_accuracy=0.899, lr=0.001] 83%|████████▎ | 138/166 [50:02<10:01, 21.49s/epoch, loss=0.271, accuracy=0.957, val_loss=0.459, val_accuracy=0.899, lr=0.001] 84%|████████▎ | 139/166 [50:24<09:43, 21.60s/epoch, loss=0.267, accuracy=0.957, val_loss=0.459, val_accuracy=0.898, lr=0.001] 84%|████████▍ | 140/166 [50:46<09:26, 21.78s/epoch, loss=0.259, accuracy=0.958, val_loss=0.476, val_accuracy=0.892, lr=0.001] 85%|████████▍ | 141/166 [51:07<08:57, 21.50s/epoch, loss=0.26, accuracy=0.956, val_loss=0.48, val_accuracy=0.895, lr=0.001]   86%|████████▌ | 142/166 [51:29<08:41, 21.74s/epoch, loss=0.253, accuracy=0.958, val_loss=0.486, val_accuracy=0.888, lr=0.001] 86%|████████▌ | 143/166 [51:51<08:20, 21.77s/epoch, loss=0.25, accuracy=0.959, val_loss=0.472, val_accuracy=0.893, lr=0.001]  87%|████████▋ | 144/166 [52:12<07:51, 21.41s/epoch, loss=0.249, accuracy=0.958, val_loss=0.517, val_accuracy=0.884, lr=0.000316] 87%|████████▋ | 145/166 [52:34<07:36, 21.73s/epoch, loss=0.242, accuracy=0.961, val_loss=0.533, val_accuracy=0.878, lr=0.001]    88%|████████▊ | 146/166 [52:56<07:12, 21.63s/epoch, loss=0.241, accuracy=0.959, val_loss=0.503, val_accuracy=0.886, lr=0.001] 89%|████████▊ | 147/166 [53:17<06:48, 21.48s/epoch, loss=0.238, accuracy=0.96, val_loss=0.476, val_accuracy=0.888, lr=0.001]  89%|████████▉ | 148/166 [53:39<06:28, 21.59s/epoch, loss=0.234, accuracy=0.96, val_loss=0.463, val_accuracy=0.896, lr=0.001] 90%|████████▉ | 149/166 [53:59<06:01, 21.26s/epoch, loss=0.235, accuracy=0.959, val_loss=0.464, val_accuracy=0.893, lr=0.000316] 90%|█████████ | 150/166 [54:21<05:41, 21.34s/epoch, loss=0.229, accuracy=0.962, val_loss=0.449, val_accuracy=0.895, lr=0.001]    91%|█████████ | 151/166 [54:43<05:22, 21.51s/epoch, loss=0.229, accuracy=0.961, val_loss=0.501, val_accuracy=0.886, lr=0.001] 92%|█████████▏| 152/166 [55:04<05:00, 21.44s/epoch, loss=0.226, accuracy=0.961, val_loss=0.457, val_accuracy=0.891, lr=0.001] 92%|█████████▏| 153/166 [55:26<04:39, 21.51s/epoch, loss=0.225, accuracy=0.96, val_loss=0.482, val_accuracy=0.889, lr=0.001]  93%|█████████▎| 154/166 [55:46<04:16, 21.34s/epoch, loss=0.223, accuracy=0.961, val_loss=0.478, val_accuracy=0.887, lr=0.001] 93%|█████████▎| 155/166 [56:08<03:55, 21.41s/epoch, loss=0.221, accuracy=0.962, val_loss=0.477, val_accuracy=0.89, lr=0.000316] 94%|█████████▍| 156/166 [56:30<03:36, 21.61s/epoch, loss=0.22, accuracy=0.961, val_loss=0.456, val_accuracy=0.896, lr=0.001]    95%|█████████▍| 157/166 [56:50<03:11, 21.24s/epoch, loss=0.218, accuracy=0.961, val_loss=0.459, val_accuracy=0.892, lr=0.001] 95%|█████████▌| 158/166 [57:12<02:49, 21.24s/epoch, loss=0.222, accuracy=0.96, val_loss=0.472, val_accuracy=0.886, lr=0.001]  96%|█████████▌| 159/166 [57:33<02:29, 21.37s/epoch, loss=0.218, accuracy=0.961, val_loss=0.485, val_accuracy=0.885, lr=0.001] 96%|█████████▋| 160/166 [57:56<02:09, 21.64s/epoch, loss=0.216, accuracy=0.961, val_loss=0.491, val_accuracy=0.889, lr=0.000316] 97%|█████████▋| 161/166 [58:18<01:48, 21.75s/epoch, loss=0.216, accuracy=0.961, val_loss=0.525, val_accuracy=0.874, lr=0.001]    98%|█████████▊| 162/166 [58:39<01:26, 21.72s/epoch, loss=0.198, accuracy=0.969, val_loss=0.403, val_accuracy=0.909, lr=1e-04] 98%|█████████▊| 163/166 [59:01<01:05, 21.86s/epoch, loss=0.18, accuracy=0.976, val_loss=0.4, val_accuracy=0.91, lr=1e-04]     99%|█████████▉| 164/166 [59:23<00:43, 21.89s/epoch, loss=0.175, accuracy=0.977, val_loss=0.401, val_accuracy=0.912, lr=1e-04] 99%|█████████▉| 165/166 [59:45<00:21, 21.88s/epoch, loss=0.172, accuracy=0.978, val_loss=0.401, val_accuracy=0.911, lr=1e-04]100%|██████████| 166/166 [1:00:07<00:00, 21.96s/epoch, loss=0.17, accuracy=0.981, val_loss=0.399, val_accuracy=0.912, lr=1e-04]100%|██████████| 166/166 [1:00:07<00:00, 21.73s/epoch, loss=0.17, accuracy=0.981, val_loss=0.399, val_accuracy=0.912, lr=1e-04]
Using real-time data augmentation.
Test loss: 0.39917701482772827
Test accuracy: 0.9117000102996826


* * * Run SGD for ID = 9_3. * * *


2024-02-15 13:08:52.770545: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 13:08:55.301469: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 13:08:55.302644: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-15 13:08:55.337760: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-15 13:08:55.337786: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 13:08:55.340530: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 13:08:55.340570: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 13:08:55.343013: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 13:08:55.343706: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 13:08:55.346040: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 13:08:55.347444: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 13:08:55.351970: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 13:08:55.352446: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 13:08:55.352523: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 13:08:56.552436: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-15 13:08:56.553550: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 13:08:56.554162: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-15 13:08:56.554192: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 13:08:56.554239: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 13:08:56.554260: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 13:08:56.554289: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 13:08:56.554328: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 13:08:56.554347: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 13:08:56.554365: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 13:08:56.554384: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 13:08:56.554805: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 13:08:56.554837: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 13:08:57.161723: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-15 13:08:57.161787: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-15 13:08:57.161797: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-15 13:08:57.162721: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': 93, 'batch_size': 128, 'epochs': 166, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/166 [00:00<?, ?epoch/s]2024-02-15 13:08:57.920330: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-15 13:08:57.932493: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2599900000 Hz
2024-02-15 13:08:59.741140: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 13:09:00.012992: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 13:09:00.753922: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-15 13:09:00.802804: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/166 [00:54<2:30:34, 54.75s/epoch, loss=3.19, accuracy=0.3, val_loss=3.34, val_accuracy=0.122, lr=0.1]  1%|          | 2/166 [01:15<1:35:21, 34.89s/epoch, loss=1.57, accuracy=0.533, val_loss=2.04, val_accuracy=0.416, lr=0.1]  2%|▏         | 3/166 [01:36<1:17:42, 28.60s/epoch, loss=1.35, accuracy=0.639, val_loss=2.16, val_accuracy=0.447, lr=0.1]  2%|▏         | 4/166 [01:59<1:10:45, 26.21s/epoch, loss=1.29, accuracy=0.679, val_loss=1.98, val_accuracy=0.472, lr=0.1]  3%|▎         | 5/166 [02:21<1:06:45, 24.88s/epoch, loss=1.26, accuracy=0.698, val_loss=2.15, val_accuracy=0.44, lr=0.1]   4%|▎         | 6/166 [02:43<1:03:43, 23.90s/epoch, loss=1.24, accuracy=0.706, val_loss=2.02, val_accuracy=0.496, lr=0.1]  4%|▍         | 7/166 [03:05<1:01:20, 23.15s/epoch, loss=1.24, accuracy=0.714, val_loss=1.8, val_accuracy=0.54, lr=0.1]    5%|▍         | 8/166 [03:27<1:00:20, 22.92s/epoch, loss=1.22, accuracy=0.719, val_loss=1.56, val_accuracy=0.614, lr=0.1]  5%|▌         | 9/166 [03:49<58:35, 22.39s/epoch, loss=1.22, accuracy=0.724, val_loss=1.62, val_accuracy=0.582, lr=0.1]    6%|▌         | 10/166 [04:11<58:03, 22.33s/epoch, loss=1.22, accuracy=0.723, val_loss=4.43, val_accuracy=0.273, lr=0.1]  7%|▋         | 11/166 [04:33<57:38, 22.31s/epoch, loss=1.21, accuracy=0.729, val_loss=1.63, val_accuracy=0.57, lr=0.1]   7%|▋         | 12/166 [04:56<57:26, 22.38s/epoch, loss=1.2, accuracy=0.733, val_loss=1.68, val_accuracy=0.588, lr=0.1]  8%|▊         | 13/166 [05:18<57:09, 22.42s/epoch, loss=1.19, accuracy=0.734, val_loss=1.87, val_accuracy=0.528, lr=0.0316]  8%|▊         | 14/166 [05:41<56:51, 22.44s/epoch, loss=1.19, accuracy=0.737, val_loss=1.68, val_accuracy=0.584, lr=0.1]     9%|▉         | 15/166 [06:02<55:22, 22.00s/epoch, loss=1.19, accuracy=0.741, val_loss=1.98, val_accuracy=0.502, lr=0.1] 10%|▉         | 16/166 [06:23<54:08, 21.66s/epoch, loss=1.19, accuracy=0.742, val_loss=2.41, val_accuracy=0.391, lr=0.1] 10%|█         | 17/166 [06:45<54:07, 21.79s/epoch, loss=1.19, accuracy=0.738, val_loss=2.54, val_accuracy=0.434, lr=0.1] 11%|█         | 18/166 [07:07<54:14, 21.99s/epoch, loss=1.18, accuracy=0.742, val_loss=1.55, val_accuracy=0.612, lr=0.1] 11%|█▏        | 19/166 [07:29<53:49, 21.97s/epoch, loss=1.18, accuracy=0.745, val_loss=1.83, val_accuracy=0.511, lr=0.1] 12%|█▏        | 20/166 [07:51<53:36, 22.03s/epoch, loss=1.17, accuracy=0.747, val_loss=1.55, val_accuracy=0.607, lr=0.1] 13%|█▎        | 21/166 [08:12<52:23, 21.68s/epoch, loss=1.18, accuracy=0.743, val_loss=3.43, val_accuracy=0.333, lr=0.1] 13%|█▎        | 22/166 [08:35<52:46, 21.99s/epoch, loss=1.17, accuracy=0.744, val_loss=1.6, val_accuracy=0.628, lr=0.1]  14%|█▍        | 23/166 [08:57<52:51, 22.18s/epoch, loss=1.17, accuracy=0.748, val_loss=2.09, val_accuracy=0.479, lr=0.0316] 14%|█▍        | 24/166 [09:18<51:28, 21.75s/epoch, loss=1.18, accuracy=0.746, val_loss=2.36, val_accuracy=0.419, lr=0.1]    15%|█▌        | 25/166 [09:41<51:40, 21.99s/epoch, loss=1.17, accuracy=0.748, val_loss=2.3, val_accuracy=0.478, lr=0.1]  16%|█▌        | 26/166 [10:03<51:33, 22.10s/epoch, loss=1.17, accuracy=0.746, val_loss=2.35, val_accuracy=0.48, lr=0.1] 16%|█▋        | 27/166 [10:25<51:22, 22.18s/epoch, loss=1.17, accuracy=0.747, val_loss=1.96, val_accuracy=0.54, lr=0.1] 17%|█▋        | 28/166 [10:46<50:08, 21.80s/epoch, loss=1.17, accuracy=0.748, val_loss=1.63, val_accuracy=0.61, lr=0.0316] 17%|█▋        | 29/166 [11:09<50:11, 21.98s/epoch, loss=1.17, accuracy=0.749, val_loss=1.5, val_accuracy=0.629, lr=0.1]    18%|█▊        | 30/166 [11:31<50:17, 22.19s/epoch, loss=1.17, accuracy=0.75, val_loss=1.7, val_accuracy=0.596, lr=0.1]  19%|█▊        | 31/166 [11:53<49:52, 22.16s/epoch, loss=1.16, accuracy=0.748, val_loss=2.25, val_accuracy=0.429, lr=0.1] 19%|█▉        | 32/166 [12:16<49:51, 22.33s/epoch, loss=1.16, accuracy=0.75, val_loss=1.69, val_accuracy=0.591, lr=0.1]  20%|█▉        | 33/166 [12:38<49:14, 22.21s/epoch, loss=1.16, accuracy=0.749, val_loss=2.57, val_accuracy=0.394, lr=0.1] 20%|██        | 34/166 [13:00<48:46, 22.17s/epoch, loss=1.16, accuracy=0.752, val_loss=1.89, val_accuracy=0.532, lr=0.0316] 21%|██        | 35/166 [13:23<48:33, 22.24s/epoch, loss=1.15, accuracy=0.751, val_loss=1.67, val_accuracy=0.569, lr=0.1]    22%|██▏       | 36/166 [13:45<48:23, 22.34s/epoch, loss=1.16, accuracy=0.751, val_loss=1.72, val_accuracy=0.539, lr=0.1] 22%|██▏       | 37/166 [14:07<47:56, 22.30s/epoch, loss=1.15, accuracy=0.753, val_loss=2.78, val_accuracy=0.417, lr=0.1] 23%|██▎       | 38/166 [14:28<46:36, 21.85s/epoch, loss=1.16, accuracy=0.753, val_loss=2.05, val_accuracy=0.453, lr=0.1] 23%|██▎       | 39/166 [14:50<46:22, 21.91s/epoch, loss=1.15, accuracy=0.751, val_loss=1.83, val_accuracy=0.557, lr=0.0316] 24%|██▍       | 40/166 [15:12<46:13, 22.01s/epoch, loss=1.15, accuracy=0.751, val_loss=1.69, val_accuracy=0.573, lr=0.1]    25%|██▍       | 41/166 [15:35<46:07, 22.14s/epoch, loss=1.15, accuracy=0.754, val_loss=2.09, val_accuracy=0.456, lr=0.1] 25%|██▌       | 42/166 [15:56<45:12, 21.88s/epoch, loss=1.14, accuracy=0.756, val_loss=3.01, val_accuracy=0.411, lr=0.1] 26%|██▌       | 43/166 [16:18<44:32, 21.72s/epoch, loss=1.15, accuracy=0.754, val_loss=1.48, val_accuracy=0.634, lr=0.1] 27%|██▋       | 44/166 [16:39<43:45, 21.52s/epoch, loss=1.15, accuracy=0.754, val_loss=2.76, val_accuracy=0.333, lr=0.1] 27%|██▋       | 45/166 [17:01<43:41, 21.67s/epoch, loss=1.14, accuracy=0.754, val_loss=2.64, val_accuracy=0.433, lr=0.1] 28%|██▊       | 46/166 [17:23<43:52, 21.94s/epoch, loss=1.14, accuracy=0.753, val_loss=2.83, val_accuracy=0.407, lr=0.1] 28%|██▊       | 47/166 [17:46<43:51, 22.11s/epoch, loss=1.14, accuracy=0.753, val_loss=1.91, val_accuracy=0.509, lr=0.1] 29%|██▉       | 48/166 [18:08<43:47, 22.27s/epoch, loss=1.14, accuracy=0.754, val_loss=5.51, val_accuracy=0.193, lr=0.0316] 30%|██▉       | 49/166 [18:31<43:38, 22.38s/epoch, loss=1.15, accuracy=0.755, val_loss=1.51, val_accuracy=0.647, lr=0.1]    30%|███       | 50/166 [18:52<42:23, 21.93s/epoch, loss=1.14, accuracy=0.753, val_loss=1.73, val_accuracy=0.556, lr=0.1] 31%|███       | 51/166 [19:13<41:24, 21.61s/epoch, loss=1.14, accuracy=0.756, val_loss=2.63, val_accuracy=0.345, lr=0.1] 31%|███▏      | 52/166 [19:35<41:30, 21.85s/epoch, loss=1.14, accuracy=0.755, val_loss=5.96, val_accuracy=0.202, lr=0.1] 32%|███▏      | 53/166 [19:58<41:34, 22.08s/epoch, loss=1.14, accuracy=0.753, val_loss=2.04, val_accuracy=0.496, lr=0.0316] 33%|███▎      | 54/166 [20:19<40:37, 21.77s/epoch, loss=1.14, accuracy=0.756, val_loss=2.39, val_accuracy=0.457, lr=0.1]    33%|███▎      | 55/166 [20:41<40:30, 21.90s/epoch, loss=1.14, accuracy=0.756, val_loss=1.93, val_accuracy=0.459, lr=0.1] 34%|███▎      | 56/166 [21:03<40:05, 21.87s/epoch, loss=1.14, accuracy=0.755, val_loss=2.06, val_accuracy=0.488, lr=0.1] 34%|███▍      | 57/166 [21:24<39:26, 21.71s/epoch, loss=1.14, accuracy=0.756, val_loss=1.64, val_accuracy=0.565, lr=0.1] 35%|███▍      | 58/166 [21:47<39:33, 21.98s/epoch, loss=1.14, accuracy=0.754, val_loss=2.04, val_accuracy=0.416, lr=0.0316] 36%|███▌      | 59/166 [22:09<39:17, 22.04s/epoch, loss=1.14, accuracy=0.756, val_loss=1.64, val_accuracy=0.586, lr=0.1]    36%|███▌      | 60/166 [22:31<38:57, 22.05s/epoch, loss=1.14, accuracy=0.754, val_loss=2.86, val_accuracy=0.417, lr=0.1] 37%|███▋      | 61/166 [22:52<37:55, 21.67s/epoch, loss=1.14, accuracy=0.755, val_loss=1.8, val_accuracy=0.525, lr=0.1]  37%|███▋      | 62/166 [23:14<37:57, 21.90s/epoch, loss=1.14, accuracy=0.758, val_loss=1.87, val_accuracy=0.502, lr=0.1] 38%|███▊      | 63/166 [23:35<37:09, 21.65s/epoch, loss=1.13, accuracy=0.758, val_loss=1.98, val_accuracy=0.535, lr=0.0316] 39%|███▊      | 64/166 [23:56<36:23, 21.40s/epoch, loss=1.14, accuracy=0.756, val_loss=2.73, val_accuracy=0.333, lr=0.1]    39%|███▉      | 65/166 [24:17<35:42, 21.22s/epoch, loss=1.15, accuracy=0.752, val_loss=1.8, val_accuracy=0.525, lr=0.1]  40%|███▉      | 66/166 [24:39<35:51, 21.52s/epoch, loss=1.13, accuracy=0.756, val_loss=2.48, val_accuracy=0.401, lr=0.1] 40%|████      | 67/166 [25:01<35:51, 21.73s/epoch, loss=1.13, accuracy=0.759, val_loss=1.71, val_accuracy=0.559, lr=0.1] 41%|████      | 68/166 [25:24<35:56, 22.01s/epoch, loss=1.13, accuracy=0.756, val_loss=3.51, val_accuracy=0.302, lr=0.0316] 42%|████▏     | 69/166 [25:45<35:11, 21.77s/epoch, loss=1.13, accuracy=0.751, val_loss=1.88, val_accuracy=0.464, lr=0.1]    42%|████▏     | 70/166 [26:08<35:16, 22.04s/epoch, loss=1.14, accuracy=0.752, val_loss=2.45, val_accuracy=0.379, lr=0.1] 43%|████▎     | 71/166 [26:30<35:01, 22.12s/epoch, loss=1.13, accuracy=0.756, val_loss=3.76, val_accuracy=0.349, lr=0.1] 43%|████▎     | 72/166 [26:53<34:50, 22.24s/epoch, loss=1.14, accuracy=0.755, val_loss=1.83, val_accuracy=0.504, lr=0.1] 44%|████▍     | 73/166 [27:15<34:32, 22.29s/epoch, loss=1.13, accuracy=0.755, val_loss=1.7, val_accuracy=0.544, lr=0.0316] 45%|████▍     | 74/166 [27:38<34:16, 22.35s/epoch, loss=1.13, accuracy=0.757, val_loss=2.03, val_accuracy=0.497, lr=0.1]   45%|████▌     | 75/166 [28:00<33:47, 22.28s/epoch, loss=1.13, accuracy=0.756, val_loss=1.89, val_accuracy=0.482, lr=0.1] 46%|████▌     | 76/166 [28:20<32:44, 21.83s/epoch, loss=1.13, accuracy=0.756, val_loss=4.06, val_accuracy=0.215, lr=0.1] 46%|████▋     | 77/166 [28:43<32:32, 21.94s/epoch, loss=1.13, accuracy=0.755, val_loss=6.86, val_accuracy=0.191, lr=0.1] 47%|████▋     | 78/166 [29:04<31:50, 21.71s/epoch, loss=1.13, accuracy=0.754, val_loss=2.76, val_accuracy=0.395, lr=0.0316] 48%|████▊     | 79/166 [29:26<31:51, 21.97s/epoch, loss=1.13, accuracy=0.755, val_loss=1.89, val_accuracy=0.482, lr=0.1]    48%|████▊     | 80/166 [29:49<31:42, 22.13s/epoch, loss=1.13, accuracy=0.757, val_loss=2.64, val_accuracy=0.412, lr=0.1] 49%|████▉     | 81/166 [30:11<31:22, 22.15s/epoch, loss=1.13, accuracy=0.752, val_loss=1.94, val_accuracy=0.524, lr=0.1] 49%|████▉     | 82/166 [30:34<31:11, 22.28s/epoch, loss=0.923, accuracy=0.815, val_loss=0.891, val_accuracy=0.805, lr=0.01] 50%|█████     | 83/166 [30:56<30:44, 22.23s/epoch, loss=0.74, accuracy=0.846, val_loss=0.858, val_accuracy=0.793, lr=0.01]  51%|█████     | 84/166 [31:18<30:26, 22.27s/epoch, loss=0.656, accuracy=0.856, val_loss=0.7, val_accuracy=0.835, lr=0.01]  51%|█████     | 85/166 [31:40<30:04, 22.28s/epoch, loss=0.611, accuracy=0.861, val_loss=0.701, val_accuracy=0.83, lr=0.01] 52%|█████▏    | 86/166 [32:01<29:05, 21.82s/epoch, loss=0.587, accuracy=0.86, val_loss=0.811, val_accuracy=0.782, lr=0.01] 52%|█████▏    | 87/166 [32:22<28:18, 21.50s/epoch, loss=0.578, accuracy=0.862, val_loss=0.821, val_accuracy=0.778, lr=0.01] 53%|█████▎    | 88/166 [32:45<28:22, 21.83s/epoch, loss=0.567, accuracy=0.864, val_loss=0.818, val_accuracy=0.782, lr=0.01] 54%|█████▎    | 89/166 [33:07<28:17, 22.05s/epoch, loss=0.567, accuracy=0.864, val_loss=0.681, val_accuracy=0.828, lr=0.01] 54%|█████▍    | 90/166 [33:29<27:44, 21.90s/epoch, loss=0.562, accuracy=0.867, val_loss=0.752, val_accuracy=0.801, lr=0.01] 55%|█████▍    | 91/166 [33:49<26:57, 21.56s/epoch, loss=0.568, accuracy=0.867, val_loss=0.831, val_accuracy=0.783, lr=0.01] 55%|█████▌    | 92/166 [34:12<26:57, 21.86s/epoch, loss=0.56, accuracy=0.869, val_loss=0.752, val_accuracy=0.814, lr=0.01]  56%|█████▌    | 93/166 [34:34<26:41, 21.94s/epoch, loss=0.559, accuracy=0.872, val_loss=0.769, val_accuracy=0.801, lr=0.01] 57%|█████▋    | 94/166 [34:57<26:30, 22.09s/epoch, loss=0.558, accuracy=0.872, val_loss=1.1, val_accuracy=0.724, lr=0.00316] 57%|█████▋    | 95/166 [35:18<26:00, 21.97s/epoch, loss=0.558, accuracy=0.872, val_loss=0.839, val_accuracy=0.778, lr=0.01]  58%|█████▊    | 96/166 [35:40<25:24, 21.78s/epoch, loss=0.559, accuracy=0.873, val_loss=0.729, val_accuracy=0.823, lr=0.01] 58%|█████▊    | 97/166 [36:01<25:02, 21.77s/epoch, loss=0.558, accuracy=0.874, val_loss=0.872, val_accuracy=0.776, lr=0.01] 59%|█████▉    | 98/166 [36:23<24:28, 21.59s/epoch, loss=0.554, accuracy=0.877, val_loss=1, val_accuracy=0.744, lr=0.01]     60%|█████▉    | 99/166 [36:43<23:50, 21.36s/epoch, loss=0.555, accuracy=0.875, val_loss=0.815, val_accuracy=0.789, lr=0.00316] 60%|██████    | 100/166 [37:05<23:38, 21.49s/epoch, loss=0.558, accuracy=0.876, val_loss=0.974, val_accuracy=0.764, lr=0.01]   61%|██████    | 101/166 [37:27<23:33, 21.74s/epoch, loss=0.559, accuracy=0.876, val_loss=0.93, val_accuracy=0.757, lr=0.01]  61%|██████▏   | 102/166 [37:50<23:21, 21.90s/epoch, loss=0.557, accuracy=0.878, val_loss=0.757, val_accuracy=0.815, lr=0.01] 62%|██████▏   | 103/166 [38:12<23:04, 21.98s/epoch, loss=0.556, accuracy=0.878, val_loss=0.935, val_accuracy=0.772, lr=0.01] 63%|██████▎   | 104/166 [38:34<22:49, 22.09s/epoch, loss=0.551, accuracy=0.88, val_loss=0.845, val_accuracy=0.789, lr=0.00316] 63%|██████▎   | 105/166 [38:55<22:07, 21.75s/epoch, loss=0.555, accuracy=0.879, val_loss=0.985, val_accuracy=0.757, lr=0.01]   64%|██████▍   | 106/166 [39:17<21:38, 21.64s/epoch, loss=0.556, accuracy=0.881, val_loss=0.787, val_accuracy=0.811, lr=0.01] 64%|██████▍   | 107/166 [39:38<21:07, 21.48s/epoch, loss=0.561, accuracy=0.879, val_loss=0.712, val_accuracy=0.828, lr=0.01] 65%|██████▌   | 108/166 [39:59<20:47, 21.50s/epoch, loss=0.553, accuracy=0.883, val_loss=1.16, val_accuracy=0.73, lr=0.01]   66%|██████▌   | 109/166 [40:21<20:27, 21.53s/epoch, loss=0.556, accuracy=0.882, val_loss=0.768, val_accuracy=0.819, lr=0.00316] 66%|██████▋   | 110/166 [40:42<20:07, 21.57s/epoch, loss=0.554, accuracy=0.882, val_loss=0.787, val_accuracy=0.816, lr=0.01]    67%|██████▋   | 111/166 [41:04<19:49, 21.63s/epoch, loss=0.558, accuracy=0.882, val_loss=0.796, val_accuracy=0.802, lr=0.01] 67%|██████▋   | 112/166 [41:27<19:42, 21.91s/epoch, loss=0.558, accuracy=0.881, val_loss=1.02, val_accuracy=0.755, lr=0.01]  68%|██████▊   | 113/166 [41:49<19:26, 22.01s/epoch, loss=0.552, accuracy=0.884, val_loss=0.773, val_accuracy=0.814, lr=0.01] 69%|██████▊   | 114/166 [42:11<19:10, 22.12s/epoch, loss=0.553, accuracy=0.882, val_loss=1.05, val_accuracy=0.749, lr=0.00316] 69%|██████▉   | 115/166 [42:34<18:49, 22.15s/epoch, loss=0.559, accuracy=0.881, val_loss=0.803, val_accuracy=0.808, lr=0.01]   70%|██████▉   | 116/166 [42:56<18:32, 22.24s/epoch, loss=0.558, accuracy=0.882, val_loss=1.11, val_accuracy=0.742, lr=0.01]  70%|███████   | 117/166 [43:17<17:49, 21.82s/epoch, loss=0.556, accuracy=0.885, val_loss=0.953, val_accuracy=0.76, lr=0.01] 71%|███████   | 118/166 [43:39<17:31, 21.90s/epoch, loss=0.554, accuracy=0.883, val_loss=0.863, val_accuracy=0.787, lr=0.01] 72%|███████▏  | 119/166 [44:00<16:51, 21.52s/epoch, loss=0.554, accuracy=0.884, val_loss=0.684, val_accuracy=0.846, lr=0.00316] 72%|███████▏  | 120/166 [44:21<16:32, 21.58s/epoch, loss=0.555, accuracy=0.886, val_loss=0.918, val_accuracy=0.788, lr=0.01]    73%|███████▎  | 121/166 [44:43<16:13, 21.64s/epoch, loss=0.556, accuracy=0.883, val_loss=0.829, val_accuracy=0.798, lr=0.01] 73%|███████▎  | 122/166 [45:04<15:43, 21.44s/epoch, loss=0.48, accuracy=0.911, val_loss=0.544, val_accuracy=0.892, lr=0.001] 74%|███████▍  | 123/166 [45:25<15:10, 21.18s/epoch, loss=0.428, accuracy=0.928, val_loss=0.516, val_accuracy=0.898, lr=0.001] 75%|███████▍  | 124/166 [45:47<15:00, 21.43s/epoch, loss=0.407, accuracy=0.933, val_loss=0.51, val_accuracy=0.9, lr=0.001]    75%|███████▌  | 125/166 [46:09<14:51, 21.74s/epoch, loss=0.388, accuracy=0.937, val_loss=0.501, val_accuracy=0.903, lr=0.001] 76%|███████▌  | 126/166 [46:32<14:38, 21.97s/epoch, loss=0.376, accuracy=0.94, val_loss=0.486, val_accuracy=0.904, lr=0.001]  77%|███████▋  | 127/166 [46:52<14:01, 21.57s/epoch, loss=0.361, accuracy=0.943, val_loss=0.483, val_accuracy=0.904, lr=0.001] 77%|███████▋  | 128/166 [47:15<13:48, 21.81s/epoch, loss=0.35, accuracy=0.944, val_loss=0.49, val_accuracy=0.902, lr=0.001]   78%|███████▊  | 129/166 [47:37<13:27, 21.82s/epoch, loss=0.343, accuracy=0.946, val_loss=0.475, val_accuracy=0.904, lr=0.001] 78%|███████▊  | 130/166 [47:58<12:57, 21.60s/epoch, loss=0.335, accuracy=0.946, val_loss=0.475, val_accuracy=0.906, lr=0.001] 79%|███████▉  | 131/166 [48:19<12:36, 21.62s/epoch, loss=0.323, accuracy=0.95, val_loss=0.462, val_accuracy=0.906, lr=0.001]  80%|███████▉  | 132/166 [48:40<12:06, 21.36s/epoch, loss=0.316, accuracy=0.951, val_loss=0.463, val_accuracy=0.903, lr=0.001] 80%|████████  | 133/166 [49:01<11:37, 21.12s/epoch, loss=0.31, accuracy=0.951, val_loss=0.461, val_accuracy=0.906, lr=0.001]  81%|████████  | 134/166 [49:23<11:28, 21.51s/epoch, loss=0.3, accuracy=0.952, val_loss=0.46, val_accuracy=0.901, lr=0.001]   81%|████████▏ | 135/166 [49:45<11:13, 21.73s/epoch, loss=0.293, accuracy=0.953, val_loss=0.454, val_accuracy=0.907, lr=0.001] 82%|████████▏ | 136/166 [50:07<10:55, 21.84s/epoch, loss=0.287, accuracy=0.953, val_loss=0.459, val_accuracy=0.901, lr=0.001] 83%|████████▎ | 137/166 [50:28<10:20, 21.40s/epoch, loss=0.284, accuracy=0.954, val_loss=0.445, val_accuracy=0.903, lr=0.001] 83%|████████▎ | 138/166 [50:50<10:02, 21.52s/epoch, loss=0.274, accuracy=0.957, val_loss=0.465, val_accuracy=0.9, lr=0.001]   84%|████████▎ | 139/166 [51:10<09:33, 21.23s/epoch, loss=0.272, accuracy=0.955, val_loss=0.478, val_accuracy=0.894, lr=0.001] 84%|████████▍ | 140/166 [51:32<09:20, 21.57s/epoch, loss=0.265, accuracy=0.958, val_loss=0.456, val_accuracy=0.899, lr=0.001] 85%|████████▍ | 141/166 [51:53<08:54, 21.39s/epoch, loss=0.26, accuracy=0.958, val_loss=0.471, val_accuracy=0.896, lr=0.001]  86%|████████▌ | 142/166 [52:16<08:38, 21.61s/epoch, loss=0.257, accuracy=0.958, val_loss=0.458, val_accuracy=0.897, lr=0.000316] 86%|████████▌ | 143/166 [52:37<08:16, 21.60s/epoch, loss=0.251, accuracy=0.96, val_loss=0.455, val_accuracy=0.9, lr=0.001]       87%|████████▋ | 144/166 [52:59<07:56, 21.65s/epoch, loss=0.25, accuracy=0.959, val_loss=0.46, val_accuracy=0.891, lr=0.001] 87%|████████▋ | 145/166 [53:21<07:35, 21.70s/epoch, loss=0.245, accuracy=0.959, val_loss=0.487, val_accuracy=0.887, lr=0.001] 88%|████████▊ | 146/166 [53:43<07:15, 21.76s/epoch, loss=0.244, accuracy=0.959, val_loss=0.44, val_accuracy=0.902, lr=0.001]  89%|████████▊ | 147/166 [54:05<06:55, 21.88s/epoch, loss=0.239, accuracy=0.96, val_loss=0.463, val_accuracy=0.895, lr=0.001] 89%|████████▉ | 148/166 [54:26<06:32, 21.79s/epoch, loss=0.237, accuracy=0.961, val_loss=0.482, val_accuracy=0.895, lr=0.001] 90%|████████▉ | 149/166 [54:49<06:14, 22.01s/epoch, loss=0.236, accuracy=0.959, val_loss=0.503, val_accuracy=0.879, lr=0.001] 90%|█████████ | 150/166 [55:11<05:51, 21.99s/epoch, loss=0.232, accuracy=0.961, val_loss=0.472, val_accuracy=0.893, lr=0.001] 91%|█████████ | 151/166 [55:33<05:29, 21.98s/epoch, loss=0.232, accuracy=0.96, val_loss=0.442, val_accuracy=0.9, lr=0.000316] 92%|█████████▏| 152/166 [55:55<05:09, 22.08s/epoch, loss=0.227, accuracy=0.962, val_loss=0.446, val_accuracy=0.9, lr=0.001]   92%|█████████▏| 153/166 [56:17<04:45, 21.99s/epoch, loss=0.227, accuracy=0.96, val_loss=0.455, val_accuracy=0.895, lr=0.001] 93%|█████████▎| 154/166 [56:39<04:24, 22.03s/epoch, loss=0.225, accuracy=0.961, val_loss=0.528, val_accuracy=0.88, lr=0.001] 93%|█████████▎| 155/166 [57:01<04:01, 21.92s/epoch, loss=0.224, accuracy=0.96, val_loss=0.493, val_accuracy=0.89, lr=0.001]  94%|█████████▍| 156/166 [57:21<03:35, 21.55s/epoch, loss=0.219, accuracy=0.962, val_loss=0.498, val_accuracy=0.883, lr=0.000316] 95%|█████████▍| 157/166 [57:43<03:15, 21.71s/epoch, loss=0.221, accuracy=0.961, val_loss=0.516, val_accuracy=0.882, lr=0.001]    95%|█████████▌| 158/166 [58:05<02:53, 21.65s/epoch, loss=0.219, accuracy=0.961, val_loss=0.481, val_accuracy=0.889, lr=0.001] 96%|█████████▌| 159/166 [58:27<02:32, 21.73s/epoch, loss=0.217, accuracy=0.962, val_loss=0.517, val_accuracy=0.878, lr=0.001] 96%|█████████▋| 160/166 [58:49<02:11, 21.89s/epoch, loss=0.217, accuracy=0.962, val_loss=0.461, val_accuracy=0.891, lr=0.001] 97%|█████████▋| 161/166 [59:10<01:48, 21.66s/epoch, loss=0.217, accuracy=0.961, val_loss=0.484, val_accuracy=0.882, lr=0.000316] 98%|█████████▊| 162/166 [59:32<01:27, 21.75s/epoch, loss=0.201, accuracy=0.968, val_loss=0.412, val_accuracy=0.906, lr=1e-04]    98%|█████████▊| 163/166 [59:54<01:05, 21.90s/epoch, loss=0.184, accuracy=0.975, val_loss=0.407, val_accuracy=0.908, lr=1e-04] 99%|█████████▉| 164/166 [1:00:17<00:43, 21.96s/epoch, loss=0.178, accuracy=0.976, val_loss=0.404, val_accuracy=0.908, lr=1e-04] 99%|█████████▉| 165/166 [1:00:37<00:21, 21.49s/epoch, loss=0.175, accuracy=0.977, val_loss=0.408, val_accuracy=0.906, lr=1e-04]100%|██████████| 166/166 [1:00:59<00:00, 21.77s/epoch, loss=0.172, accuracy=0.978, val_loss=0.404, val_accuracy=0.908, lr=1e-04]100%|██████████| 166/166 [1:00:59<00:00, 22.05s/epoch, loss=0.172, accuracy=0.978, val_loss=0.404, val_accuracy=0.908, lr=1e-04]
Using real-time data augmentation.
Test loss: 0.40378648042678833
Test accuracy: 0.9075000286102295


* * * Run SGD for ID = 9_4. * * *


2024-02-15 14:10:00.301176: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 14:10:02.911578: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 14:10:02.912825: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-15 14:10:02.948252: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-15 14:10:02.948315: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 14:10:02.951118: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 14:10:02.951155: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 14:10:02.953424: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 14:10:02.954083: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 14:10:02.956432: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 14:10:02.957834: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 14:10:02.962346: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 14:10:02.962852: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 14:10:02.962930: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 14:10:04.153506: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-15 14:10:04.154637: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 14:10:04.155226: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-15 14:10:04.155256: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 14:10:04.155317: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 14:10:04.155339: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 14:10:04.155357: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 14:10:04.155376: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 14:10:04.155394: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 14:10:04.155412: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 14:10:04.155431: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 14:10:04.155845: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 14:10:04.155878: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 14:10:04.767172: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-15 14:10:04.767237: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-15 14:10:04.767262: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-15 14:10:04.768171: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': 94, 'batch_size': 128, 'epochs': 166, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/166 [00:00<?, ?epoch/s]2024-02-15 14:10:05.544033: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-15 14:10:05.556402: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2599900000 Hz
2024-02-15 14:10:07.391722: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 14:10:07.561660: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 14:10:08.330599: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-15 14:10:08.378537: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/166 [00:53<2:26:27, 53.26s/epoch, loss=3.6, accuracy=0.307, val_loss=2.73, val_accuracy=0.177, lr=0.1]  1%|          | 2/166 [01:15<1:35:52, 35.08s/epoch, loss=1.61, accuracy=0.524, val_loss=3.4, val_accuracy=0.266, lr=0.1]  2%|▏         | 3/166 [01:37<1:18:33, 28.92s/epoch, loss=1.38, accuracy=0.635, val_loss=2.38, val_accuracy=0.432, lr=0.1]  2%|▏         | 4/166 [01:57<1:09:16, 25.66s/epoch, loss=1.3, accuracy=0.676, val_loss=2.99, val_accuracy=0.329, lr=0.1]   3%|▎         | 5/166 [02:20<1:05:28, 24.40s/epoch, loss=1.26, accuracy=0.7, val_loss=1.77, val_accuracy=0.508, lr=0.1]   4%|▎         | 6/166 [02:41<1:02:40, 23.51s/epoch, loss=1.26, accuracy=0.708, val_loss=2.09, val_accuracy=0.542, lr=0.1]  4%|▍         | 7/166 [03:04<1:01:16, 23.12s/epoch, loss=1.24, accuracy=0.714, val_loss=2.46, val_accuracy=0.449, lr=0.1]  5%|▍         | 8/166 [03:26<1:00:02, 22.80s/epoch, loss=1.23, accuracy=0.72, val_loss=1.48, val_accuracy=0.633, lr=0.1]   5%|▌         | 9/166 [03:48<59:07, 22.59s/epoch, loss=1.22, accuracy=0.725, val_loss=1.82, val_accuracy=0.526, lr=0.1]   6%|▌         | 10/166 [04:10<58:26, 22.48s/epoch, loss=1.22, accuracy=0.726, val_loss=1.76, val_accuracy=0.576, lr=0.1]  7%|▋         | 11/166 [04:32<57:49, 22.38s/epoch, loss=1.22, accuracy=0.73, val_loss=3.57, val_accuracy=0.379, lr=0.1]   7%|▋         | 12/166 [04:54<56:51, 22.15s/epoch, loss=1.21, accuracy=0.733, val_loss=1.67, val_accuracy=0.589, lr=0.1]  8%|▊         | 13/166 [05:16<56:20, 22.09s/epoch, loss=1.21, accuracy=0.737, val_loss=2.92, val_accuracy=0.438, lr=0.0316]  8%|▊         | 14/166 [05:38<55:58, 22.09s/epoch, loss=1.21, accuracy=0.732, val_loss=1.66, val_accuracy=0.56, lr=0.1]      9%|▉         | 15/166 [06:00<55:19, 21.98s/epoch, loss=1.2, accuracy=0.738, val_loss=2.16, val_accuracy=0.452, lr=0.1] 10%|▉         | 16/166 [06:22<54:59, 22.00s/epoch, loss=1.2, accuracy=0.739, val_loss=1.65, val_accuracy=0.586, lr=0.1] 10%|█         | 17/166 [06:44<54:46, 22.05s/epoch, loss=1.19, accuracy=0.739, val_loss=1.63, val_accuracy=0.579, lr=0.1] 11%|█         | 18/166 [07:06<54:16, 22.01s/epoch, loss=1.19, accuracy=0.74, val_loss=1.69, val_accuracy=0.558, lr=0.0316] 11%|█▏        | 19/166 [07:28<53:53, 22.00s/epoch, loss=1.19, accuracy=0.74, val_loss=1.96, val_accuracy=0.503, lr=0.1]    12%|█▏        | 20/166 [07:50<53:29, 21.98s/epoch, loss=1.19, accuracy=0.743, val_loss=3.94, val_accuracy=0.305, lr=0.1] 13%|█▎        | 21/166 [08:10<52:06, 21.56s/epoch, loss=1.19, accuracy=0.742, val_loss=1.82, val_accuracy=0.526, lr=0.1] 13%|█▎        | 22/166 [08:31<51:20, 21.39s/epoch, loss=1.2, accuracy=0.74, val_loss=2.7, val_accuracy=0.382, lr=0.1]    14%|█▍        | 23/166 [08:53<51:32, 21.62s/epoch, loss=1.19, accuracy=0.741, val_loss=1.97, val_accuracy=0.535, lr=0.0316] 14%|█▍        | 24/166 [09:15<51:25, 21.73s/epoch, loss=1.19, accuracy=0.741, val_loss=2.63, val_accuracy=0.412, lr=0.1]    15%|█▌        | 25/166 [09:37<50:50, 21.63s/epoch, loss=1.19, accuracy=0.74, val_loss=2.9, val_accuracy=0.349, lr=0.1]   16%|█▌        | 26/166 [09:59<50:53, 21.81s/epoch, loss=1.18, accuracy=0.743, val_loss=2.99, val_accuracy=0.386, lr=0.1] 16%|█▋        | 27/166 [10:21<50:16, 21.70s/epoch, loss=1.18, accuracy=0.744, val_loss=2.17, val_accuracy=0.507, lr=0.1] 17%|█▋        | 28/166 [10:43<50:13, 21.84s/epoch, loss=1.18, accuracy=0.745, val_loss=3.03, val_accuracy=0.285, lr=0.0316] 17%|█▋        | 29/166 [11:04<49:40, 21.75s/epoch, loss=1.18, accuracy=0.745, val_loss=1.43, val_accuracy=0.654, lr=0.1]    18%|█▊        | 30/166 [11:27<49:40, 21.92s/epoch, loss=1.18, accuracy=0.743, val_loss=5.72, val_accuracy=0.236, lr=0.1] 19%|█▊        | 31/166 [11:49<49:29, 22.00s/epoch, loss=1.16, accuracy=0.748, val_loss=2.08, val_accuracy=0.527, lr=0.1] 19%|█▉        | 32/166 [12:11<49:15, 22.05s/epoch, loss=1.18, accuracy=0.744, val_loss=1.67, val_accuracy=0.542, lr=0.1] 20%|█▉        | 33/166 [12:32<48:14, 21.76s/epoch, loss=1.17, accuracy=0.747, val_loss=1.85, val_accuracy=0.569, lr=0.1] 20%|██        | 34/166 [12:54<48:06, 21.87s/epoch, loss=1.16, accuracy=0.748, val_loss=2.12, val_accuracy=0.525, lr=0.0316] 21%|██        | 35/166 [13:16<47:49, 21.90s/epoch, loss=1.17, accuracy=0.746, val_loss=2.32, val_accuracy=0.443, lr=0.1]    22%|██▏       | 36/166 [13:38<47:37, 21.98s/epoch, loss=1.17, accuracy=0.744, val_loss=4.21, val_accuracy=0.301, lr=0.1] 22%|██▏       | 37/166 [14:00<47:25, 22.06s/epoch, loss=1.17, accuracy=0.746, val_loss=1.9, val_accuracy=0.55, lr=0.1]   23%|██▎       | 38/166 [14:23<47:13, 22.14s/epoch, loss=1.17, accuracy=0.745, val_loss=2.49, val_accuracy=0.434, lr=0.1] 23%|██▎       | 39/166 [14:45<46:51, 22.14s/epoch, loss=1.17, accuracy=0.748, val_loss=1.97, val_accuracy=0.533, lr=0.0316] 24%|██▍       | 40/166 [15:06<46:05, 21.95s/epoch, loss=1.16, accuracy=0.749, val_loss=1.79, val_accuracy=0.52, lr=0.1]     25%|██▍       | 41/166 [15:28<45:26, 21.81s/epoch, loss=1.16, accuracy=0.751, val_loss=1.75, val_accuracy=0.528, lr=0.1] 25%|██▌       | 42/166 [15:50<45:22, 21.95s/epoch, loss=1.16, accuracy=0.747, val_loss=1.67, val_accuracy=0.587, lr=0.1] 26%|██▌       | 43/166 [16:11<44:02, 21.48s/epoch, loss=1.16, accuracy=0.75, val_loss=1.63, val_accuracy=0.594, lr=0.1]  27%|██▋       | 44/166 [16:31<43:09, 21.23s/epoch, loss=1.16, accuracy=0.75, val_loss=1.77, val_accuracy=0.547, lr=0.0316] 27%|██▋       | 45/166 [16:53<43:25, 21.53s/epoch, loss=1.16, accuracy=0.75, val_loss=4.33, val_accuracy=0.249, lr=0.1]    28%|██▊       | 46/166 [17:14<42:26, 21.22s/epoch, loss=1.17, accuracy=0.749, val_loss=1.65, val_accuracy=0.58, lr=0.1] 28%|██▊       | 47/166 [17:36<42:27, 21.41s/epoch, loss=1.16, accuracy=0.751, val_loss=2.41, val_accuracy=0.421, lr=0.1] 29%|██▉       | 48/166 [17:56<41:34, 21.14s/epoch, loss=1.16, accuracy=0.753, val_loss=2.32, val_accuracy=0.458, lr=0.1] 30%|██▉       | 49/166 [18:18<41:14, 21.15s/epoch, loss=1.16, accuracy=0.75, val_loss=2.11, val_accuracy=0.437, lr=0.0316] 30%|███       | 50/166 [18:40<41:27, 21.45s/epoch, loss=1.16, accuracy=0.751, val_loss=1.76, val_accuracy=0.558, lr=0.1]   31%|███       | 51/166 [19:02<41:31, 21.66s/epoch, loss=1.16, accuracy=0.75, val_loss=2.05, val_accuracy=0.455, lr=0.1]  31%|███▏      | 52/166 [19:23<40:50, 21.50s/epoch, loss=1.16, accuracy=0.749, val_loss=1.94, val_accuracy=0.518, lr=0.1] 32%|███▏      | 53/166 [19:44<40:20, 21.42s/epoch, loss=1.16, accuracy=0.753, val_loss=2.7, val_accuracy=0.408, lr=0.1]  33%|███▎      | 54/166 [20:06<40:02, 21.45s/epoch, loss=1.16, accuracy=0.749, val_loss=1.68, val_accuracy=0.558, lr=0.0316] 33%|███▎      | 55/166 [20:27<39:32, 21.37s/epoch, loss=1.15, accuracy=0.752, val_loss=1.6, val_accuracy=0.637, lr=0.1]     34%|███▎      | 56/166 [20:49<39:37, 21.61s/epoch, loss=1.16, accuracy=0.749, val_loss=1.62, val_accuracy=0.598, lr=0.1] 34%|███▍      | 57/166 [21:11<39:22, 21.68s/epoch, loss=1.16, accuracy=0.752, val_loss=2.22, val_accuracy=0.396, lr=0.1] 35%|███▍      | 58/166 [21:32<38:30, 21.39s/epoch, loss=1.15, accuracy=0.752, val_loss=1.79, val_accuracy=0.591, lr=0.1] 36%|███▌      | 59/166 [21:52<37:45, 21.18s/epoch, loss=1.15, accuracy=0.753, val_loss=2.09, val_accuracy=0.52, lr=0.0316] 36%|███▌      | 60/166 [22:15<38:00, 21.51s/epoch, loss=1.15, accuracy=0.752, val_loss=1.73, val_accuracy=0.572, lr=0.1]   37%|███▋      | 61/166 [22:37<37:54, 21.66s/epoch, loss=1.15, accuracy=0.754, val_loss=2.57, val_accuracy=0.447, lr=0.1] 37%|███▋      | 62/166 [22:59<37:50, 21.83s/epoch, loss=1.15, accuracy=0.755, val_loss=2.04, val_accuracy=0.501, lr=0.1] 38%|███▊      | 63/166 [23:19<36:47, 21.43s/epoch, loss=1.15, accuracy=0.752, val_loss=2.14, val_accuracy=0.522, lr=0.1] 39%|███▊      | 64/166 [23:41<36:43, 21.60s/epoch, loss=1.15, accuracy=0.754, val_loss=3.28, val_accuracy=0.399, lr=0.0316] 39%|███▉      | 65/166 [24:03<36:33, 21.72s/epoch, loss=1.15, accuracy=0.751, val_loss=3.6, val_accuracy=0.314, lr=0.1]     40%|███▉      | 66/166 [24:25<36:14, 21.75s/epoch, loss=1.15, accuracy=0.752, val_loss=2.23, val_accuracy=0.48, lr=0.1] 40%|████      | 67/166 [24:47<36:05, 21.87s/epoch, loss=1.14, accuracy=0.751, val_loss=2.11, val_accuracy=0.478, lr=0.1] 41%|████      | 68/166 [25:09<35:44, 21.88s/epoch, loss=1.15, accuracy=0.754, val_loss=1.62, val_accuracy=0.605, lr=0.1] 42%|████▏     | 69/166 [25:31<35:30, 21.97s/epoch, loss=1.15, accuracy=0.752, val_loss=1.77, val_accuracy=0.55, lr=0.0316] 42%|████▏     | 70/166 [25:53<34:54, 21.82s/epoch, loss=1.15, accuracy=0.751, val_loss=1.87, val_accuracy=0.556, lr=0.1]   43%|████▎     | 71/166 [26:13<33:50, 21.37s/epoch, loss=1.15, accuracy=0.751, val_loss=1.91, val_accuracy=0.535, lr=0.1] 43%|████▎     | 72/166 [26:34<33:05, 21.12s/epoch, loss=1.14, accuracy=0.754, val_loss=2.5, val_accuracy=0.472, lr=0.1]  44%|████▍     | 73/166 [26:56<33:13, 21.43s/epoch, loss=1.15, accuracy=0.754, val_loss=2.26, val_accuracy=0.428, lr=0.1] 45%|████▍     | 74/166 [27:16<32:24, 21.14s/epoch, loss=1.15, accuracy=0.751, val_loss=1.59, val_accuracy=0.618, lr=0.0316] 45%|████▌     | 75/166 [27:39<32:33, 21.47s/epoch, loss=1.14, accuracy=0.755, val_loss=2.41, val_accuracy=0.488, lr=0.1]    46%|████▌     | 76/166 [28:01<32:30, 21.67s/epoch, loss=1.15, accuracy=0.751, val_loss=1.7, val_accuracy=0.547, lr=0.1]  46%|████▋     | 77/166 [28:22<31:58, 21.56s/epoch, loss=1.13, accuracy=0.753, val_loss=1.59, val_accuracy=0.604, lr=0.1] 47%|████▋     | 78/166 [28:44<31:55, 21.77s/epoch, loss=1.14, accuracy=0.753, val_loss=1.85, val_accuracy=0.536, lr=0.1] 48%|████▊     | 79/166 [29:06<31:35, 21.79s/epoch, loss=1.14, accuracy=0.752, val_loss=1.53, val_accuracy=0.642, lr=0.0316] 48%|████▊     | 80/166 [29:28<31:19, 21.85s/epoch, loss=1.14, accuracy=0.755, val_loss=1.86, val_accuracy=0.539, lr=0.1]    49%|████▉     | 81/166 [29:50<31:04, 21.93s/epoch, loss=1.14, accuracy=0.754, val_loss=1.63, val_accuracy=0.593, lr=0.1] 49%|████▉     | 82/166 [30:12<30:37, 21.87s/epoch, loss=0.942, accuracy=0.81, val_loss=0.961, val_accuracy=0.783, lr=0.01] 50%|█████     | 83/166 [30:34<30:12, 21.84s/epoch, loss=0.751, accuracy=0.844, val_loss=0.839, val_accuracy=0.807, lr=0.01] 51%|█████     | 84/166 [30:56<29:58, 21.93s/epoch, loss=0.666, accuracy=0.852, val_loss=0.738, val_accuracy=0.818, lr=0.01] 51%|█████     | 85/166 [31:18<29:44, 22.03s/epoch, loss=0.619, accuracy=0.855, val_loss=0.816, val_accuracy=0.786, lr=0.01] 52%|█████▏    | 86/166 [31:39<28:46, 21.58s/epoch, loss=0.596, accuracy=0.859, val_loss=0.726, val_accuracy=0.81, lr=0.01]  52%|█████▏    | 87/166 [31:59<28:00, 21.27s/epoch, loss=0.587, accuracy=0.86, val_loss=0.85, val_accuracy=0.778, lr=0.01]  53%|█████▎    | 88/166 [32:20<27:39, 21.28s/epoch, loss=0.58, accuracy=0.861, val_loss=0.753, val_accuracy=0.811, lr=0.01] 54%|█████▎    | 89/166 [32:41<26:59, 21.03s/epoch, loss=0.574, accuracy=0.863, val_loss=0.803, val_accuracy=0.788, lr=0.01] 54%|█████▍    | 90/166 [33:03<27:03, 21.37s/epoch, loss=0.575, accuracy=0.864, val_loss=0.813, val_accuracy=0.793, lr=0.01] 55%|█████▍    | 91/166 [33:25<27:01, 21.62s/epoch, loss=0.571, accuracy=0.864, val_loss=0.743, val_accuracy=0.809, lr=0.00316] 55%|█████▌    | 92/166 [33:47<26:52, 21.80s/epoch, loss=0.569, accuracy=0.868, val_loss=0.928, val_accuracy=0.755, lr=0.01]    56%|█████▌    | 93/166 [34:08<26:02, 21.40s/epoch, loss=0.57, accuracy=0.868, val_loss=0.967, val_accuracy=0.733, lr=0.01]  57%|█████▋    | 94/166 [34:29<25:38, 21.37s/epoch, loss=0.57, accuracy=0.868, val_loss=0.832, val_accuracy=0.787, lr=0.01] 57%|█████▋    | 95/166 [34:51<25:23, 21.45s/epoch, loss=0.572, accuracy=0.869, val_loss=0.786, val_accuracy=0.797, lr=0.01] 58%|█████▊    | 96/166 [35:12<24:57, 21.39s/epoch, loss=0.566, accuracy=0.871, val_loss=0.673, val_accuracy=0.836, lr=0.01] 58%|█████▊    | 97/166 [35:34<24:46, 21.55s/epoch, loss=0.566, accuracy=0.872, val_loss=0.997, val_accuracy=0.743, lr=0.01] 59%|█████▉    | 98/166 [35:55<24:20, 21.47s/epoch, loss=0.568, accuracy=0.873, val_loss=0.861, val_accuracy=0.775, lr=0.01] 60%|█████▉    | 99/166 [36:18<24:15, 21.73s/epoch, loss=0.565, accuracy=0.874, val_loss=0.858, val_accuracy=0.777, lr=0.01] 60%|██████    | 100/166 [36:40<23:57, 21.78s/epoch, loss=0.564, accuracy=0.876, val_loss=0.885, val_accuracy=0.777, lr=0.01] 61%|██████    | 101/166 [37:02<23:45, 21.92s/epoch, loss=0.57, accuracy=0.872, val_loss=0.832, val_accuracy=0.786, lr=0.00316] 61%|██████▏   | 102/166 [37:24<23:28, 22.01s/epoch, loss=0.565, accuracy=0.877, val_loss=0.796, val_accuracy=0.8, lr=0.01]     62%|██████▏   | 103/166 [37:46<23:10, 22.07s/epoch, loss=0.565, accuracy=0.877, val_loss=0.941, val_accuracy=0.781, lr=0.01] 63%|██████▎   | 104/166 [38:08<22:49, 22.09s/epoch, loss=0.565, accuracy=0.877, val_loss=1.18, val_accuracy=0.694, lr=0.01]  63%|██████▎   | 105/166 [38:30<22:18, 21.94s/epoch, loss=0.564, accuracy=0.877, val_loss=0.804, val_accuracy=0.802, lr=0.01] 64%|██████▍   | 106/166 [38:50<21:28, 21.47s/epoch, loss=0.565, accuracy=0.878, val_loss=0.983, val_accuracy=0.768, lr=0.00316] 64%|██████▍   | 107/166 [39:11<20:49, 21.18s/epoch, loss=0.567, accuracy=0.876, val_loss=0.869, val_accuracy=0.786, lr=0.01]    65%|██████▌   | 108/166 [39:33<20:44, 21.45s/epoch, loss=0.566, accuracy=0.877, val_loss=0.968, val_accuracy=0.758, lr=0.01] 66%|██████▌   | 109/166 [39:55<20:33, 21.64s/epoch, loss=0.569, accuracy=0.877, val_loss=0.735, val_accuracy=0.827, lr=0.01] 66%|██████▋   | 110/166 [40:17<20:17, 21.75s/epoch, loss=0.562, accuracy=0.88, val_loss=0.784, val_accuracy=0.813, lr=0.01]  67%|██████▋   | 111/166 [40:39<19:57, 21.77s/epoch, loss=0.562, accuracy=0.88, val_loss=0.798, val_accuracy=0.811, lr=0.00316] 67%|██████▋   | 112/166 [41:01<19:41, 21.87s/epoch, loss=0.563, accuracy=0.881, val_loss=0.808, val_accuracy=0.808, lr=0.01]   68%|██████▊   | 113/166 [41:23<19:23, 21.95s/epoch, loss=0.562, accuracy=0.881, val_loss=0.987, val_accuracy=0.751, lr=0.01] 69%|██████▊   | 114/166 [41:45<18:55, 21.84s/epoch, loss=0.566, accuracy=0.88, val_loss=1.11, val_accuracy=0.734, lr=0.01]   69%|██████▉   | 115/166 [42:06<18:23, 21.63s/epoch, loss=0.569, accuracy=0.879, val_loss=0.729, val_accuracy=0.831, lr=0.01] 70%|██████▉   | 116/166 [42:27<18:00, 21.61s/epoch, loss=0.567, accuracy=0.88, val_loss=0.804, val_accuracy=0.809, lr=0.00316] 70%|███████   | 117/166 [42:49<17:44, 21.72s/epoch, loss=0.569, accuracy=0.88, val_loss=1.04, val_accuracy=0.756, lr=0.01]     71%|███████   | 118/166 [43:10<17:11, 21.49s/epoch, loss=0.565, accuracy=0.882, val_loss=1.17, val_accuracy=0.722, lr=0.01] 72%|███████▏  | 119/166 [43:32<16:55, 21.61s/epoch, loss=0.565, accuracy=0.882, val_loss=0.844, val_accuracy=0.795, lr=0.01] 72%|███████▏  | 120/166 [43:53<16:27, 21.47s/epoch, loss=0.566, accuracy=0.881, val_loss=0.908, val_accuracy=0.789, lr=0.01] 73%|███████▎  | 121/166 [44:15<16:02, 21.40s/epoch, loss=0.569, accuracy=0.881, val_loss=1.08, val_accuracy=0.739, lr=0.00316] 73%|███████▎  | 122/166 [44:37<15:51, 21.62s/epoch, loss=0.49, accuracy=0.91, val_loss=0.543, val_accuracy=0.888, lr=0.001]    74%|███████▍  | 123/166 [44:57<15:13, 21.24s/epoch, loss=0.437, accuracy=0.926, val_loss=0.525, val_accuracy=0.895, lr=0.001] 75%|███████▍  | 124/166 [45:19<15:00, 21.45s/epoch, loss=0.412, accuracy=0.932, val_loss=0.517, val_accuracy=0.894, lr=0.001] 75%|███████▌  | 125/166 [45:41<14:47, 21.66s/epoch, loss=0.402, accuracy=0.933, val_loss=0.508, val_accuracy=0.896, lr=0.001] 76%|███████▌  | 126/166 [46:03<14:32, 21.82s/epoch, loss=0.383, accuracy=0.937, val_loss=0.501, val_accuracy=0.897, lr=0.001] 77%|███████▋  | 127/166 [46:24<13:58, 21.49s/epoch, loss=0.367, accuracy=0.942, val_loss=0.495, val_accuracy=0.9, lr=0.001]   77%|███████▋  | 128/166 [46:44<13:23, 21.15s/epoch, loss=0.359, accuracy=0.943, val_loss=0.487, val_accuracy=0.899, lr=0.001] 78%|███████▊  | 129/166 [47:05<13:00, 21.09s/epoch, loss=0.348, accuracy=0.945, val_loss=0.481, val_accuracy=0.901, lr=0.001] 78%|███████▊  | 130/166 [47:28<12:50, 21.41s/epoch, loss=0.338, accuracy=0.946, val_loss=0.484, val_accuracy=0.899, lr=0.001] 79%|███████▉  | 131/166 [47:48<12:18, 21.10s/epoch, loss=0.33, accuracy=0.947, val_loss=0.489, val_accuracy=0.898, lr=0.001]  80%|███████▉  | 132/166 [48:10<12:08, 21.42s/epoch, loss=0.324, accuracy=0.947, val_loss=0.475, val_accuracy=0.902, lr=0.001] 80%|████████  | 133/166 [48:32<11:53, 21.63s/epoch, loss=0.314, accuracy=0.951, val_loss=0.473, val_accuracy=0.9, lr=0.001]   81%|████████  | 134/166 [48:54<11:37, 21.78s/epoch, loss=0.307, accuracy=0.951, val_loss=0.472, val_accuracy=0.901, lr=0.001] 81%|████████▏ | 135/166 [49:16<11:17, 21.85s/epoch, loss=0.302, accuracy=0.951, val_loss=0.487, val_accuracy=0.896, lr=0.001] 82%|████████▏ | 136/166 [49:38<10:52, 21.76s/epoch, loss=0.295, accuracy=0.952, val_loss=0.472, val_accuracy=0.899, lr=0.001] 83%|████████▎ | 137/166 [49:59<10:27, 21.62s/epoch, loss=0.287, accuracy=0.954, val_loss=0.467, val_accuracy=0.898, lr=0.001] 83%|████████▎ | 138/166 [50:21<10:10, 21.79s/epoch, loss=0.281, accuracy=0.954, val_loss=0.452, val_accuracy=0.902, lr=0.001] 84%|████████▎ | 139/166 [50:44<09:51, 21.89s/epoch, loss=0.277, accuracy=0.955, val_loss=0.481, val_accuracy=0.891, lr=0.001] 84%|████████▍ | 140/166 [51:06<09:31, 21.97s/epoch, loss=0.272, accuracy=0.956, val_loss=0.473, val_accuracy=0.896, lr=0.001] 85%|████████▍ | 141/166 [51:26<08:56, 21.47s/epoch, loss=0.264, accuracy=0.957, val_loss=0.473, val_accuracy=0.895, lr=0.001] 86%|████████▌ | 142/166 [51:48<08:39, 21.64s/epoch, loss=0.262, accuracy=0.956, val_loss=0.495, val_accuracy=0.888, lr=0.001] 86%|████████▌ | 143/166 [52:09<08:11, 21.39s/epoch, loss=0.26, accuracy=0.956, val_loss=0.506, val_accuracy=0.884, lr=0.000316] 87%|████████▋ | 144/166 [52:30<07:51, 21.42s/epoch, loss=0.253, accuracy=0.959, val_loss=0.501, val_accuracy=0.891, lr=0.001]   87%|████████▋ | 145/166 [52:52<07:34, 21.64s/epoch, loss=0.252, accuracy=0.958, val_loss=0.519, val_accuracy=0.888, lr=0.001] 88%|████████▊ | 146/166 [53:13<07:04, 21.25s/epoch, loss=0.245, accuracy=0.959, val_loss=0.488, val_accuracy=0.894, lr=0.001] 89%|████████▊ | 147/166 [53:35<06:48, 21.48s/epoch, loss=0.245, accuracy=0.959, val_loss=0.487, val_accuracy=0.888, lr=0.001] 89%|████████▉ | 148/166 [53:57<06:29, 21.61s/epoch, loss=0.24, accuracy=0.959, val_loss=0.49, val_accuracy=0.891, lr=0.000316] 90%|████████▉ | 149/166 [54:18<06:07, 21.60s/epoch, loss=0.24, accuracy=0.959, val_loss=0.503, val_accuracy=0.889, lr=0.001]   90%|█████████ | 150/166 [54:40<05:46, 21.67s/epoch, loss=0.237, accuracy=0.959, val_loss=0.464, val_accuracy=0.892, lr=0.001] 91%|█████████ | 151/166 [55:02<05:26, 21.76s/epoch, loss=0.233, accuracy=0.96, val_loss=0.501, val_accuracy=0.882, lr=0.001]  92%|█████████▏| 152/166 [55:24<05:03, 21.67s/epoch, loss=0.232, accuracy=0.96, val_loss=0.486, val_accuracy=0.889, lr=0.001] 92%|█████████▏| 153/166 [55:45<04:39, 21.49s/epoch, loss=0.229, accuracy=0.961, val_loss=0.461, val_accuracy=0.89, lr=0.000316] 93%|█████████▎| 154/166 [56:06<04:17, 21.45s/epoch, loss=0.227, accuracy=0.96, val_loss=0.539, val_accuracy=0.879, lr=0.001]    93%|█████████▎| 155/166 [56:27<03:53, 21.27s/epoch, loss=0.228, accuracy=0.961, val_loss=0.484, val_accuracy=0.887, lr=0.001] 94%|█████████▍| 156/166 [56:49<03:34, 21.43s/epoch, loss=0.228, accuracy=0.959, val_loss=0.46, val_accuracy=0.893, lr=0.001]  95%|█████████▍| 157/166 [57:11<03:14, 21.57s/epoch, loss=0.223, accuracy=0.96, val_loss=0.481, val_accuracy=0.887, lr=0.001] 95%|█████████▌| 158/166 [57:33<02:53, 21.70s/epoch, loss=0.224, accuracy=0.959, val_loss=0.48, val_accuracy=0.889, lr=0.000316] 96%|█████████▌| 159/166 [57:54<02:32, 21.77s/epoch, loss=0.225, accuracy=0.959, val_loss=0.5, val_accuracy=0.881, lr=0.001]     96%|█████████▋| 160/166 [58:16<02:11, 21.84s/epoch, loss=0.224, accuracy=0.96, val_loss=0.529, val_accuracy=0.875, lr=0.001] 97%|█████████▋| 161/166 [58:38<01:48, 21.80s/epoch, loss=0.222, accuracy=0.96, val_loss=0.486, val_accuracy=0.881, lr=0.001] 98%|█████████▊| 162/166 [59:00<01:26, 21.70s/epoch, loss=0.201, accuracy=0.969, val_loss=0.413, val_accuracy=0.906, lr=1e-04] 98%|█████████▊| 163/166 [59:21<01:04, 21.45s/epoch, loss=0.188, accuracy=0.974, val_loss=0.406, val_accuracy=0.907, lr=1e-04] 99%|█████████▉| 164/166 [59:43<00:43, 21.61s/epoch, loss=0.181, accuracy=0.976, val_loss=0.407, val_accuracy=0.91, lr=1e-04]  99%|█████████▉| 165/166 [1:00:04<00:21, 21.67s/epoch, loss=0.18, accuracy=0.976, val_loss=0.403, val_accuracy=0.91, lr=1e-04]100%|██████████| 166/166 [1:00:26<00:00, 21.65s/epoch, loss=0.175, accuracy=0.978, val_loss=0.407, val_accuracy=0.908, lr=1e-04]100%|██████████| 166/166 [1:00:26<00:00, 21.85s/epoch, loss=0.175, accuracy=0.978, val_loss=0.407, val_accuracy=0.908, lr=1e-04]
Using real-time data augmentation.
Test loss: 0.4070996046066284
Test accuracy: 0.9083999991416931


* * * Run SGD for ID = 9_5. * * *


2024-02-15 15:10:35.749052: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 15:10:40.971357: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 15:10:40.972549: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-15 15:10:41.009563: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-15 15:10:41.009597: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 15:10:41.012473: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 15:10:41.012511: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 15:10:41.014867: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 15:10:41.015615: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 15:10:41.018055: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 15:10:41.019453: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 15:10:41.024119: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 15:10:41.024661: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 15:10:41.024740: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 15:10:42.263956: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-15 15:10:42.264538: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 15:10:42.265186: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-15 15:10:42.265223: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 15:10:42.265274: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 15:10:42.265341: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 15:10:42.265362: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 15:10:42.265379: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 15:10:42.265397: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 15:10:42.265415: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 15:10:42.265433: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 15:10:42.265869: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 15:10:42.265900: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 15:10:42.874502: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-15 15:10:42.874573: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-15 15:10:42.874604: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-15 15:10:42.875491: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': 95, 'batch_size': 128, 'epochs': 166, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/166 [00:00<?, ?epoch/s]2024-02-15 15:10:43.627157: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-15 15:10:43.639397: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2599900000 Hz
2024-02-15 15:10:45.445616: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 15:10:45.626739: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 15:10:46.525996: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-15 15:10:46.576092: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/166 [00:54<2:28:52, 54.13s/epoch, loss=3.39, accuracy=0.285, val_loss=2.98, val_accuracy=0.149, lr=0.1]  1%|          | 2/166 [01:16<1:37:27, 35.66s/epoch, loss=1.62, accuracy=0.51, val_loss=1.91, val_accuracy=0.427, lr=0.1]   2%|▏         | 3/166 [01:39<1:20:56, 29.79s/epoch, loss=1.45, accuracy=0.589, val_loss=1.7, val_accuracy=0.506, lr=0.1]  2%|▏         | 4/166 [02:02<1:12:36, 26.89s/epoch, loss=1.41, accuracy=0.619, val_loss=1.95, val_accuracy=0.461, lr=0.1]  3%|▎         | 5/166 [02:24<1:08:02, 25.36s/epoch, loss=1.36, accuracy=0.653, val_loss=1.89, val_accuracy=0.519, lr=0.1]  4%|▎         | 6/166 [02:47<1:05:03, 24.40s/epoch, loss=1.32, accuracy=0.673, val_loss=2.2, val_accuracy=0.407, lr=0.1]   4%|▍         | 7/166 [03:09<1:03:03, 23.79s/epoch, loss=1.29, accuracy=0.693, val_loss=1.99, val_accuracy=0.465, lr=0.1]  5%|▍         | 8/166 [03:32<1:01:33, 23.38s/epoch, loss=1.26, accuracy=0.701, val_loss=2.11, val_accuracy=0.479, lr=0.0316]  5%|▌         | 9/166 [03:54<1:00:25, 23.10s/epoch, loss=1.25, accuracy=0.712, val_loss=1.59, val_accuracy=0.604, lr=0.1]     6%|▌         | 10/166 [04:17<59:42, 22.96s/epoch, loss=1.24, accuracy=0.712, val_loss=1.66, val_accuracy=0.566, lr=0.1]   7%|▋         | 11/166 [04:39<58:43, 22.73s/epoch, loss=1.23, accuracy=0.719, val_loss=2.38, val_accuracy=0.507, lr=0.1]  7%|▋         | 12/166 [05:02<58:08, 22.65s/epoch, loss=1.23, accuracy=0.723, val_loss=1.66, val_accuracy=0.571, lr=0.1]  8%|▊         | 13/166 [05:24<57:31, 22.56s/epoch, loss=1.21, accuracy=0.727, val_loss=1.61, val_accuracy=0.604, lr=0.1]  8%|▊         | 14/166 [05:46<57:05, 22.54s/epoch, loss=1.21, accuracy=0.729, val_loss=2.32, val_accuracy=0.434, lr=0.0316]  9%|▉         | 15/166 [06:09<56:47, 22.57s/epoch, loss=1.2, accuracy=0.732, val_loss=1.5, val_accuracy=0.627, lr=0.1]      10%|▉         | 16/166 [06:32<56:23, 22.55s/epoch, loss=1.2, accuracy=0.737, val_loss=1.59, val_accuracy=0.621, lr=0.1] 10%|█         | 17/166 [06:53<55:21, 22.29s/epoch, loss=1.19, accuracy=0.735, val_loss=1.98, val_accuracy=0.458, lr=0.1] 11%|█         | 18/166 [07:16<55:05, 22.34s/epoch, loss=1.18, accuracy=0.736, val_loss=1.62, val_accuracy=0.592, lr=0.1] 11%|█▏        | 19/166 [07:37<53:58, 22.03s/epoch, loss=1.18, accuracy=0.738, val_loss=1.76, val_accuracy=0.54, lr=0.1]  12%|█▏        | 20/166 [07:59<53:48, 22.11s/epoch, loss=1.18, accuracy=0.738, val_loss=1.95, val_accuracy=0.507, lr=0.0316] 13%|█▎        | 21/166 [08:22<53:43, 22.23s/epoch, loss=1.18, accuracy=0.738, val_loss=1.52, val_accuracy=0.62, lr=0.1]     13%|█▎        | 22/166 [08:44<53:21, 22.23s/epoch, loss=1.18, accuracy=0.738, val_loss=2.3, val_accuracy=0.436, lr=0.1] 14%|█▍        | 23/166 [09:06<52:59, 22.23s/epoch, loss=1.17, accuracy=0.741, val_loss=1.84, val_accuracy=0.537, lr=0.1] 14%|█▍        | 24/166 [09:29<52:46, 22.30s/epoch, loss=1.17, accuracy=0.743, val_loss=2.47, val_accuracy=0.409, lr=0.1] 15%|█▌        | 25/166 [09:51<52:25, 22.31s/epoch, loss=1.17, accuracy=0.741, val_loss=1.76, val_accuracy=0.582, lr=0.0316] 16%|█▌        | 26/166 [10:12<50:59, 21.85s/epoch, loss=1.17, accuracy=0.739, val_loss=1.53, val_accuracy=0.621, lr=0.1]    16%|█▋        | 27/166 [10:34<50:57, 21.99s/epoch, loss=1.16, accuracy=0.746, val_loss=1.54, val_accuracy=0.604, lr=0.1] 17%|█▋        | 28/166 [10:57<50:56, 22.15s/epoch, loss=1.16, accuracy=0.746, val_loss=2.35, val_accuracy=0.412, lr=0.1] 17%|█▋        | 29/166 [11:19<50:48, 22.25s/epoch, loss=1.16, accuracy=0.744, val_loss=1.72, val_accuracy=0.542, lr=0.1] 18%|█▊        | 30/166 [11:42<50:27, 22.26s/epoch, loss=1.15, accuracy=0.746, val_loss=1.86, val_accuracy=0.544, lr=0.0316] 19%|█▊        | 31/166 [12:04<50:08, 22.28s/epoch, loss=1.16, accuracy=0.747, val_loss=2.28, val_accuracy=0.468, lr=0.1]    19%|█▉        | 32/166 [12:25<49:04, 21.98s/epoch, loss=1.16, accuracy=0.743, val_loss=1.66, val_accuracy=0.58, lr=0.1]  20%|█▉        | 33/166 [12:47<48:40, 21.96s/epoch, loss=1.15, accuracy=0.746, val_loss=1.73, val_accuracy=0.625, lr=0.1] 20%|██        | 34/166 [13:09<48:36, 22.10s/epoch, loss=1.15, accuracy=0.75, val_loss=1.79, val_accuracy=0.573, lr=0.1]  21%|██        | 35/166 [13:32<48:19, 22.14s/epoch, loss=1.15, accuracy=0.746, val_loss=2.18, val_accuracy=0.411, lr=0.0316] 22%|██▏       | 36/166 [13:54<48:15, 22.27s/epoch, loss=1.15, accuracy=0.747, val_loss=2, val_accuracy=0.51, lr=0.1]        22%|██▏       | 37/166 [14:15<46:52, 21.80s/epoch, loss=1.15, accuracy=0.749, val_loss=1.73, val_accuracy=0.594, lr=0.1] 23%|██▎       | 38/166 [14:37<46:26, 21.77s/epoch, loss=1.14, accuracy=0.748, val_loss=1.83, val_accuracy=0.584, lr=0.1] 23%|██▎       | 39/166 [14:58<45:41, 21.58s/epoch, loss=1.15, accuracy=0.749, val_loss=1.43, val_accuracy=0.651, lr=0.1] 24%|██▍       | 40/166 [15:20<46:00, 21.91s/epoch, loss=1.15, accuracy=0.747, val_loss=1.99, val_accuracy=0.5, lr=0.1]   25%|██▍       | 41/166 [15:43<46:02, 22.10s/epoch, loss=1.15, accuracy=0.751, val_loss=2.52, val_accuracy=0.467, lr=0.1] 25%|██▌       | 42/166 [16:05<45:45, 22.14s/epoch, loss=1.15, accuracy=0.749, val_loss=1.78, val_accuracy=0.595, lr=0.1] 26%|██▌       | 43/166 [16:28<45:29, 22.19s/epoch, loss=1.15, accuracy=0.75, val_loss=1.49, val_accuracy=0.644, lr=0.1]  27%|██▋       | 44/166 [16:48<44:13, 21.75s/epoch, loss=1.14, accuracy=0.751, val_loss=1.81, val_accuracy=0.546, lr=0.0316] 27%|██▋       | 45/166 [17:11<44:09, 21.90s/epoch, loss=1.15, accuracy=0.75, val_loss=1.33, val_accuracy=0.692, lr=0.1]     28%|██▊       | 46/166 [17:31<43:07, 21.56s/epoch, loss=1.14, accuracy=0.75, val_loss=1.7, val_accuracy=0.545, lr=0.1]  28%|██▊       | 47/166 [17:54<43:19, 21.85s/epoch, loss=1.14, accuracy=0.75, val_loss=1.82, val_accuracy=0.555, lr=0.1] 29%|██▉       | 48/166 [18:16<43:18, 22.02s/epoch, loss=1.14, accuracy=0.752, val_loss=2.24, val_accuracy=0.488, lr=0.1] 30%|██▉       | 49/166 [18:39<43:17, 22.21s/epoch, loss=1.14, accuracy=0.751, val_loss=1.86, val_accuracy=0.563, lr=0.1] 30%|███       | 50/166 [19:01<43:05, 22.29s/epoch, loss=1.15, accuracy=0.75, val_loss=1.9, val_accuracy=0.494, lr=0.0316] 31%|███       | 51/166 [19:24<42:53, 22.38s/epoch, loss=1.14, accuracy=0.751, val_loss=3.2, val_accuracy=0.406, lr=0.1]   31%|███▏      | 52/166 [19:47<42:36, 22.43s/epoch, loss=1.15, accuracy=0.75, val_loss=1.54, val_accuracy=0.611, lr=0.1] 32%|███▏      | 53/166 [20:09<42:11, 22.40s/epoch, loss=1.14, accuracy=0.75, val_loss=2.54, val_accuracy=0.423, lr=0.1] 33%|███▎      | 54/166 [20:31<41:56, 22.47s/epoch, loss=1.14, accuracy=0.752, val_loss=2.06, val_accuracy=0.45, lr=0.1] 33%|███▎      | 55/166 [20:53<41:09, 22.25s/epoch, loss=1.14, accuracy=0.754, val_loss=2.59, val_accuracy=0.419, lr=0.0316] 34%|███▎      | 56/166 [21:15<40:37, 22.16s/epoch, loss=1.14, accuracy=0.751, val_loss=1.66, val_accuracy=0.585, lr=0.1]    34%|███▍      | 57/166 [21:37<40:10, 22.12s/epoch, loss=1.13, accuracy=0.754, val_loss=1.55, val_accuracy=0.6, lr=0.1]   35%|███▍      | 58/166 [21:59<39:22, 21.88s/epoch, loss=1.13, accuracy=0.753, val_loss=1.33, val_accuracy=0.68, lr=0.1] 36%|███▌      | 59/166 [22:20<38:35, 21.64s/epoch, loss=1.13, accuracy=0.752, val_loss=1.9, val_accuracy=0.528, lr=0.1] 36%|███▌      | 60/166 [22:42<38:34, 21.83s/epoch, loss=1.14, accuracy=0.751, val_loss=1.86, val_accuracy=0.568, lr=0.1] 37%|███▋      | 61/166 [23:04<38:17, 21.88s/epoch, loss=1.13, accuracy=0.753, val_loss=5.79, val_accuracy=0.278, lr=0.1] 37%|███▋      | 62/166 [23:25<37:17, 21.52s/epoch, loss=1.14, accuracy=0.752, val_loss=1.97, val_accuracy=0.508, lr=0.1] 38%|███▊      | 63/166 [23:47<37:11, 21.66s/epoch, loss=1.13, accuracy=0.752, val_loss=2.34, val_accuracy=0.49, lr=0.0316] 39%|███▊      | 64/166 [24:07<36:18, 21.36s/epoch, loss=1.12, accuracy=0.755, val_loss=2.21, val_accuracy=0.517, lr=0.1]   39%|███▉      | 65/166 [24:30<36:30, 21.69s/epoch, loss=1.13, accuracy=0.754, val_loss=1.57, val_accuracy=0.605, lr=0.1] 40%|███▉      | 66/166 [24:50<35:35, 21.35s/epoch, loss=1.14, accuracy=0.754, val_loss=1.64, val_accuracy=0.585, lr=0.1] 40%|████      | 67/166 [25:11<34:50, 21.12s/epoch, loss=1.13, accuracy=0.755, val_loss=3.58, val_accuracy=0.337, lr=0.1] 41%|████      | 68/166 [25:31<34:15, 20.98s/epoch, loss=1.13, accuracy=0.753, val_loss=1.54, val_accuracy=0.606, lr=0.0316] 42%|████▏     | 69/166 [25:54<34:37, 21.42s/epoch, loss=1.13, accuracy=0.755, val_loss=1.66, val_accuracy=0.563, lr=0.1]    42%|████▏     | 70/166 [26:15<34:20, 21.47s/epoch, loss=1.13, accuracy=0.754, val_loss=1.7, val_accuracy=0.593, lr=0.1]  43%|████▎     | 71/166 [26:37<34:14, 21.63s/epoch, loss=1.13, accuracy=0.754, val_loss=2.27, val_accuracy=0.438, lr=0.1] 43%|████▎     | 72/166 [27:00<34:06, 21.77s/epoch, loss=1.13, accuracy=0.755, val_loss=2.89, val_accuracy=0.375, lr=0.1] 44%|████▍     | 73/166 [27:22<33:51, 21.84s/epoch, loss=1.12, accuracy=0.757, val_loss=4.05, val_accuracy=0.411, lr=0.0316] 45%|████▍     | 74/166 [27:44<33:31, 21.87s/epoch, loss=1.13, accuracy=0.754, val_loss=1.94, val_accuracy=0.557, lr=0.1]    45%|████▌     | 75/166 [28:06<33:14, 21.92s/epoch, loss=1.13, accuracy=0.755, val_loss=1.99, val_accuracy=0.537, lr=0.1] 46%|████▌     | 76/166 [28:27<32:53, 21.93s/epoch, loss=1.13, accuracy=0.754, val_loss=1.66, val_accuracy=0.627, lr=0.1] 46%|████▋     | 77/166 [28:49<32:19, 21.79s/epoch, loss=1.12, accuracy=0.754, val_loss=3.66, val_accuracy=0.318, lr=0.1] 47%|████▋     | 78/166 [29:11<32:06, 21.90s/epoch, loss=1.13, accuracy=0.757, val_loss=1.9, val_accuracy=0.569, lr=0.0316] 48%|████▊     | 79/166 [29:33<31:46, 21.92s/epoch, loss=1.13, accuracy=0.751, val_loss=2.52, val_accuracy=0.502, lr=0.1]   48%|████▊     | 80/166 [29:55<31:24, 21.92s/epoch, loss=1.13, accuracy=0.757, val_loss=1.54, val_accuracy=0.629, lr=0.1] 49%|████▉     | 81/166 [30:17<31:09, 21.99s/epoch, loss=1.13, accuracy=0.755, val_loss=1.93, val_accuracy=0.514, lr=0.1] 49%|████▉     | 82/166 [30:38<30:11, 21.56s/epoch, loss=0.913, accuracy=0.812, val_loss=0.978, val_accuracy=0.769, lr=0.01] 50%|█████     | 83/166 [30:59<29:47, 21.53s/epoch, loss=0.738, accuracy=0.844, val_loss=0.815, val_accuracy=0.807, lr=0.01] 51%|█████     | 84/166 [31:21<29:39, 21.70s/epoch, loss=0.656, accuracy=0.854, val_loss=0.802, val_accuracy=0.797, lr=0.01] 51%|█████     | 85/166 [31:43<29:25, 21.80s/epoch, loss=0.611, accuracy=0.856, val_loss=0.815, val_accuracy=0.788, lr=0.01] 52%|█████▏    | 86/166 [32:06<29:15, 21.95s/epoch, loss=0.591, accuracy=0.858, val_loss=0.994, val_accuracy=0.753, lr=0.01] 52%|█████▏    | 87/166 [32:28<28:56, 21.99s/epoch, loss=0.581, accuracy=0.86, val_loss=1.01, val_accuracy=0.74, lr=0.01]    53%|█████▎    | 88/166 [32:49<28:27, 21.89s/epoch, loss=0.573, accuracy=0.861, val_loss=0.737, val_accuracy=0.81, lr=0.01] 54%|█████▎    | 89/166 [33:11<27:50, 21.70s/epoch, loss=0.569, accuracy=0.865, val_loss=0.757, val_accuracy=0.805, lr=0.01] 54%|█████▍    | 90/166 [33:33<27:40, 21.85s/epoch, loss=0.569, accuracy=0.863, val_loss=0.899, val_accuracy=0.772, lr=0.01] 55%|█████▍    | 91/166 [33:55<27:24, 21.93s/epoch, loss=0.57, accuracy=0.865, val_loss=0.942, val_accuracy=0.768, lr=0.01]  55%|█████▌    | 92/166 [34:15<26:31, 21.50s/epoch, loss=0.57, accuracy=0.864, val_loss=0.807, val_accuracy=0.792, lr=0.01] 56%|█████▌    | 93/166 [34:37<26:21, 21.66s/epoch, loss=0.565, accuracy=0.868, val_loss=0.741, val_accuracy=0.816, lr=0.00316] 57%|█████▋    | 94/166 [34:59<25:53, 21.58s/epoch, loss=0.562, accuracy=0.869, val_loss=0.707, val_accuracy=0.823, lr=0.01]    57%|█████▋    | 95/166 [35:20<25:27, 21.51s/epoch, loss=0.56, accuracy=0.87, val_loss=0.817, val_accuracy=0.802, lr=0.01]   58%|█████▊    | 96/166 [35:42<25:21, 21.73s/epoch, loss=0.561, accuracy=0.872, val_loss=0.902, val_accuracy=0.757, lr=0.01] 58%|█████▊    | 97/166 [36:05<25:07, 21.85s/epoch, loss=0.555, accuracy=0.874, val_loss=0.817, val_accuracy=0.798, lr=0.01] 59%|█████▉    | 98/166 [36:26<24:35, 21.70s/epoch, loss=0.562, accuracy=0.871, val_loss=0.713, val_accuracy=0.823, lr=0.01] 60%|█████▉    | 99/166 [36:48<24:12, 21.68s/epoch, loss=0.564, accuracy=0.872, val_loss=0.814, val_accuracy=0.79, lr=0.00316] 60%|██████    | 100/166 [37:08<23:29, 21.35s/epoch, loss=0.557, accuracy=0.876, val_loss=0.893, val_accuracy=0.765, lr=0.01]  61%|██████    | 101/166 [37:29<23:05, 21.31s/epoch, loss=0.554, accuracy=0.877, val_loss=0.883, val_accuracy=0.781, lr=0.01] 61%|██████▏   | 102/166 [37:51<22:58, 21.54s/epoch, loss=0.56, accuracy=0.876, val_loss=0.819, val_accuracy=0.798, lr=0.01]  62%|██████▏   | 103/166 [38:13<22:47, 21.70s/epoch, loss=0.558, accuracy=0.877, val_loss=1.08, val_accuracy=0.717, lr=0.01] 63%|██████▎   | 104/166 [38:36<22:32, 21.81s/epoch, loss=0.557, accuracy=0.876, val_loss=0.818, val_accuracy=0.799, lr=0.00316] 63%|██████▎   | 105/166 [38:56<21:47, 21.43s/epoch, loss=0.558, accuracy=0.877, val_loss=0.809, val_accuracy=0.806, lr=0.01]    64%|██████▍   | 106/166 [39:18<21:33, 21.55s/epoch, loss=0.562, accuracy=0.878, val_loss=1.12, val_accuracy=0.722, lr=0.01]  64%|██████▍   | 107/166 [39:39<20:57, 21.31s/epoch, loss=0.554, accuracy=0.88, val_loss=0.87, val_accuracy=0.788, lr=0.01]  65%|██████▌   | 108/166 [40:00<20:28, 21.18s/epoch, loss=0.559, accuracy=0.877, val_loss=0.896, val_accuracy=0.767, lr=0.01] 66%|██████▌   | 109/166 [40:21<20:08, 21.21s/epoch, loss=0.562, accuracy=0.876, val_loss=0.834, val_accuracy=0.795, lr=0.00316] 66%|██████▋   | 110/166 [40:43<19:55, 21.35s/epoch, loss=0.559, accuracy=0.877, val_loss=0.99, val_accuracy=0.753, lr=0.01]     67%|██████▋   | 111/166 [41:04<19:36, 21.39s/epoch, loss=0.56, accuracy=0.88, val_loss=0.919, val_accuracy=0.765, lr=0.01]  67%|██████▋   | 112/166 [41:26<19:18, 21.45s/epoch, loss=0.556, accuracy=0.879, val_loss=0.738, val_accuracy=0.823, lr=0.01] 68%|██████▊   | 113/166 [41:47<18:59, 21.51s/epoch, loss=0.555, accuracy=0.881, val_loss=0.803, val_accuracy=0.801, lr=0.01] 69%|██████▊   | 114/166 [42:09<18:48, 21.70s/epoch, loss=0.554, accuracy=0.881, val_loss=1.08, val_accuracy=0.738, lr=0.00316] 69%|██████▉   | 115/166 [42:31<18:30, 21.78s/epoch, loss=0.557, accuracy=0.879, val_loss=1.01, val_accuracy=0.739, lr=0.01]    70%|██████▉   | 116/166 [42:52<17:58, 21.58s/epoch, loss=0.557, accuracy=0.88, val_loss=0.834, val_accuracy=0.796, lr=0.01] 70%|███████   | 117/166 [43:14<17:43, 21.71s/epoch, loss=0.557, accuracy=0.881, val_loss=0.934, val_accuracy=0.768, lr=0.01] 71%|███████   | 118/166 [43:36<17:25, 21.78s/epoch, loss=0.558, accuracy=0.88, val_loss=0.754, val_accuracy=0.812, lr=0.01]  72%|███████▏  | 119/166 [43:58<17:05, 21.81s/epoch, loss=0.554, accuracy=0.883, val_loss=0.761, val_accuracy=0.814, lr=0.00316] 72%|███████▏  | 120/166 [44:21<16:48, 21.93s/epoch, loss=0.558, accuracy=0.882, val_loss=1.08, val_accuracy=0.727, lr=0.01]     73%|███████▎  | 121/166 [44:42<16:26, 21.92s/epoch, loss=0.557, accuracy=0.881, val_loss=0.953, val_accuracy=0.767, lr=0.01] 73%|███████▎  | 122/166 [45:04<16:00, 21.83s/epoch, loss=0.484, accuracy=0.907, val_loss=0.54, val_accuracy=0.887, lr=0.001] 74%|███████▍  | 123/166 [45:24<15:20, 21.41s/epoch, loss=0.431, accuracy=0.924, val_loss=0.524, val_accuracy=0.892, lr=0.001] 75%|███████▍  | 124/166 [45:46<15:04, 21.54s/epoch, loss=0.41, accuracy=0.93, val_loss=0.521, val_accuracy=0.891, lr=0.001]   75%|███████▌  | 125/166 [46:09<14:52, 21.76s/epoch, loss=0.393, accuracy=0.934, val_loss=0.504, val_accuracy=0.896, lr=0.001] 76%|███████▌  | 126/166 [46:31<14:37, 21.94s/epoch, loss=0.377, accuracy=0.937, val_loss=0.497, val_accuracy=0.896, lr=0.001] 77%|███████▋  | 127/166 [46:52<14:02, 21.61s/epoch, loss=0.364, accuracy=0.941, val_loss=0.5, val_accuracy=0.894, lr=0.001]   77%|███████▋  | 128/166 [47:13<13:39, 21.58s/epoch, loss=0.356, accuracy=0.941, val_loss=0.489, val_accuracy=0.898, lr=0.001] 78%|███████▊  | 129/166 [47:35<13:23, 21.71s/epoch, loss=0.349, accuracy=0.941, val_loss=0.488, val_accuracy=0.896, lr=0.001] 78%|███████▊  | 130/166 [47:57<12:58, 21.63s/epoch, loss=0.335, accuracy=0.945, val_loss=0.481, val_accuracy=0.897, lr=0.001] 79%|███████▉  | 131/166 [48:19<12:41, 21.77s/epoch, loss=0.329, accuracy=0.946, val_loss=0.481, val_accuracy=0.895, lr=0.001] 80%|███████▉  | 132/166 [48:39<12:06, 21.36s/epoch, loss=0.32, accuracy=0.948, val_loss=0.468, val_accuracy=0.901, lr=0.001]  80%|████████  | 133/166 [49:01<11:46, 21.42s/epoch, loss=0.311, accuracy=0.949, val_loss=0.475, val_accuracy=0.896, lr=0.001] 81%|████████  | 134/166 [49:23<11:32, 21.65s/epoch, loss=0.305, accuracy=0.949, val_loss=0.466, val_accuracy=0.899, lr=0.001] 81%|████████▏ | 135/166 [49:45<11:13, 21.74s/epoch, loss=0.297, accuracy=0.95, val_loss=0.478, val_accuracy=0.893, lr=0.001]  82%|████████▏ | 136/166 [50:07<10:51, 21.73s/epoch, loss=0.293, accuracy=0.951, val_loss=0.483, val_accuracy=0.893, lr=0.001] 83%|████████▎ | 137/166 [50:28<10:26, 21.59s/epoch, loss=0.283, accuracy=0.953, val_loss=0.467, val_accuracy=0.897, lr=0.001] 83%|████████▎ | 138/166 [50:50<10:05, 21.62s/epoch, loss=0.283, accuracy=0.953, val_loss=0.453, val_accuracy=0.895, lr=0.001] 84%|████████▎ | 139/166 [51:11<09:45, 21.69s/epoch, loss=0.276, accuracy=0.954, val_loss=0.47, val_accuracy=0.894, lr=0.001]  84%|████████▍ | 140/166 [51:32<09:14, 21.32s/epoch, loss=0.269, accuracy=0.955, val_loss=0.51, val_accuracy=0.882, lr=0.001] 85%|████████▍ | 141/166 [51:54<09:00, 21.60s/epoch, loss=0.269, accuracy=0.953, val_loss=0.457, val_accuracy=0.896, lr=0.001] 86%|████████▌ | 142/166 [52:15<08:32, 21.37s/epoch, loss=0.261, accuracy=0.957, val_loss=0.479, val_accuracy=0.89, lr=0.001]  86%|████████▌ | 143/166 [52:36<08:11, 21.37s/epoch, loss=0.259, accuracy=0.956, val_loss=0.474, val_accuracy=0.89, lr=0.000316] 87%|████████▋ | 144/166 [52:57<07:44, 21.11s/epoch, loss=0.255, accuracy=0.957, val_loss=0.465, val_accuracy=0.894, lr=0.001]   87%|████████▋ | 145/166 [53:19<07:29, 21.40s/epoch, loss=0.251, accuracy=0.956, val_loss=0.454, val_accuracy=0.893, lr=0.001] 88%|████████▊ | 146/166 [53:41<07:09, 21.47s/epoch, loss=0.253, accuracy=0.955, val_loss=0.473, val_accuracy=0.889, lr=0.001] 89%|████████▊ | 147/166 [54:01<06:42, 21.18s/epoch, loss=0.244, accuracy=0.957, val_loss=0.479, val_accuracy=0.89, lr=0.001]  89%|████████▉ | 148/166 [54:22<06:20, 21.12s/epoch, loss=0.245, accuracy=0.957, val_loss=0.555, val_accuracy=0.872, lr=0.000316] 90%|████████▉ | 149/166 [54:44<06:03, 21.40s/epoch, loss=0.243, accuracy=0.957, val_loss=0.443, val_accuracy=0.895, lr=0.001]    90%|█████████ | 150/166 [55:06<05:46, 21.66s/epoch, loss=0.239, accuracy=0.957, val_loss=0.482, val_accuracy=0.885, lr=0.001] 91%|█████████ | 151/166 [55:28<05:25, 21.73s/epoch, loss=0.239, accuracy=0.956, val_loss=0.477, val_accuracy=0.888, lr=0.001] 92%|█████████▏| 152/166 [55:51<05:06, 21.90s/epoch, loss=0.236, accuracy=0.957, val_loss=0.481, val_accuracy=0.886, lr=0.001] 92%|█████████▏| 153/166 [56:13<04:45, 21.98s/epoch, loss=0.234, accuracy=0.957, val_loss=0.507, val_accuracy=0.882, lr=0.001] 93%|█████████▎| 154/166 [56:35<04:23, 21.93s/epoch, loss=0.234, accuracy=0.957, val_loss=0.525, val_accuracy=0.873, lr=0.000316] 93%|█████████▎| 155/166 [56:56<04:00, 21.89s/epoch, loss=0.229, accuracy=0.959, val_loss=0.528, val_accuracy=0.875, lr=0.001]    94%|█████████▍| 156/166 [57:19<03:39, 21.99s/epoch, loss=0.23, accuracy=0.957, val_loss=0.501, val_accuracy=0.879, lr=0.001]  95%|█████████▍| 157/166 [57:40<03:17, 21.95s/epoch, loss=0.227, accuracy=0.959, val_loss=0.482, val_accuracy=0.881, lr=0.001] 95%|█████████▌| 158/166 [58:01<02:52, 21.58s/epoch, loss=0.23, accuracy=0.957, val_loss=0.502, val_accuracy=0.886, lr=0.001]  96%|█████████▌| 159/166 [58:23<02:31, 21.64s/epoch, loss=0.229, accuracy=0.957, val_loss=0.458, val_accuracy=0.886, lr=0.000316] 96%|█████████▋| 160/166 [58:44<02:09, 21.59s/epoch, loss=0.224, accuracy=0.958, val_loss=0.471, val_accuracy=0.886, lr=0.001]    97%|█████████▋| 161/166 [59:06<01:48, 21.66s/epoch, loss=0.225, accuracy=0.957, val_loss=0.472, val_accuracy=0.885, lr=0.001] 98%|█████████▊| 162/166 [59:28<01:27, 21.81s/epoch, loss=0.203, accuracy=0.968, val_loss=0.415, val_accuracy=0.901, lr=1e-04] 98%|█████████▊| 163/166 [59:50<01:05, 21.81s/epoch, loss=0.19, accuracy=0.972, val_loss=0.41, val_accuracy=0.901, lr=1e-04]   99%|█████████▉| 164/166 [1:00:10<00:42, 21.36s/epoch, loss=0.184, accuracy=0.974, val_loss=0.41, val_accuracy=0.903, lr=1e-04] 99%|█████████▉| 165/166 [1:00:31<00:21, 21.02s/epoch, loss=0.182, accuracy=0.974, val_loss=0.409, val_accuracy=0.903, lr=1e-04]100%|██████████| 166/166 [1:00:53<00:00, 21.33s/epoch, loss=0.178, accuracy=0.975, val_loss=0.411, val_accuracy=0.904, lr=1e-04]100%|██████████| 166/166 [1:00:53<00:00, 22.01s/epoch, loss=0.178, accuracy=0.975, val_loss=0.411, val_accuracy=0.904, lr=1e-04]
Using real-time data augmentation.
Test loss: 0.4108687937259674
Test accuracy: 0.9035999774932861


* * * Run SGD for ID = 9_6. * * *


2024-02-15 16:11:39.277015: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 16:11:41.842361: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 16:11:41.843472: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-15 16:11:41.879428: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-15 16:11:41.879459: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 16:11:41.882437: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 16:11:41.882476: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 16:11:41.884704: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 16:11:41.885395: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 16:11:41.887592: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 16:11:41.889019: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 16:11:41.893601: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 16:11:41.896121: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 16:11:41.896200: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 16:11:43.071724: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-15 16:11:43.072329: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 16:11:43.073004: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-15 16:11:43.073033: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 16:11:43.073083: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 16:11:43.073103: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 16:11:43.073129: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 16:11:43.073148: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 16:11:43.073165: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 16:11:43.073183: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 16:11:43.073201: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 16:11:43.073666: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 16:11:43.073697: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 16:11:43.677896: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-15 16:11:43.677963: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-15 16:11:43.677974: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-15 16:11:43.678934: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': 96, 'batch_size': 128, 'epochs': 166, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/166 [00:00<?, ?epoch/s]2024-02-15 16:11:44.429182: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-15 16:11:44.441397: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2599900000 Hz
2024-02-15 16:11:46.235992: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 16:11:46.458318: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 16:11:47.269237: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-15 16:11:47.302420: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/166 [00:53<2:27:20, 53.58s/epoch, loss=3.41, accuracy=0.278, val_loss=2.39, val_accuracy=0.226, lr=0.1]  1%|          | 2/166 [01:15<1:36:11, 35.19s/epoch, loss=1.62, accuracy=0.509, val_loss=1.76, val_accuracy=0.483, lr=0.1]  2%|▏         | 3/166 [01:37<1:19:20, 29.21s/epoch, loss=1.41, accuracy=0.61, val_loss=1.61, val_accuracy=0.56, lr=0.1]    2%|▏         | 4/166 [01:58<1:09:39, 25.80s/epoch, loss=1.33, accuracy=0.664, val_loss=1.96, val_accuracy=0.443, lr=0.1]  3%|▎         | 5/166 [02:20<1:05:06, 24.26s/epoch, loss=1.29, accuracy=0.685, val_loss=2.19, val_accuracy=0.369, lr=0.1]  4%|▎         | 6/166 [02:41<1:02:03, 23.27s/epoch, loss=1.26, accuracy=0.704, val_loss=2.16, val_accuracy=0.51, lr=0.1]   4%|▍         | 7/166 [03:02<59:41, 22.53s/epoch, loss=1.25, accuracy=0.714, val_loss=2.79, val_accuracy=0.277, lr=0.1]   5%|▍         | 8/166 [03:24<59:03, 22.43s/epoch, loss=1.23, accuracy=0.72, val_loss=1.7, val_accuracy=0.555, lr=0.0316]  5%|▌         | 9/166 [03:46<58:25, 22.33s/epoch, loss=1.22, accuracy=0.724, val_loss=1.72, val_accuracy=0.584, lr=0.1]   6%|▌         | 10/166 [04:08<57:53, 22.27s/epoch, loss=1.22, accuracy=0.727, val_loss=1.67, val_accuracy=0.553, lr=0.1]  7%|▋         | 11/166 [04:30<57:19, 22.19s/epoch, loss=1.2, accuracy=0.73, val_loss=1.77, val_accuracy=0.567, lr=0.1]    7%|▋         | 12/166 [04:53<56:56, 22.18s/epoch, loss=1.2, accuracy=0.733, val_loss=1.67, val_accuracy=0.556, lr=0.1]  8%|▊         | 13/166 [05:14<56:12, 22.04s/epoch, loss=1.19, accuracy=0.734, val_loss=2.44, val_accuracy=0.424, lr=0.0316]  8%|▊         | 14/166 [05:36<55:52, 22.05s/epoch, loss=1.19, accuracy=0.734, val_loss=2.7, val_accuracy=0.446, lr=0.1]      9%|▉         | 15/166 [05:59<55:38, 22.11s/epoch, loss=1.18, accuracy=0.739, val_loss=1.45, val_accuracy=0.653, lr=0.1] 10%|▉         | 16/166 [06:21<55:35, 22.24s/epoch, loss=1.18, accuracy=0.742, val_loss=1.69, val_accuracy=0.596, lr=0.1] 10%|█         | 17/166 [06:42<53:54, 21.71s/epoch, loss=1.18, accuracy=0.742, val_loss=1.77, val_accuracy=0.525, lr=0.1] 11%|█         | 18/166 [07:04<53:50, 21.83s/epoch, loss=1.18, accuracy=0.74, val_loss=2.58, val_accuracy=0.445, lr=0.1]  11%|█▏        | 19/166 [07:26<53:37, 21.89s/epoch, loss=1.18, accuracy=0.74, val_loss=1.62, val_accuracy=0.581, lr=0.1] 12%|█▏        | 20/166 [07:48<53:31, 22.00s/epoch, loss=1.18, accuracy=0.741, val_loss=2.25, val_accuracy=0.439, lr=0.0316] 13%|█▎        | 21/166 [08:10<53:16, 22.04s/epoch, loss=1.17, accuracy=0.745, val_loss=2.12, val_accuracy=0.43, lr=0.1]     13%|█▎        | 22/166 [08:32<52:57, 22.07s/epoch, loss=1.17, accuracy=0.745, val_loss=1.47, val_accuracy=0.636, lr=0.1] 14%|█▍        | 23/166 [08:54<52:18, 21.95s/epoch, loss=1.17, accuracy=0.744, val_loss=1.77, val_accuracy=0.534, lr=0.1] 14%|█▍        | 24/166 [09:16<52:20, 22.11s/epoch, loss=1.16, accuracy=0.748, val_loss=3.1, val_accuracy=0.368, lr=0.1]  15%|█▌        | 25/166 [09:39<51:57, 22.11s/epoch, loss=1.16, accuracy=0.747, val_loss=1.63, val_accuracy=0.59, lr=0.0316] 16%|█▌        | 26/166 [10:01<51:39, 22.14s/epoch, loss=1.17, accuracy=0.748, val_loss=1.59, val_accuracy=0.61, lr=0.1]    16%|█▋        | 27/166 [10:23<51:19, 22.15s/epoch, loss=1.16, accuracy=0.748, val_loss=2.3, val_accuracy=0.421, lr=0.1] 17%|█▋        | 28/166 [10:45<50:48, 22.09s/epoch, loss=1.16, accuracy=0.747, val_loss=1.41, val_accuracy=0.658, lr=0.1] 17%|█▋        | 29/166 [11:06<49:27, 21.66s/epoch, loss=1.16, accuracy=0.747, val_loss=2.51, val_accuracy=0.431, lr=0.1] 18%|█▊        | 30/166 [11:28<49:26, 21.82s/epoch, loss=1.16, accuracy=0.748, val_loss=3.86, val_accuracy=0.251, lr=0.1] 19%|█▊        | 31/166 [11:50<49:05, 21.82s/epoch, loss=1.16, accuracy=0.748, val_loss=1.8, val_accuracy=0.548, lr=0.1]  19%|█▉        | 32/166 [12:12<49:08, 22.00s/epoch, loss=1.16, accuracy=0.751, val_loss=2.15, val_accuracy=0.46, lr=0.1] 20%|█▉        | 33/166 [12:34<48:44, 21.99s/epoch, loss=1.16, accuracy=0.749, val_loss=6.58, val_accuracy=0.216, lr=0.0316] 20%|██        | 34/166 [12:56<48:31, 22.06s/epoch, loss=1.15, accuracy=0.749, val_loss=2.26, val_accuracy=0.456, lr=0.1]    21%|██        | 35/166 [13:18<47:53, 21.94s/epoch, loss=1.15, accuracy=0.751, val_loss=2.77, val_accuracy=0.42, lr=0.1]  22%|██▏       | 36/166 [13:40<47:44, 22.03s/epoch, loss=1.16, accuracy=0.749, val_loss=2.38, val_accuracy=0.467, lr=0.1] 22%|██▏       | 37/166 [14:02<47:33, 22.12s/epoch, loss=1.15, accuracy=0.75, val_loss=1.71, val_accuracy=0.585, lr=0.1]  23%|██▎       | 38/166 [14:25<47:23, 22.22s/epoch, loss=1.15, accuracy=0.75, val_loss=5.05, val_accuracy=0.242, lr=0.0316] 23%|██▎       | 39/166 [14:47<47:01, 22.22s/epoch, loss=1.15, accuracy=0.753, val_loss=1.67, val_accuracy=0.582, lr=0.1]   24%|██▍       | 40/166 [15:09<46:46, 22.28s/epoch, loss=1.15, accuracy=0.749, val_loss=1.76, val_accuracy=0.548, lr=0.1] 25%|██▍       | 41/166 [15:31<45:55, 22.04s/epoch, loss=1.15, accuracy=0.753, val_loss=1.71, val_accuracy=0.562, lr=0.1] 25%|██▌       | 42/166 [15:53<45:48, 22.16s/epoch, loss=1.15, accuracy=0.75, val_loss=1.62, val_accuracy=0.609, lr=0.1]  26%|██▌       | 43/166 [16:15<45:21, 22.13s/epoch, loss=1.15, accuracy=0.752, val_loss=3.12, val_accuracy=0.286, lr=0.0316] 27%|██▋       | 44/166 [16:37<44:55, 22.10s/epoch, loss=1.15, accuracy=0.751, val_loss=3.37, val_accuracy=0.3, lr=0.1]      27%|██▋       | 45/166 [17:00<44:35, 22.12s/epoch, loss=1.15, accuracy=0.751, val_loss=1.62, val_accuracy=0.582, lr=0.1] 28%|██▊       | 46/166 [17:22<44:20, 22.17s/epoch, loss=1.15, accuracy=0.752, val_loss=2.14, val_accuracy=0.484, lr=0.1] 28%|██▊       | 47/166 [17:44<43:59, 22.18s/epoch, loss=1.15, accuracy=0.752, val_loss=2.78, val_accuracy=0.433, lr=0.1] 29%|██▉       | 48/166 [18:06<43:27, 22.10s/epoch, loss=1.16, accuracy=0.749, val_loss=1.98, val_accuracy=0.508, lr=0.0316] 30%|██▉       | 49/166 [18:28<43:16, 22.19s/epoch, loss=1.14, accuracy=0.751, val_loss=2.29, val_accuracy=0.445, lr=0.1]    30%|███       | 50/166 [18:51<42:56, 22.21s/epoch, loss=1.14, accuracy=0.75, val_loss=2.09, val_accuracy=0.458, lr=0.1]  31%|███       | 51/166 [19:11<41:38, 21.72s/epoch, loss=1.14, accuracy=0.753, val_loss=1.72, val_accuracy=0.583, lr=0.1] 31%|███▏      | 52/166 [19:33<41:31, 21.85s/epoch, loss=1.15, accuracy=0.752, val_loss=1.88, val_accuracy=0.543, lr=0.1] 32%|███▏      | 53/166 [19:54<40:26, 21.47s/epoch, loss=1.14, accuracy=0.752, val_loss=2.08, val_accuracy=0.535, lr=0.0316] 33%|███▎      | 54/166 [20:16<40:22, 21.63s/epoch, loss=1.14, accuracy=0.755, val_loss=2.22, val_accuracy=0.394, lr=0.1]    33%|███▎      | 55/166 [20:37<39:25, 21.31s/epoch, loss=1.15, accuracy=0.752, val_loss=1.89, val_accuracy=0.538, lr=0.1] 34%|███▎      | 56/166 [20:59<39:37, 21.61s/epoch, loss=1.15, accuracy=0.75, val_loss=1.68, val_accuracy=0.585, lr=0.1]  34%|███▍      | 57/166 [21:19<38:40, 21.29s/epoch, loss=1.14, accuracy=0.753, val_loss=2.65, val_accuracy=0.391, lr=0.1] 35%|███▍      | 58/166 [21:42<38:50, 21.58s/epoch, loss=1.14, accuracy=0.753, val_loss=2.31, val_accuracy=0.454, lr=0.0316] 36%|███▌      | 59/166 [22:03<38:22, 21.52s/epoch, loss=1.14, accuracy=0.753, val_loss=2.88, val_accuracy=0.34, lr=0.1]     36%|███▌      | 60/166 [22:25<38:16, 21.67s/epoch, loss=1.14, accuracy=0.754, val_loss=2.84, val_accuracy=0.427, lr=0.1] 37%|███▋      | 61/166 [22:47<37:58, 21.70s/epoch, loss=1.14, accuracy=0.754, val_loss=1.59, val_accuracy=0.615, lr=0.1] 37%|███▋      | 62/166 [23:09<37:46, 21.80s/epoch, loss=1.14, accuracy=0.752, val_loss=1.7, val_accuracy=0.57, lr=0.1]   38%|███▊      | 63/166 [23:31<37:41, 21.95s/epoch, loss=1.13, accuracy=0.753, val_loss=1.45, val_accuracy=0.656, lr=0.0316] 39%|███▊      | 64/166 [23:53<37:24, 22.00s/epoch, loss=1.14, accuracy=0.754, val_loss=3.68, val_accuracy=0.384, lr=0.1]    39%|███▉      | 65/166 [24:15<36:58, 21.97s/epoch, loss=1.14, accuracy=0.754, val_loss=1.79, val_accuracy=0.568, lr=0.1] 40%|███▉      | 66/166 [24:38<36:51, 22.11s/epoch, loss=1.14, accuracy=0.752, val_loss=1.86, val_accuracy=0.536, lr=0.1] 40%|████      | 67/166 [24:59<36:16, 21.98s/epoch, loss=1.13, accuracy=0.755, val_loss=1.72, val_accuracy=0.552, lr=0.1] 41%|████      | 68/166 [25:21<35:56, 22.01s/epoch, loss=1.14, accuracy=0.752, val_loss=1.89, val_accuracy=0.545, lr=0.0316] 42%|████▏     | 69/166 [25:44<35:39, 22.06s/epoch, loss=1.13, accuracy=0.754, val_loss=1.53, val_accuracy=0.61, lr=0.1]     42%|████▏     | 70/166 [26:05<35:07, 21.95s/epoch, loss=1.14, accuracy=0.749, val_loss=2.55, val_accuracy=0.409, lr=0.1] 43%|████▎     | 71/166 [26:26<34:05, 21.53s/epoch, loss=1.14, accuracy=0.752, val_loss=2.56, val_accuracy=0.41, lr=0.1]  43%|████▎     | 72/166 [26:48<34:11, 21.82s/epoch, loss=1.13, accuracy=0.753, val_loss=1.65, val_accuracy=0.566, lr=0.1] 44%|████▍     | 73/166 [27:11<34:06, 22.01s/epoch, loss=1.14, accuracy=0.752, val_loss=2.14, val_accuracy=0.515, lr=0.0316] 45%|████▍     | 74/166 [27:33<33:46, 22.03s/epoch, loss=1.14, accuracy=0.753, val_loss=1.73, val_accuracy=0.561, lr=0.1]    45%|████▌     | 75/166 [27:55<33:29, 22.08s/epoch, loss=1.14, accuracy=0.752, val_loss=2.61, val_accuracy=0.421, lr=0.1] 46%|████▌     | 76/166 [28:17<33:08, 22.10s/epoch, loss=1.13, accuracy=0.752, val_loss=3.13, val_accuracy=0.381, lr=0.1] 46%|████▋     | 77/166 [28:38<32:17, 21.76s/epoch, loss=1.13, accuracy=0.754, val_loss=2.85, val_accuracy=0.379, lr=0.1] 47%|████▋     | 78/166 [29:00<32:04, 21.86s/epoch, loss=1.13, accuracy=0.757, val_loss=2.56, val_accuracy=0.392, lr=0.0316] 48%|████▊     | 79/166 [29:21<31:10, 21.50s/epoch, loss=1.14, accuracy=0.751, val_loss=1.91, val_accuracy=0.555, lr=0.1]    48%|████▊     | 80/166 [29:43<31:06, 21.70s/epoch, loss=1.13, accuracy=0.753, val_loss=4.59, val_accuracy=0.254, lr=0.1] 49%|████▉     | 81/166 [30:05<30:50, 21.77s/epoch, loss=1.13, accuracy=0.753, val_loss=1.92, val_accuracy=0.502, lr=0.1] 49%|████▉     | 82/166 [30:26<30:07, 21.52s/epoch, loss=0.932, accuracy=0.811, val_loss=0.966, val_accuracy=0.781, lr=0.01] 50%|█████     | 83/166 [30:46<29:19, 21.20s/epoch, loss=0.748, accuracy=0.845, val_loss=0.787, val_accuracy=0.822, lr=0.01] 51%|█████     | 84/166 [31:07<28:39, 20.98s/epoch, loss=0.665, accuracy=0.854, val_loss=0.725, val_accuracy=0.827, lr=0.01] 51%|█████     | 85/166 [31:29<28:44, 21.29s/epoch, loss=0.619, accuracy=0.857, val_loss=0.754, val_accuracy=0.812, lr=0.01] 52%|█████▏    | 86/166 [31:51<28:44, 21.55s/epoch, loss=0.596, accuracy=0.859, val_loss=1.2, val_accuracy=0.653, lr=0.01]   52%|█████▏    | 87/166 [32:13<28:33, 21.68s/epoch, loss=0.581, accuracy=0.86, val_loss=0.772, val_accuracy=0.794, lr=0.01] 53%|█████▎    | 88/166 [32:34<27:54, 21.47s/epoch, loss=0.576, accuracy=0.86, val_loss=1, val_accuracy=0.722, lr=0.01]     54%|█████▎    | 89/166 [32:55<27:17, 21.27s/epoch, loss=0.569, accuracy=0.862, val_loss=0.824, val_accuracy=0.79, lr=0.00316] 54%|█████▍    | 90/166 [33:15<26:37, 21.02s/epoch, loss=0.57, accuracy=0.864, val_loss=0.788, val_accuracy=0.801, lr=0.01]    55%|█████▍    | 91/166 [33:36<26:16, 21.02s/epoch, loss=0.567, accuracy=0.866, val_loss=0.9, val_accuracy=0.761, lr=0.01]  55%|█████▌    | 92/166 [33:58<26:19, 21.35s/epoch, loss=0.564, accuracy=0.868, val_loss=0.731, val_accuracy=0.805, lr=0.01] 56%|█████▌    | 93/166 [34:21<26:16, 21.59s/epoch, loss=0.561, accuracy=0.869, val_loss=0.765, val_accuracy=0.808, lr=0.01] 57%|█████▋    | 94/166 [34:41<25:29, 21.25s/epoch, loss=0.564, accuracy=0.87, val_loss=1.12, val_accuracy=0.72, lr=0.00316] 57%|█████▋    | 95/166 [35:03<25:21, 21.42s/epoch, loss=0.564, accuracy=0.869, val_loss=0.881, val_accuracy=0.774, lr=0.01] 58%|█████▊    | 96/166 [35:24<25:04, 21.49s/epoch, loss=0.564, accuracy=0.871, val_loss=0.821, val_accuracy=0.789, lr=0.01] 58%|█████▊    | 97/166 [35:46<24:53, 21.64s/epoch, loss=0.565, accuracy=0.872, val_loss=0.791, val_accuracy=0.8, lr=0.01]   59%|█████▉    | 98/166 [36:08<24:28, 21.60s/epoch, loss=0.565, accuracy=0.872, val_loss=0.953, val_accuracy=0.764, lr=0.01] 60%|█████▉    | 99/166 [36:30<24:08, 21.63s/epoch, loss=0.561, accuracy=0.875, val_loss=1.2, val_accuracy=0.694, lr=0.00316] 60%|██████    | 100/166 [36:52<23:56, 21.77s/epoch, loss=0.561, accuracy=0.876, val_loss=0.901, val_accuracy=0.766, lr=0.01] 61%|██████    | 101/166 [37:14<23:41, 21.86s/epoch, loss=0.558, accuracy=0.877, val_loss=0.802, val_accuracy=0.799, lr=0.01] 61%|██████▏   | 102/166 [37:35<23:11, 21.75s/epoch, loss=0.558, accuracy=0.877, val_loss=0.859, val_accuracy=0.788, lr=0.01] 62%|██████▏   | 103/166 [37:58<22:58, 21.89s/epoch, loss=0.563, accuracy=0.876, val_loss=0.929, val_accuracy=0.77, lr=0.01]  63%|██████▎   | 104/166 [38:18<22:12, 21.48s/epoch, loss=0.558, accuracy=0.877, val_loss=0.849, val_accuracy=0.795, lr=0.00316] 63%|██████▎   | 105/166 [38:40<22:02, 21.68s/epoch, loss=0.558, accuracy=0.878, val_loss=0.9, val_accuracy=0.76, lr=0.01]       64%|██████▍   | 106/166 [39:02<21:49, 21.83s/epoch, loss=0.562, accuracy=0.877, val_loss=0.829, val_accuracy=0.801, lr=0.01] 64%|██████▍   | 107/166 [39:24<21:31, 21.89s/epoch, loss=0.561, accuracy=0.879, val_loss=0.99, val_accuracy=0.75, lr=0.01]   65%|██████▌   | 108/166 [39:47<21:14, 21.98s/epoch, loss=0.557, accuracy=0.88, val_loss=0.758, val_accuracy=0.829, lr=0.01] 66%|██████▌   | 109/166 [40:08<20:39, 21.75s/epoch, loss=0.557, accuracy=0.88, val_loss=0.923, val_accuracy=0.771, lr=0.00316] 66%|██████▋   | 110/166 [40:30<20:24, 21.87s/epoch, loss=0.558, accuracy=0.879, val_loss=0.764, val_accuracy=0.814, lr=0.01]   67%|██████▋   | 111/166 [40:52<20:06, 21.94s/epoch, loss=0.561, accuracy=0.879, val_loss=0.78, val_accuracy=0.806, lr=0.01]  67%|██████▋   | 112/166 [41:13<19:31, 21.70s/epoch, loss=0.561, accuracy=0.878, val_loss=1.02, val_accuracy=0.766, lr=0.01] 68%|██████▊   | 113/166 [41:35<19:06, 21.64s/epoch, loss=0.557, accuracy=0.882, val_loss=0.843, val_accuracy=0.791, lr=0.01] 69%|██████▊   | 114/166 [41:55<18:26, 21.28s/epoch, loss=0.557, accuracy=0.881, val_loss=0.833, val_accuracy=0.792, lr=0.00316] 69%|██████▉   | 115/166 [42:16<17:54, 21.06s/epoch, loss=0.557, accuracy=0.881, val_loss=1.04, val_accuracy=0.759, lr=0.01]     70%|██████▉   | 116/166 [42:38<17:47, 21.36s/epoch, loss=0.555, accuracy=0.881, val_loss=0.792, val_accuracy=0.81, lr=0.01] 70%|███████   | 117/166 [43:00<17:36, 21.56s/epoch, loss=0.559, accuracy=0.881, val_loss=1.01, val_accuracy=0.753, lr=0.01] 71%|███████   | 118/166 [43:22<17:23, 21.75s/epoch, loss=0.555, accuracy=0.882, val_loss=0.827, val_accuracy=0.8, lr=0.01]  72%|███████▏  | 119/166 [43:44<17:03, 21.77s/epoch, loss=0.556, accuracy=0.882, val_loss=0.853, val_accuracy=0.795, lr=0.00316] 72%|███████▏  | 120/166 [44:06<16:44, 21.83s/epoch, loss=0.561, accuracy=0.883, val_loss=0.715, val_accuracy=0.827, lr=0.01]    73%|███████▎  | 121/166 [44:28<16:23, 21.86s/epoch, loss=0.56, accuracy=0.882, val_loss=1.03, val_accuracy=0.74, lr=0.01]    73%|███████▎  | 122/166 [44:49<16:00, 21.84s/epoch, loss=0.487, accuracy=0.906, val_loss=0.541, val_accuracy=0.888, lr=0.001] 74%|███████▍  | 123/166 [45:11<15:37, 21.80s/epoch, loss=0.433, accuracy=0.925, val_loss=0.526, val_accuracy=0.892, lr=0.001] 75%|███████▍  | 124/166 [45:33<15:10, 21.68s/epoch, loss=0.407, accuracy=0.932, val_loss=0.521, val_accuracy=0.892, lr=0.001] 75%|███████▌  | 125/166 [45:54<14:47, 21.64s/epoch, loss=0.391, accuracy=0.935, val_loss=0.499, val_accuracy=0.897, lr=0.001] 76%|███████▌  | 126/166 [46:15<14:19, 21.50s/epoch, loss=0.379, accuracy=0.937, val_loss=0.497, val_accuracy=0.898, lr=0.001] 77%|███████▋  | 127/166 [46:37<13:59, 21.54s/epoch, loss=0.368, accuracy=0.939, val_loss=0.496, val_accuracy=0.898, lr=0.001] 77%|███████▋  | 128/166 [46:59<13:41, 21.61s/epoch, loss=0.358, accuracy=0.941, val_loss=0.48, val_accuracy=0.897, lr=0.001]  78%|███████▊  | 129/166 [47:21<13:25, 21.76s/epoch, loss=0.348, accuracy=0.942, val_loss=0.478, val_accuracy=0.9, lr=0.001]  78%|███████▊  | 130/166 [47:41<12:48, 21.34s/epoch, loss=0.337, accuracy=0.945, val_loss=0.47, val_accuracy=0.899, lr=0.001] 79%|███████▉  | 131/166 [48:02<12:16, 21.04s/epoch, loss=0.329, accuracy=0.945, val_loss=0.478, val_accuracy=0.897, lr=0.001] 80%|███████▉  | 132/166 [48:24<12:06, 21.36s/epoch, loss=0.322, accuracy=0.946, val_loss=0.469, val_accuracy=0.9, lr=0.001]   80%|████████  | 133/166 [48:44<11:35, 21.07s/epoch, loss=0.316, accuracy=0.947, val_loss=0.457, val_accuracy=0.901, lr=0.001] 81%|████████  | 134/166 [49:06<11:22, 21.34s/epoch, loss=0.307, accuracy=0.949, val_loss=0.481, val_accuracy=0.893, lr=0.001] 81%|████████▏ | 135/166 [49:28<11:03, 21.42s/epoch, loss=0.302, accuracy=0.95, val_loss=0.468, val_accuracy=0.897, lr=0.001]  82%|████████▏ | 136/166 [49:48<10:35, 21.19s/epoch, loss=0.292, accuracy=0.95, val_loss=0.474, val_accuracy=0.897, lr=0.001] 83%|████████▎ | 137/166 [50:10<10:21, 21.44s/epoch, loss=0.29, accuracy=0.951, val_loss=0.454, val_accuracy=0.896, lr=0.001] 83%|████████▎ | 138/166 [50:32<10:05, 21.62s/epoch, loss=0.281, accuracy=0.953, val_loss=0.473, val_accuracy=0.895, lr=0.001] 84%|████████▎ | 139/166 [50:54<09:46, 21.71s/epoch, loss=0.276, accuracy=0.954, val_loss=0.468, val_accuracy=0.895, lr=0.001] 84%|████████▍ | 140/166 [51:16<09:23, 21.68s/epoch, loss=0.272, accuracy=0.953, val_loss=0.468, val_accuracy=0.893, lr=0.001] 85%|████████▍ | 141/166 [51:36<08:51, 21.24s/epoch, loss=0.27, accuracy=0.953, val_loss=0.452, val_accuracy=0.895, lr=0.001]  86%|████████▌ | 142/166 [51:58<08:35, 21.47s/epoch, loss=0.264, accuracy=0.954, val_loss=0.457, val_accuracy=0.897, lr=0.001] 86%|████████▌ | 143/166 [52:20<08:17, 21.62s/epoch, loss=0.262, accuracy=0.955, val_loss=0.451, val_accuracy=0.897, lr=0.001] 87%|████████▋ | 144/166 [52:42<07:57, 21.70s/epoch, loss=0.256, accuracy=0.955, val_loss=0.465, val_accuracy=0.89, lr=0.001]  87%|████████▋ | 145/166 [53:04<07:35, 21.70s/epoch, loss=0.256, accuracy=0.955, val_loss=0.455, val_accuracy=0.899, lr=0.001] 88%|████████▊ | 146/166 [53:25<07:09, 21.47s/epoch, loss=0.248, accuracy=0.957, val_loss=0.448, val_accuracy=0.896, lr=0.001] 89%|████████▊ | 147/166 [53:47<06:51, 21.65s/epoch, loss=0.248, accuracy=0.956, val_loss=0.457, val_accuracy=0.891, lr=0.001] 89%|████████▉ | 148/166 [54:08<06:28, 21.59s/epoch, loss=0.246, accuracy=0.955, val_loss=0.45, val_accuracy=0.893, lr=0.001]  90%|████████▉ | 149/166 [54:30<06:07, 21.62s/epoch, loss=0.245, accuracy=0.955, val_loss=0.45, val_accuracy=0.894, lr=0.001] 90%|█████████ | 150/166 [54:50<05:41, 21.34s/epoch, loss=0.243, accuracy=0.956, val_loss=0.46, val_accuracy=0.892, lr=0.001] 91%|█████████ | 151/166 [55:12<05:19, 21.33s/epoch, loss=0.24, accuracy=0.956, val_loss=0.495, val_accuracy=0.883, lr=0.000316] 92%|█████████▏| 152/166 [55:34<05:01, 21.54s/epoch, loss=0.235, accuracy=0.957, val_loss=0.465, val_accuracy=0.888, lr=0.001]   92%|█████████▏| 153/166 [55:55<04:39, 21.50s/epoch, loss=0.235, accuracy=0.957, val_loss=0.481, val_accuracy=0.885, lr=0.001] 93%|█████████▎| 154/166 [56:17<04:20, 21.68s/epoch, loss=0.231, accuracy=0.958, val_loss=0.481, val_accuracy=0.884, lr=0.001] 93%|█████████▎| 155/166 [56:39<03:57, 21.55s/epoch, loss=0.231, accuracy=0.958, val_loss=0.473, val_accuracy=0.887, lr=0.001] 94%|█████████▍| 156/166 [57:01<03:36, 21.68s/epoch, loss=0.231, accuracy=0.957, val_loss=0.456, val_accuracy=0.891, lr=0.000316] 95%|█████████▍| 157/166 [57:22<03:15, 21.77s/epoch, loss=0.228, accuracy=0.958, val_loss=0.463, val_accuracy=0.888, lr=0.001]    95%|█████████▌| 158/166 [57:44<02:54, 21.79s/epoch, loss=0.227, accuracy=0.958, val_loss=0.503, val_accuracy=0.887, lr=0.001] 96%|█████████▌| 159/166 [58:06<02:32, 21.85s/epoch, loss=0.228, accuracy=0.957, val_loss=0.478, val_accuracy=0.884, lr=0.001] 96%|█████████▋| 160/166 [58:28<02:11, 21.90s/epoch, loss=0.226, accuracy=0.957, val_loss=0.463, val_accuracy=0.892, lr=0.001] 97%|█████████▋| 161/166 [58:49<01:46, 21.39s/epoch, loss=0.224, accuracy=0.957, val_loss=0.459, val_accuracy=0.888, lr=0.000316] 98%|█████████▊| 162/166 [59:10<01:26, 21.50s/epoch, loss=0.203, accuracy=0.967, val_loss=0.408, val_accuracy=0.906, lr=1e-04]    98%|█████████▊| 163/166 [59:31<01:03, 21.19s/epoch, loss=0.19, accuracy=0.972, val_loss=0.407, val_accuracy=0.905, lr=1e-04]  99%|█████████▉| 164/166 [59:51<00:42, 21.02s/epoch, loss=0.184, accuracy=0.974, val_loss=0.408, val_accuracy=0.904, lr=1e-04] 99%|█████████▉| 165/166 [1:00:12<00:20, 20.89s/epoch, loss=0.181, accuracy=0.974, val_loss=0.405, val_accuracy=0.904, lr=1e-04]100%|██████████| 166/166 [1:00:33<00:00, 20.89s/epoch, loss=0.177, accuracy=0.975, val_loss=0.408, val_accuracy=0.905, lr=1e-04]100%|██████████| 166/166 [1:00:33<00:00, 21.89s/epoch, loss=0.177, accuracy=0.975, val_loss=0.408, val_accuracy=0.905, lr=1e-04]
Using real-time data augmentation.
Test loss: 0.4084022343158722
Test accuracy: 0.9047999978065491


* * * Run SGD for ID = 9_7. * * *


2024-02-15 17:12:20.783662: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 17:12:28.262189: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 17:12:28.263417: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-15 17:12:28.299361: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-15 17:12:28.299389: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 17:12:28.305750: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 17:12:28.305788: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 17:12:28.310001: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 17:12:28.312486: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 17:12:28.317716: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 17:12:28.320906: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 17:12:28.328080: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 17:12:28.328588: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 17:12:28.328693: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 17:12:29.534752: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-15 17:12:29.536266: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 17:12:29.536930: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-15 17:12:29.536970: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 17:12:29.537021: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 17:12:29.537039: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 17:12:29.537057: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 17:12:29.537075: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 17:12:29.537092: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 17:12:29.537108: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 17:12:29.537126: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 17:12:29.537592: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 17:12:29.537623: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 17:12:30.164587: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-15 17:12:30.164648: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-15 17:12:30.164657: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-15 17:12:30.165575: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': 97, 'batch_size': 128, 'epochs': 166, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/166 [00:00<?, ?epoch/s]2024-02-15 17:12:30.921835: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-15 17:12:30.933397: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2599900000 Hz
2024-02-15 17:12:32.762152: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 17:12:33.015315: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 17:12:33.697962: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-15 17:12:33.738373: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/166 [00:56<2:35:10, 56.43s/epoch, loss=3.31, accuracy=0.27, val_loss=2.45, val_accuracy=0.255, lr=0.1]  1%|          | 2/166 [01:17<1:37:29, 35.67s/epoch, loss=1.64, accuracy=0.486, val_loss=2.29, val_accuracy=0.327, lr=0.1]  2%|▏         | 3/166 [01:37<1:17:46, 28.63s/epoch, loss=1.42, accuracy=0.598, val_loss=3.34, val_accuracy=0.242, lr=0.1]  2%|▏         | 4/166 [01:59<1:09:58, 25.92s/epoch, loss=1.3, accuracy=0.662, val_loss=1.8, val_accuracy=0.517, lr=0.1]    3%|▎         | 5/166 [02:22<1:06:10, 24.66s/epoch, loss=1.26, accuracy=0.691, val_loss=1.77, val_accuracy=0.55, lr=0.1]  4%|▎         | 6/166 [02:44<1:03:30, 23.81s/epoch, loss=1.24, accuracy=0.705, val_loss=2.21, val_accuracy=0.488, lr=0.1]  4%|▍         | 7/166 [03:05<1:00:38, 22.88s/epoch, loss=1.24, accuracy=0.712, val_loss=3.36, val_accuracy=0.214, lr=0.1]  5%|▍         | 8/166 [03:27<59:43, 22.68s/epoch, loss=1.22, accuracy=0.722, val_loss=3.06, val_accuracy=0.365, lr=0.1]    5%|▌         | 9/166 [03:48<58:25, 22.33s/epoch, loss=1.22, accuracy=0.726, val_loss=2.11, val_accuracy=0.401, lr=0.1]  6%|▌         | 10/166 [04:11<57:54, 22.27s/epoch, loss=1.21, accuracy=0.727, val_loss=1.78, val_accuracy=0.534, lr=0.0316]  7%|▋         | 11/166 [04:33<57:36, 22.30s/epoch, loss=1.2, accuracy=0.731, val_loss=3.41, val_accuracy=0.268, lr=0.1]      7%|▋         | 12/166 [04:55<57:08, 22.26s/epoch, loss=1.21, accuracy=0.73, val_loss=2.02, val_accuracy=0.503, lr=0.1]  8%|▊         | 13/166 [05:16<55:28, 21.75s/epoch, loss=1.2, accuracy=0.733, val_loss=2.07, val_accuracy=0.5, lr=0.1]    8%|▊         | 14/166 [05:37<54:50, 21.65s/epoch, loss=1.19, accuracy=0.735, val_loss=2.3, val_accuracy=0.473, lr=0.1]  9%|▉         | 15/166 [06:00<55:03, 21.88s/epoch, loss=1.19, accuracy=0.737, val_loss=1.89, val_accuracy=0.578, lr=0.0316] 10%|▉         | 16/166 [06:22<55:08, 22.05s/epoch, loss=1.19, accuracy=0.738, val_loss=1.94, val_accuracy=0.515, lr=0.1]    10%|█         | 17/166 [06:44<55:06, 22.19s/epoch, loss=1.18, accuracy=0.74, val_loss=3.81, val_accuracy=0.36, lr=0.1]   11%|█         | 18/166 [07:07<54:48, 22.22s/epoch, loss=1.18, accuracy=0.741, val_loss=1.68, val_accuracy=0.546, lr=0.1] 11%|█▏        | 19/166 [07:29<54:32, 22.26s/epoch, loss=1.18, accuracy=0.742, val_loss=2.88, val_accuracy=0.401, lr=0.1] 12%|█▏        | 20/166 [07:52<54:18, 22.32s/epoch, loss=1.19, accuracy=0.741, val_loss=5.4, val_accuracy=0.258, lr=0.1]  13%|█▎        | 21/166 [08:14<53:45, 22.25s/epoch, loss=1.18, accuracy=0.742, val_loss=1.92, val_accuracy=0.53, lr=0.1] 13%|█▎        | 22/166 [08:36<53:11, 22.16s/epoch, loss=1.18, accuracy=0.742, val_loss=2.1, val_accuracy=0.489, lr=0.1] 14%|█▍        | 23/166 [08:58<53:02, 22.26s/epoch, loss=1.18, accuracy=0.744, val_loss=2.49, val_accuracy=0.512, lr=0.0316] 14%|█▍        | 24/166 [09:19<51:55, 21.94s/epoch, loss=1.18, accuracy=0.743, val_loss=2.84, val_accuracy=0.282, lr=0.1]    15%|█▌        | 25/166 [09:40<50:41, 21.57s/epoch, loss=1.17, accuracy=0.745, val_loss=1.88, val_accuracy=0.5, lr=0.1]   16%|█▌        | 26/166 [10:02<50:21, 21.58s/epoch, loss=1.17, accuracy=0.748, val_loss=2.15, val_accuracy=0.458, lr=0.1] 16%|█▋        | 27/166 [10:22<49:23, 21.32s/epoch, loss=1.17, accuracy=0.746, val_loss=2.72, val_accuracy=0.392, lr=0.1] 17%|█▋        | 28/166 [10:45<49:46, 21.64s/epoch, loss=1.17, accuracy=0.746, val_loss=3.68, val_accuracy=0.357, lr=0.0316] 17%|█▋        | 29/166 [11:07<49:59, 21.89s/epoch, loss=1.17, accuracy=0.747, val_loss=3.86, val_accuracy=0.351, lr=0.1]    18%|█▊        | 30/166 [11:28<49:07, 21.67s/epoch, loss=1.17, accuracy=0.747, val_loss=2.45, val_accuracy=0.376, lr=0.1] 19%|█▊        | 31/166 [11:51<49:15, 21.89s/epoch, loss=1.16, accuracy=0.748, val_loss=1.39, val_accuracy=0.674, lr=0.1] 19%|█▉        | 32/166 [12:12<48:07, 21.55s/epoch, loss=1.17, accuracy=0.749, val_loss=2.11, val_accuracy=0.507, lr=0.1] 20%|█▉        | 33/166 [12:34<48:19, 21.80s/epoch, loss=1.17, accuracy=0.748, val_loss=1.77, val_accuracy=0.571, lr=0.1] 20%|██        | 34/166 [12:56<48:26, 22.02s/epoch, loss=1.16, accuracy=0.748, val_loss=1.76, val_accuracy=0.572, lr=0.1] 21%|██        | 35/166 [13:19<48:16, 22.11s/epoch, loss=1.16, accuracy=0.751, val_loss=1.9, val_accuracy=0.533, lr=0.1]  22%|██▏       | 36/166 [13:41<48:04, 22.19s/epoch, loss=1.16, accuracy=0.752, val_loss=1.49, val_accuracy=0.618, lr=0.0316] 22%|██▏       | 37/166 [14:03<47:28, 22.08s/epoch, loss=1.16, accuracy=0.749, val_loss=1.78, val_accuracy=0.552, lr=0.1]    23%|██▎       | 38/166 [14:25<47:02, 22.05s/epoch, loss=1.16, accuracy=0.752, val_loss=1.36, val_accuracy=0.685, lr=0.1] 23%|██▎       | 39/166 [14:47<46:45, 22.09s/epoch, loss=1.16, accuracy=0.753, val_loss=1.86, val_accuracy=0.562, lr=0.1] 24%|██▍       | 40/166 [15:09<45:59, 21.90s/epoch, loss=1.16, accuracy=0.752, val_loss=1.9, val_accuracy=0.573, lr=0.1]  25%|██▍       | 41/166 [15:31<45:46, 21.97s/epoch, loss=1.16, accuracy=0.752, val_loss=1.39, val_accuracy=0.67, lr=0.1] 25%|██▌       | 42/166 [15:52<44:49, 21.69s/epoch, loss=1.15, accuracy=0.753, val_loss=2.1, val_accuracy=0.454, lr=0.1] 26%|██▌       | 43/166 [16:14<45:01, 21.96s/epoch, loss=1.16, accuracy=0.752, val_loss=2.28, val_accuracy=0.448, lr=0.0316] 27%|██▋       | 44/166 [16:37<44:54, 22.09s/epoch, loss=1.16, accuracy=0.751, val_loss=2.59, val_accuracy=0.409, lr=0.1]    27%|██▋       | 45/166 [16:59<44:45, 22.19s/epoch, loss=1.16, accuracy=0.749, val_loss=1.67, val_accuracy=0.58, lr=0.1]  28%|██▊       | 46/166 [17:22<44:33, 22.28s/epoch, loss=1.16, accuracy=0.75, val_loss=1.73, val_accuracy=0.561, lr=0.1] 28%|██▊       | 47/166 [17:44<44:00, 22.19s/epoch, loss=1.15, accuracy=0.752, val_loss=2.18, val_accuracy=0.422, lr=0.1] 29%|██▉       | 48/166 [18:05<43:07, 21.93s/epoch, loss=1.15, accuracy=0.754, val_loss=2.04, val_accuracy=0.52, lr=0.0316] 30%|██▉       | 49/166 [18:26<42:25, 21.75s/epoch, loss=1.16, accuracy=0.75, val_loss=1.59, val_accuracy=0.587, lr=0.1]    30%|███       | 50/166 [18:48<42:03, 21.76s/epoch, loss=1.15, accuracy=0.752, val_loss=1.9, val_accuracy=0.482, lr=0.1] 31%|███       | 51/166 [19:10<42:03, 21.94s/epoch, loss=1.15, accuracy=0.753, val_loss=1.66, val_accuracy=0.596, lr=0.1] 31%|███▏      | 52/166 [19:33<41:58, 22.09s/epoch, loss=1.15, accuracy=0.752, val_loss=2.1, val_accuracy=0.517, lr=0.1]  32%|███▏      | 53/166 [19:54<40:50, 21.69s/epoch, loss=1.16, accuracy=0.753, val_loss=3.12, val_accuracy=0.316, lr=0.0316] 33%|███▎      | 54/166 [20:16<40:41, 21.80s/epoch, loss=1.14, accuracy=0.753, val_loss=2.76, val_accuracy=0.316, lr=0.1]    33%|███▎      | 55/166 [20:38<40:39, 21.98s/epoch, loss=1.15, accuracy=0.752, val_loss=2.33, val_accuracy=0.408, lr=0.1] 34%|███▎      | 56/166 [21:01<40:34, 22.13s/epoch, loss=1.14, accuracy=0.753, val_loss=1.77, val_accuracy=0.566, lr=0.1] 34%|███▍      | 57/166 [21:23<40:21, 22.22s/epoch, loss=1.15, accuracy=0.753, val_loss=4.42, val_accuracy=0.294, lr=0.1] 35%|███▍      | 58/166 [21:46<40:13, 22.34s/epoch, loss=1.15, accuracy=0.755, val_loss=2.22, val_accuracy=0.459, lr=0.0316] 36%|███▌      | 59/166 [22:08<39:55, 22.39s/epoch, loss=1.16, accuracy=0.753, val_loss=2.1, val_accuracy=0.413, lr=0.1]     36%|███▌      | 60/166 [22:31<39:39, 22.44s/epoch, loss=1.15, accuracy=0.754, val_loss=2.24, val_accuracy=0.506, lr=0.1] 37%|███▋      | 61/166 [22:53<39:19, 22.47s/epoch, loss=1.15, accuracy=0.753, val_loss=1.92, val_accuracy=0.523, lr=0.1] 37%|███▋      | 62/166 [23:16<39:00, 22.51s/epoch, loss=1.14, accuracy=0.754, val_loss=2.55, val_accuracy=0.394, lr=0.1] 38%|███▊      | 63/166 [23:38<38:41, 22.54s/epoch, loss=1.14, accuracy=0.754, val_loss=1.81, val_accuracy=0.516, lr=0.0316] 39%|███▊      | 64/166 [24:00<38:02, 22.38s/epoch, loss=1.14, accuracy=0.754, val_loss=1.6, val_accuracy=0.619, lr=0.1]     39%|███▉      | 65/166 [24:23<37:38, 22.36s/epoch, loss=1.14, accuracy=0.754, val_loss=2.3, val_accuracy=0.464, lr=0.1] 40%|███▉      | 66/166 [24:45<37:19, 22.39s/epoch, loss=1.14, accuracy=0.753, val_loss=1.75, val_accuracy=0.582, lr=0.1] 40%|████      | 67/166 [25:06<36:15, 21.98s/epoch, loss=1.14, accuracy=0.754, val_loss=1.62, val_accuracy=0.601, lr=0.1] 41%|████      | 68/166 [25:28<35:59, 22.04s/epoch, loss=1.14, accuracy=0.753, val_loss=3.08, val_accuracy=0.37, lr=0.0316] 42%|████▏     | 69/166 [25:51<35:44, 22.11s/epoch, loss=1.14, accuracy=0.755, val_loss=1.58, val_accuracy=0.603, lr=0.1]   42%|████▏     | 70/166 [26:13<35:32, 22.21s/epoch, loss=1.14, accuracy=0.753, val_loss=2.46, val_accuracy=0.381, lr=0.1] 43%|████▎     | 71/166 [26:36<35:21, 22.34s/epoch, loss=1.14, accuracy=0.755, val_loss=1.87, val_accuracy=0.48, lr=0.1]  43%|████▎     | 72/166 [26:58<35:04, 22.39s/epoch, loss=1.15, accuracy=0.752, val_loss=2.86, val_accuracy=0.402, lr=0.1] 44%|████▍     | 73/166 [27:20<34:17, 22.13s/epoch, loss=1.13, accuracy=0.757, val_loss=1.3, val_accuracy=0.693, lr=0.1]  45%|████▍     | 74/166 [27:42<34:07, 22.26s/epoch, loss=1.14, accuracy=0.754, val_loss=2.31, val_accuracy=0.514, lr=0.1] 45%|████▌     | 75/166 [28:05<33:53, 22.35s/epoch, loss=1.13, accuracy=0.755, val_loss=1.95, val_accuracy=0.506, lr=0.1] 46%|████▌     | 76/166 [28:27<33:29, 22.33s/epoch, loss=1.13, accuracy=0.756, val_loss=2.57, val_accuracy=0.45, lr=0.1]  46%|████▋     | 77/166 [28:49<32:40, 22.03s/epoch, loss=1.14, accuracy=0.754, val_loss=1.82, val_accuracy=0.571, lr=0.1] 47%|████▋     | 78/166 [29:11<32:30, 22.17s/epoch, loss=1.14, accuracy=0.755, val_loss=2.18, val_accuracy=0.396, lr=0.0316] 48%|████▊     | 79/166 [29:34<32:19, 22.29s/epoch, loss=1.14, accuracy=0.754, val_loss=2, val_accuracy=0.468, lr=0.1]       48%|████▊     | 80/166 [29:54<31:16, 21.82s/epoch, loss=1.13, accuracy=0.753, val_loss=2.76, val_accuracy=0.406, lr=0.1] 49%|████▉     | 81/166 [30:16<30:55, 21.83s/epoch, loss=1.14, accuracy=0.753, val_loss=2.43, val_accuracy=0.497, lr=0.1] 49%|████▉     | 82/166 [30:39<30:50, 22.03s/epoch, loss=0.929, accuracy=0.815, val_loss=0.911, val_accuracy=0.806, lr=0.01] 50%|█████     | 83/166 [31:01<30:37, 22.14s/epoch, loss=0.748, accuracy=0.846, val_loss=0.778, val_accuracy=0.824, lr=0.01] 51%|█████     | 84/166 [31:24<30:25, 22.26s/epoch, loss=0.662, accuracy=0.853, val_loss=0.805, val_accuracy=0.794, lr=0.01] 51%|█████     | 85/166 [31:44<29:23, 21.78s/epoch, loss=0.614, accuracy=0.858, val_loss=0.734, val_accuracy=0.815, lr=0.01] 52%|█████▏    | 86/166 [32:06<29:13, 21.92s/epoch, loss=0.593, accuracy=0.86, val_loss=0.785, val_accuracy=0.799, lr=0.01]  52%|█████▏    | 87/166 [32:28<28:44, 21.83s/epoch, loss=0.581, accuracy=0.861, val_loss=0.736, val_accuracy=0.808, lr=0.01] 53%|█████▎    | 88/166 [32:50<28:34, 21.98s/epoch, loss=0.577, accuracy=0.861, val_loss=1.14, val_accuracy=0.708, lr=0.01]  54%|█████▎    | 89/166 [33:13<28:25, 22.15s/epoch, loss=0.574, accuracy=0.862, val_loss=0.78, val_accuracy=0.799, lr=0.01] 54%|█████▍    | 90/166 [33:35<28:09, 22.23s/epoch, loss=0.571, accuracy=0.864, val_loss=0.892, val_accuracy=0.762, lr=0.00316] 55%|█████▍    | 91/166 [33:57<27:33, 22.05s/epoch, loss=0.569, accuracy=0.866, val_loss=0.781, val_accuracy=0.796, lr=0.01]    55%|█████▌    | 92/166 [34:18<26:58, 21.87s/epoch, loss=0.566, accuracy=0.867, val_loss=0.951, val_accuracy=0.753, lr=0.01] 56%|█████▌    | 93/166 [34:41<26:47, 22.03s/epoch, loss=0.569, accuracy=0.869, val_loss=0.868, val_accuracy=0.781, lr=0.01] 57%|█████▋    | 94/166 [35:03<26:36, 22.18s/epoch, loss=0.563, accuracy=0.872, val_loss=0.823, val_accuracy=0.79, lr=0.01]  57%|█████▋    | 95/166 [35:26<26:20, 22.26s/epoch, loss=0.565, accuracy=0.871, val_loss=0.784, val_accuracy=0.796, lr=0.00316] 58%|█████▊    | 96/166 [35:48<26:04, 22.35s/epoch, loss=0.564, accuracy=0.871, val_loss=0.82, val_accuracy=0.788, lr=0.01]     58%|█████▊    | 97/166 [36:11<25:45, 22.40s/epoch, loss=0.567, accuracy=0.87, val_loss=0.993, val_accuracy=0.76, lr=0.01]  59%|█████▉    | 98/166 [36:32<24:52, 21.94s/epoch, loss=0.561, accuracy=0.875, val_loss=0.799, val_accuracy=0.803, lr=0.01] 60%|█████▉    | 99/166 [36:54<24:37, 22.05s/epoch, loss=0.562, accuracy=0.874, val_loss=0.768, val_accuracy=0.81, lr=0.01]  60%|██████    | 100/166 [37:17<24:27, 22.23s/epoch, loss=0.563, accuracy=0.874, val_loss=1.02, val_accuracy=0.763, lr=0.00316] 61%|██████    | 101/166 [37:39<24:06, 22.26s/epoch, loss=0.562, accuracy=0.877, val_loss=0.849, val_accuracy=0.784, lr=0.01]   61%|██████▏   | 102/166 [38:01<23:39, 22.19s/epoch, loss=0.563, accuracy=0.876, val_loss=0.707, val_accuracy=0.826, lr=0.01] 62%|██████▏   | 103/166 [38:23<23:20, 22.23s/epoch, loss=0.563, accuracy=0.875, val_loss=0.799, val_accuracy=0.803, lr=0.01] 63%|██████▎   | 104/166 [38:46<23:03, 22.31s/epoch, loss=0.562, accuracy=0.878, val_loss=0.783, val_accuracy=0.81, lr=0.01]  63%|██████▎   | 105/166 [39:08<22:45, 22.38s/epoch, loss=0.561, accuracy=0.879, val_loss=1.01, val_accuracy=0.756, lr=0.01] 64%|██████▍   | 106/166 [39:31<22:26, 22.45s/epoch, loss=0.56, accuracy=0.879, val_loss=0.789, val_accuracy=0.811, lr=0.01] 64%|██████▍   | 107/166 [39:53<21:57, 22.33s/epoch, loss=0.563, accuracy=0.879, val_loss=0.904, val_accuracy=0.778, lr=0.00316] 65%|██████▌   | 108/166 [40:15<21:33, 22.30s/epoch, loss=0.559, accuracy=0.882, val_loss=0.828, val_accuracy=0.795, lr=0.01]    66%|██████▌   | 109/166 [40:38<21:09, 22.28s/epoch, loss=0.558, accuracy=0.881, val_loss=0.783, val_accuracy=0.81, lr=0.01]  66%|██████▋   | 110/166 [40:59<20:26, 21.90s/epoch, loss=0.562, accuracy=0.878, val_loss=0.914, val_accuracy=0.765, lr=0.01] 67%|██████▋   | 111/166 [41:21<20:06, 21.94s/epoch, loss=0.563, accuracy=0.879, val_loss=0.905, val_accuracy=0.767, lr=0.01] 67%|██████▋   | 112/166 [41:43<19:50, 22.04s/epoch, loss=0.559, accuracy=0.882, val_loss=0.768, val_accuracy=0.814, lr=0.00316] 68%|██████▊   | 113/166 [42:05<19:27, 22.03s/epoch, loss=0.56, accuracy=0.881, val_loss=0.998, val_accuracy=0.753, lr=0.01]     69%|██████▊   | 114/166 [42:27<19:10, 22.12s/epoch, loss=0.558, accuracy=0.883, val_loss=1.16, val_accuracy=0.725, lr=0.01] 69%|██████▉   | 115/166 [42:49<18:37, 21.92s/epoch, loss=0.557, accuracy=0.885, val_loss=0.828, val_accuracy=0.803, lr=0.01] 70%|██████▉   | 116/166 [43:11<18:18, 21.97s/epoch, loss=0.559, accuracy=0.882, val_loss=0.805, val_accuracy=0.802, lr=0.01] 70%|███████   | 117/166 [43:33<17:53, 21.90s/epoch, loss=0.56, accuracy=0.881, val_loss=0.769, val_accuracy=0.819, lr=0.00316] 71%|███████   | 118/166 [43:55<17:32, 21.94s/epoch, loss=0.56, accuracy=0.882, val_loss=0.878, val_accuracy=0.789, lr=0.01]    72%|███████▏  | 119/166 [44:16<17:00, 21.71s/epoch, loss=0.555, accuracy=0.885, val_loss=0.869, val_accuracy=0.788, lr=0.01] 72%|███████▏  | 120/166 [44:37<16:39, 21.72s/epoch, loss=0.567, accuracy=0.883, val_loss=1.16, val_accuracy=0.701, lr=0.01]  73%|███████▎  | 121/166 [44:58<16:02, 21.39s/epoch, loss=0.562, accuracy=0.884, val_loss=0.755, val_accuracy=0.825, lr=0.01] 73%|███████▎  | 122/166 [45:19<15:39, 21.36s/epoch, loss=0.477, accuracy=0.914, val_loss=0.541, val_accuracy=0.89, lr=0.001] 74%|███████▍  | 123/166 [45:40<15:12, 21.22s/epoch, loss=0.428, accuracy=0.929, val_loss=0.522, val_accuracy=0.895, lr=0.001] 75%|███████▍  | 124/166 [46:02<15:02, 21.48s/epoch, loss=0.407, accuracy=0.933, val_loss=0.51, val_accuracy=0.896, lr=0.001]  75%|███████▌  | 125/166 [46:23<14:28, 21.19s/epoch, loss=0.39, accuracy=0.937, val_loss=0.504, val_accuracy=0.897, lr=0.001] 76%|███████▌  | 126/166 [46:45<14:14, 21.36s/epoch, loss=0.375, accuracy=0.94, val_loss=0.507, val_accuracy=0.898, lr=0.001] 77%|███████▋  | 127/166 [47:07<14:06, 21.70s/epoch, loss=0.365, accuracy=0.942, val_loss=0.485, val_accuracy=0.903, lr=0.001] 77%|███████▋  | 128/166 [47:29<13:52, 21.90s/epoch, loss=0.353, accuracy=0.944, val_loss=0.495, val_accuracy=0.898, lr=0.001] 78%|███████▊  | 129/166 [47:52<13:34, 22.02s/epoch, loss=0.344, accuracy=0.945, val_loss=0.481, val_accuracy=0.901, lr=0.001] 78%|███████▊  | 130/166 [48:14<13:13, 22.03s/epoch, loss=0.334, accuracy=0.948, val_loss=0.484, val_accuracy=0.899, lr=0.001] 79%|███████▉  | 131/166 [48:36<12:47, 21.94s/epoch, loss=0.324, accuracy=0.948, val_loss=0.47, val_accuracy=0.9, lr=0.001]    80%|███████▉  | 132/166 [48:57<12:22, 21.85s/epoch, loss=0.316, accuracy=0.95, val_loss=0.512, val_accuracy=0.891, lr=0.001] 80%|████████  | 133/166 [49:19<12:04, 21.96s/epoch, loss=0.308, accuracy=0.952, val_loss=0.482, val_accuracy=0.899, lr=0.001] 81%|████████  | 134/166 [49:41<11:41, 21.92s/epoch, loss=0.302, accuracy=0.952, val_loss=0.472, val_accuracy=0.9, lr=0.001]   81%|████████▏ | 135/166 [50:03<11:22, 22.02s/epoch, loss=0.296, accuracy=0.954, val_loss=0.47, val_accuracy=0.899, lr=0.001] 82%|████████▏ | 136/166 [50:26<11:01, 22.06s/epoch, loss=0.29, accuracy=0.954, val_loss=0.466, val_accuracy=0.898, lr=0.001] 83%|████████▎ | 137/166 [50:48<10:41, 22.11s/epoch, loss=0.282, accuracy=0.954, val_loss=0.499, val_accuracy=0.889, lr=0.001] 83%|████████▎ | 138/166 [51:10<10:19, 22.12s/epoch, loss=0.277, accuracy=0.956, val_loss=0.456, val_accuracy=0.899, lr=0.001] 84%|████████▎ | 139/166 [51:32<09:56, 22.10s/epoch, loss=0.27, accuracy=0.957, val_loss=0.463, val_accuracy=0.9, lr=0.001]    84%|████████▍ | 140/166 [51:54<09:34, 22.09s/epoch, loss=0.267, accuracy=0.958, val_loss=0.47, val_accuracy=0.894, lr=0.001] 85%|████████▍ | 141/166 [52:15<09:00, 21.60s/epoch, loss=0.261, accuracy=0.958, val_loss=0.48, val_accuracy=0.897, lr=0.001] 86%|████████▌ | 142/166 [52:37<08:43, 21.81s/epoch, loss=0.258, accuracy=0.957, val_loss=0.461, val_accuracy=0.896, lr=0.001] 86%|████████▌ | 143/166 [52:58<08:18, 21.68s/epoch, loss=0.253, accuracy=0.959, val_loss=0.457, val_accuracy=0.898, lr=0.000316] 87%|████████▋ | 144/166 [53:20<08:00, 21.84s/epoch, loss=0.249, accuracy=0.959, val_loss=0.468, val_accuracy=0.891, lr=0.001]    87%|████████▋ | 145/166 [53:43<07:41, 21.99s/epoch, loss=0.246, accuracy=0.96, val_loss=0.501, val_accuracy=0.887, lr=0.001]  88%|████████▊ | 146/166 [54:05<07:20, 22.04s/epoch, loss=0.239, accuracy=0.961, val_loss=0.534, val_accuracy=0.881, lr=0.001] 89%|████████▊ | 147/166 [54:27<06:58, 22.05s/epoch, loss=0.242, accuracy=0.96, val_loss=0.456, val_accuracy=0.9, lr=0.001]    89%|████████▉ | 148/166 [54:48<06:32, 21.82s/epoch, loss=0.237, accuracy=0.959, val_loss=0.498, val_accuracy=0.887, lr=0.001] 90%|████████▉ | 149/166 [55:11<06:12, 21.93s/epoch, loss=0.235, accuracy=0.96, val_loss=0.481, val_accuracy=0.891, lr=0.001]  90%|█████████ | 150/166 [55:32<05:49, 21.85s/epoch, loss=0.233, accuracy=0.96, val_loss=0.46, val_accuracy=0.893, lr=0.001]  91%|█████████ | 151/166 [55:54<05:25, 21.73s/epoch, loss=0.23, accuracy=0.96, val_loss=0.474, val_accuracy=0.892, lr=0.001] 92%|█████████▏| 152/166 [56:16<05:05, 21.83s/epoch, loss=0.23, accuracy=0.96, val_loss=0.453, val_accuracy=0.895, lr=0.001] 92%|█████████▏| 153/166 [56:38<04:43, 21.84s/epoch, loss=0.227, accuracy=0.959, val_loss=0.491, val_accuracy=0.888, lr=0.001] 93%|█████████▎| 154/166 [56:58<04:17, 21.43s/epoch, loss=0.225, accuracy=0.961, val_loss=0.476, val_accuracy=0.888, lr=0.001] 93%|█████████▎| 155/166 [57:18<03:52, 21.10s/epoch, loss=0.227, accuracy=0.96, val_loss=0.583, val_accuracy=0.866, lr=0.001]  94%|█████████▍| 156/166 [57:40<03:32, 21.30s/epoch, loss=0.222, accuracy=0.961, val_loss=0.488, val_accuracy=0.885, lr=0.001] 95%|█████████▍| 157/166 [58:02<03:13, 21.49s/epoch, loss=0.223, accuracy=0.96, val_loss=0.494, val_accuracy=0.883, lr=0.000316] 95%|█████████▌| 158/166 [58:24<02:53, 21.69s/epoch, loss=0.221, accuracy=0.96, val_loss=0.482, val_accuracy=0.888, lr=0.001]    96%|█████████▌| 159/166 [58:46<02:32, 21.78s/epoch, loss=0.217, accuracy=0.962, val_loss=0.512, val_accuracy=0.885, lr=0.001] 96%|█████████▋| 160/166 [59:08<02:10, 21.79s/epoch, loss=0.22, accuracy=0.96, val_loss=0.538, val_accuracy=0.874, lr=0.001]   97%|█████████▋| 161/166 [59:30<01:49, 21.91s/epoch, loss=0.218, accuracy=0.961, val_loss=0.467, val_accuracy=0.888, lr=0.001] 98%|█████████▊| 162/166 [59:52<01:27, 21.78s/epoch, loss=0.197, accuracy=0.97, val_loss=0.407, val_accuracy=0.904, lr=1e-04]  98%|█████████▊| 163/166 [1:00:12<01:04, 21.44s/epoch, loss=0.182, accuracy=0.975, val_loss=0.405, val_accuracy=0.904, lr=1e-04] 99%|█████████▉| 164/166 [1:00:34<00:43, 21.63s/epoch, loss=0.178, accuracy=0.977, val_loss=0.404, val_accuracy=0.906, lr=1e-04] 99%|█████████▉| 165/166 [1:00:56<00:21, 21.73s/epoch, loss=0.174, accuracy=0.979, val_loss=0.405, val_accuracy=0.908, lr=1e-04]100%|██████████| 166/166 [1:01:18<00:00, 21.64s/epoch, loss=0.172, accuracy=0.979, val_loss=0.404, val_accuracy=0.907, lr=1e-04]100%|██████████| 166/166 [1:01:18<00:00, 22.16s/epoch, loss=0.172, accuracy=0.979, val_loss=0.404, val_accuracy=0.907, lr=1e-04]
Using real-time data augmentation.
Test loss: 0.40374818444252014
Test accuracy: 0.9067999720573425


* * * Run SGD for ID = 9_8. * * *


2024-02-15 18:13:51.447150: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 18:13:54.091787: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 18:13:54.092928: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-15 18:13:54.128488: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-15 18:13:54.128520: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 18:13:54.131339: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 18:13:54.131378: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 18:13:54.133572: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 18:13:54.134217: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 18:13:54.136499: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 18:13:54.137981: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 18:13:54.142559: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 18:13:54.143037: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 18:13:54.143112: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 18:13:55.326269: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-15 18:13:55.327310: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 18:13:55.327937: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-15 18:13:55.327967: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 18:13:55.328024: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 18:13:55.328044: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 18:13:55.328062: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 18:13:55.328080: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 18:13:55.328098: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 18:13:55.328115: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 18:13:55.328133: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 18:13:55.328594: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 18:13:55.328625: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 18:13:55.928193: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-15 18:13:55.928277: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-15 18:13:55.928295: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-15 18:13:55.929148: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': 98, 'batch_size': 128, 'epochs': 166, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/166 [00:00<?, ?epoch/s]2024-02-15 18:13:56.686819: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-15 18:13:56.698397: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2599900000 Hz
2024-02-15 18:13:58.545708: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 18:13:58.762135: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 18:13:59.469800: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-15 18:13:59.516218: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/166 [00:56<2:36:15, 56.82s/epoch, loss=3.52, accuracy=0.33, val_loss=3.01, val_accuracy=0.221, lr=0.1]  1%|          | 2/166 [01:19<1:41:10, 37.01s/epoch, loss=1.65, accuracy=0.494, val_loss=2.23, val_accuracy=0.343, lr=0.1]  2%|▏         | 3/166 [01:42<1:22:51, 30.50s/epoch, loss=1.39, accuracy=0.614, val_loss=2.31, val_accuracy=0.399, lr=0.1]  2%|▏         | 4/166 [02:04<1:13:13, 27.12s/epoch, loss=1.3, accuracy=0.672, val_loss=2.07, val_accuracy=0.414, lr=0.1]   3%|▎         | 5/166 [02:27<1:08:23, 25.49s/epoch, loss=1.27, accuracy=0.695, val_loss=1.7, val_accuracy=0.584, lr=0.1]  4%|▎         | 6/166 [02:48<1:04:26, 24.17s/epoch, loss=1.25, accuracy=0.708, val_loss=2.1, val_accuracy=0.459, lr=0.1]  4%|▍         | 7/166 [03:10<1:01:59, 23.40s/epoch, loss=1.23, accuracy=0.718, val_loss=1.42, val_accuracy=0.639, lr=0.1]  5%|▍         | 8/166 [03:33<1:00:54, 23.13s/epoch, loss=1.22, accuracy=0.721, val_loss=1.73, val_accuracy=0.578, lr=0.1]  5%|▌         | 9/166 [03:56<1:00:17, 23.04s/epoch, loss=1.21, accuracy=0.727, val_loss=1.82, val_accuracy=0.514, lr=0.1]  6%|▌         | 10/166 [04:17<58:56, 22.67s/epoch, loss=1.21, accuracy=0.729, val_loss=1.76, val_accuracy=0.592, lr=0.1]   7%|▋         | 11/166 [04:39<57:24, 22.22s/epoch, loss=1.21, accuracy=0.729, val_loss=1.64, val_accuracy=0.574, lr=0.1]  7%|▋         | 12/166 [05:00<56:17, 21.93s/epoch, loss=1.2, accuracy=0.734, val_loss=1.83, val_accuracy=0.544, lr=0.0316]  8%|▊         | 13/166 [05:23<56:33, 22.18s/epoch, loss=1.2, accuracy=0.733, val_loss=2.23, val_accuracy=0.386, lr=0.1]     8%|▊         | 14/166 [05:46<56:43, 22.39s/epoch, loss=1.2, accuracy=0.737, val_loss=1.65, val_accuracy=0.589, lr=0.1]  9%|▉         | 15/166 [06:08<56:45, 22.56s/epoch, loss=1.2, accuracy=0.737, val_loss=1.7, val_accuracy=0.591, lr=0.1]  10%|▉         | 16/166 [06:31<56:37, 22.65s/epoch, loss=1.19, accuracy=0.738, val_loss=2.05, val_accuracy=0.461, lr=0.1] 10%|█         | 17/166 [06:54<56:22, 22.70s/epoch, loss=1.2, accuracy=0.739, val_loss=2.45, val_accuracy=0.392, lr=0.0316] 11%|█         | 18/166 [07:17<56:08, 22.76s/epoch, loss=1.19, accuracy=0.742, val_loss=1.54, val_accuracy=0.614, lr=0.1]   11%|█▏        | 19/166 [07:40<55:45, 22.76s/epoch, loss=1.19, accuracy=0.741, val_loss=2.69, val_accuracy=0.365, lr=0.1] 12%|█▏        | 20/166 [08:01<54:34, 22.43s/epoch, loss=1.18, accuracy=0.744, val_loss=3.44, val_accuracy=0.249, lr=0.1] 13%|█▎        | 21/166 [08:24<54:22, 22.50s/epoch, loss=1.18, accuracy=0.743, val_loss=2.5, val_accuracy=0.47, lr=0.1]   13%|█▎        | 22/166 [08:45<52:56, 22.06s/epoch, loss=1.17, accuracy=0.745, val_loss=1.66, val_accuracy=0.582, lr=0.0316] 14%|█▍        | 23/166 [09:07<52:14, 21.92s/epoch, loss=1.18, accuracy=0.746, val_loss=1.43, val_accuracy=0.662, lr=0.1]    14%|█▍        | 24/166 [09:28<51:18, 21.68s/epoch, loss=1.18, accuracy=0.746, val_loss=1.7, val_accuracy=0.583, lr=0.1]  15%|█▌        | 25/166 [09:49<50:33, 21.51s/epoch, loss=1.18, accuracy=0.746, val_loss=2.15, val_accuracy=0.498, lr=0.1] 16%|█▌        | 26/166 [10:12<50:59, 21.85s/epoch, loss=1.18, accuracy=0.746, val_loss=2.13, val_accuracy=0.408, lr=0.1] 16%|█▋        | 27/166 [10:34<51:14, 22.12s/epoch, loss=1.17, accuracy=0.748, val_loss=1.62, val_accuracy=0.588, lr=0.0316] 17%|█▋        | 28/166 [10:57<51:25, 22.36s/epoch, loss=1.18, accuracy=0.747, val_loss=2.89, val_accuracy=0.371, lr=0.1]    17%|█▋        | 29/166 [11:20<51:24, 22.52s/epoch, loss=1.17, accuracy=0.748, val_loss=6.13, val_accuracy=0.189, lr=0.1] 18%|█▊        | 30/166 [11:43<51:10, 22.58s/epoch, loss=1.17, accuracy=0.748, val_loss=1.44, val_accuracy=0.664, lr=0.1] 19%|█▊        | 31/166 [12:06<51:00, 22.67s/epoch, loss=1.17, accuracy=0.748, val_loss=2.91, val_accuracy=0.394, lr=0.1] 19%|█▉        | 32/166 [12:27<49:35, 22.21s/epoch, loss=1.17, accuracy=0.748, val_loss=2.46, val_accuracy=0.398, lr=0.0316] 20%|█▉        | 33/166 [12:48<48:28, 21.87s/epoch, loss=1.16, accuracy=0.747, val_loss=1.91, val_accuracy=0.55, lr=0.1]     20%|██        | 34/166 [13:11<48:47, 22.18s/epoch, loss=1.16, accuracy=0.749, val_loss=2.17, val_accuracy=0.439, lr=0.1] 21%|██        | 35/166 [13:34<48:43, 22.31s/epoch, loss=1.17, accuracy=0.752, val_loss=1.97, val_accuracy=0.492, lr=0.1] 22%|██▏       | 36/166 [13:56<48:17, 22.29s/epoch, loss=1.16, accuracy=0.748, val_loss=1.67, val_accuracy=0.574, lr=0.1] 22%|██▏       | 37/166 [14:19<48:14, 22.44s/epoch, loss=1.16, accuracy=0.748, val_loss=1.94, val_accuracy=0.546, lr=0.0316] 23%|██▎       | 38/166 [14:39<46:51, 21.96s/epoch, loss=1.17, accuracy=0.75, val_loss=1.59, val_accuracy=0.613, lr=0.1]     23%|██▎       | 39/166 [15:02<46:54, 22.16s/epoch, loss=1.17, accuracy=0.749, val_loss=1.78, val_accuracy=0.583, lr=0.1] 24%|██▍       | 40/166 [15:23<45:58, 21.89s/epoch, loss=1.16, accuracy=0.75, val_loss=1.3, val_accuracy=0.697, lr=0.1]   25%|██▍       | 41/166 [15:46<46:06, 22.13s/epoch, loss=1.17, accuracy=0.751, val_loss=1.47, val_accuracy=0.652, lr=0.1] 25%|██▌       | 42/166 [16:09<46:03, 22.29s/epoch, loss=1.16, accuracy=0.752, val_loss=2.48, val_accuracy=0.508, lr=0.1] 26%|██▌       | 43/166 [16:30<45:07, 22.01s/epoch, loss=1.16, accuracy=0.753, val_loss=2.02, val_accuracy=0.478, lr=0.1] 27%|██▋       | 44/166 [16:53<45:08, 22.20s/epoch, loss=1.16, accuracy=0.752, val_loss=1.61, val_accuracy=0.569, lr=0.1] 27%|██▋       | 45/166 [17:15<45:02, 22.34s/epoch, loss=1.15, accuracy=0.753, val_loss=1.44, val_accuracy=0.668, lr=0.0316] 28%|██▊       | 46/166 [17:38<44:49, 22.41s/epoch, loss=1.16, accuracy=0.751, val_loss=1.55, val_accuracy=0.593, lr=0.1]    28%|██▊       | 47/166 [18:00<44:21, 22.37s/epoch, loss=1.15, accuracy=0.754, val_loss=1.81, val_accuracy=0.56, lr=0.1]  29%|██▉       | 48/166 [18:21<43:15, 22.00s/epoch, loss=1.16, accuracy=0.752, val_loss=1.69, val_accuracy=0.581, lr=0.1] 30%|██▉       | 49/166 [18:44<43:05, 22.10s/epoch, loss=1.15, accuracy=0.753, val_loss=2.39, val_accuracy=0.464, lr=0.1] 30%|███       | 50/166 [19:05<42:32, 22.00s/epoch, loss=1.15, accuracy=0.753, val_loss=1.74, val_accuracy=0.535, lr=0.0316] 31%|███       | 51/166 [19:27<42:01, 21.93s/epoch, loss=1.15, accuracy=0.753, val_loss=2.25, val_accuracy=0.464, lr=0.1]    31%|███▏      | 52/166 [19:50<42:07, 22.17s/epoch, loss=1.14, accuracy=0.755, val_loss=2.18, val_accuracy=0.478, lr=0.1] 32%|███▏      | 53/166 [20:13<42:06, 22.36s/epoch, loss=1.15, accuracy=0.752, val_loss=2.19, val_accuracy=0.47, lr=0.1]  33%|███▎      | 54/166 [20:36<42:04, 22.54s/epoch, loss=1.15, accuracy=0.752, val_loss=1.65, val_accuracy=0.604, lr=0.1] 33%|███▎      | 55/166 [20:57<41:12, 22.27s/epoch, loss=1.14, accuracy=0.754, val_loss=2.05, val_accuracy=0.479, lr=0.0316] 34%|███▎      | 56/166 [21:19<40:41, 22.19s/epoch, loss=1.15, accuracy=0.751, val_loss=3.3, val_accuracy=0.372, lr=0.1]     34%|███▍      | 57/166 [21:42<40:34, 22.34s/epoch, loss=1.14, accuracy=0.754, val_loss=1.7, val_accuracy=0.599, lr=0.1] 35%|███▍      | 58/166 [22:05<40:30, 22.51s/epoch, loss=1.14, accuracy=0.753, val_loss=2.16, val_accuracy=0.469, lr=0.1] 36%|███▌      | 59/166 [22:27<39:58, 22.41s/epoch, loss=1.15, accuracy=0.754, val_loss=1.67, val_accuracy=0.587, lr=0.1] 36%|███▌      | 60/166 [22:50<39:42, 22.48s/epoch, loss=1.14, accuracy=0.755, val_loss=1.96, val_accuracy=0.528, lr=0.0316] 37%|███▋      | 61/166 [23:11<38:33, 22.03s/epoch, loss=1.14, accuracy=0.754, val_loss=2.39, val_accuracy=0.377, lr=0.1]    37%|███▋      | 62/166 [23:33<38:19, 22.12s/epoch, loss=1.14, accuracy=0.756, val_loss=1.45, val_accuracy=0.648, lr=0.1] 38%|███▊      | 63/166 [23:56<38:17, 22.30s/epoch, loss=1.13, accuracy=0.756, val_loss=2.42, val_accuracy=0.43, lr=0.1]  39%|███▊      | 64/166 [24:18<37:42, 22.18s/epoch, loss=1.14, accuracy=0.757, val_loss=1.89, val_accuracy=0.554, lr=0.1] 39%|███▉      | 65/166 [24:40<37:40, 22.38s/epoch, loss=1.15, accuracy=0.752, val_loss=4.03, val_accuracy=0.298, lr=0.0316] 40%|███▉      | 66/166 [25:03<37:07, 22.27s/epoch, loss=1.14, accuracy=0.756, val_loss=2.06, val_accuracy=0.514, lr=0.1]    40%|████      | 67/166 [25:24<36:18, 22.01s/epoch, loss=1.14, accuracy=0.757, val_loss=1.94, val_accuracy=0.507, lr=0.1] 41%|████      | 68/166 [25:46<36:13, 22.18s/epoch, loss=1.14, accuracy=0.754, val_loss=3.52, val_accuracy=0.303, lr=0.1] 42%|████▏     | 69/166 [26:07<35:15, 21.81s/epoch, loss=1.14, accuracy=0.755, val_loss=2.37, val_accuracy=0.398, lr=0.1] 42%|████▏     | 70/166 [26:30<35:10, 21.98s/epoch, loss=1.14, accuracy=0.755, val_loss=2.68, val_accuracy=0.419, lr=0.0316] 43%|████▎     | 71/166 [26:53<35:15, 22.27s/epoch, loss=1.14, accuracy=0.756, val_loss=1.69, val_accuracy=0.612, lr=0.1]    43%|████▎     | 72/166 [27:16<35:15, 22.50s/epoch, loss=1.14, accuracy=0.756, val_loss=2.55, val_accuracy=0.398, lr=0.1] 44%|████▍     | 73/166 [27:39<35:00, 22.59s/epoch, loss=1.14, accuracy=0.756, val_loss=1.68, val_accuracy=0.561, lr=0.1] 45%|████▍     | 74/166 [28:00<34:04, 22.22s/epoch, loss=1.14, accuracy=0.755, val_loss=1.82, val_accuracy=0.501, lr=0.1] 45%|████▌     | 75/166 [28:22<33:50, 22.31s/epoch, loss=1.14, accuracy=0.752, val_loss=1.77, val_accuracy=0.543, lr=0.0316] 46%|████▌     | 76/166 [28:44<33:13, 22.16s/epoch, loss=1.14, accuracy=0.754, val_loss=1.81, val_accuracy=0.551, lr=0.1]    46%|████▋     | 77/166 [29:06<32:46, 22.09s/epoch, loss=1.14, accuracy=0.756, val_loss=2.53, val_accuracy=0.49, lr=0.1]  47%|████▋     | 78/166 [29:29<32:45, 22.34s/epoch, loss=1.14, accuracy=0.755, val_loss=1.87, val_accuracy=0.5, lr=0.1]  48%|████▊     | 79/166 [29:52<32:32, 22.44s/epoch, loss=1.13, accuracy=0.755, val_loss=2.21, val_accuracy=0.48, lr=0.1] 48%|████▊     | 80/166 [30:15<32:26, 22.64s/epoch, loss=1.14, accuracy=0.753, val_loss=1.99, val_accuracy=0.482, lr=0.0316] 49%|████▉     | 81/166 [30:36<31:27, 22.21s/epoch, loss=1.14, accuracy=0.755, val_loss=1.99, val_accuracy=0.52, lr=0.1]     49%|████▉     | 82/166 [30:59<31:25, 22.45s/epoch, loss=0.923, accuracy=0.815, val_loss=0.904, val_accuracy=0.804, lr=0.01] 50%|█████     | 83/166 [31:22<31:13, 22.57s/epoch, loss=0.742, accuracy=0.847, val_loss=0.819, val_accuracy=0.81, lr=0.01]  51%|█████     | 84/166 [31:45<30:56, 22.64s/epoch, loss=0.654, accuracy=0.855, val_loss=0.771, val_accuracy=0.813, lr=0.01] 51%|█████     | 85/166 [32:07<30:29, 22.59s/epoch, loss=0.611, accuracy=0.86, val_loss=0.77, val_accuracy=0.798, lr=0.01]   52%|█████▏    | 86/166 [32:30<30:18, 22.73s/epoch, loss=0.588, accuracy=0.863, val_loss=0.704, val_accuracy=0.815, lr=0.01] 52%|█████▏    | 87/166 [32:53<29:55, 22.73s/epoch, loss=0.581, accuracy=0.86, val_loss=0.844, val_accuracy=0.782, lr=0.01]  53%|█████▎    | 88/166 [33:14<29:00, 22.32s/epoch, loss=0.57, accuracy=0.863, val_loss=0.763, val_accuracy=0.803, lr=0.01] 54%|█████▎    | 89/166 [33:37<28:40, 22.35s/epoch, loss=0.567, accuracy=0.865, val_loss=0.733, val_accuracy=0.821, lr=0.01] 54%|█████▍    | 90/166 [33:58<27:47, 21.95s/epoch, loss=0.566, accuracy=0.866, val_loss=0.814, val_accuracy=0.795, lr=0.01] 55%|█████▍    | 91/166 [34:21<27:47, 22.23s/epoch, loss=0.564, accuracy=0.867, val_loss=0.828, val_accuracy=0.777, lr=0.00316] 55%|█████▌    | 92/166 [34:42<27:03, 21.93s/epoch, loss=0.566, accuracy=0.868, val_loss=0.808, val_accuracy=0.793, lr=0.01]    56%|█████▌    | 93/166 [35:03<26:24, 21.70s/epoch, loss=0.569, accuracy=0.869, val_loss=0.865, val_accuracy=0.786, lr=0.01] 57%|█████▋    | 94/166 [35:26<26:29, 22.07s/epoch, loss=0.561, accuracy=0.87, val_loss=0.785, val_accuracy=0.805, lr=0.01]  57%|█████▋    | 95/166 [35:49<26:22, 22.29s/epoch, loss=0.557, accuracy=0.874, val_loss=0.693, val_accuracy=0.83, lr=0.01] 58%|█████▊    | 96/166 [36:10<25:46, 22.09s/epoch, loss=0.56, accuracy=0.872, val_loss=0.763, val_accuracy=0.804, lr=0.01] 58%|█████▊    | 97/166 [36:32<25:03, 21.78s/epoch, loss=0.564, accuracy=0.873, val_loss=0.775, val_accuracy=0.81, lr=0.01] 59%|█████▉    | 98/166 [36:53<24:28, 21.59s/epoch, loss=0.555, accuracy=0.876, val_loss=0.704, val_accuracy=0.826, lr=0.01] 60%|█████▉    | 99/166 [37:15<24:29, 21.94s/epoch, loss=0.555, accuracy=0.877, val_loss=0.901, val_accuracy=0.755, lr=0.01] 60%|██████    | 100/166 [37:38<24:26, 22.22s/epoch, loss=0.558, accuracy=0.875, val_loss=0.814, val_accuracy=0.797, lr=0.00316] 61%|██████    | 101/166 [38:00<23:49, 21.99s/epoch, loss=0.563, accuracy=0.876, val_loss=0.79, val_accuracy=0.809, lr=0.01]     61%|██████▏   | 102/166 [38:23<23:48, 22.32s/epoch, loss=0.559, accuracy=0.876, val_loss=0.721, val_accuracy=0.826, lr=0.01] 62%|██████▏   | 103/166 [38:45<23:31, 22.40s/epoch, loss=0.556, accuracy=0.879, val_loss=0.867, val_accuracy=0.775, lr=0.01] 63%|██████▎   | 104/166 [39:07<22:47, 22.05s/epoch, loss=0.557, accuracy=0.879, val_loss=0.776, val_accuracy=0.81, lr=0.01]  63%|██████▎   | 105/166 [39:28<22:17, 21.93s/epoch, loss=0.559, accuracy=0.879, val_loss=0.979, val_accuracy=0.75, lr=0.00316] 64%|██████▍   | 106/166 [39:51<22:14, 22.24s/epoch, loss=0.562, accuracy=0.879, val_loss=1.27, val_accuracy=0.695, lr=0.01]    64%|██████▍   | 107/166 [40:14<22:04, 22.46s/epoch, loss=0.558, accuracy=0.879, val_loss=1.08, val_accuracy=0.75, lr=0.01]  65%|██████▌   | 108/166 [40:37<21:43, 22.48s/epoch, loss=0.555, accuracy=0.882, val_loss=0.861, val_accuracy=0.78, lr=0.01] 66%|██████▌   | 109/166 [41:00<21:26, 22.57s/epoch, loss=0.559, accuracy=0.881, val_loss=0.706, val_accuracy=0.827, lr=0.01] 66%|██████▋   | 110/166 [41:22<21:04, 22.58s/epoch, loss=0.562, accuracy=0.88, val_loss=0.755, val_accuracy=0.819, lr=0.00316] 67%|██████▋   | 111/166 [41:45<20:44, 22.62s/epoch, loss=0.559, accuracy=0.882, val_loss=0.831, val_accuracy=0.8, lr=0.01]     67%|██████▋   | 112/166 [42:07<20:10, 22.41s/epoch, loss=0.559, accuracy=0.881, val_loss=0.813, val_accuracy=0.807, lr=0.01] 68%|██████▊   | 113/166 [42:28<19:26, 22.00s/epoch, loss=0.562, accuracy=0.879, val_loss=0.841, val_accuracy=0.804, lr=0.01] 69%|██████▊   | 114/166 [42:51<19:18, 22.28s/epoch, loss=0.552, accuracy=0.886, val_loss=0.814, val_accuracy=0.805, lr=0.01] 69%|██████▉   | 115/166 [43:14<19:06, 22.48s/epoch, loss=0.559, accuracy=0.882, val_loss=1.6, val_accuracy=0.63, lr=0.00316] 70%|██████▉   | 116/166 [43:35<18:25, 22.12s/epoch, loss=0.56, accuracy=0.883, val_loss=0.797, val_accuracy=0.803, lr=0.01]  70%|███████   | 117/166 [43:57<17:55, 21.95s/epoch, loss=0.556, accuracy=0.883, val_loss=0.974, val_accuracy=0.767, lr=0.01] 71%|███████   | 118/166 [44:18<17:20, 21.69s/epoch, loss=0.553, accuracy=0.884, val_loss=0.793, val_accuracy=0.813, lr=0.01] 72%|███████▏  | 119/166 [44:39<16:58, 21.67s/epoch, loss=0.555, accuracy=0.884, val_loss=0.957, val_accuracy=0.759, lr=0.01] 72%|███████▏  | 120/166 [45:02<16:45, 21.86s/epoch, loss=0.559, accuracy=0.882, val_loss=0.762, val_accuracy=0.821, lr=0.00316] 73%|███████▎  | 121/166 [45:23<16:25, 21.90s/epoch, loss=0.559, accuracy=0.882, val_loss=0.756, val_accuracy=0.823, lr=0.01]    73%|███████▎  | 122/166 [45:46<16:13, 22.14s/epoch, loss=0.479, accuracy=0.911, val_loss=0.551, val_accuracy=0.885, lr=0.001] 74%|███████▍  | 123/166 [46:09<16:01, 22.36s/epoch, loss=0.427, accuracy=0.927, val_loss=0.532, val_accuracy=0.89, lr=0.001]  75%|███████▍  | 124/166 [46:32<15:43, 22.48s/epoch, loss=0.405, accuracy=0.933, val_loss=0.521, val_accuracy=0.894, lr=0.001] 75%|███████▌  | 125/166 [46:54<15:14, 22.30s/epoch, loss=0.389, accuracy=0.936, val_loss=0.513, val_accuracy=0.894, lr=0.001] 76%|███████▌  | 126/166 [47:15<14:36, 21.92s/epoch, loss=0.377, accuracy=0.939, val_loss=0.503, val_accuracy=0.896, lr=0.001] 77%|███████▋  | 127/166 [47:37<14:13, 21.89s/epoch, loss=0.366, accuracy=0.939, val_loss=0.496, val_accuracy=0.896, lr=0.001] 77%|███████▋  | 128/166 [47:58<13:48, 21.80s/epoch, loss=0.353, accuracy=0.944, val_loss=0.488, val_accuracy=0.897, lr=0.001] 78%|███████▊  | 129/166 [48:19<13:17, 21.55s/epoch, loss=0.344, accuracy=0.945, val_loss=0.483, val_accuracy=0.897, lr=0.001] 78%|███████▊  | 130/166 [48:42<13:06, 21.86s/epoch, loss=0.333, accuracy=0.946, val_loss=0.5, val_accuracy=0.893, lr=0.001]   79%|███████▉  | 131/166 [49:05<12:55, 22.16s/epoch, loss=0.324, accuracy=0.949, val_loss=0.489, val_accuracy=0.894, lr=0.001] 80%|███████▉  | 132/166 [49:28<12:41, 22.40s/epoch, loss=0.317, accuracy=0.948, val_loss=0.492, val_accuracy=0.895, lr=0.001] 80%|████████  | 133/166 [49:50<12:17, 22.34s/epoch, loss=0.31, accuracy=0.95, val_loss=0.474, val_accuracy=0.9, lr=0.001]     81%|████████  | 134/166 [50:12<11:58, 22.45s/epoch, loss=0.303, accuracy=0.951, val_loss=0.485, val_accuracy=0.896, lr=0.001] 81%|████████▏ | 135/166 [50:35<11:37, 22.49s/epoch, loss=0.295, accuracy=0.953, val_loss=0.476, val_accuracy=0.898, lr=0.001] 82%|████████▏ | 136/166 [50:58<11:15, 22.52s/epoch, loss=0.289, accuracy=0.952, val_loss=0.48, val_accuracy=0.895, lr=0.001]  83%|████████▎ | 137/166 [51:20<10:56, 22.62s/epoch, loss=0.283, accuracy=0.953, val_loss=0.484, val_accuracy=0.896, lr=0.001] 83%|████████▎ | 138/166 [51:42<10:23, 22.26s/epoch, loss=0.276, accuracy=0.955, val_loss=0.471, val_accuracy=0.896, lr=0.001] 84%|████████▎ | 139/166 [52:05<10:05, 22.42s/epoch, loss=0.271, accuracy=0.956, val_loss=0.503, val_accuracy=0.893, lr=0.001] 84%|████████▍ | 140/166 [52:27<09:43, 22.45s/epoch, loss=0.266, accuracy=0.957, val_loss=0.489, val_accuracy=0.892, lr=0.001] 85%|████████▍ | 141/166 [52:50<09:21, 22.47s/epoch, loss=0.264, accuracy=0.956, val_loss=0.497, val_accuracy=0.891, lr=0.001] 86%|████████▌ | 142/166 [53:11<08:47, 22.00s/epoch, loss=0.259, accuracy=0.957, val_loss=0.454, val_accuracy=0.896, lr=0.001] 86%|████████▌ | 143/166 [53:32<08:24, 21.93s/epoch, loss=0.255, accuracy=0.958, val_loss=0.464, val_accuracy=0.895, lr=0.001] 87%|████████▋ | 144/166 [53:55<08:06, 22.10s/epoch, loss=0.252, accuracy=0.959, val_loss=0.466, val_accuracy=0.896, lr=0.001] 87%|████████▋ | 145/166 [54:17<07:41, 21.99s/epoch, loss=0.247, accuracy=0.959, val_loss=0.459, val_accuracy=0.895, lr=0.001] 88%|████████▊ | 146/166 [54:39<07:24, 22.23s/epoch, loss=0.245, accuracy=0.958, val_loss=0.501, val_accuracy=0.887, lr=0.001] 89%|████████▊ | 147/166 [55:02<07:04, 22.35s/epoch, loss=0.24, accuracy=0.96, val_loss=0.483, val_accuracy=0.889, lr=0.000316] 89%|████████▉ | 148/166 [55:25<06:43, 22.41s/epoch, loss=0.24, accuracy=0.958, val_loss=0.467, val_accuracy=0.89, lr=0.001]    90%|████████▉ | 149/166 [55:47<06:21, 22.44s/epoch, loss=0.235, accuracy=0.96, val_loss=0.484, val_accuracy=0.893, lr=0.001] 90%|█████████ | 150/166 [56:10<06:00, 22.53s/epoch, loss=0.234, accuracy=0.959, val_loss=0.503, val_accuracy=0.885, lr=0.001] 91%|█████████ | 151/166 [56:33<05:38, 22.58s/epoch, loss=0.231, accuracy=0.96, val_loss=0.465, val_accuracy=0.897, lr=0.001]  92%|█████████▏| 152/166 [56:55<05:16, 22.63s/epoch, loss=0.231, accuracy=0.959, val_loss=0.525, val_accuracy=0.882, lr=0.000316] 92%|█████████▏| 153/166 [57:18<04:54, 22.67s/epoch, loss=0.227, accuracy=0.961, val_loss=0.49, val_accuracy=0.894, lr=0.001]     93%|█████████▎| 154/166 [57:41<04:32, 22.69s/epoch, loss=0.227, accuracy=0.96, val_loss=0.466, val_accuracy=0.895, lr=0.001] 93%|█████████▎| 155/166 [58:03<04:07, 22.52s/epoch, loss=0.226, accuracy=0.959, val_loss=0.463, val_accuracy=0.893, lr=0.001] 94%|█████████▍| 156/166 [58:24<03:40, 22.02s/epoch, loss=0.222, accuracy=0.961, val_loss=0.473, val_accuracy=0.894, lr=0.001] 95%|█████████▍| 157/166 [58:45<03:17, 21.89s/epoch, loss=0.223, accuracy=0.96, val_loss=0.486, val_accuracy=0.888, lr=0.000316] 95%|█████████▌| 158/166 [59:08<02:56, 22.08s/epoch, loss=0.22, accuracy=0.961, val_loss=0.502, val_accuracy=0.885, lr=0.001]    96%|█████████▌| 159/166 [59:30<02:34, 22.04s/epoch, loss=0.22, accuracy=0.959, val_loss=0.495, val_accuracy=0.885, lr=0.001] 96%|█████████▋| 160/166 [59:52<02:12, 22.07s/epoch, loss=0.225, accuracy=0.958, val_loss=0.498, val_accuracy=0.88, lr=0.001] 97%|█████████▋| 161/166 [1:00:14<01:50, 22.03s/epoch, loss=0.219, accuracy=0.961, val_loss=0.483, val_accuracy=0.89, lr=0.001] 98%|█████████▊| 162/166 [1:00:36<01:28, 22.19s/epoch, loss=0.195, accuracy=0.97, val_loss=0.424, val_accuracy=0.904, lr=1e-04] 98%|█████████▊| 163/166 [1:00:59<01:07, 22.34s/epoch, loss=0.184, accuracy=0.974, val_loss=0.419, val_accuracy=0.907, lr=1e-04] 99%|█████████▉| 164/166 [1:01:22<00:44, 22.43s/epoch, loss=0.179, accuracy=0.976, val_loss=0.421, val_accuracy=0.906, lr=1e-04] 99%|█████████▉| 165/166 [1:01:44<00:22, 22.43s/epoch, loss=0.176, accuracy=0.977, val_loss=0.42, val_accuracy=0.908, lr=1e-04] 100%|██████████| 166/166 [1:02:06<00:00, 22.27s/epoch, loss=0.174, accuracy=0.978, val_loss=0.421, val_accuracy=0.906, lr=1e-04]100%|██████████| 166/166 [1:02:06<00:00, 22.45s/epoch, loss=0.174, accuracy=0.978, val_loss=0.421, val_accuracy=0.906, lr=1e-04]
Using real-time data augmentation.
Test loss: 0.42068666219711304
Test accuracy: 0.906499981880188


* * * Run SGD for ID = 9_9. * * *


2024-02-15 19:16:05.791925: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 19:16:10.030702: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 19:16:10.031893: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-02-15 19:16:10.068939: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-15 19:16:10.068967: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 19:16:10.073719: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 19:16:10.073757: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 19:16:10.085014: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 19:16:10.086752: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 19:16:10.089753: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 19:16:10.115046: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 19:16:10.119981: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 19:16:10.120490: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 19:16:10.120569: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 19:16:11.346357: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-15 19:16:11.346947: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-02-15 19:16:11.347552: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-02-15 19:16:11.347583: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 19:16:11.347635: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 19:16:11.347655: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-02-15 19:16:11.347672: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-02-15 19:16:11.347692: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-02-15 19:16:11.347709: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-02-15 19:16:11.347727: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-02-15 19:16:11.347746: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 19:16:11.348178: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-02-15 19:16:11.348215: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-02-15 19:16:11.959290: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-02-15 19:16:11.959363: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-02-15 19:16:11.959373: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-02-15 19:16:11.960269: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:83:00.0, compute capability: 6.1)
{'id': 99, 'batch_size': 128, 'epochs': 166, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/166 [00:00<?, ?epoch/s]2024-02-15 19:16:12.723790: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-02-15 19:16:12.735401: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2599900000 Hz
2024-02-15 19:16:14.541904: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-02-15 19:16:14.786700: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-02-15 19:16:15.578687: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-02-15 19:16:15.649761: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/166 [00:55<2:33:00, 55.64s/epoch, loss=3.08, accuracy=0.328, val_loss=3.1, val_accuracy=0.145, lr=0.1]  1%|          | 2/166 [01:18<1:38:53, 36.18s/epoch, loss=1.55, accuracy=0.547, val_loss=4.3, val_accuracy=0.272, lr=0.1]  2%|▏         | 3/166 [01:39<1:19:14, 29.17s/epoch, loss=1.35, accuracy=0.647, val_loss=2.33, val_accuracy=0.399, lr=0.1]  2%|▏         | 4/166 [02:00<1:10:12, 26.00s/epoch, loss=1.28, accuracy=0.687, val_loss=1.96, val_accuracy=0.463, lr=0.1]  3%|▎         | 5/166 [02:23<1:06:44, 24.87s/epoch, loss=1.24, accuracy=0.707, val_loss=2.89, val_accuracy=0.375, lr=0.1]  4%|▎         | 6/166 [02:45<1:04:28, 24.18s/epoch, loss=1.23, accuracy=0.714, val_loss=2.28, val_accuracy=0.489, lr=0.1]  4%|▍         | 7/166 [03:08<1:02:42, 23.67s/epoch, loss=1.22, accuracy=0.723, val_loss=1.8, val_accuracy=0.559, lr=0.1]   5%|▍         | 8/166 [03:31<1:01:35, 23.39s/epoch, loss=1.22, accuracy=0.72, val_loss=2.04, val_accuracy=0.49, lr=0.1]   5%|▌         | 9/166 [03:52<59:13, 22.64s/epoch, loss=1.21, accuracy=0.727, val_loss=1.78, val_accuracy=0.553, lr=0.1]  6%|▌         | 10/166 [04:14<58:30, 22.50s/epoch, loss=1.2, accuracy=0.732, val_loss=1.75, val_accuracy=0.568, lr=0.1]  7%|▋         | 11/166 [04:35<57:17, 22.17s/epoch, loss=1.19, accuracy=0.734, val_loss=1.94, val_accuracy=0.558, lr=0.1]  7%|▋         | 12/166 [04:58<57:20, 22.34s/epoch, loss=1.2, accuracy=0.736, val_loss=2.77, val_accuracy=0.379, lr=0.1]   8%|▊         | 13/166 [05:21<57:12, 22.44s/epoch, loss=1.19, accuracy=0.739, val_loss=3.09, val_accuracy=0.35, lr=0.1]  8%|▊         | 14/166 [05:44<57:12, 22.58s/epoch, loss=1.18, accuracy=0.741, val_loss=1.64, val_accuracy=0.579, lr=0.1]  9%|▉         | 15/166 [06:06<56:39, 22.51s/epoch, loss=1.18, accuracy=0.74, val_loss=2.11, val_accuracy=0.515, lr=0.1]  10%|▉         | 16/166 [06:28<55:38, 22.26s/epoch, loss=1.17, accuracy=0.742, val_loss=1.73, val_accuracy=0.592, lr=0.1] 10%|█         | 17/166 [06:49<54:38, 22.00s/epoch, loss=1.18, accuracy=0.744, val_loss=2.35, val_accuracy=0.357, lr=0.1] 11%|█         | 18/166 [07:12<54:49, 22.22s/epoch, loss=1.17, accuracy=0.745, val_loss=1.89, val_accuracy=0.512, lr=0.1] 11%|█▏        | 19/166 [07:33<53:44, 21.94s/epoch, loss=1.17, accuracy=0.745, val_loss=1.81, val_accuracy=0.534, lr=0.0316] 12%|█▏        | 20/166 [07:55<53:41, 22.07s/epoch, loss=1.17, accuracy=0.744, val_loss=1.9, val_accuracy=0.505, lr=0.1]     13%|█▎        | 21/166 [08:18<53:55, 22.32s/epoch, loss=1.16, accuracy=0.746, val_loss=2.52, val_accuracy=0.426, lr=0.1] 13%|█▎        | 22/166 [08:40<53:22, 22.24s/epoch, loss=1.17, accuracy=0.744, val_loss=2.18, val_accuracy=0.506, lr=0.1] 14%|█▍        | 23/166 [09:03<53:13, 22.34s/epoch, loss=1.17, accuracy=0.746, val_loss=1.69, val_accuracy=0.59, lr=0.1]  14%|█▍        | 24/166 [09:26<53:06, 22.44s/epoch, loss=1.17, accuracy=0.748, val_loss=2.14, val_accuracy=0.453, lr=0.0316] 15%|█▌        | 25/166 [09:48<52:58, 22.54s/epoch, loss=1.17, accuracy=0.745, val_loss=3.29, val_accuracy=0.369, lr=0.1]    16%|█▌        | 26/166 [10:11<52:54, 22.67s/epoch, loss=1.16, accuracy=0.75, val_loss=1.97, val_accuracy=0.475, lr=0.1]  16%|█▋        | 27/166 [10:34<52:30, 22.66s/epoch, loss=1.16, accuracy=0.749, val_loss=2.02, val_accuracy=0.485, lr=0.1] 17%|█▋        | 28/166 [10:55<51:10, 22.25s/epoch, loss=1.16, accuracy=0.749, val_loss=4.71, val_accuracy=0.214, lr=0.1] 17%|█▋        | 29/166 [11:18<51:23, 22.51s/epoch, loss=1.15, accuracy=0.75, val_loss=2.47, val_accuracy=0.481, lr=0.0316] 18%|█▊        | 30/166 [11:41<51:13, 22.60s/epoch, loss=1.16, accuracy=0.749, val_loss=2.2, val_accuracy=0.486, lr=0.1]    19%|█▊        | 31/166 [12:04<51:09, 22.74s/epoch, loss=1.15, accuracy=0.748, val_loss=1.71, val_accuracy=0.567, lr=0.1] 19%|█▉        | 32/166 [12:27<50:30, 22.61s/epoch, loss=1.15, accuracy=0.751, val_loss=1.89, val_accuracy=0.543, lr=0.1] 20%|█▉        | 33/166 [12:50<50:16, 22.68s/epoch, loss=1.15, accuracy=0.751, val_loss=1.57, val_accuracy=0.6, lr=0.1]   20%|██        | 34/166 [13:12<49:58, 22.71s/epoch, loss=1.14, accuracy=0.752, val_loss=1.97, val_accuracy=0.43, lr=0.1] 21%|██        | 35/166 [13:33<48:29, 22.21s/epoch, loss=1.15, accuracy=0.751, val_loss=1.59, val_accuracy=0.62, lr=0.1] 22%|██▏       | 36/166 [13:55<47:50, 22.08s/epoch, loss=1.15, accuracy=0.75, val_loss=2.02, val_accuracy=0.522, lr=0.1] 22%|██▏       | 37/166 [14:17<47:21, 22.03s/epoch, loss=1.15, accuracy=0.752, val_loss=2.04, val_accuracy=0.417, lr=0.1] 23%|██▎       | 38/166 [14:40<47:27, 22.25s/epoch, loss=1.15, accuracy=0.752, val_loss=3.24, val_accuracy=0.393, lr=0.0316] 23%|██▎       | 39/166 [15:02<47:10, 22.29s/epoch, loss=1.15, accuracy=0.752, val_loss=1.45, val_accuracy=0.66, lr=0.1]     24%|██▍       | 40/166 [15:25<47:09, 22.46s/epoch, loss=1.15, accuracy=0.75, val_loss=2.55, val_accuracy=0.463, lr=0.1] 25%|██▍       | 41/166 [15:48<46:57, 22.54s/epoch, loss=1.14, accuracy=0.753, val_loss=2.13, val_accuracy=0.497, lr=0.1] 25%|██▌       | 42/166 [16:09<46:04, 22.29s/epoch, loss=1.15, accuracy=0.751, val_loss=2.46, val_accuracy=0.485, lr=0.1] 26%|██▌       | 43/166 [16:31<45:13, 22.06s/epoch, loss=1.14, accuracy=0.752, val_loss=2.16, val_accuracy=0.483, lr=0.1] 27%|██▋       | 44/166 [16:53<44:50, 22.06s/epoch, loss=1.14, accuracy=0.753, val_loss=1.83, val_accuracy=0.541, lr=0.0316] 27%|██▋       | 45/166 [17:15<44:09, 21.90s/epoch, loss=1.14, accuracy=0.753, val_loss=1.61, val_accuracy=0.599, lr=0.1]    28%|██▊       | 46/166 [17:36<43:13, 21.62s/epoch, loss=1.14, accuracy=0.754, val_loss=2.41, val_accuracy=0.473, lr=0.1] 28%|██▊       | 47/166 [17:58<43:32, 21.96s/epoch, loss=1.14, accuracy=0.755, val_loss=2.07, val_accuracy=0.519, lr=0.1] 29%|██▉       | 48/166 [18:21<43:36, 22.17s/epoch, loss=1.14, accuracy=0.752, val_loss=1.62, val_accuracy=0.566, lr=0.1] 30%|██▉       | 49/166 [18:43<43:25, 22.27s/epoch, loss=1.13, accuracy=0.753, val_loss=1.84, val_accuracy=0.557, lr=0.0316] 30%|███       | 50/166 [19:06<43:19, 22.41s/epoch, loss=1.13, accuracy=0.752, val_loss=1.86, val_accuracy=0.583, lr=0.1]    31%|███       | 51/166 [19:29<42:59, 22.43s/epoch, loss=1.14, accuracy=0.752, val_loss=1.99, val_accuracy=0.521, lr=0.1] 31%|███▏      | 52/166 [19:51<42:42, 22.48s/epoch, loss=1.13, accuracy=0.755, val_loss=5.32, val_accuracy=0.328, lr=0.1] 32%|███▏      | 53/166 [20:14<42:14, 22.43s/epoch, loss=1.13, accuracy=0.755, val_loss=5.55, val_accuracy=0.271, lr=0.1] 33%|███▎      | 54/166 [20:36<41:53, 22.44s/epoch, loss=1.12, accuracy=0.759, val_loss=1.74, val_accuracy=0.585, lr=0.0316] 33%|███▎      | 55/166 [20:58<40:58, 22.15s/epoch, loss=1.13, accuracy=0.758, val_loss=2.27, val_accuracy=0.461, lr=0.1]    34%|███▎      | 56/166 [21:20<40:52, 22.29s/epoch, loss=1.12, accuracy=0.757, val_loss=1.53, val_accuracy=0.618, lr=0.1] 34%|███▍      | 57/166 [21:41<39:42, 21.86s/epoch, loss=1.13, accuracy=0.755, val_loss=5.92, val_accuracy=0.267, lr=0.1] 35%|███▍      | 58/166 [22:04<39:45, 22.09s/epoch, loss=1.13, accuracy=0.756, val_loss=1.83, val_accuracy=0.581, lr=0.1] 36%|███▌      | 59/166 [22:26<39:36, 22.21s/epoch, loss=1.13, accuracy=0.755, val_loss=6.65, val_accuracy=0.167, lr=0.0316] 36%|███▌      | 60/166 [22:48<39:17, 22.24s/epoch, loss=1.13, accuracy=0.756, val_loss=2.12, val_accuracy=0.51, lr=0.1]     37%|███▋      | 61/166 [23:11<38:55, 22.24s/epoch, loss=1.12, accuracy=0.759, val_loss=1.84, val_accuracy=0.524, lr=0.1] 37%|███▋      | 62/166 [23:33<38:32, 22.23s/epoch, loss=1.12, accuracy=0.758, val_loss=2.75, val_accuracy=0.365, lr=0.1] 38%|███▊      | 63/166 [23:54<37:25, 21.80s/epoch, loss=1.12, accuracy=0.757, val_loss=1.89, val_accuracy=0.539, lr=0.1] 39%|███▊      | 64/166 [24:16<37:26, 22.02s/epoch, loss=1.13, accuracy=0.757, val_loss=2.14, val_accuracy=0.463, lr=0.0316] 39%|███▉      | 65/166 [24:38<36:45, 21.83s/epoch, loss=1.12, accuracy=0.756, val_loss=2.37, val_accuracy=0.505, lr=0.1]    40%|███▉      | 66/166 [24:59<35:56, 21.57s/epoch, loss=1.13, accuracy=0.756, val_loss=3.72, val_accuracy=0.198, lr=0.1] 40%|████      | 67/166 [25:21<36:03, 21.85s/epoch, loss=1.12, accuracy=0.756, val_loss=1.99, val_accuracy=0.512, lr=0.1] 41%|████      | 68/166 [25:44<36:07, 22.12s/epoch, loss=1.12, accuracy=0.756, val_loss=2.15, val_accuracy=0.4, lr=0.1]   42%|████▏     | 69/166 [26:06<35:41, 22.08s/epoch, loss=1.12, accuracy=0.756, val_loss=1.82, val_accuracy=0.564, lr=0.0316] 42%|████▏     | 70/166 [26:29<35:45, 22.35s/epoch, loss=1.12, accuracy=0.756, val_loss=2.98, val_accuracy=0.441, lr=0.1]    43%|████▎     | 71/166 [26:51<35:27, 22.40s/epoch, loss=1.12, accuracy=0.757, val_loss=1.82, val_accuracy=0.557, lr=0.1] 43%|████▎     | 72/166 [27:13<34:53, 22.27s/epoch, loss=1.13, accuracy=0.757, val_loss=2.14, val_accuracy=0.482, lr=0.1] 44%|████▍     | 73/166 [27:35<34:30, 22.26s/epoch, loss=1.12, accuracy=0.756, val_loss=2.21, val_accuracy=0.469, lr=0.1] 45%|████▍     | 74/166 [27:58<34:04, 22.23s/epoch, loss=1.12, accuracy=0.76, val_loss=2, val_accuracy=0.542, lr=0.0316]  45%|████▌     | 75/166 [28:20<33:39, 22.20s/epoch, loss=1.13, accuracy=0.756, val_loss=1.78, val_accuracy=0.537, lr=0.1] 46%|████▌     | 76/166 [28:41<32:46, 21.85s/epoch, loss=1.12, accuracy=0.758, val_loss=1.8, val_accuracy=0.536, lr=0.1]  46%|████▋     | 77/166 [29:02<32:00, 21.58s/epoch, loss=1.12, accuracy=0.757, val_loss=3.6, val_accuracy=0.38, lr=0.1]  47%|████▋     | 78/166 [29:24<31:57, 21.79s/epoch, loss=1.12, accuracy=0.758, val_loss=2.65, val_accuracy=0.435, lr=0.1] 48%|████▊     | 79/166 [29:45<31:11, 21.51s/epoch, loss=1.12, accuracy=0.756, val_loss=1.86, val_accuracy=0.55, lr=0.0316] 48%|████▊     | 80/166 [30:07<31:15, 21.81s/epoch, loss=1.12, accuracy=0.756, val_loss=1.77, val_accuracy=0.573, lr=0.1]   49%|████▉     | 81/166 [30:28<30:28, 21.51s/epoch, loss=1.12, accuracy=0.756, val_loss=2.36, val_accuracy=0.471, lr=0.1] 49%|████▉     | 82/166 [30:51<30:27, 21.76s/epoch, loss=0.952, accuracy=0.807, val_loss=0.962, val_accuracy=0.784, lr=0.01] 50%|█████     | 83/166 [31:13<30:28, 22.03s/epoch, loss=0.748, accuracy=0.845, val_loss=0.783, val_accuracy=0.818, lr=0.01] 51%|█████     | 84/166 [31:34<29:43, 21.75s/epoch, loss=0.661, accuracy=0.857, val_loss=0.756, val_accuracy=0.815, lr=0.01] 51%|█████     | 85/166 [31:56<29:26, 21.81s/epoch, loss=0.609, accuracy=0.86, val_loss=0.702, val_accuracy=0.823, lr=0.01]  52%|█████▏    | 86/166 [32:18<29:01, 21.77s/epoch, loss=0.586, accuracy=0.859, val_loss=0.946, val_accuracy=0.761, lr=0.01] 52%|█████▏    | 87/166 [32:41<29:02, 22.05s/epoch, loss=0.575, accuracy=0.861, val_loss=0.973, val_accuracy=0.747, lr=0.01] 53%|█████▎    | 88/166 [33:01<28:11, 21.68s/epoch, loss=0.57, accuracy=0.863, val_loss=0.786, val_accuracy=0.796, lr=0.01]  54%|█████▎    | 89/166 [33:23<27:38, 21.53s/epoch, loss=0.563, accuracy=0.864, val_loss=0.898, val_accuracy=0.762, lr=0.01] 54%|█████▍    | 90/166 [33:44<27:17, 21.54s/epoch, loss=0.562, accuracy=0.865, val_loss=0.992, val_accuracy=0.738, lr=0.00316] 55%|█████▍    | 91/166 [34:07<27:20, 21.88s/epoch, loss=0.562, accuracy=0.868, val_loss=0.799, val_accuracy=0.785, lr=0.01]    55%|█████▌    | 92/166 [34:30<27:16, 22.12s/epoch, loss=0.556, accuracy=0.87, val_loss=0.788, val_accuracy=0.805, lr=0.01]  56%|█████▌    | 93/166 [34:52<27:04, 22.25s/epoch, loss=0.555, accuracy=0.871, val_loss=0.951, val_accuracy=0.765, lr=0.01] 57%|█████▋    | 94/166 [35:14<26:43, 22.27s/epoch, loss=0.556, accuracy=0.872, val_loss=0.851, val_accuracy=0.775, lr=0.01] 57%|█████▋    | 95/166 [35:36<26:01, 21.99s/epoch, loss=0.557, accuracy=0.873, val_loss=0.807, val_accuracy=0.789, lr=0.00316] 58%|█████▊    | 96/166 [35:58<25:34, 21.92s/epoch, loss=0.554, accuracy=0.875, val_loss=0.839, val_accuracy=0.787, lr=0.01]    58%|█████▊    | 97/166 [36:20<25:22, 22.07s/epoch, loss=0.552, accuracy=0.875, val_loss=0.891, val_accuracy=0.777, lr=0.01] 59%|█████▉    | 98/166 [36:42<25:07, 22.17s/epoch, loss=0.552, accuracy=0.876, val_loss=0.73, val_accuracy=0.815, lr=0.01]  60%|█████▉    | 99/166 [37:03<24:18, 21.77s/epoch, loss=0.55, accuracy=0.875, val_loss=0.927, val_accuracy=0.763, lr=0.01] 60%|██████    | 100/166 [37:25<23:54, 21.74s/epoch, loss=0.549, accuracy=0.878, val_loss=1.4, val_accuracy=0.684, lr=0.00316] 61%|██████    | 101/166 [37:47<23:34, 21.76s/epoch, loss=0.549, accuracy=0.88, val_loss=1.47, val_accuracy=0.671, lr=0.01]    61%|██████▏   | 102/166 [38:08<23:05, 21.64s/epoch, loss=0.55, accuracy=0.88, val_loss=0.775, val_accuracy=0.812, lr=0.01] 62%|██████▏   | 103/166 [38:30<22:40, 21.59s/epoch, loss=0.552, accuracy=0.88, val_loss=0.782, val_accuracy=0.804, lr=0.01] 63%|██████▎   | 104/166 [38:52<22:33, 21.84s/epoch, loss=0.55, accuracy=0.881, val_loss=0.967, val_accuracy=0.762, lr=0.01] 63%|██████▎   | 105/166 [39:13<21:52, 21.51s/epoch, loss=0.552, accuracy=0.879, val_loss=1.11, val_accuracy=0.739, lr=0.00316] 64%|██████▍   | 106/166 [39:34<21:24, 21.41s/epoch, loss=0.55, accuracy=0.88, val_loss=0.931, val_accuracy=0.768, lr=0.01]     64%|██████▍   | 107/166 [39:55<20:51, 21.22s/epoch, loss=0.552, accuracy=0.88, val_loss=1.05, val_accuracy=0.739, lr=0.01] 65%|██████▌   | 108/166 [40:17<20:51, 21.57s/epoch, loss=0.547, accuracy=0.882, val_loss=0.915, val_accuracy=0.77, lr=0.01] 66%|██████▌   | 109/166 [40:38<20:13, 21.30s/epoch, loss=0.545, accuracy=0.882, val_loss=0.783, val_accuracy=0.804, lr=0.01] 66%|██████▋   | 110/166 [41:00<20:07, 21.57s/epoch, loss=0.546, accuracy=0.884, val_loss=1.1, val_accuracy=0.744, lr=0.00316] 67%|██████▋   | 111/166 [41:22<19:54, 21.71s/epoch, loss=0.552, accuracy=0.881, val_loss=0.788, val_accuracy=0.8, lr=0.01]    67%|██████▋   | 112/166 [41:44<19:42, 21.90s/epoch, loss=0.544, accuracy=0.885, val_loss=1.05, val_accuracy=0.756, lr=0.01] 68%|██████▊   | 113/166 [42:07<19:26, 22.01s/epoch, loss=0.553, accuracy=0.88, val_loss=0.832, val_accuracy=0.796, lr=0.01] 69%|██████▊   | 114/166 [42:29<19:07, 22.07s/epoch, loss=0.555, accuracy=0.883, val_loss=0.895, val_accuracy=0.788, lr=0.01] 69%|██████▉   | 115/166 [42:50<18:38, 21.92s/epoch, loss=0.549, accuracy=0.885, val_loss=1.26, val_accuracy=0.673, lr=0.00316] 70%|██████▉   | 116/166 [43:13<18:21, 22.03s/epoch, loss=0.55, accuracy=0.884, val_loss=0.868, val_accuracy=0.787, lr=0.01]    70%|███████   | 117/166 [43:35<18:07, 22.19s/epoch, loss=0.541, accuracy=0.886, val_loss=0.853, val_accuracy=0.791, lr=0.01] 71%|███████   | 118/166 [43:58<17:51, 22.32s/epoch, loss=0.545, accuracy=0.885, val_loss=0.821, val_accuracy=0.795, lr=0.01] 72%|███████▏  | 119/166 [44:20<17:32, 22.39s/epoch, loss=0.545, accuracy=0.886, val_loss=1.12, val_accuracy=0.728, lr=0.01]  72%|███████▏  | 120/166 [44:43<17:07, 22.34s/epoch, loss=0.553, accuracy=0.882, val_loss=0.859, val_accuracy=0.795, lr=0.00316] 73%|███████▎  | 121/166 [45:04<16:30, 22.01s/epoch, loss=0.548, accuracy=0.884, val_loss=0.993, val_accuracy=0.752, lr=0.01]    73%|███████▎  | 122/166 [45:25<16:03, 21.90s/epoch, loss=0.468, accuracy=0.915, val_loss=0.536, val_accuracy=0.89, lr=0.001] 74%|███████▍  | 123/166 [45:47<15:40, 21.87s/epoch, loss=0.415, accuracy=0.93, val_loss=0.521, val_accuracy=0.892, lr=0.001] 75%|███████▍  | 124/166 [46:08<15:07, 21.61s/epoch, loss=0.399, accuracy=0.933, val_loss=0.514, val_accuracy=0.894, lr=0.001] 75%|███████▌  | 125/166 [46:29<14:36, 21.37s/epoch, loss=0.381, accuracy=0.938, val_loss=0.498, val_accuracy=0.894, lr=0.001] 76%|███████▌  | 126/166 [46:51<14:21, 21.54s/epoch, loss=0.366, accuracy=0.942, val_loss=0.496, val_accuracy=0.897, lr=0.001] 77%|███████▋  | 127/166 [47:13<14:11, 21.82s/epoch, loss=0.356, accuracy=0.942, val_loss=0.498, val_accuracy=0.896, lr=0.001] 77%|███████▋  | 128/166 [47:36<13:58, 22.07s/epoch, loss=0.346, accuracy=0.945, val_loss=0.493, val_accuracy=0.895, lr=0.001] 78%|███████▊  | 129/166 [47:59<13:41, 22.21s/epoch, loss=0.337, accuracy=0.946, val_loss=0.493, val_accuracy=0.895, lr=0.001] 78%|███████▊  | 130/166 [48:20<13:12, 22.01s/epoch, loss=0.324, accuracy=0.95, val_loss=0.479, val_accuracy=0.896, lr=0.001]  79%|███████▉  | 131/166 [48:43<12:53, 22.11s/epoch, loss=0.316, accuracy=0.95, val_loss=0.478, val_accuracy=0.896, lr=0.001] 80%|███████▉  | 132/166 [49:05<12:34, 22.20s/epoch, loss=0.309, accuracy=0.952, val_loss=0.473, val_accuracy=0.897, lr=0.001] 80%|████████  | 133/166 [49:27<12:15, 22.29s/epoch, loss=0.302, accuracy=0.952, val_loss=0.468, val_accuracy=0.898, lr=0.001] 81%|████████  | 134/166 [49:50<11:55, 22.37s/epoch, loss=0.293, accuracy=0.954, val_loss=0.463, val_accuracy=0.902, lr=0.001] 81%|████████▏ | 135/166 [50:13<11:35, 22.44s/epoch, loss=0.288, accuracy=0.953, val_loss=0.466, val_accuracy=0.9, lr=0.001]   82%|████████▏ | 136/166 [50:34<11:06, 22.21s/epoch, loss=0.282, accuracy=0.955, val_loss=0.472, val_accuracy=0.897, lr=0.001] 83%|████████▎ | 137/166 [50:57<10:46, 22.29s/epoch, loss=0.276, accuracy=0.956, val_loss=0.475, val_accuracy=0.897, lr=0.001] 83%|████████▎ | 138/166 [51:19<10:27, 22.40s/epoch, loss=0.269, accuracy=0.958, val_loss=0.46, val_accuracy=0.897, lr=0.001]  84%|████████▎ | 139/166 [51:41<09:59, 22.19s/epoch, loss=0.266, accuracy=0.956, val_loss=0.471, val_accuracy=0.892, lr=0.001] 84%|████████▍ | 140/166 [52:03<09:37, 22.22s/epoch, loss=0.262, accuracy=0.958, val_loss=0.471, val_accuracy=0.894, lr=0.001] 85%|████████▍ | 141/166 [52:25<09:13, 22.12s/epoch, loss=0.255, accuracy=0.959, val_loss=0.47, val_accuracy=0.895, lr=0.001]  86%|████████▌ | 142/166 [52:47<08:47, 21.97s/epoch, loss=0.253, accuracy=0.958, val_loss=0.449, val_accuracy=0.9, lr=0.001]  86%|████████▌ | 143/166 [53:09<08:24, 21.92s/epoch, loss=0.247, accuracy=0.96, val_loss=0.45, val_accuracy=0.896, lr=0.001] 87%|████████▋ | 144/166 [53:31<08:05, 22.07s/epoch, loss=0.246, accuracy=0.96, val_loss=0.486, val_accuracy=0.888, lr=0.001] 87%|████████▋ | 145/166 [53:54<07:47, 22.24s/epoch, loss=0.241, accuracy=0.96, val_loss=0.498, val_accuracy=0.886, lr=0.001] 88%|████████▊ | 146/166 [54:16<07:27, 22.36s/epoch, loss=0.241, accuracy=0.959, val_loss=0.464, val_accuracy=0.895, lr=0.001] 89%|████████▊ | 147/166 [54:38<06:58, 22.01s/epoch, loss=0.237, accuracy=0.96, val_loss=0.495, val_accuracy=0.888, lr=0.000316] 89%|████████▉ | 148/166 [55:00<06:39, 22.19s/epoch, loss=0.233, accuracy=0.96, val_loss=0.49, val_accuracy=0.884, lr=0.001]     90%|████████▉ | 149/166 [55:23<06:19, 22.34s/epoch, loss=0.232, accuracy=0.959, val_loss=0.459, val_accuracy=0.891, lr=0.001] 90%|█████████ | 150/166 [55:44<05:49, 21.86s/epoch, loss=0.229, accuracy=0.961, val_loss=0.51, val_accuracy=0.884, lr=0.001]  91%|█████████ | 151/166 [56:05<05:26, 21.78s/epoch, loss=0.228, accuracy=0.96, val_loss=0.449, val_accuracy=0.894, lr=0.001] 92%|█████████▏| 152/166 [56:27<05:04, 21.76s/epoch, loss=0.223, accuracy=0.962, val_loss=0.443, val_accuracy=0.899, lr=0.001] 92%|█████████▏| 153/166 [56:48<04:40, 21.60s/epoch, loss=0.221, accuracy=0.961, val_loss=0.483, val_accuracy=0.877, lr=0.001] 93%|█████████▎| 154/166 [57:11<04:22, 21.86s/epoch, loss=0.221, accuracy=0.963, val_loss=0.437, val_accuracy=0.893, lr=0.001] 93%|█████████▎| 155/166 [57:33<04:00, 21.90s/epoch, loss=0.217, accuracy=0.962, val_loss=0.47, val_accuracy=0.886, lr=0.001]  94%|█████████▍| 156/166 [57:55<03:40, 22.09s/epoch, loss=0.217, accuracy=0.962, val_loss=0.495, val_accuracy=0.884, lr=0.001] 95%|█████████▍| 157/166 [58:17<03:18, 22.01s/epoch, loss=0.218, accuracy=0.961, val_loss=0.473, val_accuracy=0.892, lr=0.001] 95%|█████████▌| 158/166 [58:39<02:56, 22.09s/epoch, loss=0.216, accuracy=0.961, val_loss=0.479, val_accuracy=0.885, lr=0.001] 96%|█████████▌| 159/166 [59:00<02:32, 21.82s/epoch, loss=0.215, accuracy=0.961, val_loss=0.534, val_accuracy=0.877, lr=0.000316] 96%|█████████▋| 160/166 [59:23<02:12, 22.05s/epoch, loss=0.214, accuracy=0.962, val_loss=0.519, val_accuracy=0.877, lr=0.001]    97%|█████████▋| 161/166 [59:45<01:50, 22.11s/epoch, loss=0.213, accuracy=0.962, val_loss=0.458, val_accuracy=0.893, lr=0.001] 98%|█████████▊| 162/166 [1:00:06<01:26, 21.72s/epoch, loss=0.189, accuracy=0.971, val_loss=0.402, val_accuracy=0.908, lr=1e-04] 98%|█████████▊| 163/166 [1:00:28<01:05, 21.86s/epoch, loss=0.178, accuracy=0.976, val_loss=0.4, val_accuracy=0.908, lr=1e-04]   99%|█████████▉| 164/166 [1:00:50<00:43, 21.82s/epoch, loss=0.174, accuracy=0.977, val_loss=0.399, val_accuracy=0.908, lr=1e-04] 99%|█████████▉| 165/166 [1:01:12<00:21, 21.83s/epoch, loss=0.171, accuracy=0.978, val_loss=0.399, val_accuracy=0.909, lr=1e-04]100%|██████████| 166/166 [1:01:33<00:00, 21.54s/epoch, loss=0.168, accuracy=0.979, val_loss=0.399, val_accuracy=0.909, lr=1e-04]100%|██████████| 166/166 [1:01:33<00:00, 22.25s/epoch, loss=0.168, accuracy=0.979, val_loss=0.399, val_accuracy=0.909, lr=1e-04]
Using real-time data augmentation.
Test loss: 0.39942336082458496
Test accuracy: 0.9089999794960022
