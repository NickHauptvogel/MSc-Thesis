Tue Mar  5 00:58:43 2024       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 545.23.08              Driver Version: 545.23.08    CUDA Version: 12.3     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA TITAN X (Pascal)        Off | 00000000:02:00.0 Off |                  N/A |
| 42%   59C    P8              11W / 250W |      0MiB / 12288MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|  No running processes found                                                           |
+---------------------------------------------------------------------------------------+


* * * Run SGD for cluster size = 9. * * *


Budget: 166


* * * Run SGD for ID = 9_1. * * *


2024-03-05 00:58:45.945748: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 00:58:56.432748: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 00:58:56.434550: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-05 00:58:56.476531: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-03-05 00:58:56.476575: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 00:58:56.532245: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 00:58:56.532394: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 00:58:56.555036: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 00:58:56.622905: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 00:58:56.698448: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 00:58:56.744602: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 00:58:56.781304: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 00:58:56.782076: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 00:58:56.782198: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 00:58:58.161165: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-05 00:58:58.162664: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 00:58:58.164631: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-03-05 00:58:58.164664: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 00:58:58.164710: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 00:58:58.164729: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 00:58:58.164744: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 00:58:58.164759: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 00:58:58.164774: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 00:58:58.164789: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 00:58:58.164804: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 00:58:58.165284: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 00:58:58.165323: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 00:58:58.979850: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-05 00:58:58.979902: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-05 00:58:58.979911: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-05 00:58:58.980844: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:02:00.0, compute capability: 6.1)
{'id': '09_01', 'seed': 1, 'out_folder': 'results/epoch_budget', 'batch_size': 128, 'epochs': 166, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'bootstrapping': False, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/166 [00:00<?, ?epoch/s]2024-03-05 00:59:00.032349: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-05 00:59:00.032872: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600020000 Hz
2024-03-05 00:59:02.037453: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 00:59:02.292511: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 00:59:03.192027: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-05 00:59:03.261948: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/166 [01:05<2:59:11, 65.16s/epoch, loss=3.22, accuracy=0.316, val_loss=2.54, val_accuracy=0.213, lr=0.1]  1%|          | 2/166 [01:25<1:45:51, 38.73s/epoch, loss=1.62, accuracy=0.506, val_loss=2.32, val_accuracy=0.346, lr=0.1]  2%|▏         | 3/166 [01:45<1:22:12, 30.26s/epoch, loss=1.4, accuracy=0.614, val_loss=1.76, val_accuracy=0.482, lr=0.1]   2%|▏         | 4/166 [02:06<1:11:48, 26.60s/epoch, loss=1.31, accuracy=0.675, val_loss=1.84, val_accuracy=0.494, lr=0.1]  3%|▎         | 5/166 [02:26<1:05:20, 24.35s/epoch, loss=1.26, accuracy=0.701, val_loss=2.1, val_accuracy=0.43, lr=0.1]    4%|▎         | 6/166 [02:47<1:01:16, 22.98s/epoch, loss=1.24, accuracy=0.712, val_loss=2.38, val_accuracy=0.413, lr=0.1]  4%|▍         | 7/166 [03:07<58:49, 22.20s/epoch, loss=1.23, accuracy=0.72, val_loss=1.53, val_accuracy=0.611, lr=0.1]     5%|▍         | 8/166 [03:28<56:55, 21.62s/epoch, loss=1.22, accuracy=0.724, val_loss=3.27, val_accuracy=0.388, lr=0.1]  5%|▌         | 9/166 [03:48<55:39, 21.27s/epoch, loss=1.21, accuracy=0.726, val_loss=3.57, val_accuracy=0.248, lr=0.1]  6%|▌         | 10/166 [04:09<54:42, 21.04s/epoch, loss=1.22, accuracy=0.727, val_loss=2.27, val_accuracy=0.454, lr=0.1]  7%|▋         | 11/166 [04:29<54:07, 20.95s/epoch, loss=1.21, accuracy=0.729, val_loss=2.66, val_accuracy=0.356, lr=0.1]  7%|▋         | 12/166 [04:50<53:40, 20.91s/epoch, loss=1.2, accuracy=0.733, val_loss=2.32, val_accuracy=0.414, lr=0.0316]  8%|▊         | 13/166 [05:11<53:08, 20.84s/epoch, loss=1.19, accuracy=0.736, val_loss=2.62, val_accuracy=0.411, lr=0.1]    8%|▊         | 14/166 [05:31<52:28, 20.71s/epoch, loss=1.19, accuracy=0.739, val_loss=1.8, val_accuracy=0.558, lr=0.1]   9%|▉         | 15/166 [05:52<51:55, 20.64s/epoch, loss=1.19, accuracy=0.738, val_loss=2, val_accuracy=0.515, lr=0.1]   10%|▉         | 16/166 [06:12<51:35, 20.64s/epoch, loss=1.18, accuracy=0.741, val_loss=2.28, val_accuracy=0.427, lr=0.1] 10%|█         | 17/166 [06:33<51:12, 20.62s/epoch, loss=1.19, accuracy=0.741, val_loss=2.27, val_accuracy=0.403, lr=0.0316] 11%|█         | 18/166 [06:54<50:45, 20.58s/epoch, loss=1.18, accuracy=0.74, val_loss=2.33, val_accuracy=0.418, lr=0.1]     11%|█▏        | 19/166 [07:14<50:18, 20.53s/epoch, loss=1.18, accuracy=0.743, val_loss=2.11, val_accuracy=0.493, lr=0.1] 12%|█▏        | 20/166 [07:34<49:54, 20.51s/epoch, loss=1.17, accuracy=0.743, val_loss=1.85, val_accuracy=0.529, lr=0.1] 13%|█▎        | 21/166 [07:55<49:29, 20.48s/epoch, loss=1.16, accuracy=0.746, val_loss=1.86, val_accuracy=0.495, lr=0.1] 13%|█▎        | 22/166 [08:16<49:22, 20.57s/epoch, loss=1.16, accuracy=0.743, val_loss=1.68, val_accuracy=0.555, lr=0.0316] 14%|█▍        | 23/166 [08:36<49:01, 20.57s/epoch, loss=1.17, accuracy=0.744, val_loss=2.01, val_accuracy=0.551, lr=0.1]    14%|█▍        | 24/166 [08:57<48:36, 20.54s/epoch, loss=1.17, accuracy=0.745, val_loss=2.06, val_accuracy=0.472, lr=0.1] 15%|█▌        | 25/166 [09:17<48:16, 20.54s/epoch, loss=1.16, accuracy=0.743, val_loss=3.16, val_accuracy=0.359, lr=0.1] 16%|█▌        | 26/166 [09:38<48:01, 20.58s/epoch, loss=1.16, accuracy=0.747, val_loss=1.75, val_accuracy=0.578, lr=0.1] 16%|█▋        | 27/166 [09:59<47:44, 20.61s/epoch, loss=1.15, accuracy=0.749, val_loss=2.02, val_accuracy=0.473, lr=0.0316] 17%|█▋        | 28/166 [10:19<47:17, 20.56s/epoch, loss=1.15, accuracy=0.751, val_loss=1.85, val_accuracy=0.486, lr=0.1]    17%|█▋        | 29/166 [10:39<46:44, 20.47s/epoch, loss=1.15, accuracy=0.75, val_loss=1.43, val_accuracy=0.647, lr=0.1]  18%|█▊        | 30/166 [11:00<46:17, 20.42s/epoch, loss=1.15, accuracy=0.75, val_loss=2.2, val_accuracy=0.398, lr=0.1]  19%|█▊        | 31/166 [11:20<46:13, 20.54s/epoch, loss=1.15, accuracy=0.748, val_loss=2.53, val_accuracy=0.403, lr=0.1] 19%|█▉        | 32/166 [11:41<45:50, 20.52s/epoch, loss=1.15, accuracy=0.752, val_loss=2.05, val_accuracy=0.437, lr=0.1] 20%|█▉        | 33/166 [12:01<45:22, 20.47s/epoch, loss=1.15, accuracy=0.75, val_loss=1.8, val_accuracy=0.547, lr=0.1]   20%|██        | 34/166 [12:22<45:00, 20.46s/epoch, loss=1.15, accuracy=0.751, val_loss=2.36, val_accuracy=0.471, lr=0.0316] 21%|██        | 35/166 [12:42<44:35, 20.42s/epoch, loss=1.15, accuracy=0.75, val_loss=2.14, val_accuracy=0.431, lr=0.1]     22%|██▏       | 36/166 [13:02<43:59, 20.30s/epoch, loss=1.14, accuracy=0.749, val_loss=2.67, val_accuracy=0.341, lr=0.1] 22%|██▏       | 37/166 [13:22<43:38, 20.29s/epoch, loss=1.14, accuracy=0.751, val_loss=1.72, val_accuracy=0.571, lr=0.1] 23%|██▎       | 38/166 [13:43<43:25, 20.35s/epoch, loss=1.14, accuracy=0.751, val_loss=1.71, val_accuracy=0.582, lr=0.1] 23%|██▎       | 39/166 [14:03<43:09, 20.39s/epoch, loss=1.14, accuracy=0.753, val_loss=2.97, val_accuracy=0.307, lr=0.0316] 24%|██▍       | 40/166 [14:23<42:43, 20.34s/epoch, loss=1.13, accuracy=0.751, val_loss=2.47, val_accuracy=0.364, lr=0.1]    25%|██▍       | 41/166 [14:44<42:18, 20.31s/epoch, loss=1.13, accuracy=0.751, val_loss=1.9, val_accuracy=0.48, lr=0.1]   25%|██▌       | 42/166 [15:04<42:01, 20.33s/epoch, loss=1.13, accuracy=0.751, val_loss=1.52, val_accuracy=0.603, lr=0.1] 26%|██▌       | 43/166 [15:25<41:45, 20.37s/epoch, loss=1.13, accuracy=0.753, val_loss=1.85, val_accuracy=0.524, lr=0.1] 27%|██▋       | 44/166 [15:45<41:22, 20.35s/epoch, loss=1.14, accuracy=0.751, val_loss=2.8, val_accuracy=0.349, lr=0.0316] 27%|██▋       | 45/166 [16:05<41:01, 20.34s/epoch, loss=1.13, accuracy=0.754, val_loss=2.39, val_accuracy=0.401, lr=0.1]   28%|██▊       | 46/166 [16:25<40:22, 20.19s/epoch, loss=1.13, accuracy=0.753, val_loss=1.65, val_accuracy=0.587, lr=0.1] 28%|██▊       | 47/166 [16:45<39:46, 20.06s/epoch, loss=1.13, accuracy=0.752, val_loss=1.74, val_accuracy=0.562, lr=0.1] 29%|██▉       | 48/166 [17:05<39:24, 20.04s/epoch, loss=1.12, accuracy=0.753, val_loss=2.39, val_accuracy=0.42, lr=0.1]  30%|██▉       | 49/166 [17:25<38:59, 20.00s/epoch, loss=1.13, accuracy=0.754, val_loss=2.57, val_accuracy=0.366, lr=0.0316] 30%|███       | 50/166 [17:45<38:50, 20.09s/epoch, loss=1.13, accuracy=0.755, val_loss=1.89, val_accuracy=0.507, lr=0.1]    31%|███       | 51/166 [18:05<38:34, 20.12s/epoch, loss=1.12, accuracy=0.754, val_loss=1.93, val_accuracy=0.538, lr=0.1] 31%|███▏      | 52/166 [18:25<38:13, 20.12s/epoch, loss=1.12, accuracy=0.755, val_loss=1.81, val_accuracy=0.505, lr=0.1] 32%|███▏      | 53/166 [18:45<37:52, 20.11s/epoch, loss=1.13, accuracy=0.753, val_loss=1.72, val_accuracy=0.591, lr=0.1] 33%|███▎      | 54/166 [19:06<37:35, 20.14s/epoch, loss=1.13, accuracy=0.755, val_loss=2.39, val_accuracy=0.373, lr=0.0316] 33%|███▎      | 55/166 [19:26<37:23, 20.21s/epoch, loss=1.13, accuracy=0.754, val_loss=1.5, val_accuracy=0.605, lr=0.1]     34%|███▎      | 56/166 [19:46<37:07, 20.25s/epoch, loss=1.12, accuracy=0.754, val_loss=2.56, val_accuracy=0.333, lr=0.1] 34%|███▍      | 57/166 [20:07<36:45, 20.24s/epoch, loss=1.13, accuracy=0.755, val_loss=2.25, val_accuracy=0.418, lr=0.1] 35%|███▍      | 58/166 [20:27<36:27, 20.25s/epoch, loss=1.12, accuracy=0.755, val_loss=1.97, val_accuracy=0.513, lr=0.1] 36%|███▌      | 59/166 [20:47<36:15, 20.34s/epoch, loss=1.12, accuracy=0.757, val_loss=3.27, val_accuracy=0.393, lr=0.0316] 36%|███▌      | 60/166 [21:08<35:54, 20.33s/epoch, loss=1.12, accuracy=0.755, val_loss=1.56, val_accuracy=0.611, lr=0.1]    37%|███▋      | 61/166 [21:28<35:28, 20.27s/epoch, loss=1.12, accuracy=0.753, val_loss=2.18, val_accuracy=0.422, lr=0.1] 37%|███▋      | 62/166 [21:48<35:02, 20.22s/epoch, loss=1.12, accuracy=0.755, val_loss=2.12, val_accuracy=0.47, lr=0.1]  38%|███▊      | 63/166 [22:08<34:42, 20.22s/epoch, loss=1.12, accuracy=0.754, val_loss=3.16, val_accuracy=0.312, lr=0.1] 39%|███▊      | 64/166 [22:28<34:13, 20.13s/epoch, loss=1.13, accuracy=0.754, val_loss=1.98, val_accuracy=0.523, lr=0.0316] 39%|███▉      | 65/166 [22:48<34:00, 20.21s/epoch, loss=1.12, accuracy=0.756, val_loss=1.78, val_accuracy=0.541, lr=0.1]    40%|███▉      | 66/166 [23:09<33:44, 20.25s/epoch, loss=1.12, accuracy=0.753, val_loss=1.83, val_accuracy=0.53, lr=0.1]  40%|████      | 67/166 [23:29<33:19, 20.20s/epoch, loss=1.12, accuracy=0.757, val_loss=1.91, val_accuracy=0.572, lr=0.1] 41%|████      | 68/166 [23:49<32:57, 20.18s/epoch, loss=1.12, accuracy=0.756, val_loss=1.79, val_accuracy=0.556, lr=0.1] 42%|████▏     | 69/166 [24:09<32:38, 20.19s/epoch, loss=1.12, accuracy=0.757, val_loss=1.97, val_accuracy=0.487, lr=0.0316] 42%|████▏     | 70/166 [24:29<32:20, 20.21s/epoch, loss=1.12, accuracy=0.756, val_loss=2.45, val_accuracy=0.377, lr=0.1]    43%|████▎     | 71/166 [24:50<32:01, 20.22s/epoch, loss=1.11, accuracy=0.757, val_loss=2.74, val_accuracy=0.365, lr=0.1] 43%|████▎     | 72/166 [25:10<31:41, 20.23s/epoch, loss=1.12, accuracy=0.753, val_loss=1.66, val_accuracy=0.57, lr=0.1]  44%|████▍     | 73/166 [25:30<31:21, 20.23s/epoch, loss=1.12, accuracy=0.755, val_loss=2.31, val_accuracy=0.461, lr=0.1] 45%|████▍     | 74/166 [25:51<31:06, 20.29s/epoch, loss=1.11, accuracy=0.757, val_loss=1.95, val_accuracy=0.451, lr=0.0316] 45%|████▌     | 75/166 [26:10<30:33, 20.15s/epoch, loss=1.12, accuracy=0.756, val_loss=2.46, val_accuracy=0.393, lr=0.1]    46%|████▌     | 76/166 [26:31<30:17, 20.20s/epoch, loss=1.12, accuracy=0.755, val_loss=2.13, val_accuracy=0.439, lr=0.1] 46%|████▋     | 77/166 [26:51<29:58, 20.21s/epoch, loss=1.11, accuracy=0.758, val_loss=2.4, val_accuracy=0.468, lr=0.1]  47%|████▋     | 78/166 [27:11<29:38, 20.21s/epoch, loss=1.13, accuracy=0.755, val_loss=1.85, val_accuracy=0.54, lr=0.1] 48%|████▊     | 79/166 [27:31<29:18, 20.21s/epoch, loss=1.12, accuracy=0.753, val_loss=1.59, val_accuracy=0.589, lr=0.0316] 48%|████▊     | 80/166 [27:52<28:59, 20.23s/epoch, loss=1.11, accuracy=0.756, val_loss=3.35, val_accuracy=0.357, lr=0.1]    49%|████▉     | 81/166 [28:12<28:41, 20.25s/epoch, loss=1.11, accuracy=0.757, val_loss=2.42, val_accuracy=0.452, lr=0.1] 49%|████▉     | 82/166 [28:32<28:18, 20.22s/epoch, loss=0.9, accuracy=0.817, val_loss=0.935, val_accuracy=0.787, lr=0.01] 50%|█████     | 83/166 [28:52<27:59, 20.23s/epoch, loss=0.727, accuracy=0.847, val_loss=0.792, val_accuracy=0.811, lr=0.01] 51%|█████     | 84/166 [29:12<27:35, 20.19s/epoch, loss=0.647, accuracy=0.855, val_loss=0.819, val_accuracy=0.788, lr=0.01] 51%|█████     | 85/166 [29:33<27:17, 20.21s/epoch, loss=0.604, accuracy=0.858, val_loss=1.01, val_accuracy=0.725, lr=0.01]  52%|█████▏    | 86/166 [29:53<26:53, 20.17s/epoch, loss=0.588, accuracy=0.86, val_loss=0.778, val_accuracy=0.799, lr=0.01] 52%|█████▏    | 87/166 [30:13<26:34, 20.18s/epoch, loss=0.574, accuracy=0.863, val_loss=0.946, val_accuracy=0.739, lr=0.01] 53%|█████▎    | 88/166 [30:33<26:12, 20.16s/epoch, loss=0.568, accuracy=0.861, val_loss=1.12, val_accuracy=0.674, lr=0.01]  54%|█████▎    | 89/166 [30:53<25:50, 20.14s/epoch, loss=0.566, accuracy=0.862, val_loss=0.872, val_accuracy=0.768, lr=0.01] 54%|█████▍    | 90/166 [31:13<25:30, 20.14s/epoch, loss=0.563, accuracy=0.865, val_loss=0.778, val_accuracy=0.797, lr=0.01] 55%|█████▍    | 91/166 [31:34<25:09, 20.13s/epoch, loss=0.56, accuracy=0.867, val_loss=0.826, val_accuracy=0.776, lr=0.00316] 55%|█████▌    | 92/166 [31:54<24:51, 20.16s/epoch, loss=0.559, accuracy=0.869, val_loss=0.814, val_accuracy=0.783, lr=0.01]   56%|█████▌    | 93/166 [32:14<24:29, 20.13s/epoch, loss=0.561, accuracy=0.867, val_loss=0.871, val_accuracy=0.779, lr=0.01] 57%|█████▋    | 94/166 [32:34<24:08, 20.12s/epoch, loss=0.557, accuracy=0.872, val_loss=0.695, val_accuracy=0.828, lr=0.01] 57%|█████▋    | 95/166 [32:54<23:50, 20.15s/epoch, loss=0.555, accuracy=0.872, val_loss=1.08, val_accuracy=0.729, lr=0.01]  58%|█████▊    | 96/166 [33:14<23:31, 20.16s/epoch, loss=0.556, accuracy=0.872, val_loss=0.957, val_accuracy=0.749, lr=0.01] 58%|█████▊    | 97/166 [33:34<23:06, 20.10s/epoch, loss=0.558, accuracy=0.873, val_loss=0.745, val_accuracy=0.808, lr=0.01] 59%|█████▉    | 98/166 [33:54<22:47, 20.11s/epoch, loss=0.555, accuracy=0.874, val_loss=1.36, val_accuracy=0.669, lr=0.01]  60%|█████▉    | 99/166 [34:14<22:26, 20.09s/epoch, loss=0.556, accuracy=0.872, val_loss=1.79, val_accuracy=0.605, lr=0.00316] 60%|██████    | 100/166 [34:35<22:06, 20.10s/epoch, loss=0.553, accuracy=0.875, val_loss=1.01, val_accuracy=0.752, lr=0.01]   61%|██████    | 101/166 [34:55<21:50, 20.16s/epoch, loss=0.556, accuracy=0.877, val_loss=0.78, val_accuracy=0.805, lr=0.01] 61%|██████▏   | 102/166 [35:15<21:34, 20.23s/epoch, loss=0.553, accuracy=0.877, val_loss=0.905, val_accuracy=0.768, lr=0.01] 62%|██████▏   | 103/166 [35:36<21:15, 20.25s/epoch, loss=0.556, accuracy=0.877, val_loss=0.787, val_accuracy=0.803, lr=0.01] 63%|██████▎   | 104/166 [35:56<20:56, 20.27s/epoch, loss=0.552, accuracy=0.876, val_loss=0.748, val_accuracy=0.818, lr=0.00316] 63%|██████▎   | 105/166 [36:16<20:33, 20.23s/epoch, loss=0.557, accuracy=0.877, val_loss=0.942, val_accuracy=0.758, lr=0.01]    64%|██████▍   | 106/166 [36:36<20:14, 20.23s/epoch, loss=0.556, accuracy=0.877, val_loss=0.921, val_accuracy=0.78, lr=0.01]  64%|██████▍   | 107/166 [36:56<19:51, 20.19s/epoch, loss=0.554, accuracy=0.879, val_loss=0.986, val_accuracy=0.755, lr=0.01] 65%|██████▌   | 108/166 [37:16<19:30, 20.18s/epoch, loss=0.552, accuracy=0.88, val_loss=0.756, val_accuracy=0.816, lr=0.01]  66%|██████▌   | 109/166 [37:37<19:09, 20.16s/epoch, loss=0.556, accuracy=0.878, val_loss=0.914, val_accuracy=0.766, lr=0.00316] 66%|██████▋   | 110/166 [37:57<18:45, 20.10s/epoch, loss=0.556, accuracy=0.88, val_loss=0.848, val_accuracy=0.799, lr=0.01]     67%|██████▋   | 111/166 [38:17<18:23, 20.07s/epoch, loss=0.554, accuracy=0.879, val_loss=0.887, val_accuracy=0.786, lr=0.01] 67%|██████▋   | 112/166 [38:36<18:01, 20.03s/epoch, loss=0.555, accuracy=0.881, val_loss=0.837, val_accuracy=0.779, lr=0.01] 68%|██████▊   | 113/166 [38:56<17:41, 20.02s/epoch, loss=0.554, accuracy=0.883, val_loss=1.34, val_accuracy=0.657, lr=0.01]  69%|██████▊   | 114/166 [39:16<17:17, 19.96s/epoch, loss=0.558, accuracy=0.881, val_loss=1.01, val_accuracy=0.738, lr=0.00316] 69%|██████▉   | 115/166 [39:36<16:58, 19.97s/epoch, loss=0.554, accuracy=0.881, val_loss=0.866, val_accuracy=0.79, lr=0.01]    70%|██████▉   | 116/166 [39:56<16:38, 19.97s/epoch, loss=0.555, accuracy=0.881, val_loss=0.946, val_accuracy=0.773, lr=0.01] 70%|███████   | 117/166 [40:16<16:18, 19.96s/epoch, loss=0.555, accuracy=0.88, val_loss=1.58, val_accuracy=0.644, lr=0.01]   71%|███████   | 118/166 [40:36<15:58, 19.96s/epoch, loss=0.557, accuracy=0.881, val_loss=0.972, val_accuracy=0.761, lr=0.01] 72%|███████▏  | 119/166 [40:56<15:39, 19.98s/epoch, loss=0.552, accuracy=0.884, val_loss=1.19, val_accuracy=0.726, lr=0.00316] 72%|███████▏  | 120/166 [41:16<15:18, 19.97s/epoch, loss=0.555, accuracy=0.883, val_loss=0.72, val_accuracy=0.825, lr=0.01]    73%|███████▎  | 121/166 [41:36<14:57, 19.94s/epoch, loss=0.558, accuracy=0.881, val_loss=0.843, val_accuracy=0.789, lr=0.01] 73%|███████▎  | 122/166 [41:56<14:39, 19.99s/epoch, loss=0.478, accuracy=0.91, val_loss=0.545, val_accuracy=0.887, lr=0.001] 74%|███████▍  | 123/166 [42:16<14:21, 20.03s/epoch, loss=0.426, accuracy=0.926, val_loss=0.526, val_accuracy=0.891, lr=0.001] 75%|███████▍  | 124/166 [42:36<14:01, 20.02s/epoch, loss=0.402, accuracy=0.933, val_loss=0.514, val_accuracy=0.891, lr=0.001] 75%|███████▌  | 125/166 [42:57<13:44, 20.11s/epoch, loss=0.387, accuracy=0.936, val_loss=0.51, val_accuracy=0.891, lr=0.001]  76%|███████▌  | 126/166 [43:17<13:25, 20.14s/epoch, loss=0.374, accuracy=0.938, val_loss=0.502, val_accuracy=0.892, lr=0.001] 77%|███████▋  | 127/166 [43:37<13:04, 20.12s/epoch, loss=0.361, accuracy=0.94, val_loss=0.492, val_accuracy=0.898, lr=0.001]  77%|███████▋  | 128/166 [43:57<12:44, 20.13s/epoch, loss=0.351, accuracy=0.943, val_loss=0.493, val_accuracy=0.896, lr=0.001] 78%|███████▊  | 129/166 [44:17<12:24, 20.12s/epoch, loss=0.342, accuracy=0.944, val_loss=0.493, val_accuracy=0.891, lr=0.001] 78%|███████▊  | 130/166 [44:37<12:04, 20.12s/epoch, loss=0.333, accuracy=0.945, val_loss=0.481, val_accuracy=0.895, lr=0.001] 79%|███████▉  | 131/166 [44:57<11:44, 20.14s/epoch, loss=0.323, accuracy=0.948, val_loss=0.499, val_accuracy=0.888, lr=0.001] 80%|███████▉  | 132/166 [45:18<11:24, 20.14s/epoch, loss=0.314, accuracy=0.949, val_loss=0.493, val_accuracy=0.89, lr=0.001]  80%|████████  | 133/166 [45:38<11:04, 20.14s/epoch, loss=0.308, accuracy=0.949, val_loss=0.491, val_accuracy=0.89, lr=0.001] 81%|████████  | 134/166 [45:58<10:43, 20.10s/epoch, loss=0.301, accuracy=0.951, val_loss=0.487, val_accuracy=0.895, lr=0.001] 81%|████████▏ | 135/166 [46:18<10:22, 20.10s/epoch, loss=0.297, accuracy=0.95, val_loss=0.477, val_accuracy=0.893, lr=0.001]  82%|████████▏ | 136/166 [46:38<10:02, 20.09s/epoch, loss=0.289, accuracy=0.952, val_loss=0.469, val_accuracy=0.892, lr=0.001] 83%|████████▎ | 137/166 [46:58<09:42, 20.09s/epoch, loss=0.282, accuracy=0.954, val_loss=0.469, val_accuracy=0.894, lr=0.001] 83%|████████▎ | 138/166 [47:18<09:20, 20.03s/epoch, loss=0.278, accuracy=0.953, val_loss=0.483, val_accuracy=0.891, lr=0.001] 84%|████████▎ | 139/166 [47:38<09:00, 20.04s/epoch, loss=0.273, accuracy=0.954, val_loss=0.491, val_accuracy=0.889, lr=0.001] 84%|████████▍ | 140/166 [47:58<08:40, 20.03s/epoch, loss=0.267, accuracy=0.956, val_loss=0.476, val_accuracy=0.89, lr=0.001]  85%|████████▍ | 141/166 [48:18<08:21, 20.06s/epoch, loss=0.262, accuracy=0.956, val_loss=0.485, val_accuracy=0.888, lr=0.001] 86%|████████▌ | 142/166 [48:38<08:02, 20.12s/epoch, loss=0.259, accuracy=0.956, val_loss=0.502, val_accuracy=0.879, lr=0.000316] 86%|████████▌ | 143/166 [48:58<07:42, 20.11s/epoch, loss=0.254, accuracy=0.957, val_loss=0.501, val_accuracy=0.885, lr=0.001]    87%|████████▋ | 144/166 [49:18<07:21, 20.09s/epoch, loss=0.25, accuracy=0.958, val_loss=0.492, val_accuracy=0.886, lr=0.001]  87%|████████▋ | 145/166 [49:39<07:02, 20.14s/epoch, loss=0.248, accuracy=0.957, val_loss=0.499, val_accuracy=0.884, lr=0.001] 88%|████████▊ | 146/166 [49:59<06:43, 20.17s/epoch, loss=0.244, accuracy=0.958, val_loss=0.483, val_accuracy=0.887, lr=0.001] 89%|████████▊ | 147/166 [50:19<06:23, 20.21s/epoch, loss=0.243, accuracy=0.957, val_loss=0.528, val_accuracy=0.875, lr=0.000316] 89%|████████▉ | 148/166 [50:39<06:03, 20.22s/epoch, loss=0.239, accuracy=0.959, val_loss=0.517, val_accuracy=0.879, lr=0.001]    90%|████████▉ | 149/166 [51:00<05:44, 20.29s/epoch, loss=0.236, accuracy=0.959, val_loss=0.497, val_accuracy=0.883, lr=0.001] 90%|█████████ | 150/166 [51:20<05:24, 20.29s/epoch, loss=0.234, accuracy=0.958, val_loss=0.573, val_accuracy=0.86, lr=0.001]  91%|█████████ | 151/166 [51:41<05:04, 20.30s/epoch, loss=0.231, accuracy=0.959, val_loss=0.484, val_accuracy=0.887, lr=0.001] 92%|█████████▏| 152/166 [52:01<04:43, 20.28s/epoch, loss=0.23, accuracy=0.96, val_loss=0.48, val_accuracy=0.886, lr=0.000316] 92%|█████████▏| 153/166 [52:21<04:24, 20.31s/epoch, loss=0.229, accuracy=0.959, val_loss=0.491, val_accuracy=0.887, lr=0.001] 93%|█████████▎| 154/166 [52:41<04:03, 20.28s/epoch, loss=0.23, accuracy=0.958, val_loss=0.518, val_accuracy=0.876, lr=0.001]  93%|█████████▎| 155/166 [53:02<03:42, 20.24s/epoch, loss=0.226, accuracy=0.96, val_loss=0.591, val_accuracy=0.858, lr=0.001] 94%|█████████▍| 156/166 [53:22<03:22, 20.22s/epoch, loss=0.223, accuracy=0.96, val_loss=0.516, val_accuracy=0.872, lr=0.001] 95%|█████████▍| 157/166 [53:42<03:01, 20.22s/epoch, loss=0.224, accuracy=0.959, val_loss=0.52, val_accuracy=0.878, lr=0.000316] 95%|█████████▌| 158/166 [54:02<02:41, 20.20s/epoch, loss=0.221, accuracy=0.959, val_loss=0.517, val_accuracy=0.878, lr=0.001]   96%|█████████▌| 159/166 [54:22<02:21, 20.23s/epoch, loss=0.223, accuracy=0.958, val_loss=0.515, val_accuracy=0.879, lr=0.001] 96%|█████████▋| 160/166 [54:42<02:01, 20.19s/epoch, loss=0.22, accuracy=0.96, val_loss=0.539, val_accuracy=0.874, lr=0.001]   97%|█████████▋| 161/166 [55:03<01:40, 20.19s/epoch, loss=0.219, accuracy=0.959, val_loss=0.495, val_accuracy=0.882, lr=0.001] 98%|█████████▊| 162/166 [55:23<01:20, 20.21s/epoch, loss=0.199, accuracy=0.968, val_loss=0.424, val_accuracy=0.9, lr=1e-04]   98%|█████████▊| 163/166 [55:43<01:00, 20.24s/epoch, loss=0.183, accuracy=0.975, val_loss=0.419, val_accuracy=0.901, lr=1e-04] 99%|█████████▉| 164/166 [56:03<00:40, 20.18s/epoch, loss=0.178, accuracy=0.976, val_loss=0.417, val_accuracy=0.902, lr=1e-04] 99%|█████████▉| 165/166 [56:23<00:20, 20.09s/epoch, loss=0.175, accuracy=0.978, val_loss=0.418, val_accuracy=0.903, lr=1e-04]100%|██████████| 166/166 [56:43<00:00, 20.11s/epoch, loss=0.173, accuracy=0.978, val_loss=0.419, val_accuracy=0.902, lr=1e-04]100%|██████████| 166/166 [56:43<00:00, 20.50s/epoch, loss=0.173, accuracy=0.978, val_loss=0.419, val_accuracy=0.902, lr=1e-04]
Using real-time data augmentation.
Test score: 0.4190201163291931
Test accuracy: 0.9024999737739563


* * * Run SGD for ID = 9_2. * * *


2024-03-05 01:55:47.478539: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 01:55:50.033040: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 01:55:50.034116: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-05 01:55:50.071467: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-03-05 01:55:50.071513: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 01:55:50.074424: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 01:55:50.074467: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 01:55:50.076406: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 01:55:50.077126: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 01:55:50.079332: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 01:55:50.080696: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 01:55:50.085334: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 01:55:50.085950: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 01:55:50.086063: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 01:55:51.294758: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-05 01:55:51.295389: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 01:55:51.296175: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-03-05 01:55:51.296207: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 01:55:51.296245: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 01:55:51.296262: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 01:55:51.296278: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 01:55:51.296293: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 01:55:51.296308: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 01:55:51.296324: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 01:55:51.296339: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 01:55:51.296780: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 01:55:51.296820: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 01:55:51.943054: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-05 01:55:51.943111: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-05 01:55:51.943121: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-05 01:55:51.944023: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:02:00.0, compute capability: 6.1)
{'id': '09_02', 'seed': 2, 'out_folder': 'results/epoch_budget', 'batch_size': 128, 'epochs': 166, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'bootstrapping': False, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/166 [00:00<?, ?epoch/s]2024-03-05 01:55:52.764716: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-05 01:55:52.777125: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600020000 Hz
2024-03-05 01:55:54.629776: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 01:55:54.842862: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 01:55:55.611716: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-05 01:55:55.658099: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/166 [01:01<2:49:24, 61.60s/epoch, loss=2.83, accuracy=0.393, val_loss=4.16, val_accuracy=0.193, lr=0.1]  1%|          | 2/166 [01:22<1:42:34, 37.53s/epoch, loss=1.44, accuracy=0.6, val_loss=2.12, val_accuracy=0.445, lr=0.1]    2%|▏         | 3/166 [01:42<1:20:39, 29.69s/epoch, loss=1.28, accuracy=0.67, val_loss=2.1, val_accuracy=0.427, lr=0.1]  2%|▏         | 4/166 [02:02<1:09:56, 25.90s/epoch, loss=1.25, accuracy=0.695, val_loss=1.6, val_accuracy=0.59, lr=0.1]  3%|▎         | 5/166 [02:22<1:03:49, 23.78s/epoch, loss=1.23, accuracy=0.708, val_loss=2.13, val_accuracy=0.426, lr=0.1]  4%|▎         | 6/166 [02:42<1:00:01, 22.51s/epoch, loss=1.21, accuracy=0.717, val_loss=2.18, val_accuracy=0.497, lr=0.1]  4%|▍         | 7/166 [03:02<57:26, 21.68s/epoch, loss=1.21, accuracy=0.722, val_loss=1.7, val_accuracy=0.543, lr=0.1]     5%|▍         | 8/166 [03:23<55:56, 21.24s/epoch, loss=1.21, accuracy=0.725, val_loss=3.35, val_accuracy=0.347, lr=0.1]  5%|▌         | 9/166 [03:43<54:41, 20.90s/epoch, loss=1.2, accuracy=0.733, val_loss=3.06, val_accuracy=0.384, lr=0.0316]  6%|▌         | 10/166 [04:03<53:49, 20.70s/epoch, loss=1.19, accuracy=0.733, val_loss=1.69, val_accuracy=0.58, lr=0.1]    7%|▋         | 11/166 [04:23<53:16, 20.62s/epoch, loss=1.19, accuracy=0.735, val_loss=2.65, val_accuracy=0.425, lr=0.1]  7%|▋         | 12/166 [04:44<52:42, 20.54s/epoch, loss=1.19, accuracy=0.735, val_loss=2, val_accuracy=0.459, lr=0.1]     8%|▊         | 13/166 [05:04<52:06, 20.44s/epoch, loss=1.19, accuracy=0.74, val_loss=2.65, val_accuracy=0.46, lr=0.1]  8%|▊         | 14/166 [05:24<51:32, 20.35s/epoch, loss=1.18, accuracy=0.741, val_loss=2.12, val_accuracy=0.506, lr=0.0316]  9%|▉         | 15/166 [05:44<50:58, 20.25s/epoch, loss=1.17, accuracy=0.744, val_loss=2.2, val_accuracy=0.482, lr=0.1]     10%|▉         | 16/166 [06:04<50:26, 20.18s/epoch, loss=1.17, accuracy=0.743, val_loss=1.54, val_accuracy=0.617, lr=0.1] 10%|█         | 17/166 [06:24<50:12, 20.22s/epoch, loss=1.17, accuracy=0.745, val_loss=1.78, val_accuracy=0.513, lr=0.1] 11%|█         | 18/166 [06:45<49:56, 20.25s/epoch, loss=1.17, accuracy=0.743, val_loss=1.87, val_accuracy=0.502, lr=0.1] 11%|█▏        | 19/166 [07:05<49:36, 20.25s/epoch, loss=1.16, accuracy=0.747, val_loss=1.52, val_accuracy=0.621, lr=0.1] 12%|█▏        | 20/166 [07:25<49:18, 20.27s/epoch, loss=1.16, accuracy=0.747, val_loss=1.98, val_accuracy=0.52, lr=0.1]  13%|█▎        | 21/166 [07:46<49:01, 20.29s/epoch, loss=1.16, accuracy=0.747, val_loss=2.16, val_accuracy=0.472, lr=0.1] 13%|█▎        | 22/166 [08:06<48:35, 20.25s/epoch, loss=1.15, accuracy=0.75, val_loss=2.31, val_accuracy=0.379, lr=0.1]  14%|█▍        | 23/166 [08:26<48:20, 20.28s/epoch, loss=1.15, accuracy=0.75, val_loss=1.58, val_accuracy=0.602, lr=0.1] 14%|█▍        | 24/166 [08:47<48:06, 20.33s/epoch, loss=1.15, accuracy=0.748, val_loss=1.79, val_accuracy=0.524, lr=0.0316] 15%|█▌        | 25/166 [09:07<47:43, 20.31s/epoch, loss=1.16, accuracy=0.749, val_loss=1.6, val_accuracy=0.587, lr=0.1]     16%|█▌        | 26/166 [09:27<47:19, 20.28s/epoch, loss=1.15, accuracy=0.75, val_loss=2.39, val_accuracy=0.431, lr=0.1] 16%|█▋        | 27/166 [09:47<46:52, 20.23s/epoch, loss=1.15, accuracy=0.748, val_loss=1.62, val_accuracy=0.595, lr=0.1] 17%|█▋        | 28/166 [10:07<46:31, 20.23s/epoch, loss=1.14, accuracy=0.751, val_loss=1.85, val_accuracy=0.526, lr=0.1] 17%|█▋        | 29/166 [10:28<46:05, 20.19s/epoch, loss=1.14, accuracy=0.751, val_loss=2.15, val_accuracy=0.409, lr=0.0316] 18%|█▊        | 30/166 [10:48<45:44, 20.18s/epoch, loss=1.14, accuracy=0.752, val_loss=3.07, val_accuracy=0.309, lr=0.1]    19%|█▊        | 31/166 [11:08<45:24, 20.18s/epoch, loss=1.14, accuracy=0.752, val_loss=1.6, val_accuracy=0.584, lr=0.1]  19%|█▉        | 32/166 [11:28<45:01, 20.16s/epoch, loss=1.14, accuracy=0.749, val_loss=1.71, val_accuracy=0.534, lr=0.1] 20%|█▉        | 33/166 [11:48<44:39, 20.15s/epoch, loss=1.14, accuracy=0.752, val_loss=1.56, val_accuracy=0.618, lr=0.1] 20%|██        | 34/166 [12:08<44:21, 20.16s/epoch, loss=1.14, accuracy=0.752, val_loss=2.04, val_accuracy=0.427, lr=0.0316] 21%|██        | 35/166 [12:29<44:08, 20.22s/epoch, loss=1.13, accuracy=0.753, val_loss=1.58, val_accuracy=0.576, lr=0.1]    22%|██▏       | 36/166 [12:49<43:52, 20.25s/epoch, loss=1.14, accuracy=0.754, val_loss=5.72, val_accuracy=0.199, lr=0.1] 22%|██▏       | 37/166 [13:09<43:37, 20.29s/epoch, loss=1.14, accuracy=0.752, val_loss=1.47, val_accuracy=0.641, lr=0.1] 23%|██▎       | 38/166 [13:29<43:05, 20.20s/epoch, loss=1.14, accuracy=0.751, val_loss=2.03, val_accuracy=0.519, lr=0.1] 23%|██▎       | 39/166 [13:50<42:43, 20.18s/epoch, loss=1.13, accuracy=0.753, val_loss=1.66, val_accuracy=0.617, lr=0.1] 24%|██▍       | 40/166 [14:10<42:23, 20.19s/epoch, loss=1.13, accuracy=0.757, val_loss=1.81, val_accuracy=0.545, lr=0.1] 25%|██▍       | 41/166 [14:30<42:07, 20.22s/epoch, loss=1.14, accuracy=0.755, val_loss=2.87, val_accuracy=0.419, lr=0.1] 25%|██▌       | 42/166 [14:50<41:43, 20.19s/epoch, loss=1.13, accuracy=0.755, val_loss=1.85, val_accuracy=0.584, lr=0.0316] 26%|██▌       | 43/166 [15:10<41:24, 20.20s/epoch, loss=1.14, accuracy=0.752, val_loss=2.31, val_accuracy=0.429, lr=0.1]    27%|██▋       | 44/166 [15:31<41:14, 20.28s/epoch, loss=1.14, accuracy=0.753, val_loss=2.55, val_accuracy=0.306, lr=0.1] 27%|██▋       | 45/166 [15:51<40:54, 20.29s/epoch, loss=1.14, accuracy=0.753, val_loss=1.54, val_accuracy=0.62, lr=0.1]  28%|██▊       | 46/166 [16:11<40:29, 20.25s/epoch, loss=1.13, accuracy=0.754, val_loss=4.49, val_accuracy=0.239, lr=0.1] 28%|██▊       | 47/166 [16:32<40:11, 20.26s/epoch, loss=1.14, accuracy=0.754, val_loss=3.26, val_accuracy=0.372, lr=0.0316] 29%|██▉       | 48/166 [16:52<39:49, 20.25s/epoch, loss=1.14, accuracy=0.755, val_loss=1.61, val_accuracy=0.595, lr=0.1]    30%|██▉       | 49/166 [17:12<39:32, 20.28s/epoch, loss=1.13, accuracy=0.758, val_loss=2.65, val_accuracy=0.34, lr=0.1]  30%|███       | 50/166 [17:32<39:14, 20.30s/epoch, loss=1.14, accuracy=0.751, val_loss=2.53, val_accuracy=0.411, lr=0.1] 31%|███       | 51/166 [17:53<38:53, 20.29s/epoch, loss=1.13, accuracy=0.755, val_loss=2.39, val_accuracy=0.494, lr=0.1] 31%|███▏      | 52/166 [18:13<38:24, 20.21s/epoch, loss=1.13, accuracy=0.755, val_loss=1.8, val_accuracy=0.517, lr=0.0316] 32%|███▏      | 53/166 [18:33<38:09, 20.26s/epoch, loss=1.13, accuracy=0.759, val_loss=1.53, val_accuracy=0.635, lr=0.1]   33%|███▎      | 54/166 [18:53<37:50, 20.28s/epoch, loss=1.14, accuracy=0.751, val_loss=2.74, val_accuracy=0.361, lr=0.1] 33%|███▎      | 55/166 [19:14<37:34, 20.31s/epoch, loss=1.13, accuracy=0.756, val_loss=2.07, val_accuracy=0.431, lr=0.1] 34%|███▎      | 56/166 [19:34<37:17, 20.34s/epoch, loss=1.13, accuracy=0.753, val_loss=1.96, val_accuracy=0.538, lr=0.1] 34%|███▍      | 57/166 [19:54<36:51, 20.29s/epoch, loss=1.13, accuracy=0.755, val_loss=2.48, val_accuracy=0.429, lr=0.0316] 35%|███▍      | 58/166 [20:15<36:27, 20.26s/epoch, loss=1.13, accuracy=0.755, val_loss=1.48, val_accuracy=0.646, lr=0.1]    36%|███▌      | 59/166 [20:35<36:08, 20.27s/epoch, loss=1.13, accuracy=0.755, val_loss=2.41, val_accuracy=0.472, lr=0.1] 36%|███▌      | 60/166 [20:55<35:37, 20.16s/epoch, loss=1.13, accuracy=0.757, val_loss=2.17, val_accuracy=0.439, lr=0.1] 37%|███▋      | 61/166 [21:15<35:14, 20.14s/epoch, loss=1.13, accuracy=0.755, val_loss=1.8, val_accuracy=0.529, lr=0.1]  37%|███▋      | 62/166 [21:35<35:02, 20.21s/epoch, loss=1.13, accuracy=0.756, val_loss=1.4, val_accuracy=0.66, lr=0.1]  38%|███▊      | 63/166 [21:56<34:44, 20.24s/epoch, loss=1.13, accuracy=0.756, val_loss=2.36, val_accuracy=0.462, lr=0.1] 39%|███▊      | 64/166 [22:16<34:22, 20.22s/epoch, loss=1.13, accuracy=0.757, val_loss=2.42, val_accuracy=0.432, lr=0.1] 39%|███▉      | 65/166 [22:36<34:00, 20.20s/epoch, loss=1.13, accuracy=0.755, val_loss=2.54, val_accuracy=0.389, lr=0.1] 40%|███▉      | 66/166 [22:56<33:43, 20.24s/epoch, loss=1.13, accuracy=0.754, val_loss=3.92, val_accuracy=0.318, lr=0.1] 40%|████      | 67/166 [23:16<33:18, 20.19s/epoch, loss=1.13, accuracy=0.756, val_loss=1.85, val_accuracy=0.48, lr=0.0316] 41%|████      | 68/166 [23:36<32:54, 20.15s/epoch, loss=1.13, accuracy=0.756, val_loss=1.58, val_accuracy=0.604, lr=0.1]   42%|████▏     | 69/166 [23:56<32:33, 20.14s/epoch, loss=1.13, accuracy=0.756, val_loss=1.96, val_accuracy=0.478, lr=0.1] 42%|████▏     | 70/166 [24:17<32:11, 20.12s/epoch, loss=1.14, accuracy=0.753, val_loss=2.36, val_accuracy=0.435, lr=0.1] 43%|████▎     | 71/166 [24:37<31:47, 20.08s/epoch, loss=1.12, accuracy=0.753, val_loss=1.87, val_accuracy=0.55, lr=0.1]  43%|████▎     | 72/166 [24:57<31:29, 20.10s/epoch, loss=1.13, accuracy=0.753, val_loss=2.19, val_accuracy=0.396, lr=0.0316] 44%|████▍     | 73/166 [25:17<31:05, 20.06s/epoch, loss=1.13, accuracy=0.757, val_loss=1.93, val_accuracy=0.512, lr=0.1]    45%|████▍     | 74/166 [25:37<30:43, 20.04s/epoch, loss=1.12, accuracy=0.758, val_loss=1.45, val_accuracy=0.645, lr=0.1] 45%|████▌     | 75/166 [25:57<30:25, 20.06s/epoch, loss=1.13, accuracy=0.753, val_loss=2.02, val_accuracy=0.539, lr=0.1] 46%|████▌     | 76/166 [26:17<30:07, 20.08s/epoch, loss=1.12, accuracy=0.756, val_loss=2.4, val_accuracy=0.451, lr=0.1]  46%|████▋     | 77/166 [26:37<29:43, 20.04s/epoch, loss=1.12, accuracy=0.758, val_loss=3.46, val_accuracy=0.33, lr=0.0316] 47%|████▋     | 78/166 [26:57<29:26, 20.07s/epoch, loss=1.12, accuracy=0.755, val_loss=2.05, val_accuracy=0.515, lr=0.1]   48%|████▊     | 79/166 [27:17<29:09, 20.11s/epoch, loss=1.12, accuracy=0.759, val_loss=1.87, val_accuracy=0.533, lr=0.1] 48%|████▊     | 80/166 [27:37<28:50, 20.12s/epoch, loss=1.13, accuracy=0.757, val_loss=1.54, val_accuracy=0.634, lr=0.1] 49%|████▉     | 81/166 [27:57<28:25, 20.07s/epoch, loss=1.12, accuracy=0.753, val_loss=2.67, val_accuracy=0.409, lr=0.1] 49%|████▉     | 82/166 [28:17<28:05, 20.06s/epoch, loss=0.932, accuracy=0.813, val_loss=0.885, val_accuracy=0.81, lr=0.01] 50%|█████     | 83/166 [28:37<27:43, 20.05s/epoch, loss=0.743, accuracy=0.846, val_loss=0.809, val_accuracy=0.813, lr=0.01] 51%|█████     | 84/166 [28:57<27:22, 20.03s/epoch, loss=0.66, accuracy=0.853, val_loss=0.743, val_accuracy=0.817, lr=0.01]  51%|█████     | 85/166 [29:17<27:01, 20.01s/epoch, loss=0.617, accuracy=0.858, val_loss=0.792, val_accuracy=0.797, lr=0.01] 52%|█████▏    | 86/166 [29:37<26:36, 19.95s/epoch, loss=0.589, accuracy=0.86, val_loss=0.762, val_accuracy=0.797, lr=0.01]  52%|█████▏    | 87/166 [29:57<26:15, 19.94s/epoch, loss=0.579, accuracy=0.862, val_loss=0.757, val_accuracy=0.801, lr=0.01] 53%|█████▎    | 88/166 [30:17<25:53, 19.92s/epoch, loss=0.571, accuracy=0.862, val_loss=0.794, val_accuracy=0.799, lr=0.01] 54%|█████▎    | 89/166 [30:37<25:33, 19.91s/epoch, loss=0.57, accuracy=0.864, val_loss=0.813, val_accuracy=0.786, lr=0.00316] 54%|█████▍    | 90/166 [30:57<25:13, 19.91s/epoch, loss=0.566, accuracy=0.866, val_loss=0.8, val_accuracy=0.791, lr=0.01]     55%|█████▍    | 91/166 [31:17<24:51, 19.88s/epoch, loss=0.562, accuracy=0.867, val_loss=0.668, val_accuracy=0.837, lr=0.01] 55%|█████▌    | 92/166 [31:36<24:33, 19.91s/epoch, loss=0.559, accuracy=0.869, val_loss=1.03, val_accuracy=0.736, lr=0.01]  56%|█████▌    | 93/166 [31:56<24:12, 19.90s/epoch, loss=0.561, accuracy=0.869, val_loss=0.79, val_accuracy=0.79, lr=0.01]  57%|█████▋    | 94/166 [32:16<23:51, 19.88s/epoch, loss=0.561, accuracy=0.869, val_loss=1.13, val_accuracy=0.706, lr=0.01] 57%|█████▋    | 95/166 [32:36<23:29, 19.85s/epoch, loss=0.559, accuracy=0.872, val_loss=0.775, val_accuracy=0.795, lr=0.01] 58%|█████▊    | 96/166 [32:56<23:09, 19.85s/epoch, loss=0.557, accuracy=0.874, val_loss=0.788, val_accuracy=0.804, lr=0.00316] 58%|█████▊    | 97/166 [33:16<22:49, 19.85s/epoch, loss=0.558, accuracy=0.874, val_loss=0.886, val_accuracy=0.766, lr=0.01]    59%|█████▉    | 98/166 [33:35<22:28, 19.84s/epoch, loss=0.56, accuracy=0.873, val_loss=0.68, val_accuracy=0.838, lr=0.01]   60%|█████▉    | 99/166 [33:55<22:06, 19.79s/epoch, loss=0.557, accuracy=0.876, val_loss=0.748, val_accuracy=0.812, lr=0.01] 60%|██████    | 100/166 [34:15<21:51, 19.87s/epoch, loss=0.559, accuracy=0.878, val_loss=0.746, val_accuracy=0.817, lr=0.01] 61%|██████    | 101/166 [34:35<21:34, 19.92s/epoch, loss=0.556, accuracy=0.876, val_loss=0.767, val_accuracy=0.816, lr=0.00316] 61%|██████▏   | 102/166 [34:55<21:18, 19.98s/epoch, loss=0.557, accuracy=0.878, val_loss=0.709, val_accuracy=0.829, lr=0.01]    62%|██████▏   | 103/166 [35:15<20:59, 20.00s/epoch, loss=0.558, accuracy=0.877, val_loss=0.765, val_accuracy=0.812, lr=0.01] 63%|██████▎   | 104/166 [35:35<20:40, 20.00s/epoch, loss=0.552, accuracy=0.88, val_loss=0.961, val_accuracy=0.775, lr=0.01]  63%|██████▎   | 105/166 [35:55<20:16, 19.94s/epoch, loss=0.557, accuracy=0.879, val_loss=0.778, val_accuracy=0.808, lr=0.01] 64%|██████▍   | 106/166 [36:15<19:55, 19.93s/epoch, loss=0.558, accuracy=0.878, val_loss=0.737, val_accuracy=0.825, lr=0.00316] 64%|██████▍   | 107/166 [36:35<19:34, 19.91s/epoch, loss=0.556, accuracy=0.88, val_loss=0.83, val_accuracy=0.804, lr=0.01]      65%|██████▌   | 108/166 [36:55<19:15, 19.93s/epoch, loss=0.557, accuracy=0.88, val_loss=0.805, val_accuracy=0.811, lr=0.01] 66%|██████▌   | 109/166 [37:15<18:53, 19.89s/epoch, loss=0.559, accuracy=0.879, val_loss=0.793, val_accuracy=0.808, lr=0.01] 66%|██████▋   | 110/166 [37:35<18:36, 19.94s/epoch, loss=0.553, accuracy=0.881, val_loss=0.926, val_accuracy=0.769, lr=0.01] 67%|██████▋   | 111/166 [37:55<18:16, 19.94s/epoch, loss=0.556, accuracy=0.88, val_loss=0.862, val_accuracy=0.796, lr=0.00316] 67%|██████▋   | 112/166 [38:15<17:58, 19.98s/epoch, loss=0.554, accuracy=0.881, val_loss=0.75, val_accuracy=0.824, lr=0.01]    68%|██████▊   | 113/166 [38:35<17:35, 19.91s/epoch, loss=0.554, accuracy=0.883, val_loss=1.04, val_accuracy=0.745, lr=0.01] 69%|██████▊   | 114/166 [38:55<17:18, 19.97s/epoch, loss=0.557, accuracy=0.882, val_loss=0.833, val_accuracy=0.812, lr=0.01] 69%|██████▉   | 115/166 [39:15<17:00, 20.00s/epoch, loss=0.556, accuracy=0.882, val_loss=0.747, val_accuracy=0.823, lr=0.01] 70%|██████▉   | 116/166 [39:35<16:43, 20.07s/epoch, loss=0.551, accuracy=0.885, val_loss=0.934, val_accuracy=0.777, lr=0.00316] 70%|███████   | 117/166 [39:55<16:22, 20.05s/epoch, loss=0.554, accuracy=0.883, val_loss=0.854, val_accuracy=0.797, lr=0.01]    71%|███████   | 118/166 [40:15<16:02, 20.06s/epoch, loss=0.558, accuracy=0.883, val_loss=0.863, val_accuracy=0.784, lr=0.01] 72%|███████▏  | 119/166 [40:35<15:43, 20.07s/epoch, loss=0.56, accuracy=0.884, val_loss=0.928, val_accuracy=0.781, lr=0.01]  72%|███████▏  | 120/166 [40:55<15:22, 20.06s/epoch, loss=0.552, accuracy=0.884, val_loss=1.05, val_accuracy=0.744, lr=0.01] 73%|███████▎  | 121/166 [41:15<15:03, 20.08s/epoch, loss=0.559, accuracy=0.883, val_loss=0.772, val_accuracy=0.819, lr=0.00316] 73%|███████▎  | 122/166 [41:36<14:44, 20.11s/epoch, loss=0.484, accuracy=0.909, val_loss=0.536, val_accuracy=0.891, lr=0.001]   74%|███████▍  | 123/166 [41:56<14:23, 20.08s/epoch, loss=0.428, accuracy=0.927, val_loss=0.522, val_accuracy=0.896, lr=0.001] 75%|███████▍  | 124/166 [42:16<14:01, 20.05s/epoch, loss=0.407, accuracy=0.932, val_loss=0.509, val_accuracy=0.898, lr=0.001] 75%|███████▌  | 125/166 [42:36<13:41, 20.04s/epoch, loss=0.389, accuracy=0.936, val_loss=0.499, val_accuracy=0.898, lr=0.001] 76%|███████▌  | 126/166 [42:55<13:19, 19.99s/epoch, loss=0.377, accuracy=0.939, val_loss=0.505, val_accuracy=0.898, lr=0.001] 77%|███████▋  | 127/166 [43:15<12:59, 19.98s/epoch, loss=0.363, accuracy=0.941, val_loss=0.495, val_accuracy=0.898, lr=0.001] 77%|███████▋  | 128/166 [43:35<12:40, 20.01s/epoch, loss=0.352, accuracy=0.945, val_loss=0.491, val_accuracy=0.899, lr=0.001] 78%|███████▊  | 129/166 [43:55<12:17, 19.94s/epoch, loss=0.344, accuracy=0.944, val_loss=0.478, val_accuracy=0.899, lr=0.001] 78%|███████▊  | 130/166 [44:15<11:58, 19.96s/epoch, loss=0.333, accuracy=0.947, val_loss=0.491, val_accuracy=0.898, lr=0.001] 79%|███████▉  | 131/166 [44:35<11:39, 19.97s/epoch, loss=0.323, accuracy=0.949, val_loss=0.468, val_accuracy=0.903, lr=0.001] 80%|███████▉  | 132/166 [44:55<11:21, 20.05s/epoch, loss=0.315, accuracy=0.95, val_loss=0.481, val_accuracy=0.897, lr=0.001]  80%|████████  | 133/166 [45:15<11:00, 20.01s/epoch, loss=0.31, accuracy=0.951, val_loss=0.468, val_accuracy=0.899, lr=0.001] 81%|████████  | 134/166 [45:35<10:40, 20.02s/epoch, loss=0.3, accuracy=0.952, val_loss=0.475, val_accuracy=0.897, lr=0.001]  81%|████████▏ | 135/166 [45:55<10:19, 20.00s/epoch, loss=0.295, accuracy=0.953, val_loss=0.468, val_accuracy=0.9, lr=0.001] 82%|████████▏ | 136/166 [46:15<09:59, 20.00s/epoch, loss=0.288, accuracy=0.953, val_loss=0.471, val_accuracy=0.899, lr=0.000316] 83%|████████▎ | 137/166 [46:35<09:38, 19.94s/epoch, loss=0.284, accuracy=0.955, val_loss=0.469, val_accuracy=0.897, lr=0.001]    83%|████████▎ | 138/166 [46:55<09:18, 19.93s/epoch, loss=0.276, accuracy=0.957, val_loss=0.463, val_accuracy=0.9, lr=0.001]   84%|████████▎ | 139/166 [47:15<08:56, 19.89s/epoch, loss=0.272, accuracy=0.956, val_loss=0.473, val_accuracy=0.894, lr=0.001] 84%|████████▍ | 140/166 [47:35<08:35, 19.83s/epoch, loss=0.264, accuracy=0.957, val_loss=0.472, val_accuracy=0.897, lr=0.001] 85%|████████▍ | 141/166 [47:55<08:16, 19.87s/epoch, loss=0.263, accuracy=0.957, val_loss=0.463, val_accuracy=0.898, lr=0.001] 86%|████████▌ | 142/166 [48:14<07:56, 19.85s/epoch, loss=0.259, accuracy=0.958, val_loss=0.457, val_accuracy=0.896, lr=0.001] 86%|████████▌ | 143/166 [48:34<07:36, 19.87s/epoch, loss=0.253, accuracy=0.958, val_loss=0.461, val_accuracy=0.891, lr=0.001] 87%|████████▋ | 144/166 [48:54<07:16, 19.84s/epoch, loss=0.251, accuracy=0.958, val_loss=0.463, val_accuracy=0.894, lr=0.001] 87%|████████▋ | 145/166 [49:14<06:56, 19.82s/epoch, loss=0.247, accuracy=0.959, val_loss=0.455, val_accuracy=0.897, lr=0.001] 88%|████████▊ | 146/166 [49:34<06:36, 19.82s/epoch, loss=0.242, accuracy=0.959, val_loss=0.467, val_accuracy=0.891, lr=0.001] 89%|████████▊ | 147/166 [49:54<06:16, 19.84s/epoch, loss=0.238, accuracy=0.96, val_loss=0.462, val_accuracy=0.893, lr=0.001]  89%|████████▉ | 148/166 [50:13<05:57, 19.86s/epoch, loss=0.236, accuracy=0.96, val_loss=0.451, val_accuracy=0.893, lr=0.001] 90%|████████▉ | 149/166 [50:33<05:38, 19.89s/epoch, loss=0.238, accuracy=0.959, val_loss=0.477, val_accuracy=0.894, lr=0.001] 90%|█████████ | 150/166 [50:53<05:18, 19.91s/epoch, loss=0.232, accuracy=0.96, val_loss=0.458, val_accuracy=0.893, lr=0.001]  91%|█████████ | 151/166 [51:13<04:58, 19.91s/epoch, loss=0.232, accuracy=0.959, val_loss=0.461, val_accuracy=0.896, lr=0.001] 92%|█████████▏| 152/166 [51:33<04:38, 19.91s/epoch, loss=0.229, accuracy=0.96, val_loss=0.482, val_accuracy=0.889, lr=0.001]  92%|█████████▏| 153/166 [51:53<04:18, 19.90s/epoch, loss=0.229, accuracy=0.961, val_loss=0.478, val_accuracy=0.888, lr=0.000316] 93%|█████████▎| 154/166 [52:13<03:58, 19.91s/epoch, loss=0.227, accuracy=0.959, val_loss=0.467, val_accuracy=0.891, lr=0.001]    93%|█████████▎| 155/166 [52:33<03:38, 19.88s/epoch, loss=0.224, accuracy=0.96, val_loss=0.483, val_accuracy=0.886, lr=0.001]  94%|█████████▍| 156/166 [52:53<03:18, 19.87s/epoch, loss=0.224, accuracy=0.96, val_loss=0.474, val_accuracy=0.886, lr=0.001] 95%|█████████▍| 157/166 [53:12<02:58, 19.83s/epoch, loss=0.22, accuracy=0.962, val_loss=0.472, val_accuracy=0.89, lr=0.001]  95%|█████████▌| 158/166 [53:32<02:38, 19.82s/epoch, loss=0.22, accuracy=0.961, val_loss=0.493, val_accuracy=0.887, lr=0.000316] 96%|█████████▌| 159/166 [53:52<02:18, 19.79s/epoch, loss=0.22, accuracy=0.959, val_loss=0.491, val_accuracy=0.883, lr=0.001]    96%|█████████▋| 160/166 [54:12<01:58, 19.76s/epoch, loss=0.217, accuracy=0.961, val_loss=0.509, val_accuracy=0.882, lr=0.001] 97%|█████████▋| 161/166 [54:31<01:38, 19.78s/epoch, loss=0.218, accuracy=0.961, val_loss=0.475, val_accuracy=0.886, lr=0.001] 98%|█████████▊| 162/166 [54:51<01:19, 19.80s/epoch, loss=0.199, accuracy=0.969, val_loss=0.421, val_accuracy=0.905, lr=1e-04] 98%|█████████▊| 163/166 [55:11<00:59, 19.76s/epoch, loss=0.184, accuracy=0.974, val_loss=0.417, val_accuracy=0.908, lr=1e-04] 99%|█████████▉| 164/166 [55:31<00:39, 19.77s/epoch, loss=0.176, accuracy=0.977, val_loss=0.417, val_accuracy=0.908, lr=1e-04] 99%|█████████▉| 165/166 [55:51<00:19, 19.81s/epoch, loss=0.175, accuracy=0.977, val_loss=0.415, val_accuracy=0.91, lr=1e-04] 100%|██████████| 166/166 [56:10<00:00, 19.81s/epoch, loss=0.172, accuracy=0.978, val_loss=0.418, val_accuracy=0.909, lr=1e-04]100%|██████████| 166/166 [56:10<00:00, 20.31s/epoch, loss=0.172, accuracy=0.978, val_loss=0.418, val_accuracy=0.909, lr=1e-04]
Using real-time data augmentation.
Test score: 0.417537122964859
Test accuracy: 0.9089999794960022


* * * Run SGD for ID = 9_3. * * *


2024-03-05 02:52:08.087963: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 02:52:15.068114: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 02:52:15.069339: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-05 02:52:15.106029: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-03-05 02:52:15.106077: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 02:52:15.111676: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 02:52:15.111723: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 02:52:15.116002: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 02:52:15.118425: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 02:52:15.122003: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 02:52:15.123477: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 02:52:15.130701: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 02:52:15.131372: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 02:52:15.131477: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 02:52:16.380899: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-05 02:52:16.381997: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 02:52:16.382525: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-03-05 02:52:16.382567: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 02:52:16.382609: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 02:52:16.382626: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 02:52:16.382641: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 02:52:16.382656: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 02:52:16.382671: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 02:52:16.382686: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 02:52:16.382701: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 02:52:16.383173: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 02:52:16.383216: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 02:52:17.042919: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-05 02:52:17.042981: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-05 02:52:17.042991: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-05 02:52:17.043935: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:02:00.0, compute capability: 6.1)
{'id': '09_03', 'seed': 3, 'out_folder': 'results/epoch_budget', 'batch_size': 128, 'epochs': 166, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'bootstrapping': False, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/166 [00:00<?, ?epoch/s]2024-03-05 02:52:17.971146: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-05 02:52:17.971703: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600020000 Hz
2024-03-05 02:52:19.984539: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 02:52:20.276020: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 02:52:21.183674: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-05 02:52:21.248194: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/166 [01:00<2:46:02, 60.38s/epoch, loss=2.86, accuracy=0.401, val_loss=2.38, val_accuracy=0.363, lr=0.1]  1%|          | 2/166 [01:20<1:40:28, 36.76s/epoch, loss=1.51, accuracy=0.57, val_loss=2.27, val_accuracy=0.414, lr=0.1]   2%|▏         | 3/166 [01:41<1:19:40, 29.33s/epoch, loss=1.34, accuracy=0.649, val_loss=1.53, val_accuracy=0.595, lr=0.1]  2%|▏         | 4/166 [02:01<1:09:10, 25.62s/epoch, loss=1.29, accuracy=0.685, val_loss=2.36, val_accuracy=0.374, lr=0.1]  3%|▎         | 5/166 [02:20<1:03:11, 23.55s/epoch, loss=1.26, accuracy=0.705, val_loss=2.16, val_accuracy=0.437, lr=0.1]  4%|▎         | 6/166 [02:40<59:30, 22.32s/epoch, loss=1.25, accuracy=0.716, val_loss=3.19, val_accuracy=0.343, lr=0.1]    4%|▍         | 7/166 [03:00<57:05, 21.55s/epoch, loss=1.23, accuracy=0.722, val_loss=4.1, val_accuracy=0.347, lr=0.1]   5%|▍         | 8/166 [03:20<55:32, 21.09s/epoch, loss=1.22, accuracy=0.725, val_loss=1.52, val_accuracy=0.631, lr=0.1]  5%|▌         | 9/166 [03:41<54:57, 21.00s/epoch, loss=1.22, accuracy=0.727, val_loss=1.69, val_accuracy=0.575, lr=0.1]  6%|▌         | 10/166 [04:01<53:55, 20.74s/epoch, loss=1.21, accuracy=0.734, val_loss=2.86, val_accuracy=0.322, lr=0.1]  7%|▋         | 11/166 [04:21<52:57, 20.50s/epoch, loss=1.21, accuracy=0.733, val_loss=1.99, val_accuracy=0.53, lr=0.1]   7%|▋         | 12/166 [04:42<52:46, 20.56s/epoch, loss=1.2, accuracy=0.734, val_loss=2.28, val_accuracy=0.461, lr=0.1]  8%|▊         | 13/166 [05:02<52:10, 20.46s/epoch, loss=1.19, accuracy=0.74, val_loss=2.11, val_accuracy=0.494, lr=0.0316]  8%|▊         | 14/166 [05:23<52:22, 20.67s/epoch, loss=1.19, accuracy=0.738, val_loss=1.62, val_accuracy=0.608, lr=0.1]    9%|▉         | 15/166 [05:44<52:01, 20.67s/epoch, loss=1.2, accuracy=0.739, val_loss=2.53, val_accuracy=0.37, lr=0.1]   10%|▉         | 16/166 [06:05<51:37, 20.65s/epoch, loss=1.19, accuracy=0.741, val_loss=2.61, val_accuracy=0.379, lr=0.1] 10%|█         | 17/166 [06:26<51:27, 20.72s/epoch, loss=1.19, accuracy=0.744, val_loss=1.75, val_accuracy=0.555, lr=0.1] 11%|█         | 18/166 [06:46<51:07, 20.73s/epoch, loss=1.18, accuracy=0.743, val_loss=1.71, val_accuracy=0.565, lr=0.0316] 11%|█▏        | 19/166 [07:07<50:41, 20.69s/epoch, loss=1.18, accuracy=0.745, val_loss=2.82, val_accuracy=0.431, lr=0.1]    12%|█▏        | 20/166 [07:27<50:12, 20.63s/epoch, loss=1.18, accuracy=0.744, val_loss=1.77, val_accuracy=0.551, lr=0.1] 13%|█▎        | 21/166 [07:48<49:51, 20.63s/epoch, loss=1.17, accuracy=0.747, val_loss=1.35, val_accuracy=0.684, lr=0.1] 13%|█▎        | 22/166 [08:09<49:40, 20.70s/epoch, loss=1.18, accuracy=0.747, val_loss=2.88, val_accuracy=0.349, lr=0.1] 14%|█▍        | 23/166 [08:30<49:18, 20.69s/epoch, loss=1.17, accuracy=0.745, val_loss=3.34, val_accuracy=0.288, lr=0.1] 14%|█▍        | 24/166 [08:50<48:55, 20.68s/epoch, loss=1.17, accuracy=0.749, val_loss=1.88, val_accuracy=0.562, lr=0.1] 15%|█▌        | 25/166 [09:11<48:34, 20.67s/epoch, loss=1.17, accuracy=0.749, val_loss=1.61, val_accuracy=0.582, lr=0.1] 16%|█▌        | 26/166 [09:32<48:14, 20.68s/epoch, loss=1.17, accuracy=0.748, val_loss=1.75, val_accuracy=0.557, lr=0.0316] 16%|█▋        | 27/166 [09:52<47:49, 20.64s/epoch, loss=1.17, accuracy=0.749, val_loss=2.02, val_accuracy=0.475, lr=0.1]    17%|█▋        | 28/166 [10:13<47:26, 20.63s/epoch, loss=1.17, accuracy=0.75, val_loss=1.75, val_accuracy=0.566, lr=0.1]  17%|█▋        | 29/166 [10:33<47:05, 20.63s/epoch, loss=1.16, accuracy=0.752, val_loss=2.41, val_accuracy=0.463, lr=0.1] 18%|█▊        | 30/166 [10:54<46:41, 20.60s/epoch, loss=1.16, accuracy=0.753, val_loss=2.33, val_accuracy=0.33, lr=0.1]  19%|█▊        | 31/166 [11:14<46:20, 20.59s/epoch, loss=1.15, accuracy=0.753, val_loss=2.82, val_accuracy=0.32, lr=0.0316] 19%|█▉        | 32/166 [11:35<46:00, 20.60s/epoch, loss=1.16, accuracy=0.753, val_loss=2.04, val_accuracy=0.501, lr=0.1]   20%|█▉        | 33/166 [11:55<45:32, 20.54s/epoch, loss=1.16, accuracy=0.751, val_loss=1.69, val_accuracy=0.582, lr=0.1] 20%|██        | 34/166 [12:16<45:07, 20.51s/epoch, loss=1.16, accuracy=0.749, val_loss=2.25, val_accuracy=0.459, lr=0.1] 21%|██        | 35/166 [12:36<44:44, 20.49s/epoch, loss=1.15, accuracy=0.75, val_loss=1.55, val_accuracy=0.616, lr=0.1]  22%|██▏       | 36/166 [12:57<44:21, 20.48s/epoch, loss=1.15, accuracy=0.751, val_loss=2.92, val_accuracy=0.271, lr=0.0316] 22%|██▏       | 37/166 [13:17<44:04, 20.50s/epoch, loss=1.16, accuracy=0.751, val_loss=1.41, val_accuracy=0.655, lr=0.1]    23%|██▎       | 38/166 [13:38<43:41, 20.48s/epoch, loss=1.16, accuracy=0.752, val_loss=1.87, val_accuracy=0.522, lr=0.1] 23%|██▎       | 39/166 [13:58<43:20, 20.48s/epoch, loss=1.16, accuracy=0.754, val_loss=2.6, val_accuracy=0.415, lr=0.1]  24%|██▍       | 40/166 [14:19<42:58, 20.46s/epoch, loss=1.16, accuracy=0.752, val_loss=1.75, val_accuracy=0.532, lr=0.1] 25%|██▍       | 41/166 [14:39<42:29, 20.40s/epoch, loss=1.15, accuracy=0.755, val_loss=1.95, val_accuracy=0.486, lr=0.0316] 25%|██▌       | 42/166 [14:59<42:04, 20.36s/epoch, loss=1.15, accuracy=0.754, val_loss=1.95, val_accuracy=0.534, lr=0.1]    26%|██▌       | 43/166 [15:19<41:32, 20.27s/epoch, loss=1.14, accuracy=0.755, val_loss=1.44, val_accuracy=0.657, lr=0.1] 27%|██▋       | 44/166 [15:39<41:07, 20.23s/epoch, loss=1.15, accuracy=0.754, val_loss=1.86, val_accuracy=0.496, lr=0.1] 27%|██▋       | 45/166 [16:00<40:55, 20.30s/epoch, loss=1.16, accuracy=0.754, val_loss=1.53, val_accuracy=0.617, lr=0.1] 28%|██▊       | 46/166 [16:20<40:41, 20.34s/epoch, loss=1.16, accuracy=0.753, val_loss=1.73, val_accuracy=0.555, lr=0.0316] 28%|██▊       | 47/166 [16:41<40:25, 20.38s/epoch, loss=1.15, accuracy=0.751, val_loss=2.49, val_accuracy=0.443, lr=0.1]    29%|██▉       | 48/166 [17:01<40:05, 20.39s/epoch, loss=1.15, accuracy=0.754, val_loss=2.9, val_accuracy=0.267, lr=0.1]  30%|██▉       | 49/166 [17:22<39:50, 20.43s/epoch, loss=1.15, accuracy=0.755, val_loss=1.62, val_accuracy=0.569, lr=0.1] 30%|███       | 50/166 [17:42<39:32, 20.45s/epoch, loss=1.14, accuracy=0.755, val_loss=3.47, val_accuracy=0.346, lr=0.1] 31%|███       | 51/166 [18:03<39:11, 20.44s/epoch, loss=1.15, accuracy=0.755, val_loss=3.32, val_accuracy=0.293, lr=0.0316] 31%|███▏      | 52/166 [18:23<38:52, 20.46s/epoch, loss=1.14, accuracy=0.753, val_loss=2.12, val_accuracy=0.428, lr=0.1]    32%|███▏      | 53/166 [18:44<38:41, 20.55s/epoch, loss=1.15, accuracy=0.753, val_loss=4.21, val_accuracy=0.316, lr=0.1] 33%|███▎      | 54/166 [19:04<38:18, 20.52s/epoch, loss=1.14, accuracy=0.753, val_loss=1.56, val_accuracy=0.611, lr=0.1] 33%|███▎      | 55/166 [19:25<38:01, 20.55s/epoch, loss=1.14, accuracy=0.755, val_loss=1.74, val_accuracy=0.543, lr=0.1] 34%|███▎      | 56/166 [19:45<37:38, 20.53s/epoch, loss=1.14, accuracy=0.755, val_loss=7.42, val_accuracy=0.158, lr=0.0316] 34%|███▍      | 57/166 [20:06<37:19, 20.55s/epoch, loss=1.14, accuracy=0.757, val_loss=2.08, val_accuracy=0.511, lr=0.1]    35%|███▍      | 58/166 [20:26<36:53, 20.49s/epoch, loss=1.13, accuracy=0.76, val_loss=3.99, val_accuracy=0.332, lr=0.1]  36%|███▌      | 59/166 [20:47<36:30, 20.47s/epoch, loss=1.14, accuracy=0.755, val_loss=1.91, val_accuracy=0.502, lr=0.1] 36%|███▌      | 60/166 [21:07<36:09, 20.47s/epoch, loss=1.14, accuracy=0.757, val_loss=1.52, val_accuracy=0.615, lr=0.1] 37%|███▋      | 61/166 [21:27<35:39, 20.38s/epoch, loss=1.14, accuracy=0.757, val_loss=2.99, val_accuracy=0.382, lr=0.0316] 37%|███▋      | 62/166 [21:48<35:19, 20.38s/epoch, loss=1.13, accuracy=0.758, val_loss=2.27, val_accuracy=0.503, lr=0.1]    38%|███▊      | 63/166 [22:08<34:59, 20.39s/epoch, loss=1.14, accuracy=0.753, val_loss=1.56, val_accuracy=0.62, lr=0.1]  39%|███▊      | 64/166 [22:29<34:37, 20.37s/epoch, loss=1.14, accuracy=0.757, val_loss=2.11, val_accuracy=0.48, lr=0.1] 39%|███▉      | 65/166 [22:49<34:14, 20.34s/epoch, loss=1.13, accuracy=0.753, val_loss=1.82, val_accuracy=0.524, lr=0.1] 40%|███▉      | 66/166 [23:09<33:50, 20.30s/epoch, loss=1.13, accuracy=0.759, val_loss=1.76, val_accuracy=0.566, lr=0.0316] 40%|████      | 67/166 [23:29<33:26, 20.26s/epoch, loss=1.13, accuracy=0.757, val_loss=4.69, val_accuracy=0.336, lr=0.1]    41%|████      | 68/166 [23:49<33:04, 20.25s/epoch, loss=1.13, accuracy=0.756, val_loss=2.41, val_accuracy=0.46, lr=0.1]  42%|████▏     | 69/166 [24:10<32:44, 20.26s/epoch, loss=1.13, accuracy=0.756, val_loss=1.63, val_accuracy=0.604, lr=0.1] 42%|████▏     | 70/166 [24:30<32:25, 20.26s/epoch, loss=1.13, accuracy=0.756, val_loss=3.05, val_accuracy=0.388, lr=0.1] 43%|████▎     | 71/166 [24:50<32:03, 20.25s/epoch, loss=1.13, accuracy=0.756, val_loss=2.1, val_accuracy=0.507, lr=0.0316] 43%|████▎     | 72/166 [25:10<31:43, 20.25s/epoch, loss=1.13, accuracy=0.757, val_loss=2.96, val_accuracy=0.422, lr=0.1]   44%|████▍     | 73/166 [25:31<31:22, 20.24s/epoch, loss=1.13, accuracy=0.761, val_loss=1.72, val_accuracy=0.545, lr=0.1] 45%|████▍     | 74/166 [25:51<31:00, 20.22s/epoch, loss=1.12, accuracy=0.757, val_loss=1.76, val_accuracy=0.579, lr=0.1] 45%|████▌     | 75/166 [26:11<30:43, 20.26s/epoch, loss=1.13, accuracy=0.757, val_loss=1.86, val_accuracy=0.552, lr=0.1] 46%|████▌     | 76/166 [26:32<30:25, 20.28s/epoch, loss=1.13, accuracy=0.757, val_loss=1.99, val_accuracy=0.478, lr=0.0316] 46%|████▋     | 77/166 [26:52<30:04, 20.28s/epoch, loss=1.12, accuracy=0.759, val_loss=2.81, val_accuracy=0.384, lr=0.1]    47%|████▋     | 78/166 [27:12<29:44, 20.28s/epoch, loss=1.13, accuracy=0.759, val_loss=3.52, val_accuracy=0.375, lr=0.1] 48%|████▊     | 79/166 [27:32<29:24, 20.28s/epoch, loss=1.13, accuracy=0.758, val_loss=2, val_accuracy=0.486, lr=0.1]    48%|████▊     | 80/166 [27:53<29:13, 20.38s/epoch, loss=1.13, accuracy=0.758, val_loss=1.66, val_accuracy=0.616, lr=0.1] 49%|████▉     | 81/166 [28:14<28:59, 20.47s/epoch, loss=1.12, accuracy=0.758, val_loss=1.54, val_accuracy=0.635, lr=0.0316] 49%|████▉     | 82/166 [28:34<28:40, 20.48s/epoch, loss=0.911, accuracy=0.821, val_loss=0.919, val_accuracy=0.803, lr=0.01] 50%|█████     | 83/166 [28:54<28:11, 20.38s/epoch, loss=0.739, accuracy=0.848, val_loss=0.786, val_accuracy=0.819, lr=0.01] 51%|█████     | 84/166 [29:15<27:47, 20.33s/epoch, loss=0.651, accuracy=0.858, val_loss=0.736, val_accuracy=0.821, lr=0.01] 51%|█████     | 85/166 [29:35<27:26, 20.33s/epoch, loss=0.605, accuracy=0.86, val_loss=0.822, val_accuracy=0.786, lr=0.01]  52%|█████▏    | 86/166 [29:55<27:00, 20.26s/epoch, loss=0.586, accuracy=0.862, val_loss=1.1, val_accuracy=0.688, lr=0.01]  52%|█████▏    | 87/166 [30:15<26:41, 20.27s/epoch, loss=0.571, accuracy=0.863, val_loss=0.773, val_accuracy=0.803, lr=0.01] 53%|█████▎    | 88/166 [30:36<26:21, 20.27s/epoch, loss=0.565, accuracy=0.866, val_loss=1, val_accuracy=0.731, lr=0.01]     54%|█████▎    | 89/166 [30:56<26:01, 20.28s/epoch, loss=0.563, accuracy=0.865, val_loss=0.839, val_accuracy=0.78, lr=0.00316] 54%|█████▍    | 90/166 [31:16<25:45, 20.33s/epoch, loss=0.562, accuracy=0.868, val_loss=0.843, val_accuracy=0.768, lr=0.01]   55%|█████▍    | 91/166 [31:37<25:23, 20.31s/epoch, loss=0.555, accuracy=0.871, val_loss=0.735, val_accuracy=0.811, lr=0.01] 55%|█████▌    | 92/166 [31:57<25:02, 20.30s/epoch, loss=0.554, accuracy=0.871, val_loss=0.973, val_accuracy=0.738, lr=0.01] 56%|█████▌    | 93/166 [32:17<24:43, 20.32s/epoch, loss=0.556, accuracy=0.871, val_loss=1.04, val_accuracy=0.73, lr=0.01]   57%|█████▋    | 94/166 [32:37<24:19, 20.27s/epoch, loss=0.553, accuracy=0.873, val_loss=0.829, val_accuracy=0.787, lr=0.01] 57%|█████▋    | 95/166 [32:58<23:58, 20.27s/epoch, loss=0.554, accuracy=0.874, val_loss=0.771, val_accuracy=0.803, lr=0.01] 58%|█████▊    | 96/166 [33:18<23:40, 20.29s/epoch, loss=0.554, accuracy=0.874, val_loss=0.892, val_accuracy=0.774, lr=0.00316] 58%|█████▊    | 97/166 [33:38<23:17, 20.25s/epoch, loss=0.555, accuracy=0.876, val_loss=0.682, val_accuracy=0.836, lr=0.01]    59%|█████▉    | 98/166 [33:59<23:00, 20.30s/epoch, loss=0.554, accuracy=0.878, val_loss=1.19, val_accuracy=0.694, lr=0.01]  60%|█████▉    | 99/166 [34:19<22:38, 20.28s/epoch, loss=0.551, accuracy=0.877, val_loss=1.12, val_accuracy=0.73, lr=0.01]  60%|██████    | 100/166 [34:39<22:17, 20.27s/epoch, loss=0.549, accuracy=0.881, val_loss=0.87, val_accuracy=0.78, lr=0.01] 61%|██████    | 101/166 [35:00<22:01, 20.33s/epoch, loss=0.552, accuracy=0.88, val_loss=0.77, val_accuracy=0.816, lr=0.01] 61%|██████▏   | 102/166 [35:20<21:39, 20.31s/epoch, loss=0.553, accuracy=0.879, val_loss=0.772, val_accuracy=0.808, lr=0.00316] 62%|██████▏   | 103/166 [35:40<21:20, 20.32s/epoch, loss=0.55, accuracy=0.879, val_loss=0.92, val_accuracy=0.776, lr=0.01]      63%|██████▎   | 104/166 [36:00<20:59, 20.32s/epoch, loss=0.549, accuracy=0.882, val_loss=0.992, val_accuracy=0.744, lr=0.01] 63%|██████▎   | 105/166 [36:21<20:35, 20.26s/epoch, loss=0.552, accuracy=0.881, val_loss=0.799, val_accuracy=0.803, lr=0.01] 64%|██████▍   | 106/166 [36:41<20:16, 20.27s/epoch, loss=0.554, accuracy=0.881, val_loss=1.01, val_accuracy=0.75, lr=0.01]   64%|██████▍   | 107/166 [37:01<19:54, 20.24s/epoch, loss=0.552, accuracy=0.881, val_loss=0.842, val_accuracy=0.793, lr=0.00316] 65%|██████▌   | 108/166 [37:21<19:34, 20.24s/epoch, loss=0.55, accuracy=0.881, val_loss=0.712, val_accuracy=0.832, lr=0.01]     66%|██████▌   | 109/166 [37:41<19:12, 20.21s/epoch, loss=0.543, accuracy=0.885, val_loss=0.882, val_accuracy=0.773, lr=0.01] 66%|██████▋   | 110/166 [38:01<18:49, 20.17s/epoch, loss=0.552, accuracy=0.883, val_loss=0.802, val_accuracy=0.811, lr=0.01] 67%|██████▋   | 111/166 [38:22<18:29, 20.18s/epoch, loss=0.547, accuracy=0.885, val_loss=1.17, val_accuracy=0.714, lr=0.01]  67%|██████▋   | 112/166 [38:42<18:07, 20.15s/epoch, loss=0.553, accuracy=0.883, val_loss=0.8, val_accuracy=0.802, lr=0.00316] 68%|██████▊   | 113/166 [39:02<17:46, 20.12s/epoch, loss=0.55, accuracy=0.885, val_loss=0.961, val_accuracy=0.773, lr=0.01]   69%|██████▊   | 114/166 [39:22<17:24, 20.08s/epoch, loss=0.549, accuracy=0.884, val_loss=0.865, val_accuracy=0.79, lr=0.01] 69%|██████▉   | 115/166 [39:42<17:05, 20.10s/epoch, loss=0.549, accuracy=0.884, val_loss=1.17, val_accuracy=0.72, lr=0.01]  70%|██████▉   | 116/166 [40:02<16:45, 20.11s/epoch, loss=0.551, accuracy=0.884, val_loss=0.946, val_accuracy=0.761, lr=0.01] 70%|███████   | 117/166 [40:22<16:25, 20.11s/epoch, loss=0.552, accuracy=0.886, val_loss=1.14, val_accuracy=0.703, lr=0.00316] 71%|███████   | 118/166 [40:42<16:04, 20.10s/epoch, loss=0.547, accuracy=0.886, val_loss=0.822, val_accuracy=0.796, lr=0.01]   72%|███████▏  | 119/166 [41:02<15:42, 20.05s/epoch, loss=0.551, accuracy=0.886, val_loss=1.09, val_accuracy=0.747, lr=0.01]  72%|███████▏  | 120/166 [41:22<15:23, 20.07s/epoch, loss=0.553, accuracy=0.884, val_loss=1.2, val_accuracy=0.728, lr=0.01]  73%|███████▎  | 121/166 [41:42<15:03, 20.07s/epoch, loss=0.551, accuracy=0.886, val_loss=0.882, val_accuracy=0.788, lr=0.01] 73%|███████▎  | 122/166 [42:02<14:43, 20.07s/epoch, loss=0.475, accuracy=0.912, val_loss=0.548, val_accuracy=0.888, lr=0.001] 74%|███████▍  | 123/166 [42:23<14:24, 20.11s/epoch, loss=0.423, accuracy=0.929, val_loss=0.52, val_accuracy=0.896, lr=0.001]  75%|███████▍  | 124/166 [42:43<14:06, 20.15s/epoch, loss=0.399, accuracy=0.935, val_loss=0.514, val_accuracy=0.897, lr=0.001] 75%|███████▌  | 125/166 [43:03<13:46, 20.15s/epoch, loss=0.383, accuracy=0.938, val_loss=0.509, val_accuracy=0.896, lr=0.001] 76%|███████▌  | 126/166 [43:23<13:26, 20.17s/epoch, loss=0.371, accuracy=0.941, val_loss=0.502, val_accuracy=0.898, lr=0.001] 77%|███████▋  | 127/166 [43:43<13:06, 20.16s/epoch, loss=0.358, accuracy=0.944, val_loss=0.495, val_accuracy=0.899, lr=0.001] 77%|███████▋  | 128/166 [44:04<12:46, 20.17s/epoch, loss=0.347, accuracy=0.945, val_loss=0.497, val_accuracy=0.898, lr=0.001] 78%|███████▊  | 129/166 [44:24<12:24, 20.13s/epoch, loss=0.338, accuracy=0.947, val_loss=0.489, val_accuracy=0.9, lr=0.001]   78%|███████▊  | 130/166 [44:44<12:07, 20.22s/epoch, loss=0.329, accuracy=0.948, val_loss=0.474, val_accuracy=0.901, lr=0.001] 79%|███████▉  | 131/166 [45:04<11:46, 20.20s/epoch, loss=0.317, accuracy=0.95, val_loss=0.474, val_accuracy=0.901, lr=0.001]  80%|███████▉  | 132/166 [45:24<11:27, 20.22s/epoch, loss=0.312, accuracy=0.951, val_loss=0.479, val_accuracy=0.9, lr=0.001]  80%|████████  | 133/166 [45:45<11:08, 20.25s/epoch, loss=0.302, accuracy=0.953, val_loss=0.479, val_accuracy=0.898, lr=0.001] 81%|████████  | 134/166 [46:05<10:52, 20.38s/epoch, loss=0.296, accuracy=0.954, val_loss=0.476, val_accuracy=0.899, lr=0.001] 81%|████████▏ | 135/166 [46:26<10:31, 20.36s/epoch, loss=0.291, accuracy=0.953, val_loss=0.471, val_accuracy=0.895, lr=0.001] 82%|████████▏ | 136/166 [46:46<10:09, 20.33s/epoch, loss=0.283, accuracy=0.955, val_loss=0.471, val_accuracy=0.899, lr=0.001] 83%|████████▎ | 137/166 [47:06<09:48, 20.29s/epoch, loss=0.279, accuracy=0.956, val_loss=0.449, val_accuracy=0.904, lr=0.001] 83%|████████▎ | 138/166 [47:26<09:27, 20.27s/epoch, loss=0.27, accuracy=0.958, val_loss=0.483, val_accuracy=0.896, lr=0.001]  84%|████████▎ | 139/166 [47:47<09:06, 20.23s/epoch, loss=0.267, accuracy=0.958, val_loss=0.455, val_accuracy=0.898, lr=0.001] 84%|████████▍ | 140/166 [48:07<08:46, 20.25s/epoch, loss=0.26, accuracy=0.958, val_loss=0.471, val_accuracy=0.897, lr=0.001]  85%|████████▍ | 141/166 [48:27<08:26, 20.26s/epoch, loss=0.257, accuracy=0.959, val_loss=0.493, val_accuracy=0.886, lr=0.001] 86%|████████▌ | 142/166 [48:47<08:06, 20.26s/epoch, loss=0.254, accuracy=0.958, val_loss=0.49, val_accuracy=0.888, lr=0.000316] 86%|████████▌ | 143/166 [49:08<07:46, 20.30s/epoch, loss=0.247, accuracy=0.961, val_loss=0.468, val_accuracy=0.896, lr=0.001]   87%|████████▋ | 144/166 [49:28<07:26, 20.30s/epoch, loss=0.244, accuracy=0.961, val_loss=0.463, val_accuracy=0.895, lr=0.001] 87%|████████▋ | 145/166 [49:48<07:06, 20.31s/epoch, loss=0.241, accuracy=0.96, val_loss=0.48, val_accuracy=0.889, lr=0.001]   88%|████████▊ | 146/166 [50:09<06:45, 20.30s/epoch, loss=0.238, accuracy=0.961, val_loss=0.461, val_accuracy=0.898, lr=0.001] 89%|████████▊ | 147/166 [50:29<06:26, 20.32s/epoch, loss=0.237, accuracy=0.96, val_loss=0.549, val_accuracy=0.88, lr=0.000316] 89%|████████▉ | 148/166 [50:50<06:06, 20.35s/epoch, loss=0.233, accuracy=0.962, val_loss=0.452, val_accuracy=0.895, lr=0.001]  90%|████████▉ | 149/166 [51:10<05:45, 20.30s/epoch, loss=0.231, accuracy=0.961, val_loss=0.447, val_accuracy=0.893, lr=0.001] 90%|█████████ | 150/166 [51:30<05:25, 20.35s/epoch, loss=0.229, accuracy=0.961, val_loss=0.514, val_accuracy=0.883, lr=0.001] 91%|█████████ | 151/166 [51:51<05:06, 20.44s/epoch, loss=0.228, accuracy=0.962, val_loss=0.498, val_accuracy=0.882, lr=0.001] 92%|█████████▏| 152/166 [52:11<04:45, 20.41s/epoch, loss=0.226, accuracy=0.961, val_loss=0.481, val_accuracy=0.887, lr=0.001] 92%|█████████▏| 153/166 [52:31<04:24, 20.37s/epoch, loss=0.224, accuracy=0.963, val_loss=0.505, val_accuracy=0.884, lr=0.001] 93%|█████████▎| 154/166 [52:52<04:04, 20.35s/epoch, loss=0.219, accuracy=0.963, val_loss=0.488, val_accuracy=0.889, lr=0.000316] 93%|█████████▎| 155/166 [53:12<03:42, 20.26s/epoch, loss=0.22, accuracy=0.962, val_loss=0.535, val_accuracy=0.878, lr=0.001]     94%|█████████▍| 156/166 [53:32<03:22, 20.20s/epoch, loss=0.218, accuracy=0.962, val_loss=0.455, val_accuracy=0.896, lr=0.001] 95%|█████████▍| 157/166 [53:52<03:01, 20.16s/epoch, loss=0.216, accuracy=0.962, val_loss=0.472, val_accuracy=0.891, lr=0.001] 95%|█████████▌| 158/166 [54:12<02:41, 20.14s/epoch, loss=0.215, accuracy=0.962, val_loss=0.511, val_accuracy=0.881, lr=0.001] 96%|█████████▌| 159/166 [54:32<02:21, 20.16s/epoch, loss=0.217, accuracy=0.962, val_loss=0.447, val_accuracy=0.894, lr=0.000316] 96%|█████████▋| 160/166 [54:52<02:00, 20.14s/epoch, loss=0.216, accuracy=0.961, val_loss=0.472, val_accuracy=0.89, lr=0.001]     97%|█████████▋| 161/166 [55:12<01:40, 20.11s/epoch, loss=0.211, accuracy=0.963, val_loss=0.51, val_accuracy=0.874, lr=0.001] 98%|█████████▊| 162/166 [55:33<01:20, 20.15s/epoch, loss=0.195, accuracy=0.969, val_loss=0.424, val_accuracy=0.902, lr=1e-04] 98%|█████████▊| 163/166 [55:53<01:00, 20.23s/epoch, loss=0.179, accuracy=0.975, val_loss=0.417, val_accuracy=0.903, lr=1e-04] 99%|█████████▉| 164/166 [56:13<00:40, 20.20s/epoch, loss=0.176, accuracy=0.976, val_loss=0.415, val_accuracy=0.905, lr=1e-04] 99%|█████████▉| 165/166 [56:33<00:20, 20.17s/epoch, loss=0.171, accuracy=0.978, val_loss=0.414, val_accuracy=0.907, lr=1e-04]100%|██████████| 166/166 [56:53<00:00, 20.17s/epoch, loss=0.167, accuracy=0.98, val_loss=0.42, val_accuracy=0.904, lr=1e-04]  100%|██████████| 166/166 [56:53<00:00, 20.57s/epoch, loss=0.167, accuracy=0.98, val_loss=0.42, val_accuracy=0.904, lr=1e-04]
Using real-time data augmentation.
Test score: 0.41988736391067505
Test accuracy: 0.9036999940872192


* * * Run SGD for ID = 9_4. * * *


2024-03-05 03:49:15.528478: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 03:49:18.031778: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 03:49:18.032968: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-05 03:49:18.073442: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-03-05 03:49:18.073488: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 03:49:18.076386: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 03:49:18.076426: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 03:49:18.078463: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 03:49:18.079109: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 03:49:18.081329: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 03:49:18.082702: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 03:49:18.087308: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 03:49:18.087918: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 03:49:18.088019: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 03:49:19.304066: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-05 03:49:19.304654: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 03:49:19.305427: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-03-05 03:49:19.305457: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 03:49:19.305493: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 03:49:19.305510: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 03:49:19.305529: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 03:49:19.305546: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 03:49:19.305561: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 03:49:19.305576: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 03:49:19.305592: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 03:49:19.306030: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 03:49:19.306067: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 03:49:19.944714: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-05 03:49:19.944771: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-05 03:49:19.944780: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-05 03:49:19.945704: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:02:00.0, compute capability: 6.1)
{'id': '09_04', 'seed': 4, 'out_folder': 'results/epoch_budget', 'batch_size': 128, 'epochs': 166, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'bootstrapping': False, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/166 [00:00<?, ?epoch/s]2024-03-05 03:49:20.805607: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-05 03:49:20.806162: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600020000 Hz
2024-03-05 03:49:22.800617: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 03:49:23.013844: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 03:49:24.030518: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-05 03:49:24.094939: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/166 [01:08<3:09:11, 68.80s/epoch, loss=3.06, accuracy=0.351, val_loss=2.71, val_accuracy=0.277, lr=0.1]  1%|          | 2/166 [01:28<1:49:29, 40.06s/epoch, loss=1.56, accuracy=0.534, val_loss=2.44, val_accuracy=0.363, lr=0.1]  2%|▏         | 3/166 [01:48<1:23:31, 30.75s/epoch, loss=1.37, accuracy=0.62, val_loss=2.99, val_accuracy=0.315, lr=0.1]   2%|▏         | 4/166 [02:08<1:11:25, 26.45s/epoch, loss=1.28, accuracy=0.671, val_loss=3.93, val_accuracy=0.264, lr=0.1]  3%|▎         | 5/166 [02:28<1:04:30, 24.04s/epoch, loss=1.24, accuracy=0.694, val_loss=1.77, val_accuracy=0.516, lr=0.1]  4%|▎         | 6/166 [02:48<1:00:34, 22.72s/epoch, loss=1.22, accuracy=0.71, val_loss=1.87, val_accuracy=0.501, lr=0.1]   4%|▍         | 7/166 [03:08<57:46, 21.80s/epoch, loss=1.22, accuracy=0.718, val_loss=2.34, val_accuracy=0.455, lr=0.1]   5%|▍         | 8/166 [03:28<56:02, 21.28s/epoch, loss=1.21, accuracy=0.724, val_loss=1.78, val_accuracy=0.543, lr=0.1]  5%|▌         | 9/166 [03:48<54:50, 20.96s/epoch, loss=1.2, accuracy=0.73, val_loss=1.96, val_accuracy=0.542, lr=0.1]    6%|▌         | 10/166 [04:08<53:33, 20.60s/epoch, loss=1.2, accuracy=0.733, val_loss=2.43, val_accuracy=0.373, lr=0.0316]  7%|▋         | 11/166 [04:27<52:24, 20.28s/epoch, loss=1.19, accuracy=0.734, val_loss=1.39, val_accuracy=0.672, lr=0.1]    7%|▋         | 12/166 [04:48<52:17, 20.37s/epoch, loss=1.19, accuracy=0.735, val_loss=1.88, val_accuracy=0.564, lr=0.1]  8%|▊         | 13/166 [05:08<51:58, 20.38s/epoch, loss=1.18, accuracy=0.74, val_loss=2.09, val_accuracy=0.465, lr=0.1]   8%|▊         | 14/166 [05:29<51:32, 20.34s/epoch, loss=1.19, accuracy=0.74, val_loss=1.65, val_accuracy=0.593, lr=0.1]  9%|▉         | 15/166 [05:49<51:00, 20.27s/epoch, loss=1.18, accuracy=0.741, val_loss=1.47, val_accuracy=0.654, lr=0.1] 10%|▉         | 16/166 [06:09<50:36, 20.24s/epoch, loss=1.18, accuracy=0.745, val_loss=2, val_accuracy=0.54, lr=0.0316]  10%|█         | 17/166 [06:29<50:09, 20.19s/epoch, loss=1.18, accuracy=0.743, val_loss=1.88, val_accuracy=0.534, lr=0.1] 11%|█         | 18/166 [06:49<49:45, 20.17s/epoch, loss=1.18, accuracy=0.746, val_loss=2.48, val_accuracy=0.469, lr=0.1] 11%|█▏        | 19/166 [07:09<49:25, 20.17s/epoch, loss=1.18, accuracy=0.745, val_loss=2.06, val_accuracy=0.456, lr=0.1] 12%|█▏        | 20/166 [07:29<49:04, 20.16s/epoch, loss=1.17, accuracy=0.745, val_loss=1.49, val_accuracy=0.642, lr=0.1] 13%|█▎        | 21/166 [07:50<48:49, 20.20s/epoch, loss=1.17, accuracy=0.749, val_loss=3.98, val_accuracy=0.353, lr=0.0316] 13%|█▎        | 22/166 [08:10<48:37, 20.26s/epoch, loss=1.17, accuracy=0.745, val_loss=1.69, val_accuracy=0.582, lr=0.1]    14%|█▍        | 23/166 [08:30<48:18, 20.27s/epoch, loss=1.17, accuracy=0.747, val_loss=2.55, val_accuracy=0.427, lr=0.1] 14%|█▍        | 24/166 [08:51<47:57, 20.26s/epoch, loss=1.17, accuracy=0.748, val_loss=2.27, val_accuracy=0.445, lr=0.1] 15%|█▌        | 25/166 [09:11<47:49, 20.35s/epoch, loss=1.17, accuracy=0.749, val_loss=1.92, val_accuracy=0.553, lr=0.1] 16%|█▌        | 26/166 [09:31<47:18, 20.28s/epoch, loss=1.17, accuracy=0.75, val_loss=2.13, val_accuracy=0.509, lr=0.0316] 16%|█▋        | 27/166 [09:52<46:55, 20.26s/epoch, loss=1.17, accuracy=0.749, val_loss=1.75, val_accuracy=0.527, lr=0.1]   17%|█▋        | 28/166 [10:12<46:46, 20.34s/epoch, loss=1.16, accuracy=0.75, val_loss=2.97, val_accuracy=0.41, lr=0.1]   17%|█▋        | 29/166 [10:32<46:24, 20.33s/epoch, loss=1.17, accuracy=0.75, val_loss=1.86, val_accuracy=0.524, lr=0.1] 18%|█▊        | 30/166 [10:53<46:03, 20.32s/epoch, loss=1.15, accuracy=0.753, val_loss=5.18, val_accuracy=0.276, lr=0.1] 19%|█▊        | 31/166 [11:13<45:53, 20.40s/epoch, loss=1.17, accuracy=0.751, val_loss=2.73, val_accuracy=0.447, lr=0.0316] 19%|█▉        | 32/166 [11:34<45:32, 20.39s/epoch, loss=1.16, accuracy=0.75, val_loss=1.74, val_accuracy=0.527, lr=0.1]     20%|█▉        | 33/166 [11:54<45:06, 20.35s/epoch, loss=1.15, accuracy=0.751, val_loss=1.75, val_accuracy=0.548, lr=0.1] 20%|██        | 34/166 [12:14<44:49, 20.38s/epoch, loss=1.15, accuracy=0.753, val_loss=3.06, val_accuracy=0.373, lr=0.1] 21%|██        | 35/166 [12:34<44:21, 20.32s/epoch, loss=1.15, accuracy=0.753, val_loss=2.1, val_accuracy=0.486, lr=0.1]  22%|██▏       | 36/166 [12:55<43:59, 20.31s/epoch, loss=1.16, accuracy=0.752, val_loss=2.79, val_accuracy=0.399, lr=0.0316] 22%|██▏       | 37/166 [13:15<43:42, 20.33s/epoch, loss=1.15, accuracy=0.754, val_loss=1.62, val_accuracy=0.612, lr=0.1]    23%|██▎       | 38/166 [13:36<43:24, 20.35s/epoch, loss=1.15, accuracy=0.754, val_loss=1.39, val_accuracy=0.664, lr=0.1] 23%|██▎       | 39/166 [13:56<42:58, 20.30s/epoch, loss=1.15, accuracy=0.754, val_loss=2.53, val_accuracy=0.434, lr=0.1] 24%|██▍       | 40/166 [14:16<42:36, 20.29s/epoch, loss=1.15, accuracy=0.754, val_loss=1.95, val_accuracy=0.532, lr=0.1] 25%|██▍       | 41/166 [14:36<42:14, 20.28s/epoch, loss=1.15, accuracy=0.753, val_loss=2.32, val_accuracy=0.339, lr=0.0316] 25%|██▌       | 42/166 [14:57<41:55, 20.29s/epoch, loss=1.15, accuracy=0.754, val_loss=1.97, val_accuracy=0.55, lr=0.1]     26%|██▌       | 43/166 [15:17<41:30, 20.24s/epoch, loss=1.15, accuracy=0.755, val_loss=1.85, val_accuracy=0.524, lr=0.1] 27%|██▋       | 44/166 [15:37<41:07, 20.23s/epoch, loss=1.15, accuracy=0.753, val_loss=1.99, val_accuracy=0.52, lr=0.1]  27%|██▋       | 45/166 [15:57<40:45, 20.21s/epoch, loss=1.15, accuracy=0.752, val_loss=1.53, val_accuracy=0.626, lr=0.1] 28%|██▊       | 46/166 [16:17<40:24, 20.21s/epoch, loss=1.14, accuracy=0.755, val_loss=2.28, val_accuracy=0.475, lr=0.0316] 28%|██▊       | 47/166 [16:37<40:03, 20.20s/epoch, loss=1.14, accuracy=0.754, val_loss=2.56, val_accuracy=0.51, lr=0.1]     29%|██▉       | 48/166 [16:57<39:38, 20.16s/epoch, loss=1.14, accuracy=0.756, val_loss=1.57, val_accuracy=0.63, lr=0.1] 30%|██▉       | 49/166 [17:18<39:17, 20.15s/epoch, loss=1.14, accuracy=0.755, val_loss=1.96, val_accuracy=0.449, lr=0.1] 30%|███       | 50/166 [17:38<38:58, 20.16s/epoch, loss=1.14, accuracy=0.756, val_loss=2.03, val_accuracy=0.541, lr=0.1] 31%|███       | 51/166 [17:58<38:38, 20.16s/epoch, loss=1.14, accuracy=0.756, val_loss=2.1, val_accuracy=0.478, lr=0.0316] 31%|███▏      | 52/166 [18:18<38:17, 20.15s/epoch, loss=1.13, accuracy=0.758, val_loss=2.41, val_accuracy=0.443, lr=0.1]   32%|███▏      | 53/166 [18:38<37:50, 20.09s/epoch, loss=1.14, accuracy=0.756, val_loss=2.57, val_accuracy=0.417, lr=0.1] 33%|███▎      | 54/166 [18:58<37:33, 20.12s/epoch, loss=1.14, accuracy=0.757, val_loss=1.35, val_accuracy=0.689, lr=0.1] 33%|███▎      | 55/166 [19:18<37:13, 20.12s/epoch, loss=1.13, accuracy=0.76, val_loss=2.52, val_accuracy=0.407, lr=0.1]  34%|███▎      | 56/166 [19:39<36:54, 20.13s/epoch, loss=1.14, accuracy=0.758, val_loss=2.38, val_accuracy=0.484, lr=0.1] 34%|███▍      | 57/166 [19:59<36:32, 20.11s/epoch, loss=1.14, accuracy=0.755, val_loss=3.7, val_accuracy=0.321, lr=0.1]  35%|███▍      | 58/166 [20:19<36:11, 20.10s/epoch, loss=1.13, accuracy=0.757, val_loss=2.33, val_accuracy=0.411, lr=0.1] 36%|███▌      | 59/166 [20:39<35:55, 20.15s/epoch, loss=1.13, accuracy=0.756, val_loss=1.62, val_accuracy=0.607, lr=0.0316] 36%|███▌      | 60/166 [20:59<35:37, 20.16s/epoch, loss=1.13, accuracy=0.757, val_loss=2.86, val_accuracy=0.367, lr=0.1]    37%|███▋      | 61/166 [21:19<35:13, 20.13s/epoch, loss=1.13, accuracy=0.757, val_loss=1.9, val_accuracy=0.478, lr=0.1]  37%|███▋      | 62/166 [21:39<34:49, 20.09s/epoch, loss=1.13, accuracy=0.756, val_loss=3.43, val_accuracy=0.354, lr=0.1] 38%|███▊      | 63/166 [21:59<34:25, 20.06s/epoch, loss=1.14, accuracy=0.754, val_loss=1.74, val_accuracy=0.546, lr=0.1] 39%|███▊      | 64/166 [22:19<34:10, 20.11s/epoch, loss=1.13, accuracy=0.757, val_loss=4.3, val_accuracy=0.35, lr=0.0316] 39%|███▉      | 65/166 [22:39<33:47, 20.08s/epoch, loss=1.13, accuracy=0.757, val_loss=2.39, val_accuracy=0.442, lr=0.1]  40%|███▉      | 66/166 [23:00<33:32, 20.13s/epoch, loss=1.13, accuracy=0.757, val_loss=1.8, val_accuracy=0.565, lr=0.1]  40%|████      | 67/166 [23:20<33:09, 20.09s/epoch, loss=1.13, accuracy=0.755, val_loss=2.85, val_accuracy=0.384, lr=0.1] 41%|████      | 68/166 [23:40<32:44, 20.04s/epoch, loss=1.13, accuracy=0.757, val_loss=3.78, val_accuracy=0.28, lr=0.1]  42%|████▏     | 69/166 [23:59<32:14, 19.94s/epoch, loss=1.12, accuracy=0.757, val_loss=2.32, val_accuracy=0.447, lr=0.0316] 42%|████▏     | 70/166 [24:19<31:56, 19.96s/epoch, loss=1.12, accuracy=0.759, val_loss=2.07, val_accuracy=0.508, lr=0.1]    43%|████▎     | 71/166 [24:39<31:34, 19.94s/epoch, loss=1.13, accuracy=0.759, val_loss=3.12, val_accuracy=0.371, lr=0.1] 43%|████▎     | 72/166 [24:59<31:10, 19.90s/epoch, loss=1.13, accuracy=0.757, val_loss=1.84, val_accuracy=0.524, lr=0.1] 44%|████▍     | 73/166 [25:19<30:54, 19.94s/epoch, loss=1.13, accuracy=0.755, val_loss=1.79, val_accuracy=0.562, lr=0.1] 45%|████▍     | 74/166 [25:39<30:39, 19.99s/epoch, loss=1.12, accuracy=0.758, val_loss=2.03, val_accuracy=0.492, lr=0.0316] 45%|████▌     | 75/166 [25:59<30:18, 19.99s/epoch, loss=1.12, accuracy=0.756, val_loss=1.58, val_accuracy=0.586, lr=0.1]    46%|████▌     | 76/166 [26:19<30:02, 20.02s/epoch, loss=1.12, accuracy=0.758, val_loss=1.55, val_accuracy=0.613, lr=0.1] 46%|████▋     | 77/166 [26:39<29:44, 20.05s/epoch, loss=1.12, accuracy=0.758, val_loss=3.9, val_accuracy=0.411, lr=0.1]  47%|████▋     | 78/166 [26:59<29:26, 20.08s/epoch, loss=1.12, accuracy=0.76, val_loss=3.07, val_accuracy=0.315, lr=0.1] 48%|████▊     | 79/166 [27:19<29:04, 20.05s/epoch, loss=1.12, accuracy=0.758, val_loss=2.54, val_accuracy=0.353, lr=0.0316] 48%|████▊     | 80/166 [27:40<28:47, 20.09s/epoch, loss=1.12, accuracy=0.76, val_loss=2.44, val_accuracy=0.468, lr=0.1]     49%|████▉     | 81/166 [28:00<28:30, 20.12s/epoch, loss=1.12, accuracy=0.76, val_loss=1.9, val_accuracy=0.543, lr=0.1]  49%|████▉     | 82/166 [28:20<28:14, 20.17s/epoch, loss=0.898, accuracy=0.822, val_loss=0.868, val_accuracy=0.811, lr=0.01] 50%|█████     | 83/166 [28:40<27:53, 20.16s/epoch, loss=0.722, accuracy=0.85, val_loss=0.803, val_accuracy=0.814, lr=0.01]  51%|█████     | 84/166 [29:00<27:31, 20.14s/epoch, loss=0.64, accuracy=0.859, val_loss=0.943, val_accuracy=0.752, lr=0.01] 51%|█████     | 85/166 [29:20<27:09, 20.12s/epoch, loss=0.601, accuracy=0.861, val_loss=0.802, val_accuracy=0.791, lr=0.01] 52%|█████▏    | 86/166 [29:40<26:46, 20.08s/epoch, loss=0.58, accuracy=0.861, val_loss=1.05, val_accuracy=0.722, lr=0.01]   52%|█████▏    | 87/166 [30:01<26:27, 20.10s/epoch, loss=0.569, accuracy=0.863, val_loss=0.671, val_accuracy=0.83, lr=0.01] 53%|█████▎    | 88/166 [30:21<26:09, 20.13s/epoch, loss=0.563, accuracy=0.865, val_loss=0.739, val_accuracy=0.811, lr=0.01] 54%|█████▎    | 89/166 [30:41<25:50, 20.13s/epoch, loss=0.561, accuracy=0.865, val_loss=0.705, val_accuracy=0.821, lr=0.01] 54%|█████▍    | 90/166 [31:01<25:30, 20.14s/epoch, loss=0.557, accuracy=0.869, val_loss=1.04, val_accuracy=0.715, lr=0.01]  55%|█████▍    | 91/166 [31:21<25:05, 20.07s/epoch, loss=0.555, accuracy=0.871, val_loss=1.39, val_accuracy=0.674, lr=0.01] 55%|█████▌    | 92/166 [31:41<24:40, 20.01s/epoch, loss=0.553, accuracy=0.872, val_loss=0.91, val_accuracy=0.75, lr=0.00316] 56%|█████▌    | 93/166 [32:01<24:16, 19.96s/epoch, loss=0.554, accuracy=0.872, val_loss=0.831, val_accuracy=0.785, lr=0.01]  57%|█████▋    | 94/166 [32:21<24:02, 20.03s/epoch, loss=0.549, accuracy=0.874, val_loss=0.737, val_accuracy=0.816, lr=0.01] 57%|█████▋    | 95/166 [32:41<23:42, 20.03s/epoch, loss=0.553, accuracy=0.875, val_loss=0.745, val_accuracy=0.817, lr=0.01] 58%|█████▊    | 96/166 [33:01<23:21, 20.01s/epoch, loss=0.551, accuracy=0.878, val_loss=0.752, val_accuracy=0.81, lr=0.01]  58%|█████▊    | 97/166 [33:21<22:59, 19.99s/epoch, loss=0.554, accuracy=0.875, val_loss=1.19, val_accuracy=0.689, lr=0.00316] 59%|█████▉    | 98/166 [33:41<22:42, 20.03s/epoch, loss=0.552, accuracy=0.877, val_loss=0.823, val_accuracy=0.791, lr=0.01]   60%|█████▉    | 99/166 [34:01<22:24, 20.06s/epoch, loss=0.554, accuracy=0.876, val_loss=0.749, val_accuracy=0.804, lr=0.01] 60%|██████    | 100/166 [34:21<22:08, 20.12s/epoch, loss=0.554, accuracy=0.877, val_loss=0.707, val_accuracy=0.83, lr=0.01] 61%|██████    | 101/166 [34:41<21:47, 20.12s/epoch, loss=0.552, accuracy=0.879, val_loss=1.11, val_accuracy=0.726, lr=0.01] 61%|██████▏   | 102/166 [35:02<21:28, 20.13s/epoch, loss=0.553, accuracy=0.879, val_loss=1.26, val_accuracy=0.658, lr=0.00316] 62%|██████▏   | 103/166 [35:22<21:06, 20.10s/epoch, loss=0.548, accuracy=0.881, val_loss=0.865, val_accuracy=0.78, lr=0.01]    63%|██████▎   | 104/166 [35:42<20:45, 20.10s/epoch, loss=0.543, accuracy=0.883, val_loss=0.839, val_accuracy=0.793, lr=0.01] 63%|██████▎   | 105/166 [36:02<20:23, 20.05s/epoch, loss=0.546, accuracy=0.882, val_loss=0.746, val_accuracy=0.812, lr=0.01] 64%|██████▍   | 106/166 [36:22<20:05, 20.08s/epoch, loss=0.549, accuracy=0.882, val_loss=0.894, val_accuracy=0.774, lr=0.01] 64%|██████▍   | 107/166 [36:42<19:43, 20.05s/epoch, loss=0.547, accuracy=0.883, val_loss=0.891, val_accuracy=0.786, lr=0.00316] 65%|██████▌   | 108/166 [37:01<19:16, 19.94s/epoch, loss=0.548, accuracy=0.883, val_loss=0.919, val_accuracy=0.778, lr=0.01]    66%|██████▌   | 109/166 [37:21<18:58, 19.97s/epoch, loss=0.551, accuracy=0.881, val_loss=0.876, val_accuracy=0.793, lr=0.01] 66%|██████▋   | 110/166 [37:41<18:38, 19.98s/epoch, loss=0.551, accuracy=0.884, val_loss=0.774, val_accuracy=0.812, lr=0.01] 67%|██████▋   | 111/166 [38:01<18:17, 19.95s/epoch, loss=0.546, accuracy=0.884, val_loss=0.821, val_accuracy=0.804, lr=0.01] 67%|██████▋   | 112/166 [38:21<17:58, 19.97s/epoch, loss=0.547, accuracy=0.884, val_loss=0.744, val_accuracy=0.818, lr=0.00316] 68%|██████▊   | 113/166 [38:41<17:37, 19.96s/epoch, loss=0.544, accuracy=0.886, val_loss=0.882, val_accuracy=0.778, lr=0.01]    69%|██████▊   | 114/166 [39:01<17:18, 19.97s/epoch, loss=0.547, accuracy=0.885, val_loss=1.04, val_accuracy=0.748, lr=0.01]  69%|██████▉   | 115/166 [39:21<16:56, 19.94s/epoch, loss=0.545, accuracy=0.884, val_loss=1.23, val_accuracy=0.674, lr=0.01] 70%|██████▉   | 116/166 [39:41<16:36, 19.92s/epoch, loss=0.546, accuracy=0.885, val_loss=0.785, val_accuracy=0.798, lr=0.01] 70%|███████   | 117/166 [40:01<16:17, 19.94s/epoch, loss=0.549, accuracy=0.884, val_loss=0.885, val_accuracy=0.776, lr=0.00316] 71%|███████   | 118/166 [40:21<15:59, 19.98s/epoch, loss=0.548, accuracy=0.886, val_loss=0.894, val_accuracy=0.78, lr=0.01]     72%|███████▏  | 119/166 [40:41<15:37, 19.95s/epoch, loss=0.551, accuracy=0.884, val_loss=0.988, val_accuracy=0.765, lr=0.01] 72%|███████▏  | 120/166 [41:01<15:16, 19.92s/epoch, loss=0.545, accuracy=0.887, val_loss=0.758, val_accuracy=0.818, lr=0.01] 73%|███████▎  | 121/166 [41:21<14:56, 19.92s/epoch, loss=0.544, accuracy=0.888, val_loss=1.03, val_accuracy=0.746, lr=0.01]  73%|███████▎  | 122/166 [41:41<14:36, 19.92s/epoch, loss=0.472, accuracy=0.913, val_loss=0.533, val_accuracy=0.892, lr=0.001] 74%|███████▍  | 123/166 [42:01<14:15, 19.89s/epoch, loss=0.416, accuracy=0.931, val_loss=0.511, val_accuracy=0.898, lr=0.001] 75%|███████▍  | 124/166 [42:20<13:56, 19.91s/epoch, loss=0.4, accuracy=0.935, val_loss=0.501, val_accuracy=0.899, lr=0.001]   75%|███████▌  | 125/166 [42:40<13:36, 19.92s/epoch, loss=0.38, accuracy=0.94, val_loss=0.497, val_accuracy=0.901, lr=0.001] 76%|███████▌  | 126/166 [43:00<13:15, 19.88s/epoch, loss=0.368, accuracy=0.942, val_loss=0.484, val_accuracy=0.903, lr=0.001] 77%|███████▋  | 127/166 [43:20<12:56, 19.90s/epoch, loss=0.355, accuracy=0.944, val_loss=0.484, val_accuracy=0.903, lr=0.001] 77%|███████▋  | 128/166 [43:40<12:37, 19.93s/epoch, loss=0.345, accuracy=0.945, val_loss=0.477, val_accuracy=0.901, lr=0.001] 78%|███████▊  | 129/166 [44:00<12:16, 19.90s/epoch, loss=0.335, accuracy=0.947, val_loss=0.473, val_accuracy=0.905, lr=0.001] 78%|███████▊  | 130/166 [44:20<11:54, 19.85s/epoch, loss=0.327, accuracy=0.948, val_loss=0.471, val_accuracy=0.899, lr=0.001] 79%|███████▉  | 131/166 [44:40<11:35, 19.88s/epoch, loss=0.318, accuracy=0.951, val_loss=0.468, val_accuracy=0.902, lr=0.001] 80%|███████▉  | 132/166 [44:59<11:14, 19.85s/epoch, loss=0.31, accuracy=0.951, val_loss=0.47, val_accuracy=0.901, lr=0.001]   80%|████████  | 133/166 [45:19<10:56, 19.89s/epoch, loss=0.301, accuracy=0.953, val_loss=0.464, val_accuracy=0.9, lr=0.001] 81%|████████  | 134/166 [45:39<10:37, 19.92s/epoch, loss=0.295, accuracy=0.954, val_loss=0.457, val_accuracy=0.899, lr=0.001] 81%|████████▏ | 135/166 [46:00<10:21, 20.03s/epoch, loss=0.29, accuracy=0.953, val_loss=0.462, val_accuracy=0.901, lr=0.001]  82%|████████▏ | 136/166 [46:20<10:01, 20.05s/epoch, loss=0.28, accuracy=0.956, val_loss=0.456, val_accuracy=0.901, lr=0.001] 83%|████████▎ | 137/166 [46:40<09:41, 20.04s/epoch, loss=0.274, accuracy=0.957, val_loss=0.469, val_accuracy=0.896, lr=0.001] 83%|████████▎ | 138/166 [47:00<09:20, 20.02s/epoch, loss=0.269, accuracy=0.957, val_loss=0.472, val_accuracy=0.894, lr=0.001] 84%|████████▎ | 139/166 [47:20<09:00, 20.00s/epoch, loss=0.263, accuracy=0.959, val_loss=0.464, val_accuracy=0.896, lr=0.001] 84%|████████▍ | 140/166 [47:40<08:39, 20.00s/epoch, loss=0.26, accuracy=0.958, val_loss=0.464, val_accuracy=0.892, lr=0.001]  85%|████████▍ | 141/166 [48:00<08:20, 20.02s/epoch, loss=0.254, accuracy=0.959, val_loss=0.489, val_accuracy=0.887, lr=0.000316] 86%|████████▌ | 142/166 [48:20<08:00, 20.02s/epoch, loss=0.25, accuracy=0.959, val_loss=0.459, val_accuracy=0.895, lr=0.001]     86%|████████▌ | 143/166 [48:40<07:41, 20.06s/epoch, loss=0.248, accuracy=0.961, val_loss=0.468, val_accuracy=0.897, lr=0.001] 87%|████████▋ | 144/166 [49:00<07:21, 20.06s/epoch, loss=0.242, accuracy=0.961, val_loss=0.458, val_accuracy=0.896, lr=0.001] 87%|████████▋ | 145/166 [49:20<07:00, 20.02s/epoch, loss=0.24, accuracy=0.961, val_loss=0.46, val_accuracy=0.894, lr=0.001]   88%|████████▊ | 146/166 [49:40<06:40, 20.04s/epoch, loss=0.238, accuracy=0.96, val_loss=0.446, val_accuracy=0.899, lr=0.001] 89%|████████▊ | 147/166 [50:00<06:20, 20.04s/epoch, loss=0.237, accuracy=0.96, val_loss=0.47, val_accuracy=0.893, lr=0.001]  89%|████████▉ | 148/166 [50:20<06:02, 20.13s/epoch, loss=0.23, accuracy=0.962, val_loss=0.473, val_accuracy=0.89, lr=0.001] 90%|████████▉ | 149/166 [50:41<05:43, 20.19s/epoch, loss=0.228, accuracy=0.962, val_loss=0.479, val_accuracy=0.888, lr=0.001] 90%|█████████ | 150/166 [51:01<05:22, 20.19s/epoch, loss=0.225, accuracy=0.961, val_loss=0.486, val_accuracy=0.885, lr=0.001] 91%|█████████ | 151/166 [51:21<05:03, 20.20s/epoch, loss=0.225, accuracy=0.962, val_loss=0.469, val_accuracy=0.893, lr=0.000316] 92%|█████████▏| 152/166 [51:41<04:42, 20.18s/epoch, loss=0.221, accuracy=0.963, val_loss=0.469, val_accuracy=0.896, lr=0.001]    92%|█████████▏| 153/166 [52:01<04:22, 20.16s/epoch, loss=0.221, accuracy=0.962, val_loss=0.447, val_accuracy=0.894, lr=0.001] 93%|█████████▎| 154/166 [52:22<04:01, 20.15s/epoch, loss=0.218, accuracy=0.963, val_loss=0.45, val_accuracy=0.892, lr=0.001]  93%|█████████▎| 155/166 [52:42<03:41, 20.10s/epoch, loss=0.219, accuracy=0.961, val_loss=0.464, val_accuracy=0.891, lr=0.001] 94%|█████████▍| 156/166 [53:02<03:21, 20.13s/epoch, loss=0.217, accuracy=0.961, val_loss=0.485, val_accuracy=0.888, lr=0.000316] 95%|█████████▍| 157/166 [53:22<03:01, 20.15s/epoch, loss=0.214, accuracy=0.963, val_loss=0.508, val_accuracy=0.883, lr=0.001]    95%|█████████▌| 158/166 [53:42<02:41, 20.14s/epoch, loss=0.214, accuracy=0.962, val_loss=0.535, val_accuracy=0.875, lr=0.001] 96%|█████████▌| 159/166 [54:02<02:20, 20.08s/epoch, loss=0.213, accuracy=0.962, val_loss=0.462, val_accuracy=0.889, lr=0.001] 96%|█████████▋| 160/166 [54:22<02:00, 20.13s/epoch, loss=0.214, accuracy=0.962, val_loss=0.475, val_accuracy=0.885, lr=0.001] 97%|█████████▋| 161/166 [54:42<01:40, 20.09s/epoch, loss=0.211, accuracy=0.962, val_loss=0.481, val_accuracy=0.891, lr=0.000316] 98%|█████████▊| 162/166 [55:02<01:20, 20.09s/epoch, loss=0.193, accuracy=0.97, val_loss=0.413, val_accuracy=0.905, lr=1e-04]     98%|█████████▊| 163/166 [55:22<01:00, 20.06s/epoch, loss=0.178, accuracy=0.976, val_loss=0.404, val_accuracy=0.907, lr=1e-04] 99%|█████████▉| 164/166 [55:42<00:39, 19.99s/epoch, loss=0.17, accuracy=0.978, val_loss=0.407, val_accuracy=0.907, lr=1e-04]  99%|█████████▉| 165/166 [56:02<00:19, 19.98s/epoch, loss=0.168, accuracy=0.98, val_loss=0.405, val_accuracy=0.908, lr=1e-04]100%|██████████| 166/166 [56:22<00:00, 19.99s/epoch, loss=0.167, accuracy=0.979, val_loss=0.404, val_accuracy=0.908, lr=1e-04]100%|██████████| 166/166 [56:22<00:00, 20.38s/epoch, loss=0.167, accuracy=0.979, val_loss=0.404, val_accuracy=0.908, lr=1e-04]
Using real-time data augmentation.
Test score: 0.4036554992198944
Test accuracy: 0.9075000286102295


* * * Run SGD for ID = 9_5. * * *


2024-03-05 04:45:47.310977: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 04:45:51.169512: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 04:45:51.170691: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-05 04:45:51.207207: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-03-05 04:45:51.207254: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 04:45:51.210149: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 04:45:51.210187: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 04:45:51.212288: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 04:45:51.212895: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 04:45:51.215155: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 04:45:51.216506: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 04:45:51.221194: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 04:45:51.221819: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 04:45:51.221901: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 04:45:52.435461: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-05 04:45:52.436579: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 04:45:52.437401: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-03-05 04:45:52.437433: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 04:45:52.437472: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 04:45:52.437488: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 04:45:52.437504: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 04:45:52.437521: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 04:45:52.437546: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 04:45:52.437562: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 04:45:52.437578: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 04:45:52.438031: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 04:45:52.438063: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 04:45:53.120390: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-05 04:45:53.120440: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-05 04:45:53.120449: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-05 04:45:53.121433: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:02:00.0, compute capability: 6.1)
{'id': '09_05', 'seed': 5, 'out_folder': 'results/epoch_budget', 'batch_size': 128, 'epochs': 166, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'bootstrapping': False, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/166 [00:00<?, ?epoch/s]2024-03-05 04:45:53.995325: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-05 04:45:54.007124: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600020000 Hz
2024-03-05 04:45:56.028540: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 04:45:56.254565: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 04:45:57.131423: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-05 04:45:57.190047: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/166 [01:07<3:05:57, 67.62s/epoch, loss=3.03, accuracy=0.323, val_loss=2.49, val_accuracy=0.268, lr=0.1]  1%|          | 2/166 [01:28<1:48:59, 39.88s/epoch, loss=1.53, accuracy=0.556, val_loss=2.65, val_accuracy=0.378, lr=0.1]  2%|▏         | 3/166 [01:48<1:23:48, 30.85s/epoch, loss=1.34, accuracy=0.646, val_loss=1.9, val_accuracy=0.488, lr=0.1]   2%|▏         | 4/166 [02:08<1:11:47, 26.59s/epoch, loss=1.27, accuracy=0.683, val_loss=1.92, val_accuracy=0.507, lr=0.1]  3%|▎         | 5/166 [02:28<1:05:00, 24.23s/epoch, loss=1.26, accuracy=0.698, val_loss=1.9, val_accuracy=0.505, lr=0.1]   4%|▎         | 6/166 [02:48<1:00:40, 22.75s/epoch, loss=1.24, accuracy=0.709, val_loss=1.84, val_accuracy=0.532, lr=0.1]  4%|▍         | 7/166 [03:08<57:52, 21.84s/epoch, loss=1.23, accuracy=0.713, val_loss=2.58, val_accuracy=0.412, lr=0.1]    5%|▍         | 8/166 [03:28<55:58, 21.26s/epoch, loss=1.22, accuracy=0.721, val_loss=1.93, val_accuracy=0.491, lr=0.1]  5%|▌         | 9/166 [03:48<54:36, 20.87s/epoch, loss=1.2, accuracy=0.726, val_loss=1.76, val_accuracy=0.546, lr=0.1]   6%|▌         | 10/166 [04:08<53:37, 20.62s/epoch, loss=1.2, accuracy=0.731, val_loss=2.24, val_accuracy=0.433, lr=0.1]  7%|▋         | 11/166 [04:28<52:51, 20.46s/epoch, loss=1.19, accuracy=0.732, val_loss=1.87, val_accuracy=0.545, lr=0.1]  7%|▋         | 12/166 [04:48<52:06, 20.30s/epoch, loss=1.18, accuracy=0.738, val_loss=1.49, val_accuracy=0.633, lr=0.1]  8%|▊         | 13/166 [05:08<51:40, 20.27s/epoch, loss=1.18, accuracy=0.737, val_loss=2.27, val_accuracy=0.428, lr=0.1]  8%|▊         | 14/166 [05:28<51:20, 20.27s/epoch, loss=1.17, accuracy=0.741, val_loss=1.81, val_accuracy=0.523, lr=0.1]  9%|▉         | 15/166 [05:48<50:45, 20.17s/epoch, loss=1.16, accuracy=0.742, val_loss=2.78, val_accuracy=0.468, lr=0.1] 10%|▉         | 16/166 [06:08<50:14, 20.10s/epoch, loss=1.17, accuracy=0.741, val_loss=1.68, val_accuracy=0.566, lr=0.1] 10%|█         | 17/166 [06:28<49:48, 20.06s/epoch, loss=1.15, accuracy=0.747, val_loss=1.42, val_accuracy=0.665, lr=0.1] 11%|█         | 18/166 [06:48<49:30, 20.07s/epoch, loss=1.16, accuracy=0.746, val_loss=1.98, val_accuracy=0.47, lr=0.1]  11%|█▏        | 19/166 [07:08<49:07, 20.05s/epoch, loss=1.15, accuracy=0.746, val_loss=2.4, val_accuracy=0.46, lr=0.1]  12%|█▏        | 20/166 [07:28<48:46, 20.05s/epoch, loss=1.15, accuracy=0.749, val_loss=1.59, val_accuracy=0.576, lr=0.1] 13%|█▎        | 21/166 [07:49<48:41, 20.15s/epoch, loss=1.15, accuracy=0.749, val_loss=2.22, val_accuracy=0.506, lr=0.1] 13%|█▎        | 22/166 [08:09<48:15, 20.10s/epoch, loss=1.15, accuracy=0.749, val_loss=2.13, val_accuracy=0.485, lr=0.0316] 14%|█▍        | 23/166 [08:29<47:53, 20.10s/epoch, loss=1.14, accuracy=0.752, val_loss=2.56, val_accuracy=0.414, lr=0.1]    14%|█▍        | 24/166 [08:49<47:38, 20.13s/epoch, loss=1.14, accuracy=0.752, val_loss=2.27, val_accuracy=0.397, lr=0.1] 15%|█▌        | 25/166 [09:09<47:18, 20.13s/epoch, loss=1.14, accuracy=0.75, val_loss=1.76, val_accuracy=0.566, lr=0.1]  16%|█▌        | 26/166 [09:29<46:55, 20.11s/epoch, loss=1.14, accuracy=0.752, val_loss=1.97, val_accuracy=0.508, lr=0.1] 16%|█▋        | 27/166 [09:49<46:30, 20.07s/epoch, loss=1.14, accuracy=0.75, val_loss=1.75, val_accuracy=0.555, lr=0.0316] 17%|█▋        | 28/166 [10:09<46:09, 20.07s/epoch, loss=1.13, accuracy=0.755, val_loss=2.11, val_accuracy=0.511, lr=0.1]   17%|█▋        | 29/166 [10:29<45:48, 20.06s/epoch, loss=1.13, accuracy=0.753, val_loss=1.35, val_accuracy=0.677, lr=0.1] 18%|█▊        | 30/166 [10:49<45:23, 20.03s/epoch, loss=1.14, accuracy=0.752, val_loss=3.52, val_accuracy=0.327, lr=0.1] 19%|█▊        | 31/166 [11:09<45:04, 20.04s/epoch, loss=1.13, accuracy=0.755, val_loss=1.47, val_accuracy=0.638, lr=0.1] 19%|█▉        | 32/166 [11:29<44:44, 20.03s/epoch, loss=1.13, accuracy=0.752, val_loss=2.2, val_accuracy=0.479, lr=0.1]  20%|█▉        | 33/166 [11:49<44:22, 20.02s/epoch, loss=1.14, accuracy=0.753, val_loss=1.69, val_accuracy=0.57, lr=0.1] 20%|██        | 34/166 [12:09<44:05, 20.04s/epoch, loss=1.13, accuracy=0.753, val_loss=2.09, val_accuracy=0.533, lr=0.0316] 21%|██        | 35/166 [12:29<43:44, 20.04s/epoch, loss=1.13, accuracy=0.755, val_loss=3.8, val_accuracy=0.357, lr=0.1]     22%|██▏       | 36/166 [12:49<43:19, 19.99s/epoch, loss=1.14, accuracy=0.751, val_loss=2.11, val_accuracy=0.545, lr=0.1] 22%|██▏       | 37/166 [13:09<43:04, 20.03s/epoch, loss=1.13, accuracy=0.754, val_loss=1.78, val_accuracy=0.554, lr=0.1] 23%|██▎       | 38/166 [13:29<42:49, 20.08s/epoch, loss=1.14, accuracy=0.752, val_loss=2.3, val_accuracy=0.422, lr=0.1]  23%|██▎       | 39/166 [13:50<42:28, 20.07s/epoch, loss=1.13, accuracy=0.755, val_loss=1.85, val_accuracy=0.563, lr=0.0316] 24%|██▍       | 40/166 [14:10<42:11, 20.09s/epoch, loss=1.13, accuracy=0.757, val_loss=2.2, val_accuracy=0.493, lr=0.1]     25%|██▍       | 41/166 [14:30<41:54, 20.12s/epoch, loss=1.13, accuracy=0.754, val_loss=2.19, val_accuracy=0.465, lr=0.1] 25%|██▌       | 42/166 [14:50<41:38, 20.15s/epoch, loss=1.13, accuracy=0.756, val_loss=1.8, val_accuracy=0.58, lr=0.1]   26%|██▌       | 43/166 [15:10<41:14, 20.12s/epoch, loss=1.13, accuracy=0.757, val_loss=1.74, val_accuracy=0.542, lr=0.1] 27%|██▋       | 44/166 [15:30<40:52, 20.10s/epoch, loss=1.12, accuracy=0.753, val_loss=1.65, val_accuracy=0.601, lr=0.0316] 27%|██▋       | 45/166 [15:50<40:33, 20.11s/epoch, loss=1.12, accuracy=0.755, val_loss=3.57, val_accuracy=0.309, lr=0.1]    28%|██▊       | 46/166 [16:10<40:10, 20.09s/epoch, loss=1.13, accuracy=0.756, val_loss=3.54, val_accuracy=0.341, lr=0.1] 28%|██▊       | 47/166 [16:30<39:47, 20.06s/epoch, loss=1.11, accuracy=0.757, val_loss=2.92, val_accuracy=0.424, lr=0.1] 29%|██▉       | 48/166 [16:51<39:32, 20.11s/epoch, loss=1.12, accuracy=0.756, val_loss=1.35, val_accuracy=0.674, lr=0.1] 30%|██▉       | 49/166 [17:11<39:17, 20.15s/epoch, loss=1.12, accuracy=0.756, val_loss=1.53, val_accuracy=0.608, lr=0.0316] 30%|███       | 50/166 [17:31<38:51, 20.10s/epoch, loss=1.12, accuracy=0.754, val_loss=2.91, val_accuracy=0.401, lr=0.1]    31%|███       | 51/166 [17:51<38:25, 20.05s/epoch, loss=1.12, accuracy=0.756, val_loss=2.17, val_accuracy=0.462, lr=0.1] 31%|███▏      | 52/166 [18:11<38:06, 20.05s/epoch, loss=1.12, accuracy=0.759, val_loss=8.69, val_accuracy=0.165, lr=0.1] 32%|███▏      | 53/166 [18:31<37:47, 20.06s/epoch, loss=1.12, accuracy=0.761, val_loss=4.85, val_accuracy=0.359, lr=0.1] 33%|███▎      | 54/166 [18:51<37:22, 20.02s/epoch, loss=1.12, accuracy=0.755, val_loss=1.72, val_accuracy=0.534, lr=0.0316] 33%|███▎      | 55/166 [19:11<37:05, 20.05s/epoch, loss=1.11, accuracy=0.759, val_loss=1.76, val_accuracy=0.57, lr=0.1]     34%|███▎      | 56/166 [19:31<36:45, 20.05s/epoch, loss=1.12, accuracy=0.757, val_loss=1.68, val_accuracy=0.563, lr=0.1] 34%|███▍      | 57/166 [19:51<36:25, 20.05s/epoch, loss=1.12, accuracy=0.757, val_loss=1.84, val_accuracy=0.521, lr=0.1] 35%|███▍      | 58/166 [20:11<36:04, 20.04s/epoch, loss=1.12, accuracy=0.758, val_loss=2.58, val_accuracy=0.367, lr=0.1] 36%|███▌      | 59/166 [20:31<35:45, 20.05s/epoch, loss=1.11, accuracy=0.759, val_loss=3.65, val_accuracy=0.257, lr=0.0316] 36%|███▌      | 60/166 [20:51<35:20, 20.01s/epoch, loss=1.11, accuracy=0.758, val_loss=2.71, val_accuracy=0.39, lr=0.1]     37%|███▋      | 61/166 [21:11<35:03, 20.03s/epoch, loss=1.11, accuracy=0.759, val_loss=5.08, val_accuracy=0.2, lr=0.1]  37%|███▋      | 62/166 [21:31<34:43, 20.03s/epoch, loss=1.11, accuracy=0.757, val_loss=1.41, val_accuracy=0.66, lr=0.1] 38%|███▊      | 63/166 [21:51<34:22, 20.03s/epoch, loss=1.11, accuracy=0.759, val_loss=1.61, val_accuracy=0.612, lr=0.1] 39%|███▊      | 64/166 [22:11<33:59, 19.99s/epoch, loss=1.12, accuracy=0.757, val_loss=4.96, val_accuracy=0.196, lr=0.0316] 39%|███▉      | 65/166 [22:31<33:39, 20.00s/epoch, loss=1.12, accuracy=0.758, val_loss=2.29, val_accuracy=0.448, lr=0.1]    40%|███▉      | 66/166 [22:51<33:19, 19.99s/epoch, loss=1.11, accuracy=0.756, val_loss=1.73, val_accuracy=0.507, lr=0.1] 40%|████      | 67/166 [23:11<32:56, 19.97s/epoch, loss=1.11, accuracy=0.758, val_loss=1.79, val_accuracy=0.571, lr=0.1] 41%|████      | 68/166 [23:31<32:29, 19.89s/epoch, loss=1.11, accuracy=0.758, val_loss=3.24, val_accuracy=0.309, lr=0.1] 42%|████▏     | 69/166 [23:51<32:13, 19.93s/epoch, loss=1.11, accuracy=0.757, val_loss=2.63, val_accuracy=0.445, lr=0.0316] 42%|████▏     | 70/166 [24:11<31:53, 19.93s/epoch, loss=1.11, accuracy=0.758, val_loss=4.84, val_accuracy=0.189, lr=0.1]    43%|████▎     | 71/166 [24:31<31:33, 19.93s/epoch, loss=1.11, accuracy=0.758, val_loss=3.32, val_accuracy=0.299, lr=0.1] 43%|████▎     | 72/166 [24:50<31:11, 19.91s/epoch, loss=1.12, accuracy=0.756, val_loss=3.21, val_accuracy=0.37, lr=0.1]  44%|████▍     | 73/166 [25:10<30:49, 19.88s/epoch, loss=1.12, accuracy=0.759, val_loss=1.73, val_accuracy=0.575, lr=0.1] 45%|████▍     | 74/166 [25:30<30:28, 19.88s/epoch, loss=1.12, accuracy=0.756, val_loss=1.86, val_accuracy=0.527, lr=0.0316] 45%|████▌     | 75/166 [25:50<30:09, 19.89s/epoch, loss=1.11, accuracy=0.757, val_loss=2.02, val_accuracy=0.52, lr=0.1]     46%|████▌     | 76/166 [26:10<29:51, 19.90s/epoch, loss=1.11, accuracy=0.755, val_loss=1.62, val_accuracy=0.58, lr=0.1] 46%|████▋     | 77/166 [26:30<29:33, 19.92s/epoch, loss=1.11, accuracy=0.758, val_loss=3.38, val_accuracy=0.359, lr=0.1] 47%|████▋     | 78/166 [26:50<29:13, 19.93s/epoch, loss=1.11, accuracy=0.76, val_loss=3.59, val_accuracy=0.315, lr=0.1]  48%|████▊     | 79/166 [27:10<28:55, 19.95s/epoch, loss=1.12, accuracy=0.756, val_loss=2.63, val_accuracy=0.42, lr=0.0316] 48%|████▊     | 80/166 [27:30<28:37, 19.97s/epoch, loss=1.11, accuracy=0.758, val_loss=3.17, val_accuracy=0.332, lr=0.1]   49%|████▉     | 81/166 [27:50<28:16, 19.96s/epoch, loss=1.11, accuracy=0.76, val_loss=2.47, val_accuracy=0.402, lr=0.1]  49%|████▉     | 82/166 [28:10<27:58, 19.98s/epoch, loss=0.897, accuracy=0.82, val_loss=0.932, val_accuracy=0.787, lr=0.01] 50%|█████     | 83/166 [28:30<27:38, 19.98s/epoch, loss=0.726, accuracy=0.848, val_loss=0.981, val_accuracy=0.757, lr=0.01] 51%|█████     | 84/166 [28:50<27:16, 19.95s/epoch, loss=0.645, accuracy=0.856, val_loss=0.818, val_accuracy=0.788, lr=0.01] 51%|█████     | 85/166 [29:10<26:53, 19.92s/epoch, loss=0.602, accuracy=0.859, val_loss=0.822, val_accuracy=0.781, lr=0.01] 52%|█████▏    | 86/166 [29:30<26:35, 19.94s/epoch, loss=0.579, accuracy=0.862, val_loss=0.791, val_accuracy=0.792, lr=0.01] 52%|█████▏    | 87/166 [29:49<26:15, 19.94s/epoch, loss=0.573, accuracy=0.86, val_loss=0.715, val_accuracy=0.809, lr=0.01]  53%|█████▎    | 88/166 [30:09<25:54, 19.94s/epoch, loss=0.564, accuracy=0.863, val_loss=0.663, val_accuracy=0.831, lr=0.01] 54%|█████▎    | 89/166 [30:29<25:34, 19.93s/epoch, loss=0.561, accuracy=0.866, val_loss=0.745, val_accuracy=0.807, lr=0.01] 54%|█████▍    | 90/166 [30:49<25:14, 19.93s/epoch, loss=0.559, accuracy=0.866, val_loss=0.99, val_accuracy=0.744, lr=0.01]  55%|█████▍    | 91/166 [31:09<24:53, 19.92s/epoch, loss=0.56, accuracy=0.867, val_loss=0.921, val_accuracy=0.766, lr=0.01] 55%|█████▌    | 92/166 [31:29<24:36, 19.95s/epoch, loss=0.557, accuracy=0.869, val_loss=0.779, val_accuracy=0.803, lr=0.01] 56%|█████▌    | 93/166 [31:49<24:11, 19.89s/epoch, loss=0.554, accuracy=0.871, val_loss=0.788, val_accuracy=0.796, lr=0.00316] 57%|█████▋    | 94/166 [32:09<23:54, 19.92s/epoch, loss=0.558, accuracy=0.87, val_loss=0.833, val_accuracy=0.802, lr=0.01]     57%|█████▋    | 95/166 [32:29<23:31, 19.89s/epoch, loss=0.551, accuracy=0.873, val_loss=0.929, val_accuracy=0.762, lr=0.01] 58%|█████▊    | 96/166 [32:49<23:12, 19.89s/epoch, loss=0.556, accuracy=0.874, val_loss=1.18, val_accuracy=0.684, lr=0.01]  58%|█████▊    | 97/166 [33:09<22:52, 19.89s/epoch, loss=0.554, accuracy=0.874, val_loss=0.783, val_accuracy=0.799, lr=0.01] 59%|█████▉    | 98/166 [33:28<22:33, 19.90s/epoch, loss=0.551, accuracy=0.874, val_loss=0.711, val_accuracy=0.821, lr=0.00316] 60%|█████▉    | 99/166 [33:48<22:14, 19.92s/epoch, loss=0.552, accuracy=0.875, val_loss=1.76, val_accuracy=0.63, lr=0.01]      60%|██████    | 100/166 [34:08<21:57, 19.96s/epoch, loss=0.549, accuracy=0.877, val_loss=1.08, val_accuracy=0.732, lr=0.01] 61%|██████    | 101/166 [34:28<21:35, 19.93s/epoch, loss=0.551, accuracy=0.877, val_loss=0.883, val_accuracy=0.774, lr=0.01] 61%|██████▏   | 102/166 [34:48<21:17, 19.96s/epoch, loss=0.555, accuracy=0.877, val_loss=1.37, val_accuracy=0.663, lr=0.01]  62%|██████▏   | 103/166 [35:08<20:59, 19.99s/epoch, loss=0.553, accuracy=0.878, val_loss=1.07, val_accuracy=0.735, lr=0.00316] 63%|██████▎   | 104/166 [35:29<20:41, 20.02s/epoch, loss=0.547, accuracy=0.879, val_loss=0.85, val_accuracy=0.797, lr=0.01]    63%|██████▎   | 105/166 [35:49<20:22, 20.05s/epoch, loss=0.549, accuracy=0.88, val_loss=0.867, val_accuracy=0.79, lr=0.01]  64%|██████▍   | 106/166 [36:09<20:04, 20.08s/epoch, loss=0.554, accuracy=0.879, val_loss=1.05, val_accuracy=0.738, lr=0.01] 64%|██████▍   | 107/166 [36:29<19:42, 20.05s/epoch, loss=0.551, accuracy=0.879, val_loss=0.743, val_accuracy=0.817, lr=0.01] 65%|██████▌   | 108/166 [36:49<19:22, 20.04s/epoch, loss=0.545, accuracy=0.882, val_loss=1.23, val_accuracy=0.711, lr=0.00316] 66%|██████▌   | 109/166 [37:09<19:02, 20.04s/epoch, loss=0.555, accuracy=0.88, val_loss=1.18, val_accuracy=0.712, lr=0.01]     66%|██████▋   | 110/166 [37:29<18:42, 20.05s/epoch, loss=0.546, accuracy=0.884, val_loss=1.21, val_accuracy=0.707, lr=0.01] 67%|██████▋   | 111/166 [37:49<18:23, 20.06s/epoch, loss=0.549, accuracy=0.884, val_loss=0.77, val_accuracy=0.816, lr=0.01] 67%|██████▋   | 112/166 [38:09<18:06, 20.12s/epoch, loss=0.549, accuracy=0.883, val_loss=0.892, val_accuracy=0.784, lr=0.01] 68%|██████▊   | 113/166 [38:29<17:45, 20.10s/epoch, loss=0.551, accuracy=0.883, val_loss=0.824, val_accuracy=0.805, lr=0.00316] 69%|██████▊   | 114/166 [38:49<17:25, 20.11s/epoch, loss=0.549, accuracy=0.884, val_loss=0.881, val_accuracy=0.787, lr=0.01]    69%|██████▉   | 115/166 [39:09<17:02, 20.05s/epoch, loss=0.555, accuracy=0.883, val_loss=0.772, val_accuracy=0.814, lr=0.01] 70%|██████▉   | 116/166 [39:29<16:41, 20.02s/epoch, loss=0.546, accuracy=0.886, val_loss=0.815, val_accuracy=0.805, lr=0.01] 70%|███████   | 117/166 [39:49<16:21, 20.02s/epoch, loss=0.546, accuracy=0.884, val_loss=0.719, val_accuracy=0.827, lr=0.01] 71%|███████   | 118/166 [40:09<15:59, 19.99s/epoch, loss=0.549, accuracy=0.884, val_loss=0.971, val_accuracy=0.751, lr=0.00316] 72%|███████▏  | 119/166 [40:29<15:37, 19.94s/epoch, loss=0.549, accuracy=0.885, val_loss=1.07, val_accuracy=0.747, lr=0.01]     72%|███████▏  | 120/166 [40:49<15:16, 19.92s/epoch, loss=0.548, accuracy=0.886, val_loss=0.811, val_accuracy=0.792, lr=0.01] 73%|███████▎  | 121/166 [41:09<14:55, 19.90s/epoch, loss=0.549, accuracy=0.885, val_loss=1, val_accuracy=0.764, lr=0.01]     73%|███████▎  | 122/166 [41:29<14:35, 19.89s/epoch, loss=0.477, accuracy=0.91, val_loss=0.539, val_accuracy=0.889, lr=0.001] 74%|███████▍  | 123/166 [41:48<14:14, 19.87s/epoch, loss=0.427, accuracy=0.927, val_loss=0.519, val_accuracy=0.895, lr=0.001] 75%|███████▍  | 124/166 [42:08<13:53, 19.84s/epoch, loss=0.401, accuracy=0.933, val_loss=0.502, val_accuracy=0.899, lr=0.001] 75%|███████▌  | 125/166 [42:28<13:35, 19.88s/epoch, loss=0.386, accuracy=0.938, val_loss=0.498, val_accuracy=0.898, lr=0.001] 76%|███████▌  | 126/166 [42:48<13:14, 19.87s/epoch, loss=0.371, accuracy=0.939, val_loss=0.495, val_accuracy=0.9, lr=0.001]   77%|███████▋  | 127/166 [43:08<12:55, 19.90s/epoch, loss=0.36, accuracy=0.942, val_loss=0.49, val_accuracy=0.899, lr=0.001] 77%|███████▋  | 128/166 [43:28<12:38, 19.96s/epoch, loss=0.35, accuracy=0.943, val_loss=0.477, val_accuracy=0.902, lr=0.001] 78%|███████▊  | 129/166 [43:48<12:17, 19.92s/epoch, loss=0.338, accuracy=0.946, val_loss=0.485, val_accuracy=0.9, lr=0.001]  78%|███████▊  | 130/166 [44:08<11:55, 19.88s/epoch, loss=0.33, accuracy=0.946, val_loss=0.479, val_accuracy=0.9, lr=0.001]  79%|███████▉  | 131/166 [44:28<11:34, 19.86s/epoch, loss=0.321, accuracy=0.949, val_loss=0.481, val_accuracy=0.897, lr=0.001] 80%|███████▉  | 132/166 [44:47<11:15, 19.86s/epoch, loss=0.312, accuracy=0.95, val_loss=0.483, val_accuracy=0.895, lr=0.001]  80%|████████  | 133/166 [45:07<10:54, 19.83s/epoch, loss=0.306, accuracy=0.951, val_loss=0.467, val_accuracy=0.899, lr=0.001] 81%|████████  | 134/166 [45:27<10:35, 19.85s/epoch, loss=0.3, accuracy=0.952, val_loss=0.458, val_accuracy=0.899, lr=0.001]   81%|████████▏ | 135/166 [45:47<10:14, 19.82s/epoch, loss=0.293, accuracy=0.953, val_loss=0.461, val_accuracy=0.899, lr=0.001] 82%|████████▏ | 136/166 [46:07<09:54, 19.81s/epoch, loss=0.287, accuracy=0.953, val_loss=0.464, val_accuracy=0.895, lr=0.001] 83%|████████▎ | 137/166 [46:26<09:33, 19.78s/epoch, loss=0.281, accuracy=0.954, val_loss=0.461, val_accuracy=0.899, lr=0.001] 83%|████████▎ | 138/166 [46:46<09:12, 19.74s/epoch, loss=0.275, accuracy=0.955, val_loss=0.46, val_accuracy=0.895, lr=0.001]  84%|████████▎ | 139/166 [47:06<08:54, 19.78s/epoch, loss=0.269, accuracy=0.956, val_loss=0.452, val_accuracy=0.899, lr=0.001] 84%|████████▍ | 140/166 [47:26<08:33, 19.76s/epoch, loss=0.266, accuracy=0.956, val_loss=0.455, val_accuracy=0.897, lr=0.001] 85%|████████▍ | 141/166 [47:45<08:15, 19.80s/epoch, loss=0.262, accuracy=0.956, val_loss=0.456, val_accuracy=0.895, lr=0.001] 86%|████████▌ | 142/166 [48:05<07:55, 19.80s/epoch, loss=0.257, accuracy=0.958, val_loss=0.481, val_accuracy=0.893, lr=0.001] 86%|████████▌ | 143/166 [48:25<07:34, 19.77s/epoch, loss=0.254, accuracy=0.956, val_loss=0.512, val_accuracy=0.887, lr=0.001] 87%|████████▋ | 144/166 [48:45<07:14, 19.77s/epoch, loss=0.246, accuracy=0.959, val_loss=0.473, val_accuracy=0.892, lr=0.000316] 87%|████████▋ | 145/166 [49:04<06:54, 19.73s/epoch, loss=0.246, accuracy=0.958, val_loss=0.446, val_accuracy=0.902, lr=0.001]    88%|████████▊ | 146/166 [49:24<06:34, 19.72s/epoch, loss=0.241, accuracy=0.96, val_loss=0.468, val_accuracy=0.892, lr=0.001]  89%|████████▊ | 147/166 [49:44<06:15, 19.75s/epoch, loss=0.241, accuracy=0.96, val_loss=0.466, val_accuracy=0.891, lr=0.001] 89%|████████▉ | 148/166 [50:04<05:56, 19.78s/epoch, loss=0.235, accuracy=0.96, val_loss=0.477, val_accuracy=0.889, lr=0.001] 90%|████████▉ | 149/166 [50:24<05:36, 19.80s/epoch, loss=0.231, accuracy=0.961, val_loss=0.457, val_accuracy=0.896, lr=0.001] 90%|█████████ | 150/166 [50:43<05:16, 19.78s/epoch, loss=0.231, accuracy=0.96, val_loss=0.455, val_accuracy=0.896, lr=0.000316] 91%|█████████ | 151/166 [51:03<04:57, 19.81s/epoch, loss=0.229, accuracy=0.961, val_loss=0.498, val_accuracy=0.882, lr=0.001]   92%|█████████▏| 152/166 [51:23<04:37, 19.79s/epoch, loss=0.225, accuracy=0.962, val_loss=0.473, val_accuracy=0.889, lr=0.001] 92%|█████████▏| 153/166 [51:43<04:17, 19.77s/epoch, loss=0.226, accuracy=0.96, val_loss=0.477, val_accuracy=0.889, lr=0.001]  93%|█████████▎| 154/166 [52:02<03:57, 19.79s/epoch, loss=0.223, accuracy=0.961, val_loss=0.497, val_accuracy=0.885, lr=0.001] 93%|█████████▎| 155/166 [52:22<03:37, 19.75s/epoch, loss=0.224, accuracy=0.961, val_loss=0.487, val_accuracy=0.887, lr=0.000316] 94%|█████████▍| 156/166 [52:42<03:17, 19.76s/epoch, loss=0.222, accuracy=0.959, val_loss=0.52, val_accuracy=0.879, lr=0.001]     95%|█████████▍| 157/166 [53:02<02:58, 19.81s/epoch, loss=0.217, accuracy=0.962, val_loss=0.473, val_accuracy=0.887, lr=0.001] 95%|█████████▌| 158/166 [53:22<02:38, 19.80s/epoch, loss=0.216, accuracy=0.961, val_loss=0.506, val_accuracy=0.883, lr=0.001] 96%|█████████▌| 159/166 [53:41<02:17, 19.70s/epoch, loss=0.217, accuracy=0.96, val_loss=0.533, val_accuracy=0.878, lr=0.001]  96%|█████████▋| 160/166 [54:01<01:58, 19.70s/epoch, loss=0.219, accuracy=0.96, val_loss=0.494, val_accuracy=0.886, lr=0.000316] 97%|█████████▋| 161/166 [54:20<01:38, 19.65s/epoch, loss=0.215, accuracy=0.961, val_loss=0.531, val_accuracy=0.873, lr=0.001]   98%|█████████▊| 162/166 [54:40<01:18, 19.74s/epoch, loss=0.198, accuracy=0.968, val_loss=0.415, val_accuracy=0.905, lr=1e-04] 98%|█████████▊| 163/166 [55:00<00:59, 19.71s/epoch, loss=0.182, accuracy=0.974, val_loss=0.413, val_accuracy=0.905, lr=1e-04] 99%|█████████▉| 164/166 [55:20<00:39, 19.69s/epoch, loss=0.176, accuracy=0.977, val_loss=0.412, val_accuracy=0.907, lr=1e-04] 99%|█████████▉| 165/166 [55:39<00:19, 19.64s/epoch, loss=0.173, accuracy=0.978, val_loss=0.412, val_accuracy=0.906, lr=1e-04]100%|██████████| 166/166 [55:58<00:00, 19.53s/epoch, loss=0.171, accuracy=0.978, val_loss=0.415, val_accuracy=0.905, lr=1e-04]100%|██████████| 166/166 [55:58<00:00, 20.23s/epoch, loss=0.171, accuracy=0.978, val_loss=0.415, val_accuracy=0.905, lr=1e-04]
Using real-time data augmentation.
Test score: 0.4151865839958191
Test accuracy: 0.9052000045776367


* * * Run SGD for ID = 9_6. * * *


2024-03-05 05:41:56.349039: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 05:41:58.905703: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 05:41:58.906715: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-05 05:41:58.943110: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-03-05 05:41:58.943154: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 05:41:58.946141: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 05:41:58.946201: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 05:41:58.948617: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 05:41:58.949331: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 05:41:58.951719: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 05:41:58.953136: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 05:41:58.957407: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 05:41:58.957993: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 05:41:58.958077: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 05:42:00.231435: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-05 05:42:00.232027: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 05:42:00.232754: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-03-05 05:42:00.232784: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 05:42:00.232827: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 05:42:00.232844: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 05:42:00.232858: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 05:42:00.232873: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 05:42:00.232889: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 05:42:00.232905: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 05:42:00.232922: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 05:42:00.233377: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 05:42:00.233411: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 05:42:00.902401: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-05 05:42:00.902460: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-05 05:42:00.902469: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-05 05:42:00.903422: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:02:00.0, compute capability: 6.1)
{'id': '09_06', 'seed': 6, 'out_folder': 'results/epoch_budget', 'batch_size': 128, 'epochs': 166, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'bootstrapping': False, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/166 [00:00<?, ?epoch/s]2024-03-05 05:42:01.768197: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-05 05:42:01.780112: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600020000 Hz
2024-03-05 05:42:03.798264: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 05:42:03.994375: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 05:42:04.662982: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-05 05:42:04.727308: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/166 [01:08<3:07:03, 68.02s/epoch, loss=2.91, accuracy=0.37, val_loss=2.06, val_accuracy=0.354, lr=0.1]  1%|          | 2/166 [01:28<1:49:21, 40.01s/epoch, loss=1.48, accuracy=0.577, val_loss=1.71, val_accuracy=0.543, lr=0.1]  2%|▏         | 3/166 [01:48<1:24:24, 31.07s/epoch, loss=1.29, accuracy=0.666, val_loss=1.58, val_accuracy=0.587, lr=0.1]  2%|▏         | 4/166 [02:08<1:12:08, 26.72s/epoch, loss=1.24, accuracy=0.697, val_loss=2.48, val_accuracy=0.399, lr=0.1]  3%|▎         | 5/166 [02:29<1:05:21, 24.36s/epoch, loss=1.22, accuracy=0.708, val_loss=2.95, val_accuracy=0.369, lr=0.1]  4%|▎         | 6/166 [02:49<1:01:00, 22.88s/epoch, loss=1.21, accuracy=0.72, val_loss=2.16, val_accuracy=0.451, lr=0.1]   4%|▍         | 7/166 [03:08<57:57, 21.87s/epoch, loss=1.19, accuracy=0.728, val_loss=3.02, val_accuracy=0.34, lr=0.1]    5%|▍         | 8/166 [03:28<55:56, 21.24s/epoch, loss=1.18, accuracy=0.73, val_loss=4.98, val_accuracy=0.271, lr=0.0316]  5%|▌         | 9/166 [03:48<54:21, 20.78s/epoch, loss=1.17, accuracy=0.735, val_loss=1.8, val_accuracy=0.498, lr=0.1]     6%|▌         | 10/166 [04:08<53:27, 20.56s/epoch, loss=1.18, accuracy=0.735, val_loss=3.37, val_accuracy=0.322, lr=0.1]  7%|▋         | 11/166 [04:28<52:36, 20.37s/epoch, loss=1.16, accuracy=0.739, val_loss=1.78, val_accuracy=0.529, lr=0.1]  7%|▋         | 12/166 [04:48<52:02, 20.28s/epoch, loss=1.15, accuracy=0.743, val_loss=1.84, val_accuracy=0.519, lr=0.1]  8%|▊         | 13/166 [05:08<51:40, 20.26s/epoch, loss=1.16, accuracy=0.741, val_loss=1.68, val_accuracy=0.569, lr=0.0316]  8%|▊         | 14/166 [05:29<51:25, 20.30s/epoch, loss=1.15, accuracy=0.742, val_loss=2.49, val_accuracy=0.332, lr=0.1]     9%|▉         | 15/166 [05:49<50:59, 20.26s/epoch, loss=1.15, accuracy=0.746, val_loss=2.3, val_accuracy=0.451, lr=0.1]  10%|▉         | 16/166 [06:09<50:29, 20.19s/epoch, loss=1.15, accuracy=0.747, val_loss=1.53, val_accuracy=0.603, lr=0.1] 10%|█         | 17/166 [06:29<50:09, 20.20s/epoch, loss=1.15, accuracy=0.745, val_loss=2.56, val_accuracy=0.453, lr=0.1] 11%|█         | 18/166 [06:49<49:39, 20.13s/epoch, loss=1.14, accuracy=0.747, val_loss=1.61, val_accuracy=0.6, lr=0.1]   11%|█▏        | 19/166 [07:10<49:40, 20.27s/epoch, loss=1.14, accuracy=0.748, val_loss=1.34, val_accuracy=0.678, lr=0.1] 12%|█▏        | 20/166 [07:30<49:21, 20.28s/epoch, loss=1.14, accuracy=0.749, val_loss=2.11, val_accuracy=0.458, lr=0.1] 13%|█▎        | 21/166 [07:51<49:13, 20.37s/epoch, loss=1.14, accuracy=0.749, val_loss=2.17, val_accuracy=0.498, lr=0.1] 13%|█▎        | 22/166 [08:11<49:03, 20.44s/epoch, loss=1.14, accuracy=0.75, val_loss=2.02, val_accuracy=0.514, lr=0.1]  14%|█▍        | 23/166 [08:32<48:38, 20.41s/epoch, loss=1.14, accuracy=0.75, val_loss=2.43, val_accuracy=0.492, lr=0.1] 14%|█▍        | 24/166 [08:52<48:28, 20.48s/epoch, loss=1.13, accuracy=0.754, val_loss=1.76, val_accuracy=0.566, lr=0.0316] 15%|█▌        | 25/166 [09:13<48:04, 20.46s/epoch, loss=1.13, accuracy=0.75, val_loss=1.94, val_accuracy=0.508, lr=0.1]     16%|█▌        | 26/166 [09:33<47:49, 20.50s/epoch, loss=1.13, accuracy=0.751, val_loss=2.13, val_accuracy=0.509, lr=0.1] 16%|█▋        | 27/166 [09:54<47:25, 20.47s/epoch, loss=1.13, accuracy=0.751, val_loss=2.09, val_accuracy=0.511, lr=0.1] 17%|█▋        | 28/166 [10:14<47:03, 20.46s/epoch, loss=1.13, accuracy=0.75, val_loss=3.73, val_accuracy=0.19, lr=0.1]   17%|█▋        | 29/166 [10:34<46:42, 20.45s/epoch, loss=1.12, accuracy=0.754, val_loss=1.86, val_accuracy=0.547, lr=0.0316] 18%|█▊        | 30/166 [10:55<46:15, 20.41s/epoch, loss=1.13, accuracy=0.754, val_loss=1.57, val_accuracy=0.594, lr=0.1]    19%|█▊        | 31/166 [11:15<45:55, 20.41s/epoch, loss=1.13, accuracy=0.751, val_loss=2.05, val_accuracy=0.534, lr=0.1] 19%|█▉        | 32/166 [11:36<45:39, 20.45s/epoch, loss=1.12, accuracy=0.755, val_loss=2.46, val_accuracy=0.354, lr=0.1] 20%|█▉        | 33/166 [11:56<45:20, 20.46s/epoch, loss=1.12, accuracy=0.754, val_loss=2.5, val_accuracy=0.356, lr=0.1]  20%|██        | 34/166 [12:17<45:02, 20.47s/epoch, loss=1.12, accuracy=0.754, val_loss=1.45, val_accuracy=0.636, lr=0.0316] 21%|██        | 35/166 [12:37<44:34, 20.42s/epoch, loss=1.12, accuracy=0.755, val_loss=1.53, val_accuracy=0.639, lr=0.1]    22%|██▏       | 36/166 [12:57<44:14, 20.42s/epoch, loss=1.12, accuracy=0.752, val_loss=2.01, val_accuracy=0.491, lr=0.1] 22%|██▏       | 37/166 [13:18<43:49, 20.38s/epoch, loss=1.12, accuracy=0.758, val_loss=2.18, val_accuracy=0.461, lr=0.1] 23%|██▎       | 38/166 [13:38<43:33, 20.42s/epoch, loss=1.12, accuracy=0.755, val_loss=4.2, val_accuracy=0.162, lr=0.1]  23%|██▎       | 39/166 [13:59<43:18, 20.46s/epoch, loss=1.12, accuracy=0.758, val_loss=1.54, val_accuracy=0.605, lr=0.0316] 24%|██▍       | 40/166 [14:19<42:55, 20.44s/epoch, loss=1.12, accuracy=0.753, val_loss=2.12, val_accuracy=0.492, lr=0.1]    25%|██▍       | 41/166 [14:40<42:34, 20.44s/epoch, loss=1.12, accuracy=0.755, val_loss=3.21, val_accuracy=0.342, lr=0.1] 25%|██▌       | 42/166 [15:00<42:12, 20.42s/epoch, loss=1.12, accuracy=0.756, val_loss=5.87, val_accuracy=0.109, lr=0.1] 26%|██▌       | 43/166 [15:21<41:57, 20.47s/epoch, loss=1.11, accuracy=0.758, val_loss=1.59, val_accuracy=0.595, lr=0.1] 27%|██▋       | 44/166 [15:41<41:34, 20.45s/epoch, loss=1.11, accuracy=0.755, val_loss=1.55, val_accuracy=0.633, lr=0.0316] 27%|██▋       | 45/166 [16:01<41:08, 20.40s/epoch, loss=1.11, accuracy=0.757, val_loss=1.72, val_accuracy=0.556, lr=0.1]    28%|██▊       | 46/166 [16:22<40:54, 20.46s/epoch, loss=1.11, accuracy=0.757, val_loss=1.46, val_accuracy=0.634, lr=0.1] 28%|██▊       | 47/166 [16:42<40:31, 20.44s/epoch, loss=1.11, accuracy=0.758, val_loss=1.54, val_accuracy=0.612, lr=0.1] 29%|██▉       | 48/166 [17:03<40:18, 20.50s/epoch, loss=1.11, accuracy=0.756, val_loss=1.93, val_accuracy=0.512, lr=0.1] 30%|██▉       | 49/166 [17:23<40:00, 20.51s/epoch, loss=1.11, accuracy=0.756, val_loss=3.27, val_accuracy=0.428, lr=0.0316] 30%|███       | 50/166 [17:44<39:33, 20.47s/epoch, loss=1.11, accuracy=0.758, val_loss=2.47, val_accuracy=0.519, lr=0.1]    31%|███       | 51/166 [18:04<39:14, 20.47s/epoch, loss=1.11, accuracy=0.759, val_loss=2.1, val_accuracy=0.492, lr=0.1]  31%|███▏      | 52/166 [18:25<38:49, 20.43s/epoch, loss=1.12, accuracy=0.754, val_loss=3.95, val_accuracy=0.329, lr=0.1] 32%|███▏      | 53/166 [18:45<38:37, 20.51s/epoch, loss=1.11, accuracy=0.757, val_loss=2.09, val_accuracy=0.458, lr=0.1] 33%|███▎      | 54/166 [19:06<38:16, 20.50s/epoch, loss=1.1, accuracy=0.761, val_loss=1.83, val_accuracy=0.544, lr=0.0316] 33%|███▎      | 55/166 [19:26<37:59, 20.54s/epoch, loss=1.11, accuracy=0.758, val_loss=3.48, val_accuracy=0.301, lr=0.1]   34%|███▎      | 56/166 [19:47<37:36, 20.52s/epoch, loss=1.11, accuracy=0.758, val_loss=1.73, val_accuracy=0.579, lr=0.1] 34%|███▍      | 57/166 [20:07<37:15, 20.51s/epoch, loss=1.11, accuracy=0.76, val_loss=2.35, val_accuracy=0.378, lr=0.1]  35%|███▍      | 58/166 [20:28<36:56, 20.52s/epoch, loss=1.11, accuracy=0.757, val_loss=2.14, val_accuracy=0.418, lr=0.1] 36%|███▌      | 59/166 [20:48<36:28, 20.45s/epoch, loss=1.11, accuracy=0.759, val_loss=2.24, val_accuracy=0.439, lr=0.0316] 36%|███▌      | 60/166 [21:08<36:01, 20.40s/epoch, loss=1.1, accuracy=0.759, val_loss=2.56, val_accuracy=0.435, lr=0.1]     37%|███▋      | 61/166 [21:29<35:40, 20.39s/epoch, loss=1.1, accuracy=0.761, val_loss=2.12, val_accuracy=0.499, lr=0.1] 37%|███▋      | 62/166 [21:49<35:25, 20.44s/epoch, loss=1.11, accuracy=0.758, val_loss=3.29, val_accuracy=0.307, lr=0.1] 38%|███▊      | 63/166 [22:10<34:59, 20.38s/epoch, loss=1.11, accuracy=0.76, val_loss=1.96, val_accuracy=0.465, lr=0.1]  39%|███▊      | 64/166 [22:30<34:40, 20.39s/epoch, loss=1.11, accuracy=0.757, val_loss=2.83, val_accuracy=0.377, lr=0.0316] 39%|███▉      | 65/166 [22:50<34:10, 20.30s/epoch, loss=1.1, accuracy=0.76, val_loss=1.84, val_accuracy=0.595, lr=0.1]      40%|███▉      | 66/166 [23:10<33:50, 20.31s/epoch, loss=1.1, accuracy=0.76, val_loss=1.53, val_accuracy=0.613, lr=0.1] 40%|████      | 67/166 [23:31<33:26, 20.27s/epoch, loss=1.11, accuracy=0.761, val_loss=3.29, val_accuracy=0.338, lr=0.1] 41%|████      | 68/166 [23:51<33:01, 20.22s/epoch, loss=1.1, accuracy=0.761, val_loss=4.21, val_accuracy=0.204, lr=0.1]  42%|████▏     | 69/166 [24:11<32:42, 20.23s/epoch, loss=1.11, accuracy=0.759, val_loss=3.03, val_accuracy=0.397, lr=0.0316] 42%|████▏     | 70/166 [24:31<32:22, 20.24s/epoch, loss=1.1, accuracy=0.761, val_loss=2.36, val_accuracy=0.404, lr=0.1]     43%|████▎     | 71/166 [24:51<32:00, 20.21s/epoch, loss=1.11, accuracy=0.758, val_loss=3.23, val_accuracy=0.316, lr=0.1] 43%|████▎     | 72/166 [25:12<31:42, 20.24s/epoch, loss=1.11, accuracy=0.757, val_loss=1.66, val_accuracy=0.59, lr=0.1]  44%|████▍     | 73/166 [25:32<31:24, 20.26s/epoch, loss=1.11, accuracy=0.759, val_loss=1.96, val_accuracy=0.51, lr=0.1] 45%|████▍     | 74/166 [25:52<31:05, 20.28s/epoch, loss=1.11, accuracy=0.759, val_loss=1.6, val_accuracy=0.559, lr=0.0316] 45%|████▌     | 75/166 [26:13<30:42, 20.25s/epoch, loss=1.11, accuracy=0.76, val_loss=2.89, val_accuracy=0.368, lr=0.1]    46%|████▌     | 76/166 [26:33<30:19, 20.22s/epoch, loss=1.11, accuracy=0.757, val_loss=1.73, val_accuracy=0.571, lr=0.1] 46%|████▋     | 77/166 [26:53<30:00, 20.23s/epoch, loss=1.1, accuracy=0.76, val_loss=2.38, val_accuracy=0.394, lr=0.1]   47%|████▋     | 78/166 [27:13<29:36, 20.18s/epoch, loss=1.1, accuracy=0.76, val_loss=2.89, val_accuracy=0.435, lr=0.1] 48%|████▊     | 79/166 [27:33<29:19, 20.23s/epoch, loss=1.1, accuracy=0.759, val_loss=1.83, val_accuracy=0.496, lr=0.0316] 48%|████▊     | 80/166 [27:54<29:00, 20.24s/epoch, loss=1.1, accuracy=0.762, val_loss=1.67, val_accuracy=0.59, lr=0.1]     49%|████▉     | 81/166 [28:14<28:35, 20.19s/epoch, loss=1.1, accuracy=0.758, val_loss=2.25, val_accuracy=0.462, lr=0.1] 49%|████▉     | 82/166 [28:34<28:19, 20.23s/epoch, loss=0.905, accuracy=0.818, val_loss=0.868, val_accuracy=0.816, lr=0.01] 50%|█████     | 83/166 [28:54<27:55, 20.19s/epoch, loss=0.728, accuracy=0.85, val_loss=0.823, val_accuracy=0.809, lr=0.01]  51%|█████     | 84/166 [29:14<27:31, 20.14s/epoch, loss=0.644, accuracy=0.858, val_loss=0.724, val_accuracy=0.825, lr=0.01] 51%|█████     | 85/166 [29:35<27:21, 20.26s/epoch, loss=0.601, accuracy=0.859, val_loss=0.863, val_accuracy=0.774, lr=0.01] 52%|█████▏    | 86/166 [29:55<27:02, 20.28s/epoch, loss=0.576, accuracy=0.864, val_loss=0.956, val_accuracy=0.75, lr=0.01]  52%|█████▏    | 87/166 [30:15<26:32, 20.16s/epoch, loss=0.569, accuracy=0.862, val_loss=0.824, val_accuracy=0.79, lr=0.01] 53%|█████▎    | 88/166 [30:35<26:11, 20.15s/epoch, loss=0.558, accuracy=0.864, val_loss=0.78, val_accuracy=0.798, lr=0.01] 54%|█████▎    | 89/166 [30:55<25:52, 20.16s/epoch, loss=0.555, accuracy=0.867, val_loss=0.717, val_accuracy=0.809, lr=0.01] 54%|█████▍    | 90/166 [31:15<25:30, 20.13s/epoch, loss=0.558, accuracy=0.865, val_loss=0.891, val_accuracy=0.762, lr=0.01] 55%|█████▍    | 91/166 [31:35<25:08, 20.11s/epoch, loss=0.55, accuracy=0.869, val_loss=0.889, val_accuracy=0.77, lr=0.01]   55%|█████▌    | 92/166 [31:56<24:53, 20.18s/epoch, loss=0.553, accuracy=0.87, val_loss=0.932, val_accuracy=0.772, lr=0.01] 56%|█████▌    | 93/166 [32:16<24:34, 20.20s/epoch, loss=0.548, accuracy=0.872, val_loss=1.66, val_accuracy=0.627, lr=0.01] 57%|█████▋    | 94/166 [32:36<24:15, 20.21s/epoch, loss=0.548, accuracy=0.875, val_loss=0.778, val_accuracy=0.804, lr=0.00316] 57%|█████▋    | 95/166 [32:56<23:56, 20.23s/epoch, loss=0.552, accuracy=0.874, val_loss=0.924, val_accuracy=0.764, lr=0.01]    58%|█████▊    | 96/166 [33:17<23:33, 20.19s/epoch, loss=0.552, accuracy=0.873, val_loss=1.18, val_accuracy=0.711, lr=0.01]  58%|█████▊    | 97/166 [33:37<23:14, 20.21s/epoch, loss=0.547, accuracy=0.876, val_loss=0.756, val_accuracy=0.803, lr=0.01] 59%|█████▉    | 98/166 [33:57<22:55, 20.22s/epoch, loss=0.545, accuracy=0.877, val_loss=0.907, val_accuracy=0.759, lr=0.01] 60%|█████▉    | 99/166 [34:17<22:37, 20.26s/epoch, loss=0.549, accuracy=0.876, val_loss=1.13, val_accuracy=0.735, lr=0.00316] 60%|██████    | 100/166 [34:38<22:18, 20.29s/epoch, loss=0.548, accuracy=0.876, val_loss=0.759, val_accuracy=0.808, lr=0.01]  61%|██████    | 101/166 [34:58<22:00, 20.32s/epoch, loss=0.548, accuracy=0.878, val_loss=0.743, val_accuracy=0.814, lr=0.01] 61%|██████▏   | 102/166 [35:19<21:42, 20.35s/epoch, loss=0.545, accuracy=0.881, val_loss=0.901, val_accuracy=0.771, lr=0.01] 62%|██████▏   | 103/166 [35:39<21:21, 20.34s/epoch, loss=0.546, accuracy=0.88, val_loss=0.754, val_accuracy=0.811, lr=0.01]  63%|██████▎   | 104/166 [35:59<21:03, 20.38s/epoch, loss=0.551, accuracy=0.879, val_loss=0.994, val_accuracy=0.761, lr=0.00316] 63%|██████▎   | 105/166 [36:20<20:42, 20.38s/epoch, loss=0.547, accuracy=0.879, val_loss=1.2, val_accuracy=0.695, lr=0.01]      64%|██████▍   | 106/166 [36:40<20:25, 20.42s/epoch, loss=0.55, accuracy=0.879, val_loss=0.808, val_accuracy=0.792, lr=0.01] 64%|██████▍   | 107/166 [37:01<20:02, 20.39s/epoch, loss=0.548, accuracy=0.881, val_loss=0.852, val_accuracy=0.792, lr=0.01] 65%|██████▌   | 108/166 [37:21<19:39, 20.34s/epoch, loss=0.55, accuracy=0.88, val_loss=0.91, val_accuracy=0.772, lr=0.01]    66%|██████▌   | 109/166 [37:41<19:16, 20.29s/epoch, loss=0.548, accuracy=0.881, val_loss=1.24, val_accuracy=0.714, lr=0.00316] 66%|██████▋   | 110/166 [38:01<18:54, 20.25s/epoch, loss=0.545, accuracy=0.883, val_loss=0.783, val_accuracy=0.808, lr=0.01]   67%|██████▋   | 111/166 [38:21<18:30, 20.19s/epoch, loss=0.545, accuracy=0.884, val_loss=1.03, val_accuracy=0.729, lr=0.01]  67%|██████▋   | 112/166 [38:41<18:08, 20.16s/epoch, loss=0.544, accuracy=0.883, val_loss=0.945, val_accuracy=0.766, lr=0.01] 68%|██████▊   | 113/166 [39:01<17:46, 20.12s/epoch, loss=0.547, accuracy=0.883, val_loss=1.2, val_accuracy=0.714, lr=0.01]   69%|██████▊   | 114/166 [39:22<17:28, 20.17s/epoch, loss=0.545, accuracy=0.883, val_loss=0.914, val_accuracy=0.775, lr=0.00316] 69%|██████▉   | 115/166 [39:42<17:07, 20.15s/epoch, loss=0.549, accuracy=0.882, val_loss=1.21, val_accuracy=0.704, lr=0.01]     70%|██████▉   | 116/166 [40:02<16:45, 20.10s/epoch, loss=0.544, accuracy=0.884, val_loss=0.722, val_accuracy=0.826, lr=0.01] 70%|███████   | 117/166 [40:21<16:18, 19.96s/epoch, loss=0.548, accuracy=0.883, val_loss=0.975, val_accuracy=0.751, lr=0.01] 71%|███████   | 118/166 [40:41<15:58, 19.96s/epoch, loss=0.547, accuracy=0.884, val_loss=0.806, val_accuracy=0.791, lr=0.01] 72%|███████▏  | 119/166 [41:01<15:39, 19.98s/epoch, loss=0.545, accuracy=0.883, val_loss=0.808, val_accuracy=0.811, lr=0.00316] 72%|███████▏  | 120/166 [41:22<15:22, 20.06s/epoch, loss=0.542, accuracy=0.885, val_loss=1.06, val_accuracy=0.756, lr=0.01]     73%|███████▎  | 121/166 [41:41<15:01, 20.04s/epoch, loss=0.549, accuracy=0.884, val_loss=0.915, val_accuracy=0.774, lr=0.01] 73%|███████▎  | 122/166 [42:01<14:39, 20.00s/epoch, loss=0.468, accuracy=0.912, val_loss=0.535, val_accuracy=0.891, lr=0.001] 74%|███████▍  | 123/166 [42:21<14:18, 19.96s/epoch, loss=0.414, accuracy=0.929, val_loss=0.531, val_accuracy=0.893, lr=0.001] 75%|███████▍  | 124/166 [42:41<13:57, 19.95s/epoch, loss=0.393, accuracy=0.935, val_loss=0.516, val_accuracy=0.895, lr=0.001] 75%|███████▌  | 125/166 [43:01<13:40, 20.01s/epoch, loss=0.377, accuracy=0.938, val_loss=0.502, val_accuracy=0.9, lr=0.001]   76%|███████▌  | 126/166 [43:21<13:21, 20.04s/epoch, loss=0.361, accuracy=0.942, val_loss=0.496, val_accuracy=0.901, lr=0.001] 77%|███████▋  | 127/166 [43:41<13:00, 20.02s/epoch, loss=0.349, accuracy=0.944, val_loss=0.502, val_accuracy=0.899, lr=0.001] 77%|███████▋  | 128/166 [44:01<12:41, 20.03s/epoch, loss=0.338, accuracy=0.947, val_loss=0.49, val_accuracy=0.899, lr=0.001]  78%|███████▊  | 129/166 [44:21<12:20, 20.00s/epoch, loss=0.329, accuracy=0.947, val_loss=0.482, val_accuracy=0.902, lr=0.001] 78%|███████▊  | 130/166 [44:41<11:59, 19.99s/epoch, loss=0.318, accuracy=0.95, val_loss=0.469, val_accuracy=0.904, lr=0.001]  79%|███████▉  | 131/166 [45:01<11:38, 19.97s/epoch, loss=0.313, accuracy=0.95, val_loss=0.468, val_accuracy=0.904, lr=0.001] 80%|███████▉  | 132/166 [45:21<11:17, 19.91s/epoch, loss=0.304, accuracy=0.951, val_loss=0.476, val_accuracy=0.905, lr=0.001] 80%|████████  | 133/166 [45:41<10:56, 19.89s/epoch, loss=0.299, accuracy=0.952, val_loss=0.478, val_accuracy=0.9, lr=0.001]   81%|████████  | 134/166 [46:01<10:35, 19.86s/epoch, loss=0.29, accuracy=0.953, val_loss=0.48, val_accuracy=0.899, lr=0.001] 81%|████████▏ | 135/166 [46:21<10:15, 19.87s/epoch, loss=0.281, accuracy=0.955, val_loss=0.477, val_accuracy=0.897, lr=0.001] 82%|████████▏ | 136/166 [46:40<09:56, 19.87s/epoch, loss=0.278, accuracy=0.955, val_loss=0.487, val_accuracy=0.894, lr=0.000316] 83%|████████▎ | 137/166 [47:00<09:36, 19.86s/epoch, loss=0.272, accuracy=0.957, val_loss=0.48, val_accuracy=0.897, lr=0.001]     83%|████████▎ | 138/166 [47:20<09:17, 19.92s/epoch, loss=0.264, accuracy=0.959, val_loss=0.467, val_accuracy=0.899, lr=0.001] 84%|████████▎ | 139/166 [47:40<08:58, 19.96s/epoch, loss=0.262, accuracy=0.957, val_loss=0.465, val_accuracy=0.901, lr=0.001] 84%|████████▍ | 140/166 [48:00<08:38, 19.94s/epoch, loss=0.257, accuracy=0.958, val_loss=0.473, val_accuracy=0.894, lr=0.001] 85%|████████▍ | 141/166 [48:20<08:18, 19.92s/epoch, loss=0.253, accuracy=0.958, val_loss=0.478, val_accuracy=0.896, lr=0.001] 86%|████████▌ | 142/166 [48:40<07:56, 19.87s/epoch, loss=0.245, accuracy=0.961, val_loss=0.515, val_accuracy=0.891, lr=0.001] 86%|████████▌ | 143/166 [49:00<07:38, 19.92s/epoch, loss=0.245, accuracy=0.96, val_loss=0.475, val_accuracy=0.894, lr=0.001]  87%|████████▋ | 144/166 [49:20<07:17, 19.90s/epoch, loss=0.242, accuracy=0.961, val_loss=0.502, val_accuracy=0.892, lr=0.000316] 87%|████████▋ | 145/166 [49:40<06:57, 19.86s/epoch, loss=0.238, accuracy=0.961, val_loss=0.49, val_accuracy=0.889, lr=0.001]     88%|████████▊ | 146/166 [49:59<06:37, 19.87s/epoch, loss=0.235, accuracy=0.961, val_loss=0.482, val_accuracy=0.887, lr=0.001] 89%|████████▊ | 147/166 [50:20<06:18, 19.92s/epoch, loss=0.236, accuracy=0.96, val_loss=0.477, val_accuracy=0.891, lr=0.001]  89%|████████▉ | 148/166 [50:40<05:59, 19.96s/epoch, loss=0.231, accuracy=0.961, val_loss=0.502, val_accuracy=0.888, lr=0.001] 90%|████████▉ | 149/166 [51:00<05:40, 20.02s/epoch, loss=0.23, accuracy=0.96, val_loss=0.48, val_accuracy=0.889, lr=0.000316] 90%|█████████ | 150/166 [51:20<05:20, 20.02s/epoch, loss=0.227, accuracy=0.962, val_loss=0.48, val_accuracy=0.889, lr=0.001]  91%|█████████ | 151/166 [51:40<05:00, 20.05s/epoch, loss=0.224, accuracy=0.962, val_loss=0.503, val_accuracy=0.889, lr=0.001] 92%|█████████▏| 152/166 [52:00<04:41, 20.08s/epoch, loss=0.224, accuracy=0.962, val_loss=0.486, val_accuracy=0.891, lr=0.001] 92%|█████████▏| 153/166 [52:20<04:20, 20.08s/epoch, loss=0.223, accuracy=0.962, val_loss=0.472, val_accuracy=0.897, lr=0.001] 93%|█████████▎| 154/166 [52:40<04:00, 20.07s/epoch, loss=0.22, accuracy=0.962, val_loss=0.49, val_accuracy=0.889, lr=0.000316] 93%|█████████▎| 155/166 [53:00<03:40, 20.04s/epoch, loss=0.218, accuracy=0.962, val_loss=0.559, val_accuracy=0.874, lr=0.001]  94%|█████████▍| 156/166 [53:20<03:20, 20.02s/epoch, loss=0.218, accuracy=0.962, val_loss=0.525, val_accuracy=0.882, lr=0.001] 95%|█████████▍| 157/166 [53:40<02:59, 19.97s/epoch, loss=0.215, accuracy=0.962, val_loss=0.512, val_accuracy=0.884, lr=0.001] 95%|█████████▌| 158/166 [54:00<02:39, 19.98s/epoch, loss=0.216, accuracy=0.962, val_loss=0.537, val_accuracy=0.882, lr=0.001] 96%|█████████▌| 159/166 [54:20<02:19, 19.97s/epoch, loss=0.212, accuracy=0.962, val_loss=0.551, val_accuracy=0.879, lr=0.000316] 96%|█████████▋| 160/166 [54:40<01:59, 19.97s/epoch, loss=0.213, accuracy=0.962, val_loss=0.467, val_accuracy=0.891, lr=0.001]    97%|█████████▋| 161/166 [55:00<01:39, 19.96s/epoch, loss=0.21, accuracy=0.964, val_loss=0.502, val_accuracy=0.885, lr=0.001]  98%|█████████▊| 162/166 [55:20<01:20, 20.00s/epoch, loss=0.188, accuracy=0.972, val_loss=0.419, val_accuracy=0.908, lr=1e-04] 98%|█████████▊| 163/166 [55:40<00:59, 19.98s/epoch, loss=0.174, accuracy=0.978, val_loss=0.423, val_accuracy=0.91, lr=1e-04]  99%|█████████▉| 164/166 [56:00<00:40, 20.05s/epoch, loss=0.169, accuracy=0.979, val_loss=0.418, val_accuracy=0.91, lr=1e-04] 99%|█████████▉| 165/166 [56:20<00:20, 20.01s/epoch, loss=0.164, accuracy=0.981, val_loss=0.418, val_accuracy=0.911, lr=1e-04]100%|██████████| 166/166 [56:40<00:00, 20.05s/epoch, loss=0.161, accuracy=0.982, val_loss=0.42, val_accuracy=0.91, lr=1e-04]  100%|██████████| 166/166 [56:40<00:00, 20.49s/epoch, loss=0.161, accuracy=0.982, val_loss=0.42, val_accuracy=0.91, lr=1e-04]
Using real-time data augmentation.
Test score: 0.4203161597251892
Test accuracy: 0.910099983215332


* * * Run SGD for ID = 9_7. * * *


2024-03-05 06:38:45.868374: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 06:38:48.423269: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 06:38:48.424331: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-05 06:38:48.461015: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-03-05 06:38:48.461068: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 06:38:48.463904: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 06:38:48.463965: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 06:38:48.466301: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 06:38:48.467027: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 06:38:48.469372: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 06:38:48.470841: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 06:38:48.475354: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 06:38:48.475941: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 06:38:48.476033: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 06:38:49.720351: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-05 06:38:49.720911: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 06:38:49.721630: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-03-05 06:38:49.721660: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 06:38:49.721696: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 06:38:49.721712: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 06:38:49.721727: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 06:38:49.721743: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 06:38:49.721757: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 06:38:49.721771: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 06:38:49.721786: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 06:38:49.722221: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 06:38:49.722253: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 06:38:50.370853: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-05 06:38:50.370903: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-05 06:38:50.370911: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-05 06:38:50.371766: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:02:00.0, compute capability: 6.1)
{'id': '09_07', 'seed': 7, 'out_folder': 'results/epoch_budget', 'batch_size': 128, 'epochs': 166, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'bootstrapping': False, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/166 [00:00<?, ?epoch/s]2024-03-05 06:38:51.232789: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-05 06:38:51.233382: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600020000 Hz
2024-03-05 06:38:53.220133: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 06:38:53.438559: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 06:38:54.178591: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-05 06:38:54.248660: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/166 [01:08<3:07:30, 68.18s/epoch, loss=3.14, accuracy=0.309, val_loss=3.31, val_accuracy=0.185, lr=0.1]  1%|          | 2/166 [01:28<1:49:42, 40.14s/epoch, loss=1.52, accuracy=0.554, val_loss=3.36, val_accuracy=0.289, lr=0.1]  2%|▏         | 3/166 [01:49<1:24:42, 31.18s/epoch, loss=1.32, accuracy=0.654, val_loss=1.74, val_accuracy=0.5, lr=0.1]    2%|▏         | 4/166 [02:09<1:12:38, 26.91s/epoch, loss=1.26, accuracy=0.688, val_loss=1.85, val_accuracy=0.475, lr=0.1]  3%|▎         | 5/166 [02:29<1:05:47, 24.52s/epoch, loss=1.24, accuracy=0.704, val_loss=1.39, val_accuracy=0.65, lr=0.1]   4%|▎         | 6/166 [02:50<1:01:34, 23.09s/epoch, loss=1.23, accuracy=0.714, val_loss=3.83, val_accuracy=0.321, lr=0.1]  4%|▍         | 7/166 [03:10<58:43, 22.16s/epoch, loss=1.22, accuracy=0.717, val_loss=2.03, val_accuracy=0.497, lr=0.1]    5%|▍         | 8/166 [03:30<56:42, 21.54s/epoch, loss=1.21, accuracy=0.724, val_loss=2.38, val_accuracy=0.358, lr=0.1]  5%|▌         | 9/166 [03:50<55:11, 21.09s/epoch, loss=1.2, accuracy=0.728, val_loss=1.74, val_accuracy=0.541, lr=0.1]   6%|▌         | 10/166 [04:10<54:04, 20.80s/epoch, loss=1.19, accuracy=0.731, val_loss=1.56, val_accuracy=0.591, lr=0.0316]  7%|▋         | 11/166 [04:31<53:26, 20.69s/epoch, loss=1.19, accuracy=0.733, val_loss=2.15, val_accuracy=0.504, lr=0.1]     7%|▋         | 12/166 [04:51<52:47, 20.57s/epoch, loss=1.18, accuracy=0.738, val_loss=1.79, val_accuracy=0.524, lr=0.1]  8%|▊         | 13/166 [05:11<52:15, 20.49s/epoch, loss=1.17, accuracy=0.74, val_loss=2.38, val_accuracy=0.38, lr=0.1]    8%|▊         | 14/166 [05:32<51:41, 20.41s/epoch, loss=1.17, accuracy=0.74, val_loss=1.88, val_accuracy=0.566, lr=0.1]  9%|▉         | 15/166 [05:52<51:10, 20.33s/epoch, loss=1.17, accuracy=0.743, val_loss=1.85, val_accuracy=0.519, lr=0.0316] 10%|▉         | 16/166 [06:12<50:48, 20.33s/epoch, loss=1.16, accuracy=0.746, val_loss=1.67, val_accuracy=0.59, lr=0.1]     10%|█         | 17/166 [06:32<50:28, 20.33s/epoch, loss=1.16, accuracy=0.743, val_loss=2.41, val_accuracy=0.419, lr=0.1] 11%|█         | 18/166 [06:53<50:02, 20.28s/epoch, loss=1.16, accuracy=0.744, val_loss=1.79, val_accuracy=0.527, lr=0.1] 11%|█▏        | 19/166 [07:13<49:34, 20.24s/epoch, loss=1.16, accuracy=0.746, val_loss=2.29, val_accuracy=0.452, lr=0.1] 12%|█▏        | 20/166 [07:33<49:12, 20.22s/epoch, loss=1.16, accuracy=0.744, val_loss=1.89, val_accuracy=0.544, lr=0.0316] 13%|█▎        | 21/166 [07:53<48:54, 20.24s/epoch, loss=1.15, accuracy=0.748, val_loss=1.81, val_accuracy=0.555, lr=0.1]    13%|█▎        | 22/166 [08:13<48:36, 20.26s/epoch, loss=1.15, accuracy=0.749, val_loss=2.39, val_accuracy=0.421, lr=0.1] 14%|█▍        | 23/166 [08:34<48:18, 20.27s/epoch, loss=1.15, accuracy=0.748, val_loss=3.01, val_accuracy=0.4, lr=0.1]   14%|█▍        | 24/166 [08:54<48:07, 20.34s/epoch, loss=1.15, accuracy=0.748, val_loss=2.82, val_accuracy=0.329, lr=0.1] 15%|█▌        | 25/166 [09:14<47:31, 20.22s/epoch, loss=1.14, accuracy=0.751, val_loss=1.63, val_accuracy=0.581, lr=0.0316] 16%|█▌        | 26/166 [09:34<47:08, 20.21s/epoch, loss=1.15, accuracy=0.749, val_loss=1.92, val_accuracy=0.502, lr=0.1]    16%|█▋        | 27/166 [09:54<46:41, 20.15s/epoch, loss=1.13, accuracy=0.755, val_loss=1.52, val_accuracy=0.614, lr=0.1] 17%|█▋        | 28/166 [10:15<46:19, 20.14s/epoch, loss=1.14, accuracy=0.751, val_loss=1.68, val_accuracy=0.564, lr=0.1] 17%|█▋        | 29/166 [10:35<45:59, 20.14s/epoch, loss=1.13, accuracy=0.752, val_loss=2.9, val_accuracy=0.437, lr=0.1]  18%|█▊        | 30/166 [10:55<45:36, 20.12s/epoch, loss=1.14, accuracy=0.753, val_loss=1.88, val_accuracy=0.531, lr=0.0316] 19%|█▊        | 31/166 [11:15<45:14, 20.11s/epoch, loss=1.13, accuracy=0.754, val_loss=2.09, val_accuracy=0.517, lr=0.1]    19%|█▉        | 32/166 [11:35<44:55, 20.12s/epoch, loss=1.13, accuracy=0.753, val_loss=4.74, val_accuracy=0.247, lr=0.1] 20%|█▉        | 33/166 [11:55<44:32, 20.10s/epoch, loss=1.14, accuracy=0.754, val_loss=3.62, val_accuracy=0.312, lr=0.1] 20%|██        | 34/166 [12:15<44:17, 20.13s/epoch, loss=1.13, accuracy=0.754, val_loss=1.48, val_accuracy=0.66, lr=0.1]  21%|██        | 35/166 [12:35<43:53, 20.10s/epoch, loss=1.12, accuracy=0.754, val_loss=2.97, val_accuracy=0.312, lr=0.0316] 22%|██▏       | 36/166 [12:55<43:34, 20.11s/epoch, loss=1.13, accuracy=0.754, val_loss=2.3, val_accuracy=0.464, lr=0.1]     22%|██▏       | 37/166 [13:16<43:20, 20.16s/epoch, loss=1.13, accuracy=0.756, val_loss=2.33, val_accuracy=0.445, lr=0.1] 23%|██▎       | 38/166 [13:36<42:59, 20.15s/epoch, loss=1.13, accuracy=0.754, val_loss=2.44, val_accuracy=0.432, lr=0.1] 23%|██▎       | 39/166 [13:56<42:39, 20.15s/epoch, loss=1.13, accuracy=0.757, val_loss=4.24, val_accuracy=0.211, lr=0.1] 24%|██▍       | 40/166 [14:16<42:22, 20.18s/epoch, loss=1.13, accuracy=0.755, val_loss=1.93, val_accuracy=0.481, lr=0.0316] 25%|██▍       | 41/166 [14:36<41:55, 20.12s/epoch, loss=1.13, accuracy=0.755, val_loss=1.69, val_accuracy=0.569, lr=0.1]    25%|██▌       | 42/166 [14:56<41:32, 20.10s/epoch, loss=1.12, accuracy=0.758, val_loss=2.15, val_accuracy=0.47, lr=0.1]  26%|██▌       | 43/166 [15:16<41:09, 20.08s/epoch, loss=1.12, accuracy=0.758, val_loss=1.72, val_accuracy=0.546, lr=0.1] 27%|██▋       | 44/166 [15:36<40:45, 20.04s/epoch, loss=1.13, accuracy=0.757, val_loss=1.46, val_accuracy=0.659, lr=0.1] 27%|██▋       | 45/166 [15:56<40:23, 20.03s/epoch, loss=1.13, accuracy=0.757, val_loss=2.59, val_accuracy=0.398, lr=0.0316] 28%|██▊       | 46/166 [16:16<40:09, 20.08s/epoch, loss=1.12, accuracy=0.757, val_loss=3.4, val_accuracy=0.346, lr=0.1]     28%|██▊       | 47/166 [16:37<39:57, 20.15s/epoch, loss=1.12, accuracy=0.756, val_loss=4.15, val_accuracy=0.24, lr=0.1] 29%|██▉       | 48/166 [16:57<39:37, 20.15s/epoch, loss=1.12, accuracy=0.757, val_loss=1.71, val_accuracy=0.549, lr=0.1] 30%|██▉       | 49/166 [17:17<39:21, 20.19s/epoch, loss=1.12, accuracy=0.757, val_loss=2.45, val_accuracy=0.421, lr=0.1] 30%|███       | 50/166 [17:37<39:03, 20.20s/epoch, loss=1.12, accuracy=0.756, val_loss=3.2, val_accuracy=0.38, lr=0.0316] 31%|███       | 51/166 [17:58<38:45, 20.22s/epoch, loss=1.12, accuracy=0.757, val_loss=5.91, val_accuracy=0.211, lr=0.1]  31%|███▏      | 52/166 [18:18<38:28, 20.25s/epoch, loss=1.13, accuracy=0.757, val_loss=3.04, val_accuracy=0.356, lr=0.1] 32%|███▏      | 53/166 [18:38<38:12, 20.29s/epoch, loss=1.12, accuracy=0.758, val_loss=1.92, val_accuracy=0.511, lr=0.1] 33%|███▎      | 54/166 [18:59<37:57, 20.34s/epoch, loss=1.12, accuracy=0.759, val_loss=2.08, val_accuracy=0.448, lr=0.1] 33%|███▎      | 55/166 [19:19<37:36, 20.33s/epoch, loss=1.12, accuracy=0.757, val_loss=2.14, val_accuracy=0.447, lr=0.0316] 34%|███▎      | 56/166 [19:39<37:12, 20.30s/epoch, loss=1.12, accuracy=0.757, val_loss=2.33, val_accuracy=0.381, lr=0.1]    34%|███▍      | 57/166 [20:00<36:52, 20.30s/epoch, loss=1.12, accuracy=0.757, val_loss=1.87, val_accuracy=0.587, lr=0.1] 35%|███▍      | 58/166 [20:20<36:35, 20.32s/epoch, loss=1.11, accuracy=0.758, val_loss=1.61, val_accuracy=0.586, lr=0.1] 36%|███▌      | 59/166 [20:40<36:13, 20.31s/epoch, loss=1.13, accuracy=0.755, val_loss=1.42, val_accuracy=0.663, lr=0.1] 36%|███▌      | 60/166 [21:01<35:52, 20.30s/epoch, loss=1.12, accuracy=0.76, val_loss=2.02, val_accuracy=0.526, lr=0.0316] 37%|███▋      | 61/166 [21:21<35:34, 20.33s/epoch, loss=1.12, accuracy=0.758, val_loss=2, val_accuracy=0.47, lr=0.1]       37%|███▋      | 62/166 [21:41<35:17, 20.36s/epoch, loss=1.12, accuracy=0.758, val_loss=1.85, val_accuracy=0.54, lr=0.1] 38%|███▊      | 63/166 [22:02<34:53, 20.32s/epoch, loss=1.13, accuracy=0.755, val_loss=1.48, val_accuracy=0.629, lr=0.1] 39%|███▊      | 64/166 [22:22<34:28, 20.28s/epoch, loss=1.12, accuracy=0.758, val_loss=1.87, val_accuracy=0.525, lr=0.1] 39%|███▉      | 65/166 [22:42<34:03, 20.23s/epoch, loss=1.12, accuracy=0.758, val_loss=1.74, val_accuracy=0.569, lr=0.0316] 40%|███▉      | 66/166 [23:02<33:39, 20.20s/epoch, loss=1.12, accuracy=0.758, val_loss=2.33, val_accuracy=0.444, lr=0.1]    40%|████      | 67/166 [23:22<33:21, 20.21s/epoch, loss=1.12, accuracy=0.757, val_loss=2, val_accuracy=0.465, lr=0.1]    41%|████      | 68/166 [23:42<32:52, 20.12s/epoch, loss=1.11, accuracy=0.758, val_loss=2.96, val_accuracy=0.317, lr=0.1] 42%|████▏     | 69/166 [24:02<32:32, 20.13s/epoch, loss=1.11, accuracy=0.757, val_loss=2.13, val_accuracy=0.47, lr=0.1]  42%|████▏     | 70/166 [24:23<32:12, 20.13s/epoch, loss=1.12, accuracy=0.756, val_loss=2.22, val_accuracy=0.486, lr=0.0316] 43%|████▎     | 71/166 [24:43<31:53, 20.15s/epoch, loss=1.11, accuracy=0.756, val_loss=5.08, val_accuracy=0.225, lr=0.1]    43%|████▎     | 72/166 [25:03<31:30, 20.11s/epoch, loss=1.12, accuracy=0.758, val_loss=2.93, val_accuracy=0.316, lr=0.1] 44%|████▍     | 73/166 [25:23<31:05, 20.06s/epoch, loss=1.11, accuracy=0.759, val_loss=2.04, val_accuracy=0.498, lr=0.1] 45%|████▍     | 74/166 [25:43<30:52, 20.14s/epoch, loss=1.12, accuracy=0.757, val_loss=2.82, val_accuracy=0.324, lr=0.1] 45%|████▌     | 75/166 [26:03<30:30, 20.12s/epoch, loss=1.11, accuracy=0.759, val_loss=2.75, val_accuracy=0.44, lr=0.0316] 46%|████▌     | 76/166 [26:23<30:05, 20.06s/epoch, loss=1.12, accuracy=0.757, val_loss=2.16, val_accuracy=0.495, lr=0.1]   46%|████▋     | 77/166 [26:43<29:47, 20.09s/epoch, loss=1.11, accuracy=0.759, val_loss=3.9, val_accuracy=0.366, lr=0.1]  47%|████▋     | 78/166 [27:03<29:31, 20.13s/epoch, loss=1.1, accuracy=0.758, val_loss=3.31, val_accuracy=0.42, lr=0.1]  48%|████▊     | 79/166 [27:23<29:10, 20.12s/epoch, loss=1.11, accuracy=0.757, val_loss=2.72, val_accuracy=0.429, lr=0.1] 48%|████▊     | 80/166 [27:44<28:53, 20.16s/epoch, loss=1.12, accuracy=0.759, val_loss=2.62, val_accuracy=0.397, lr=0.0316] 49%|████▉     | 81/166 [28:04<28:38, 20.21s/epoch, loss=1.11, accuracy=0.76, val_loss=1.79, val_accuracy=0.57, lr=0.1]      49%|████▉     | 82/166 [28:24<28:19, 20.24s/epoch, loss=0.887, accuracy=0.822, val_loss=0.915, val_accuracy=0.795, lr=0.01] 50%|█████     | 83/166 [28:44<27:56, 20.20s/epoch, loss=0.72, accuracy=0.85, val_loss=0.773, val_accuracy=0.817, lr=0.01]   51%|█████     | 84/166 [29:05<27:33, 20.16s/epoch, loss=0.644, accuracy=0.857, val_loss=0.913, val_accuracy=0.761, lr=0.01] 51%|█████     | 85/166 [29:25<27:10, 20.13s/epoch, loss=0.598, accuracy=0.861, val_loss=0.992, val_accuracy=0.735, lr=0.01] 52%|█████▏    | 86/166 [29:45<26:47, 20.10s/epoch, loss=0.577, accuracy=0.862, val_loss=0.777, val_accuracy=0.795, lr=0.01] 52%|█████▏    | 87/166 [30:05<26:29, 20.12s/epoch, loss=0.568, accuracy=0.863, val_loss=0.863, val_accuracy=0.767, lr=0.01] 53%|█████▎    | 88/166 [30:25<26:06, 20.08s/epoch, loss=0.566, accuracy=0.862, val_loss=1.14, val_accuracy=0.706, lr=0.00316] 54%|█████▎    | 89/166 [30:45<25:49, 20.12s/epoch, loss=0.56, accuracy=0.864, val_loss=1.05, val_accuracy=0.72, lr=0.01]      54%|█████▍    | 90/166 [31:05<25:28, 20.11s/epoch, loss=0.558, accuracy=0.866, val_loss=1.28, val_accuracy=0.677, lr=0.01] 55%|█████▍    | 91/166 [31:25<25:10, 20.14s/epoch, loss=0.553, accuracy=0.87, val_loss=1.16, val_accuracy=0.697, lr=0.01]  55%|█████▌    | 92/166 [31:46<24:55, 20.21s/epoch, loss=0.55, accuracy=0.871, val_loss=0.729, val_accuracy=0.81, lr=0.01] 56%|█████▌    | 93/166 [32:06<24:33, 20.19s/epoch, loss=0.554, accuracy=0.87, val_loss=0.987, val_accuracy=0.758, lr=0.01] 57%|█████▋    | 94/166 [32:26<24:13, 20.19s/epoch, loss=0.551, accuracy=0.872, val_loss=0.811, val_accuracy=0.782, lr=0.01] 57%|█████▋    | 95/166 [32:46<23:54, 20.20s/epoch, loss=0.554, accuracy=0.873, val_loss=0.711, val_accuracy=0.826, lr=0.01] 58%|█████▊    | 96/166 [33:06<23:31, 20.17s/epoch, loss=0.554, accuracy=0.873, val_loss=0.966, val_accuracy=0.751, lr=0.01] 58%|█████▊    | 97/166 [33:26<23:05, 20.09s/epoch, loss=0.547, accuracy=0.876, val_loss=0.901, val_accuracy=0.762, lr=0.01] 59%|█████▉    | 98/166 [33:46<22:42, 20.03s/epoch, loss=0.552, accuracy=0.874, val_loss=0.707, val_accuracy=0.832, lr=0.01] 60%|█████▉    | 99/166 [34:06<22:19, 20.00s/epoch, loss=0.549, accuracy=0.876, val_loss=0.841, val_accuracy=0.788, lr=0.01] 60%|██████    | 100/166 [34:26<21:59, 19.99s/epoch, loss=0.549, accuracy=0.877, val_loss=0.883, val_accuracy=0.787, lr=0.01] 61%|██████    | 101/166 [34:46<21:38, 19.98s/epoch, loss=0.554, accuracy=0.876, val_loss=1.08, val_accuracy=0.722, lr=0.01]  61%|██████▏   | 102/166 [35:06<21:22, 20.05s/epoch, loss=0.549, accuracy=0.877, val_loss=1.11, val_accuracy=0.736, lr=0.01] 62%|██████▏   | 103/166 [35:26<21:00, 20.01s/epoch, loss=0.547, accuracy=0.879, val_loss=0.955, val_accuracy=0.755, lr=0.00316] 63%|██████▎   | 104/166 [35:46<20:42, 20.04s/epoch, loss=0.546, accuracy=0.879, val_loss=0.858, val_accuracy=0.771, lr=0.01]    63%|██████▎   | 105/166 [36:06<20:23, 20.06s/epoch, loss=0.547, accuracy=0.88, val_loss=0.786, val_accuracy=0.813, lr=0.01]  64%|██████▍   | 106/166 [36:26<20:04, 20.07s/epoch, loss=0.547, accuracy=0.881, val_loss=1.1, val_accuracy=0.726, lr=0.01]  64%|██████▍   | 107/166 [36:46<19:43, 20.06s/epoch, loss=0.546, accuracy=0.881, val_loss=0.802, val_accuracy=0.805, lr=0.01] 65%|██████▌   | 108/166 [37:06<19:20, 20.01s/epoch, loss=0.549, accuracy=0.881, val_loss=0.827, val_accuracy=0.796, lr=0.00316] 66%|██████▌   | 109/166 [37:26<18:57, 19.96s/epoch, loss=0.545, accuracy=0.882, val_loss=0.86, val_accuracy=0.793, lr=0.01]     66%|██████▋   | 110/166 [37:46<18:35, 19.91s/epoch, loss=0.549, accuracy=0.881, val_loss=0.746, val_accuracy=0.823, lr=0.01] 67%|██████▋   | 111/166 [38:06<18:14, 19.89s/epoch, loss=0.551, accuracy=0.882, val_loss=0.824, val_accuracy=0.803, lr=0.01] 67%|██████▋   | 112/166 [38:26<17:53, 19.87s/epoch, loss=0.554, accuracy=0.879, val_loss=1.1, val_accuracy=0.736, lr=0.01]   68%|██████▊   | 113/166 [38:45<17:32, 19.85s/epoch, loss=0.549, accuracy=0.883, val_loss=1.11, val_accuracy=0.738, lr=0.00316] 69%|██████▊   | 114/166 [39:05<17:13, 19.87s/epoch, loss=0.546, accuracy=0.884, val_loss=0.835, val_accuracy=0.804, lr=0.01]   69%|██████▉   | 115/166 [39:25<16:54, 19.89s/epoch, loss=0.543, accuracy=0.884, val_loss=1.17, val_accuracy=0.739, lr=0.01]  70%|██████▉   | 116/166 [39:45<16:34, 19.89s/epoch, loss=0.546, accuracy=0.885, val_loss=0.747, val_accuracy=0.82, lr=0.01] 70%|███████   | 117/166 [40:05<16:15, 19.90s/epoch, loss=0.546, accuracy=0.886, val_loss=0.834, val_accuracy=0.791, lr=0.01] 71%|███████   | 118/166 [40:25<15:53, 19.86s/epoch, loss=0.547, accuracy=0.883, val_loss=0.999, val_accuracy=0.754, lr=0.00316] 72%|███████▏  | 119/166 [40:45<15:32, 19.85s/epoch, loss=0.545, accuracy=0.886, val_loss=0.864, val_accuracy=0.794, lr=0.01]    72%|███████▏  | 120/166 [41:05<15:12, 19.85s/epoch, loss=0.545, accuracy=0.886, val_loss=0.835, val_accuracy=0.804, lr=0.01] 73%|███████▎  | 121/166 [41:24<14:54, 19.88s/epoch, loss=0.54, accuracy=0.887, val_loss=1.5, val_accuracy=0.676, lr=0.01]    73%|███████▎  | 122/166 [41:44<14:35, 19.89s/epoch, loss=0.47, accuracy=0.912, val_loss=0.54, val_accuracy=0.89, lr=0.001] 74%|███████▍  | 123/166 [42:04<14:15, 19.89s/epoch, loss=0.414, accuracy=0.929, val_loss=0.514, val_accuracy=0.895, lr=0.001] 75%|███████▍  | 124/166 [42:24<13:55, 19.90s/epoch, loss=0.388, accuracy=0.937, val_loss=0.502, val_accuracy=0.899, lr=0.001] 75%|███████▌  | 125/166 [42:44<13:30, 19.77s/epoch, loss=0.374, accuracy=0.939, val_loss=0.497, val_accuracy=0.9, lr=0.001]   76%|███████▌  | 126/166 [43:03<13:08, 19.72s/epoch, loss=0.362, accuracy=0.942, val_loss=0.48, val_accuracy=0.904, lr=0.001] 77%|███████▋  | 127/166 [43:23<12:54, 19.85s/epoch, loss=0.351, accuracy=0.943, val_loss=0.488, val_accuracy=0.899, lr=0.001] 77%|███████▋  | 128/166 [43:43<12:35, 19.89s/epoch, loss=0.34, accuracy=0.946, val_loss=0.475, val_accuracy=0.9, lr=0.001]    78%|███████▊  | 129/166 [44:03<12:16, 19.91s/epoch, loss=0.331, accuracy=0.948, val_loss=0.463, val_accuracy=0.903, lr=0.001] 78%|███████▊  | 130/166 [44:23<11:56, 19.90s/epoch, loss=0.323, accuracy=0.949, val_loss=0.466, val_accuracy=0.902, lr=0.001] 79%|███████▉  | 131/166 [44:43<11:36, 19.91s/epoch, loss=0.313, accuracy=0.95, val_loss=0.47, val_accuracy=0.899, lr=0.001]   80%|███████▉  | 132/166 [45:03<11:16, 19.91s/epoch, loss=0.307, accuracy=0.951, val_loss=0.457, val_accuracy=0.901, lr=0.001] 80%|████████  | 133/166 [45:23<10:56, 19.89s/epoch, loss=0.299, accuracy=0.953, val_loss=0.456, val_accuracy=0.903, lr=0.001] 81%|████████  | 134/166 [45:43<10:37, 19.94s/epoch, loss=0.293, accuracy=0.952, val_loss=0.458, val_accuracy=0.902, lr=0.001] 81%|████████▏ | 135/166 [46:03<10:16, 19.90s/epoch, loss=0.288, accuracy=0.953, val_loss=0.446, val_accuracy=0.904, lr=0.001] 82%|████████▏ | 136/166 [46:23<09:57, 19.93s/epoch, loss=0.28, accuracy=0.956, val_loss=0.444, val_accuracy=0.904, lr=0.001]  83%|████████▎ | 137/166 [46:43<09:38, 19.94s/epoch, loss=0.276, accuracy=0.955, val_loss=0.464, val_accuracy=0.9, lr=0.001]  83%|████████▎ | 138/166 [47:03<09:19, 19.98s/epoch, loss=0.267, accuracy=0.957, val_loss=0.468, val_accuracy=0.898, lr=0.001] 84%|████████▎ | 139/166 [47:23<08:57, 19.91s/epoch, loss=0.262, accuracy=0.959, val_loss=0.477, val_accuracy=0.895, lr=0.001] 84%|████████▍ | 140/166 [47:42<08:37, 19.90s/epoch, loss=0.259, accuracy=0.958, val_loss=0.46, val_accuracy=0.895, lr=0.001]  85%|████████▍ | 141/166 [48:02<08:16, 19.84s/epoch, loss=0.255, accuracy=0.958, val_loss=0.464, val_accuracy=0.899, lr=0.000316] 86%|████████▌ | 142/166 [48:22<07:57, 19.91s/epoch, loss=0.25, accuracy=0.96, val_loss=0.446, val_accuracy=0.899, lr=0.001]      86%|████████▌ | 143/166 [48:42<07:36, 19.86s/epoch, loss=0.246, accuracy=0.959, val_loss=0.455, val_accuracy=0.896, lr=0.001] 87%|████████▋ | 144/166 [49:02<07:16, 19.85s/epoch, loss=0.244, accuracy=0.959, val_loss=0.466, val_accuracy=0.896, lr=0.001] 87%|████████▋ | 145/166 [49:22<06:57, 19.88s/epoch, loss=0.241, accuracy=0.959, val_loss=0.458, val_accuracy=0.892, lr=0.001] 88%|████████▊ | 146/166 [49:42<06:37, 19.87s/epoch, loss=0.238, accuracy=0.96, val_loss=0.455, val_accuracy=0.898, lr=0.000316] 89%|████████▊ | 147/166 [50:02<06:18, 19.92s/epoch, loss=0.234, accuracy=0.96, val_loss=0.467, val_accuracy=0.89, lr=0.001]     89%|████████▉ | 148/166 [50:22<05:58, 19.92s/epoch, loss=0.233, accuracy=0.96, val_loss=0.478, val_accuracy=0.89, lr=0.001] 90%|████████▉ | 149/166 [50:42<05:39, 19.95s/epoch, loss=0.226, accuracy=0.962, val_loss=0.447, val_accuracy=0.895, lr=0.001] 90%|█████████ | 150/166 [51:02<05:20, 20.01s/epoch, loss=0.228, accuracy=0.96, val_loss=0.449, val_accuracy=0.896, lr=0.001]  91%|█████████ | 151/166 [51:22<05:00, 20.05s/epoch, loss=0.227, accuracy=0.96, val_loss=0.452, val_accuracy=0.891, lr=0.000316] 92%|█████████▏| 152/166 [51:42<04:40, 20.05s/epoch, loss=0.224, accuracy=0.96, val_loss=0.477, val_accuracy=0.892, lr=0.001]    92%|█████████▏| 153/166 [52:02<04:20, 20.04s/epoch, loss=0.222, accuracy=0.961, val_loss=0.459, val_accuracy=0.891, lr=0.001] 93%|█████████▎| 154/166 [52:22<04:00, 20.04s/epoch, loss=0.218, accuracy=0.962, val_loss=0.49, val_accuracy=0.888, lr=0.001]  93%|█████████▎| 155/166 [52:42<03:39, 20.00s/epoch, loss=0.221, accuracy=0.96, val_loss=0.527, val_accuracy=0.873, lr=0.001] 94%|█████████▍| 156/166 [53:02<03:19, 19.97s/epoch, loss=0.217, accuracy=0.962, val_loss=0.477, val_accuracy=0.892, lr=0.000316] 95%|█████████▍| 157/166 [53:22<02:59, 19.99s/epoch, loss=0.217, accuracy=0.961, val_loss=0.468, val_accuracy=0.887, lr=0.001]    95%|█████████▌| 158/166 [53:42<02:39, 19.90s/epoch, loss=0.217, accuracy=0.961, val_loss=0.496, val_accuracy=0.882, lr=0.001] 96%|█████████▌| 159/166 [54:01<02:19, 19.90s/epoch, loss=0.212, accuracy=0.962, val_loss=0.531, val_accuracy=0.873, lr=0.001] 96%|█████████▋| 160/166 [54:21<01:59, 19.86s/epoch, loss=0.214, accuracy=0.961, val_loss=0.533, val_accuracy=0.875, lr=0.001] 97%|█████████▋| 161/166 [54:41<01:39, 19.81s/epoch, loss=0.211, accuracy=0.961, val_loss=0.467, val_accuracy=0.889, lr=0.000316] 98%|█████████▊| 162/166 [55:01<01:19, 19.84s/epoch, loss=0.19, accuracy=0.97, val_loss=0.405, val_accuracy=0.907, lr=1e-04]      98%|█████████▊| 163/166 [55:21<00:59, 19.84s/epoch, loss=0.179, accuracy=0.974, val_loss=0.4, val_accuracy=0.908, lr=1e-04] 99%|█████████▉| 164/166 [55:40<00:39, 19.76s/epoch, loss=0.172, accuracy=0.977, val_loss=0.401, val_accuracy=0.911, lr=1e-04] 99%|█████████▉| 165/166 [56:00<00:19, 19.81s/epoch, loss=0.169, accuracy=0.979, val_loss=0.398, val_accuracy=0.909, lr=1e-04]100%|██████████| 166/166 [56:20<00:00, 19.79s/epoch, loss=0.167, accuracy=0.98, val_loss=0.4, val_accuracy=0.909, lr=1e-04]   100%|██████████| 166/166 [56:20<00:00, 20.36s/epoch, loss=0.167, accuracy=0.98, val_loss=0.4, val_accuracy=0.909, lr=1e-04]
Using real-time data augmentation.
Test score: 0.4001210331916809
Test accuracy: 0.9086999893188477


* * * Run SGD for ID = 9_8. * * *


2024-03-05 07:35:15.401151: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 07:35:17.928057: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 07:35:17.929163: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-05 07:35:17.966467: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-03-05 07:35:17.966511: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 07:35:17.969349: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 07:35:17.969386: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 07:35:17.971425: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 07:35:17.972075: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 07:35:17.974338: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 07:35:17.975753: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 07:35:17.980371: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 07:35:17.981010: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 07:35:17.981096: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 07:35:19.183923: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-05 07:35:19.184450: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 07:35:19.185208: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-03-05 07:35:19.185239: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 07:35:19.185275: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 07:35:19.185293: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 07:35:19.185308: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 07:35:19.185324: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 07:35:19.185340: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 07:35:19.185354: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 07:35:19.185370: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 07:35:19.185911: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 07:35:19.185943: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 07:35:19.806449: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-05 07:35:19.806505: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-05 07:35:19.806513: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-05 07:35:19.807410: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:02:00.0, compute capability: 6.1)
{'id': '09_08', 'seed': 8, 'out_folder': 'results/epoch_budget', 'batch_size': 128, 'epochs': 166, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'bootstrapping': False, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/166 [00:00<?, ?epoch/s]2024-03-05 07:35:20.637124: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-05 07:35:20.649115: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600020000 Hz
2024-03-05 07:35:22.576822: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 07:35:22.810100: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 07:35:23.583039: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-05 07:35:23.627768: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/166 [00:56<2:36:34, 56.94s/epoch, loss=2.84, accuracy=0.399, val_loss=1.84, val_accuracy=0.462, lr=0.1]  1%|          | 2/166 [01:17<1:36:52, 35.44s/epoch, loss=1.46, accuracy=0.584, val_loss=2.43, val_accuracy=0.362, lr=0.1]  2%|▏         | 3/166 [01:37<1:17:08, 28.40s/epoch, loss=1.3, accuracy=0.654, val_loss=2.36, val_accuracy=0.402, lr=0.1]   2%|▏         | 4/166 [01:57<1:07:47, 25.11s/epoch, loss=1.24, accuracy=0.688, val_loss=3.28, val_accuracy=0.34, lr=0.1]  3%|▎         | 5/166 [02:17<1:02:10, 23.17s/epoch, loss=1.22, accuracy=0.71, val_loss=1.86, val_accuracy=0.535, lr=0.1]  4%|▎         | 6/166 [02:37<58:47, 22.04s/epoch, loss=1.22, accuracy=0.714, val_loss=2.19, val_accuracy=0.384, lr=0.0316]  4%|▍         | 7/166 [02:57<56:47, 21.43s/epoch, loss=1.21, accuracy=0.724, val_loss=1.67, val_accuracy=0.554, lr=0.1]     5%|▍         | 8/166 [03:16<55:04, 20.92s/epoch, loss=1.21, accuracy=0.728, val_loss=1.82, val_accuracy=0.544, lr=0.1]  5%|▌         | 9/166 [03:37<54:14, 20.73s/epoch, loss=1.2, accuracy=0.734, val_loss=2.28, val_accuracy=0.468, lr=0.1]   6%|▌         | 10/166 [03:57<53:28, 20.57s/epoch, loss=1.19, accuracy=0.735, val_loss=1.67, val_accuracy=0.588, lr=0.1]  7%|▋         | 11/166 [04:17<52:36, 20.37s/epoch, loss=1.18, accuracy=0.741, val_loss=2.3, val_accuracy=0.471, lr=0.1]   7%|▋         | 12/166 [04:37<51:53, 20.22s/epoch, loss=1.18, accuracy=0.74, val_loss=2.63, val_accuracy=0.342, lr=0.1]  8%|▊         | 13/166 [04:57<51:33, 20.22s/epoch, loss=1.18, accuracy=0.743, val_loss=2.12, val_accuracy=0.504, lr=0.1]  8%|▊         | 14/166 [05:18<51:28, 20.32s/epoch, loss=1.17, accuracy=0.743, val_loss=2.25, val_accuracy=0.469, lr=0.1]  9%|▉         | 15/166 [05:38<51:15, 20.37s/epoch, loss=1.17, accuracy=0.744, val_loss=1.57, val_accuracy=0.602, lr=0.1] 10%|▉         | 16/166 [05:58<50:56, 20.38s/epoch, loss=1.16, accuracy=0.746, val_loss=2.54, val_accuracy=0.373, lr=0.1] 10%|█         | 17/166 [06:19<50:41, 20.41s/epoch, loss=1.16, accuracy=0.747, val_loss=1.93, val_accuracy=0.489, lr=0.1] 11%|█         | 18/166 [06:39<50:25, 20.44s/epoch, loss=1.15, accuracy=0.748, val_loss=1.95, val_accuracy=0.487, lr=0.1] 11%|█▏        | 19/166 [07:00<50:05, 20.45s/epoch, loss=1.15, accuracy=0.748, val_loss=2.12, val_accuracy=0.466, lr=0.1] 12%|█▏        | 20/166 [07:20<49:48, 20.47s/epoch, loss=1.16, accuracy=0.749, val_loss=2.3, val_accuracy=0.426, lr=0.0316] 13%|█▎        | 21/166 [07:41<49:28, 20.47s/epoch, loss=1.14, accuracy=0.75, val_loss=1.76, val_accuracy=0.552, lr=0.1]    13%|█▎        | 22/166 [08:01<49:10, 20.49s/epoch, loss=1.15, accuracy=0.75, val_loss=1.65, val_accuracy=0.562, lr=0.1] 14%|█▍        | 23/166 [08:22<48:52, 20.51s/epoch, loss=1.15, accuracy=0.752, val_loss=2.63, val_accuracy=0.314, lr=0.1] 14%|█▍        | 24/166 [08:43<48:33, 20.52s/epoch, loss=1.14, accuracy=0.754, val_loss=2.16, val_accuracy=0.388, lr=0.1] 15%|█▌        | 25/166 [09:03<48:15, 20.54s/epoch, loss=1.14, accuracy=0.751, val_loss=1.29, val_accuracy=0.696, lr=0.1] 16%|█▌        | 26/166 [09:24<47:49, 20.50s/epoch, loss=1.14, accuracy=0.752, val_loss=1.76, val_accuracy=0.57, lr=0.1]  16%|█▋        | 27/166 [09:44<47:25, 20.47s/epoch, loss=1.14, accuracy=0.751, val_loss=1.89, val_accuracy=0.49, lr=0.1] 17%|█▋        | 28/166 [10:04<47:06, 20.48s/epoch, loss=1.14, accuracy=0.751, val_loss=1.74, val_accuracy=0.546, lr=0.1] 17%|█▋        | 29/166 [10:25<46:42, 20.46s/epoch, loss=1.14, accuracy=0.753, val_loss=1.61, val_accuracy=0.613, lr=0.1] 18%|█▊        | 30/166 [10:45<46:20, 20.44s/epoch, loss=1.14, accuracy=0.753, val_loss=1.71, val_accuracy=0.553, lr=0.0316] 19%|█▊        | 31/166 [11:06<45:57, 20.42s/epoch, loss=1.14, accuracy=0.753, val_loss=1.37, val_accuracy=0.665, lr=0.1]    19%|█▉        | 32/166 [11:26<45:35, 20.41s/epoch, loss=1.14, accuracy=0.753, val_loss=2.43, val_accuracy=0.461, lr=0.1] 20%|█▉        | 33/166 [11:47<45:20, 20.46s/epoch, loss=1.13, accuracy=0.754, val_loss=4.37, val_accuracy=0.266, lr=0.1] 20%|██        | 34/166 [12:07<45:01, 20.47s/epoch, loss=1.13, accuracy=0.754, val_loss=2.21, val_accuracy=0.432, lr=0.1] 21%|██        | 35/166 [12:28<44:42, 20.48s/epoch, loss=1.13, accuracy=0.756, val_loss=1.54, val_accuracy=0.642, lr=0.0316] 22%|██▏       | 36/166 [12:48<44:27, 20.52s/epoch, loss=1.13, accuracy=0.757, val_loss=2.27, val_accuracy=0.456, lr=0.1]    22%|██▏       | 37/166 [13:09<44:02, 20.49s/epoch, loss=1.13, accuracy=0.758, val_loss=2.06, val_accuracy=0.477, lr=0.1] 23%|██▎       | 38/166 [13:29<43:46, 20.52s/epoch, loss=1.13, accuracy=0.755, val_loss=1.62, val_accuracy=0.59, lr=0.1]  23%|██▎       | 39/166 [13:50<43:19, 20.47s/epoch, loss=1.12, accuracy=0.758, val_loss=1.39, val_accuracy=0.657, lr=0.1] 24%|██▍       | 40/166 [14:10<42:52, 20.42s/epoch, loss=1.12, accuracy=0.754, val_loss=2.67, val_accuracy=0.407, lr=0.0316] 25%|██▍       | 41/166 [14:30<42:36, 20.45s/epoch, loss=1.13, accuracy=0.754, val_loss=1.73, val_accuracy=0.548, lr=0.1]    25%|██▌       | 42/166 [14:51<42:16, 20.46s/epoch, loss=1.12, accuracy=0.757, val_loss=4.13, val_accuracy=0.213, lr=0.1] 26%|██▌       | 43/166 [15:11<41:59, 20.48s/epoch, loss=1.12, accuracy=0.755, val_loss=1.93, val_accuracy=0.472, lr=0.1] 27%|██▋       | 44/166 [15:32<41:46, 20.54s/epoch, loss=1.12, accuracy=0.76, val_loss=1.87, val_accuracy=0.559, lr=0.1]  27%|██▋       | 45/166 [15:53<41:29, 20.57s/epoch, loss=1.13, accuracy=0.753, val_loss=1.64, val_accuracy=0.611, lr=0.0316] 28%|██▊       | 46/166 [16:13<41:09, 20.58s/epoch, loss=1.12, accuracy=0.757, val_loss=1.51, val_accuracy=0.606, lr=0.1]    28%|██▊       | 47/166 [16:34<40:48, 20.58s/epoch, loss=1.12, accuracy=0.756, val_loss=3.16, val_accuracy=0.406, lr=0.1] 29%|██▉       | 48/166 [16:55<40:31, 20.60s/epoch, loss=1.12, accuracy=0.759, val_loss=2.49, val_accuracy=0.421, lr=0.1] 30%|██▉       | 49/166 [17:15<40:12, 20.62s/epoch, loss=1.12, accuracy=0.758, val_loss=1.79, val_accuracy=0.553, lr=0.1] 30%|███       | 50/166 [17:36<39:51, 20.61s/epoch, loss=1.12, accuracy=0.759, val_loss=2.06, val_accuracy=0.424, lr=0.0316] 31%|███       | 51/166 [17:56<39:16, 20.49s/epoch, loss=1.13, accuracy=0.756, val_loss=2.72, val_accuracy=0.344, lr=0.1]    31%|███▏      | 52/166 [18:17<38:56, 20.49s/epoch, loss=1.11, accuracy=0.761, val_loss=1.43, val_accuracy=0.655, lr=0.1] 32%|███▏      | 53/166 [18:37<38:44, 20.57s/epoch, loss=1.12, accuracy=0.757, val_loss=3.92, val_accuracy=0.251, lr=0.1] 33%|███▎      | 54/166 [18:58<38:33, 20.66s/epoch, loss=1.12, accuracy=0.758, val_loss=2.88, val_accuracy=0.431, lr=0.1] 33%|███▎      | 55/166 [19:19<38:12, 20.65s/epoch, loss=1.12, accuracy=0.757, val_loss=2.34, val_accuracy=0.455, lr=0.0316] 34%|███▎      | 56/166 [19:39<37:38, 20.53s/epoch, loss=1.11, accuracy=0.759, val_loss=2.23, val_accuracy=0.484, lr=0.1]    34%|███▍      | 57/166 [19:59<37:13, 20.49s/epoch, loss=1.12, accuracy=0.761, val_loss=2.4, val_accuracy=0.345, lr=0.1]  35%|███▍      | 58/166 [20:20<36:42, 20.39s/epoch, loss=1.11, accuracy=0.759, val_loss=2.24, val_accuracy=0.433, lr=0.1] 36%|███▌      | 59/166 [20:40<36:24, 20.42s/epoch, loss=1.12, accuracy=0.76, val_loss=1.88, val_accuracy=0.521, lr=0.1]  36%|███▌      | 60/166 [21:00<36:04, 20.42s/epoch, loss=1.11, accuracy=0.759, val_loss=1.76, val_accuracy=0.552, lr=0.0316] 37%|███▋      | 61/166 [21:21<35:38, 20.37s/epoch, loss=1.12, accuracy=0.756, val_loss=1.8, val_accuracy=0.534, lr=0.1]     37%|███▋      | 62/166 [21:41<35:18, 20.37s/epoch, loss=1.12, accuracy=0.758, val_loss=2.46, val_accuracy=0.348, lr=0.1] 38%|███▊      | 63/166 [22:01<34:57, 20.37s/epoch, loss=1.12, accuracy=0.76, val_loss=4.41, val_accuracy=0.211, lr=0.1]  39%|███▊      | 64/166 [22:22<34:34, 20.34s/epoch, loss=1.12, accuracy=0.758, val_loss=2.06, val_accuracy=0.494, lr=0.1] 39%|███▉      | 65/166 [22:42<34:10, 20.30s/epoch, loss=1.11, accuracy=0.758, val_loss=1.74, val_accuracy=0.531, lr=0.0316] 40%|███▉      | 66/166 [23:02<33:55, 20.35s/epoch, loss=1.11, accuracy=0.759, val_loss=4.96, val_accuracy=0.278, lr=0.1]    40%|████      | 67/166 [23:23<33:31, 20.32s/epoch, loss=1.11, accuracy=0.759, val_loss=4.18, val_accuracy=0.338, lr=0.1] 41%|████      | 68/166 [23:43<33:08, 20.29s/epoch, loss=1.11, accuracy=0.759, val_loss=2.55, val_accuracy=0.407, lr=0.1] 42%|████▏     | 69/166 [24:03<32:43, 20.24s/epoch, loss=1.11, accuracy=0.759, val_loss=3.74, val_accuracy=0.362, lr=0.1] 42%|████▏     | 70/166 [24:23<32:28, 20.30s/epoch, loss=1.11, accuracy=0.758, val_loss=1.91, val_accuracy=0.52, lr=0.0316] 43%|████▎     | 71/166 [24:44<32:02, 20.23s/epoch, loss=1.11, accuracy=0.76, val_loss=4.11, val_accuracy=0.206, lr=0.1]    43%|████▎     | 72/166 [25:04<31:35, 20.17s/epoch, loss=1.11, accuracy=0.759, val_loss=3.05, val_accuracy=0.366, lr=0.1] 44%|████▍     | 73/166 [25:24<31:13, 20.14s/epoch, loss=1.11, accuracy=0.756, val_loss=1.65, val_accuracy=0.627, lr=0.1] 45%|████▍     | 74/166 [25:44<30:49, 20.11s/epoch, loss=1.12, accuracy=0.757, val_loss=1.63, val_accuracy=0.606, lr=0.1] 45%|████▌     | 75/166 [26:04<30:30, 20.11s/epoch, loss=1.11, accuracy=0.759, val_loss=2.01, val_accuracy=0.474, lr=0.0316] 46%|████▌     | 76/166 [26:24<30:13, 20.15s/epoch, loss=1.11, accuracy=0.761, val_loss=1.46, val_accuracy=0.652, lr=0.1]    46%|████▋     | 77/166 [26:44<29:53, 20.16s/epoch, loss=1.11, accuracy=0.757, val_loss=4.26, val_accuracy=0.275, lr=0.1] 47%|████▋     | 78/166 [27:04<29:36, 20.18s/epoch, loss=1.1, accuracy=0.761, val_loss=1.98, val_accuracy=0.464, lr=0.1]  48%|████▊     | 79/166 [27:25<29:18, 20.22s/epoch, loss=1.1, accuracy=0.764, val_loss=1.71, val_accuracy=0.59, lr=0.1]  48%|████▊     | 80/166 [27:45<29:02, 20.27s/epoch, loss=1.1, accuracy=0.762, val_loss=2.88, val_accuracy=0.415, lr=0.0316] 49%|████▉     | 81/166 [28:05<28:40, 20.24s/epoch, loss=1.1, accuracy=0.759, val_loss=3.03, val_accuracy=0.332, lr=0.1]    49%|████▉     | 82/166 [28:26<28:23, 20.28s/epoch, loss=0.895, accuracy=0.822, val_loss=0.902, val_accuracy=0.798, lr=0.01] 50%|█████     | 83/166 [28:46<28:03, 20.28s/epoch, loss=0.723, accuracy=0.849, val_loss=0.793, val_accuracy=0.813, lr=0.01] 51%|█████     | 84/166 [29:06<27:43, 20.29s/epoch, loss=0.643, accuracy=0.858, val_loss=0.73, val_accuracy=0.824, lr=0.01]  51%|█████     | 85/166 [29:26<27:21, 20.27s/epoch, loss=0.6, accuracy=0.861, val_loss=0.694, val_accuracy=0.824, lr=0.01]  52%|█████▏    | 86/166 [29:47<26:59, 20.25s/epoch, loss=0.578, accuracy=0.862, val_loss=0.891, val_accuracy=0.759, lr=0.01] 52%|█████▏    | 87/166 [30:07<26:32, 20.16s/epoch, loss=0.567, accuracy=0.863, val_loss=0.87, val_accuracy=0.783, lr=0.01]  53%|█████▎    | 88/166 [30:27<26:12, 20.17s/epoch, loss=0.562, accuracy=0.864, val_loss=0.851, val_accuracy=0.779, lr=0.01] 54%|█████▎    | 89/166 [30:47<25:50, 20.13s/epoch, loss=0.558, accuracy=0.866, val_loss=0.718, val_accuracy=0.811, lr=0.01] 54%|█████▍    | 90/166 [31:07<25:31, 20.15s/epoch, loss=0.554, accuracy=0.867, val_loss=0.728, val_accuracy=0.809, lr=0.00316] 55%|█████▍    | 91/166 [31:27<25:09, 20.13s/epoch, loss=0.552, accuracy=0.871, val_loss=1.01, val_accuracy=0.746, lr=0.01]     55%|█████▌    | 92/166 [31:47<24:54, 20.19s/epoch, loss=0.553, accuracy=0.869, val_loss=0.974, val_accuracy=0.741, lr=0.01] 56%|█████▌    | 93/166 [32:08<24:33, 20.18s/epoch, loss=0.552, accuracy=0.873, val_loss=0.743, val_accuracy=0.813, lr=0.01] 57%|█████▋    | 94/166 [32:28<24:09, 20.14s/epoch, loss=0.552, accuracy=0.872, val_loss=0.818, val_accuracy=0.795, lr=0.01] 57%|█████▋    | 95/166 [32:48<23:49, 20.14s/epoch, loss=0.553, accuracy=0.872, val_loss=0.84, val_accuracy=0.785, lr=0.00316] 58%|█████▊    | 96/166 [33:08<23:32, 20.18s/epoch, loss=0.55, accuracy=0.875, val_loss=0.806, val_accuracy=0.792, lr=0.01]    58%|█████▊    | 97/166 [33:28<23:11, 20.17s/epoch, loss=0.549, accuracy=0.876, val_loss=0.719, val_accuracy=0.827, lr=0.01] 59%|█████▉    | 98/166 [33:48<22:54, 20.21s/epoch, loss=0.554, accuracy=0.874, val_loss=0.915, val_accuracy=0.773, lr=0.01] 60%|█████▉    | 99/166 [34:09<22:33, 20.20s/epoch, loss=0.548, accuracy=0.877, val_loss=0.925, val_accuracy=0.767, lr=0.01] 60%|██████    | 100/166 [34:29<22:18, 20.29s/epoch, loss=0.549, accuracy=0.879, val_loss=0.733, val_accuracy=0.821, lr=0.00316] 61%|██████    | 101/166 [34:49<21:55, 20.24s/epoch, loss=0.548, accuracy=0.877, val_loss=0.721, val_accuracy=0.825, lr=0.01]    61%|██████▏   | 102/166 [35:09<21:34, 20.22s/epoch, loss=0.547, accuracy=0.878, val_loss=0.705, val_accuracy=0.826, lr=0.01] 62%|██████▏   | 103/166 [35:30<21:17, 20.28s/epoch, loss=0.544, accuracy=0.88, val_loss=0.806, val_accuracy=0.791, lr=0.01]  63%|██████▎   | 104/166 [35:50<20:55, 20.25s/epoch, loss=0.552, accuracy=0.878, val_loss=0.762, val_accuracy=0.806, lr=0.01] 63%|██████▎   | 105/166 [36:10<20:32, 20.20s/epoch, loss=0.55, accuracy=0.881, val_loss=0.865, val_accuracy=0.796, lr=0.00316] 64%|██████▍   | 106/166 [36:30<20:07, 20.12s/epoch, loss=0.546, accuracy=0.881, val_loss=0.929, val_accuracy=0.772, lr=0.01]   64%|██████▍   | 107/166 [36:50<19:45, 20.09s/epoch, loss=0.546, accuracy=0.882, val_loss=0.908, val_accuracy=0.769, lr=0.01] 65%|██████▌   | 108/166 [37:10<19:27, 20.12s/epoch, loss=0.548, accuracy=0.881, val_loss=0.968, val_accuracy=0.775, lr=0.01] 66%|██████▌   | 109/166 [37:31<19:08, 20.14s/epoch, loss=0.548, accuracy=0.881, val_loss=0.889, val_accuracy=0.789, lr=0.01] 66%|██████▋   | 110/166 [37:50<18:45, 20.10s/epoch, loss=0.55, accuracy=0.882, val_loss=0.814, val_accuracy=0.794, lr=0.00316] 67%|██████▋   | 111/166 [38:11<18:28, 20.16s/epoch, loss=0.546, accuracy=0.882, val_loss=0.823, val_accuracy=0.801, lr=0.01]   67%|██████▋   | 112/166 [38:31<18:09, 20.18s/epoch, loss=0.544, accuracy=0.885, val_loss=1.04, val_accuracy=0.76, lr=0.01]   68%|██████▊   | 113/166 [38:51<17:51, 20.21s/epoch, loss=0.548, accuracy=0.883, val_loss=1.12, val_accuracy=0.716, lr=0.01] 69%|██████▊   | 114/166 [39:12<17:32, 20.23s/epoch, loss=0.554, accuracy=0.88, val_loss=0.866, val_accuracy=0.79, lr=0.01]  69%|██████▉   | 115/166 [39:32<17:11, 20.23s/epoch, loss=0.549, accuracy=0.884, val_loss=0.949, val_accuracy=0.772, lr=0.00316] 70%|██████▉   | 116/166 [39:52<16:52, 20.25s/epoch, loss=0.546, accuracy=0.886, val_loss=0.828, val_accuracy=0.798, lr=0.01]    70%|███████   | 117/166 [40:12<16:32, 20.26s/epoch, loss=0.543, accuracy=0.884, val_loss=0.863, val_accuracy=0.796, lr=0.01] 71%|███████   | 118/166 [40:33<16:11, 20.23s/epoch, loss=0.546, accuracy=0.886, val_loss=0.957, val_accuracy=0.75, lr=0.01]  72%|███████▏  | 119/166 [40:53<15:50, 20.22s/epoch, loss=0.55, accuracy=0.883, val_loss=0.874, val_accuracy=0.786, lr=0.01] 72%|███████▏  | 120/166 [41:13<15:29, 20.20s/epoch, loss=0.546, accuracy=0.885, val_loss=0.811, val_accuracy=0.804, lr=0.00316] 73%|███████▎  | 121/166 [41:33<15:07, 20.18s/epoch, loss=0.55, accuracy=0.886, val_loss=0.763, val_accuracy=0.822, lr=0.01]     73%|███████▎  | 122/166 [41:53<14:49, 20.21s/epoch, loss=0.477, accuracy=0.91, val_loss=0.539, val_accuracy=0.89, lr=0.001] 74%|███████▍  | 123/166 [42:14<14:29, 20.22s/epoch, loss=0.421, accuracy=0.927, val_loss=0.523, val_accuracy=0.895, lr=0.001] 75%|███████▍  | 124/166 [42:34<14:10, 20.26s/epoch, loss=0.398, accuracy=0.934, val_loss=0.51, val_accuracy=0.897, lr=0.001]  75%|███████▌  | 125/166 [42:54<13:49, 20.23s/epoch, loss=0.381, accuracy=0.937, val_loss=0.509, val_accuracy=0.895, lr=0.001] 76%|███████▌  | 126/166 [43:14<13:30, 20.27s/epoch, loss=0.367, accuracy=0.941, val_loss=0.495, val_accuracy=0.898, lr=0.001] 77%|███████▋  | 127/166 [43:35<13:09, 20.24s/epoch, loss=0.358, accuracy=0.941, val_loss=0.49, val_accuracy=0.899, lr=0.001]  77%|███████▋  | 128/166 [43:55<12:47, 20.19s/epoch, loss=0.347, accuracy=0.945, val_loss=0.5, val_accuracy=0.897, lr=0.001]  78%|███████▊  | 129/166 [44:15<12:26, 20.18s/epoch, loss=0.339, accuracy=0.945, val_loss=0.479, val_accuracy=0.901, lr=0.001] 78%|███████▊  | 130/166 [44:35<12:05, 20.15s/epoch, loss=0.328, accuracy=0.948, val_loss=0.481, val_accuracy=0.899, lr=0.001] 79%|███████▉  | 131/166 [44:55<11:47, 20.23s/epoch, loss=0.318, accuracy=0.95, val_loss=0.478, val_accuracy=0.898, lr=0.001]  80%|███████▉  | 132/166 [45:15<11:26, 20.19s/epoch, loss=0.311, accuracy=0.951, val_loss=0.481, val_accuracy=0.895, lr=0.001] 80%|████████  | 133/166 [45:35<11:04, 20.14s/epoch, loss=0.302, accuracy=0.952, val_loss=0.473, val_accuracy=0.9, lr=0.001]   81%|████████  | 134/166 [45:56<10:44, 20.13s/epoch, loss=0.296, accuracy=0.952, val_loss=0.458, val_accuracy=0.902, lr=0.001] 81%|████████▏ | 135/166 [46:16<10:25, 20.18s/epoch, loss=0.289, accuracy=0.953, val_loss=0.462, val_accuracy=0.897, lr=0.001] 82%|████████▏ | 136/166 [46:36<10:03, 20.13s/epoch, loss=0.284, accuracy=0.955, val_loss=0.463, val_accuracy=0.9, lr=0.001]   83%|████████▎ | 137/166 [46:56<09:42, 20.10s/epoch, loss=0.278, accuracy=0.955, val_loss=0.467, val_accuracy=0.901, lr=0.001] 83%|████████▎ | 138/166 [47:16<09:22, 20.09s/epoch, loss=0.271, accuracy=0.956, val_loss=0.472, val_accuracy=0.899, lr=0.001] 84%|████████▎ | 139/166 [47:36<09:02, 20.08s/epoch, loss=0.263, accuracy=0.958, val_loss=0.47, val_accuracy=0.896, lr=0.000316] 84%|████████▍ | 140/166 [47:56<08:42, 20.08s/epoch, loss=0.26, accuracy=0.958, val_loss=0.462, val_accuracy=0.899, lr=0.001]    85%|████████▍ | 141/166 [48:16<08:23, 20.14s/epoch, loss=0.257, accuracy=0.958, val_loss=0.459, val_accuracy=0.9, lr=0.001]  86%|████████▌ | 142/166 [48:37<08:03, 20.16s/epoch, loss=0.251, accuracy=0.96, val_loss=0.472, val_accuracy=0.896, lr=0.001] 86%|████████▌ | 143/166 [48:57<07:43, 20.15s/epoch, loss=0.246, accuracy=0.959, val_loss=0.48, val_accuracy=0.895, lr=0.001] 87%|████████▋ | 144/166 [49:17<07:22, 20.11s/epoch, loss=0.243, accuracy=0.961, val_loss=0.47, val_accuracy=0.893, lr=0.000316] 87%|████████▋ | 145/166 [49:37<07:01, 20.08s/epoch, loss=0.241, accuracy=0.96, val_loss=0.54, val_accuracy=0.879, lr=0.001]     88%|████████▊ | 146/166 [49:57<06:41, 20.07s/epoch, loss=0.235, accuracy=0.962, val_loss=0.472, val_accuracy=0.89, lr=0.001] 89%|████████▊ | 147/166 [50:17<06:22, 20.12s/epoch, loss=0.234, accuracy=0.961, val_loss=0.494, val_accuracy=0.884, lr=0.001] 89%|████████▉ | 148/166 [50:37<06:02, 20.13s/epoch, loss=0.232, accuracy=0.962, val_loss=0.448, val_accuracy=0.896, lr=0.001] 90%|████████▉ | 149/166 [50:57<05:42, 20.13s/epoch, loss=0.229, accuracy=0.962, val_loss=0.458, val_accuracy=0.891, lr=0.001] 90%|█████████ | 150/166 [51:17<05:21, 20.12s/epoch, loss=0.23, accuracy=0.96, val_loss=0.46, val_accuracy=0.892, lr=0.001]    91%|█████████ | 151/166 [51:37<05:01, 20.07s/epoch, loss=0.228, accuracy=0.96, val_loss=0.46, val_accuracy=0.892, lr=0.001] 92%|█████████▏| 152/166 [51:58<04:41, 20.09s/epoch, loss=0.222, accuracy=0.962, val_loss=0.457, val_accuracy=0.894, lr=0.001] 92%|█████████▏| 153/166 [52:17<04:19, 19.99s/epoch, loss=0.22, accuracy=0.962, val_loss=0.485, val_accuracy=0.891, lr=0.000316] 93%|█████████▎| 154/166 [52:38<04:00, 20.07s/epoch, loss=0.22, accuracy=0.962, val_loss=0.603, val_accuracy=0.86, lr=0.001]     93%|█████████▎| 155/166 [52:58<03:41, 20.09s/epoch, loss=0.223, accuracy=0.96, val_loss=0.508, val_accuracy=0.883, lr=0.001] 94%|█████████▍| 156/166 [53:18<03:20, 20.07s/epoch, loss=0.219, accuracy=0.961, val_loss=0.54, val_accuracy=0.876, lr=0.001] 95%|█████████▍| 157/166 [53:38<03:00, 20.01s/epoch, loss=0.217, accuracy=0.962, val_loss=0.498, val_accuracy=0.883, lr=0.001] 95%|█████████▌| 158/166 [53:58<02:40, 20.04s/epoch, loss=0.217, accuracy=0.962, val_loss=0.468, val_accuracy=0.892, lr=0.000316] 96%|█████████▌| 159/166 [54:18<02:20, 20.04s/epoch, loss=0.213, accuracy=0.962, val_loss=0.513, val_accuracy=0.877, lr=0.001]    96%|█████████▋| 160/166 [54:38<02:00, 20.02s/epoch, loss=0.214, accuracy=0.962, val_loss=0.482, val_accuracy=0.883, lr=0.001] 97%|█████████▋| 161/166 [54:58<01:40, 20.03s/epoch, loss=0.213, accuracy=0.961, val_loss=0.506, val_accuracy=0.882, lr=0.001] 98%|█████████▊| 162/166 [55:18<01:20, 20.03s/epoch, loss=0.195, accuracy=0.969, val_loss=0.415, val_accuracy=0.906, lr=1e-04] 98%|█████████▊| 163/166 [55:38<01:00, 20.03s/epoch, loss=0.179, accuracy=0.976, val_loss=0.412, val_accuracy=0.907, lr=1e-04] 99%|█████████▉| 164/166 [55:58<00:40, 20.02s/epoch, loss=0.173, accuracy=0.978, val_loss=0.41, val_accuracy=0.907, lr=1e-04]  99%|█████████▉| 165/166 [56:18<00:20, 20.05s/epoch, loss=0.17, accuracy=0.979, val_loss=0.412, val_accuracy=0.909, lr=1e-04]100%|██████████| 166/166 [56:38<00:00, 20.09s/epoch, loss=0.167, accuracy=0.979, val_loss=0.411, val_accuracy=0.909, lr=1e-04]100%|██████████| 166/166 [56:38<00:00, 20.47s/epoch, loss=0.167, accuracy=0.979, val_loss=0.411, val_accuracy=0.909, lr=1e-04]
Using real-time data augmentation.
Test score: 0.41055312752723694
Test accuracy: 0.9085999727249146


* * * Run SGD for ID = 9_9. * * *


2024-03-05 08:32:03.066788: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 08:32:05.615707: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 08:32:05.616748: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2024-03-05 08:32:05.664232: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-03-05 08:32:05.664277: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 08:32:05.667019: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 08:32:05.667075: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 08:32:05.669439: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 08:32:05.670105: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 08:32:05.672502: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 08:32:05.673869: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 08:32:05.678296: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 08:32:05.678895: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 08:32:05.679019: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 08:32:06.922227: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-05 08:32:06.923207: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2024-03-05 08:32:06.923927: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2024-03-05 08:32:06.923965: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 08:32:06.924001: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 08:32:06.924019: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2024-03-05 08:32:06.924034: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2024-03-05 08:32:06.924050: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2024-03-05 08:32:06.924065: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2024-03-05 08:32:06.924080: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2024-03-05 08:32:06.924095: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 08:32:06.924519: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2024-03-05 08:32:06.924550: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2024-03-05 08:32:07.584345: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-03-05 08:32:07.584407: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2024-03-05 08:32:07.584416: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2024-03-05 08:32:07.585333: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11227 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:02:00.0, compute capability: 6.1)
{'id': '09_09', 'seed': 9, 'out_folder': 'results/epoch_budget', 'batch_size': 128, 'epochs': 166, 'validation_split': 0.0, 'checkpointing': False, 'data_augmentation': True, 'augm_shift': 4, 'initial_lr': 0.1, 'l2_reg': 0.002, 'optimizer': 'sgd', 'momentum': 0.9, 'nesterov': True, 'bootstrapping': False, 'model': 'ResNet20v1', 'tf_version': '2.4.1', 'keras_version': '2.4.3', 'GPU': 'NVIDIA TITAN X (Pascal)'}
Using test set as validation set
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 validation samples
10000 test samples
y_train shape: (50000, 1)
ResNet20v1
0epoch [00:00, ?epoch/s]  0%|          | 0/166 [00:00<?, ?epoch/s]2024-03-05 08:32:08.450663: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2024-03-05 08:32:08.463123: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600020000 Hz
2024-03-05 08:32:10.454599: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2024-03-05 08:32:10.654028: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2024-03-05 08:32:11.357288: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2024-03-05 08:32:11.426508: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
  1%|          | 1/166 [01:03<2:55:42, 63.89s/epoch, loss=2.86, accuracy=0.391, val_loss=2.14, val_accuracy=0.325, lr=0.1]  1%|          | 2/166 [01:24<1:45:01, 38.42s/epoch, loss=1.45, accuracy=0.588, val_loss=3.08, val_accuracy=0.298, lr=0.1]  2%|▏         | 3/166 [01:44<1:22:06, 30.22s/epoch, loss=1.28, accuracy=0.668, val_loss=3, val_accuracy=0.323, lr=0.1]     2%|▏         | 4/166 [02:05<1:11:12, 26.37s/epoch, loss=1.23, accuracy=0.702, val_loss=2.65, val_accuracy=0.444, lr=0.1]  3%|▎         | 5/166 [02:25<1:04:58, 24.22s/epoch, loss=1.22, accuracy=0.711, val_loss=2.59, val_accuracy=0.345, lr=0.1]  4%|▎         | 6/166 [02:46<1:01:16, 22.98s/epoch, loss=1.2, accuracy=0.724, val_loss=1.77, val_accuracy=0.543, lr=0.1]   4%|▍         | 7/166 [03:06<58:37, 22.12s/epoch, loss=1.2, accuracy=0.727, val_loss=1.72, val_accuracy=0.556, lr=0.1]    5%|▍         | 8/166 [03:27<56:53, 21.60s/epoch, loss=1.19, accuracy=0.732, val_loss=2.53, val_accuracy=0.334, lr=0.1]  5%|▌         | 9/166 [03:47<55:29, 21.21s/epoch, loss=1.18, accuracy=0.735, val_loss=1.86, val_accuracy=0.52, lr=0.1]   6%|▌         | 10/166 [04:07<54:22, 20.91s/epoch, loss=1.18, accuracy=0.738, val_loss=1.93, val_accuracy=0.513, lr=0.1]  7%|▋         | 11/166 [04:28<53:30, 20.71s/epoch, loss=1.18, accuracy=0.739, val_loss=1.98, val_accuracy=0.447, lr=0.1]  7%|▋         | 12/166 [04:48<52:47, 20.57s/epoch, loss=1.17, accuracy=0.742, val_loss=2.29, val_accuracy=0.449, lr=0.0316]  8%|▊         | 13/166 [05:08<52:14, 20.49s/epoch, loss=1.17, accuracy=0.744, val_loss=2.76, val_accuracy=0.374, lr=0.1]     8%|▊         | 14/166 [05:28<51:48, 20.45s/epoch, loss=1.17, accuracy=0.744, val_loss=2.09, val_accuracy=0.499, lr=0.1]  9%|▉         | 15/166 [05:49<51:24, 20.42s/epoch, loss=1.16, accuracy=0.745, val_loss=1.91, val_accuracy=0.502, lr=0.1] 10%|▉         | 16/166 [06:09<50:56, 20.38s/epoch, loss=1.16, accuracy=0.746, val_loss=2.74, val_accuracy=0.346, lr=0.1] 10%|█         | 17/166 [06:30<50:54, 20.50s/epoch, loss=1.16, accuracy=0.747, val_loss=3.33, val_accuracy=0.304, lr=0.0316] 11%|█         | 18/166 [06:50<50:31, 20.48s/epoch, loss=1.16, accuracy=0.745, val_loss=1.44, val_accuracy=0.657, lr=0.1]    11%|█▏        | 19/166 [07:11<50:03, 20.43s/epoch, loss=1.15, accuracy=0.748, val_loss=1.97, val_accuracy=0.526, lr=0.1] 12%|█▏        | 20/166 [07:31<49:41, 20.42s/epoch, loss=1.15, accuracy=0.75, val_loss=3.96, val_accuracy=0.283, lr=0.1]  13%|█▎        | 21/166 [07:51<49:17, 20.40s/epoch, loss=1.15, accuracy=0.75, val_loss=1.34, val_accuracy=0.688, lr=0.1] 13%|█▎        | 22/166 [08:12<49:00, 20.42s/epoch, loss=1.15, accuracy=0.749, val_loss=2, val_accuracy=0.486, lr=0.1]   14%|█▍        | 23/166 [08:32<48:39, 20.42s/epoch, loss=1.13, accuracy=0.753, val_loss=2.26, val_accuracy=0.47, lr=0.1] 14%|█▍        | 24/166 [08:53<48:20, 20.43s/epoch, loss=1.14, accuracy=0.749, val_loss=3.38, val_accuracy=0.356, lr=0.1] 15%|█▌        | 25/166 [09:13<47:58, 20.41s/epoch, loss=1.14, accuracy=0.75, val_loss=2.28, val_accuracy=0.417, lr=0.1]  16%|█▌        | 26/166 [09:34<47:39, 20.43s/epoch, loss=1.14, accuracy=0.75, val_loss=1.32, val_accuracy=0.69, lr=0.1]  16%|█▋        | 27/166 [09:54<47:18, 20.42s/epoch, loss=1.13, accuracy=0.753, val_loss=1.97, val_accuracy=0.5, lr=0.1] 17%|█▋        | 28/166 [10:14<46:55, 20.40s/epoch, loss=1.13, accuracy=0.752, val_loss=2.5, val_accuracy=0.368, lr=0.1] 17%|█▋        | 29/166 [10:34<46:22, 20.31s/epoch, loss=1.13, accuracy=0.752, val_loss=1.6, val_accuracy=0.578, lr=0.1] 18%|█▊        | 30/166 [10:55<46:10, 20.37s/epoch, loss=1.13, accuracy=0.751, val_loss=3.69, val_accuracy=0.315, lr=0.1] 19%|█▊        | 31/166 [11:15<45:48, 20.36s/epoch, loss=1.12, accuracy=0.757, val_loss=2.06, val_accuracy=0.515, lr=0.0316] 19%|█▉        | 32/166 [11:36<45:33, 20.40s/epoch, loss=1.13, accuracy=0.755, val_loss=1.99, val_accuracy=0.506, lr=0.1]    20%|█▉        | 33/166 [11:56<44:58, 20.29s/epoch, loss=1.13, accuracy=0.754, val_loss=2.5, val_accuracy=0.474, lr=0.1]  20%|██        | 34/166 [12:16<44:29, 20.22s/epoch, loss=1.13, accuracy=0.752, val_loss=1.63, val_accuracy=0.597, lr=0.1] 21%|██        | 35/166 [12:36<44:11, 20.24s/epoch, loss=1.12, accuracy=0.755, val_loss=1.57, val_accuracy=0.623, lr=0.1] 22%|██▏       | 36/166 [12:56<43:49, 20.23s/epoch, loss=1.12, accuracy=0.755, val_loss=1.81, val_accuracy=0.53, lr=0.0316] 22%|██▏       | 37/166 [13:17<43:28, 20.22s/epoch, loss=1.12, accuracy=0.755, val_loss=1.59, val_accuracy=0.613, lr=0.1]   23%|██▎       | 38/166 [13:37<43:08, 20.22s/epoch, loss=1.12, accuracy=0.755, val_loss=2.47, val_accuracy=0.429, lr=0.1] 23%|██▎       | 39/166 [13:57<42:50, 20.24s/epoch, loss=1.13, accuracy=0.755, val_loss=3.3, val_accuracy=0.256, lr=0.1]  24%|██▍       | 40/166 [14:17<42:24, 20.19s/epoch, loss=1.12, accuracy=0.755, val_loss=3.11, val_accuracy=0.353, lr=0.1] 25%|██▍       | 41/166 [14:37<41:57, 20.14s/epoch, loss=1.11, accuracy=0.759, val_loss=2.83, val_accuracy=0.353, lr=0.0316] 25%|██▌       | 42/166 [14:57<41:38, 20.15s/epoch, loss=1.11, accuracy=0.759, val_loss=1.52, val_accuracy=0.612, lr=0.1]    26%|██▌       | 43/166 [15:18<41:25, 20.21s/epoch, loss=1.11, accuracy=0.756, val_loss=3.78, val_accuracy=0.25, lr=0.1]  27%|██▋       | 44/166 [15:38<41:19, 20.32s/epoch, loss=1.12, accuracy=0.756, val_loss=2.56, val_accuracy=0.38, lr=0.1] 27%|██▋       | 45/166 [15:59<41:00, 20.33s/epoch, loss=1.12, accuracy=0.756, val_loss=1.72, val_accuracy=0.573, lr=0.1] 28%|██▊       | 46/166 [16:19<40:39, 20.33s/epoch, loss=1.11, accuracy=0.755, val_loss=3.21, val_accuracy=0.179, lr=0.0316] 28%|██▊       | 47/166 [16:39<40:19, 20.33s/epoch, loss=1.11, accuracy=0.756, val_loss=2.38, val_accuracy=0.477, lr=0.1]    29%|██▉       | 48/166 [17:00<39:59, 20.34s/epoch, loss=1.12, accuracy=0.756, val_loss=1.45, val_accuracy=0.651, lr=0.1] 30%|██▉       | 49/166 [17:20<39:35, 20.30s/epoch, loss=1.11, accuracy=0.756, val_loss=1.74, val_accuracy=0.51, lr=0.1]  30%|███       | 50/166 [17:40<39:12, 20.28s/epoch, loss=1.11, accuracy=0.758, val_loss=1.85, val_accuracy=0.555, lr=0.1] 31%|███       | 51/166 [18:00<38:52, 20.28s/epoch, loss=1.11, accuracy=0.76, val_loss=1.76, val_accuracy=0.532, lr=0.0316] 31%|███▏      | 52/166 [18:21<38:31, 20.27s/epoch, loss=1.12, accuracy=0.758, val_loss=1.9, val_accuracy=0.483, lr=0.1]    32%|███▏      | 53/166 [18:41<38:13, 20.29s/epoch, loss=1.11, accuracy=0.757, val_loss=3.25, val_accuracy=0.37, lr=0.1] 33%|███▎      | 54/166 [19:01<37:48, 20.25s/epoch, loss=1.11, accuracy=0.759, val_loss=1.68, val_accuracy=0.602, lr=0.1] 33%|███▎      | 55/166 [19:22<37:38, 20.35s/epoch, loss=1.11, accuracy=0.757, val_loss=2.7, val_accuracy=0.362, lr=0.1]  34%|███▎      | 56/166 [19:42<37:16, 20.33s/epoch, loss=1.11, accuracy=0.758, val_loss=2.76, val_accuracy=0.33, lr=0.0316] 34%|███▍      | 57/166 [20:02<36:47, 20.25s/epoch, loss=1.11, accuracy=0.759, val_loss=2.86, val_accuracy=0.422, lr=0.1]   35%|███▍      | 58/166 [20:22<36:26, 20.25s/epoch, loss=1.11, accuracy=0.76, val_loss=2.8, val_accuracy=0.33, lr=0.1]    36%|███▌      | 59/166 [20:42<36:05, 20.24s/epoch, loss=1.11, accuracy=0.759, val_loss=2.71, val_accuracy=0.39, lr=0.1] 36%|███▌      | 60/166 [21:03<35:44, 20.24s/epoch, loss=1.12, accuracy=0.758, val_loss=2.02, val_accuracy=0.477, lr=0.1] 37%|███▋      | 61/166 [21:23<35:22, 20.21s/epoch, loss=1.11, accuracy=0.758, val_loss=1.78, val_accuracy=0.514, lr=0.0316] 37%|███▋      | 62/166 [21:43<35:05, 20.24s/epoch, loss=1.1, accuracy=0.761, val_loss=2.05, val_accuracy=0.413, lr=0.1]     38%|███▊      | 63/166 [22:03<34:41, 20.21s/epoch, loss=1.11, accuracy=0.757, val_loss=2.78, val_accuracy=0.413, lr=0.1] 39%|███▊      | 64/166 [22:23<34:19, 20.19s/epoch, loss=1.11, accuracy=0.759, val_loss=2.6, val_accuracy=0.304, lr=0.1]  39%|███▉      | 65/166 [22:44<33:56, 20.16s/epoch, loss=1.11, accuracy=0.758, val_loss=1.93, val_accuracy=0.576, lr=0.1] 40%|███▉      | 66/166 [23:04<33:34, 20.14s/epoch, loss=1.11, accuracy=0.761, val_loss=1.96, val_accuracy=0.485, lr=0.0316] 40%|████      | 67/166 [23:24<33:09, 20.10s/epoch, loss=1.12, accuracy=0.755, val_loss=3.62, val_accuracy=0.372, lr=0.1]    41%|████      | 68/166 [23:44<32:49, 20.09s/epoch, loss=1.11, accuracy=0.758, val_loss=1.98, val_accuracy=0.498, lr=0.1] 42%|████▏     | 69/166 [24:04<32:27, 20.08s/epoch, loss=1.1, accuracy=0.759, val_loss=2.85, val_accuracy=0.315, lr=0.1]  42%|████▏     | 70/166 [24:24<32:08, 20.08s/epoch, loss=1.11, accuracy=0.759, val_loss=1.79, val_accuracy=0.544, lr=0.1] 43%|████▎     | 71/166 [24:44<31:42, 20.03s/epoch, loss=1.11, accuracy=0.756, val_loss=1.7, val_accuracy=0.578, lr=0.0316] 43%|████▎     | 72/166 [25:04<31:20, 20.00s/epoch, loss=1.11, accuracy=0.758, val_loss=1.66, val_accuracy=0.548, lr=0.1]   44%|████▍     | 73/166 [25:24<31:01, 20.01s/epoch, loss=1.1, accuracy=0.759, val_loss=1.8, val_accuracy=0.52, lr=0.1]    45%|████▍     | 74/166 [25:43<30:33, 19.93s/epoch, loss=1.11, accuracy=0.755, val_loss=2.72, val_accuracy=0.376, lr=0.1] 45%|████▌     | 75/166 [26:04<30:16, 19.96s/epoch, loss=1.11, accuracy=0.759, val_loss=3.03, val_accuracy=0.345, lr=0.1] 46%|████▌     | 76/166 [26:24<29:57, 19.97s/epoch, loss=1.11, accuracy=0.759, val_loss=2.26, val_accuracy=0.464, lr=0.0316] 46%|████▋     | 77/166 [26:44<29:40, 20.01s/epoch, loss=1.11, accuracy=0.757, val_loss=1.74, val_accuracy=0.555, lr=0.1]    47%|████▋     | 78/166 [27:04<29:18, 19.99s/epoch, loss=1.1, accuracy=0.759, val_loss=3.16, val_accuracy=0.326, lr=0.1]  48%|████▊     | 79/166 [27:23<28:57, 19.97s/epoch, loss=1.11, accuracy=0.759, val_loss=2.71, val_accuracy=0.364, lr=0.1] 48%|████▊     | 80/166 [27:44<28:40, 20.00s/epoch, loss=1.1, accuracy=0.76, val_loss=1.68, val_accuracy=0.576, lr=0.1]   49%|████▉     | 81/166 [28:04<28:22, 20.02s/epoch, loss=1.11, accuracy=0.755, val_loss=2.8, val_accuracy=0.335, lr=0.0316] 49%|████▉     | 82/166 [28:24<28:02, 20.03s/epoch, loss=0.904, accuracy=0.816, val_loss=0.88, val_accuracy=0.812, lr=0.01] 50%|█████     | 83/166 [28:44<27:41, 20.02s/epoch, loss=0.726, accuracy=0.848, val_loss=0.811, val_accuracy=0.809, lr=0.01] 51%|█████     | 84/166 [29:04<27:22, 20.03s/epoch, loss=0.646, accuracy=0.855, val_loss=0.843, val_accuracy=0.788, lr=0.01] 51%|█████     | 85/166 [29:24<27:08, 20.10s/epoch, loss=0.597, accuracy=0.861, val_loss=0.842, val_accuracy=0.777, lr=0.01] 52%|█████▏    | 86/166 [29:44<26:47, 20.09s/epoch, loss=0.582, accuracy=0.861, val_loss=0.884, val_accuracy=0.755, lr=0.01] 52%|█████▏    | 87/166 [30:04<26:23, 20.04s/epoch, loss=0.574, accuracy=0.86, val_loss=1.18, val_accuracy=0.711, lr=0.01]   53%|█████▎    | 88/166 [30:24<25:56, 19.95s/epoch, loss=0.563, accuracy=0.864, val_loss=1.04, val_accuracy=0.723, lr=0.00316] 54%|█████▎    | 89/166 [30:44<25:32, 19.90s/epoch, loss=0.563, accuracy=0.864, val_loss=0.808, val_accuracy=0.776, lr=0.01]   54%|█████▍    | 90/166 [31:03<25:14, 19.92s/epoch, loss=0.561, accuracy=0.864, val_loss=0.789, val_accuracy=0.796, lr=0.01] 55%|█████▍    | 91/166 [31:23<24:52, 19.90s/epoch, loss=0.556, accuracy=0.868, val_loss=0.729, val_accuracy=0.812, lr=0.01] 55%|█████▌    | 92/166 [31:43<24:28, 19.85s/epoch, loss=0.559, accuracy=0.867, val_loss=1.23, val_accuracy=0.687, lr=0.01]  56%|█████▌    | 93/166 [32:03<24:14, 19.93s/epoch, loss=0.555, accuracy=0.872, val_loss=0.846, val_accuracy=0.784, lr=0.01] 57%|█████▋    | 94/166 [32:23<23:59, 20.00s/epoch, loss=0.552, accuracy=0.873, val_loss=1.03, val_accuracy=0.731, lr=0.01]  57%|█████▋    | 95/166 [32:43<23:42, 20.04s/epoch, loss=0.554, accuracy=0.872, val_loss=0.795, val_accuracy=0.795, lr=0.01] 58%|█████▊    | 96/166 [33:04<23:24, 20.06s/epoch, loss=0.551, accuracy=0.876, val_loss=0.971, val_accuracy=0.775, lr=0.00316] 58%|█████▊    | 97/166 [33:24<23:05, 20.08s/epoch, loss=0.549, accuracy=0.877, val_loss=0.749, val_accuracy=0.809, lr=0.01]    59%|█████▉    | 98/166 [33:44<22:48, 20.12s/epoch, loss=0.548, accuracy=0.877, val_loss=1.36, val_accuracy=0.682, lr=0.01]  60%|█████▉    | 99/166 [34:04<22:30, 20.16s/epoch, loss=0.55, accuracy=0.877, val_loss=0.863, val_accuracy=0.782, lr=0.01] 60%|██████    | 100/166 [34:24<22:12, 20.19s/epoch, loss=0.551, accuracy=0.877, val_loss=0.89, val_accuracy=0.787, lr=0.01] 61%|██████    | 101/166 [34:45<21:51, 20.18s/epoch, loss=0.549, accuracy=0.879, val_loss=1.01, val_accuracy=0.749, lr=0.00316] 61%|██████▏   | 102/166 [35:05<21:29, 20.16s/epoch, loss=0.554, accuracy=0.877, val_loss=0.776, val_accuracy=0.812, lr=0.01]   62%|██████▏   | 103/166 [35:25<21:09, 20.14s/epoch, loss=0.552, accuracy=0.878, val_loss=0.918, val_accuracy=0.768, lr=0.01] 63%|██████▎   | 104/166 [35:45<20:51, 20.19s/epoch, loss=0.553, accuracy=0.879, val_loss=1.09, val_accuracy=0.737, lr=0.01]  63%|██████▎   | 105/166 [36:05<20:31, 20.19s/epoch, loss=0.55, accuracy=0.879, val_loss=0.831, val_accuracy=0.799, lr=0.01] 64%|██████▍   | 106/166 [36:25<20:10, 20.18s/epoch, loss=0.549, accuracy=0.88, val_loss=0.785, val_accuracy=0.808, lr=0.00316] 64%|██████▍   | 107/166 [36:46<19:50, 20.18s/epoch, loss=0.548, accuracy=0.881, val_loss=0.82, val_accuracy=0.798, lr=0.01]    65%|██████▌   | 108/166 [37:06<19:29, 20.17s/epoch, loss=0.551, accuracy=0.881, val_loss=0.733, val_accuracy=0.824, lr=0.01] 66%|██████▌   | 109/166 [37:26<19:07, 20.14s/epoch, loss=0.55, accuracy=0.88, val_loss=0.837, val_accuracy=0.794, lr=0.01]   66%|██████▋   | 110/166 [37:46<18:48, 20.15s/epoch, loss=0.55, accuracy=0.882, val_loss=0.768, val_accuracy=0.811, lr=0.01] 67%|██████▋   | 111/166 [38:06<18:26, 20.12s/epoch, loss=0.547, accuracy=0.882, val_loss=0.832, val_accuracy=0.789, lr=0.00316] 67%|██████▋   | 112/166 [38:26<18:05, 20.10s/epoch, loss=0.543, accuracy=0.883, val_loss=1.02, val_accuracy=0.731, lr=0.01]     68%|██████▊   | 113/166 [38:46<17:42, 20.05s/epoch, loss=0.551, accuracy=0.882, val_loss=0.853, val_accuracy=0.794, lr=0.01] 69%|██████▊   | 114/166 [39:06<17:20, 20.02s/epoch, loss=0.549, accuracy=0.883, val_loss=1.97, val_accuracy=0.571, lr=0.01]  69%|██████▉   | 115/166 [39:26<16:58, 19.98s/epoch, loss=0.55, accuracy=0.882, val_loss=0.93, val_accuracy=0.769, lr=0.01]  70%|██████▉   | 116/166 [39:46<16:38, 19.97s/epoch, loss=0.546, accuracy=0.883, val_loss=0.858, val_accuracy=0.795, lr=0.00316] 70%|███████   | 117/166 [40:06<16:17, 19.94s/epoch, loss=0.546, accuracy=0.885, val_loss=0.803, val_accuracy=0.804, lr=0.01]    71%|███████   | 118/166 [40:26<15:57, 19.94s/epoch, loss=0.546, accuracy=0.884, val_loss=0.766, val_accuracy=0.816, lr=0.01] 72%|███████▏  | 119/166 [40:45<15:34, 19.89s/epoch, loss=0.55, accuracy=0.884, val_loss=0.77, val_accuracy=0.813, lr=0.01]   72%|███████▏  | 120/166 [41:05<15:15, 19.91s/epoch, loss=0.545, accuracy=0.885, val_loss=0.93, val_accuracy=0.765, lr=0.01] 73%|███████▎  | 121/166 [41:25<14:56, 19.93s/epoch, loss=0.551, accuracy=0.885, val_loss=0.747, val_accuracy=0.823, lr=0.00316] 73%|███████▎  | 122/166 [41:45<14:37, 19.95s/epoch, loss=0.466, accuracy=0.915, val_loss=0.537, val_accuracy=0.888, lr=0.001]   74%|███████▍  | 123/166 [42:05<14:17, 19.95s/epoch, loss=0.418, accuracy=0.928, val_loss=0.522, val_accuracy=0.888, lr=0.001] 75%|███████▍  | 124/166 [42:25<13:58, 19.95s/epoch, loss=0.399, accuracy=0.932, val_loss=0.507, val_accuracy=0.895, lr=0.001] 75%|███████▌  | 125/166 [42:45<13:37, 19.95s/epoch, loss=0.378, accuracy=0.938, val_loss=0.504, val_accuracy=0.897, lr=0.001] 76%|███████▌  | 126/166 [43:05<13:17, 19.94s/epoch, loss=0.368, accuracy=0.941, val_loss=0.499, val_accuracy=0.896, lr=0.001] 77%|███████▋  | 127/166 [43:25<12:58, 19.96s/epoch, loss=0.359, accuracy=0.941, val_loss=0.489, val_accuracy=0.895, lr=0.001] 77%|███████▋  | 128/166 [43:45<12:38, 19.97s/epoch, loss=0.347, accuracy=0.944, val_loss=0.483, val_accuracy=0.896, lr=0.001] 78%|███████▊  | 129/166 [44:05<12:18, 19.97s/epoch, loss=0.335, accuracy=0.946, val_loss=0.484, val_accuracy=0.895, lr=0.001] 78%|███████▊  | 130/166 [44:25<11:58, 19.96s/epoch, loss=0.325, accuracy=0.948, val_loss=0.49, val_accuracy=0.896, lr=0.001]  79%|███████▉  | 131/166 [44:45<11:39, 19.99s/epoch, loss=0.317, accuracy=0.95, val_loss=0.49, val_accuracy=0.893, lr=0.001]  80%|███████▉  | 132/166 [45:05<11:19, 19.99s/epoch, loss=0.31, accuracy=0.949, val_loss=0.473, val_accuracy=0.896, lr=0.001] 80%|████████  | 133/166 [45:25<10:58, 19.94s/epoch, loss=0.304, accuracy=0.95, val_loss=0.492, val_accuracy=0.894, lr=0.001] 81%|████████  | 134/166 [45:45<10:39, 19.97s/epoch, loss=0.295, accuracy=0.953, val_loss=0.462, val_accuracy=0.898, lr=0.001] 81%|████████▏ | 135/166 [46:05<10:20, 20.00s/epoch, loss=0.291, accuracy=0.952, val_loss=0.48, val_accuracy=0.894, lr=0.001]  82%|████████▏ | 136/166 [46:25<09:59, 19.97s/epoch, loss=0.283, accuracy=0.955, val_loss=0.479, val_accuracy=0.893, lr=0.001] 83%|████████▎ | 137/166 [46:45<09:38, 19.96s/epoch, loss=0.277, accuracy=0.955, val_loss=0.476, val_accuracy=0.892, lr=0.001] 83%|████████▎ | 138/166 [47:05<09:18, 19.96s/epoch, loss=0.274, accuracy=0.955, val_loss=0.476, val_accuracy=0.893, lr=0.001] 84%|████████▎ | 139/166 [47:25<08:58, 19.96s/epoch, loss=0.268, accuracy=0.956, val_loss=0.477, val_accuracy=0.89, lr=0.000316] 84%|████████▍ | 140/166 [47:45<08:37, 19.91s/epoch, loss=0.26, accuracy=0.958, val_loss=0.471, val_accuracy=0.894, lr=0.001]    85%|████████▍ | 141/166 [48:05<08:18, 19.95s/epoch, loss=0.257, accuracy=0.958, val_loss=0.476, val_accuracy=0.892, lr=0.001] 86%|████████▌ | 142/166 [48:24<07:57, 19.88s/epoch, loss=0.251, accuracy=0.959, val_loss=0.467, val_accuracy=0.893, lr=0.001] 86%|████████▌ | 143/166 [48:44<07:36, 19.85s/epoch, loss=0.246, accuracy=0.959, val_loss=0.469, val_accuracy=0.895, lr=0.001] 87%|████████▋ | 144/166 [49:04<07:17, 19.87s/epoch, loss=0.245, accuracy=0.959, val_loss=0.491, val_accuracy=0.887, lr=0.000316] 87%|████████▋ | 145/166 [49:24<06:57, 19.89s/epoch, loss=0.243, accuracy=0.959, val_loss=0.456, val_accuracy=0.894, lr=0.001]    88%|████████▊ | 146/166 [49:44<06:38, 19.94s/epoch, loss=0.24, accuracy=0.959, val_loss=0.483, val_accuracy=0.888, lr=0.001]  89%|████████▊ | 147/166 [50:04<06:19, 19.95s/epoch, loss=0.237, accuracy=0.96, val_loss=0.516, val_accuracy=0.88, lr=0.001]  89%|████████▉ | 148/166 [50:24<05:59, 19.98s/epoch, loss=0.235, accuracy=0.959, val_loss=0.478, val_accuracy=0.892, lr=0.001] 90%|████████▉ | 149/166 [50:44<05:40, 20.00s/epoch, loss=0.234, accuracy=0.959, val_loss=0.472, val_accuracy=0.892, lr=0.001] 90%|█████████ | 150/166 [51:04<05:19, 19.97s/epoch, loss=0.232, accuracy=0.96, val_loss=0.512, val_accuracy=0.879, lr=0.000316] 91%|█████████ | 151/166 [51:24<04:59, 20.00s/epoch, loss=0.227, accuracy=0.96, val_loss=0.518, val_accuracy=0.88, lr=0.001]     92%|█████████▏| 152/166 [51:44<04:40, 20.01s/epoch, loss=0.224, accuracy=0.961, val_loss=0.557, val_accuracy=0.872, lr=0.001] 92%|█████████▏| 153/166 [52:04<04:19, 20.00s/epoch, loss=0.222, accuracy=0.961, val_loss=0.483, val_accuracy=0.887, lr=0.001] 93%|█████████▎| 154/166 [52:24<03:59, 19.99s/epoch, loss=0.225, accuracy=0.959, val_loss=0.546, val_accuracy=0.875, lr=0.001] 93%|█████████▎| 155/166 [52:44<03:39, 19.97s/epoch, loss=0.224, accuracy=0.96, val_loss=0.463, val_accuracy=0.892, lr=0.000316] 94%|█████████▍| 156/166 [53:04<03:19, 19.93s/epoch, loss=0.22, accuracy=0.961, val_loss=0.489, val_accuracy=0.88, lr=0.001]     95%|█████████▍| 157/166 [53:24<02:59, 19.94s/epoch, loss=0.222, accuracy=0.96, val_loss=0.493, val_accuracy=0.879, lr=0.001] 95%|█████████▌| 158/166 [53:44<02:39, 19.98s/epoch, loss=0.22, accuracy=0.961, val_loss=0.502, val_accuracy=0.885, lr=0.001] 96%|█████████▌| 159/166 [54:04<02:19, 19.96s/epoch, loss=0.216, accuracy=0.961, val_loss=0.505, val_accuracy=0.876, lr=0.001] 96%|█████████▋| 160/166 [54:24<01:59, 19.94s/epoch, loss=0.215, accuracy=0.961, val_loss=0.515, val_accuracy=0.874, lr=0.000316] 97%|█████████▋| 161/166 [54:44<01:39, 19.93s/epoch, loss=0.219, accuracy=0.959, val_loss=0.563, val_accuracy=0.866, lr=0.001]    98%|█████████▊| 162/166 [55:04<01:19, 19.99s/epoch, loss=0.193, accuracy=0.97, val_loss=0.427, val_accuracy=0.903, lr=1e-04]  98%|█████████▊| 163/166 [55:23<00:59, 19.89s/epoch, loss=0.18, accuracy=0.975, val_loss=0.425, val_accuracy=0.903, lr=1e-04] 99%|█████████▉| 164/166 [55:43<00:39, 19.92s/epoch, loss=0.175, accuracy=0.977, val_loss=0.419, val_accuracy=0.903, lr=1e-04] 99%|█████████▉| 165/166 [56:03<00:19, 19.96s/epoch, loss=0.173, accuracy=0.978, val_loss=0.417, val_accuracy=0.905, lr=1e-04]100%|██████████| 166/166 [56:23<00:00, 19.97s/epoch, loss=0.169, accuracy=0.979, val_loss=0.415, val_accuracy=0.906, lr=1e-04]100%|██████████| 166/166 [56:23<00:00, 20.38s/epoch, loss=0.169, accuracy=0.979, val_loss=0.415, val_accuracy=0.906, lr=1e-04]
Using real-time data augmentation.
Test score: 0.4148460924625397
Test accuracy: 0.9057999849319458
